<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Readme</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        .header {
            background: #2c3e50;
            color: white;
            padding: 20px;
            border-bottom: 1px solid #34495e;
        }
        .header h1 {
            margin: 0;
            font-size: 1.5em;
        }
        .content {
            padding: 20px;
        }
        pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 16px;
            overflow-x: auto;
            margin: 0;
        }
        code {
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 14px;
        }
        .markdown-content {
            line-height: 1.7;
        }
        .markdown-content h1, .markdown-content h2, .markdown-content h3 {
            color: #2c3e50;
            border-bottom: 1px solid #e9ecef;
            padding-bottom: 8px;
        }
        .markdown-content pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 16px;
            overflow-x: auto;
        }
        .markdown-content code {
            background: #f1f3f4;
            padding: 2px 4px;
            border-radius: 3px;
            font-size: 0.9em;
        }
        .markdown-content pre code {
            background: none;
            padding: 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Readme</h1>
        </div>
        <div class="content">
            <div class="markdown-content"><h1>Prometheus Cheatsheets</h1>
<ul>
<li><a href="#basics">Basics</a></li>
<li><a href="#curated-examples">Curated Examples</a></li>
<li><a href="#example-queries">Example Queries</a></li>
<li><a href="#scrape-config">Scrape Configs</a></li>
<li><a href="#recording-rules">Recording Rules</a></li>
<li><a href="#external-sources">External Sources</a></li>
</ul>
<h2>Basics</h2>
<ul>
<li><code>Counter</code>: A counter metric always increases</li>
<li><code>Gauge</code>: A gauge metric can increase or decrease</li>
<li><code>Histogram</code>: A histogram metric can increase or descrease</li>
<li><a href="https://opensource.com/article/18/4/metrics-monitoring-and-python">Source and Statistics 101</a></li>
</ul>
<p>Query Functions:</p>
<ul>
<li><code>rate</code> - The rate function calculates at what rate the counter increases per second over a given time window. <a href="https://levelup.gitconnected.com/prometheus-counter-metrics-d6c393d86076">src</a></li>
<li><code>irate</code> - Calculates at what rate the counter increases per second over a defined time window. The difference being that irate only looks at the last two data points. This makes irate well suited for graphing volatile and/or fast-moving counters. <a href="https://levelup.gitconnected.com/prometheus-counter-metrics-d6c393d86076">src</a></li>
<li><code>increase</code> - The increase function calculates the counter increase over a given time frame. <a href="https://levelup.gitconnected.com/prometheus-counter-metrics-d6c393d86076">src</a></li>
<li><code>resets</code> - The function gives you the number of counter resets over a given time window. <a href="https://levelup.gitconnected.com/prometheus-counter-metrics-d6c393d86076">src</a></li>
</ul>
<h2>Curated Examples</h2>
<p>Example queries per exporter / service:</p>
<ul>
<li><a href="metric_examples/NODE_METRICS.md">Node Metrics</a></li>
</ul>
<h2>Questions and Answers</h2>
<p>How can I get the amount of requests over a given time (dashboard time):</p>
<pre class="codehilite"><code>sum by (uri) (increase(http_requests_total[$__range]))
</code></pre>

<p>How many pod restarts per minute?</p>
<pre class="codehilite"><code>rate(kube_pod_container_status_restarts_total{job=&quot;kube-state-metrics&quot;,namespace=&quot;default&quot;}[15m]) * 60 * 15
</code></pre>

<p>View the pod restarts over time:</p>
<pre class="codehilite"><code class="language-bash">sum(kube_pod_container_status_restarts_total{container=&quot;my-service&quot;}) by (pod)
</code></pre>

<h2>Example Queries</h2>
<p>Show me all the metric names for the job=app:</p>
<pre class="codehilite"><code>group ({job=&quot;app&quot;}) by (__name__)
</code></pre>

<p>How many nodes are up?</p>
<pre class="codehilite"><code>up
</code></pre>

<p>Combining values from 2 different vectors (Hostname with a Metric):</p>
<pre class="codehilite"><code>up * on(instance) group_left(nodename) (node_uname_info)
</code></pre>

<p>Exclude labels:</p>
<pre class="codehilite"><code>sum without(job) (up * on(instance)  group_left(nodename)  (node_uname_info))
</code></pre>

<p>Count targets per job:</p>
<pre class="codehilite"><code>count by (job) (up)
</code></pre>

<p>Amount of Memory Available:</p>
<pre class="codehilite"><code>node_memory_MemAvailable_bytes
</code></pre>

<p>Amount of Memory Available in MB:</p>
<pre class="codehilite"><code>node_memory_MemAvailable_bytes/1024/1024
</code></pre>

<p>Amount of Memory Available in MB 10 minutes ago:</p>
<pre class="codehilite"><code>node_memory_MemAvailable_bytes/1024/1024 offset 10m
</code></pre>

<p>Average Memory Available for Last 5 Minutes:</p>
<pre class="codehilite"><code>avg_over_time(node_memory_MemAvailable_bytes[5m])/1024/1024
</code></pre>

<p>Memory Usage in Percent:</p>
<pre class="codehilite"><code>100 * (1 - ((avg_over_time(node_memory_MemFree_bytes[10m]) + avg_over_time(node_memory_Cached_bytes[10m]) + avg_over_time(node_memory_Buffers_bytes[10m])) / avg_over_time(node_memory_MemTotal_bytes[10m])))
</code></pre>

<p>CPU Utilization:</p>
<pre class="codehilite"><code>100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=&quot;idle&quot;, instance=&quot;my-instance&quot;}[5m])) * 100 ) 
</code></pre>

<p>CPU Utilization offset with 24hours ago:</p>
<pre class="codehilite"><code>100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=&quot;idle&quot;, instance=&quot;my-instance&quot;}[5m] offset 24h)) * 100 )
</code></pre>

<p>CPU Utilization per Core:</p>
<pre class="codehilite"><code>( (1 - rate(node_cpu_seconds_total{job=&quot;node-exporter&quot;, mode=&quot;idle&quot;, instance=&quot;$instance&quot;}[$__interval])) / ignoring(cpu) group_left count without (cpu)( node_cpu_seconds_total{job=&quot;node-exporter&quot;, mode=&quot;idle&quot;, instance=&quot;$instance&quot;}) ) 
</code></pre>

<p>CPU Utilization by Node:</p>
<pre class="codehilite"><code>100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=&quot;idle&quot;}[10m]) * 100) * on(instance) group_left(nodename) (node_uname_info))
</code></pre>

<p>Memory Available by Node:</p>
<pre class="codehilite"><code>node_memory_MemAvailable_bytes * on(instance) group_left(nodename) (node_uname_info)
</code></pre>

<p>Or if you rely on labels from other metrics:</p>
<pre class="codehilite"><code>(node_memory_MemTotal_bytes{job=&quot;node-exporter&quot;} - node_memory_MemFree_bytes{job=&quot;node-exporter&quot;} - node_memory_Buffers_bytes{job=&quot;node-exporter&quot;} - node_memory_Cached_bytes{job=&quot;node-exporter&quot;}) * on(instance) group_left(nodename) (node_uname_info{nodename=~&quot;$nodename&quot;})
</code></pre>

<p>Load Average in percentage:</p>
<pre class="codehilite"><code>avg(node_load1{instance=~&quot;$name&quot;, job=~&quot;$job&quot;}) /  count(count(node_cpu_seconds_total{instance=~&quot;$name&quot;, job=~&quot;$job&quot;}) by (cpu)) * 100
</code></pre>

<p>Load Average per Instance:</p>
<pre class="codehilite"><code>sum(node_load5{}) by (instance) / count(node_cpu_seconds_total{mode=&quot;user&quot;}) by (instance) * 100
</code></pre>

<p>Load Average (average per instance_id: lets say the metric has 2 identical label values but are different):</p>
<pre class="codehilite"><code>avg by (instance_id, instance) (node_load1{job=~&quot;node-exporter&quot;, aws_environment=&quot;dev&quot;, instance=&quot;debug-dev&quot;})
# {instance=&quot;debug-dev&quot;,instance_id=&quot;i-aaaaaaaaaaaaaaaaa&quot;}
# {instance=&quot;debug-dev&quot;,instance_id=&quot;i-bbbbbbbbbbbbbbbbb&quot;}
</code></pre>

<p>Disk Available by Node:</p>
<pre class="codehilite"><code>node_filesystem_free_bytes{mountpoint=&quot;/&quot;} * on(instance) group_left(nodename) (node_uname_info)
</code></pre>

<p>Disk IO per Node: Outbound:</p>
<pre class="codehilite"><code>sum(rate(node_disk_read_bytes_total[1m])) by (device, instance) * on(instance) group_left(nodename) (node_uname_info)
</code></pre>

<p>Disk IO per Node: Inbound:</p>
<pre class="codehilite"><code>sum(rate(node_disk_written_bytes_total{job=&quot;node&quot;}[1m])) by (device, instance) * on(instance) group_left(nodename) (node_uname_info)
</code></pre>

<p>Network IO per Node:</p>
<pre class="codehilite"><code>sum(rate(node_network_receive_bytes_total[1m])) by (device, instance) * on(instance) group_left(nodename) (node_uname_info)
sum(rate(node_network_transmit_bytes_total[1m])) by (device, instance) * on(instance) group_left(nodename) (node_uname_info)
</code></pre>

<p>Process Restarts:</p>
<pre class="codehilite"><code>changes(process_start_time_seconds{job=~&quot;.+&quot;}[15m])
</code></pre>

<p>Container Cycling:</p>
<pre class="codehilite"><code>(time() - container_start_time_seconds{job=~&quot;.+&quot;}) &lt; 60
</code></pre>

<p>Histogram:</p>
<pre class="codehilite"><code>histogram_quantile(1.00, sum(rate(prometheus_http_request_duration_seconds_bucket[5m])) by (handler, le)) * 1e3
</code></pre>

<p>Metrics 24 hours ago (nice when you compare today with yesterday):</p>
<pre class="codehilite"><code># query a
total_number_of_errors{instance=&quot;my-instance&quot;, region=&quot;eu-west-1&quot;}
# query b
total_number_of_errors{instance=&quot;my-instance&quot;, region=&quot;eu-west-1&quot;} offset 24h

# related:
# https://about.gitlab.com/blog/2019/07/23/anomaly-detection-using-prometheus/
</code></pre>

<p>Number of Nodes (Up):</p>
<pre class="codehilite"><code>count(up{job=&quot;cadvisor_my-swarm&quot;})
</code></pre>

<p>Running Containers per Node:</p>
<pre class="codehilite"><code>count(container_last_seen) BY (container_label_com_docker_swarm_node_id)
</code></pre>

<p>Running Containers per Node, include corresponding hostnames:</p>
<pre class="codehilite"><code>count(container_last_seen) BY (container_label_com_docker_swarm_node_id) * ON (container_label_com_docker_swarm_node_id) GROUP_LEFT(node_name) node_meta 
</code></pre>

<p>HAProxy Response Codes:</p>
<pre class="codehilite"><code>haproxy_server_http_responses_total{backend=~&quot;$backend&quot;, server=~&quot;$server&quot;, code=~&quot;$code&quot;, alias=~&quot;$alias&quot;} &gt; 0
</code></pre>

<p>Metrics with the most resources:</p>
<pre class="codehilite"><code>topk(10, count by (__name__)({__name__=~&quot;.+&quot;}))
</code></pre>

<p>the same, but per job:</p>
<pre class="codehilite"><code>topk(10, count by (__name__, job)({__name__=~&quot;.+&quot;}))
</code></pre>

<p>or jobs have the most time series:</p>
<pre class="codehilite"><code>topk(10, count by (job)({__name__=~&quot;.+&quot;}))
</code></pre>

<p>Top 5 per value:</p>
<pre class="codehilite"><code>sort_desc(topk(5, aws_service_costs))
</code></pre>

<p>Table - Top 5 (enable instant as well):</p>
<pre class="codehilite"><code>sort(topk(5, aws_service_costs))
</code></pre>

<p>Most metrics per job, sorted:</p>
<pre class="codehilite"><code>sort_desc (sum by (job) (count by (__name__, job)({job=~&quot;.+&quot;})))
</code></pre>

<p>Group per Day (Table) - wip</p>
<pre class="codehilite"><code>aws_service_costs{service=~&quot;$service&quot;} + ignoring(year, month, day) group_right
  count_values without() (&quot;year&quot;, year(timestamp(
    count_values without() (&quot;month&quot;, month(timestamp(
      count_values without() (&quot;day&quot;, day_of_month(timestamp(
        aws_service_costs{service=~&quot;$service&quot;}
      )))
    )))
  ))) * 0
</code></pre>

<p>Group Metrics per node hostname:</p>
<pre class="codehilite"><code>node_memory_MemAvailable_bytes * on(instance) group_left(nodename) (node_uname_info)

..
{cloud_provider=&quot;amazon&quot;,instance=&quot;x.x.x.x:9100&quot;,job=&quot;node_n1&quot;,my_hostname=&quot;n1.x.x&quot;,nodename=&quot;n1.x.x&quot;}
</code></pre>

<p>Subtract two gauge metrics (exclude the label that dont match):</p>
<pre class="codehilite"><code>polkadot_block_height{instance=&quot;polkadot&quot;, chain=~&quot;$chain&quot;, status=&quot;sync_target&quot;} - ignoring(status) polkadot_block_height{instance=&quot;polkadot&quot;, chain=~&quot;$chain&quot;, status=&quot;finalized&quot;}
</code></pre>

<p>Conditional joins when labels exisits:</p>
<pre class="codehilite"><code>(
    # source: https://stackoverflow.com/a/72218915
    # For all sensors that have a name (label &quot;label&quot;), join them with `node_hwmon_sensor_label` to get that name.
    (node_hwmon_temp_celsius * ignoring(label) group_left(label) node_hwmon_sensor_label)
  or
    # For all sensors that do NOT a name (label &quot;label&quot;) in `node_hwmon_sensor_label`, assign them `label=&quot;unknown-sensor-name&quot;`.
    # `label_replace()` only adds the new label, it does not remove the old one.
    (label_replace((node_hwmon_temp_celsius unless ignoring(label) node_hwmon_sensor_label), &quot;label&quot;, &quot;unknown-sensor-name&quot;, &quot;&quot;, &quot;.*&quot;))
)
</code></pre>

<p>Container CPU Average for 5m:</p>
<pre class="codehilite"><code>(sum by(instance, container_label_com_amazonaws_ecs_container_name, container_label_com_amazonaws_ecs_cluster) (rate(container_cpu_usage_seconds_total[5m])) * 100) 
</code></pre>

<p>Container Memory Usage: Total:</p>
<pre class="codehilite"><code>sum(container_memory_rss{container_label_com_docker_swarm_task_name=~&quot;.+&quot;})
</code></pre>

<p>Container Memory, per Task, Node:</p>
<pre class="codehilite"><code>sum(container_memory_rss{container_label_com_docker_swarm_task_name=~&quot;.+&quot;}) BY (container_label_com_docker_swarm_task_name, container_label_com_docker_swarm_node_id)
</code></pre>

<p>Container Memory per Node:</p>
<pre class="codehilite"><code>sum(container_memory_rss{container_label_com_docker_swarm_task_name=~&quot;.+&quot;}) BY (container_label_com_docker_swarm_node_id)
</code></pre>

<p>Memory Usage per Stack:</p>
<pre class="codehilite"><code>sum(container_memory_rss{container_label_com_docker_swarm_task_name=~&quot;.+&quot;}) BY (container_label_com_docker_stack_namespace)
</code></pre>

<p>Remove metrics from results that does not contain a specific label:</p>
<pre class="codehilite"><code>container_cpu_usage_seconds_total{container_label_com_amazonaws_ecs_cluster!=&quot;&quot;}
</code></pre>

<p>Remove labels from a metric:</p>
<pre class="codehilite"><code>sum without (age, country) (people_metrics)
</code></pre>

<p>View top 10 biggest metrics by name:</p>
<pre class="codehilite"><code>topk(10, count by (__name__)({__name__=~&quot;.+&quot;}))
</code></pre>

<p>View top 10 biggest metrics by name, job:</p>
<pre class="codehilite"><code>topk(10, count by (__name__, job)({__name__=~&quot;.+&quot;}))
</code></pre>

<p>View all metrics for a specific job:</p>
<pre class="codehilite"><code>{__name__=~&quot;.+&quot;, job=&quot;node-exporter&quot;}
</code></pre>

<p>View all metrics for more than one job using vector selectors</p>
<pre class="codehilite"><code>{__name__=~&quot;.+&quot;, job=~&quot;traefik|cadvisor|prometheus&quot;}
</code></pre>

<p>Website uptime with blackbox-exporter:</p>
<pre class="codehilite"><code># https://www.robustperception.io/what-percentage-of-time-is-my-service-down-for

avg_over_time(probe_success{job=&quot;node&quot;}[15m]) * 100
</code></pre>

<p>Remove / Replace:</p>
<ul>
<li>https://medium.com/@texasdave2/replace-and-remove-a-label-in-a-prometheus-query-9500faa302f0</li>
</ul>
<p><strong>Client Request Counts</strong>:</p>
<pre class="codehilite"><code>irate(http_client_requests_seconds_count{job=&quot;web-metrics&quot;, environment=&quot;dev&quot;, uri!~&quot;.*actuator.*&quot;}[5m])
</code></pre>

<p><strong>Client Response Time</strong>:</p>
<pre class="codehilite"><code>irate(http_client_requests_seconds_sum{job=&quot;web-metrics&quot;, environment=&quot;dev&quot;, uri!~&quot;.*actuator.*&quot;}[5m]) / 
irate(http_client_requests_seconds_count{job=&quot;web-metrics&quot;, environment=&quot;dev&quot;, uri!~&quot;.*actuator.*&quot;}[5m])
</code></pre>

<p><strong>Requests per Second</strong>:</p>
<pre class="codehilite"><code>sum(increase(http_server_requests_seconds_count{service=&quot;my-service&quot;, env=&quot;dev&quot;}[1m])) by (uri)
</code></pre>

<p>is the same as:</p>
<pre class="codehilite"><code>sum(rate(http_server_requests_seconds_count{service=&quot;my-service&quot;, env=&quot;dev&quot;}[1m]) * 60 ) by (uri)
</code></pre>

<p>See this <a href="https://stackoverflow.com/questions/66282512/grafana-graphing-http-requests-per-minute-with-http-server-requests-seconds-coun">SO thread</a> for more details</p>
<p><strong>p95 Request Latencies</strong> with <code>histogram_quantile</code> (the latency experienced by the slowest 5% of requests in seconds):</p>
<pre class="codehilite"><code class="language-promql">histogram_quantile(0.95, sum by (le, store) (rate(myapp_latency_seconds_bucket{application=&quot;product-service&quot;, category=~&quot;.+&quot;}[5m])))
</code></pre>

<p>Resource Requests and Limits:</p>
<pre class="codehilite"><code># for cpu: average rate of cpu usage over 15minutes
rate(container_cpu_usage_seconds_total{job=&quot;kubelet&quot;,container=&quot;my-application&quot;}[15m])

# for mem: shows in mb
container_memory_usage_bytes{job=&quot;kubelet&quot;,container=&quot;my-application&quot;}  / (1024 * 1024)
</code></pre>

<h2>Scrape Config</h2>
<p>relabel configs:</p>
<pre class="codehilite"><code># full example: https://gist.github.com/ruanbekker/72216bea59fc56af189f5a7b2e3a8002
scrape_configs:
  - job_name: 'multipass-nodes'
    static_configs:
    - targets: ['ip-192-168-64-29.multipass:9100']
      labels:
        env: test
    - targets: ['ip-192-168-64-30.multipass:9100']
      labels:
        env: test
    # https://grafana.com/blog/2022/03/21/how-relabeling-in-prometheus-works/#internal-labels
    relabel_configs:
    - source_labels: [__address__]
      separator: ':'
      regex: '(.*):(.*)'
      replacement: '${1}'
      target_label: instance
</code></pre>

<p>static_configs:</p>
<pre class="codehilite"><code>scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 5s
    static_configs:
         - targets: ['localhost:9090']
      labels:
        region: 'eu-west-1'
</code></pre>

<p>dns_sd_configs:</p>
<pre class="codehilite"><code>scrape_configs:
  - job_name: 'mysql-exporter'
    scrape_interval: 5s
    dns_sd_configs:
    - names:
      - 'tasks.mysql-exporter'
      type: 'A'
      port: 9104
    relabel_configs:
    - source_labels: [__address__]
      regex: '.*'
      target_label: instance
      replacement: 'mysqld-exporter'
</code></pre>

<p>Useful links:</p>
<ul>
<li>https://gist.github.com/ruanbekker/72216bea59fc56af189f5a7b2e3a8002</li>
<li>https://gist.github.com/trastle/1aa205354577ef0b329d4b8cc84c674a</li>
<li>https://github.com/prometheus/docs/issues/341</li>
<li>https://medium.com/quiq-blog/prometheus-relabeling-tricks-6ae62c56cbda</li>
<li>https://blog.freshtracks.io/prometheus-relabel-rules-and-the-action-parameter-39c71959354a</li>
<li>https://www.robustperception.io/relabel_configs-vs-metric_relabel_configs</li>
<li>https://training.robustperception.io/courses/prometheus-configuration/lectures/3170347</li>
</ul>
<h2>Grafana with Prometheus</h2>
<p>If you have output like this on grafana:</p>
<pre class="codehilite"><code>{instance=&quot;10.0.2.66:9100&quot;,job=&quot;node&quot;,nodename=&quot;rpi-02&quot;}
</code></pre>

<p>and you only want to show the hostnames, you can apply the following in "Legend" input:</p>
<pre class="codehilite"><code>{{nodename}}
</code></pre>

<p>If your output want <code>exported_instance</code> in:</p>
<pre class="codehilite"><code>sum(exporter_memory_usage{exported_instance=&quot;myapp&quot;})
</code></pre>

<p>You would need to do:</p>
<pre class="codehilite"><code>sum by (exported_instance) (exporter_memory_usage{exported_instance=&quot;my_app&quot;})
</code></pre>

<p>Then on Legend:</p>
<pre class="codehilite"><code>{{exported_instance}}
</code></pre>

<h3>Variables</h3>
<ul>
<li>Hostname:</li>
</ul>
<p>name: <code>node</code>
label: <code>node</code>
node: <code>label_values(node_uname_info, nodename)</code></p>
<p>Then in Grafana you can use:</p>
<pre class="codehilite"><code>sum(rate(node_disk_read_bytes_total{job=&quot;node&quot;}[1m])) by (device, instance) * on(instance) group_left(nodename) (node_uname_info{nodename=~&quot;$node&quot;})
</code></pre>

<ul>
<li>Node Exporter Address</li>
</ul>
<p>type: <code>query</code>
query: <code>label_values(node_network_up, instance)</code></p>
<ul>
<li>MySQL Exporter Address</li>
</ul>
<p>type: <code>query</code>
query: <code>label_values(mysql_up, instance)</code></p>
<ul>
<li>Static Values:</li>
</ul>
<p>type: <code>custom</code>
name: <code>dc</code>
label: <code>dc</code>
values seperated by comma: <code>eu-west-1a,eu-west-1b,eu-west-1c</code></p>
<ul>
<li>Docker Swarm Stack Names</li>
</ul>
<p>name: <code>stack</code>
label: <code>stack</code>
query: <code>label_values(container_last_seen,container_label_com_docker_stack_namespace)</code></p>
<ul>
<li>Docker Swarm Service Names</li>
</ul>
<p>name: <code>service_name</code>
label: <code>service_name</code>
query: <code>label_values(container_last_seen,container_label_com_docker_swarm_service_name)</code></p>
<ul>
<li>Docker Swarm Manager NodeId:</li>
</ul>
<p>name: <code>manager_node_id</code>
label: <code>manager_node_id</code>
query: </p>
<pre class="codehilite"><code>label_values(container_last_seen{container_label_com_docker_swarm_service_name=~&quot;proxy_traefik&quot;, container_label_com_docker_swarm_node_id=~&quot;.*&quot;}, container_label_com_docker_swarm_node_id)
</code></pre>

<ul>
<li>Docker Swarm Stacks Running on Managers</li>
</ul>
<p>name: <code>stack_on_manager</code>
label: <code>stack_on_manager</code>
query: </p>
<pre class="codehilite"><code>label_values(container_last_seen{container_label_com_docker_swarm_node_id=~&quot;$manager_node_id&quot;},container_label_com_docker_stack_namespace)
</code></pre>

<h2>Recording Rules</h2>
<ul>
<li><a href="https://deploy.live/blog/today-i-learned-prometheus-recording-rules/">@deploy.live's Recording Rules Post</a></li>
</ul>
<h2>Application Instrumentation</h2>
<h3>Python Flask</h3>
<ul>
<li><a href="https://github.com/ramdesh/flask-prometheus-grafana-example">@ramdesh flask-prometheus-grafana-example</a></li>
</ul>
<h2>External Sources</h2>
<ul>
<li><a href="https://prometheus.io/docs/querying/basics/">Prometheus</a></li>
<li><a href="https://medium.com/@valyala/promql-tutorial-for-beginners-9ab455142085">PromQL for Beginners</a></li>
<li><a href="https://medianetlab.gr/prometheus-101/">Prometheus 101</a></li>
<li><a href="https://www.section.io/blog/prometheus-querying/">Section.io: Prometheus Querying</a></li>
<li><a href="https://www.innoq.com/en/blog/prometheus-counters/">InnoQ: Prometheus Counters</a></li>
<li><a href="https://www.robustperception.io/which-are-my-biggest-metrics">Biggest Metrics</a></li>
<li><a href="https://github.com/grafana/grafana/issues/6561">Top Metrics</a></li>
<li><a href="https://ordina-jworks.github.io/monitoring/2016/09/23/Monitoring-with-Prometheus.html">Ordina-Jworks</a></li>
<li><a href="https://github.com/infinityworks/prometheus-example-queries">Infinity Works</a></li>
<li><a href="https://medium.com/quiq-blog/prometheus-relabeling-tricks-6ae62c56cbda">Prometheus Relabeling Tricks</a></li>
<li><a href="https://medium.com/@valyala/promql-tutorial-for-beginners-9ab455142085">@Valyala: PromQL Tutorial for Beginners</a></li>
<li><a href="https://github.com/jitendra-1217/promql.cheat.sheet">@Jitendra: PromQL Cheat Sheet</a></li>
<li><a href="https://github.com/infinityworks/prometheus-example-queries/blob/master/README.md">InfinityWorks: Prometheus Example Queries</a></li>
<li><a href="https://timber.io/blog/promql-for-humans/">Timber: PromQL for Humans</a></li>
<li><a href="https://www.section.io/blog/prometheus-querying/">SectionIO: Prometheus Querying</a></li>
<li><a href="">RobustPerception</a></li>
<li><a href="https://www.robustperception.io/understanding-machine-cpu-usage">RobustPerception: Understanding Machine CPU Usage</a></li>
<li><a href="https://www.robustperception.io/common-query-patterns-in-promql">RobustPerception: Common Query Patterns</a></li>
<li><a href="https://www.robustperception.io/what-percentage-of-time-is-my-service-down-for">RobustPerception: Website Uptime</a></li>
<li><a href="https://www.robustperception.io/how-does-a-prometheus-histogram-work">RobustPerception: Prometheus Histogram</a></li>
<li><a href="https://www.robustperception.io/how-does-a-prometheus-counter-work">RobustPerception: Prometheus Counter</a></li>
<li><a href="https://www.robustperception.io/how-does-a-prometheus-gauge-work">RobustPerception: Prometheus Guage</a></li>
<li><a href="https://www.robustperception.io/how-does-a-prometheus-summary-work">RobustPerception: Prometheus Summary</a></li>
<li><a href="https://devconnected.com/the-definitive-guide-to-prometheus-in-2019/">DevConnected: The Definitive Guide to Prometheus</a></li>
<li><a href="https://tech.showmax.com/2019/10/prometheus-introduction/">@showmax Prometheus Introduction</a></li>
<li><a href="https://rancher.com/docs/rancher/v2.0-v2.4/en/cluster-admin/tools/cluster-monitoring/expression/">@rancher Cluster Monitoring</a></li>
<li><a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusCPUStats">Prometheus CPU Stats</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-Prometheus-Setup-configure.html#ContainerInsights-Prometheus-Setup-config-scrape">@aws Prometheus Rewrite Rules for k8s</a></li>
<li><a href="">ec2_sd_configs</a></li>
<li><a href="https://jarodw.com/posts/prometheus-ec2-sd-multiple-aws-accounts/">Prometheus AWS Cross Account ec2_sd_config</a></li>
<li><a href="https://medium.com/investing-in-tech/automatic-monitoring-for-all-new-aws-instances-using-prometheus-service-discovery-97d37a5b2ea2">Prometheus AWS ec2_sd_config role</a></li>
<li><a href="">kubernetes_sd_configs</a></li>
<li><a href="https://fabianlee.org/2022/07/08/prometheus-monitoring-services-using-additional-scrape-config-for-prometheus-operator/">fabianlee kubernetes configs</a></li>
<li><a href="https://www.metricfire.com/blog/understanding-the-prometheus-rate-function/">@metricfire.com: Understanding the Rate Function</a>
Dashboarding:</li>
<li><a href="https://niravshah2705.medium.com/prometheus-alert-for-missing-metrics-and-labels-afd4b8f12b1">Alerting on Missing Labels and Metrics</a></li>
<li><a href="https://devconnected.com/monitoring-disk-i-o-on-linux-with-the-node-exporter/">@devconnected Disk IO Dashboarding</a></li>
<li><a href="https://deploy.live/blog/today-i-learned-prometheus-recording-rules/">@deploy.live recording rules</a></li>
<li><a href="https://gist.github.com/max-rocket-internet/6a05ee757b6587668a1de8a5c177728b">CPU and Memory Requests</a></li>
<li><a href="https://levelup.gitconnected.com/prometheus-counter-metrics-d6c393d86076">Prometheus Counter Metrics</a></li>
<li><a href="https://last9.io/blog/promql-cheat-sheet/?ref=cheatsheets.ruanbekker.com">last9.io PromQL Cheatsheet</a></li>
</ul>
<p>Setups:</p>
<ul>
<li><a href="https://ops.tips/blog/simulating-aws-tags-in-local-prometheus/">Simulating AWS Tags in Local Prometheus</a></li>
</ul></div>
        </div>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>
        hljs.highlightAll();
    </script>
</body>
</html>