<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kubernetes Prometheus Metrics - Monitor Cluster Health</title>
    <meta name="description" content="Monitor Kubernetes cluster health with Prometheus metrics. Explore container and node metrics for resource usage, performance, and potential issues.">
    <meta name="keywords" content="Kubernetes, Prometheus, metrics, monitoring, cluster health, container metrics, node metrics, Kubelet, API server, resource usage, CPU throttling, memory, disk space">
    <link rel="canonical" href="https://your-website.com/prometheus/KUBERNETES.html">
    <meta name="robots" content="index, follow">
    <meta property="og:title" content="Kubernetes Prometheus Metrics - Monitor Cluster Health">
    <meta property="og:description" content="Monitor Kubernetes cluster health with Prometheus metrics. Explore container and node metrics for resource usage, performance, and potential issues.">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://your-website.com/prometheus/KUBERNETES.html">
    <meta property="og:image" content="https://your-website.com/path/to/your/og-image.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Kubernetes Prometheus Metrics - Monitor Cluster Health">
    <meta name="twitter:description" content="Monitor Kubernetes cluster health with Prometheus metrics. Explore container and node metrics for resource usage, performance, and potential issues.">
    <meta name="twitter:image" content="https://your-website.com/path/to/your/twitter-image.png">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        .header {
            background: #2c3e50;
            color: white;
            padding: 20px;
            border-bottom: 1px solid #34495e;
        }
        .header h1 {
            margin: 0;
            font-size: 1.5em;
        }
        .content {
            padding: 20px;
        }
        pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 16px;
            overflow-x: auto;
            margin: 0;
        }
        code {
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 14px;
        }
        .markdown-content {
            line-height: 1.7;
        }
        .markdown-content h1, .markdown-content h2, .markdown-content h3 {
            color: #2c3e50;
            border-bottom: 1px solid #e9ecef;
            padding-bottom: 8px;
        }
        .markdown-content pre {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 16px;
            overflow-x: auto;
        }
        .markdown-content code {
            background: #f1f3f4;
            padding: 2px 4px;
            border-radius: 3px;
            font-size: 0.9em;
        }
        .markdown-content pre code {
            background: none;
            padding: 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Kubernetes Prometheus Metrics</h1>
        </div>
        <div class="content">
            <div class="markdown-content">
                <h2>Container Metrics</h2>
                <h3>Pod Resource Constraints</h3>
                <p>This section details metrics related to pod memory usage and limits, specifically when resource requests and limits are configured. Understanding these metrics is crucial for efficient resource allocation and preventing OOMKilled events.</p>
                <pre class="codehilite"><code>process_resident_memory_bytes{pod="prometheus-prometheus-kube-prometheus-prometheus-0"}
kube_pod_container_resource_requests{resource="memory", pod="kube-prometheus-prometheus-0"}
kube_pod_container_resource_limits{resource="memory", pod="kube-prometheus-prometheus-0"}
</code></pre>

                <h3>High CPU Throttling</h3>
                <p>Alerts when a container experiences significant CPU throttling. This indicates that the container is not receiving enough CPU resources to meet its demands, potentially impacting application performance.</p>
                <pre class="codehilite"><code>sum by(container, pod, namespace) (increase(container_cpu_cfs_throttled_periods_total{container!=""}[5m])) / sum by(container, pod, namespace) (increase(container_cpu_cfs_periods_total[5m])) > (25 / 100)
</code></pre>

                <h3>Kube API Server Down</h3>
                <p>Detects when the Kubernetes API server is no longer discoverable by Prometheus, indicating a critical failure in the control plane.</p>
                <pre class="codehilite"><code>absent(up{job="apiserver"} == 1)
</code></pre>

                <h3>Kubelet Down</h3>
                <p>Alerts if the Kubelet, responsible for managing pods on a node, disappears from Prometheus target discovery, signaling a potential node issue.</p>
                <pre class="codehilite"><code>absent(up{job="kubelet"} == 1)
</code></pre>

                <h3>High Kube API Errors</h3>
                <p>Monitors the rate of HTTP 5xx errors returned by the Kubernetes API server, indicating potential instability or overload.</p>
                <pre class="codehilite"><code>sum by(resource, subresource, verb) (rate(apiserver_request_total{code=~"5..",job="apiserver"}[5m])) / sum by(resource, subresource, verb) (rate(apiserver_request_total{job="apiserver"}[5m])) > 0.1
</code></pre>

                <h3>High Kube API Latency</h3>
                <p>Identifies abnormal latency in API server requests, helping to pinpoint performance bottlenecks within the Kubernetes control plane.</p>
                <pre class="codehilite"><code>(cluster:apiserver_request_duration_seconds:mean5m{job="apiserver"} > on(verb) group_left() (avg by(verb) (cluster:apiserver_request_duration_seconds:mean5m{job="apiserver"} >= 0) + 2 * stddev by(verb) (cluster:apiserver_request_duration_seconds:mean5m{job="apiserver"} >= 0))) > on(verb) group_left() 1.2 * avg by(verb) (cluster:apiserver_request_duration_seconds:mean5m{job="apiserver"} >= 0) and on(verb, resource) cluster_quantile:apiserver_request_duration_seconds:histogram_quantile{job="apiserver",quantile="0.99"} > 1
</code></pre>

                <h3>Container in Waiting State</h3>
                <p>Alerts when a pod's container has been in a waiting state for an extended period (e.g., over an hour), which could indicate issues with image pulling, scheduling, or readiness probes.</p>
                <pre class="codehilite"><code>sum by(namespace, pod, container) (kube_pod_container_status_waiting_reason{job="kube-state-metrics",namespace=~".*"}) > 0
</code></pre>

                <h3>Deployment Replicas Mismatch</h3>
                <p>Notifies when a Kubernetes Deployment has a mismatch between the desired and available replicas for more than 15 minutes, suggesting a problem with scaling or rollout.</p>
                <pre class="codehilite"><code>(kube_deployment_spec_replicas{job="kube-state-metrics",namespace=~".*"} != kube_deployment_status_replicas_available{job="kube-state-metrics",namespace=~".*"}) and (changes(kube_deployment_status_replicas_updated{job="kube-state-metrics",namespace=~".*"} [5m]) == 0)
</code></pre>

                <h3>StatefulSet Replicas Mismatch</h3>
                <p>Similar to Deployments, this alerts on discrepancies between desired and ready replicas for StatefulSets, crucial for stateful applications.</p>
                <pre class="codehilite"><code>(kube_statefulset_status_replicas_ready{job="kube-state-metrics",namespace=~".*"} != kube_statefulset_status_replicas{job="kube-state-metrics",namespace=~".*"}) and (changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics",namespace=~".*"} [5m]) == 0)
</code></pre>

                <h3>Persistent Volume Filling Up</h3>
                <p>Warns when a Persistent Volume (PV) is running low on free space, providing a percentage of available space. This helps prevent data loss due to full storage.</p>
                <pre class="codehilite"><code>kubelet_volume_stats_available_bytes{job="kubelet",metrics_path="/metrics",namespace=~".*"} / kubelet_volume_stats_capacity_bytes{job="kubelet",metrics_path="/metrics",namespace=~".*"} < 0.03
</code></pre>

                <h3>Low Persistent Volume Percentage</h3>
                <p>A more general alert for Persistent Volumes that are over 80% utilized, prompting proactive storage management.</p>
                <pre class="codehilite"><code>sum by (persistentvolumeclaim) (kubelet_volume_stats_used_bytes{job="kubelet"} / kubelet_volume_stats_capacity_bytes) * 100.0 > 80
</code></pre>

                <h3>Persistent Volume Errors</h3>
                <p>Detects Persistent Volumes in an erroneous state, such as 'Failed' or 'Pending', which requires immediate attention.</p>
                <pre class="codehilite"><code>kube_persistentvolume_status_phase{job="kube-state-metrics",phase=~"Failed|Pending"} > 0
</code></pre>

                <h3>Pod Crashing Loop</h3>
                <p>Identifies pods that are repeatedly restarting within a short timeframe (e.g., 5 minutes), indicating an application crash or misconfiguration.</p>
                <pre class="codehilite"><code>rate(kube_pod_container_status_restarts_total{job="kube-state-metrics",namespace=~".*"}[15m]) * 60 * 5 > 0
</code></pre>

                <p>Customizable message for pod restart alerts:</p>
                <pre class="codehilite"><code>Pod {{ $labels.namespace }} / {{ $labels.pod }} ({{ $labels.container }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
</code></pre>

                <h3>Pod Not Running</h3>
                <p>Alerts when a pod is not in a ready state, which could mean it's failing to start, crashing, or experiencing other issues.</p>
                <pre class="codehilite"><code>sum by (pod)(kube_pod_status_ready{condition="true"} == 0)
</code></pre>

                <h3>Total Restarts for Container</h3>
                <p>Tracks the total number of container restarts over a specified period (e.g., 1 hour), useful for diagnosing intermittent issues.</p>
                <pre class="codehilite"><code>increase(kube_pod_container_status_restarts_total[1h])
# Example with namespace and pod filtering:
# increase(kube_pod_container_status_restarts_total{namespace="my-namespace", pod=~".*prefix.*"}[1h])
</code></pre>

                <h3>OOMKilled Reason for Termination</h3>
                <p>Specifically detects containers that have been terminated due to Out Of Memory (OOM) errors, a common cause of application failures.</p>
                <pre class="codehilite"><code>kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}
# Alternative metric:
# container_oom_events_total{name="container-name"}
# Example with namespace filtering:
# kube_pod_container_status_last_terminated_reason{reason="OOMKilled",namespace="my-namespace"}
</code></pre>

                <h3>Less Replicas Than Desired</h3>
                <p>Monitors Kubernetes Deployments to ensure the number of available replicas matches the desired count, crucial for high availability.</p>
                <pre class="codehilite"><code>kube_deployment_status_replicas_available{namespace="my-namespace"} / kube_deployment_spec_replicas{namespace="my-namespace"}
</code></pre>

                <h3>Prometheus Down</h3>
                <p>Alerts if the Prometheus server itself is not being scraped by Prometheus, indicating a critical monitoring system failure.</p>
                <pre class="codehilite"><code>absent(up{job="prometheus-operator-prometheus",namespace="monitoring"} == 1)
</code></pre>

                <h2>Node Metrics</h2>
                <h3>Node Filesystem Space Filling Up</h3>
                <p>Warns when a node's filesystem is filling up rapidly, predicting potential space exhaustion within the next 24 hours. This is critical for preventing node instability.</p>
                <pre class="codehilite"><code>(node_filesystem_avail_bytes{fstype!="",job="node-exporter"} / node_filesystem_size_bytes{fstype!="",job="node-exporter"} * 100 < 40 and predict_linear(node_filesystem_avail_bytes{fstype!="",job="node-exporter"}[6h], 24 * 60 * 60) < 0 and node_filesystem_readonly{fstype!="",job="node-exporter"} == 0)
</code></pre>

                <h3>Node Filesystem Almost Out of Space</h3>
                <p>Alerts when a node's filesystem has less than 5% of available space remaining, requiring immediate attention to free up disk space.</p>
                <pre class="codehilite"><code>(node_filesystem_avail_bytes{fstype!="",job="node-exporter"} / node_filesystem_size_bytes{fstype!="",job="node-exporter"} * 100 < 5 and node_filesystem_readonly{fstype!="",job="node-exporter"} == 0)
</code></pre>

                <h3>High Node CPU Usage</h3>
                <p>Monitors the overall CPU utilization on a node, alerting when it exceeds 80%. High CPU usage can lead to performance degradation across all pods on that node.</p>
                <pre class="codehilite"><code>100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle", instance=~"(.*)"}[5m])) * 100) * on(instance) group_left(nodename) node_uname_info{} > 80
</code></pre>

                <h3>High Node Memory Usage</h3>
                <p>Tracks the memory utilization on a node, alerting when it exceeds 80%. High memory usage can lead to swapping and reduced performance.</p>
                <pre class="codehilite"><code>100 * (1 - ((avg_over_time(node_memory_MemFree_bytes[10m]) + avg_over_time(node_memory_Cached_bytes[10m]) + avg_over_time(node_memory_Buffers_bytes[10m])) / avg_over_time(node_memory_MemTotal_bytes[10m]))) * on(instance) group_left(nodename) node_uname_info{} > 80
</code></pre>
            </div>
        </div>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>
        hljs.highlightAll();
    </script>
</body>
</html>