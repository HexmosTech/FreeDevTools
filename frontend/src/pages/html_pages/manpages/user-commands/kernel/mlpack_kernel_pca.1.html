<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>mlpack_kernel_pca - kernel principal components analysis</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/mlpack-bin">mlpack-bin_4.5.1-1build2_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>mlpack_kernel_pca</b> - kernel principal components analysis

</pre><h4><b>SYNOPSIS</b></h4><pre>
        <b>mlpack_kernel_pca</b> <b>-i</b> <u>unknown</u> <b>-k</b> <u>string</u> [<b>-b</b> <u>double</u>] [<b>-c</b> <u>bool</u>] [<b>-D</b> <u>double</u>] [<b>-S</b> <u>double</u>] [<b>-d</b> <u>int</u>] [<b>-n</b> <u>bool</u>] [<b>-O</b> <u>double</u>] [<b>-s</b> <u>string</u>] [<b>-V</b> <u>bool</u>] [<b>-o</b> <u>unknown</u>] [<b>-h</b> <b>-v</b>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This  program  performs  Kernel  Principal  Components  Analysis (KPCA) on the specified dataset with the
       specified kernel. This will transform the data onto  the  kernel  principal  components,  and  optionally
       reduce the dimensionality by ignoring the kernel principal components with the smallest eigenvalues.

       For the case where a linear kernel is used, this reduces to regular PCA.

       The kernels that are supported are listed below:

              •  ’linear': the standard linear dot product (same as normal PCA): `K(x, y) = x^T y`

              •  ’gaussian':  a  Gaussian  kernel;  requires bandwidth: `K(x, y) = <b>exp</b>(-(|| x - y || ^ 2) / (2 *
                 (bandwidth ^ 2)))`

              •  ’polynomial': polynomial kernel; requires offset and degree: `K(x, y) =  (x^T  y  +  offset)  ^
                 degree`

              •  ’hyptan': hyperbolic tangent kernel; requires scale and offset: `K(x, y) = <b>tanh</b>(scale * (x^T y)
                 + offset)`

              •  ’laplacian': Laplacian kernel; requires bandwidth: `K(x, y) = <b>exp</b>(-(|| x - y ||) / bandwidth)`

              •  ’epanechnikov':  Epanechnikov kernel; requires bandwidth: `K(x, y) = <b>max</b>(0, 1 - || x - y ||^2 /
                 bandwidth^2)`

              •  ’cosine': cosine distance: `K(x, y) = 1 - (x^T y) / (|| x || * || y ||)`

       The parameters for each of  the  kernels  should  be  specified  with  the  options  ’<b>--bandwidth</b>  (<b>-b</b>)',
       '<b>--kernel_scale</b> (<b>-S</b>)', '<b>--offset</b> (<b>-O</b>)', or '<b>--degree</b> (<b>-D</b>)' (or a combination of those parameters).

       Optionally,  the  Nystroem  method ("Using the Nystroem method to speed up kernel machines", 2001) can be
       used to calculate the kernel matrix by specifying the ’<b>--nystroem_method</b> (<b>-n</b>)' parameter.  This  approach
       works  by  using  a subset of the data as basis to reconstruct the kernel matrix; to specify the sampling
       scheme, the '<b>--sampling</b> (<b>-s</b>)' parameter is used. The sampling scheme  for  the  Nystroem  method  can  be
       chosen from the following list: 'kmeans', 'random', ’ordered'.

       For  example,  the  following  command  will  perform  KPCA on the dataset ’input.csv' using the Gaussian
       kernel, and saving the transformed data to ’transformed.csv':

       $ <b>mlpack_kernel_pca</b> <b>--input_file</b> input.csv <b>--kernel</b> gaussian <b>--output_file</b> transformed.csv

</pre><h4><b>REQUIRED</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--input_file</b> <b>(-i)</b> <b>[</b><u>unknown</u><b>]</b>
              Input dataset to perform KPCA on.

       <b>--kernel</b> <b>(-k)</b> <b>[</b><u>string</u><b>]</b>
              The kernel to use; see the above documentation for the list of usable kernels.

</pre><h4><b>OPTIONAL</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--bandwidth</b> <b>(-b)</b> <b>[</b><u>double</u><b>]</b>
              Bandwidth, for 'gaussian' and 'laplacian' kernels. Default value 1.

       <b>--center</b> <b>(-c)</b> <b>[</b><u>bool</u><b>]</b>
              If set, the transformed data will be centered about the origin.

       <b>--degree</b> <b>(-D)</b> <b>[</b><u>double</u><b>]</b>
              Degree of polynomial, for 'polynomial' kernel.  Default value 1.

       <b>--help</b> <b>(-h)</b> <b>[</b><u>bool</u><b>]</b>
              Default help info.

       <b>--info</b> <b>[</b><u>string</u><b>]</b>
              Print help on a specific option. Default  value  ''.   <b>--kernel_scale</b>  (<b>-S</b>)  [<u>double</u>]  Scale,  for
              'hyptan' kernel. Default value 1.

       <b>--new_dimensionality</b> <b>(-d)</b> <b>[</b><u>int</u><b>]</b>
              If  not  0,  reduce  the  dimensionality of the output dataset by ignoring the dimensions with the
              smallest eigenvalues. Default value 0.

       <b>--nystroem_method</b> <b>(-n)</b> <b>[</b><u>bool</u><b>]</b>
              If set, the Nystroem method will be used.

       <b>--offset</b> <b>(-O)</b> <b>[</b><u>double</u><b>]</b>
              Offset, for 'hyptan' and 'polynomial' kernels.  Default value 0.

       <b>--sampling</b> <b>(-s)</b> <b>[</b><u>string</u><b>]</b>
              Sampling scheme to use for the  Nystroem  method:  'kmeans',  'random',  'ordered'  Default  value
              'kmeans'.

       <b>--verbose</b> <b>(-v)</b> <b>[</b><u>bool</u><b>]</b>
              Display informational messages and the full list of parameters and timers at the end of execution.

       <b>--version</b> <b>(-V)</b> <b>[</b><u>bool</u><b>]</b>
              Display the version of mlpack.

</pre><h4><b>OPTIONAL</b> <b>OUTPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--output_file</b> (<b>-o</b>) [<u>unknown</u>] Matrix to save modified dataset to.

</pre><h4><b>ADDITIONAL</b> <b>INFORMATION</b></h4><pre>
       For  further  information,  including  relevant  papers, citations, and theory, consult the documentation
       found at <a href="http://www.mlpack.org">http://www.mlpack.org</a> or included with your distribution of mlpack.

mlpack-4.5.1                                     29 January 2025                            <u><a href="../man1/mlpack_kernel_pca.1.html">mlpack_kernel_pca</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>