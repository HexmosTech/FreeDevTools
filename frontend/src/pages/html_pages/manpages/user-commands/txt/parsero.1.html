<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>parsero - Audit tool for robots.txt of a site</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/parsero">parsero_0.0+git20140929.e5b585a-7_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>parsero</b> - Audit tool for robots.txt of a site

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>parsero</b> [<b>-h</b>] [<b>-u</b> <u>URL</u>] [<b>-o</b>] [<b>-sb</b>] [<b>-f</b> <u>FILE</u>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       Parsero  is  a  free script written in Python which reads the Robots.txt file of a web server through the
       network and looks at the Disallow entries. The Disallow entries tell the search engines what  directories
       or files hosted on a web server mustn't be indexed. For example, "Disallow: /portal/login" means that the
       content  on  www.example.com/portal/login  it's  not allowed to be indexed by crawlers like Google, Bing,
       Yahoo... This is the way the administrator have to not share sensitive or private  information  with  the
       search engines.

</pre><h4><b>OPTIONS</b></h4><pre>
       <b>-h,</b> <b>--help</b>
              Show help message and exit.

       <b>-u</b> <u>URL</u> Type the <u>URL</u> which will be analyzed.

       <b>-o</b>     Show only the "HTTP 200" status code.

       <b>-sb</b>    Search in Bing indexed Disallows.

       <b>-f</b> <u>FILE</u>
              Scan a list of domains from a list.

</pre><h4><b>EXAMPLE</b></h4><pre>
       Common usage:

           $ parsero -u www.example.com

       Using a list of domains from a list:

           $ parsero -f /tmp/list-of-domains.txt

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man1/linkchecker.1.html">linkchecker</a></b>(1), <b><a href="../man1/proxychains4.1.html">proxychains4</a></b>(1).

</pre><h4><b>AUTHOR</b></h4><pre>
       <b>parsero</b> was written by Javier Nieto &lt;<a href="mailto:javier.nieto@behindthefirewalls.com">javier.nieto@behindthefirewalls.com</a>&gt;.

       This  manual  page was written by Thiago Andrade Marques &lt;<a href="mailto:andrade@debian.org">andrade@debian.org</a>&gt; for the Debian project (but
       may be used by others).

parsero-0.0+git20140929.e5b585a                    18 Aug 2020                                        <u><a href="../man1/parsero.1.html">parsero</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>