<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pocketsphinx_continuous - Run speech recognition in continuous listening mode</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/pocketsphinx">pocketsphinx_0.8.0+real5prealpha+1-15ubuntu5_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       pocketsphinx_continuous - Run speech recognition in continuous listening mode

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>pocketsphinx_continuous</b> [<b>-infile</b> <u>filename.wav</u> ] [ <b>-inmic</b> <b>yes</b> ] [ <u>options</u> ]...

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This  program  opens  the  audio device or a file and waits for speech.  When it detects an utterance, it
       performs speech recognition on it.

       To record from microphone and decode use

       <b>-inmic</b> <b>yes</b>

       To decode a 16kHz 16-bit mono WAV file use

       <b>-infile</b> <u>filename.wav</u>

       You can also specify <b>-lm</b> or <b>-fsg</b> or <b>-kws</b> depending on whether you are using a statistical language  model
       or a finite-state grammar or look for a keyphase.

</pre><h4><b>OPTIONS</b></h4><pre>
       <b>-adcdev</b>
              of audio device to use for input.

       <b>-agc</b>   Automatic gain control for c0 ('max', 'emax', 'noise', or 'none')

       <b>-agcthresh</b>
              Initial threshold for automatic gain control

       <b>-allphone</b>
              phoneme decoding with phonetic lm

       <b>-allphone_ci</b>
              Perform phoneme decoding with phonetic lm and context-independent units only

       <b>-alpha</b> Preemphasis parameter

       <b>-argfile</b>
              file giving extra arguments.

       <b>-ascale</b>
              Inverse of acoustic model scale for confidence score calculation

       <b>-aw</b>    Inverse weight applied to acoustic scores.

       <b>-backtrace</b>
              Print results and backtraces to log file.

       <b>-beam</b>  Beam width applied to every frame in Viterbi search (smaller values mean wider beam)

       <b>-bestpath</b>
              Run bestpath (Dijkstra) search over word lattice (3rd pass)

       <b>-bestpathlw</b>
              Language model probability weight for bestpath search

       <b>-ceplen</b>
              Number of components in the input feature vector

       <b>-cmn</b>   Cepstral mean normalization scheme ('current', 'prior', or 'none')

       <b>-cmninit</b>
              Initial values (comma-separated) for cepstral mean when 'prior' is used

       <b>-compallsen</b>
              Compute all senone scores in every frame (can be faster when there are many senones)

       <b>-debug</b> level for debugging messages

       <b>-dict</b>  pronunciation dictionary (lexicon) input file

       <b>-dictcase</b>
              Dictionary is case sensitive (NOTE: case insensitivity applies to ASCII characters only)

       <b>-dither</b>
              Add 1/2-bit noise

       <b>-doublebw</b>
              Use double bandwidth filters (same center freq)

       <b>-ds</b>    Frame GMM computation downsampling ratio

       <b>-fdict</b> word pronunciation dictionary input file

       <b>-feat</b>  Feature stream type, depends on the acoustic model

       <b>-featparams</b>
              containing feature extraction parameters.

       <b>-fillprob</b>
              Filler word transition probability

       <b>-frate</b> Frame rate

       <b>-fsg</b>   format finite state grammar file

       <b>-fsgusealtpron</b>
              Add alternate pronunciations to FSG

       <b>-fsgusefiller</b>
              Insert filler words at each state.

       <b>-fwdflat</b>
              Run forward flat-lexicon search over word lattice (2nd pass)

       <b>-fwdflatbeam</b>
              Beam width applied to every frame in second-pass flat search

       <b>-fwdflatefwid</b>
              Minimum number of end frames for a word to be searched in fwdflat search

       <b>-fwdflatlw</b>
              Language model probability weight for flat lexicon (2nd pass) decoding

       <b>-fwdflatsfwin</b>
              Window of frames in lattice to search for successor words in fwdflat search

       <b>-fwdflatwbeam</b>
              Beam width applied to word exits in second-pass flat search

       <b>-fwdtree</b>
              Run forward lexicon-tree search (1st pass)

       <b>-hmm</b>   containing acoustic model files.

       <b>-infile</b>
              file to transcribe.

       <b>-inmic</b> Transcribe audio from microphone.

       <b>-input_endian</b>
              Endianness of input data, big or little, ignored if NIST or MS Wav

       <b>-jsgf</b>  grammar file

       <b>-keyphrase</b>
              to spot

       <b>-kws</b>   file with keyphrases to spot, one per line

       <b>-kws_delay</b>
              Delay to wait for best detection score

       <b>-kws_plp</b>
              Phone loop probability for keyword spotting

       <b>-kws_threshold</b>
              Threshold for p(hyp)/p(alternatives) ratio

       <b>-latsize</b>
              Initial backpointer table size

       <b>-lda</b>   containing transformation matrix to be applied to features (single-stream features only)

       <b>-ldadim</b>
              Dimensionality of output of feature transformation (0 to use entire matrix)

       <b>-lifter</b>
              Length of sin-curve for liftering, or 0 for no liftering.

       <b>-lm</b>    trigram language model input file

       <b>-lmctl</b> a set of language model

       <b>-lmname</b>
              language model in <b>-lmctl</b> to use by default

       <b>-logbase</b>
              Base in which all log-likelihoods calculated

       <b>-logfn</b> to write log messages in

       <b>-logspec</b>
              Write out logspectral files instead of cepstra

       <b>-lowerf</b>
              Lower edge of filters

       <b>-lpbeam</b>
              Beam width applied to last phone in words

       <b>-lponlybeam</b>
              Beam width applied to last phone in single-phone words

       <b>-lw</b>    Language model probability weight

       <b>-maxhmmpf</b>
              Maximum number of active HMMs to maintain at each frame (or <b>-1</b> for no pruning)

       <b>-maxwpf</b>
              Maximum number of distinct word exits at each frame (or <b>-1</b> for no pruning)

       <b>-mdef</b>  definition input file

       <b>-mean</b>  gaussian means input file

       <b>-mfclogdir</b>
              to log feature files to

       <b>-min_endfr</b>
              Nodes ignored in lattice construction if they persist for fewer than N frames

       <b>-mixw</b>  mixture weights input file (uncompressed)

       <b>-mixwfloor</b>
              Senone mixture weights floor (applied to data from <b>-mixw</b> file)

       <b>-mllr</b>  transformation to apply to means and variances

       <b>-mmap</b>  Use memory-mapped I/O (if possible) for model files

       <b>-ncep</b>  Number of cep coefficients

       <b>-nfft</b>  Size of FFT

       <b>-nfilt</b> Number of filter banks

       <b>-nwpen</b> New word transition penalty

       <b>-pbeam</b> Beam width applied to phone transitions

       <b>-pip</b>   Phone insertion penalty

       <b>-pl_beam</b>
              Beam width applied to phone loop search for lookahead

       <b>-pl_pbeam</b>
              Beam width applied to phone loop transitions for lookahead

       <b>-pl_pip</b>
              Phone insertion penalty for phone loop

       <b>-pl_weight</b>
              Weight for phoneme lookahead penalties

       <b>-pl_window</b>
              Phoneme lookahead window size, in frames

       <b>-rawlogdir</b>
              to log raw audio files to

       <b>-remove_dc</b>
              Remove DC offset from each frame

       <b>-remove_noise</b>
              Remove noise with spectral subtraction in mel-energies

       <b>-remove_silence</b>
              Enables VAD, removes silence frames from processing

       <b>-round_filters</b>
              Round mel filter frequencies to DFT points

       <b>-samprate</b>
              Sampling rate

       <b>-seed</b>  Seed for random number generator; if less than zero, pick our own

       <b>-sendump</b>
              dump (compressed mixture weights) input file

       <b>-senlogdir</b>
              to log senone score files to

       <b>-senmgau</b>
              to codebook mapping input file (usually not needed)

       <b>-silprob</b>
              Silence word transition probability

       <b>-smoothspec</b>
              Write out cepstral-smoothed logspectral files

       <b>-svspec</b>
              specification (e.g., 24,0-11/25,12-23/26-38 or 0-12/13-25/26-38)

       <b>-time</b>  Print word times in file transcription.

       <b>-tmat</b>  state transition matrix input file

       <b>-tmatfloor</b>
              HMM state transition probability floor (applied to <b>-tmat</b> file)

       <b>-topn</b>  Maximum number of top Gaussians to use in scoring.

       <b>-topn_beam</b>
              Beam width used to determine top-N Gaussians (or a list, per-feature)

       <b>-toprule</b>
              rule for JSGF (first public rule is default)

       <b>-transform</b>
              Which type of transform to use to calculate cepstra (legacy, dct, or htk)

       <b>-unit_area</b>
              Normalize mel filters to unit area

       <b>-upperf</b>
              Upper edge of filters

       <b>-uw</b>    Unigram weight

       <b>-vad_postspeech</b>
              Num of silence frames to keep after from speech to silence.

       <b>-vad_prespeech</b>
              Num of speech frames to keep before silence to speech.

       <b>-vad_startspeech</b>
              Num of speech frames to trigger vad from silence to speech.

       <b>-vad_threshold</b>
              Threshold  for decision between noise and silence frames. Log-ratio between signal level and noise
              level.

       <b>-var</b>   gaussian variances input file

       <b>-varfloor</b>
              Mixture gaussian variance floor (applied to data from <b>-var</b> file)

       <b>-varnorm</b>
              Variance normalize each utterance (only if CMN == current)

       <b>-verbose</b>
              Show input filenames

       <b>-warp_params</b>
              defining the warping function

       <b>-warp_type</b>
              Warping function type (or shape)

       <b>-wbeam</b> Beam width applied to word exits

       <b>-wip</b>   Word insertion penalty

       <b>-wlen</b>  Hamming window length

</pre><h4><b>AUTHOR</b></h4><pre>
       Written by numerous people  at  CMU  from  1994  onwards.   This  manual  page  by  David  Huggins-Daines
       &lt;<a href="mailto:dhuggins@cs.cmu.edu">dhuggins@cs.cmu.edu</a>&gt;

</pre><h4><b>COPYRIGHT</b></h4><pre>
       Copyright  Â©  1994-2016  Carnegie Mellon University.  See the file <u>LICENSE</u> included with this package for
       more information.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man1/pocketsphinx_batch.1.html">pocketsphinx_batch</a></b>(1), <b><a href="../man1/sphinx_fe.1.html">sphinx_fe</a></b>(1).

                                                   2016-04-01                         <u><a href="../man1/POCKETSPHINX_CONTINUOUS.1.html">POCKETSPHINX_CONTINUOUS</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>