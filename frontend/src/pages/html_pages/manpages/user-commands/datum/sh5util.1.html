<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>sh5util  - Tool for merging HDF5 files from the acct_gather_profile plugin that gathers detailed data for</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/slurm-wlm-hdf5-plugin">slurm-wlm-hdf5-plugin_24.11.3-2_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       sh5util  - Tool for merging HDF5 files from the acct_gather_profile plugin that gathers detailed data for
       jobs running under Slurm

</pre><h4><b>SYNOPSIS</b></h4><pre>
       sh5util

</pre><h4><b>DESCRIPTION</b></h4><pre>
       sh5util merges HDF5 files produced on each node for each step of a job into one HDF5 file  for  the  job.
       The  resulting  file can be viewed and manipulated by common HDF5 tools such as HDF5View, h5dump, h5edit,
       or h5ls.

       sh5util also has two extract modes. The first, writes a limited set of data for  specific  nodes,  steps,
       and data series in "comma separated value" form to a file which can be imported into other analysis tools
       such as spreadsheets.

       The  second,  (Item-Extract)  extracts  one data time from one time series for all the samples on all the
       nodes from a jobs HDF5 profile.

       - Finds sample with maximum value of the item.

       - Write CSV file with min, ave, max, and item totals for each node for each sample

</pre><h4><b>OPTIONS</b></h4><pre>
       <b>-E</b>, <b>--extract</b>

              Extract data series from a merged job file.

              Extract mode options

              <b>-i</b>, <b>--input</b>=<u>path</u>
                        merged file to extract from (default ./job_$jobid.h5)

              <b>-N</b>, <b>--node</b>=<u>nodename</u>
                        Node name to extract (default is all)

              <b>-l</b>, <b>--level</b>=[Node:Totals | Node:TimeSeries]
                        Level to which series is attached. (default Node:Totals)

              <b>-s</b>, <b>--series</b>=[Energy | Filesystem | Network | Task | Task_#]
                        <b>Task</b> is all tasks, <b>Task_#</b> (# is a task id) (default is everything)

       <b>-h</b>, <b>--help</b>
              Print this description of use.

       <b>-I</b>, <b>--item-extract</b>

              Extract one data item from all samples of one data series from all nodes in a merged job file.

              Item-Extract mode options

              <b>-s</b>, <b>--series</b>=[Energy | Filesystem | Network | Task]

              <b>-d</b>, <b>--data</b>
                        Name of data item in series (See note below).

       <b>-j</b>, <b>--jobs</b>=&lt;<u>job</u>[.<u>step</u>]&gt;
              Format is &lt;<u>job</u>[.<u>step</u>]&gt;. Merge this job/step (or a comma-separated list of job steps). This  option
              is required.  Not specifying a step will result in all steps found to be processed.

       <b>-L</b>, <b>--list</b>

              Print the items of a series contained in a job file.

              List mode options

              <b>-i</b>, <b>--input</b>=<u>path</u>
                        Merged file to extract from (default ./job_$jobid.h5)

              <b>-s</b>, <b>--series</b>=[Energy | Filesystem | Network | Task]

       <b>-o</b>, <b>--output</b>=&lt;<u>path</u>&gt;
              Path  to  a file into which to write.  Default for merge is ./job_$jobid.h5 Default for extract is
              ./extract_$jobid.csv

       <b>-p</b>, <b>--profiledir</b>=&lt;<u>dir</u>&gt;
              Directory location where node-step files exist default is set in acct_gather.conf.

       <b>-S</b>, <b>--savefiles</b>
              Instead of removing node-step files after merging them into the job file, keep them around.

       <b>--usage</b>
              Display brief usage message.

       <b>--user</b>=&lt;<u>user</u>&gt;
              User who profiled job.  (Handy for root user, defaults to user running this command.)

</pre><h4><b>Data</b> <b>Items</b> <b>per</b> <b>Series</b></h4><pre>
       <b>Energy</b>
              Power
              CPU_Frequency

       <b>Filesystem</b>
              Reads
              Megabytes_Read
              Writes
              Megabytes_Write

       <b>Network</b>
              Packets_In
              Megabytes_In
              Packets_Out
              Megabytes_Out

       <b>Task</b>
              CPU_Frequency
              CPU_Time
              CPU_Utilization
              RSS
              VM_Size
              Pages
              Read_Megabytes
              Write_Megabytes

</pre><h4><b>PERFORMANCE</b></h4><pre>
       Executing <b>sh5util</b> sends a remote procedure call to <b>slurmctld</b>. If enough calls from <b>sh5util</b> or other Slurm
       client commands that send remote procedure calls to the <b>slurmctld</b> daemon come in at once, it  can  result
       in a degradation of performance of the <b>slurmctld</b> daemon, possibly resulting in a denial of service.

       Do  not  run  <b>sh5util</b>  or  other Slurm client commands that send remote procedure calls to <b>slurmctld</b> from
       loops in shell scripts or other programs. Ensure that programs limit calls  to  <b>sh5util</b>  to  the  minimum
       necessary for the information you are trying to gather.

</pre><h4><b>EXAMPLES</b></h4><pre>
       Merge node-step files (as part of a sbatch script):

              $ sbatch -n1 -d$SLURM_JOB_ID --wrap="sh5util --savefiles -j $SLURM_JOB_ID"

       Extract all task data from a node:

              $ sh5util -j 42 -N snowflake01 --level=Node:TimeSeries --series=Tasks

       Extract all energy data:

              $ sh5util -j 42 --series=Energy --data=power

</pre><h4><b>COPYING</b></h4><pre>
       Copyright (C) 2013 Bull.
       Copyright  (C)  2013-2022  SchedMD LLC.  Slurm is free software; you can redistribute it and/or modify it
       under the terms of the GNU General Public License as published by the Free  Software  Foundation;  either
       version 2 of the License, or (at your option) any later version.

       Slurm  is  distributed  in  the  hope  that it will be useful, but WITHOUT ANY WARRANTY; without even the
       implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR  PURPOSE.  See  the  GNU  General  Public
       License for more details.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
February 2021                                    Slurm Commands                                       <u><a href="../man1/sh5util.1.html">sh5util</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>