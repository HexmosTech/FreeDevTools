<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>llvm-exegesis - LLVM Machine Instruction Benchmark</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/llvm-14">llvm-14_14.0.6-20ubuntu1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       llvm-exegesis - LLVM Machine Instruction Benchmark

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>llvm-exegesis</b> [<u>options</u>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <b>llvm-exegesis</b>  is  a  benchmarking  tool  that uses information available in LLVM to measure host machine
       instruction characteristics like latency, throughput, or port decomposition.

       Given an LLVM opcode name and a benchmarking mode, <b>llvm-exegesis</b> generates  a  code  snippet  that  makes
       execution  as  serial  (resp.  as parallel) as possible so that we can measure the latency (resp. inverse
       throughput/uop decomposition) of the instruction.  The code snippet is jitted and executed  on  the  host
       subtarget.  The  time  taken  (resp. resource usage) is measured using hardware performance counters. The
       result is printed out as YAML to the standard output.

       The main goal of this tool is to automatically (in)validate the LLVM’s  TableDef  scheduling  models.  To
       that end, we also provide analysis of the results.

       <b>llvm-exegesis</b> can also benchmark arbitrary user-provided code snippets.

</pre><h4><b>EXAMPLE</b> <b>1:</b> <b>BENCHMARKING</b> <b>INSTRUCTIONS</b></h4><pre>
       Assume you have an X86-64 machine. To measure the latency of a single instruction, run:

          $ llvm-exegesis -mode=latency -opcode-name=ADD64rr

       Measuring the uop decomposition or inverse throughput of an instruction works similarly:

          $ llvm-exegesis -mode=uops -opcode-name=ADD64rr
          $ llvm-exegesis -mode=inverse_throughput -opcode-name=ADD64rr

       The  output  is  a YAML document (the default is to write to stdout, but you can redirect the output to a
       file using <u>-benchmarks-file</u>):

          ---
          key:
            opcode_name:     ADD64rr
            mode:            latency
            config:          ''
          cpu_name:        haswell
          llvm_triple:     x86_64-unknown-linux-gnu
          num_repetitions: 10000
          measurements:
            - { key: latency, value: 1.0058, debug_string: '' }
          error:           ''
          info:            'explicit self cycles, selecting one aliasing configuration.
          Snippet:
          ADD64rr R8, R8, R10
          '
          ...

       To measure the latency of all instructions for the host architecture, run:

          $ llvm-exegesis -mode=latency -opcode-index=-1

</pre><h4><b>EXAMPLE</b> <b>2:</b> <b>BENCHMARKING</b> <b>A</b> <b>CUSTOM</b> <b>CODE</b> <b>SNIPPET</b></h4><pre>
       To measure the latency/uops of a custom piece of code, you can specify the <u>snippets-file</u> option (<u>-</u>  reads
       from standard input).

          $ echo "vzeroupper" | llvm-exegesis -mode=uops -snippets-file=-

       Real-life  code snippets typically depend on registers or memory.  <b>llvm-exegesis</b> checks the liveliness of
       registers (i.e. any register use has a corresponding def or is a “live in”). If your code depends on  the
       value of some registers, you have two options:

       • Mark  the  register  as  requiring a definition. <b>llvm-exegesis</b> will automatically assign a value to the
         register. This can be done using the  directive  <u>LLVM-EXEGESIS-DEFREG</u>  <u>&lt;reg</u>  <u>name&gt;</u>  <u>&lt;hex_value&gt;</u>,  where
         <u>&lt;hex_value&gt;</u>  is  a  bit  pattern  used  to fill <u>&lt;reg_name&gt;</u>. If <u>&lt;hex_value&gt;</u> is smaller than the register
         width, it will be sign-extended.

       • Mark the register as a “live in”. <b>llvm-exegesis</b>  will  benchmark  using  whatever  value  was  in  this
         registers on entry. This can be done using the directive <u>LLVM-EXEGESIS-LIVEIN</u> <u>&lt;reg</u> <u>name&gt;</u>.

       For example, the following code snippet depends on the values of XMM1 (which will be set by the tool) and
       the memory buffer passed in RDI (live in).

          # LLVM-EXEGESIS-LIVEIN RDI
          # LLVM-EXEGESIS-DEFREG XMM1 42
          vmulps        (%rdi), %xmm1, %xmm2
          vhaddps       %xmm2, %xmm2, %xmm3
          addq $0x10, %rdi

</pre><h4><b>EXAMPLE</b> <b>3:</b> <b>ANALYSIS</b></h4><pre>
       Assuming  you  have  a  set  of  benchmarked  instructions  (either  latency  or  uops)  as  YAML in file
       <u>/tmp/benchmarks.yaml</u>, you can analyze the results using the following command:

            $ llvm-exegesis -mode=analysis \
          -benchmarks-file=/tmp/benchmarks.yaml \
          -analysis-clusters-output-file=/tmp/clusters.csv \
          -analysis-inconsistencies-output-file=/tmp/inconsistencies.html

       This will group the instructions into clusters with the same performance  characteristics.  The  clusters
       will be written out to <u>/tmp/clusters.csv</u> in the following format:

          cluster_id,opcode_name,config,sched_class
          ...
          2,ADD32ri8_DB,,WriteALU,1.00
          2,ADD32ri_DB,,WriteALU,1.01
          2,ADD32rr,,WriteALU,1.01
          2,ADD32rr_DB,,WriteALU,1.00
          2,ADD32rr_REV,,WriteALU,1.00
          2,ADD64i32,,WriteALU,1.01
          2,ADD64ri32,,WriteALU,1.01
          2,MOVSX64rr32,,BSWAP32r_BSWAP64r_MOVSX64rr32,1.00
          2,VPADDQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.02
          2,VPSUBQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.01
          2,ADD64ri8,,WriteALU,1.00
          2,SETBr,,WriteSETCC,1.01
          ...

       <b>llvm-exegesis</b>  will also analyze the clusters to point out inconsistencies in the scheduling information.
       The output is an html file.  For  example,  <u>/tmp/inconsistencies.html</u>  will  contain  messages  like  the
       following : [image]

       Note  that the scheduling class names will be resolved only when <b>llvm-exegesis</b> is compiled in debug mode,
       else only the class id will be shown. This does not invalidate any of the analysis results though.

</pre><h4><b>OPTIONS</b></h4><pre>
       <b>-help</b>  Print a summary of command line options.

       <b>-opcode-index=&lt;LLVM</b> <b>opcode</b> <b>index&gt;</b>
              Specify the opcode to measure, by index. Specifying <u>-1</u> will result  in  measuring  every  existing
              opcode. See example 1 for details.  Either <u>opcode-index</u>, <u>opcode-name</u> or <u>snippets-file</u> must be set.

       <b>-opcode-name=&lt;opcode</b> <b>name</b> <b>1&gt;,&lt;opcode</b> <b>name</b> <b>2&gt;,...</b>
              Specify  the  opcode  to  measure,  by name. Several opcodes can be specified as a comma-separated
              list. See example 1 for details.  Either <u>opcode-index</u>, <u>opcode-name</u> or <u>snippets-file</u> must be set.

       <b>-snippets-file=&lt;filename&gt;</b>
              Specify the custom code snippet to measure. See  example  2  for  details.   Either  <u>opcode-index</u>,
              <u>opcode-name</u> or <u>snippets-file</u> must be set.

       <b>-mode=[latency|uops|inverse_throughput|analysis]</b>
              Specify the run mode. Note that some modes have additional requirements and options.

              <u>latency</u>  mode  can be  make use of either RDTSC or LBR.  <u>latency[LBR]</u> is only available on X86 (at
              least  <u>Skylake</u>).   To  run  in  <u>latency</u>  mode,  a   positive   value   must   be   specified   for
              <u>x86-lbr-sample-period</u> and <u>–repetition-mode=loop</u>.

              In <u>analysis</u> mode, you also need to specify at least one of the <u>-analysis-clusters-output-file=</u> and
              <u>-analysis-inconsistencies-output-file=</u>.

       <b>-x86-lbr-sample-period=&lt;nBranches/sample&gt;</b>
              Specify  the  LBR  sampling  period  - how many branches before we take a sample.  When a positive
              value is specified for this option and when the mode is <u>latency</u>, we will use LBRs  for  measuring.
              On choosing the “right” sampling period, a small value is preferred, but throttling could occur if
              the sampling is too frequent. A prime number should be used to avoid consistently skipping certain
              blocks.

       <b>-repetition-mode=[duplicate|loop|min]</b>
              Specify  the  repetition  mode.  <u>duplicate</u>  will  create  a  large, straight line basic block with
              <u>num-repetitions</u> instructions (repeating the  snippet  <u>num-repetitions</u>/<u>snippet</u>  <u>size</u>  times).  <u>loop</u>
              will,  optionally,  duplicate  the  snippet  until  the loop body contains at least <u>loop-body-size</u>
              instructions, and then wrap the result in a loop which will execute  <u>num-repetitions</u>  instructions
              (thus, again, repeating the snippet <u>num-repetitions</u>/<u>snippet</u> <u>size</u> times). The <u>loop</u> mode, especially
              with  loop  unrolling  tends  to better hide the effects of the CPU frontend on architectures that
              cache decoded instructions, but consumes a register for  counting  iterations.  If  performing  an
              analysis  over many opcodes, it may be best to instead use the <u>min</u> mode, which will run each other
              mode, and produce the minimal measured result.

       <b>-num-repetitions=&lt;Number</b> <b>of</b> <b>repetitions&gt;</b>
              Specify the target number of executed instructions. Note that the actual repetition count  of  the
              snippet  will  be  <u>num-repetitions</u>/<u>snippet</u> <u>size</u>.  Higher values lead to more accurate measurements
              but lengthen the benchmark.

       <b>-loop-body-size=&lt;Preferred</b> <b>loop</b> <b>body</b> <b>size&gt;</b>
              Only effective for <u>-repetition-mode=[loop|min]</u>.  Instead of looping  over  the  snippet  directly,
              first  duplicate  it  so  that  the  loop  body  contains  at  least  this many instructions. This
              potentially results in loop body being cached in the CPU Op Cache / Loop Cache,  which  allows  to
              which may have higher throughput than the CPU decoders.

       <b>-max-configs-per-opcode=&lt;value&gt;</b>
              Specify  the  maximum configurations that can be generated for each opcode.  By default this is <u>1</u>,
              meaning that we assume that a single measurement is enough to characterize an opcode.  This  might
              not  be  true  of  all  instructions:  for  example,  the  performance  characteristics of the LEA
              instruction on X86 depends on the value of assigned registers and immediates. Setting a  value  of
              <u>-max-configs-per-opcode</u>  larger  than  <u>1</u>  allows  <u>llvm-exegesis</u>  to explore more configurations to
              discover if some register or immediate assignments lead to different performance characteristics.

       <b>-benchmarks-file=&lt;/path/to/file&gt;</b>
              File to read (<u>analysis</u> mode) or write (<u>latency</u>/<u>uops</u>/<u>inverse_throughput</u> modes)  benchmark  results.
              “-” uses stdin/stdout.

       <b>-analysis-clusters-output-file=&lt;/path/to/file&gt;</b>
              If  provided,  write  the analysis clusters as CSV to this file. “-” prints to stdout. By default,
              this analysis is not run.

       <b>-analysis-inconsistencies-output-file=&lt;/path/to/file&gt;</b>
              If non-empty, write inconsistencies found during analysis to this file. <u>-</u>  prints  to  stdout.  By
              default, this analysis is not run.

       <b>-analysis-clustering=[dbscan,naive]</b>
              Specify  the  clustering  algorithm  to  use.  By  default  DBSCAN will be used.  Naive clustering
              algorithm is better for doing further work on the  <u>-analysis-inconsistencies-output-file=</u>  output,
              it  will  create  one  cluster  per  opcode,  and check that the cluster is stable (all points are
              neighbours).

       <b>-analysis-numpoints=&lt;dbscan</b> <b>numPoints</b> <b>parameter&gt;</b>
              Specify the numPoints parameters to be used for DBSCAN clustering (<u>analysis</u> mode, DBSCAN only).

       <b>-analysis-clustering-epsilon=&lt;dbscan</b> <b>epsilon</b> <b>parameter&gt;</b>
              Specify the epsilon parameter used for clustering of benchmark points (<u>analysis</u> mode).

       <b>-analysis-inconsistency-epsilon=&lt;epsilon&gt;</b>
              Specify the epsilon parameter used for detection of when the cluster is different  from  the  LLVM
              schedule profile values (<u>analysis</u> mode).

       <b>-analysis-display-unstable-clusters</b>
              If  there is more than one benchmark for an opcode, said benchmarks may end up not being clustered
              into the same cluster if the measured performance characteristics are different.  by  default  all
              such opcodes are filtered out.  This flag will instead show only such unstable opcodes.

       <b>-ignore-invalid-sched-class=false</b>
              If set, ignore instructions that do not have a sched class (class idx = 0).

       <b>-mcpu=&lt;cpu</b> <b>name&gt;</b>
              If  set,  measure  the  cpu  characteristics  using the counters for this CPU. This is useful when
              creating new sched models (the host CPU is unknown to LLVM).

       <b>--dump-object-to-disk=true</b>
              By default, llvm-exegesis will dump the  generated  code  to  a  temporary  file  to  enable  code
              inspection. You may disable it to speed up the execution and save disk space.

</pre><h4><b>EXIT</b> <b>STATUS</b></h4><pre>
       <b>llvm-exegesis</b>  returns  0  on  success. Otherwise, an error message is printed to standard error, and the
       tool returns a non 0 value.

</pre><h4><b>AUTHOR</b></h4><pre>
       Maintained by the LLVM Team (https://llvm.org/).

</pre><h4><b>COPYRIGHT</b></h4><pre>
       2003-2025, LLVM Project

14                                                 2025-01-05                                   <u><a href="../man1/LLVM-EXEGESIS.1.html">LLVM-EXEGESIS</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>