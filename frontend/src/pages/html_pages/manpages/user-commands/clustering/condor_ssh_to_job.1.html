<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>condor_ssh_to_job - HTCondor Manual</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/condor">condor_23.6.2+dfsg-2build1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       condor_ssh_to_job - HTCondor Manual

       create an ssh session to a running job

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>condor_ssh_to_job</b> [<b>-help</b> ]

       <b>condor_ssh_to_job</b>  [<b>-debug</b>  ]  [<b>-name</b>  <u>schedd-name</u>] [<b>-pool</b> <u>pool-name</u>] [<b>-ssh</b> <u>ssh-command</u>] [<b>-keygen-options</b>
       <u>ssh-keygen-options</u>]  [<b>-shells</b>  <u>shell1,shell2,...</u>]  [<b>-auto-retry</b>  ]  [<b>-remove-on-interrupt</b>  ]  <u>cluster</u>   <u>|</u>
       <u>cluster.process</u> <u>|</u> <u>cluster.process.node</u> [<u>remote-command</u> ]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <u>condor_ssh_to_job</u>  creates  an  <u>ssh</u>  session to a running job. The job is specified with the argument. If
       only the job <u>cluster</u> id is given, then the job <u>process</u> id defaults to the value 0.

       <u>condor_ssh_to_job</u> is available in Unix HTCondor distributions, and only works with jobs in  the  vanilla,
       container,  docker,  vm,  java, local, or parallel universes. In the grid universe it only works with EC2
       resources. It will not work with other grid universe jobs.

       The user must be the owner of the job or must be a queue super  user,  and  both  the  <u>condor_schedd</u>  and
       <u>condor_starter</u>  daemons  must  be  configured  to allow <u>condor_ssh_to_job</u> access. If no <u>remote-command</u> is
       specified, an interactive shell is created. An alternate <u>ssh</u> program such as <u>sftp</u> may be specified, using
       the <b>-ssh</b> option, for uploading and downloading files.

       The remote command or shell runs with the same user id as the running job, and it is initialized with the
       same working directory. The environment is initialized to be the same  as  that  of  the  job,  plus  any
       changes  made  by  the  shell  setup  scripts  and any environment variables passed by the <u>ssh</u> client. In
       addition, the environment variable <b>_CONDOR_JOB_PIDS</b> is defined. It is  a  space-separated  list  of  PIDs
       associated  with the job. At a minimum, the list will contain the PID of the process started when the job
       was launched, and it will be the first item in  the  list.  It  may  contain  additional  PIDs  of  other
       processes that the job has created.

       If  the  job  is  a  docker  or container universe job, the interactive shell will be launched inside the
       container, and as much as possible should have all the access and visibility that the  job  proper  does.
       Note  this  requires  the  container  image to have a shell inside it, <u>condor_ssh_to_job</u> will fail if the
       container lacks a shell.

       The <u>ssh</u> session and all processes it creates are  treated  by  HTCondor  as  though  they  are  processes
       belonging to the job. If the slot is preempted or suspended, the <u>ssh</u> session is killed or suspended along
       with  the  job.  If  the  job exits before the <u>ssh</u> session finishes, the slot remains in the Claimed Busy
       state and is treated as though not all job processes have exited  until  all  <u>ssh</u>  sessions  are  closed.
       Multiple  <u>ssh</u>  sessions may be created to the same job at the same time. Resource consumption of the <u>sshd</u>
       process and all processes spawned by it are monitored by the <u>condor_starter</u>  as  though  these  processes
       belong to the job, so any policies such as <u>PREEMPT</u> that enforce a limit on resource consumption also take
       into account resources consumed by the <u>ssh</u> session.

       <u>condor_ssh_to_job</u> stores ssh keys in temporary files within a newly created and uniquely named directory.
       The  newly  created  directory  will  be within the directory defined by the environment variable <b>TMPDIR</b>.
       When the ssh session is finished, this directory and the ssh keys contained within it are removed.

       See the HTCondor administrator's manual  section  on  configuration  for  details  of  the  configuration
       variables related to <u>condor_ssh_to_job</u>.

       An   <u>ssh</u>   session   works   by   first  authenticating  and  authorizing  a  secure  connection  between
       <u>condor_ssh_to_job</u> and the <u>condor_starter</u> daemon, using HTCondor protocols. The  <u>condor_starter</u>  generates
       an  ssh key pair and sends it securely to <u>condor_ssh_to_job</u>. Then the <u>condor_starter</u> spawns <u>sshd</u> in inetd
       mode with its stdin and stdout attached to the TCP connection from <u>condor_ssh_to_job</u>.   <u>condor_ssh_to_job</u>
       acts  as a proxy for the <u>ssh</u> client to communicate with <u>sshd</u>, using the existing connection authorized by
       HTCondor. At no point is <u>sshd</u> listening on the network for connections or  running  with  any  privileges
       other  than that of the user identity running the job. If CCB is being used to enable connectivity to the
       execute node from outside of a firewall or private network, <u>condor_ssh_to_job</u> is able to make use of  CCB
       in order to form the <u>ssh</u> connection.

       The <u>sshd</u> command HTCondor runs on the EP requires an entry in the <a href="file:/etc/passwd">/etc/passwd</a> file with a valid shell and
       home  directory.  As these are often missing, the <u>condor_starter</u> uses the LD_PRELOAD environment variable
       to inject an implementation of the libc getpwnam function call into the ssh that forces the shell  to  be
       <a href="file:/bin/sh">/bin/sh</a> and the home directory to be the scratch directory for that user.  This can be disabled on the EP
       by setting <u>CONDOR_SSH_TO_JOB_FAKE_PASSWD_ENTRY</u> to false.

       <u>condor_ssh_to_job</u> is intended to work with <u>OpenSSH</u> as installed in typical environments. It does not work
       on  Windows  platforms.  If  the  <u>ssh</u> programs are installed in non-standard locations, then the paths to
       these programs will need to be customized within the HTCondor configuration. Versions of <u>ssh</u>  other  than
       <u>OpenSSH</u>  may  work,  but  they  will  likely  require additional configuration of command-line arguments,
       changes   to   the   <u>sshd</u>   configuration   template   file,   and   possibly   modification    of    the
       $(LIBEXEC)/condor_ssh_to_job_sshd_setup script used by the <u>condor_starter</u> to set up <u>sshd</u>.

       For  jobs  in  the  grid  universe  which use EC2 resources, a request that HTCondor have the EC2 service
       create a new key pair for the job by specifying <u>ec2_keypair_file</u> causes <u>condor_ssh_to_job</u> to  attempt  to
       connect to the corresponding instance via <u>ssh</u>. This attempts invokes <u>ssh</u> directly, bypassing the HTCondor
       networking  layer. It supplies <u>ssh</u> with the public DNS name of the instance and the name of the file with
       the new key pair's private key. For the connection to succeed, the instance  must  have  started  an  <u>ssh</u>
       server,  and  its  security group(s) must allow connections on port 22. Conventionally, images will allow
       logins using the key pair on a single specific account. Because <u>ssh</u> defaults to logging in as the current
       user, the <b>-l</b> <b>&lt;username&gt;</b> option or its equivalent for other versions of <u>ssh</u> will be needed as part of  the
       <u>remote-command</u>  argument.  Although  the  <b>-X</b>  option  does  not apply to EC2 jobs, adding <b>-X</b> or <b>-Y</b> to the
       <u>remote-command</u> argument can duplicate the effect.

</pre><h4><b>OPTIONS</b></h4><pre>
          <b>-help</b>  Display brief usage information and exit.

          <b>-debug</b> Causes debugging information to be sent to <b>stderr</b>, based on  the  value  of  the  configuration
                 variable <u>TOOL_DEBUG</u>.

          <b>-name</b> <u>schedd-name</u>
                 Specify an alternate <u>condor_schedd</u>, if the default (local) one is not desired.

          <b>-pool</b> <u>pool-name</u>
                 Specify  an  alternate  HTCondor pool, if the default one is not desired. Does not apply to EC2
                 jobs.

          <b>-ssh</b> <u>ssh-command</u>
                 Specify an alternate <u>ssh</u> program to run in place of <u>ssh</u>, for example <u>sftp</u>  or  <u>scp</u>.  Additional
                 arguments  are  specified  as  <u>ssh-command</u>.  Since the arguments are delimited by spaces, place
                 double quote marks around the whole command, to  prevent  the  shell  from  splitting  it  into
                 multiple  arguments  to  <u>condor_ssh_to_job</u>.  If any arguments must contain spaces, enclose them
                 within single quotes. Does not apply to EC2 jobs.

          <b>-keygen-options</b> <u>ssh-keygen-options</u>
                 Specify additional arguments to the <u>ssh_keygen</u> program, for creating the ssh key that  is  used
                 for  the  duration of the session.  For example, a different number of bits could be used, or a
                 different key type than the default. Does not apply to EC2 jobs.

          <b>-shells</b> <u>shell1,shell2,...</u>
                 Specify a comma-separated list of shells to attempt to launch. If  the  first  shell  does  not
                 exist  on the remote machine, then the following ones in the list will be tried. If none of the
                 specified shells can be found, <u><a href="file:/bin/sh">/bin/sh</a></u> is used by default. If this option is not specified,  it
                 defaults  to the environment variable <b>SHELL</b> from within the <u>condor_ssh_to_job</u> environment. Does
                 not apply to EC2 jobs.

          <b>-auto-retry</b>
                 Specifies that if the job is not yet running, <u>condor_ssh_to_job</u> should keep trying periodically
                 until it succeeds or encounters some other error.

          <b>-remove-on-interrupt</b>
                 If specified, attempt to remove the job from the queue if <u>condor_ssh_to_job</u> is interrupted  via
                 a CTRL-c or otherwise terminated abnormally.

          <b>-X</b>     Enable X11 forwarding. Does not apply to EC2 jobs.

          <b>-x</b>     Disable X11 forwarding.

</pre><h4><b>EXAMPLES</b></h4><pre>
          $ condor_ssh_to_job 32.0
          Welcome to <a href="mailto:slot2@tonic.cs.wisc.edu">slot2@tonic.cs.wisc.edu</a>!
          Your condor job is running with pid(s) 65881.
          $ gdb -p 65881
          (gdb) where
          ...
          $ logout
          Connection to condor-job.tonic.cs.wisc.edu closed.

       To upload or download files interactively with <u>sftp</u>:

          $ condor_ssh_to_job -ssh sftp 32.0
          Connecting to condor-job.tonic.cs.wisc.edu...
          sftp&gt; ls
          ...
          sftp&gt; get outputfile.dat

       This  example  shows  downloading a file from the job with <u>scp</u>. The string "remote" is used in place of a
       host name in this example. It is not necessary to insert the correct remote host name, or  even  a  valid
       one,  because  the  connection  to  the  job is created automatically.  Therefore, the placeholder string
       "remote" is perfectly fine.

          $ condor_ssh_to_job -ssh scp 32 remote:outputfile.dat .

       This example uses <u>condor_ssh_to_job</u> to accomplish the task of running <u>rsync</u> to synchronize a  local  file
       with  a  remote  file in the job's working directory. Job id 32.0 is used in place of a host name in this
       example. This causes <u>rsync</u> to insert the expected job id in the arguments to <u>condor_ssh_to_job</u>.

          $ rsync -v -e "condor_ssh_to_job" 32.0:outputfile.dat .

       Note that <u>condor_ssh_to_job</u> was added to HTCondor in version  7.3.   If  one  uses  <u>condor_ssh_to_job</u>  to
       connect  to  a  job  on  an  execute machine running a version of HTCondor older than the 7.3 series, the
       command will fail with the error message

          Failed to send CREATE_JOB_OWNER_SEC_SESSION to starter

</pre><h4><b>EXIT</b> <b>STATUS</b></h4><pre>
       <u>condor_ssh_to_job</u> will exit with a non-zero status value if it fails to set up  an  ssh  session.  If  it
       succeeds, it will exit with the status value of the remote command or shell.

</pre><h4><b>AUTHOR</b></h4><pre>
       HTCondor Team

</pre><h4><b>COPYRIGHT</b></h4><pre>
       1990-2024,  Center  for High Throughput Computing, Computer Sciences Department, University of Wisconsin-
       Madison, Madison, WI, US. Licensed under the Apache License, Version 2.0.

                                                  Jan 04, 2025                              <u><a href="../man1/CONDOR_SSH_TO_JOB.1.html">CONDOR_SSH_TO_JOB</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>