<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>s3cmd - tool for managing Amazon S3 storage space and Amazon CloudFront content delivery network</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/s3cmd">s3cmd_2.4.0-2_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       s3cmd - tool for managing Amazon S3 storage space and Amazon CloudFront content delivery network

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>s3cmd</b> [<u>OPTIONS</u>] <u>COMMAND</u> [<u>PARAMETERS</u>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <b>s3cmd</b>  is  a  command  line  client  for  copying  files  to/from  Amazon S3 (Simple Storage Service) and
       performing other related tasks, for instance creating and removing buckets, listing objects, etc.

</pre><h4><b>COMMANDS</b></h4><pre>
       <b>s3cmd</b> can do several <u>actions</u> specified by the following <u>commands</u>.

       s3cmd <b>mb</b> <u>s3://BUCKET</u>
              Make bucket

       s3cmd <b>rb</b> <u>s3://BUCKET</u>
              Remove bucket

       s3cmd <b>ls</b> <u>[s3://BUCKET[/PREFIX]]</u>
              List objects or buckets

       s3cmd <b>la</b>
              List all object in all buckets

       s3cmd <b>put</b> <u>FILE</u> <u>[FILE...]</u> <u>s3://BUCKET[/PREFIX]</u>
              Put file into bucket

       s3cmd <b>get</b> <u>s3://BUCKET/OBJECT</u> <u>LOCAL_FILE</u>
              Get file from bucket

       s3cmd <b>del</b> <u>s3://BUCKET/OBJECT</u>
              Delete file from bucket

       s3cmd <b>rm</b> <u>s3://BUCKET/OBJECT</u>
              Delete file from bucket (alias for del)

       s3cmd <b>restore</b> <u>s3://BUCKET/OBJECT</u>
              Restore file from Glacier storage

       s3cmd <b>sync</b> <u>LOCAL_DIR</u> <u>s3://BUCKET[/PREFIX]</u> <u>or</u> <u>s3://BUCKET[/PREFIX]</u> <u>LOCAL_DIR</u> <u>or</u> <u>s3://BUCKET[/PREFIX]</u>
       <u>s3://BUCKET[/PREFIX]</u>
              Synchronize a directory tree to S3 (checks files freshness using size  and  md5  checksum,  unless
              overridden by options, see below)

       s3cmd <b>du</b> <u>[s3://BUCKET[/PREFIX]]</u>
              Disk usage by buckets

       s3cmd <b>info</b> <u>s3://BUCKET[/OBJECT]</u>
              Get various information about Buckets or Files

       s3cmd <b>cp</b> <u>s3://BUCKET1/OBJECT1</u> <u>s3://BUCKET2[/OBJECT2]</u>
              Copy object

       s3cmd <b>modify</b> <u>s3://BUCKET1/OBJECT</u>
              Modify object metadata

       s3cmd <b>mv</b> <u>s3://BUCKET1/OBJECT1</u> <u>s3://BUCKET2[/OBJECT2]</u>
              Move object

       s3cmd <b>setacl</b> <u>s3://BUCKET[/OBJECT]</u>
              Modify Access control list for Bucket or Files

       s3cmd <b>setversioning</b> <u>s3://BUCKET</u> <u>enable|disable</u>
              Modify Bucket Versioning

       s3cmd <b>setownership</b> <u>s3://BUCKET</u> <u>BucketOwnerPreferred|BucketOwnerEnforced|ObjectWriter</u>
              Modify Bucket Object Ownership

       s3cmd <b>setblockpublicaccess</b> <u>s3://BUCKET</u>
       <u>BlockPublicAcls,IgnorePublicAcls,BlockPublicPolicy,RestrictPublicBuckets</u>
              Modify Block Public Access rules

       s3cmd <b>setobjectlegalhold</b> <u>STATUS</u> <u>s3://BUCKET/OBJECT</u>
              Modify Object Legal Hold

       s3cmd <b>setobjectretention</b> <u>MODE</u> <u>RETAIN_UNTIL_DATE</u> <u>s3://BUCKET/OBJECT</u>
              Modify Object Retention

       s3cmd <b>setpolicy</b> <u>FILE</u> <u>s3://BUCKET</u>
              Modify Bucket Policy

       s3cmd <b>delpolicy</b> <u>s3://BUCKET</u>
              Delete Bucket Policy

       s3cmd <b>setcors</b> <u>FILE</u> <u>s3://BUCKET</u>
              Modify Bucket CORS

       s3cmd <b>delcors</b> <u>s3://BUCKET</u>
              Delete Bucket CORS

       s3cmd <b>payer</b> <u>s3://BUCKET</u>
              Modify Bucket Requester Pays policy

       s3cmd <b>multipart</b> <u>s3://BUCKET</u> <u>[Id]</u>
              Show multipart uploads

       s3cmd <b>abortmp</b> <u>s3://BUCKET/OBJECT</u> <u>Id</u>
              Abort a multipart upload

       s3cmd <b>listmp</b> <u>s3://BUCKET/OBJECT</u> <u>Id</u>
              List parts of a multipart upload

       s3cmd <b>accesslog</b> <u>s3://BUCKET</u>
              Enable/disable bucket access logging

       s3cmd <b>sign</b> <u>STRING-TO-SIGN</u>
              Sign arbitrary string using the secret key

       s3cmd <b>signurl</b> <u>s3://BUCKET/OBJECT</u> <u>&lt;expiry_epoch|+expiry_offset&gt;</u>
              Sign an S3 URL to provide limited public access with expiry

       s3cmd <b>fixbucket</b> <u>s3://BUCKET[/PREFIX]</u>
              Fix invalid file names in a bucket

       s3cmd <b>settagging</b> <u>s3://BUCKET[/OBJECT]</u> <u>"KEY=VALUE[&amp;KEY=VALUE</u> <u>...]"</u>
              Modify tagging for Bucket or Files

       s3cmd <b>gettagging</b> <u>s3://BUCKET[/OBJECT]</u>
              Get tagging for Bucket or Files

       s3cmd <b>deltagging</b> <u>s3://BUCKET[/OBJECT]</u>
              Delete tagging for Bucket or Files

       s3cmd <b>expire</b> <u>s3://BUCKET</u>
              Set or delete expiration rule for the bucket

       s3cmd <b>setlifecycle</b> <u>FILE</u> <u>s3://BUCKET</u>
              Upload a lifecycle policy for the bucket

       s3cmd <b>getlifecycle</b> <u>s3://BUCKET</u>
              Get a lifecycle policy for the bucket

       s3cmd <b>dellifecycle</b> <u>s3://BUCKET</u>
              Remove a lifecycle policy for the bucket

       s3cmd <b>setnotification</b> <u>FILE</u> <u>s3://BUCKET</u>
              Upload a notification policy for the bucket

       s3cmd <b>getnotification</b> <u>s3://BUCKET</u>
              Get a notification policy for the bucket

       s3cmd <b>delnotification</b> <u>s3://BUCKET</u>
              Remove a notification policy for the bucket

       Commands for static WebSites configuration

       s3cmd <b>ws-create</b> <u>s3://BUCKET</u>
              Create Website from bucket

       s3cmd <b>ws-delete</b> <u>s3://BUCKET</u>
              Delete Website

       s3cmd <b>ws-info</b> <u>s3://BUCKET</u>
              Info about Website

       Commands for CloudFront management

       s3cmd <b>cflist</b>
              List CloudFront distribution points

       s3cmd <b>cfinfo</b> <u>[cf://DIST_ID]</u>
              Display CloudFront distribution point parameters

       s3cmd <b>cfcreate</b> <u>s3://BUCKET</u>
              Create CloudFront distribution point

       s3cmd <b>cfdelete</b> <u>cf://DIST_ID</u>
              Delete CloudFront distribution point

       s3cmd <b>cfmodify</b> <u>cf://DIST_ID</u>
              Change CloudFront distribution point parameters

       s3cmd <b>cfinval</b> <u>s3://BUCKET/OBJECT</u> <u>[s3://BUCKET/OBJECT</u> <u>...]</u>
              Invalidate CloudFront objects

       s3cmd <b>cfinvalinfo</b> <u>cf://DIST_ID[/INVAL_ID]</u>
              Display CloudFront invalidation request(s) status

</pre><h4><b>OPTIONS</b></h4><pre>
       Some  of  the  below specified options can have their default values set in <b>s3cmd</b> config file (by default
       $HOME/.s3cmd). As it's a simple text file feel free to open it with your favorite text editor and do  any
       changes you like.

       <b>-h</b>, <b>--help</b>
              show this help message and exit

       <b>--configure</b>
              Invoke  interactive  (re)configuration  tool.  Optionally use as '<b>--configure</b> s3://some-bucket' to
              test access to a specific bucket instead of attempting to list them all.

       <b>-c</b> FILE, <b>--config</b>=FILE
              Config file name. Defaults to $HOME/.s3cfg

       <b>--dump-config</b>
              Dump current configuration after parsing config files and command line options and exit.

       <b>--access_key</b>=ACCESS_KEY
              AWS Access Key

       <b>--secret_key</b>=SECRET_KEY
              AWS Secret Key

       <b>--access_token</b>=ACCESS_TOKEN
              AWS Access Token

       <b>-n</b>, <b>--dry-run</b>
              Only show what should be uploaded or downloaded but don't actually do it.  May  still  perform  S3
              requests to get bucket listings and other information though (only for file transfer commands)

       <b>-s</b>, <b>--ssl</b>
              Use HTTPS connection when communicating with S3.  (default)

       <b>--no-ssl</b>
              Don't use HTTPS.

       <b>-e</b>, <b>--encrypt</b>
              Encrypt files before uploading to S3.

       <b>--no-encrypt</b>
              Don't encrypt files.

       <b>-f</b>, <b>--force</b>
              Force overwrite and other dangerous operations.

       <b>--continue</b>
              Continue getting a partially downloaded file (only for [get] command).

       <b>--continue-put</b>
              Continue  uploading partially uploaded files or multipart upload parts.  Restarts parts/files that
              don't have matching size and md5.  Skips files/parts that do.  Note: md5sum checks are not  always
              sufficient to check (part) file equality.  Enable this at your own risk.

       <b>--upload-id</b>=UPLOAD_ID
              UploadId  for  Multipart  Upload,  in  case  you  want  continue an existing upload (equivalent to
              <b>--continue-</b> put) and there are multiple partial uploads.  Use s3cmd multipart [URI]  to  see  what
              UploadIds are associated with the given URI.

       <b>--skip-existing</b>
              Skip over files that exist at the destination (only for [get] and [sync] commands).

       <b>-r</b>, <b>--recursive</b>
              Recursive upload, download or removal.

       <b>--check-md5</b>
              Check MD5 sums when comparing files for [sync].  (default)

       <b>--no-check-md5</b>
              Do  not  check  MD5  sums  when  comparing  files  for  [sync].   Only  size will be compared. May
              significantly speed up transfer but may also miss some changed files.

       <b>-P</b>, <b>--acl-public</b>
              Store objects with ACL allowing read for anyone.

       <b>--acl-private</b>
              Store objects with default ACL allowing access for you only.

       <b>--acl-grant</b>=PERMISSION:EMAIL or USER_CANONICAL_ID
              Grant stated permission to a given amazon user.  Permission is  one  of:  read,  write,  read_acp,
              write_acp, full_control, all

       <b>--acl-revoke</b>=PERMISSION:USER_CANONICAL_ID
              Revoke  stated  permission  for a given amazon user.  Permission is one of: read, write, read_acp,
              write_acp, full_control, all

       <b>-D</b> NUM, <b>--restore-days</b>=NUM
              Number of days to keep restored file available (only for 'restore' command). Default is 1 day.

       <b>--restore-priority</b>=RESTORE_PRIORITY
              Priority for restoring files from S3 Glacier (only for expedited

       <b>--delete-removed</b>
              Delete destination objects with no corresponding source file [sync]

       <b>--no-delete-removed</b>
              Don't delete destination objects [sync]

       <b>--delete-after</b>
              Perform deletes AFTER new uploads when delete-removed is enabled [sync]

       <b>--delay-updates</b>
              *OBSOLETE* Put all updated files into place at end [sync]

       <b>--max-delete</b>=NUM
              Do not delete more than NUM files. [del] and [sync]

       <b>--limit</b>=NUM
              Limit number of objects returned in the response body (only for [ls] and [la] commands)

       <b>--add-destination</b>=ADDITIONAL_DESTINATIONS
              Additional destination for parallel uploads, in addition to last arg.  May be repeated.

       <b>--delete-after-fetch</b>
              Delete remote objects after fetching to local file (only for [get] and [sync] commands).

       <b>-p</b>, <b>--preserve</b>
              Preserve filesystem attributes (mode, ownership, timestamps). Default for [sync] command.

       <b>--no-preserve</b>
              Don't store FS attributes

       <b>--keep-dirs</b>
              Preserve all local  directories  as  remote  objects  including  empty  directories.  Experimental
              feature.

       <b>--exclude</b>=GLOB
              Filenames and paths matching GLOB will be excluded from sync

       <b>--exclude-from</b>=FILE
              Read --exclude GLOBs from FILE

       <b>--rexclude</b>=REGEXP
              Filenames and paths matching REGEXP (regular expression) will be excluded from sync

       <b>--rexclude-from</b>=FILE
              Read --rexclude REGEXPs from FILE

       <b>--include</b>=GLOB
              Filenames  and  paths  matching  GLOB  will  be  included  even  if  previously excluded by one of
              <b>--(r)exclude(-from)</b> patterns

       <b>--include-from</b>=FILE
              Read --include GLOBs from FILE

       <b>--rinclude</b>=REGEXP
              Same as --include but uses REGEXP (regular expression) instead of GLOB

       <b>--rinclude-from</b>=FILE
              Read --rinclude REGEXPs from FILE

       <b>--files-from</b>=FILE
              Read list of source-file names from FILE. Use - to read from stdin.

       <b>--region</b>=REGION, <b>--bucket-location</b>=REGION
              Region to create bucket in. As of now the regions are: us-east-1, us-west-1, us-west-2, eu-west-1,
              eu- central-1, ap-northeast-1, ap-southeast-1, ap- southeast-2, sa-east-1

       <b>--host</b>=HOSTNAME
              HOSTNAME:PORT  for  S3  endpoint  (default:  s3.amazonaws.com,   alternatives   such   as   s3-eu-
              west-1.amazonaws.com). You should also set <b>--host-</b> bucket.

       <b>--host-bucket</b>=HOST_BUCKET
              DNS-style     bucket+hostname:port     template     for     accessing     a    bucket    (default:
              %(bucket)s.s3.amazonaws.com)

       <b>--reduced-redundancy</b>, <b>--rr</b>
              Store object with 'Reduced redundancy'. Lower per-GB price. [put, cp, mv]

       <b>--no-reduced-redundancy</b>, <b>--no-rr</b>
              Store object without 'Reduced redundancy'. Higher per- GB price. [put, cp, mv]

       <b>--storage-class</b>=CLASS
              Store object with specified CLASS (STANDARD, STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, GLACIER
              or DEEP_ARCHIVE). [put, cp, mv]

       <b>--access-logging-target-prefix</b>=LOG_TARGET_PREFIX
              Target prefix for access logs (S3 URI) (for [cfmodify] and [accesslog] commands)

       <b>--no-access-logging</b>
              Disable access logging (for [cfmodify] and [accesslog] commands)

       <b>--default-mime-type</b>=DEFAULT_MIME_TYPE
              Default MIME-type for stored objects. Application default is binary/octet-stream.

       <b>-M</b>, <b>--guess-mime-type</b>
              Guess MIME-type of files by their extension or mime magic.  Fall  back  to  default  MIME-Type  as
              specified by <b>--default-mime-type</b> option

       <b>--no-guess-mime-type</b>
              Don't guess MIME-type and use the default type instead.

       <b>--no-mime-magic</b>
              Don't use mime magic when guessing MIME-type.

       <b>-m</b> MIME/TYPE, <b>--mime-type</b>=MIME/TYPE
              Force MIME-type. Override both <b>--default-mime-type</b> and <b>--guess-mime-type</b>.

       <b>--add-header</b>=NAME:VALUE
              Add  a  given  HTTP  header  to  the  upload request. Can be used multiple times. For instance set
              'Expires' or 'Cache-Control' headers (or both) using this option.

       <b>--remove-header</b>=NAME
              Remove a given HTTP header.  Can be used  multiple  times.   For  instance,  remove  'Expires'  or
              'Cache- Control' headers (or both) using this option. [modify]

       <b>--server-side-encryption</b>
              Specifies that server-side encryption will be used when putting objects. [put, sync, cp, modify]

       <b>--server-side-encryption-kms-id</b>=KMS_KEY
              Specifies  the  key  id  used  for server-side encryption with AWS KMS-Managed Keys (SSE-KMS) when
              putting objects. [put, sync, cp, modify]

       <b>--encoding</b>=ENCODING
              Override autodetected terminal and filesystem encoding (character set). Autodetected: UTF-8

       <b>--add-encoding-exts</b>=EXTENSIONs
              Add encoding to these comma delimited extensions i.e.  (css,js,html) when uploading to S3 )

       <b>--verbatim</b>
              Use the S3 name as given on the command line. No pre- processing, encoding, etc. Use with caution!

       <b>--disable-multipart</b>
              Disable multipart upload on files bigger than <b>--multipart-chunk-size-mb</b>

       <b>--multipart-chunk-size-mb</b>=SIZE
              Size of each chunk of a multipart upload. Files bigger than SIZE  are  automatically  uploaded  as
              multithreaded-  multipart,  smaller  files  are  uploaded using the traditional method. SIZE is in
              Mega-Bytes, default chunk size is 15MB, minimum allowed chunk size is 5MB, maximum is 5GB.

       <b>--list-md5</b>
              Include MD5 sums in bucket listings (only for 'ls' command).

       <b>--list-allow-unordered</b>
              Not an AWS standard. Allow the listing results to be returned  in  unsorted  order.  This  may  be
              faster when listing very large buckets.

       <b>-H</b>, <b>--human-readable-sizes</b>
              Print sizes in human readable form (eg 1kB instead of 1234).

       <b>--ws-index</b>=WEBSITE_INDEX
              Name of index-document (only for [ws-create] command)

       <b>--ws-error</b>=WEBSITE_ERROR
              Name of error-document (only for [ws-create] command)

       <b>--expiry-date</b>=EXPIRY_DATE
              Indicates when the expiration rule takes effect. (only for [expire] command)

       <b>--expiry-days</b>=EXPIRY_DAYS
              Indicates  the  number  of  days after object creation the expiration rule takes effect. (only for
              [expire] command)

       <b>--expiry-prefix</b>=EXPIRY_PREFIX
              Identifying one or more objects with the prefix to which the expiration rule  applies.  (only  for
              [expire] command)

       <b>--skip-destination-validation</b>
              Skips validation of Amazon SQS, Amazon SNS, and AWS Lambda destinations when applying notification
              configuration. (only for [setnotification] command)

       <b>--progress</b>
              Display progress meter (default on TTY).

       <b>--no-progress</b>
              Don't display progress meter (default on non-TTY).

       <b>--stats</b>
              Give some file-transfer stats.

       <b>--enable</b>
              Enable given CloudFront distribution (only for [cfmodify] command)

       <b>--disable</b>
              Disable given CloudFront distribution (only for [cfmodify] command)

       <b>--cf-invalidate</b>
              Invalidate the uploaded filed in CloudFront. Also see [cfinval] command.

       <b>--cf-invalidate-default-index</b>
              When using Custom Origin and S3 static website, invalidate the default index file.

       <b>--cf-no-invalidate-default-index-root</b>
              When  using  Custom  Origin  and S3 static website, don't invalidate the path to the default index
              file.

       <b>--cf-add-cname</b>=CNAME
              Add given CNAME to a CloudFront distribution (only for [cfcreate] and [cfmodify] commands)

       <b>--cf-remove-cname</b>=CNAME
              Remove given CNAME from a CloudFront distribution (only for [cfmodify] command)

       <b>--cf-comment</b>=COMMENT
              Set COMMENT for a given CloudFront distribution (only for [cfcreate] and [cfmodify] commands)

       <b>--cf-default-root-object</b>=DEFAULT_ROOT_OBJECT
              Set the default root object to return when no object is specified in the URL. Use a relative path,
              i.e.  default/index.html instead of /default/index.html  or  s3://bucket/default/index.html  (only
              for [cfcreate] and [cfmodify] commands)

       <b>-v</b>, <b>--verbose</b>
              Enable verbose output.

       <b>-d</b>, <b>--debug</b>
              Enable debug output.

       <b>--version</b>
              Show s3cmd version (2.4.0) and exit.

       <b>-F</b>, <b>--follow-symlinks</b>
              Follow symbolic links as if they are regular files

       <b>--cache-file</b>=FILE
              Cache FILE containing local source MD5 values

       <b>-q</b>, <b>--quiet</b>
              Silence output on stdout

       <b>--ca-certs</b>=CA_CERTS_FILE
              Path to SSL CA certificate FILE (instead of system default)

       <b>--ssl-cert</b>=SSL_CLIENT_CERT_FILE
              Path to client own SSL certificate CRT_FILE

       <b>--ssl-key</b>=SSL_CLIENT_KEY_FILE
              Path to client own SSL certificate private key KEY_FILE

       <b>--check-certificate</b>
              Check SSL certificate validity

       <b>--no-check-certificate</b>
              Do not check SSL certificate validity

       <b>--check-hostname</b>
              Check SSL certificate hostname validity

       <b>--no-check-hostname</b>
              Do not check SSL certificate hostname validity

       <b>--signature-v2</b>
              Use  AWS  Signature version 2 instead of newer signature methods. Helpful for S3-like systems that
              don't have AWS Signature v4 yet.

       <b>--limit-rate</b>=LIMITRATE
              Limit the upload or download speed to amount bytes per second.  Amount may be expressed in  bytes,
              kilobytes with the k suffix, or megabytes with the m suffix

       <b>--no-connection-pooling</b>
              Disable connection reuse

       <b>--requester-pays</b>
              Set the REQUESTER PAYS flag for operations

       <b>-l</b>, <b>--long-listing</b>
              Produce long listing [ls]

       <b>--stop-on-error</b>
              stop if error in transfer

       <b>--max-retries</b>=NUM
              Maximum number of times to retry a failed request before giving up. Default is 5

       <b>--content-disposition</b>=CONTENT_DISPOSITION
              Provide a Content-Disposition for signed URLs, e.g., "inline; filename=myvideo.mp4"

       <b>--content-type</b>=CONTENT_TYPE
              Provide a Content-Type for signed URLs, e.g., "video/mp4"

</pre><h4><b>EXAMPLES</b></h4><pre>
       One  of the most powerful commands of <u>s3cmd</u> is <b>s3cmd</b> <b>sync</b> used for synchronising complete directory trees
       to or from remote S3 storage. To some extent <b>s3cmd</b> <b>put</b> and <b>s3cmd</b> <b>get</b> share a similar behaviour with <b>sync</b>.

       Basic usage common in backup scenarios is as simple as:
            s3cmd sync /local/path/ s3://test-bucket/backup/

       This command will find all files under /local/path directory and copy them to corresponding  paths  under
       s3://test-bucket/backup on the remote side.  For example:
            /local/path/<b>file1.ext</b>         -&gt;  s3://bucket/backup/<b>file1.ext</b>
            /local/path/<b>dir123/file2.bin</b>  -&gt;  s3://bucket/backup/<b>dir123/file2.bin</b>

       However  if  the local path doesn't end with a slash the last directory's name is used on the remote side
       as well. Compare these with the previous example:
            s3cmd sync /local/path s3://test-bucket/backup/
       will sync:
            /local/<b>path/file1.ext</b>         -&gt;  s3://bucket/backup/<b>path/file1.ext</b>
            /local/<b>path/dir123/file2.bin</b>  -&gt;  s3://bucket/backup/<b>path/dir123/file2.bin</b>

       To retrieve the files back from S3 use inverted syntax:
            s3cmd sync s3://test-bucket/backup/ <a href="file:~/restore/">~/restore/</a>
       that will download files:
            s3://bucket/backup/<b>file1.ext</b>         -&gt;  <a href="file:~/restore/">~/restore/</a><b>file1.ext</b>
            s3://bucket/backup/<b>dir123/file2.bin</b>  -&gt;  <a href="file:~/restore/">~/restore/</a><b>dir123/file2.bin</b>

       Without the trailing slash on source the behaviour is similar to what has been demonstrated with upload:
            s3cmd sync s3://test-bucket/backup <a href="file:~/restore/">~/restore/</a>
       will download the files as:
            s3://bucket/<b>backup/file1.ext</b>         -&gt;  <a href="file:~/restore/">~/restore/</a><b>backup/file1.ext</b>
            s3://bucket/<b>backup/dir123/file2.bin</b>  -&gt;  <a href="file:~/restore/">~/restore/</a><b>backup/dir123/file2.bin</b>

       All source file names, the bold ones above, are matched against <b>exclude</b> rules and those  that  match  are
       then re-checked against <b>include</b> rules to see whether they should be excluded or kept in the source list.

       For the purpose of <b>--exclude</b> and <b>--include</b> matching only the bold file names above are used. For instance
       only <b>path/file1.ext</b> is tested against the patterns, not <u>/local/</u><b>path/file1.ext</b>

       Both  <b>--exclude</b>  and  <b>--include</b> work with shell-style wildcards (a.k.a. GLOB).  For a greater flexibility
       s3cmd provides Regular-expression versions of the two exclude options named  <b>--rexclude</b>  and  <b>--rinclude</b>.
       The options with ...<b>-from</b> suffix (eg --rinclude-from) expect a filename as an argument. Each line of such
       a file is treated as one pattern.

       There  is  only  one set of patterns built from all <b>--(r)exclude(-from)</b> options and similarly for include
       variant. Any file excluded with eg --exclude can be put back with  a  pattern  found  in  --rinclude-from
       list.

       Run  s3cmd  with  <b>--dry-run</b>  to  verify  that your rules work as expected.  Use together with <b>--debug</b> get
       detailed information about matching file names against exclude and include rules.

       For example to exclude all files with ".jpg" extension except those beginning with a number use:

            --exclude '*.jpg' --rinclude '[0-9].*.jpg'

       To exclude all files except "*.jpg" extension, use:

            --exclude '*' --include '*.jpg'

       To exclude local directory 'somedir', be sure to use a trailing forward slash, as such:

            --exclude 'somedir/'

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       For the most up to date list of options run: <b>s3cmd</b> <b>--help</b>
       For more info about usage, examples and other related info visit project homepage at: <b>https://s3tools.org</b>

</pre><h4><b>AUTHOR</b></h4><pre>
       Written by Michal Ludvig, Florent Viard and contributors

</pre><h4><b>CONTACT,</b> <b>SUPPORT</b></h4><pre>
       Preferred way to get support is our mailing list:
       <u><a href="mailto:s3tools-general@lists.sourceforge.net">s3tools-general@lists.sourceforge.net</a></u>
       or visit the project homepage:
       <b>https://s3tools.org</b>

</pre><h4><b>REPORTING</b> <b>BUGS</b></h4><pre>
       Report bugs to <u><a href="mailto:s3tools-bugs@lists.sourceforge.net">s3tools-bugs@lists.sourceforge.net</a></u>

</pre><h4><b>COPYRIGHT</b></h4><pre>
       Copyright © 2007-2023 TGRMN Software (https://www.tgrmn.com),  Sodria  SAS  (https://www.sodria.com)  and
       contributors

</pre><h4><b>LICENSE</b></h4><pre>
       This  program  is  free  software;  you  can  redistribute it and/or modify it under the terms of the GNU
       General Public License as published by the Free Software Foundation; either version 2 of the License,  or
       (at  your option) any later version.  This program is distributed in the hope that it will be useful, but
       WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS  FOR  A  PARTICULAR
       PURPOSE.  See the GNU General Public License for more details.

                                                                                                        <u><a href="../man1/s3cmd.1.html">s3cmd</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>