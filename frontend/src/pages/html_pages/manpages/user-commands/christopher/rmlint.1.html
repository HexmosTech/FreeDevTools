<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>rmlint - find duplicate files and other space waste efficiently</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/rmlint">rmlint_2.10.2-0ubuntu1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       rmlint - find duplicate files and other space waste efficiently

</pre><h4><b>FIND</b> <b>DUPLICATE</b> <b>FILES</b> <b>AND</b> <b>OTHER</b> <b>SPACE</b> <b>WASTE</b> <b>EFFICIENTLY</b></h4><pre>
   <b>SYNOPSIS</b>
       rmlint [TARGET_DIR_OR_FILES ...] [//] [TAGGED_TARGET_DIR_OR_FILES ...] [-] [OPTIONS]

   <b>DESCRIPTION</b>
       <b>rmlint</b>  finds  space  waste  and  other broken things on your filesystem.  Its main focus lies on finding
       duplicate files and directories.

       It is able to find the following types of lint:

       • Duplicate files and directories (and as a by-product unique files).

       • Nonstripped Binaries (Binaries with debug symbols; needs to be explicitly enabled).

       • Broken symbolic links.

       • Empty files and directories (also nested empty directories).

       • Files with broken user or group id.

       <b>rmlint</b> itself WILL NOT DELETE ANY FILES. It does however produce executable output (for example  a  shell
       script) to help you delete the files if you want to. Another design principle is that it should work well
       together  with other tools like <b>find</b>. Therefore we do not replicate features of other well know programs,
       as for example pattern matching and finding duplicate filenames.  However  we  provide  many  convenience
       options for common use cases that are hard to build from scratch with standard tools.

       In  order  to  find  the lint, <b>rmlint</b> is given one or more directories to traverse.  If no directories or
       files were given, the current working directory is assumed.  By default, <b>rmlint</b> will ignore hidden  files
       and  will  not  follow  symlinks  (see  <u>Traversal</u> <u>Options</u>).  <b>rmlint</b> will first find "other lint" and then
       search the remaining files for duplicates.

       <b>rmlint</b> tries to be helpful by guessing what file of a group of duplicates is the <b>original</b> (i.e. the  file
       that  should  not  be deleted). It does this by using different sorting strategies that can be controlled
       via the <b>-S</b> option. By default it chooses the first-named path on the commandline. If two duplicates  come
       from  the  same path, it will also apply different fallback sort strategies (See the documentation of the
       <b>-S</b> strategy).

       This behaviour can be also overwritten if you know that  a  certain  directory  contains  duplicates  and
       another one originals. In this case you write the original directory after specifying a single <b>//</b>  on the
       commandline.   Everything  that  comes  after  is  a  preferred  (or  a "tagged") directory. If there are
       duplicates from an unpreferred and from a preferred directory, the preferred one  will  always  count  as
       original. Special options can also be used to always keep files in preferred directories (<b>-k</b>) and to only
       find duplicates that are present in both given directories (<b>-m</b>).

       We advise new users to have a short look at all options <b>rmlint</b> has to offer, and maybe test some examples
       before  letting  it  run on productive data.  WRONG ASSUMPTIONS ARE THE BIGGEST ENEMY OF YOUR DATA. There
       are some extended example at the end of this manual, but each option that is  not  self-explanatory  will
       also try to give examples.

   <b>OPTIONS</b>
   <b>General</b> <b>Options</b>
       <b>-T</b> <b>--types="list"</b> <b>(default:</b> <u>defaults</u><b>)</b>
              Configure  the  types  of  lint rmlint will look for. The <u>list</u> string is a comma-separated list of
              lint types or lint groups (other separators like semicolon or space also work though).

              One of the following groups can be specified at the beginning of the list:

              • <b>all</b>: Enables all lint types.

              • <b>defaults</b>: Enables all lint types, but <b>nonstripped</b>.

              • <b>minimal</b>: <b>defaults</b> minus <b>emptyfiles</b> and <b>emptydirs</b>.

              • <b>minimaldirs</b>: <b>defaults</b> minus <b>emptyfiles</b>, <b>emptydirs</b> and <b>duplicates</b>, but with <b>duplicatedirs</b>.

              • <b>none</b>: Disable all lint types [default].

              Any of the following lint types can be added individually, or deselected by prefixing with a <b>-</b>:

              • <b>badids</b>, <b>bi</b>: Find files with bad UID, GID or both.

              • <b>badlinks</b>, <b>bl</b>: Find bad symlinks pointing nowhere valid.

              • <b>emptydirs</b>, <b>ed</b>: Find empty directories.

              • <b>emptyfiles</b>, <b>ef</b>: Find empty files.

              • <b>nonstripped</b>, <b>ns</b>: Find nonstripped binaries.

              • <b>duplicates</b>, <b>df</b>: Find duplicate files.

              • <b>duplicatedirs</b>, <b>dd</b>: Find duplicate directories (This is the same <b>-D</b>!)

              <b>WARNING:</b> It is good practice to enclose the description in single or  double  quotes.  In  obscure
              cases argument parsing might fail in weird ways, especially when using spaces as separator.

              Example:

                 $ rmlint -T "df,dd"        # Only search for duplicate files and directories
                 $ rmlint -T "all -df -dd"  # Search for all lint except duplicate files and dirs.

       <b>-o</b> <b>--output=spec</b> <b>/</b> <b>-O</b> <b>--add-output=spec</b> <b>(default:</b> <u>-o</u> <u>sh:rmlint.sh</u> <u>-o</u> <u>pretty:stdout</u> <u>-o</u> <u>summary:stdout</u> <u>-o</u>
       <u>json:rmlint.json</u><b>)</b>
              Configure the way <b>rmlint</b> outputs its results. A <b>spec</b> is in the form <b>format:file</b> or just <b>format</b>.  A
              <b>file</b>  might  either  be  an  arbitrary  path  or  <b>stdout</b> or <b>stderr</b>.  If file is omitted, <b>stdout</b> is
              assumed. <b>format</b> is the name of a formatter supported by this program. For a list of formatters and
              their options, refer to the <b>Formatters</b> section below.

              If <b>-o</b> is specified,  rmlint's  default  outputs  are  overwritten.   With  <b>--O</b>  the  defaults  are
              preserved.   Either  <b>-o</b>  or  <b>-O</b> may be specified multiple times to get multiple outputs, including
              multiple outputs of the same format.

              Examples:

                 $ rmlint -o json                 # Stream the json output to stdout
                 $ rmlint -O csv:/tmp/rmlint.csv  # Output an extra csv file to <a href="file:/tmp">/tmp</a>

       <b>-c</b> <b>--config=spec[=value]</b> <b>(default:</b> <u>none</u><b>)</b>
              Configure a format. This option can be used to fine-tune the behaviour of the existing formatters.
              See the <b>Formatters</b> section for details on the available keys.

              If the value is omitted it is set to a value meaning "enabled".

              Examples:

                 $ rmlint -c sh:link            # Smartly link duplicates instead of removing
                 $ rmlint -c progressbar:fancy  # Use a different theme for the progressbar

       <b>-z</b> <b>--perms[=[rwx]]</b> <b>(default:</b> <u>no</u> <u>check</u><b>)</b>
              Only look into file if it is readable, writable or executable by the current user.  Which  one  of
              the can be given as argument as one of <u>"rwx"</u>.

              If  no  argument  is given, <u>"rw"</u> is assumed. Note that <u>r</u> does basically nothing user-visible since
              <b>rmlint</b> will ignore unreadable files anyways.  It's just there for the sake of completeness.

              By default this check is not done.

              <b>$</b> <b>rmlint</b> <b>-z</b> <b>rx</b> <b>$(echo</b> <b>$PATH</b> <b>|</b> <b>tr</b> <b>":"</b> <b>"</b> <b>")</b>  <b>#</b> <b>Look</b> <b>at</b> <b>all</b> <b>executable</b> <b>files</b> <b>in</b> <b>$PATH</b>

       <b>-a</b> <b>--algorithm=name</b> <b>(default:</b> <u>blake2b</u><b>)</b>
              Choose the algorithm to use for finding duplicate files. The  algorithm  can  be  either  <b>paranoid</b>
              (byte-by-byte  file comparison) or use one of several file hash algorithms to identify duplicates.
              The following hash families are  available  (in  approximate  descending  order  of  cryptographic
              strength):

              <b>sha3</b>, <b>blake</b>,

              <b>sha</b>,

              <b>highway</b>, <b>md</b>

              <b>metro</b>, <b>murmur</b>, <b>xxhash</b>

              The  weaker hash functions still offer excellent distribution properties, but are potentially more
              vulnerable to <u>malicious</u> crafting of duplicate files.

              The full list of hash functions (in decreasing order of checksum length) is:

              512-bit: <b>blake2b</b>, <b>blake2bp</b>, <b>sha3-512</b>, <b>sha512</b>

              384-bit: <b>sha3-384</b>,

              256-bit: <b>blake2s</b>, <b>blake2sp</b>, <b>sha3-256</b>, <b>sha256</b>, <b>highway256</b>, <b>metro256</b>, <b>metrocrc256</b>

              160-bit: <b>sha1</b>

              128-bit: <b>md5</b>, <b>murmur</b>, <b>metro</b>, <b>metrocrc</b>

              64-bit: <b>highway64</b>, <b>xxhash</b>.

              The use of 64-bit hash length for detecting  duplicate  files  is  not  recommended,  due  to  the
              probability of a random hash collision.

       <b>-p</b> <b>--paranoid</b> <b>/</b> <b>-P</b> <b>--less-paranoid</b> <b>(default)</b>
              Increase  or  decrease  the  paranoia  of  <b>rmlint</b>'s  duplicate  algorithm.   Use  <b>-p</b>  if  you want
              byte-by-byte comparison without any hashing.

              • <b>-p</b> is equivalent to <b>--algorithm=paranoid</b>

              • <b>-P</b> is equivalent to <b>--algorithm=highway256</b>

              • <b>-PP</b> is equivalent to <b>--algorithm=metro256</b>

              • <b>-PPP</b> is equivalent to <b>--algorithm=metro</b>

       <b>-v</b> <b>--loud</b> <b>/</b> <b>-V</b> <b>--quiet</b>
              Increase or decrease the verbosity. You can pass these options several times.  This  only  affects
              <b>rmlint</b>'s  logging  on <u>stderr</u>, but not the outputs defined with <b>-o</b>. Passing either option more than
              three times has no further effect.

       <b>-g</b> <b>--progress</b> <b>/</b> <b>-G</b> <b>--no-progress</b> <b>(default)</b>
              Show a progressbar with sane defaults.

              Convenience shortcut for <b>-o</b> <b>progressbar</b> <b>-o</b> <b>summary</b> <b>-o</b> <b>sh:rmlint.sh</b> <b>-o</b> <b>json:rmlint.json</b> <b>-VVV</b>.

              NOTE: This flag clears all previous outputs. If you want additional outputs,  specify  them  after
              this flag using <b>-O</b>.

       <b>-D</b> <b>--merge-directories</b> <b>(default:</b> <u>disabled</u><b>)</b>
              Makes  rmlint  use  a  special  mode where all found duplicates are collected and checked if whole
              directory trees  are  duplicates.  Use  with  caution:  You  always  should  make  sure  that  the
              investigated directory is not modified during <b>rmlint</b>'s or its removal scripts run.

              IMPORTANT: Definition of equal: Two directories are considered equal by <b>rmlint</b> if they contain the
              exact  same  data,  no  matter  how  the  files containing the data are named. Imagine that <b>rmlint</b>
              creates a long, sorted stream out of the data found in the directory and compares this in a  magic
              way  to  another  directory.  This  means that the layout of the directory is not considered to be
              important by default. Also empty files will not count as content. This might be surprising to some
              users, but remember that <b>rmlint</b> generally cares only about content, not about any  other  metadata
              or   layout.   If   you  want  to  only  find  trees  with  the  same  hierarchy  you  should  use
              <b>--honour-dir-layout</b> <b>/</b> <b>-j</b>.

              Output is deferred until all duplicates were  found.  Duplicate  directories  are  printed  first,
              followed by any remaining duplicate files that are isolated or inside of any original directories.

              <b>--rank-by</b>  applies  for  directories too, but 'p' or 'P' (path index) has no defined (i.e. useful)
              meaning. Sorting takes only place when the number of preferred files in the directory differs.

              <b>NOTES:</b>

              • This option enables <b>--partial-hidden</b> and <b>-@</b> (<b>--see-symlinks</b>) for convenience.  If  this  is  not
                desired, you should change this after specifying <b>-D</b>.

              • This feature might add some runtime for large datasets.

              • When using this option, you will not be able to use the <b>-c</b> <b>sh:clone</b> option.  Use <b>-c</b> <b>sh:link</b> as a
                good alternative.

       <b>-j</b> <b>--honour-dir-layout</b> <b>(default:</b> <u>disabled</u><b>)</b>
              Only  recognize  directories  as  duplicates  that  have the same path layout. In other words: All
              duplicates that build the duplicate directory must have the  same  path  from  the  root  of  each
              respective directory.  This flag makes no sense without <b>--merge-directories</b>.

       <b>-y</b> <b>--sort-by=order</b> <b>(default:</b> <u>none</u><b>)</b>
              During  output, sort the found duplicate groups by criteria described by <u>order</u>.  <u>order</u> is a string
              that may consist of one or more of the following letters:

              • <u>s</u>: Sort by size of group.

              • <u>a</u>: Sort alphabetically by the basename of the original.

              • <u>m</u>: Sort by mtime of the original.

              • <u>p</u>: Sort by path-index of the original.

              • <u>o</u>: Sort by natural found order (might be different on each run).

              • <u>n</u>: Sort by number of files in the group.

              The letter may also be written uppercase (similar to <b>-S</b> <b>/</b> <b>--rank-by</b>) to reverse the sorting.  Note
              that <b>rmlint</b> has to hold back all results to the end of the run before sorting and printing.

       <b>-w</b> <b>--with-color</b> <b>(default)</b> <b>/</b> <b>-W</b> <b>--no-with-color</b>
              Use  color  escapes for pretty output or disable them.  If you pipe <u>rmlints</u> output to a file <b>-W</b> is
              assumed automatically.

       <b>-h</b> <b>--help</b> <b>/</b> <b>-H</b> <b>--show-man</b>
              Show a shorter reference help text (<b>-h</b>) or the full man page (<b>-H</b>).

       <b>--version</b>
              Print the version of rmlint. Includes git revision and compile time features. Please include  this
              when giving feedback to us.

   <b>Traversal</b> <b>Options</b>
       <b>-s</b> <b>--size=range</b> <b>(default:</b> <b>"1")</b>
              Only  consider files as duplicates in a certain size range.  The format of <u>range</u> is <u>min-max</u>, where
              both ends can be specified as a number with an optional multiplier. The available multipliers are:

              • <u>C</u> (1^1), <u>W</u> (2^1), B (512^1), <u>K</u> (1000^1), KB (1024^1), <u>M</u> (1000^2), <u>MB</u> (1024^2),  <u>G</u>  (1000^3),  <u>GB</u>
                (1024^3),

              • <u>T</u> (1000^4), <u>TB</u> (1024^4), <u>P</u> (1000^5), <u>PB</u> (1024^5), <u>E</u> (1000^6), <u>EB</u> (1024^6)

              The size format is about the same as <u><a href="../man1/dd.1.html">dd</a>(1)</u> uses. A valid example would be: <b>"100KB-2M"</b>. This limits
              duplicates to a range from 100 Kilobyte to 2 Megabyte.

              It's  also  possible  to specify only one size. In this case the size is interpreted as <u>"bigger</u> <u>or</u>
              <u>equal"</u>. If you want to filter for files <u>up</u> <u>to</u> <u>this</u> <u>size</u> you can add a <b>-</b> in front  (<b>-s</b>  <b>-1M</b>  ==  <b>-s</b>
              <b>0-1M</b>).

              <b>Edge</b> <b>case:</b> The default excludes empty files from the duplicate search.  Normally these are treated
              specially  by  <b>rmlint</b>  by  handling  them  as  <u>other</u>  <u>lint</u>.  If you want to include empty files as
              duplicates you should lower the limit to zero:

              <b>$</b> <b>rmlint</b> <b>-T</b> <b>df</b> <b>--size</b> <b>0</b>

       <b>-d</b> <b>--max-depth=depth</b> <b>(default:</b> <u>INF</u><b>)</b>
              Only recurse up to this depth. A depth of 1  would  disable  recursion  and  is  equivalent  to  a
              directory listing. A depth of 2 would also consider all children directories and so on.

       <b>-l</b> <b>--hardlinked</b> <b>(default)</b> <b>/</b> <b>--keep-hardlinked</b> <b>/</b> <b>-L</b> <b>--no-hardlinked</b>
              Hardlinked  files  are  treated  as  duplicates by default (<b>--hardlinked</b>). If <b>--keep-hardlinked</b> is
              given, <u>rmlint</u> will not delete any files that are hardlinked to an  original  in  their  respective
              group.  Such  files  will  be displayed like originals, i.e. for the default output with a "ls" in
              front.  The reasoning here is to maximize the number of kept files, while maximizing the number of
              freed space: Removing hardlinks to originals will not allocate any free space.

              If <u>--no-hardlinked</u> is given, only one file (of a set of hardlinked files) is considered,  all  the
              others  are  ignored;  this means, they are not deleted and also not even shown in the output. The
              "highest ranked" of the set is the one that is considered.

       <b>-f</b> <b>--followlinks</b> <b>/</b> <b>-F</b> <b>--no-followlinks</b> <b>/</b> <b>-@</b> <b>--see-symlinks</b> <b>(default)</b>
              <b>-f</b> will always follow symbolic links. If file system loops occurs <b>rmlint</b> will detect this.  If  <u>-F</u>
              is  specified,  symbolic  links  will  be  ignored completely, if <b>-@</b> is specified, <b>rmlint</b> will see
              symlinks and treats them like small files with the path to their target in them. The latter is the
              default behaviour, since it is a sensible default for <b>--merge-directories</b>.

       <b>-x</b> <b>--no-crossdev</b> <b>/</b> <b>-X</b> <b>--crossdev</b> <b>(default)</b>
              Stay always on the same device (<b>-x</b>), or  allow  crossing  mountpoints  (<b>-X</b>).  The  latter  is  the
              default.

       <b>-r</b> <b>--hidden</b> <b>/</b> <b>-R</b> <b>--no-hidden</b> <b>(default)</b> <b>/</b> <b>--partial-hidden</b>
              Also  traverse  hidden  directories?  This  is often not a good idea, since directories like <b>.git/</b>
              would be investigated, possibly leading to the deletion of internal <b>git</b> files which in turn  break
              a  repository.   With  <b>--partial-hidden</b>  hidden  files  and folders are only considered if they're
              inside duplicate directories (see <b>--merge-directories</b>) and will be deleted as part of it.

       <b>-b</b> <b>--match-basename</b>
              Only consider those files as dupes that have the same basename.  See  also  <b>man</b>  <b>1</b>  <b>basename</b>.  The
              comparison of the basenames is case-insensitive.

       <b>-B</b> <b>--unmatched-basename</b>
              Only  consider those files as dupes that do not share the same basename.  See also <b>man</b> <b>1</b> <b>basename</b>.
              The comparison of the basenames is case-insensitive.

       <b>-e</b> <b>--match-extension</b> <b>/</b> <b>-E</b> <b>--no-match-extension</b> <b>(default)</b>
              Only consider those files as dupes that have the same file extension. For example two photos would
              only match if they are a <b>.png</b>. The extension is compared case-insensitive, so <b>.PNG</b> is the same  as
              <b>.png</b>.

       <b>-i</b> <b>--match-without-extension</b> <b>/</b> <b>-I</b> <b>--no-match-without-extension</b> <b>(default)</b>
              Only  consider  those  files  as  dupes  that have the same basename minus the file extension. For
              example: <b>banana.png</b> and <b>Banana.jpeg</b> would be considered, while <b>apple.png</b> and <b>peach.png</b> won't.  The
              comparison is case-insensitive.

       <b>-n</b> <b>--newer-than-stamp=&lt;timestamp_filename&gt;</b> <b>/</b> <b>-N</b> <b>--newer-than=&lt;iso8601_timestamp_or_unix_timestamp&gt;</b>
              Only  consider  files  (and  their size siblings for duplicates) newer than a certain modification
              time (<u>mtime</u>).  The age barrier may be given as seconds since the  epoch  or  as  ISO8601-Timestamp
              like <u>2014-09-08T00:12:32+0200</u>.

              <b>-n</b> expects a file from which it can read the timestamp. After rmlint run, the file will be updated
              with  the  current  timestamp.  If the file does not initially exist, no filtering is done but the
              stampfile is still written.

              <b>-N</b>, in contrast, takes the timestamp directly and will not write anything.

              Note that <b>rmlint</b> will find duplicates newer than <b>timestamp</b>, even if the original is older.  If you
              want only find duplicates where both original and duplicate are newer than <b>timestamp</b> you  can  use
              <b><a href="../man1/find.1.html">find</a>(1)</b>:

              • <b>find</b> <b>-mtime</b> <b>-1</b> <b>-print0</b> <b>|</b> <b>rmlint</b> <b>-0</b> <b>#</b> <b>pass</b> <b>all</b> <b>files</b> <b>younger</b> <b>than</b> <b>a</b> <b>day</b> <b>to</b> <b>rmlint</b>

              <u>Note:</u> you can make rmlint write out a compatible timestamp with:

              • <b>-O</b> <b>stamp:stdout</b>  <b>#</b> <b>Write</b> <b>a</b> <b>seconds-since-epoch</b> <b>timestamp</b> <b>to</b> <b>stdout</b> <b>on</b> <b>finish.</b>

              • <b>-O</b> <b>stamp:stdout</b> <b>-c</b> <b>stamp:iso8601</b> <b>#</b> <b>Same,</b> <b>but</b> <b>write</b> <b>as</b> <b>ISO8601.</b>

   <b>Original</b> <b>Detection</b> <b>Options</b>
       <b>-k</b> <b>--keep-all-tagged</b> <b>/</b> <b>-K</b> <b>--keep-all-untagged</b>
              Don't  delete  any  duplicates that are in tagged paths (<b>-k</b>) or that are in non-tagged paths (<b>-K</b>).
              (Tagged paths are those that were named after <b>//</b>).

       <b>-m</b> <b>--must-match-tagged</b> <b>/</b> <b>-M</b> <b>--must-match-untagged</b>
              Only look for duplicates of which at least one is in one of the tagged paths.   (Paths  that  were
              named after <b>//</b>).

              Note    that    the   combinations   of   <b>-kM</b>   and   <b>-Km</b>   are   prohibited   by   <b>rmlint</b>.    See
              <u>https://github.com/sahib/rmlint/issues/244</u> for more information.

       <b>-S</b> <b>--rank-by=criteria</b> <b>(default:</b> <u>pOma</u><b>)</b>
              Sort the files in a group of duplicates into originals and duplicates by  one  or  more  criteria.
              Each criteria is defined by a single letter (except <b>r</b> and <b>x</b> which expect a regex pattern after the
              letter). Multiple criteria may be given as string, where the first criteria is the most important.
              If one criteria cannot decide between original and duplicate the next one is tried.

              • <b>m</b>: keep lowest mtime (oldest)           <b>M</b>: keep highest mtime (newest)

              • <b>a</b>: keep first alphabetically            <b>A</b>: keep last alphabetically

              • <b>p</b>: keep first named path                <b>P</b>: keep last named path

              • <b>d</b>: keep path with lowest depth          <b>D</b>: keep path with highest depth

              • <b>l</b>: keep path with shortest basename     <b>L</b>: keep path with longest basename

              • <b>r</b>: keep paths matching regex            <b>R</b>: keep path not matching regex

              • <b>x</b>: keep basenames matching regex        <b>X</b>: keep basenames not matching regex

              • <b>h</b>: keep file with lowest hardlink count <b>H</b>: keep file with highest hardlink count

              • <b>o</b>: keep file with lowest number of hardlinks outside of the paths traversed by <b>rmlint</b>.

              • <b>O</b>: keep file with highest number of hardlinks outside of the paths traversed by <b>rmlint</b>.

              Alphabetical  sort  will  only  use  the  basename  of the file and ignore its case.  One can have
              multiple criteria, e.g.: <b>-S</b> <b>am</b> will choose first alphabetically; if tied  then  by  mtime.   <b>Note:</b>
              original path criteria (specified using <u>//</u>) will always take first priority over <u>-S</u> options.

              For more fine grained control, it is possible to give a regular expression to sort by. This can be
              useful when you know a common fact that identifies original paths (like a path component being <b>src</b>
              or a certain file ending).

              To  use  the  regular  expression  you  simply  enclose  it  in  the  criteria  string  by  adding
              <u>&lt;REGULAR_EXPRESSION&gt;</u> after specifying <u>r</u> or <u>x</u>. Example: <b>-S</b> <b>'r&lt;.*\.bak$&gt;'</b> makes all files that  have
              a <b>.bak</b> suffix original files.

              Warning:  When  using  <b>r</b> or <b>x</b>, try to make your regex to be as specific as possible! Good practice
              includes adding a <b>$</b> anchor at the end of the regex.

              Tips:

              • <b>l</b> is useful for files like <u>file.mp3</u> <u>vs</u> <u>file.1.mp3</u> <u>or</u> <u>file.mp3.bak</u>.

              • <b>a</b> can be used as last criteria to assert a defined order.

              • <b>o/O</b> and <b>h/H</b> are only useful if there any hardlinks in the traversed path.

              • <b>o/O</b> takes the number of hardlinks outside the traversed paths (and  thereby  minimizes/maximizes
                the  overall  number of hardlinks). <b>h/H</b> in contrast only takes the number of hardlinks <u>inside</u> of
                the traversed paths. When hardlinking files, one would like to link to the  original  file  with
                the highest outer link count (<b>O</b>) in order to maximise the space cleanup. <b>H</b> does not maximise the
                space  cleanup, it just selects the file with the highest total hardlink count. You usually want
                to specify <b>O</b>.

              • <b>pOma</b> is the default since <b>p</b> ensures that first given paths rank as  originals,  <b>O</b>  ensures  that
                hardlinks  are handled well, <b>m</b> ensures that the oldest file is the original and <b>a</b> simply ensures
                a defined ordering if no other criteria applies.

   <b>Caching</b>
       <b>--replay</b>
              Read an existing json file and re-output it. When <b>--replay</b> is given, <b>rmlint</b> does  <b>no</b>  <b>input/output</b>
              <b>on</b>  <b>the</b>  <b>filesystem</b>,  even  if  you  pass  additional  paths.  The paths you pass will be used for
              filtering the <b>--replay</b> output.

              This is very useful if you want to reformat, refilter or resort the output you got from a previous
              run. Usage is simple: Just pass <b>--replay</b> on  the  second  run,  with  other  changed  to  the  new
              formatters or filters. Pass the <b>.json</b> files of the previous runs additionally to the paths you ran
              <b>rmlint</b>  on.  You  can  also merge several previous runs by specifying more than one <b>.json</b> file, in
              this case it will merge all files given and output them as one big run.

              If you want to view only  the  duplicates  of  certain  subdirectories,  just  pass  them  on  the
              commandline as usual.

              The  usage  of  <b>//</b> has the same effect as in a normal run. It can be used to prefer one <b>.json</b> file
              over another. However note that running <b>rmlint</b> in <b>--replay</b> mode includes no real  disk  traversal,
              i.e.  only  duplicates  from previous runs are printed. Therefore specifying new paths will simply
              have no effect. As a security measure, <b>--replay</b> will ignore  files  whose  mtime  changed  in  the
              meantime  (i.e. mtime in the <b>.json</b> file differs from the current one). These files might have been
              modified and are silently ignored.

              By design, some options will not have any effect. Those are:

              • <b>--followlinks</b>

              • <b>--algorithm</b>

              • <b>--paranoid</b>

              • <b>--clamp-low</b>

              • <b>--hardlinked</b>

              • <b>--write-unfinished</b>

              • ... and all other caching options below.

              <u>NOTE:</u> In <b>--replay</b> mode, a new <b>.json</b> file will be written to <b>rmlint.replay.json</b> in order  to  avoid
              overwriting <b>rmlint.json</b>.

       <b>-C</b> <b>--xattr</b>
              Shortcut  for  <b>--xattr-read</b>,  <b>--xattr-write</b>, <b>--write-unfinished</b>.  This will write a checksum and a
              timestamp to the extended attributes of each file that rmlint hashed. This  speeds  up  subsequent
              runs  on  the same data set.  Please note that not all filesystems may support extended attributes
              and you need write support to use this feature.

              See the individual options below for more details and some examples.

       <b>--xattr-read</b> <b>/</b> <b>--xattr-write</b> <b>/</b> <b>--xattr-clear</b>
              Read or write cached checksums from the extended file attributes.  This feature  can  be  used  to
              speed up consecutive runs.

              <b>CAUTION:</b>  This  could  potentially  lead  to false positives if file contents are somehow modified
              without changing the file modification time.  rmlint uses the mtime to determine the  modification
              timestamp  if  a  checksum  is  outdated.  This  is  not a problem if you use the clone or reflink
              operation on a filesystem like btrfs. There an outdated checksum entry would simply lead  to  some
              duplicate work done in the kernel but would do no harm otherwise.

              <b>NOTE:</b>  Many  tools  do  not  support extended file attributes properly, resulting in a loss of the
              information when copying the file or editing it.

              <b>NOTE:</b> You can specify <b>--xattr-write</b> and <b>--xattr-read</b> at  the  same  time.   This  will  read  from
              existing checksums at the start of the run and update all hashed files at the end.

              <b>--xattr-write</b>  has no effect when <b>--clamp-low</b> or <b>--clamp-top</b> is used to prevent false negatives in
              future runs without clamping.

              Usage example:

                 $ rmlint large_file_cluster/ -U --xattr-write   # first run should be slow.
                 $ rmlint large_file_cluster/ --xattr-read       # second run should be faster.

                 # Or do the same in just one run:
                 $ rmlint large_file_cluster/ --xattr

       <b>-U</b> <b>--write-unfinished</b>
              Include files in output that have not been hashed fully, i.e. files that do not appear to  have  a
              duplicate.  Note  that  this  will not include all files that <b>rmlint</b> traversed, but only the files
              that were chosen to be hashed.

              This is mainly useful in conjunction with <b>--xattr-write/read</b>. When re-running rmlint  on  a  large
              dataset  this  can  greatly  speed  up a re-run in some cases. Please refer to <b>--xattr-read</b> for an
              example.

              If you want to output unique files, please look into the <b>uniques</b> output formatter.

   <b>Rarely</b> <b>used,</b> <b>miscellaneous</b> <b>options</b>
       <b>-t</b> <b>--threads=N</b> <b>(</b><u>default:</u> <b>16)</b>
              The number of threads to use during file tree traversal and hashing.  <b>rmlint</b> probably knows better
              than you how to set this value, so just leave it as it is. Setting it to  <b>1</b>  will  also  not  make
              <b>rmlint</b> a single threaded program.

       <b>-u</b> <b>--limit-mem=size</b>
              Apply  a  maximum  number of memory to use for hashing and <b>--paranoid</b>.  The total number of memory
              might still exceed this limit though, especially when setting it very low. In general <b>rmlint</b>  will
              however consume about this amount of memory plus a more or less constant extra amount that depends
              on the data you are scanning.

              The  <b>size</b>-description  has the same format as for <b>--size</b>, therefore you can do something like this
              (use this if you have 1GB of memory available):

              <b>$</b> <b>rmlint</b> <b>-u</b> <b>512M</b>  <b>#</b> <b>Limit</b> <b>paranoid</b> <b>mem</b> <b>usage</b> <b>to</b> <b>512</b> <b>MB</b>

       <b>-q</b> <b>--clamp-low=[fac.tor|percent%|offset]</b> <b>(default:</b> <u>0</u><b>)</b> <b>/</b> <b>-Q</b> <b>--clamp-top=[fac.tor|percent%|offset]</b>
       <b>(default:</b> <u>1.0</u><b>)</b>
              The argument can be either passed as factor (a number with a <b>.</b> in it), a percent  value  (suffixed
              by <b>%</b>) or as absolute number or size spec, like in <b>--size</b>.

              Only look at the content of files in the range of from <b>low</b> to (including) <b>high</b>. This means, if the
              range  is  less than <b>-q</b> <b>0%</b> to <b>-Q</b> <b>100%</b>, than only partial duplicates are searched. If the file size
              is less than the clamp limits, the file is ignored during traversing. Be careful when  using  this
              function, you can easily get dangerous results for small files.

              This  is  useful  in  a few cases where a file consists of a constant sized header or footer. With
              this option you can just compare the data in between.  Also it might  be  useful  for  approximate
              comparison where it suffices when the file is the same in the middle part.

              Example:

              <b>$</b> <b>rmlint</b> <b>-q</b> <b>10%</b> <b>-Q</b> <b>512M</b>  <b>#</b> <b>Only</b> <b>read</b> <b>the</b> <b>last</b> <b>90%</b> <b>of</b> <b>a</b> <b>file,</b> <b>but</b> <b>read</b> <b>at</b> <b>max.</b> <b>512MB</b>

       <b>-Z</b> <b>--mtime-window=T</b> <b>(default:</b> <u>-1</u><b>)</b>
              Only  consider those files as duplicates that have the same content and the same modification time
              (mtime) within a certain window of <u>T</u> seconds.  If <u>T</u> is 0, both files need to have the same  mtime.
              For  <u>T=1</u>  they  may  differ  one  second  and  so on. If the window size is negative, the mtime of
              duplicates will not be considered. <u>T</u> may be a floating point number.

              However, with three (or more) files, the mtime difference between two  duplicates  can  be  bigger
              than  the  mtime window <u>T</u>, i.e. several files may be chained together by the window. Example: If <u>T</u>
              is 1, the four files fooA (mtime: 00:00:00), fooB (00:00:01),  fooC  (00:00:02),  fooD  (00:00:03)
              would  all  belong  to  the same duplicate group, although the mtime of fooA and fooD differs by 3
              seconds.

       <b>--with-fiemap</b> <b>(default)</b> <b>/</b> <b>--without-fiemap</b>
              Enable or disable reading the file extents on rotational disk in order  to  optimize  disk  access
              patterns. If this feature is not available, it is disabled automatically.

   <b>FORMATTERS</b>
       • <b>csv</b>: Output all found lint as comma-separated-value list.

         Available options:

         • <u>no_header</u>: Do not write a first line describing the column headers.

         • <u>unique</u>: Include unique files in the output.

       •

         <b>sh:</b> <b>Output</b> <b>all</b> <b>found</b> <b>lint</b> <b>as</b> <b>shell</b> <b>script</b> <b>This</b> <b>formatter</b> <b>is</b> <b>activated</b>
                as default.

         available options:

         • <u>cmd</u>:  Specify  a  user  defined  command  to  run  on  duplicates.   The  command  can  be  any valid
           <b><a href="file:/bin/sh">/bin/sh</a></b>-expression. The duplicate path and original path can be accessed  via  <b>"$1"</b>  and  <b>"$2"</b>.   The
           command will be written to the <b>user_command</b> function in the <b>sh</b>-file produced by rmlint.

         • <u>handler</u> Define a comma separated list of handlers to try on duplicate files in that given order until
           one  handler  succeeds. Handlers are just the name of a way of getting rid of the file and can be any
           of the following:

           • <b>clone</b>: For reflink-capable filesystems only.  Try  to  clone  both  files  with  the  FIDEDUPERANGE
             <b><a href="../man3p/ioctl.3p.html">ioctl</a>(3p)</b>  (or  BTRFS_IOC_FILE_EXTENT_SAME on older kernels).  This will free up duplicate extents.
             Needs at least kernel 4.2.  Use this option  when  you  only  have  read-only  access  to  a  btrfs
             filesystem but still want to deduplicate it. This is usually the case for snapshots.

           • <b>reflink</b>:  Try  to reflink the duplicate file to the original. See also <b>--reflink</b> in <b>man</b> <b>1</b> <b>cp</b>. Fails
             if the filesystem does not support it.

           • <b>hardlink</b>: Replace the duplicate file with a hardlink to the original file. The resulting files will
             have  the same inode number. Fails if both files are not on the same partition. You can use  <b>ls</b>  <b>-i</b>
             to  show  the  inode number of a file and <b>find</b> <b>-samefile</b> <b>&lt;path&gt;</b> to find all hardlinks for a certain
             file.

           • <b>symlink</b>: Tries to replace the duplicate file with a symbolic link to  the  original.  This  handler
             never fails.

           • <b>remove</b>: Remove the file using <b>rm</b> <b>-rf</b>. (<b>-r</b> for duplicate dirs).  This handler never fails.

           • <b>usercmd</b>: Use the provided user defined command (<b>-c</b> <b>sh:cmd=something</b>). This handler never fails.

           Default is <b>remove</b>.

         • <u>link</u>:  Shortcut  for  <b>-c</b>  <b>sh:handler=clone,reflink,hardlink,symlink</b>.   Use  this  if  you  are  on  a
           reflink-capable system.

         • <u>hardlink</u>: Shortcut for <b>-c</b> <b>sh:handler=hardlink,symlink</b>.  Use this if you want to hardlink  files,  but
           want to fallback for duplicates that lie on different devices.

         • <u>symlink</u>: Shortcut for <b>-c</b> <b>sh:handler=symlink</b>.  Use this as last straw.

       • <b>json</b>:  Print  a  JSON-formatted  dump  of  all  found reports. Outputs all lint as a json document. The
         document is a list of dictionaries, where the first and last element is  the  header  and  the  footer.
         Everything between are data-dictionaries.

         Available options:

         • <u>unique</u>: Include unique files in the output.

         • <u>no_header=[true|false]:</u> Print the header with metadata (default: true)

         • <u>no_footer=[true|false]:</u> Print the footer with statistics (default: true)

         • <u>oneline=[true|false]:</u> Print one json document per line (default: false) This is useful if you plan to
           parse the output line-by-line, e.g. while <b>rmlint</b> is sill running.

         This  formatter  is extremely useful if you're in need of scripting more complex behaviour, that is not
         directly possible with rmlint's built-in options. A very handy tool here is <b>jq</b>.  Here is an example  to
         output all original files directly from a <b>rmlint</b> run:

         <b>$</b> <b>rmlint</b> <b>-o</b> <b>|</b> <b>json</b> <b>jq</b> <b>-r</b> <b>'.[1:-1][]</b> <b>|</b> <b>select(.is_original)</b> <b>|</b> <b>.path'</b>

       • <b>py</b>:  Outputs  a  python script and a JSON document, just like the <b>json</b> formatter.  The JSON document is
         written to <b>.rmlint.json</b>, executing the script will make it read from there. This  formatter  is  mostly
         intended  for  complex  use-cases  where  the lint needs special handling that you define in the python
         script.  Therefore the python script can be modified to do things standard <b>rmlint</b> is  not  able  to  do
         easily.

       • <b>uniques</b>:  Outputs  all  unique paths found during the run, one path per line.  This is often useful for
         scripting purposes.

         Available options:

         • <u>print0</u>: Do not put newlines between paths but zero bytes.

       • <b>stamp</b>:

         Outputs a timestamp of the time <b>rmlint</b> was run.  See also the <b>--newer-than</b> and <b>--newer-than-stamp</b>  file
         option.

         Available options:

         • <u>iso8601=[true|false]:</u> Write an ISO8601 formatted timestamps or seconds since epoch?

       • <b>progressbar</b>: Shows a progressbar. This is meant for use with <b>stdout</b> or <b>stderr</b> [default].

         See also: <b>-g</b> (<b>--progress</b>) for a convenience shortcut option.

         Available options:

         • <u>update_interval=number:</u>  Number  of  milliseconds  to  wait  between updates.  Higher values use less
           resources (default 50).

         • <u>ascii:</u> Do not attempt to use unicode characters, which might not be supported by some terminals.

         • <u>fancy:</u> Use a more fancy style for the progressbar.

       • <b>pretty</b>: Shows all found items in realtime nicely colored. This formatter is activated as default.

       • <b>summary</b>: Shows counts of files and their respective size after the run.  Also list all  written  output
         files.

       • <b>fdupes</b>:  Prints  an output similar to the popular duplicate finder <b><a href="../man1/fdupes.1.html">fdupes</a>(1)</b>. At first a progressbar is
         printed on <b>stderr.</b> Afterwards the found files are printed  on  <b>stdout;</b>  each  set  of  duplicates  gets
         printed  as  a block separated by newlines. Originals are highlighted in green. At the bottom a summary
         is printed on <b>stderr</b>. This is mostly useful for scripts that were set up for parsing fdupes output.  We
         recommend the <b>json</b> formatter for every other scripting purpose.

         Available options:

         • <u>omitfirst:</u>  Same  as  the  <b>-f</b>  <b>/</b> <b>--omitfirst</b> option in <b><a href="../man1/fdupes.1.html">fdupes</a>(1)</b>. Omits the first line of each set of
           duplicates (i.e. the original file.

         • <u>sameline:</u> Same as the <b>-1</b> <b>/</b> <b>--sameline</b> option in <b><a href="../man1/fdupes.1.html">fdupes</a>(1)</b>. Does not  print  newlines  between  files,
           only a space. Newlines are printed only between sets of duplicates.

   <b>OTHER</b> <b>STAND-ALONE</b> <b>COMMANDS</b>
       <b>rmlint</b> <b>--gui</b>
              Start the optional graphical frontend to <b>rmlint</b> called <b>Shredder</b>.

              This   will   only   work   when   <b>Shredder</b>  and  its  dependencies  were  installed.   See  also:
              <u><a href="http://rmlint.readthedocs.org/en/latest/gui.html">http://rmlint.readthedocs.org/en/latest/gui.html</a></u>

              The gui has its own set of options, see <b>--gui</b> <b>--help</b> for a list.  These should be  placed  at  the
              end, ie <b>rmlint</b> <b>--gui</b> <b>[options]</b> when calling it from commandline.

       <b>rmlint</b> <b>--hash</b> <b>[paths...]</b>
              Make  <b>rmlint</b>  work as a multi-threaded file hash utility, similar to the popular <b>md5sum</b> or <b>sha1sum</b>
              utilities, but faster and with more algorithms.  A set of paths given on the commandline  or  from
              <u>stdin</u> is hashed using one of the available hash algorithms.  Use <b>rmlint</b> <b>--hash</b> <b>-h</b> to see options.

       <b>rmlint</b> <b>--equal</b> <b>[paths...]</b>
              Check  if the paths given on the commandline all have equal content. If all paths are equal and no
              other error happened, rmlint will exit with an exit code 0. Otherwise it will exit with a  nonzero
              exit  code.  All  other  options can be used as normal, but note that no other formatters (<b>sh</b>, <b>csv</b>
              etc.) will be executed by default. At least two paths need to be passed.

              Note: This even works for directories and also in combination with paranoid  mode  (pass  <b>-pp</b>  for
              byte  comparison);  remember that rmlint does not care about the layout of the directory, but only
              about the content of the files in it. At least two paths need to be given to the commandline.

              By default this will use hashing to compare the files and/or directories.

       <b>rmlint</b> <b>--dedupe</b> <b>[-r]</b> <b>[-v|-V]</b> <b>&lt;src&gt;</b> <b>&lt;dest&gt;</b>
              If the filesystem supports files sharing physical storage between multiple files, and if  <b>src</b>  and
              <b>dest</b>  have  same  content,  this  command  makes  the data in the <b>src</b> file appear the <b>dest</b> file by
              sharing the underlying storage.

              This command is similar to <b>cp</b> <b>--reflink=always</b> <b>&lt;src&gt;</b> <b>&lt;dest&gt;</b> except that it (a) checks that <b>src</b> and
              <b>dest</b> have identical data, and it makes no changes to <b>dest</b>'s metadata.

              Running with <b>-r</b> option will enable deduplication of read-only [btrfs] snapshots (requires root).

       <b>rmlint</b> <b>--is-reflink</b> <b>[-v|-V]</b> <b>&lt;file1&gt;</b> <b>&lt;file2&gt;</b>
              Tests whether <b>file1</b> and <b>file2</b> are reflinks (reference same data).  This command makes <b>rmlint</b>  exit
              with one of the following exit codes:

              • 0: files are reflinks

              • 1: files are not reflinks

              • 3: not a regular file

              • 4: file sizes differ

              • 5: fiemaps can't be read

              • 6: file1 and file2 are the same path

              • 7: file1 and file2 are the same file under different mountpoints

              • 8: files are hardlinks

              • 9: files are symlinks

              • 10: files are not on same device

              • 11: other error encountered

   <b>EXAMPLES</b>
       This is a collection of common use cases and other tricks:

       • Check the current working directory for duplicates.

         <b>$</b> <b>rmlint</b>

       • Show a progressbar:

         <b>$</b> <b>rmlint</b> <b>-g</b>

       • Quick re-run on large datasets using different ranking criteria on second run:

         <b>$</b> <b>rmlint</b> <b>large_dir/</b> <b>#</b> <b>First</b> <b>run;</b> <b>writes</b> <b>rmlint.json</b>

         <b>$</b> <b>rmlint</b> <b>--replay</b> <b>rmlint.json</b> <b>large_dir</b> <b>-S</b> <b>MaD</b>

       • Merge  together  previous  runs, but prefer the originals to be from <b>b.json</b> and make sure that no files
         are deleted from <b>b.json</b>:

         <b>$</b> <b>rmlint</b> <b>--replay</b> <b>a.json</b> <b>//</b> <b>b.json</b> <b>-k</b>

       • Search only for duplicates and duplicate directories

         <b>$</b> <b>rmlint</b> <b>-T</b> <b>"df,dd"</b> <b>.</b>

       • Compare files byte-by-byte in current directory:

         <b>$</b> <b>rmlint</b> <b>-pp</b> <b>.</b>

       • Find duplicates with same basename (excluding extension):

         <b>$</b> <b>rmlint</b> <b>-e</b>

       • Do more complex traversal using <b><a href="../man1/find.1.html">find</a>(1)</b>.

         <b>$</b> <b>find</b> <b><a href="file:/usr/lib">/usr/lib</a></b> <b>-iname</b> <b>'*.so'</b> <b>-type</b> <b>f</b> <b>|</b> <b>rmlint</b> <b>-</b> <b>#</b> <b>find</b> <b>all</b> <b>duplicate</b> <b>.so</b> <b>files</b>

         <b>$</b> <b>find</b> <b><a href="file:/usr/lib">/usr/lib</a></b> <b>-iname</b> <b>'*.so'</b> <b>-type</b> <b>f</b> <b>-print0</b> <b>|</b> <b>rmlint</b> <b>-0</b> <b>#</b> <b>as</b> <b>above</b> <b>but</b> <b>handles</b> <b>filenames</b> <b>with</b> <b>newline</b>
         <b>character</b> <b>in</b> <b>them</b>

         <b>$</b> <b>find</b> <b><a href="file:~/pics">~/pics</a></b> <b>-iname</b> <b>'*.png'</b> <b>|</b> <b>./rmlint</b> <b>-</b> <b>#</b> <b>compare</b> <b>png</b> <b>files</b> <b>only</b>

       • Limit file size range to investigate:

         <b>$</b> <b>rmlint</b> <b>-s</b> <b>2GB</b>    <b>#</b> <b>Find</b> <b>everything</b> <b>&gt;=</b> <b>2GB</b>

         <b>$</b> <b>rmlint</b> <b>-s</b> <b>0-2GB</b>  <b>#</b> <b>Find</b> <b>everything</b> <b>&lt;</b>  <b>2GB</b>

       • Only find writable and executable files:

         <b>$</b> <b>rmlint</b> <b>--perms</b> <b>wx</b>

       • Reflink if possible, else hardlink duplicates to original if possible, else replace  duplicate  with  a
         symbolic link:

         <b>$</b> <b>rmlint</b> <b>-c</b> <b>sh:link</b>

       • Inject user-defined command into shell script output:

         <b>$</b> <b>rmlint</b> <b>-o</b> <b>sh</b> <b>-c</b> <b>sh:cmd='echo</b> <b>"original:"</b> <b>"$2"</b> <b>"is</b> <b>the</b> <b>same</b> <b>as"</b> <b>"$1"'</b>

       • Use <b>shred</b> to overwrite the contents of a file fully:

         <b>$</b> <b>rmlint</b> <b>-c</b> <b>'sh:cmd=shred</b> <b>-un</b> <b>10</b> <b>"$1"'</b>

       • Use  <u>data</u>  as master directory. Find <b>only</b> duplicates in <u>backup</u> that are also in <u>data</u>. Do not delete any
         files in <u>data</u>:

         <b>$</b> <b>rmlint</b> <b>backup</b> <b>//</b> <b>data</b> <b>--keep-all-tagged</b> <b>--must-match-tagged</b>

       • Compare if the directories a b c and are equal

         <b>$</b> <b>rmlint</b> <b>--equal</b> <b>a</b> <b>b</b> <b>c</b> <b>&amp;&amp;</b> <b>echo</b> <b>"Files</b> <b>are</b> <b>equal"</b> <b>||</b> <b>echo</b> <b>"Files</b> <b>are</b> <b>not</b> <b>equal"</b>

       • Test if two files are reflinks

         <b>$</b> <b>rmlint</b> <b>--is-reflink</b> <b>a</b> <b>b</b> <b>&amp;&amp;</b> <b>echo</b> <b>"Files</b> <b>are</b> <b>reflinks"</b> <b>||</b> <b>echo</b> <b>"Files</b> <b>are</b> <b>not</b> <b>reflinks"</b>.

       • Cache calculated checksums for next run. The checksums will be written to the extended file attributes:

         <b>$</b> <b>rmlint</b> <b>--xattr</b>

       • Produce a list of unique files in a folder:

         <b>$</b> <b>rmlint</b> <b>-o</b> <b>uniques</b>

       • Produce a list of files that are unique, including original files ("one of each"):

         <b>$</b> <b>rmlint</b> <b>t</b> <b>-o</b> <b>json</b> <b>-o</b> <b>uniques:unique_files</b> <b>|</b>  <b>jq</b> <b>-r</b> <b>'.[1:-1][]</b> <b>|</b> <b>select(.is_original)</b> <b>|</b> <b>.path'</b> <b>|</b> <b>sort</b> <b>&gt;</b>
         <b>original_files</b> <b>$</b> <b>cat</b> <b>unique_files</b> <b>original_files</b>

       • Sort files by a user-defined regular expression

                # Always keep files with ABC or DEF in their basename,
                # dismiss all duplicates with tmp, temp or cache in their names
                # and if none of those are applicable, keep the oldest files instead.
                $ ./rmlint -S 'x&lt;.*(ABC|DEF).*&gt;X&lt;.*(tmp|temp|cache).*&gt;m' /some/path

       • Sort files by adding priorities to several user-defined regular expressions:

                # Unlike the previous snippet, this one uses priorities:
                # Always keep files in ABC, DEF, GHI by following that particular order of
                # importance (ABC has a top priority), dismiss all duplicates with
                # tmp, temp, cache in their paths and if none of those are applicable,
                # keep the oldest files instead.
                $ rmlint -S 'r&lt;.*ABC.*&gt;r&lt;.*DEF.*&gt;r&lt;.*GHI.*&gt;R&lt;.*(tmp|temp|cache).*&gt;m' /some/path

   <b>PROBLEMS</b>
       1. <b>False</b> <b>Positives:</b> Depending on the options you use, there is a very  slight  risk  of  false  positives
          (files  that are erroneously detected as duplicate).  The default hash function (blake2b) is very safe
          but in theory it is possible for two files to have then same hash. If you had 10^73  different  files,
          all  the  same size, then the chance of a false positive is still less than 1 in a billion.  If you're
          concerned just use the <b>--paranoid</b> (<b>-pp</b>) option. This will compare all the files  byte-by-byte  and  is
          not much slower than blake2b (it may even be faster), although it is a lot more memory-hungry.

       2. <b>File</b>  <b>modification</b>  <b>during</b>  <b>or</b>  <b>after</b> <b>rmlint</b> <b>run:</b> It is possible that a file that <b>rmlint</b> recognized as
          duplicate is modified afterwards, resulting in a different file.   If  you  use  the  rmlint-generated
          shell  script to delete the duplicates, you can run it with the <b>-p</b> option to do a full re-check of the
          duplicate against the original before it deletes the file. When using <b>-c</b> <b>sh:hardlink</b> or <b>-c</b>  <b>sh:symlink</b>
          care  should  be taken that a modification of one file will now result in a modification of all files.
          This is not the case for <b>-c</b> <b>sh:reflink</b> or <b>-c</b> <b>sh:clone</b>. Use <b>-c</b> <b>sh:link</b> to minimise this risk.

   <b>SEE</b> <b>ALSO</b>
       Reading the manpages of these tools might help working with <b>rmlint</b>:

       • <u><a href="../man1/find.1.html">find</a>(1)</u>

       • <u><a href="../man1/rm.1.html">rm</a>(1)</u>

       • <u><a href="../man1/cp.1.html">cp</a>(1)</u>

       Extended documentation and an in-depth tutorial can be found at:

       • <u><a href="http://rmlint.rtfd.org">http://rmlint.rtfd.org</a></u>

   <b>BUGS</b>
       If  you  found  a  bug,  have  a  feature  requests  or  want  to  say  something  nice,   please   visit
       <u>https://github.com/sahib/rmlint/issues</u>.

       Please make sure to describe your problem in detail. Always include the version of <b>rmlint</b> (<b>--version</b>). If
       you  experienced  a crash, please include at least one of the following information with a debug build of
       <b>rmlint</b>:

       • <b>gdb</b> <b>--ex</b> <b>run</b> <b>-ex</b> <b>bt</b> <b>--args</b> <b>rmlint</b> <b>-vvv</b> <b>[your_options]</b>

       • <b>valgrind</b> <b>--leak-check=no</b> <b>rmlint</b> <b>-vvv</b> <b>[your_options]</b>

       You can build a debug build of <b>rmlint</b> like this:

       • <b>git</b> <b>clone</b> <b><a href="mailto:git@github.com">git@github.com</a>:sahib/rmlint.git</b>

       • <b>cd</b> <b>rmlint</b>

       • <b>scons</b> <b>GDB=1</b> <b>DEBUG=1</b>

       • <b>sudo</b> <b>scons</b> <b>install</b>  <b>#</b> <b>Optional</b>

   <b>LICENSE</b>
       <b>rmlint</b> is licensed under the terms of the GPLv3.

       See the COPYRIGHT file that came with the source for more information.

   <b>PROGRAM</b> <b>AUTHORS</b>
       <b>rmlint</b> was written by:

       • Christopher &lt;sahib&gt; Pahl 2010-2017 (<u>https://github.com/sahib</u>)

       • Daniel &lt;SeeSpotRun&gt; T.   2014-2017 (<u>https://github.com/SeeSpotRun</u>)

       Also see the  <u><a href="http://rmlint.rtfd.org">http://rmlint.rtfd.org</a></u> for other people that helped us.

</pre><h4><b>AUTHOR</b></h4><pre>
       Christopher Pahl, Daniel Thomas

</pre><h4><b>COPYRIGHT</b></h4><pre>
       2014-2024, Christopher Pahl &amp; Daniel Thomas

                                                  May 28, 2024                                         <u><a href="../man1/RMLINT.1.html">RMLINT</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>