<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>httrack - offline browser : copy websites to a local directory</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/httrack">httrack_3.49.6-1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       httrack - offline browser : copy websites to a local directory

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>httrack</b>  <b>[</b> <b>url</b> <b>]...</b> <b>[</b> <b>-filter</b> <b>]...</b> <b>[</b> <b>+filter</b> <b>]...</b> <b>[</b> <b>-O,</b> <b>--path</b> ] [ <b>-w,</b> <b>--mirror</b> ] [ <b>-W,</b> <b>--mirror-wizard</b> ]
       [ <b>-g,</b> <b>--get-files</b> ] [ <b>-i,</b> <b>--continue</b> ] [ <b>-Y,</b> <b>--mirrorlinks</b> ] [ <b>-P,</b> <b>--proxy</b> ] [ <b>-%f,</b> <b>--httpproxy-ftp[=N]</b> ]
       [ <b>-%b,</b> <b>--bind</b> ] [ <b>-rN,</b> <b>--depth[=N]</b>  ]  [  <b>-%eN,</b>  <b>--ext-depth[=N]</b>  ]  [  <b>-mN,</b>  <b>--max-files[=N]</b>  ]  [  <b>-MN,</b>
       <b>--max-size[=N]</b>  ] [ <b>-EN,</b> <b>--max-time[=N]</b> ] [ <b>-AN,</b> <b>--max-rate[=N]</b> ] [ <b>-%cN,</b> <b>--connection-per-second[=N]</b> ] [
       <b>-GN,</b> <b>--max-pause[=N]</b> ] [ <b>-cN,</b> <b>--sockets[=N]</b> ] [ <b>-TN,</b> <b>--timeout[=N]</b>  ]  [  <b>-RN,</b>  <b>--retries[=N]</b>  ]  [  <b>-JN,</b>
       <b>--min-rate[=N]</b>  ] [ <b>-HN,</b> <b>--host-control[=N]</b> ] [ <b>-%P,</b> <b>--extended-parsing[=N]</b> ] [ <b>-n,</b> <b>--near</b> ] [ <b>-t,</b> <b>--test</b>
       ] [ <b>-%L,</b> <b>--list</b> ] [ <b>-%S,</b> <b>--urllist</b> ] [ <b>-NN,</b> <b>--structure[=N]</b> ] [ <b>-%D,</b> <b>--cached-delayed-type-check</b> ] [ <b>-%M,</b>
       <b>--mime-html</b> ] [ <b>-LN,</b> <b>--long-names[=N]</b> ] [ <b>-KN,</b> <b>--keep-links[=N]</b> ]  [  <b>-x,</b>  <b>--replace-external</b>  ]  [  <b>-%x,</b>
       <b>--disable-passwords</b> ] [ <b>-%q,</b> <b>--include-query-string</b> ] [ <b>-o,</b> <b>--generate-errors</b> ] [ <b>-X,</b> <b>--purge-old[=N]</b> ] [
       <b>-%p,</b>  <b>--preserve</b>  ]  [  <b>-%T,</b>  <b>--utf8-conversion</b>  ]  [ <b>-bN,</b> <b>--cookies[=N]</b> ] [ <b>-u,</b> <b>--check-type[=N]</b> ] [ <b>-j,</b>
       <b>--parse-java[=N]</b> ] [ <b>-sN,</b> <b>--robots[=N]</b> ] [ <b>-%h,</b> <b>--http-10</b> ] [ <b>-%k,</b> <b>--keep-alive</b> ] [ <b>-%B,</b> <b>--tolerant</b>  ]  [
       <b>-%s,</b> <b>--updatehack</b> ] [ <b>-%u,</b> <b>--urlhack</b> ] [ <b>-%A,</b> <b>--assume</b> ] [ <b>-@iN,</b> <b>--protocol[=N]</b> ] [ <b>-%w,</b> <b>--disable-module</b>
       ]  [  <b>-F,</b>  <b>--user-agent</b> ] [ <b>-%R,</b> <b>--referer</b> ] [ <b>-%E,</b> <b>--from</b> ] [ <b>-%F,</b> <b>--footer</b> ] [ <b>-%l,</b> <b>--language</b> ] [ <b>-%a,</b>
       <b>--accept</b> ] [ <b>-%X,</b> <b>--headers</b> ] [ <b>-C,</b> <b>--cache[=N]</b> ] [ <b>-k,</b> <b>--store-all-in-cache</b> ] [ <b>-%n,</b> <b>--do-not-recatch</b>  ]
       [  <b>-%v,</b>  <b>--display</b>  ]  [ <b>-Q,</b> <b>--do-not-log</b> ] [ <b>-q,</b> <b>--quiet</b> ] [ <b>-z,</b> <b>--extra-log</b> ] [ <b>-Z,</b> <b>--debug-log</b> ] [ <b>-v,</b>
       <b>--verbose</b> ] [ <b>-f,</b> <b>--file-log</b> ] [ <b>-f2,</b> <b>--single-log</b> ] [ <b>-I,</b> <b>--index</b> ] [ <b>-%i,</b> <b>--build-top-index</b>  ]  [  <b>-%I,</b>
       <b>--search-index</b>  ]  [  <b>-pN,</b>  <b>--priority[=N]</b>  ]  [  <b>-S,</b>  <b>--stay-on-same-dir</b>  ]  [ <b>-D,</b> <b>--can-go-down</b> ] [ <b>-U,</b>
       <b>--can-go-up</b> ] [ <b>-B,</b> <b>--can-go-up-and-down</b> ] [ <b>-a,</b> <b>--stay-on-same-address</b> ] [ <b>-d,</b> <b>--stay-on-same-domain</b> ] [
       <b>-l,</b>   <b>--stay-on-same-tld</b>   ]   [   <b>-e,</b>   <b>--go-everywhere</b>   ]   [   <b>-%H,</b>   <b>--debug-headers</b>   ]   [    <b>-%!,</b>
       <b>--disable-security-limits</b> ] [ <b>-V,</b> <b>--userdef-cmd</b> ] [ <b>-%W,</b> <b>--callback</b> ] [ <b>-K,</b> <b>--keep-links[=N]</b> ] [

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <b>httrack</b>  allows  you  to  download a World Wide Web site from the Internet to a local directory, building
       recursively all directories, getting HTML, images, and other files from  the  server  to  your  computer.
       HTTrack  arranges  the  original  site's  relative  link-structure.  Simply open a page of the "mirrored"
       website in your browser, and you can browse the site from link to link, as if you were viewing it online.
       HTTrack can also update an existing mirrored site, and resume interrupted downloads.

</pre><h4><b>EXAMPLES</b></h4><pre>
       <b>httrack</b> <b>www.someweb.com/bob/</b>
               mirror site www.someweb.com/bob/ and only this site

       <b>httrack</b> <b>www.someweb.com/bob/</b> <b>www.anothertest.com/mike/</b> <b>+*.com/*.jpg</b> <b>-mime:application/*</b>
               mirror the two sites together (with shared links) and accept any .jpg files on .com sites

       <b>httrack</b> <b>www.someweb.com/bob/bobby.html</b> <b>+*</b> <b>-r6</b>
              means get all files starting  from  bobby.html,  with  6  link-depth,  and  possibility  of  going
              everywhere on the web

       <b>httrack</b> <b>www.someweb.com/bob/bobby.html</b> <b>--spider</b> <b>-P</b> <b>proxy.myhost.com:8080</b>
              runs the spider on www.someweb.com/bob/bobby.html using a proxy

       <b>httrack</b> <b>--update</b>
              updates a mirror in the current folder

       <b>httrack</b>
              will bring you to the interactive mode

       <b>httrack</b> <b>--continue</b>
              continues a mirror in the current folder

</pre><h4><b>OPTIONS</b></h4><pre>
   <b>General</b> <b>options:</b>
       -O     path for mirror/logfiles+cache (-O path mirror[,path cache and logfiles]) (--path &lt;param&gt;)

   <b>Action</b> <b>options:</b>
       -w     *mirror web sites (--mirror)

       -W     mirror web sites, semi-automatic (asks questions) (--mirror-wizard)

       -g     just get files (saved in the current directory) (--get-files)

       -i     continue an interrupted mirror using the cache (--continue)

       -Y     mirror ALL links located in the first level pages (mirror links) (--mirrorlinks)

   <b>Proxy</b> <b>options:</b>
       -P     proxy use (-P proxy:port or -P user:pass@proxy:port) (--proxy &lt;param&gt;)

       -%f    *use proxy for ftp (f0 don t use) (--httpproxy-ftp[=N])

       -%b    use this local hostname to make/send requests (-%b hostname) (--bind &lt;param&gt;)

   <b>Limits</b> <b>options:</b>
       -rN    set the mirror depth to N (* r9999) (--depth[=N])

       -%eN   set the external links depth to N (* %e0) (--ext-depth[=N])

       -mN    maximum file length for a non-html file (--max-files[=N])

       -mN,N2 maximum file length for non html (N) and html (N2)

       -MN    maximum overall size that can be uploaded/scanned (--max-size[=N])

       -EN    maximum mirror time in seconds (60=1 minute, 3600=1 hour) (--max-time[=N])

       -AN    maximum transfer rate in bytes/seconds (1000=1KB/s max) (--max-rate[=N])

       -%cN   maximum number of connections/seconds (*%c10) (--connection-per-second[=N])

       -GN    pause transfer if N bytes reached, and wait until lock file is deleted (--max-pause[=N])

   <b>Flow</b> <b>control:</b>
       -cN    number of multiple connections (*c8) (--sockets[=N])

       -TN    timeout, number of seconds after a non-responding link is shutdown (--timeout[=N])

       -RN    number of retries, in case of timeout or non-fatal errors (*R1) (--retries[=N])

       -JN    traffic jam control, minimum transfert rate (bytes/seconds) tolerated for a link (--min-rate[=N])

       -HN    host is abandoned if: 0=never, 1=timeout, 2=slow, 3=timeout or slow (--host-control[=N])

   <b>Links</b> <b>options:</b>
       -%P    *extended  parsing, attempt to parse all links, even in unknown tags or Javascript (%P0 don t use)
              (--extended-parsing[=N])

       -n     get non-html files  near  an html file (ex: an image located outside) (--near)

       -t     test all URLs (even forbidden ones) (--test)

       -%L    &lt;file&gt; add all URL located in this text file (one URL per line) (--list &lt;param&gt;)

       -%S    &lt;file&gt; add all scan rules located in this text file (one scan rule per line) (--urllist &lt;param&gt;)

   <b>Build</b> <b>options:</b>
       -NN    structure type (0 *original structure, 1+: see below) (--structure[=N])

       -or    user defined structure (-N "%h%p/%n%q.%t")

       -%N    delayed type check, don t make any link  test  but  wait  for  files  download  to  start  instead
              (experimental) (%N0 don t use, %N1 use for unknown extensions, * %N2 always use)

       -%D    cached delayed type check, don t wait for remote type during updates, to speedup them (%D0 wait, *
              %D1 don t wait) (--cached-delayed-type-check)

       -%M    generate a RFC MIME-encapsulated full-archive (.mht) (--mime-html)

       -LN    long names (L1 *long names / L0 8-3 conversion / L2 ISO9660 compatible) (--long-names[=N])

       -KN    keep  original  links (e.g. <a href="http://www.adr/link">http://www.adr/link</a>) (K0 *relative link, K absolute links, K4 original
              links, K3 absolute URI links, K5 transparent proxy link) (--keep-links[=N])

       -x     replace external html links by error pages (--replace-external)

       -%x    do  not  include  any  password  for  external   password   protected   websites   (%x0   include)
              (--disable-passwords)

       -%q    *include  query string for local files (useless, for information purpose only) (%q0 don t include)
              (--include-query-string)

       -o     *generate output html file in case of error (404..) (o0 don t generate) (--generate-errors)

       -X     *purge old files after update (X0 keep delete) (--purge-old[=N])

       -%p    preserve html files  as is  (identical to  -K4 -%F "" ) (--preserve)

       -%T    links conversion to UTF-8 (--utf8-conversion)

   <b>Spider</b> <b>options:</b>
       -bN    accept cookies in cookies.txt (0=do not accept,* 1=accept) (--cookies[=N])

       -u     check document type if unknown (cgi,asp..) (u0 don t check, * u1 check but  /,  u2  check  always)
              (--check-type[=N])

       -j     *parse  Java  Classes  (j0  don t parse, bitmask: |1 parse default, |2 don t parse .class |4 don t
              parse .js |8 don t be aggressive) (--parse-java[=N])

       -sN    follow robots.txt and meta robots tags  (0=never,1=sometimes,*  2=always,  3=always  (even  strict
              rules)) (--robots[=N])

       -%h    force HTTP/1.0 requests (reduce update features, only for old servers or proxies) (--http-10)

       -%k    use keep-alive if possible, greately reducing latency for small files and test requests (%k0 don t
              use) (--keep-alive)

       -%B    tolerant requests (accept bogus responses on some servers, but not standard!) (--tolerant)

       -%s    update hacks: various hacks to limit re-transfers when updating (identical size, bogus response..)
              (--updatehack)

       -%u    url hacks: various hacks to limit duplicate URLs (strip //, www.foo.com==foo.com..) (--urlhack)

       -%A    assume    that    a    type    (cgi,asp..)    is   always   linked   with   a   mime   type   (-%A
              php3,cgi=text/html;dat,bin=application/x-zip) (--assume &lt;param&gt;)

       -can   also be used to force a specific file type: --assume foo.cgi=text/html

       -@iN   internet protocol (0=both ipv6+ipv4, 4=ipv4 only, 6=ipv6 only) (--protocol[=N])

       -%w    disable a specific external mime module (-%w htsswf -%w htsjava) (--disable-module &lt;param&gt;)

   <b>Browser</b> <b>ID:</b>
       -F     user-agent field sent in HTTP headers (-F "user-agent name") (--user-agent &lt;param&gt;)

       -%R    default referer field sent in HTTP headers (--referer &lt;param&gt;)

       -%E    from email address sent in HTTP headers (--from &lt;param&gt;)

       -%F    footer string in Html code (-%F "Mirrored [from host %s [file %s [at %s]]]" (--footer &lt;param&gt;)

       -%l    preffered language (-%l "fr, en, jp, *" (--language &lt;param&gt;)

       -%a    accepted formats (-%a "text/html,image/png;q=0.9,*/*;q=0.1" (--accept &lt;param&gt;)

       -%X    additional HTTP header line (-%X "X-Magic: 42" (--headers &lt;param&gt;)

   <b>Log,</b> <b>index,</b> <b>cache</b>
       -C     create/use a cache for updates and retries (C0 no cache,C1 cache is prioritary,*  C2  test  update
              before) (--cache[=N])

       -k     store all files in cache (not useful if files on disk) (--store-all-in-cache)

       -%n    do not re-download locally erased files (--do-not-recatch)

       -%v    display  on  screen  filenames downloaded (in realtime) - * %v1 short version - %v2 full animation
              (--display)

       -Q     no log - quiet mode (--do-not-log)

       -q     no questions - quiet mode (--quiet)

       -z     log - extra infos (--extra-log)

       -Z     log - debug (--debug-log)

       -v     log on screen (--verbose)

       -f     *log in files (--file-log)

       -f2    one single log file (--single-log)

       -I     *make an index (I0 don t make) (--index)

       -%i    make a top index for a project folder (* %i0 don t make) (--build-top-index)

       -%I    make an searchable index for this mirror (* %I0 don t make) (--search-index)

   <b>Expert</b> <b>options:</b>
       -pN    priority mode: (* p3) (--priority[=N])

       -p0    just scan, don t save anything (for checking links)

       -p1    save only html files

       -p2    save only non html files

       -*p3   save all files

       -p7    get html files before, then treat other files

       -S     stay on the same directory (--stay-on-same-dir)

       -D     *can only go down into subdirs (--can-go-down)

       -U     can only go to upper directories (--can-go-up)

       -B     can both go up&amp;down into the directory structure (--can-go-up-and-down)

       -a     *stay on the same address (--stay-on-same-address)

       -d     stay on the same principal domain (--stay-on-same-domain)

       -l     stay on the same TLD (eg: .com) (--stay-on-same-tld)

       -e     go everywhere on the web (--go-everywhere)

       -%H    debug HTTP headers in logfile (--debug-headers)

   <b>Guru</b> <b>options:</b> <b>(do</b> <b>NOT</b> <b>use</b> <b>if</b> <b>possible)</b>
       -#X    *use optimized engine (limited memory boundary checks) (--fast-engine)

       -#0    filter test (-#0  *.gif   www.bar.com/foo.gif ) (--debug-testfilters &lt;param&gt;)

       -#1    simplify test (-#1 ./foo/bar/../foobar)

       -#2    type test (-#2 /foo/bar.php)

       -#C    cache list (-#C  *.com/spider*.gif  (--debug-cache &lt;param&gt;)

       -#R    cache repair (damaged cache) (--repair-cache)

       -#d    debug parser (--debug-parsing)

       -#E    extract new.zip cache meta-data in meta.zip

       -#f    always flush log files (--advanced-flushlogs)

       -#FN   maximum number of filters (--advanced-maxfilters[=N])

       -#h    version info (--version)

       -#K    scan stdin (debug) (--debug-scanstdin)

       -#L    maximum number of links (-#L1000000) (--advanced-maxlinks[=N])

       -#p    display ugly progress information (--advanced-progressinfo)

       -#P    catch URL (--catch-url)

       -#R    old FTP routines (debug) (--repair-cache)

       -#T    generate transfer ops. log every minutes (--debug-xfrstats)

       -#u    wait time (--advanced-wait)

       -#Z    generate transfer rate statistics every minutes (--debug-ratestats)

   <b>Dangerous</b> <b>options:</b> <b>(do</b> <b>NOT</b> <b>use</b> <b>unless</b> <b>you</b> <b>exactly</b> <b>know</b> <b>what</b> <b>you</b> <b>are</b> <b>doing)</b>
       -%!    bypass  built-in  security  limits  aimed  to  avoid  bandwidth  abuses  (bandwidth,  simultaneous
              connections) (--disable-security-limits)

       -IMPORTANT
              NOTE: DANGEROUS OPTION, ONLY SUITABLE FOR EXPERTS

       -USE   IT WITH EXTREME CARE

   <b>Command-line</b> <b>specific</b> <b>options:</b>
       -V     execute system command after each files ($0 is the filename: -V "rm \$0") (--userdef-cmd &lt;param&gt;)

       -%W    use an external library function as a wrapper (-%W myfoo.so[,myparameters]) (--callback &lt;param&gt;)

   <b>Details:</b> <b>Option</b> <b>N</b>
       -N0    Site-structure (default)

       -N1    HTML in web/, images/other files in web/images/

       -N2    HTML in web/HTML, images/other in web/images

       -N3    HTML in web/,  images/other in web/

       -N4    HTML  in  web/,  images/other  in web/xxx, where xxx is the file extension (all gif will be placed
              onto web/gif, for example)

       -N5    Images/other in web/xxx and HTML in web/HTML

       -N99   All files in web/, with random names (gadget !)

       -N100  Site-structure, without www.domain.xxx/

       -N101  Identical to N1 except that "web" is replaced by the site s name

       -N102  Identical to N2 except that "web" is replaced by the site s name

       -N103  Identical to N3 except that "web" is replaced by the site s name

       -N104  Identical to N4 except that "web" is replaced by the site s name

       -N105  Identical to N5 except that "web" is replaced by the site s name

       -N199  Identical to N99 except that "web" is replaced by the site s name

       -N1001 Identical to N1 except that there is no "web" directory

       -N1002 Identical to N2 except that there is no "web" directory

       -N1003 Identical to N3 except that there is no "web" directory (option set for g option)

       -N1004 Identical to N4 except that there is no "web" directory

       -N1005 Identical to N5 except that there is no "web" directory

       -N1099 Identical to N99 except that there is no "web" directory

   <b>Details:</b> <b>User-defined</b> <b>option</b> <b>N</b>
          %n  Name of file without file type (ex: image)
          %N  Name of file, including file type (ex: image.gif)
          %t  File type (ex: gif)
          %p  Path [without ending /] (ex: /someimages)
          %h  Host name (ex: www.someweb.com)
          %M  URL MD5 (128 bits, 32 ascii bytes)
          %Q  query string MD5 (128 bits, 32 ascii bytes)
          %k  full query string
          %r  protocol name (ex: http)
          %q  small query string MD5 (16 bits, 4 ascii bytes)
             %s?  Short name version (ex: %sN)
          %[param]  param variable in query string
          %[param:before:after:empty:notfound]  advanced variable extraction

   <b>Details:</b> <b>User-defined</b> <b>option</b> <b>N</b> <b>and</b> <b>advanced</b> <b>variable</b> <b>extraction</b>
          %[param:before:after:empty:notfound]

       -param : parameter name

       -before
              : string to prepend if the parameter was found

       -after : string to append if the parameter was found

       -notfound
              : string replacement if the parameter could not be found

       -empty : string replacement if the parameter was empty

       -all   fields, except the first one (the parameter name), can be empty

   <b>Details:</b> <b>Option</b> <b>K</b>
       -K0    foo.cgi?q=45  -&gt;  foo4B54.html?q=45 (relative URI, default)

       -K     -&gt;  <a href="http://www.foobar.com/folder/foo.cgi">http://www.foobar.com/folder/foo.cgi</a>?q=45 (absolute URL) (--keep-links[=N])

       -K3    -&gt;  /folder/foo.cgi?q=45 (absolute URI)

       -K4    -&gt;  foo.cgi?q=45 (original URL)

       -K5    -&gt;  <a href="http://www.foobar.com/folder/foo4B54.html">http://www.foobar.com/folder/foo4B54.html</a>?q=45 (transparent proxy URL)

   <b>Shortcuts:</b>
       --mirror
                   &lt;URLs&gt; *make a mirror of site(s) (default)

       --get
                      &lt;URLs&gt;  get the files indicated, do not seek other URLs (-qg)

       --list
                &lt;text file&gt;  add all URL located in this text file (-%L)

       --mirrorlinks
              &lt;URLs&gt;  mirror all links in 1st level pages (-Y)

       --testlinks
                &lt;URLs&gt;  test links in pages (-r1p0C0I0t)

       --spider
                   &lt;URLs&gt;  spider site(s), to test links: reports Errors &amp; Warnings (-p0C0I0t)

       --testsite
                 &lt;URLs&gt;  identical to --spider

       --skeleton
                 &lt;URLs&gt;  make a mirror, but gets only html files (-p1)

       --update
                           update a mirror, without confirmation (-iC2)

       --continue
                         continue a mirror, without confirmation (-iC1)

       --catchurl
                         create a temporary proxy to capture an URL or a form post URL

       --clean
                            erase cache &amp; log files

       --http10
                           force http/1.0 requests (-%h)

   <b>Details:</b> <b>Option</b> <b>%W:</b> <b>External</b> <b>callbacks</b> <b>prototypes</b>
   <b>see</b> <b>htsdefines.h</b>
</pre><h4><b>FILES</b></h4><pre>
       <u>/etc/httrack.conf</u>
              The system wide configuration file.

</pre><h4><b>ENVIRONMENT</b></h4><pre>
       HOME   Is being used if you defined in /etc/httrack.conf the line <u>path</u> <u><a href="file:~/websites/">~/websites/</a>#</u>

</pre><h4><b>DIAGNOSTICS</b></h4><pre>
       Errors/Warnings are reported to <u>hts-log.txt</u> by default, or to stderr if the <u>-v</u> option was specified.

</pre><h4><b>LIMITS</b></h4><pre>
       These are the principals limits of HTTrack for that moment. Note that we did not heard  about  any  other
       utility that would have solved them.

       - Several scripts generating complex filenames may not find them (ex: img.src='image'+a+Mobj.dst+'.gif')

       - Some java classes may not find some files on them (class included)

       -  Cgi-bin links may not work properly in some cases (parameters needed). To avoid them: use filters like
       -*cgi-bin*

</pre><h4><b>BUGS</b></h4><pre>
       Please reports bugs to <b>&lt;<a href="mailto:bugs@httrack.com">bugs@httrack.com</a>&gt;.</b>  Include a complete, self-contained example  that  will  allow
       the bug to be reproduced, and say which version of httrack you are using. Do not forget to detail options
       used, OS version, and any other information you deem necessary.

</pre><h4><b>COPYRIGHT</b></h4><pre>
       Copyright (C) 1998-2024 Xavier Roche and other contributors

       This  program  is  free  software:  you  can  redistribute it and/or modify it under the terms of the GNU
       General Public License as published by the Free Software Foundation, either version 3 of the License,  or
       (at your option) any later version.

       This  program  is  distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even
       the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General  Public
       License for more details.

       You  should  have  received a copy of the GNU General Public License along with this program. If not, see
       &lt;<a href="http://www.gnu.org/licenses/">http://www.gnu.org/licenses/</a>&gt;.

</pre><h4><b>AVAILABILITY</b></h4><pre>
       The  most  recent released version of httrack can be found at: <b><a href="http://www.httrack.com">http://www.httrack.com</a></b>

</pre><h4><b>AUTHOR</b></h4><pre>
       Xavier Roche &lt;<a href="mailto:roche@httrack.com">roche@httrack.com</a>&gt;

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       The <b>HTML</b> documentation  (available  online  at  <b><a href="http://www.httrack.com/html/">http://www.httrack.com/html/</a></b>  )  contains  more  detailed
       information.     Please     also     refer     to     the    <b>httrack</b>    <b>FAQ</b>    (available    online    at
       <b><a href="http://www.httrack.com/html/faq.html">http://www.httrack.com/html/faq.html</a></b> )

httrack website copier                           27 January 2024                                      <u><a href="../man1/httrack.1.html">httrack</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>