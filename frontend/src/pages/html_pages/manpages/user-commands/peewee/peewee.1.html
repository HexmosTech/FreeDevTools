<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>peewee - peewee Documentation [image]</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/peewee">peewee_3.17.7+dfsg-1build2_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       peewee - peewee Documentation [image]

       Peewee  is  a  simple  and  small  ORM. It has few (but expressive) concepts, making it easy to learn and
       intuitive to use.

       • a small, expressive ORM

       • python 2.7+ and 3.4+

       • supports sqlite, mysql, mariadb, postgresql and cockroachdb

       • <u>tons</u> <u>of</u> <u>extensions</u>
       <u>postgresqlmysqlmariadbsqlitecockroachdb</u>

       Peewee's source code hosted on <u>GitHub</u>.

       New to peewee? These may help:

       • <u>Quickstart</u>

       • <u>Example</u> <u>twitter</u> <u>app</u>

       • <u>Using</u> <u>peewee</u> <u>interactively</u>

       • <u>Models</u> <u>and</u> <u>fields</u>

       • <u>Querying</u>

       • <u>Relationships</u> <u>and</u> <u>joins</u>

</pre><h4><b>CONTENTS:</b></h4><pre>
   <b>Installing</b> <b>and</b> <b>Testing</b>
       Most users will want to simply install the latest version, hosted on PyPI:

          pip install peewee

       Peewee comes with a couple C extensions that will be built if Cython is available.

       • Sqlite extensions, which includes Cython implementations of the SQLite date manipulation functions, the
         REGEXP operator, and full-text search result ranking algorithms.

   <b>Installing</b> <b>with</b> <b>git</b>
       The project is hosted at <u>https://github.com/coleifer/peewee</u> and can be installed using git:

          git clone https://github.com/coleifer/peewee.git
          cd peewee
          python setup.py install

       <b>NOTE:</b>
          On some systems you may need to use <b>sudo</b> <b>python</b> <b>setup.py</b> <b>install</b> to install peewee system-wide.

       If you would like to build the SQLite extension in a git checkout, you can run:

          # Build the C extension and place shared libraries alongside other modules.
          python setup.py build_ext -i

   <b>Running</b> <b>tests</b>
       You can test your installation by running the test suite.

          python runtests.py

       You can test specific features or specific database drivers using the <b>runtests.py</b>  script.  To  view  the
       available test runner options, use:

          python runtests.py --help

       <b>NOTE:</b>
          To  run tests against Postgres or MySQL you need to create a database named "peewee_test". To test the
          Postgres extension module, you will also want to install the HStore extension  in  the  postgres  test
          database:

              -- install the hstore extension on the peewee_test postgres db.
              CREATE EXTENSION hstore;

   <b>Optional</b> <b>dependencies</b>
       <b>NOTE:</b>
          To  use  Peewee,  you  typically  won't  need anything outside the standard library, since most Python
          distributions are compiled with SQLite support.  You can test by running <b>import</b> <b>sqlite3</b> in the  Python
          console.  If you wish to use another database, there are many DB-API 2.0-compatible drivers out there,
          such as <b>pymysql</b> or <b>psycopg2</b> for MySQL and Postgres respectively.

       • <u>Cython</u>: used to expose additional functionality when using SQLite and to implement things  like  search
         result  ranking  in  a  performant  manner.  Since  the generated C files are included with the package
         distribution, Cython is no longer required to use the C extensions.

       • <u>apsw</u>: an optional 3rd-party SQLite binding offering greater performance and comprehensive  support  for
         SQLite's C APIs. Use with <u>APSWDatabase</u>.

       • <u>gevent</u> is an optional dependency for <b>SqliteQueueDatabase</b> (though it works with <b>threading</b> just fine).

       • <u>BerkeleyDB</u>  can be compiled with a SQLite frontend, which works with Peewee. Compiling can be tricky so
         <u>here</u> <u>are</u> <u>instructions</u>.

       • Lastly, if you use the <u>Flask</u> framework, there are helper extension modules available.

   <b>Note</b> <b>on</b> <b>the</b> <b>SQLite</b> <b>extensions</b>
       Peewee includes two SQLite-specific C extensions which  provide  additional  functionality  and  improved
       performance  for  SQLite  database  users.  Peewee  will attempt to determine ahead-of-time if SQLite3 is
       installed, and only build the SQLite extensions if the SQLite shared-library is available on your system.

       If, however, you receive errors like the following when attempting to install Peewee, you can  explicitly
       disable the compilation of the SQLite C extensions by settings the <b>NO_SQLITE</b> environment variable.

          fatal error: sqlite3.h: No such file or directory

       Here is how to install Peewee with the SQLite extensions explicitly disabled:

          $ NO_SQLITE=1 python setup.py install

   <b>Quickstart</b>
       This document presents a brief, high-level overview of Peewee's primary features. This guide will cover:

       • <u>Model</u> <u>Definition</u>

       • <u>Storing</u> <u>data</u>

       • <u>Retrieving</u> <u>Data</u>

       <b>NOTE:</b>
          If  you'd  like something a bit more meaty, there is a thorough tutorial on <u>creating</u> <u>a</u> <u>"twitter"-style</u>
          <u>web</u> <u>app</u> using peewee and the Flask framework. In the projects  <b>examples/</b>  folder  you  can  find  more
          self-contained Peewee examples, like a <u>blog</u> <u>app</u>.

       I  <b>strongly</b>  recommend  opening an interactive shell session and running the code. That way you can get a
       feel for typing in queries.

   <b>Model</b> <b>Definition</b>
       Model classes, fields and model instances all map to database concepts:
                                     ┌────────────────┬─────────────────────────┐
                                     │ Object         │ Corresponds to...       │
                                     ├────────────────┼─────────────────────────┤
                                     │ Model class    │ Database table          │
                                     ├────────────────┼─────────────────────────┤
                                     │ Field instance │ Column on a table       │
                                     ├────────────────┼─────────────────────────┤
                                     │ Model instance │ Row in a database table │
                                     └────────────────┴─────────────────────────┘

       When starting a project with peewee, it's typically best to begin with your data model, by  defining  one
       or more <u>Model</u> classes:

          from peewee import *

          db = SqliteDatabase('people.db')

          class Person(Model):
              name = CharField()
              birthday = DateField()

              class Meta:
                  database = db # This model uses the "people.db" database.

       <b>NOTE:</b>
          Peewee  will  automatically infer the database table name from the name of the class. You can override
          the default name by specifying a <b>table_name</b>  attribute  in  the  inner  "Meta"  class  (alongside  the
          <b>database</b>  attribute).   To learn more about how Peewee generates table names, refer to the <u>Table</u> <u>Names</u>
          section.

          Also note that we named our model <b>Person</b> instead of <b>People</b>. This is a convention you should follow  --
          even though the table will contain multiple people, we always name the class using the singular form.

       There  are  lots  of  <u>field</u>  <u>types</u>  suitable for storing various types of data. Peewee handles converting
       between <u>pythonic</u> values and those used by the database, so you can use Python types in your code  without
       having to worry.

       Things  get interesting when we set up relationships between models using <u>foreign</u> <u>key</u> <u>relationships</u>. This
       is simple with peewee:

          class Pet(Model):
              owner = ForeignKeyField(Person, backref='pets')
              name = CharField()
              animal_type = CharField()

              class Meta:
                  database = db # this model uses the "people.db" database

       Now that we have our models, let's connect to the database. Although  it's  not  necessary  to  open  the
       connection  explicitly, it is good practice since it will reveal any errors with your database connection
       immediately, as opposed to some arbitrary time later when the first query is executed. It is also good to
       close the connection when you are done -- for instance, a  web  app  might  open  a  connection  when  it
       receives a request, and close the connection when it sends the response.

          db.connect()

       We'll begin by creating the tables in the database that will store our data.  This will create the tables
       with the appropriate columns, indexes, sequences, and foreign key constraints:

          db.create_tables([Person, Pet])

   <b>Storing</b> <b>data</b>
       Let's  begin  by populating the database with some people. We will use the <u>save()</u> and <u>create()</u> methods to
       add and update people's records.

          from datetime import date
          uncle_bob = Person(name='Bob', birthday=date(1960, 1, 15))
          uncle_bob.save() # bob is now stored in the database
          # Returns: 1

       <b>NOTE:</b>
          When you call <u>save()</u>, the number of rows modified is returned.

       You can also add a person by calling the <u>create()</u> method, which returns a model instance:

          grandma = Person.create(name='Grandma', birthday=date(1935, 3, 1))
          herb = Person.create(name='Herb', birthday=date(1950, 5, 5))

       To update a row, modify the model instance and call <u>save()</u> to persist the changes. Here  we  will  change
       Grandma's name and then save the changes in the database:

          grandma.name = 'Grandma L.'
          grandma.save()  # Update grandma's name in the database.
          # Returns: 1

       Now  we  have stored 3 people in the database. Let's give them some pets. Grandma doesn't like animals in
       the house, so she won't have any, but Herb is an animal lover:

          bob_kitty = Pet.create(owner=uncle_bob, name='Kitty', animal_type='cat')
          herb_fido = Pet.create(owner=herb, name='Fido', animal_type='dog')
          herb_mittens = Pet.create(owner=herb, name='Mittens', animal_type='cat')
          herb_mittens_jr = Pet.create(owner=herb, name='Mittens Jr', animal_type='cat')

       After a long full life, Mittens sickens and dies. We need to remove him from the database:

          herb_mittens.delete_instance() # he had a great life
          # Returns: 1

       <b>NOTE:</b>
          The return value of <u>delete_instance()</u> is the number of rows removed from the database.

       Uncle Bob decides that too many animals have been dying at Herb's house, so he adopts Fido:

          herb_fido.owner = uncle_bob
          herb_fido.save()

   <b>Retrieving</b> <b>Data</b>
       The real strength of our database is in how it allows us to retrieve  data  through  <u>queries</u>.  Relational
       databases are excellent for making ad-hoc queries.

   <b>Getting</b> <b>single</b> <b>records</b>
       Let's  retrieve  Grandma's  record  from  the  database.  To  get  a single record from the database, use
       <b>Select.get()</b>:

          grandma = Person.select().where(Person.name == 'Grandma L.').get()

       We can also use the equivalent shorthand <u>Model.get()</u>:

          grandma = Person.get(Person.name == 'Grandma L.')

   <b>Lists</b> <b>of</b> <b>records</b>
       Let's list all the people in the database:

          for person in Person.select():
              print(person.name)

          # prints:
          # Bob
          # Grandma L.
          # Herb

       Let's list all the cats and their owner's name:

          query = Pet.select().where(Pet.animal_type == 'cat')
          for pet in query:
              print(pet.name, pet.owner.name)

          # prints:
          # Kitty Bob
          # Mittens Jr Herb

       <b>ATTENTION:</b>
          There is a big problem with the previous query: because we are accessing <b>pet.owner.name</b> and we did not
          select this relation in our original query, peewee  will  have  to  perform  an  additional  query  to
          retrieve the pet's owner.  This behavior is referred to as <u>N+1</u> and it should generally be avoided.

          For  an  in-depth  guide to working with relationships and joins, refer to the <u>Relationships</u> <u>and</u> <u>Joins</u>
          documentation.

       We can avoid the extra queries by selecting both <u>Pet</u> and <u>Person</u>, and adding a <u>join</u>.

          query = (Pet
                   .select(Pet, Person)
                   .join(Person)
                   .where(Pet.animal_type == 'cat'))

          for pet in query:
              print(pet.name, pet.owner.name)

          # prints:
          # Kitty Bob
          # Mittens Jr Herb

       Let's get all the pets owned by Bob:

          for pet in Pet.select().join(Person).where(Person.name == 'Bob'):
              print(pet.name)

          # prints:
          # Kitty
          # Fido

       We can do another cool thing here to get bob's pets. Since we already have an object to represent Bob, we
       can do this instead:

          for pet in Pet.select().where(Pet.owner == uncle_bob):
              print(pet.name)

   <b>Sorting</b>
       Let's make sure these are sorted alphabetically by adding an <b>order_by()</b> clause:

          for pet in Pet.select().where(Pet.owner == uncle_bob).order_by(Pet.name):
              print(pet.name)

          # prints:
          # Fido
          # Kitty

       Let's list all the people now, youngest to oldest:

          for person in Person.select().order_by(Person.birthday.desc()):
              print(person.name, person.birthday)

          # prints:
          # Bob 1960-01-15
          # Herb 1950-05-05
          # Grandma L. 1935-03-01

   <b>Combining</b> <b>filter</b> <b>expressions</b>
       Peewee supports arbitrarily-nested expressions. Let's get all the people whose birthday was either:

       • before 1940 (grandma)

       • after 1959 (bob)

          d1940 = date(1940, 1, 1)
          d1960 = date(1960, 1, 1)
          query = (Person
                   .select()
                   .where((Person.birthday &lt; d1940) | (Person.birthday &gt; d1960)))

          for person in query:
              print(person.name, person.birthday)

          # prints:
          # Bob 1960-01-15
          # Grandma L. 1935-03-01

       Now let's do the opposite. People whose birthday is between 1940 and 1960 (inclusive of both years):

          query = (Person
                   .select()
                   .where(Person.birthday.between(d1940, d1960)))

          for person in query:
              print(person.name, person.birthday)

          # prints:
          # Herb 1950-05-05

   <b>Aggregates</b> <b>and</b> <b>Prefetch</b>
       Now let's list all the people <u>and</u> how many pets they have:

          for person in Person.select():
              print(person.name, person.pets.count(), 'pets')

          # prints:
          # Bob 2 pets
          # Grandma L. 0 pets
          # Herb 1 pets

       Once again we've run into a classic example of <u>N+1</u> query behavior.  In  this  case,  we're  executing  an
       additional query for every <b>Person</b> returned by the original <b>SELECT</b>! We can avoid this by performing a <u>JOIN</u>
       and using a SQL function to aggregate the results.

          query = (Person
                   .select(Person, fn.COUNT(Pet.id).alias('pet_count'))
                   .join(Pet, JOIN.LEFT_OUTER)  # include people without pets.
                   .group_by(Person)
                   .order_by(Person.name))

          for person in query:
              # "pet_count" becomes an attribute on the returned model instances.
              print(person.name, person.pet_count, 'pets')

          # prints:
          # Bob 2 pets
          # Grandma L. 0 pets
          # Herb 1 pets

       <b>NOTE:</b>
          Peewee  provides  a  magical  helper  <u>fn()</u>,  which  can be used to call any SQL function. In the above
          example, <b>fn.COUNT(Pet.id).alias('pet_count')</b> would be translated into <b>COUNT(pet.id)</b> <b>AS</b> <b>pet_count</b>.

       Now let's list all the people and the names of all their pets. As you may have guessed, this could easily
       turn into another <u>N+1</u> situation if we're not careful.

       Before diving into the code, consider how this example is different from the  earlier  example  where  we
       listed  all the pets and their owner's name. A pet can only have one owner, so when we performed the join
       from <b>Pet</b> to <b>Person</b>, there was always going to be a single match. The situation is different when  we  are
       joining  from  <b>Person</b>  to  <b>Pet</b> because a person may have zero pets or they may have several pets. Because
       we're using a relational databases, if we were to do a join from <b>Person</b> to <b>Pet</b>  then  every  person  with
       multiple pets would be repeated, once for each pet.

       It would look like this:

          query = (Person
                   .select(Person, Pet)
                   .join(Pet, JOIN.LEFT_OUTER)
                   .order_by(Person.name, Pet.name))
          for person in query:
              # We need to check if they have a pet instance attached, since not all
              # people have pets.
              if hasattr(person, 'pet'):
                  print(person.name, person.pet.name)
              else:
                  print(person.name, 'no pets')

          # prints:
          # Bob Fido
          # Bob Kitty
          # Grandma L. no pets
          # Herb Mittens Jr

       Usually  this type of duplication is undesirable. To accommodate the more common (and intuitive) workflow
       of listing a person and attaching <b>a</b> <b>list</b> of that person's pets,  we  can  use  a  special  method  called
       <u>prefetch()</u>:

          query = Person.select().order_by(Person.name).prefetch(Pet)
          for person in query:
              print(person.name)
              for pet in person.pets:
                  print('  *', pet.name)

          # prints:
          # Bob
          #   * Kitty
          #   * Fido
          # Grandma L.
          # Herb
          #   * Mittens Jr

   <b>SQL</b> <b>Functions</b>
       One last query. This will use a SQL function to find all people whose names start with either an upper or
       lower-case <u>G</u>:

          expression = fn.Lower(fn.Substr(Person.name, 1, 1)) == 'g'
          for person in Person.select().where(expression):
              print(person.name)

          # prints:
          # Grandma L.

       This  is  just  the basics! You can make your queries as complex as you like.  Check the documentation on
       <u>Querying</u> for more info.

   <b>Database</b>
       We're done with our database, let's close the connection:

          db.close()

       In an actual application, there are some established patterns for how  you  would  manage  your  database
       connection lifetime. For example, a web application will typically open a connection at start of request,
       and  close  the  connection  after  generating the response. A <u>connection</u> <u>pool</u> can help eliminate latency
       associated with startup costs.

       To learn about setting up your database, see the <u>Database</u> documentation, which  provides  many  examples.
       Peewee  also supports <u>configuring</u> <u>the</u> <u>database</u> <u>at</u> <u>run-time</u> as well as setting or changing the database at
       any time.

   <b>Working</b> <b>with</b> <b>existing</b> <b>databases</b>
       If you already have a database, you can autogenerate peewee models using <u>pwiz,</u>  <u>a</u>  <u>model</u>  <u>generator</u>.  For
       instance, if I have a postgresql database named <u>charles_blog</u>, I might run:

          python -m pwiz -e postgresql charles_blog &gt; blog_models.py

   <b>What</b> <b>next?</b>
       That's it for the quickstart. If you want to look at a full web-app, check out the <u>Example</u> <u>app</u>.

   <b>Example</b> <b>app</b>
       We'll  be  building  a  simple  <u>twitter</u>-like  site.  The  source code for the example can be found in the
       <b>examples/twitter</b> directory. You can also <u>browse</u> <u>the</u> <u>source-code</u> on github. There is also an example  <u>blog</u>
       <u>app</u> if that's more to your liking, however it is not covered in this guide.

       The  example  app  uses the <u>flask</u> web framework which is very easy to get started with. If you don't have
       flask already, you will need to install it to run the example:

          pip install flask

   <b>Running</b> <b>the</b> <b>example</b>
       [image]

       After ensuring that  flask  is  installed,  <b>cd</b>  into  the  twitter  example  directory  and  execute  the
       <b>run_example.py</b> script:

          python run_example.py

       The example app will be accessible at <u><a href="http://localhost">http://localhost</a>:5000/</u>

   <b>Diving</b> <b>into</b> <b>the</b> <b>code</b>
       For simplicity all example code is contained within a single module, <b>examples/twitter/app.py</b>. For a guide
       on structuring larger Flask apps with peewee, check out <u>Structuring</u> <u>Flask</u> <u>Apps</u>.

   <b>Models</b>
       In  the  spirit of the popular web framework Django, peewee uses declarative model definitions. If you're
       not familiar with Django, the idea is that you declare a model class for each table. The model class then
       defines one or more field attributes which correspond to the table's  columns.  For  the  twitter  clone,
       there are just three models:

       <u>User</u><b>:</b>  Represents  a  user  account and stores the username and password, an email address for generating
              avatars using <u>gravatar</u>, and a datetime field indicating when that account was created.

       <u>Relationship</u><b>:</b>
              This is a utility model that contains two foreign-keys to the <u>User</u> model and  stores  which  users
              follow one another.

       <u>Message</u><b>:</b>
              Analogous to a tweet. The Message model stores the text content of the tweet, when it was created,
              and who posted it (foreign key to User).

       If you like UML, these are the tables and relationships: [image]

       In  order to create these models we need to instantiate a <u>SqliteDatabase</u> object. Then we define our model
       classes, specifying the columns as <u>Field</u> instances on the class.

          # create a peewee database instance -- our models will use this database to
          # persist information
          database = SqliteDatabase(DATABASE)

          # model definitions -- the standard "pattern" is to define a base model class
          # that specifies which database to use.  then, any subclasses will automatically
          # use the correct storage.
          class BaseModel(Model):
              class Meta:
                  database = database

          # the user model specifies its fields (or columns) declaratively, like django
          class User(BaseModel):
              username = CharField(unique=True)
              password = CharField()
              email = CharField()
              join_date = DateTimeField()

          # this model contains two foreign keys to user -- it essentially allows us to
          # model a "many-to-many" relationship between users.  by querying and joining
          # on different columns we can expose who a user is "related to" and who is
          # "related to" a given user
          class Relationship(BaseModel):
              from_user = ForeignKeyField(User, backref='relationships')
              to_user = ForeignKeyField(User, backref='related_to')

              class Meta:
                  # `indexes` is a tuple of 2-tuples, where the 2-tuples are
                  # a tuple of column names to index and a boolean indicating
                  # whether the index is unique or not.
                  indexes = (
                      # Specify a unique multi-column index on from/to-user.
                      (('from_user', 'to_user'), True),
                  )

          # a dead simple one-to-many relationship: one user has 0..n messages, exposed by
          # the foreign key. a users messages will be accessible as a special attribute,
          # User.messages.
          class Message(BaseModel):
              user = ForeignKeyField(User, backref='messages')
              content = TextField()
              pub_date = DateTimeField()

       <b>NOTE:</b>
          Note that we create a <u>BaseModel</u> class that simply defines what database we would  like  to  use.   All
          other models then extend this class and will also use the correct database connection.

       Peewee  supports  many  different  <u>field</u>  <u>types</u> which map to different column types commonly supported by
       database  engines.   Conversion  between  python  types  and  those  used  in  the  database  is  handled
       transparently, allowing you to use the following in your application:

       • Strings (unicode or otherwise)

       • Integers, floats, and <b>Decimal</b> numbers.

       • Boolean values

       • Dates, times and datetimes

       • <b>None</b> (NULL)

       • Binary data

   <b>Creating</b> <b>tables</b>
       In  order to start using the models, its necessary to create the tables. This is a one-time operation and
       can be done quickly using the interactive  interpreter.   We  can  create  a  small  helper  function  to
       accomplish this:

          def create_tables():
              with database:
                  database.create_tables([User, Relationship, Message])

       Open a python shell in the directory alongside the example app and execute the following:

          &gt;&gt;&gt; from app import *
          &gt;&gt;&gt; create_tables()

       <b>NOTE:</b>
          If  you  encounter  an  <u>ImportError</u>  it means that either <u>flask</u> or <u>peewee</u> was not found and may not be
          installed correctly. Check the <u>Installing</u> <u>and</u> <u>Testing</u> document for instructions on installing peewee.

       Every model has a <u>create_table()</u> classmethod which runs a SQL <u>CREATE</u> <u>TABLE</u>  statement  in  the  database.
       This  method  will  create  the  table,  including  all  columns,  foreign-key  constraints, indexes, and
       sequences. Usually this is something you'll only do once, whenever a new model is added.

       Peewee provides a helper method <u>Database.create_tables()</u> which will resolve inter-model dependencies  and
       call <u>create_table()</u> on each model, ensuring the tables are created in order.

       <b>NOTE:</b>
          Adding fields after the table has been created will require you to either drop the table and re-create
          it or manually add the columns using an <u>ALTER</u> <u>TABLE</u> query.

          Alternatively, you can use the <u>schema</u> <u>migrations</u> extension to alter your database schema using Python.

   <b>Establishing</b> <b>a</b> <b>database</b> <b>connection</b>
       You  may  have noticed in the above model code that there is a class defined on the base model named <u>Meta</u>
       that sets the <b>database</b> attribute. Peewee allows every model to specify which database it uses. There  are
       many <u>Meta</u> <u>options</u> you can specify which control the behavior of your model.

       This is a peewee idiom:

          DATABASE = 'tweepee.db'

          # Create a database instance that will manage the connection and
          # execute queries
          database = SqliteDatabase(DATABASE)

          # Create a base-class all our models will inherit, which defines
          # the database we'll be using.
          class BaseModel(Model):
              class Meta:
                  database = database

       When  developing  a web application, it's common to open a connection when a request starts, and close it
       when the response is returned. <b>You</b> <b>should</b> <b>always</b> <b>manage</b> <b>your</b> <b>connections</b> <b>explicitly</b>. For instance, if you
       are using a <u>connection</u> <u>pool</u>, connections will only be  recycled  correctly  if  you  call  <u>connect()</u>  and
       <u>close()</u>.

       We will tell flask that during the request/response cycle we need to create a connection to the database.
       Flask provides some handy decorators to make this a snap:

          @app.before_request
          def before_request():
              database.connect()

          @app.after_request
          def after_request(response):
              database.close()
              return response

       <b>NOTE:</b>
          Peewee  uses  thread  local  storage  to  manage  connection  state,  so this pattern can be used with
          multi-threaded WSGI servers.

   <b>Making</b> <b>queries</b>
       In the <u>User</u> model there are a few instance methods that encapsulate some user-specific functionality:

       • <b>following()</b>: who is this user following?

       • <b>followers()</b>: who is following this user?

       These methods are similar in their implementation but with an important difference in the  SQL  <u>JOIN</u>  and
       <u>WHERE</u> clauses:

          def following(self):
              # query other users through the "relationship" table
              return (User
                      .select()
                      .join(Relationship, on=Relationship.to_user)
                      .where(Relationship.from_user == self)
                      .order_by(User.username))

          def followers(self):
              return (User
                      .select()
                      .join(Relationship, on=Relationship.from_user)
                      .where(Relationship.to_user == self)
                      .order_by(User.username))

   <b>Creating</b> <b>new</b> <b>objects</b>
       When  a new user wants to join the site we need to make sure the username is available, and if so, create
       a new <u>User</u> record. Looking at the <u>join()</u> view, we can see that our application  attempts  to  create  the
       User  using  <u>Model.create()</u>.  We  defined  the  <u>User.username</u>  field  with a unique constraint, so if the
       username is taken the database will raise an <b>IntegrityError</b>.

          try:
              with database.atomic():
                  # Attempt to create the user. If the username is taken, due to the
                  # unique constraint, the database will raise an IntegrityError.
                  user = User.create(
                      username=request.form['username'],
                      password=md5(request.form['password']).hexdigest(),
                      email=request.form['email'],
                      join_date=datetime.datetime.now())

              # mark the user as being 'authenticated' by setting the session vars
              auth_user(user)
              return redirect(url_for('homepage'))

          except IntegrityError:
              flash('That username is already taken')

       We will use a  similar  approach  when  a  user  wishes  to  follow  someone.  To  indicate  a  following
       relationship,  we  create  a  row in the <u>Relationship</u> table pointing from one user to another. Due to the
       unique index on <b>from_user</b> and <b>to_user</b>, we will be sure not to end up with duplicate rows:

          user = get_object_or_404(User, username=username)
          try:
              with database.atomic():
                  Relationship.create(
                      from_user=get_current_user(),
                      to_user=user)
          except IntegrityError:
              pass

   <b>Performing</b> <b>subqueries</b>
       If you are logged-in and visit the twitter homepage, you will see tweets from the users that you  follow.
       In order to implement this cleanly, we can use a subquery:

       <b>NOTE:</b>
          The  subquery, <b>user.following()</b>, by default would ordinarily select all the columns on the <b>User</b> model.
          Because we're using it as a subquery, peewee will only select the primary key.

          # python code
          user = get_current_user()
          messages = (Message
                      .select()
                      .where(Message.user.in_(user.following()))
                      .order_by(Message.pub_date.desc()))

       This code corresponds to the following SQL query:

          SELECT t1."id", t1."user_id", t1."content", t1."pub_date"
          FROM "message" AS t1
          WHERE t1."user_id" IN (
              SELECT t2."id"
              FROM "user" AS t2
              INNER JOIN "relationship" AS t3
                  ON t2."id" = t3."to_user_id"
              WHERE t3."from_user_id" = ?
          )

   <b>Other</b> <b>topics</b> <b>of</b> <b>interest</b>
       There are a couple other neat things going on in the example app that are worth mentioning briefly.

       • Support for paginating lists of results is implemented in a simple function called  <b>object_list</b>  (after
         it's corollary in Django).  This function is used by all the views that return lists of objects.

            def object_list(template_name, qr, var_name='object_list', **kwargs):
                kwargs.update(
                    page=int(request.args.get('page', 1)),
                    pages=qr.count() / 20 + 1)
                kwargs[var_name] = qr.paginate(kwargs['page'])
                return render_template(template_name, **kwargs)

       • Simple authentication system with a <b>login_required</b> decorator.  The first function simply adds user data
         into the current session when a user successfully logs in.  The decorator <b>login_required</b> can be used to
         wrap  view  functions,  checking for whether the session is authenticated and if not redirecting to the
         login page.

            def auth_user(user):
                session['logged_in'] = True
                session['user'] = user
                session['username'] = user.username
                flash('You are logged in as %s' % (user.username))

            def login_required(f):
                @wraps(f)
                def inner(*args, **kwargs):
                    if not session.get('logged_in'):
                        return redirect(url_for('login'))
                    return f(*args, **kwargs)
                return inner

       • Return a 404 response instead of throwing exceptions when an object is not found in the database.

            def get_object_or_404(model, *expressions):
                try:
                    return model.get(*expressions)
                except model.DoesNotExist:
                    <a href="../man404/abort.404.html">abort</a>(404)

       <b>NOTE:</b>
          To avoid having to frequently copy/paste <u>object_list()</u> or  <u>get_object_or_404()</u>,  these  functions  are
          included as part of the playhouse <u>flask</u> <u>extension</u> <u>module</u>.

              from playhouse.flask_utils import get_object_or_404, object_list

   <b>More</b> <b>examples</b>
       There are more examples included in the peewee <u>examples</u> <u>directory</u>, including:

       • <u>Example</u> <u>blog</u> <u>app</u> using Flask and peewee. Also see <u>accompanying</u> <u>blog</u> <u>post</u>.

       • <u>An</u> <u>encrypted</u> <u>command-line</u> <u>diary</u>. There is a <u>companion</u> <u>blog</u> <u>post</u> you might enjoy as well.

       • <u>Analytics</u>  <u>web-service</u>  (like  a  lite  version of Google Analytics). Also check out the <u>companion</u> <u>blog</u>
         <u>post</u>.

       <b>NOTE:</b>
          Like these snippets and interested in more?  Check out <u>flask-peewee</u> - a flask plugin that  provides  a
          django-like Admin interface, RESTful API, Authentication and more for your peewee models.

   <b>Using</b> <b>Peewee</b> <b>Interactively</b>
       Peewee  contains  helpers for working interactively from a Python interpreter or something like a Jupyter
       notebook. For this example, we'll assume that we have a pre-existing Sqlite database with  the  following
       simple schema:

          CREATE TABLE IF NOT EXISTS "event" (
              "id" INTEGER NOT NULL PRIMARY KEY,
              "key" TEXT NOT NULL,
              "timestamp" DATETIME NOT NULL,
              "metadata" TEXT NOT NULL);

       To  experiment  with  querying  this database from an interactive interpreter session, we would start our
       interpreter and import the following helpers:

       • <b>peewee.SqliteDatabase</b> - to reference the "events.db"

       • <b>playhouse.reflection.generate_models</b> - to generate models from an existing database.

       • <b>playhouse.reflection.print_model</b> - to view the model definition.

       • <b>playhouse.reflection.print_table_sql</b> - to view the table SQL.

       Our terminal session might look like this:

          &gt;&gt;&gt; from peewee import SqliteDatabase
          &gt;&gt;&gt; from playhouse.reflection import generate_models, print_model, print_table_sql
          &gt;&gt;&gt;

       The <u>generate_models()</u> function will introspect the database and generate model classes for all the tables
       that are found. This is a handy way to get started and can save a lot of typing. The function  returns  a
       dictionary keyed by the table name, with the generated model as the corresponding value:

          &gt;&gt;&gt; db = SqliteDatabase('events.db')
          &gt;&gt;&gt; models = generate_models(db)
          &gt;&gt;&gt; list(models.items())
          [('events', &lt;Model: event&gt;)]

          &gt;&gt;&gt; globals().<a href="../manmodels/update.models.html">update</a>(models)  # Inject models into global namespace.
          &gt;&gt;&gt; event
          &lt;Model: event&gt;

       To  take  a  look  at  the model definition, which lists the model's fields and data-type, we can use the
       <u>print_model()</u> function:

          &gt;&gt;&gt; print_model(event)
          event
            id AUTO
            key TEXT
            timestamp DATETIME
            metadata TEXT

       We can also generate a SQL <b>CREATE</b> <b>TABLE</b> for the introspected model, if you find that easier to read. This
       should match the actual table definition in the introspected database:

          &gt;&gt;&gt; print_table_sql(event)
          CREATE TABLE IF NOT EXISTS "event" (
            "id" INTEGER NOT NULL PRIMARY KEY,
            "key" TEXT NOT NULL,
            "timestamp" DATETIME NOT NULL,
            "metadata" TEXT NOT NULL)

       Now that we are familiar with the structure of the table we're working with, we can run some  queries  on
       the generated <b>event</b> model:

          &gt;&gt;&gt; for e in event.select().order_by(event.timestamp).<a href="../man5/limit.5.html">limit</a>(5):
          ...     print(e.key, e.timestamp)
          ...
          e00 2019-01-01 00:01:00
          e01 2019-01-01 00:02:00
          e02 2019-01-01 00:03:00
          e03 2019-01-01 00:04:00
          e04 2019-01-01 00:05:00

          &gt;&gt;&gt; event.select(fn.MIN(event.timestamp), fn.MAX(event.timestamp)).scalar(as_tuple=True)
          (datetime.datetime(2019, 1, 1, 0, 1), datetime.datetime(2019, 1, 1, 1, 0))

          &gt;&gt;&gt; event.select().count()  # Or, len(event)
          60

       For  more information about these APIs and other similar reflection utilities, see the <u>Reflection</u> section
       of the <u>playhouse</u> <u>extensions</u> document.

       To generate an actual Python module containing model definitions for an existing database,  you  can  use
       the command-line <u>pwiz</u> tool. Here is a quick example:

          $ pwiz -e sqlite events.db &gt; events.py

       The  <b>events.py</b>  file  will  now  be an import-able module containing a database instance (referencing the
       <b>events.db</b>) along with model definitions for any tables found in the database. <b>pwiz</b> does  some  additional
       nice things like introspecting indexes and adding proper flags for <b>NULL</b>/<b>NOT</b> <b>NULL</b> constraints, etc.

       The APIs discussed in this section:

       • <u>generate_models()</u>

       • <u>print_model()</u>

       • <u>print_table_sql()</u>

       More low-level APIs are also available on the <u>Database</u> instance:

       • <u>Database.get_tables()</u>

       • <u>Database.get_indexes()</u>

       • <u>Database.get_columns()</u> (for a given table)

       • <u>Database.get_primary_keys()</u> (for a given table)

       • <u>Database.get_foreign_keys()</u> (for a given table)

   <b>Contributing</b>
       In order to continually improve, Peewee needs the help of developers like you.  Whether it's contributing
       patches, submitting bug reports, or just asking and answering questions, you are helping to make Peewee a
       better library.

       In this document I'll describe some of the ways you can help.

   <b>Patches</b>
       Do  you  have an idea for a new feature, or is there a clunky API you'd like to improve? Before coding it
       up and submitting a pull-request, <u>open</u> <u>a</u> <u>new</u> <u>issue</u> on  GitHub  describing  your  proposed  changes.  This
       doesn't have to be anything formal, just a description of what you'd like to do and why.

       When  you're  ready,  you  can  submit a pull-request with your changes. Successful patches will have the
       following:

       • Unit tests.

       • Documentation, both prose form and general <u>API</u> <u>documentation</u>.

       • Code that conforms stylistically with the rest of the Peewee codebase.

   <b>Bugs</b>
       If you've found a bug, please check to see if it has <u>already</u> <u>been</u> <u>reported</u>, and if not <u>create</u> <u>an</u> <u>issue</u> <u>on</u>
       <u>GitHub</u>.  The more information you include, the more quickly the bug will get  fixed,  so  please  try  to
       include the following:

       • Traceback and the error message (please <u>format</u> <u>your</u> <u>code</u>!)

       • Relevant portions of your code or code to reproduce the error

       • Peewee version: <b>python</b> <b>-c</b> <b>"from</b> <b>peewee</b> <b>import</b> <b>__version__;</b> <b>print(__version__)"</b>

       • Which database you're using

       If you have found a bug in the code and submit a failing test-case, then hats-off to you, you are a hero!

   <b>Questions</b>
       If you have questions about how to do something with peewee, then I recommend either:

       • Ask  on StackOverflow. I check SO just about every day for new peewee questions and try to answer them.
         This has the benefit also of preserving the question and answer for other people to find.

       • Ask on the mailing list, <u>https://groups.google.com/group/peewee-orm</u>

   <b>Database</b>
       The Peewee <u>Database</u> object represents a connection to a database.  The  <u>Database</u>  class  is  instantiated
       with all the information needed to open a connection to a database, and then can be used to:

       • Open and close connections.

       • Execute queries.

       • Manage transactions (and savepoints).

       • Introspect tables, columns, indexes, and constraints.

       Peewee  comes  with  support  for  SQLite, MySQL, MariaDB and Postgres. Each database class provides some
       basic, database-specific configuration options.

          from peewee import *

          # SQLite database using WAL journal mode and 64MB cache.
          sqlite_db = SqliteDatabase('/path/to/app.db', pragmas={
              'journal_mode': 'wal',
              'cache_size': -1024 * 64})

          # Connect to a MySQL database on network.
          mysql_db = MySQLDatabase('my_app', user='app', password='db_password',
                                   host='10.1.0.8', port=3306)

          # Connect to a Postgres database.
          pg_db = PostgresqlDatabase('my_app', user='postgres', password='secret',
                                     host='10.1.0.9', port=5432)

       Peewee provides advanced support for SQLite, Postgres and  CockroachDB  via  database-specific  extension
       modules.  To  use the extended-functionality, import the appropriate database-specific module and use the
       database class provided:

          from playhouse.sqlite_ext import SqliteExtDatabase

          # Use SQLite (will register a REGEXP function and set busy timeout to 3s).
          db = SqliteExtDatabase('/path/to/app.db', regexp_function=True, timeout=3,
                                 pragmas={'journal_mode': 'wal'})

          from playhouse.postgres_ext import PostgresqlExtDatabase

          # Use Postgres (and register hstore extension).
          db = PostgresqlExtDatabase('my_app', user='postgres', register_hstore=True)

          from playhouse.cockroachdb import CockroachDatabase

          # Use CockroachDB.
          db = CockroachDatabase('my_app', user='root', port=26257, host='10.1.0.8')

          # CockroachDB connections may require a number of parameters, which can
          # alternatively be specified using a connection-string.
          db = CockroachDatabase('postgresql://...')

       For more information on database extensions, see:

       • <u>Postgresql</u> <u>Extensions</u>

       • <u>SQLite</u> <u>Extensions</u>

       • <u>Cockroach</u> <u>Database</u>

       • <u>Sqlcipher</u> <u>backend</u> (encrypted SQLite database).

       • <u>apsw,</u> <u>an</u> <u>advanced</u> <u>sqlite</u> <u>driver</u>

       • <u>SqliteQ</u>

   <b>Initializing</b> <b>a</b> <b>Database</b>
       The <u>Database</u> initialization method expects the name of the database as the  first  parameter.  Subsequent
       keyword arguments are passed to the underlying database driver when establishing the connection, allowing
       you to pass vendor-specific parameters easily.

       For  instance,  with Postgresql it is common to need to specify the <b>host</b>, <b>user</b> and <b>password</b> when creating
       your connection. These are not standard Peewee <u>Database</u> parameters, so they will be passed directly  back
       to <b>psycopg2</b> when creating connections:

          db = PostgresqlDatabase(
              'database_name',  # Required by Peewee.
              user='postgres',  # Will be passed directly to psycopg2.
              password='secret',  # Ditto.
              host='db.mysite.com')  # Ditto.

       As  another  example,  the  <b>pymysql</b>  driver  accepts  a  <b>charset</b> parameter which is not a standard Peewee
       <u>Database</u> parameter. To set this value, simply pass in <b>charset</b> alongside your other values:

          db = MySQLDatabase('database_name', user='www-data', charset='utf8mb4')

       Consult your database driver's documentation for the available parameters:

       • Postgres: <u>psycopg2</u>

       • MySQL: <u>pymysql</u>

       • MySQL: <u>mysqlclient</u>

       • SQLite: <u>sqlite3</u>

       • CockroachDB: see <u>psycopg2</u>

   <b>Using</b> <b>Postgresql</b>
       To connect to a Postgresql database, we will use <u>PostgresqlDatabase</u>. The first parameter  is  always  the
       name of the database, and after that you can specify arbitrary <u>psycopg2</u> <u>parameters</u>.

          psql_db = PostgresqlDatabase('my_database', user='postgres')

          class BaseModel(Model):
              """A base model that will use our Postgresql database"""
              class Meta:
                  database = psql_db

          class User(BaseModel):
              username = CharField()

       The  <u>Playhouse,</u>  <u>extensions</u>  <u>to</u>  <u>Peewee</u>  contains  a  <u>Postgresql</u>  <u>extension</u>  <u>module</u>  which  provides many
       postgres-specific features such as:

       • <u>Arrays</u>

       • <u>HStore</u>

       • <u>JSON</u>

       • <u>Server-side</u> <u>cursors</u>

       • And more!

       If  you  would  like  to  use  these  awesome  features,   use   the   <u>PostgresqlExtDatabase</u>   from   the
       <b>playhouse.postgres_ext</b> module:

          from playhouse.postgres_ext import PostgresqlExtDatabase

          psql_db = PostgresqlExtDatabase('my_database', user='postgres')

   <b>Isolation</b> <b>level</b>
       As  of  Peewee  3.9.7,  the  isolation  level  can be specified as an initialization parameter, using the
       symbolic constants in <b>psycopg2.extensions</b>:

          from psycopg2.extensions import ISOLATION_LEVEL_SERIALIZABLE

          db = PostgresqlDatabase('my_app', user='postgres', host='db-host',
                                  isolation_level=ISOLATION_LEVEL_SERIALIZABLE)

       <b>NOTE:</b>
          In older versions, you can manually set the isolation level on  the  underlying  psycopg2  connection.
          This can be done in a one-off fashion:

              db = PostgresqlDatabase(...)
              conn = db.connection()  # returns current connection.

              from psycopg2.extensions import ISOLATION_LEVEL_SERIALIZABLE
              conn.set_isolation_level(ISOLATION_LEVEL_SERIALIZABLE)

          To  run  this  every  time  a connection is created, subclass and implement the <b>_initialize_database()</b>
          hook, which is designed for this purpose:

              class SerializedPostgresqlDatabase(PostgresqlDatabase):
                  def _initialize_connection(self, conn):
                      conn.set_isolation_level(ISOLATION_LEVEL_SERIALIZABLE)

   <b>Using</b> <b>CockroachDB</b>
       Connect   to   CockroachDB   (CRDB)   using   the   <u>CockroachDatabase</u>   database   class,   defined    in
       <b>playhouse.cockroachdb</b>:

          from playhouse.cockroachdb import CockroachDatabase

          db = CockroachDatabase('my_app', user='root', port=26257, host='localhost')

       If  you  are  using  <u>Cockroach</u> <u>Cloud</u>, you may find it easier to specify the connection parameters using a
       connection-string:

          db = CockroachDatabase('postgresql:/<a href="file:/root">/root</a>:secret@host:26257/defaultdb...')

       <b>NOTE:</b>
          CockroachDB requires the <b>psycopg2</b> (postgres) Python driver.

       <b>NOTE:</b>
          CockroachDB    installation    and    getting-started    guide    can     be     found     here:     ‐
          <u>https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html</u>

       CRDB    provides    client-side    transaction   retries,   which   are   available   using   a   special
       <u>CockroachDatabase.run_transaction()</u> helper-method. This method accepts a callable, which  is  responsible
       for executing any transactional statements that may need to be retried.

       Simplest possible example of <u>run_transaction()</u>:

          def create_user(email):
              # Callable that accepts a single argument (the database instance) and
              # which is responsible for executing the transactional SQL.
              def callback(db_ref):
                  return User.create(email=email)

              return db.run_transaction(callback, max_attempts=10)

          huey = create_user('<a href="mailto:huey@example.com">huey@example.com</a>')

       <b>NOTE:</b>
          The  <b>cockroachdb.ExceededMaxAttempts</b>  exception  will be raised if the transaction cannot be committed
          after the given number of attempts. If the SQL is mal-formed, violates a constraint,  etc.,  then  the
          function will raise the exception to the caller.

       For more information, see:

       • <u>CRDB</u> <u>extension</u> <u>documentation</u>

       • <u>SSL</u> <u>configuration</u> <u>with</u> <u>CockroachDB</u>

       • <u>Arrays</u> (postgres-specific, but applies to CRDB)

       • <u>JSON</u> (postgres-specific, but applies to CRDB)

   <b>Using</b> <b>SQLite</b>
       To  connect  to  a  SQLite  database,  we  will  use  <u>SqliteDatabase</u>. The first parameter is the filename
       containing the database, or the string <b>':memory:'</b> to create an in-memory  database.  After  the  database
       filename, you can specify a list or pragmas or any other arbitrary <u>sqlite3</u> <u>parameters</u>.

          sqlite_db = SqliteDatabase('my_app.db', pragmas={'journal_mode': 'wal'})

          class BaseModel(Model):
              """A base model that will use our Sqlite database."""
              class Meta:
                  database = sqlite_db

          class User(BaseModel):
              username = TextField()
              # etc, etc

       Peewee  includes a <u>SQLite</u> <u>extension</u> <u>module</u> which provides many SQLite-specific features such as <u>full-text</u>
       <u>search</u>, <u>json</u> <u>extension</u> <u>support</u>, and much, much more. If you would like to use these awesome features, use
       the <u>SqliteExtDatabase</u> from the <b>playhouse.sqlite_ext</b> module:

          from playhouse.sqlite_ext import SqliteExtDatabase

          sqlite_db = SqliteExtDatabase('my_app.db', pragmas={
              'journal_mode': 'wal',  # WAL-mode.
              'cache_size': -64 * 1000,  # 64MB cache.
              'synchronous': 0})  # Let the OS manage syncing.

   <b>PRAGMA</b> <b>statements</b>
       SQLite allows run-time configuration  of  a  number  of  parameters  through  <b>PRAGMA</b>  statements  (<u>SQLite</u>
       <u>documentation</u>).   These  statements  are typically run when a new database connection is created.  To run
       one or more <b>PRAGMA</b> statements against new connections, you can specify them as a dictionary or a list  of
       2-tuples containing the pragma name and value:

          db = SqliteDatabase('my_app.db', pragmas={
              'journal_mode': 'wal',
              'cache_size': 10000,  # 10000 pages, or ~40MB
              'foreign_keys': 1,  # Enforce foreign-key constraints
          })

       PRAGMAs  may  also  be  configured dynamically using either the <u>pragma()</u> method or the special properties
       exposed on the <u>SqliteDatabase</u> object:

          # Set cache size to 64MB for *current connection*.
          db.pragma('cache_size', -1024 * 64)

          # Same as above.
          db.cache_size = -1024 * 64

          # Read the value of several pragmas:
          print('cache_size:', db.cache_size)
          print('foreign_keys:', db.foreign_keys)
          print('journal_mode:', db.journal_mode)
          print('page_size:', db.page_size)

          # Set foreign_keys pragma on current connection *AND* on all
          # connections opened subsequently.
          db.pragma('foreign_keys', 1, permanent=True)

       <b>ATTENTION:</b>
          Pragmas set using the <u>pragma()</u> method, by default, do not persist after the connection is  closed.  To
          configure a pragma to be run whenever a connection is opened, specify <b>permanent=True</b>.

       <b>NOTE:</b>
          A  full  list  of  PRAGMA  settings,  their  meaning  and  accepted  values can be found in the SQLite
          documentation: <u><a href="http://sqlite.org/pragma.html">http://sqlite.org/pragma.html</a></u>

   <b>Recommended</b> <b>Settings</b>
       The following settings are what I use with SQLite for a typical web application database.
                  ┌──────────────────────────┬─────────────────────┬──────────────────────────────┐
                  │ pragma                   │ recommended setting │ explanation                  │
                  ├──────────────────────────┼─────────────────────┼──────────────────────────────┤
                  │ journal_mode             │ wal                 │ allow readers and writers to │
                  │                          │                     │ co-exist                     │
                  ├──────────────────────────┼─────────────────────┼──────────────────────────────┤
                  │ cache_size               │ -1 * data_size_kb   │ set page-cache size in  KiB, │
                  │                          │                     │ e.g. -32000 = 32MB           │
                  ├──────────────────────────┼─────────────────────┼──────────────────────────────┤
                  │ foreign_keys             │ 1                   │ enforce          foreign-key │
                  │                          │                     │ constraints                  │
                  ├──────────────────────────┼─────────────────────┼──────────────────────────────┤
                  │ ignore_check_constraints │ 0                   │ enforce CHECK constraints    │
                  ├──────────────────────────┼─────────────────────┼──────────────────────────────┤
                  │ synchronous              │ 0                   │ let  OS  handle  fsync  (use │
                  │                          │                     │ with caution)                │
                  └──────────────────────────┴─────────────────────┴──────────────────────────────┘

       Example database using the above options:

          db = SqliteDatabase('my_app.db', pragmas={
              'journal_mode': 'wal',
              'cache_size': -1 * 64000,  # 64MB
              'foreign_keys': 1,
              'ignore_check_constraints': 0,
              'synchronous': 0})

   <b>User-defined</b> <b>functions</b>
       SQLite  can  be  extended with user-defined Python code. The <u>SqliteDatabase</u> class supports three types of
       user-defined extensions:

       • Functions - which take any number of parameters and return a single value.

       • Aggregates - which aggregate parameters from multiple rows and return a single value.

       • Collations - which describe how to sort some value.

       <b>NOTE:</b>
          For even more extension support, see <u>SqliteExtDatabase</u>, which is in the <b>playhouse.sqlite_ext</b> module.

       Example user-defined function:

          db = SqliteDatabase('analytics.db')

          from urllib.parse import urlparse

          @db.func('hostname')
          def hostname(url):
              if url is not None:
                  return urlparse(url).netloc

          # Call this function in our code:
          # The following finds the most common hostnames of referrers by count:
          query = (PageView
                   .select(fn.hostname(PageView.referrer), fn.COUNT(PageView.id))
                   .group_by(fn.hostname(PageView.referrer))
                   .order_by(fn.COUNT(PageView.id).desc()))

       Example user-defined aggregate:

          from hashlib import md5

          @db.aggregate('md5')
          class MD5Checksum(object):
              def __init__(self):
                  self.checksum = md5()

              def step(self, value):
                  self.checksum.update(value.encode('utf-8'))

              def finalize(self):
                  return self.checksum.hexdigest()

          # Usage:
          # The following computes an aggregate MD5 checksum for files broken
          # up into chunks and stored in the database.
          query = (FileChunk
                   .select(FileChunk.filename, fn.MD5(FileChunk.data))
                   .group_by(FileChunk.filename)
                   .order_by(FileChunk.filename, FileChunk.sequence))

       Example collation:

          @db.collation('ireverse')
          def collate_reverse(s1, s2):
              # Case-insensitive reverse.
              s1, s2 = s1.lower(), s2.lower()
              return (s1 &lt; s2) - (s1 &gt; s2)  # Equivalent to -cmp(s1, s2)

          # To use this collation to sort books in reverse order...
          Book.select().order_by(collate_reverse.collation(Book.title))

          # Or...
          Book.select().order_by(Book.title.asc(collation='reverse'))

       Example user-defined table-value function (see <u>TableFunction</u> and <u>table_function</u>) for additional details:

          from playhouse.sqlite_ext import TableFunction

          db = SqliteDatabase('my_app.db')

          @db.table_function('series')
          class Series(TableFunction):
              columns = ['value']
              params = ['start', 'stop', 'step']

              def initialize(self, start=0, stop=None, step=1):
                  """
                  Table-functions declare an initialize() method, which is
                  called with whatever arguments the user has called the
                  function with.
                  """
                  self.start = self.current = start
                  self.stop = stop or float('Inf')
                  self.step = step

              def iterate(self, idx):
                  """
                  Iterate is called repeatedly by the SQLite database engine
                  until the required number of rows has been read **or** the
                  function raises a `StopIteration` signalling no more rows
                  are available.
                  """
                  if self.current &gt; self.stop:
                      raise StopIteration

                  ret, self.current = self.current, self.current + self.step
                  return (ret,)

          # Usage:
          cursor = db.execute_sql('SELECT * FROM series(?, ?, ?)', (0, 5, 2))
          for value, in cursor:
              print(value)

          # Prints:
          # 0
          # 2
          # 4

       For more information, see:

       • <u>SqliteDatabase.func()</u>

       • <u>SqliteDatabase.aggregate()</u>

       • <u>SqliteDatabase.collation()</u>

       • <u>SqliteDatabase.table_function()</u>

       • For even more SQLite extensions, see <u>SQLite</u> <u>Extensions</u>

   <b>Set</b> <b>locking</b> <b>mode</b> <b>for</b> <b>transaction</b>
       SQLite transactions can be opened in three different modes:

       • <u>Deferred</u> (<b>default</b>) - only acquires lock when a read or write is performed. The first read creates  a  ‐
         <u>shared</u>  <u>lock</u>  and  the  first  write  creates  a <u>reserved</u> <u>lock</u>.  Because the acquisition of the lock is
         deferred until actually needed, it is possible that another thread or process could create  a  separate
         transaction and write to the database after the BEGIN on the current thread has executed.

       • <u>Immediate</u>  -  a <u>reserved</u> <u>lock</u> is acquired immediately. In this mode, no other database may write to the
         database or open an <u>immediate</u> or <u>exclusive</u> transaction. Other processes can continue to read  from  the
         database, however.

       • <u>Exclusive</u>  -  opens an <u>exclusive</u> <u>lock</u> which prevents all (except for read uncommitted) connections from
         accessing the database until the transaction is complete.

       Example specifying the locking mode:

          db = SqliteDatabase('app.db')

          with db.atomic('EXCLUSIVE'):
              do_something()

          @db.atomic('IMMEDIATE')
          def some_other_function():
              # This function is wrapped in an "IMMEDIATE" transaction.
              do_something_else()

       For more information, see the SQLite <u>locking</u> <u>documentation</u>.  To learn more about transactions in  Peewee,
       see the <u>Managing</u> <u>Transactions</u> documentation.

   <b>APSW,</b> <b>an</b> <b>Advanced</b> <b>SQLite</b> <b>Driver</b>
       Peewee  also  comes  with  an  alternate SQLite database that uses <u>apsw,</u> <u>an</u> <u>advanced</u> <u>sqlite</u> <u>driver</u>.  More
       information on APSW can be obtained on the <u>APSW</u> <u>project</u> <u>website</u>. APSW provides special features like:

       • Virtual tables, virtual file-systems, Blob I/O, backups and file control.

       • Connections can be shared across threads without any additional locking.

       • Transactions are managed explicitly by your code.

       • Unicode is handled <u>correctly</u>.

       • APSW is faster that the standard library sqlite3 module.

       • Exposes pretty much the entire SQLite C API to your Python app.

       If you would like to use APSW, use the <u>APSWDatabase</u> from the <u>apsw_ext</u> module:

          from playhouse.apsw_ext import APSWDatabase

          apsw_db = APSWDatabase('my_app.db')

   <b>Using</b> <b>MariaDB</b>
       Peewee supports MariaDB. To use MariaDB, use the MySQL backend, which is  shared  between  the  two.  See
       <u>"Using</u> <u>MySQL"</u> for more details.

   <b>Using</b> <b>MySQL</b>
       To  connect  to  a  MySQL  database,  we will use <u>MySQLDatabase</u>. After the database name, you can specify
       arbitrary connection parameters that will be passed back to the driver (e.g. <b>pymysql</b> or <b>mysqlclient</b>).

          mysql_db = MySQLDatabase('my_database')

          class BaseModel(Model):
              """A base model that will use our MySQL database"""
              class Meta:
                  database = mysql_db

          class User(BaseModel):
              username = CharField()
              # etc, etc

       Driver information:

       • <u>pymysql</u> is a pure-python mysql client, works with python 2 and  3.  Peewee  will  use  attempt  to  use
         pymysql first.

       • <u>mysqlclient</u>  uses a c extension and supports python 3. It exposes a <b>MySQLdb</b> module. Peewee will attempt
         to use this module if pymysql is not installed.

       • <b>mysql-python</b> is also called <u>MySQLdb1</u> and is legacy and should not be used. Since this shares  the  same
         module name as mysqlclient, same applies.

       • <u>mysql-connector</u>  <u>python</u>  pure-python  (I  think??)  supports  python  3. To use this driver you can use
         MySQLConnectorDatabase from the <b>playhouse.mysql_ext</b> extension.

   <b>Error</b> <b>2006:</b> <b>MySQL</b> <b>server</b> <b>has</b> <b>gone</b> <b>away</b>
       This particular error can occur when MySQL kills an idle database  connection.   This  typically  happens
       with  web  apps  that  do  not  explicitly  manage database connections. What happens is your application
       starts, a connection is opened to handle the first query that executes, and,  since  that  connection  is
       never closed, it remains open, waiting for more queries.

       To  fix  this,  make sure you are explicitly connecting to the database when you need to execute queries,
       and close your connection when you are done. In a web-application, this typically means you will  open  a
       connection when a request comes in, and close the connection when you return a response.

       See  the  <u>Framework</u>  <u>Integration</u>  section  for  examples  of  configuring common web frameworks to manage
       database connections.

   <b>Connecting</b> <b>using</b> <b>a</b> <b>Database</b> <b>URL</b>
       The playhouse module <u>Database</u> <u>URL</u> provides a helper <u>connect()</u> function that accepts a  database  URL  and
       returns a <u>Database</u> instance.

       Example code:

          import os

          from peewee import *
          from playhouse.db_url import connect

          # Connect to the database URL defined in the environment, falling
          # back to a local Sqlite database if no database URL is specified.
          db = connect(os.environ.get('DATABASE') or 'sqlite:///default.db')

          class BaseModel(Model):
              class Meta:
                  database = db

       Example database URLs:

       • <b>sqlite:///my_database.db</b>  will  create  a  <u>SqliteDatabase</u>  instance  for the file <b>my_database.db</b> in the
         current directory.

       • <b>sqlite:///:memory:</b> will create an in-memory <u>SqliteDatabase</u> instance.

       • <b>postgresql://postgres:my_password@localhost:5432/my_database</b> will create a <u>PostgresqlDatabase</u> instance.
         A username and password are provided, as well as the host and port to connect to.

       • <b>mysql://user:passwd@ip:port/my_db</b> will create a <u>MySQLDatabase</u> instance for  the  local  MySQL  database
         <u>my_db</u>.

       • <u>More</u> <u>examples</u> <u>in</u> <u>the</u> <u>db_url</u> <u>documentation</u>.

   <b>Run-time</b> <b>database</b> <b>configuration</b>
       Sometimes  the database connection settings are not known until run-time, when these values may be loaded
       from a configuration file or the environment. In these cases, you can <u>defer</u>  the  initialization  of  the
       database by specifying <b>None</b> as the database_name.

          database = PostgresqlDatabase(None)  # Un-initialized database.

          class SomeModel(Model):
              class Meta:
                  database = database

       If  you  try  to  connect  or  issue  any  queries  while  your database is uninitialized you will get an
       exception:

          &gt;&gt;&gt; database.connect()
          Exception: Error, database not properly initialized before opening connection

       To initialize your database, call the <u>init()</u> method with the database name  and  any  additional  keyword
       arguments:

          database_name = input('What is the name of the db? ')
          database.init(database_name, host='localhost', user='postgres')

       For  even  more  control  over  initializing  your database, see the next section, <u>Dynamically</u> <u>defining</u> <u>a</u>
       <u>database</u>.

   <b>Dynamically</b> <b>defining</b> <b>a</b> <b>database</b>
       For even more control over how your database  is  defined/initialized,  you  can  use  the  <u>DatabaseProxy</u>
       helper.  <u>DatabaseProxy</u>  objects  act  as  a  placeholder,  and then at run-time you can swap it out for a
       different object. In the example below, we will swap out  the  database  depending  on  how  the  app  is
       configured:

          database_proxy = DatabaseProxy()  # Create a proxy for our db.

          class BaseModel(Model):
              class Meta:
                  database = database_proxy  # Use proxy for our DB.

          class User(BaseModel):
              username = CharField()

          # Based on configuration, use a different database.
          if app.config['DEBUG']:
              database = SqliteDatabase('local.db')
          elif app.config['TESTING']:
              database = SqliteDatabase(':memory:')
          else:
              database = PostgresqlDatabase('mega_production_db')

          # Configure our proxy to use the db we specified in config.
          database_proxy.initialize(database)

       <b>WARNING:</b>
          Only  use  this  method if your actual database driver varies at run-time. For instance, if your tests
          and local dev environment run on SQLite, but your deployed  app  uses  PostgreSQL,  you  can  use  the
          <u>DatabaseProxy</u> to swap out engines at run-time.

          However, if it is only connection values that vary at run-time, such as the path to the database file,
          or  the database host, you should instead use <u>Database.init()</u>. See <u>Run-time</u> <u>database</u> <u>configuration</u> for
          more details.

       <b>NOTE:</b>
          It may be easier to avoid the use of <u>DatabaseProxy</u> and instead use <u>Database.bind()</u> and related methods
          to set or change the database. See <u>Setting</u> <u>the</u> <u>database</u> <u>at</u> <u>run-time</u> for details.

   <b>Setting</b> <b>the</b> <b>database</b> <b>at</b> <b>run-time</b>
       We have seen three ways that databases can be configured with Peewee:

          # The usual way:
          db = SqliteDatabase('my_app.db', pragmas={'journal_mode': 'wal'})

          # Specify the details at run-time:
          db = SqliteDatabase(None)
          ...
          db.init(db_filename, pragmas={'journal_mode': 'wal'})

          # Or use a placeholder:
          db = DatabaseProxy()
          ...
          db.initialize(SqliteDatabase('my_app.db', pragmas={'journal_mode': 'wal'}))

       Peewee can also set or change the database for your model classes. This technique is used by  the  Peewee
       test suite to bind test model classes to various database instances when running the tests.

       There are two sets of complementary methods:

       • <u>Database.bind()</u> and <u>Model.bind()</u> - bind one or more models to a database.

       • <u>Database.bind_ctx()</u>  and <u>Model.bind_ctx()</u> - which are the same as their <b>bind()</b> counterparts, but return
         a context-manager and are useful when the database should only be changed temporarily.

       As an example, we'll declare two models <b>without</b> specifying any database:

          class User(Model):
              username = TextField()

          class Tweet(Model):
              user = ForeignKeyField(User, backref='tweets')
              content = TextField()
              timestamp = TimestampField()

       Bind the models to a database at run-time:

          postgres_db = PostgresqlDatabase('my_app', user='postgres')
          sqlite_db = SqliteDatabase('my_app.db')

          # At this point, the User and Tweet models are NOT bound to any database.

          # Let's bind them to the Postgres database:
          postgres_db.bind([User, Tweet])

          # Now we will temporarily bind them to the sqlite database:
          with sqlite_db.bind_ctx([User, Tweet]):
              # User and Tweet are now bound to the sqlite database.
              assert User._meta.database is sqlite_db

          # User and Tweet are once again bound to the Postgres database.
          assert User._meta.database is postgres_db

       The <u>Model.bind()</u> and <u>Model.bind_ctx()</u> methods work the same for binding a given model class:

          # Bind the user model to the sqlite db. By default, Peewee will also
          # bind any models that are related to User via foreign-key as well.
          User.bind(sqlite_db)

          assert User._meta.database is sqlite_db
          assert Tweet._meta.database is sqlite_db  # Related models bound too.

          # Here we will temporarily bind *just* the User model to the postgres db.
          with User.bind_ctx(postgres_db, bind_backrefs=False):
              assert User._meta.database is postgres_db
              assert Tweet._meta.database is sqlite_db  # Has not changed.

          # And now User is back to being bound to the sqlite_db.
          assert User._meta.database is sqlite_db

       The <u>Testing</u> <u>Peewee</u> <u>Applications</u> section of this document also contains some examples of using the  <b>bind()</b>
       methods.

   <b>Thread-Safety</b> <b>and</b> <b>Multiple</b> <b>Databases</b>
       If  you  plan  to  change  the  database at run-time in a multi-threaded application, storing the model's
       database in a thread-local will prevent race-conditions.  This can be accomplished with  a  custom  model
       <b>Metadata</b> class (see <u>ThreadSafeDatabaseMetadata</u>, included in <b>playhouse.shortcuts</b>):

          from peewee import *
          from playhouse.shortcuts import ThreadSafeDatabaseMetadata

          class BaseModel(Model):
              class Meta:
                  # Instruct peewee to use our thread-safe metadata implementation.
                  model_metadata_class = ThreadSafeDatabaseMetadata

       The  database  can now be swapped safely while running in a multi-threaded environment using the familiar
       <u>Database.bind()</u> or <u>Database.bind_ctx()</u> methods.

   <b>Connection</b> <b>Management</b>
       To open a connection to a database, use the <u>Database.connect()</u> method:

          &gt;&gt;&gt; db = SqliteDatabase(':memory:')  # In-memory SQLite database.
          &gt;&gt;&gt; db.connect()
          True

       If we try to call <b>connect()</b> on an already-open database, we get a <b>OperationalError</b>:

          &gt;&gt;&gt; db.connect()
          Traceback (most recent call last):
            File "&lt;stdin&gt;", line 1, in &lt;module&gt;
            File "/home/charles/pypath/peewee.py", line 2390, in connect
              raise OperationalError('Connection already opened.')
          peewee.OperationalError: Connection already opened.

       To prevent this exception from  being  raised,  we  can  call  <b>connect()</b>  with  an  additional  argument,
       <b>reuse_if_open</b>:

          &gt;&gt;&gt; db.close()  # Close connection.
          True
          &gt;&gt;&gt; db.connect()
          True
          &gt;&gt;&gt; db.connect(reuse_if_open=True)
          False

       Note that the call to <b>connect()</b> returns <b>False</b> if the database connection was already open.

       To close a connection, use the <u>Database.close()</u> method:

          &gt;&gt;&gt; db.close()
          True

       Calling <b>close()</b> on an already-closed connection will not result in an exception, but will return <b>False</b>:

          &gt;&gt;&gt; db.connect()  # Open connection.
          True
          &gt;&gt;&gt; db.close()  # Close connection.
          True
          &gt;&gt;&gt; db.close()  # Connection already closed, returns False.
          False

       You can test whether the database is closed using the <u>Database.is_closed()</u> method:

          &gt;&gt;&gt; db.is_closed()
          True

   <b>Using</b> <b>autoconnect</b>
       It  is not necessary to explicitly connect to the database before using it if the database is initialized
       with <b>autoconnect=True</b> (the default).  Managing connections explicitly  is  considered  a  <b>best</b>  <b>practice</b>,
       therefore you may consider disabling the <b>autoconnect</b> behavior.

       It is very helpful to be explicit about your connection lifetimes. If the connection fails, for instance,
       the  exception  will be caught when the connection is being opened, rather than some arbitrary time later
       when a query is executed. Furthermore, if using a <u>connection</u> <u>pool</u>, it is necessary to call <u>connect()</u>  and
       <u>close()</u> to ensure connections are recycled properly.

       For the best guarantee of correctness, disable <b>autoconnect</b>:

          db = PostgresqlDatabase('my_app', user='postgres', autoconnect=False)

   <b>Thread</b> <b>Safety</b>
       Peewee  keeps track of the connection state using thread-local storage, making the Peewee <u>Database</u> object
       safe to use with multiple threads. Each thread will have it's own connection, and as a result  any  given
       thread will only have a single connection open at a given time.

   <b>Context</b> <b>managers</b>
       The database object itself can be used as a context-manager, which opens a connection for the duration of
       the  wrapped  block  of code. Additionally, a transaction is opened at the start of the wrapped block and
       committed before the connection is closed (unless an error occurs,  in  which  case  the  transaction  is
       rolled back).

          &gt;&gt;&gt; db.is_closed()
          True
          &gt;&gt;&gt; with db:
          ...     print(db.is_closed())  # db is open inside context manager.
          ...
          False
          &gt;&gt;&gt; db.is_closed()  # db is closed.
          True

       If  you  want  to  manage  transactions separately, you can use the <u>Database.connection_context()</u> context
       manager.

          &gt;&gt;&gt; with db.connection_context():
          ...     # db connection is open.
          ...     pass
          ...
          &gt;&gt;&gt; db.is_closed()  # db connection is closed.
          True

       The <b>connection_context()</b> method can also be used as a decorator:

          @db.connection_context()
          def prepare_database():
              # DB connection will be managed by the decorator, which opens
              # a connection, calls function, and closes upon returning.
              db.create_tables(MODELS)  # Create schema.
              load_fixture_data(db)

   <b>DB-API</b> <b>Connection</b> <b>Object</b>
       To obtain a reference to the underlying DB-API 2.0 connection, use the <u>Database.connection()</u> method. This
       method will return the currently-open connection object, if one exists, otherwise  it  will  open  a  new
       connection.

          &gt;&gt;&gt; db.connection()
          &lt;sqlite3.Connection object at 0x7f94e9362f10&gt;

   <b>Connection</b> <b>Pooling</b>
       Connection pooling is provided by the <u>pool</u> <u>module</u>, included in the <u>playhouse</u> extensions library. The pool
       supports:

       • Timeout after which connections will be recycled.

       • Upper bound on the number of open connections.

          from playhouse.pool import PooledPostgresqlExtDatabase

          db = PooledPostgresqlExtDatabase(
              'my_database',
              max_connections=8,
              stale_timeout=300,
              user='postgres')

          class BaseModel(Model):
              class Meta:
                  database = db

       The following pooled database classes are available:

       • <u>PooledPostgresqlDatabase</u>

       • <u>PooledPostgresqlExtDatabase</u>

       • <u>PooledMySQLDatabase</u>

       • <u>PooledSqliteDatabase</u>

       • <u>PooledSqliteExtDatabase</u>

       For  an in-depth discussion of peewee's connection pool, see the <u>Connection</u> <u>pool</u> section of the <u>playhouse</u>
       documentation.

   <b>Testing</b> <b>Peewee</b> <b>Applications</b>
       When writing tests for an application that uses Peewee, it may be desirable to use a special database for
       tests. Another common practice is to run tests against a clean database, which means ensuring tables  are
       empty at the start of each test.

       To bind your models to a database at run-time, you can use the following methods:

       • <u>Database.bind_ctx()</u>,  which  returns  a context-manager that will bind the given models to the database
         instance for the duration of the wrapped block.

       • <u>Model.bind_ctx()</u>, which likewise returns a context-manager that binds the  model  (and  optionally  its
         dependencies) to the given database for the duration of the wrapped block.

       • <u>Database.bind()</u>,  which is a one-time operation that binds the models (and optionally its dependencies)
         to the given database.

       • <u>Model.bind()</u>, which is a one-time operation that binds the model (and optionally its  dependencies)  to
         the given database.

       Depending  on your use-case, one of these options may make more sense. For the examples below, I will use
       <u>Model.bind()</u>.

       Example test-case setup:

          # tests.py
          import unittest
          from my_app.models import EventLog, Relationship, Tweet, User

          MODELS = [User, Tweet, EventLog, Relationship]

          # use an in-memory SQLite for tests.
          test_db = SqliteDatabase(':memory:')

          class BaseTestCase(unittest.TestCase):
              def setUp(self):
                  # Bind model classes to test db. Since we have a complete list of
                  # all models, we do not need to recursively bind dependencies.
                  test_db.bind(MODELS, bind_refs=False, bind_backrefs=False)

                  test_db.connect()
                  test_db.create_tables(MODELS)

              def tearDown(self):
                  # Not strictly necessary since SQLite in-memory databases only live
                  # for the duration of the connection, and in the next step we close
                  # the connection...but a good practice all the same.
                  test_db.drop_tables(MODELS)

                  # Close connection to db.
                  test_db.close()

                  # If we wanted, we could re-bind the models to their original
                  # database here. But for tests this is probably not necessary.

       As an aside, and speaking from experience, I recommend testing your application using the  same  database
       backend you use in production, so as to avoid any potential compatibility issues.

       If  you'd  like  to  see  some  more  examples of how to run tests using Peewee, check out Peewee's own ‐
       <u>test-suite</u>.

   <b>Async</b> <b>with</b> <b>Gevent</b>
       <u>gevent</u> is recommended for doing asynchronous I/O with Postgresql or MySQL. Reasons I prefer gevent:

       • No need for special-purpose "loop-aware" re-implementations of <u>everything</u>.  Third-party libraries using
         asyncio usually have to re-implement layers and layers of code as well as re-implementing the protocols
         themselves.

       • Gevent allows you to write your application in normal, clean, idiomatic Python. No need to litter every
         line with "async", "await" and other noise.  No callbacks, futures, tasks, promises. No cruft.

       • Gevent works with both Python 2 <u>and</u> Python 3.

       • Gevent is <u>Pythonic</u>. Asyncio is an un-pythonic abomination.

       Besides monkey-patching socket, no special steps are required if you are using <b>MySQL</b> with a  pure  Python
       driver  like  <u>pymysql</u>  or  are using <u>mysql-connector</u> in pure-python mode. MySQL drivers written in C will
       require special configuration which is beyond the scope of this document.

       For <b>Postgres</b> and <u>psycopg2</u>, which is a C extension, you can use the following  code  snippet  to  register
       event hooks that will make your connection async:

          from gevent.socket import wait_read, wait_write
          from psycopg2 import extensions

          # Call this function after monkey-patching socket (etc).
          def patch_psycopg2():
              extensions.set_wait_callback(_psycopg2_gevent_callback)

          def _psycopg2_gevent_callback(conn, timeout=None):
              while True:
                  state = conn.poll()
                  if state == extensions.POLL_OK:
                      break
                  elif state == extensions.POLL_READ:
                      wait_read(conn.fileno(), timeout=timeout)
                  elif state == extensions.POLL_WRITE:
                      wait_write(conn.fileno(), timeout=timeout)
                  else:
                      raise ValueError('poll() returned unexpected result')

       <b>SQLite</b>,  because  it is embedded in the Python application itself, does not do any socket operations that
       would be a candidate for non-blocking. Async has no effect one way or the other on SQLite databases.

   <b>Framework</b> <b>Integration</b>
       For web applications, it is common to open a connection when a request is  received,  and  to  close  the
       connection  when  the response is delivered. In this section I will describe how to add hooks to your web
       app to ensure the database connection is handled properly.

       These steps will ensure that regardless of whether you're using a simple SQLite database, or  a  pool  of
       multiple Postgres connections, peewee will handle the connections correctly.

       <b>NOTE:</b>
          Applications  that  receive  lots  of traffic may benefit from using a <u>connection</u> <u>pool</u> to mitigate the
          cost of setting up and tearing down connections on every request.

   <b>Flask</b>
       Flask and peewee are a great combo and my go-to for projects of any size. Flask provides two hooks  which
       we  will  use  to open and close our db connection. We'll open the connection when a request is received,
       then close it when the response is returned.

          from flask import Flask
          from peewee import *

          database = SqliteDatabase('my_app.db')
          app = Flask(__name__)

          # This hook ensures that a connection is opened to handle any queries
          # generated by the request.
          @app.before_request
          def _db_connect():
              database.connect()

          # This hook ensures that the connection is closed when we've finished
          # processing the request.
          @app.teardown_request
          def _db_close(exc):
              if not database.is_closed():
                  database.close()

   <b>Django</b>
       While it's less common to see peewee used with Django, it is actually very easy to use the two. To manage
       your peewee database connections with Django, the easiest way in my opinion is to  add  a  middleware  to
       your  app.  The  middleware  should be the very first in the list of middlewares, to ensure it runs first
       when a request is handled, and last when the response is returned.

       If you have a django project named <u>my_blog</u> and your peewee database is defined in the module  <b>my_blog.db</b>,
       you might add the following middleware class:

          # middleware.py
          from my_blog.db import database  # Import the peewee database instance.

          def PeeweeConnectionMiddleware(get_response):
              def middleware(request):
                  database.connect()
                  try:
                      response = get_response(request)
                  finally:
                      if not database.is_closed():
                          database.close()
                  return response
              return middleware

          # Older Django &lt; 1.10 middleware.
          class PeeweeConnectionMiddleware(object):
              def process_request(self, request):
                  database.connect()

              def process_response(self, request, response):
                  if not database.is_closed():
                      database.close()
                  return response

       To ensure this middleware gets executed, add it to your <b>settings</b> module:

          # settings.py
          MIDDLEWARE_CLASSES = (
              # Our custom middleware appears first in the list.
              'my_blog.middleware.PeeweeConnectionMiddleware',

              # These are the default Django 1.7 middlewares. Yours may differ,
              # but the important this is that our Peewee middleware comes first.
              'django.middleware.common.CommonMiddleware',
              'django.contrib.sessions.middleware.SessionMiddleware',
              'django.middleware.csrf.CsrfViewMiddleware',
              'django.contrib.auth.middleware.AuthenticationMiddleware',
              'django.contrib.messages.middleware.MessageMiddleware',
          )

          # ... other Django settings ...

   <b>Bottle</b>
       I haven't used bottle myself, but looking at the documentation I believe the following code should ensure
       the database connections are properly managed:

          # app.py
          from bottle import hook  #, route, etc, etc.
          from peewee import *

          db = SqliteDatabase('my-bottle-app.db')

          @hook('before_request')
          def _connect_db():
              db.connect()

          @hook('after_request')
          def _close_db():
              if not db.is_closed():
                  db.close()

          # Rest of your bottle app goes here.

   <b>Web.py</b>
       See the documentation for <u>application</u> <u>processors</u>.

          db = SqliteDatabase('my_webpy_app.db')

          def connection_processor(handler):
              db.connect()
              try:
                  return handler()
              finally:
                  if not db.is_closed():
                      db.close()

          app.add_processor(connection_processor)

   <b>Tornado</b>
       It  looks  like  Tornado's  <b>RequestHandler</b> class implements two hooks which can be used to open and close
       connections when a request is handled.

          from tornado.web import RequestHandler

          db = SqliteDatabase('my_db.db')

          class PeeweeRequestHandler(RequestHandler):
              def prepare(self):
                  db.connect()
                  return super(PeeweeRequestHandler, self).prepare()

              def on_finish(self):
                  if not db.is_closed():
                      db.close()
                  return super(PeeweeRequestHandler, self).on_finish()

       In your app, instead of extending the default <b>RequestHandler</b>, now you can extend <b>PeeweeRequestHandler</b>.

       Note that this does not address how to use peewee asynchronously with Tornado or another event loop.

   <b>Wheezy.web</b>
       The connection handling code can be placed in a <u>middleware</u>.

          def peewee_middleware(request, following):
              db.connect()
              try:
                  response = following(request)
              finally:
                  if not db.is_closed():
                      db.close()
              return response

          app = WSGIApplication(middleware=[
              lambda x: peewee_middleware,
              # ... other middlewares ...
          ])

       Thanks to GitHub user <u>@tuukkamustonen</u> for submitting this code.

   <b>Falcon</b>
       The connection handling code can be placed in a <u>middleware</u> <u>component</u>.

          import falcon
          from peewee import *

          database = SqliteDatabase('my_app.db')

          class PeeweeConnectionMiddleware(object):
              def process_request(self, req, resp):
                  database.connect()

              def process_response(self, req, resp, resource, req_succeeded):
                  if not database.is_closed():
                      database.close()

          application = falcon.API(middleware=[
              PeeweeConnectionMiddleware(),
              # ... other middlewares ...
          ])

   <b>Pyramid</b>
       Set up a Request factory that handles database connection lifetime as follows:

          from pyramid.request import Request

          db = SqliteDatabase('pyramidapp.db')

          class MyRequest(Request):
              def __init__(self, *args, **kwargs):
                  super().__init__(*args, **kwargs)
                  db.connect()
                  self.add_finished_callback(self.finish)

              def finish(self, request):
                  if not db.is_closed():
                      db.close()

       In your application <u>main()</u> make sure <u>MyRequest</u> is used as <u>request_factory</u>:

          def main(global_settings, **settings):
              config = Configurator(settings=settings, ...)
              config.set_request_factory(MyRequest)

   <b>CherryPy</b>
       See <u>Publish/Subscribe</u> <u>pattern</u>.

          def _db_connect():
              db.connect()

          def _db_close():
              if not db.is_closed():
                  db.close()

          cherrypy.engine.subscribe('before_request', _db_connect)
          cherrypy.engine.subscribe('after_request', _db_close)

   <b>Sanic</b>
       In Sanic, the connection handling code can be  placed  in  the  request  and  response  middleware  <u>sanic</u>
       <u>middleware</u>.

          # app.py
          @app.middleware('request')
          async def handle_request(request):
              db.connect()

          @app.middleware('response')
          async def handle_response(request, response):
              if not db.is_closed():
                  db.close()

   <b>FastAPI</b>
       FastAPI  is  an  asyncio-compatible  framework. Peewee relies on thread locals (which are also compatible
       with gevent) to manage the connection state across requests. For use with  asyncio,  some  overrides  are
       necessary  to  replace  the  thread-local  behavior  with  an  asyncio-compatible  context-local.  Peewee
       recommends using Flask + gevent for lightweight async web-framework.

   <b>Other</b> <b>frameworks</b>
       Don't see your framework here? Please <u>open</u> <u>a</u> <u>GitHub</u> <u>ticket</u> and I'll see about adding a section, or better
       yet, submit a documentation pull-request.

   <b>Executing</b> <b>Queries</b>
       SQL queries  will  typically  be  executed  by  calling  <b>execute()</b>  on  a  query  constructed  using  the
       query-builder  APIs (or by simply iterating over a query object in the case of a <u>Select</u> query). For cases
       where you wish to execute SQL directly, you can use the <u>Database.execute_sql()</u> method.

          db = SqliteDatabase('my_app.db')
          db.connect()

          # Example of executing a simple query and ignoring the results.
          db.execute_sql("ATTACH DATABASE ':memory:' AS cache;")

          # Example of iterating over the results of a query using the cursor.
          cursor = db.execute_sql('SELECT * FROM users WHERE status = ?', (ACTIVE,))
          for row in cursor.fetchall():
              # Do something with row, which is a tuple containing column data.
              pass

   <b>Managing</b> <b>Transactions</b>
       Peewee  provides  several  interfaces  for  working  with  transactions.  The   most   general   is   the
       <u>Database.atomic()</u>  method,  which  also  supports  nested  transactions. <u>atomic()</u> blocks will be run in a
       transaction or savepoint, depending on the level of nesting.

       If an unhandled exception occurs in a wrapped block, the current  transaction/savepoint  will  be  rolled
       back. Otherwise the statements will be committed at the end of the wrapped block.

       Examples:

          # Transaction will commit automatically at the end of the "with" block:
          with db.atomic() as txn:
              User.create(username='u1')

          # Unhandled exceptions will cause transaction to be rolled-back:
          with db.atomic() as txn:
              User.create(username='huey')
              # User has been INSERTed into the database but the transaction is not
              # yet committed because we haven't left the scope of the "with" block.

              raise ValueError('uh-oh')
              # This exception is unhandled - the transaction will be rolled-back and
              # the ValueError will be raised.

       <b>NOTE:</b>
          While inside a block wrapped by the <u>atomic()</u> context manager, you can explicitly rollback or commit at
          any point by calling <b>Transaction.rollback()</b> or <b>Transaction.commit()</b>. When you do this inside a wrapped
          block of code, a new transaction will be started automatically.

              with db.atomic() as transaction:  # Opens new transaction.
                  try:
                      save_some_objects()
                  except ErrorSavingData:
                      # Because this block of code is wrapped with "atomic", a
                      # new transaction will begin automatically after the call
                      # to rollback().
                      transaction.rollback()
                      error_saving = True

                  create_report(error_saving=error_saving)
                  # Note: no need to call commit. Since this marks the end of the
                  # wrapped block of code, the `atomic` context manager will
                  # automatically call commit for us.

       <b>NOTE:</b>
          <u>atomic()</u> can be used as either a <b>context</b> <b>manager</b> or a <b>decorator</b>.

       <b>NOTE:</b>
          Peewee's  behavior  differs from the DB-API 2.0 behavior you may be used to (see PEP-249 for details).
          By default, Peewee puts all connections into <b>autocommit-mode</b> and transaction management is handled  by
          Peewee.

   <b>Context</b> <b>manager</b>
       Using <b>atomic</b> as context manager:

          db = SqliteDatabase(':memory:')

          with db.atomic() as txn:
              # This is the outer-most level, so this block corresponds to
              # a transaction.
              User.create(username='charlie')

              with db.atomic() as nested_txn:
                  # This block corresponds to a savepoint.
                  User.create(username='huey')

                  # This will roll back the above create() query.
                  nested_txn.rollback()

              User.create(username='mickey')

          # When the block ends, the transaction is committed (assuming no error
          # occurs). At that point there will be two users, "charlie" and "mickey".

       You can use the <b>atomic</b> method to perform <u>get</u> <u>or</u> <u>create</u> operations as well:

          try:
              with db.atomic():
                  user = User.create(username=username)
              return 'Success'
          except peewee.IntegrityError:
              return 'Failure: %s is already in use.' % username

   <b>Decorator</b>
       Using <b>atomic</b> as a decorator:

          @db.atomic()
          def create_user(username):
              # This statement will run in a transaction. If the caller is already
              # running in an `atomic` block, then a savepoint will be used instead.
              return User.create(username=username)

          create_user('charlie')

   <b>Nesting</b> <b>Transactions</b>
       <u>atomic()</u>  provides  transparent nesting of transactions. When using <u>atomic()</u>, the outer-most call will be
       wrapped in a transaction, and any nested calls will use savepoints.

          with db.atomic() as txn:
              perform_operation()

              with db.atomic() as nested_txn:
                  perform_another_operation()

       Peewee  supports  nested  transactions  through  the  use  of  savepoints  (for  more  information,   see
       <u>savepoint()</u>).

   <b>Explicit</b> <b>transaction</b>
       If  you  wish  to  explicitly  run  code  in  a  transaction,  you  can use <u>transaction()</u>. Like <u>atomic()</u>,
       <u>transaction()</u> can be used as a context manager or as a decorator.

       If an exception occurs in a wrapped block, the transaction will be rolled back.  Otherwise the statements
       will be committed at the end of the wrapped block.

          db = SqliteDatabase(':memory:')

          with db.transaction() as txn:
              # Delete the user and their associated tweets.
              user.delete_instance(recursive=True)

       Transactions can be explicitly committed or rolled-back within the wrapped block. When  this  happens,  a
       new transaction will be started.

          with db.transaction() as txn:
              User.create(username='mickey')
              txn.commit()  # Changes are saved and a new transaction begins.
              User.create(username='huey')

              # Roll back. "huey" will not be saved, but since "mickey" was already
              # committed, that row will remain in the database.
              txn.rollback()

          with db.transaction() as txn:
              User.create(username='whiskers')
              # Roll back changes, which removes "whiskers".
              txn.rollback()

              # Create a new row for "mr. whiskers" which will be implicitly committed
              # at the end of the `with` block.
              User.create(username='mr. whiskers')

       <b>NOTE:</b>
          If  you  attempt  to  nest  transactions with peewee using the <u>transaction()</u> context manager, only the
          outer-most transaction will be used. If an exception occurs in a nested block,  the  transaction  will
          NOT  be  rolled-back  --  only  exceptions that bubble-up to the outer-most transaction will trigger a
          rollback.

          As this may lead to unpredictable behavior, it is recommended that you use <u>atomic()</u>.

   <b>Explicit</b> <b>Savepoints</b>
       Just as you can explicitly create transactions, you can  also  explicitly  create  savepoints  using  the
       <u>savepoint()</u> method. Savepoints must occur within a transaction, but can be nested arbitrarily deep.

          with db.transaction() as txn:
              with db.savepoint() as sp:
                  User.create(username='mickey')

              with db.savepoint() as sp2:
                  User.create(username='zaizee')
                  sp2.rollback()  # "zaizee" will not be saved, but "mickey" will be.

       <b>WARNING:</b>
          If  you  manually  commit or roll back a savepoint, a new savepoint <b>will</b> <b>not</b> automatically be created.
          This differs from the behavior of <b>transaction</b>, which will automatically open a new  transaction  after
          manual commit/rollback.

   <b>Autocommit</b> <b>Mode</b>
       By  default,  Peewee  operates  in  <u>autocommit</u>  <u>mode</u>,  such  that  any  statements  executed outside of a
       transaction are run in their own transaction. To group multiple statements  into  a  transaction,  Peewee
       provides  the  <u>atomic()</u>  context-manager/decorator.  This should cover all use-cases, but in the unlikely
       event you want to temporarily disable  Peewee's  transaction  management  completely,  you  can  use  the
       <u>Database.manual_commit()</u> context-manager/decorator.

       Here is how you might emulate the behavior of the <u>transaction()</u> context manager:

          with db.manual_commit():
              db.begin()  # Have to begin transaction explicitly.
              try:
                  user.delete_instance(recursive=True)
              except:
                  db.rollback()  # Rollback! An error occurred.
                  raise
              else:
                  try:
                      db.commit()  # Commit changes.
                  except:
                      db.rollback()
                      raise

       Again -- I don't anticipate anyone needing this, but it's here just in case.

   <b>Database</b> <b>Errors</b>
       The  Python  DB-API  2.0  spec  describes <u>several</u> <u>types</u> <u>of</u> <u>exceptions</u>. Because most database drivers have
       their own implementations of these exceptions, Peewee simplifies things by  providing  its  own  wrappers
       around  any  implementation-specific exception classes. That way, you don't need to worry about importing
       any special exception classes, you can just use the ones from peewee:

       • <b>DatabaseError</b>

       • <b>DataError</b>

       • <b>IntegrityError</b>

       • <b>InterfaceError</b>

       • <b>InternalError</b>

       • <b>NotSupportedError</b>

       • <b>OperationalError</b>

       • <b>ProgrammingError</b>

       <b>NOTE:</b>
          All of these error classes extend <b>PeeweeException</b>.

   <b>Logging</b> <b>queries</b>
       All queries are logged to the <u>peewee</u> namespace using the standard library  <b>logging</b>  module.  Queries  are
       logged  using  the <u>DEBUG</u> level.  If you're interested in doing something with the queries, you can simply
       register a handler.

          # Print all queries to stderr.
          import logging
          logger = logging.getLogger('peewee')
          logger.addHandler(logging.StreamHandler())
          logger.setLevel(logging.DEBUG)

   <b>Adding</b> <b>a</b> <b>new</b> <b>Database</b> <b>Driver</b>
       Peewee comes with built-in support for Postgres, MySQL, MariaDB and SQLite.   These  databases  are  very
       popular and run the gamut from fast, embeddable databases to heavyweight servers suitable for large-scale
       deployments.   That  being  said, there are a ton of cool databases out there and adding support for your
       database-of-choice should be really easy, provided the driver supports the <u>DB-API</u> <u>2.0</u> <u>spec</u>.

       <b>WARNING:</b>
          Peewee requires the database connection be put into autocommit-mode.

       The DB-API 2.0 spec should be familiar to you  if  you've  used  the  standard  library  sqlite3  driver,
       psycopg2 or the like. Peewee currently relies on a handful of parts:

       • <u>Connection.commit</u>

       • <u>Connection.execute</u>

       • <u>Connection.rollback</u>

       • <u>Cursor.description</u>

       • <u>Cursor.fetchone</u>

       These  methods are generally wrapped up in higher-level abstractions and exposed by the <u>Database</u>, so even
       if your driver doesn't do these exactly you can still get a lot of mileage out of peewee.  An example  is
       the <u>apsw</u> <u>sqlite</u> <u>driver</u> in the "playhouse" module.

       The  first  thing  is  to  provide  a  subclass  of  <u>Database</u> that will open a connection, and ensure the
       connection is in autocommit-mode (thus disabling all the DB-API transaction semantics):

          from peewee import Database
          import foodb  # Our fictional DB-API 2.0 driver.

          class FooDatabase(Database):
              def _connect(self, database):
                  return foodb.connect(self.database, autocommit=True, **self.connect_params)

       The <u>Database</u> provides a higher-level API and is responsible for executing queries,  creating  tables  and
       indexes,  and introspecting the database to get lists of tables. The above implementation is the absolute
       minimum needed, though some features will not work -- for best results you will want to additionally  add
       a  method  for extracting a list of tables and indexes for a table from the database.  We'll pretend that
       <b>FooDB</b> is a lot like MySQL and has special "SHOW" statements:

          class FooDatabase(Database):
              def _connect(self):
                  return foodb.connect(self.database, autocommit=True, **self.connect_params)

              def get_tables(self):
                  res = self.execute('SHOW TABLES;')
                  return [r[0] for r in res.fetchall()]

       Other things the database handles that are not covered here include:

       • <u>last_insert_id()</u> and <u>rows_affected()</u>

       • <b>param</b> and <b>quote</b>, which tell the SQL-generating code how to add parameter placeholders and quote  entity
         names.

       • <b>field_types</b> for mapping data-types like INT or TEXT to their vendor-specific type names.

       • <b>operations</b> for mapping operations such as "LIKE/ILIKE" to their database equivalent

       Refer to the <u>Database</u> API reference or the <u>source</u> <u>code</u>. for details.

       <b>NOTE:</b>
          If  your  driver  conforms  to  the DB-API 2.0 spec, there shouldn't be much work needed to get up and
          running.

       Our new database can be used just like any of the other database subclasses:

          from peewee import *
          from foodb_ext import FooDatabase

          db = FooDatabase('my_database', user='foo', password='secret')

          class BaseModel(Model):
              class Meta:
                  database = db

          class Blog(BaseModel):
              title = CharField()
              contents = TextField()
              pub_date = DateTimeField()

   <b>Models</b> <b>and</b> <b>Fields</b>
       <u>Model</u> classes, <u>Field</u> instances and model instances all map to database concepts:
                                     ┌────────────────┬─────────────────────────┐
                                     │ Thing          │ Corresponds to...       │
                                     ├────────────────┼─────────────────────────┤
                                     │ Model class    │ Database table          │
                                     ├────────────────┼─────────────────────────┤
                                     │ Field instance │ Column on a table       │
                                     ├────────────────┼─────────────────────────┤
                                     │ Model instance │ Row in a database table │
                                     └────────────────┴─────────────────────────┘

       The following code shows the typical way you will define your database connection and model classes.

          import datetime
          from peewee import *

          db = SqliteDatabase('my_app.db')

          class BaseModel(Model):
              class Meta:
                  database = db

          class User(BaseModel):
              username = CharField(unique=True)

          class Tweet(BaseModel):
              user = ForeignKeyField(User, backref='tweets')
              message = TextField()
              created_date = DateTimeField(default=datetime.datetime.now)
              is_published = BooleanField(default=True)

       1. Create an instance of a <u>Database</u>.

                 db = SqliteDatabase('my_app.db')

             The <b>db</b> object will be used to manage the connections to the Sqlite database. In this example  we're
             using <u>SqliteDatabase</u>, but you could also use one of the other <u>database</u> <u>engines</u>.

       2. Create a base model class which specifies our database.

                 class BaseModel(Model):
                     class Meta:
                         database = db

             It  is  good  practice to define a base model class which establishes the database connection. This
             makes your code DRY as you will not have to specify the database for subsequent models.

             Model configuration is kept namespaced in a special class called <b>Meta</b>.  This convention is borrowed
             from Django. <u>Meta</u> configuration is passed on to  subclasses,  so  our  project's  models  will  all
             subclass <u>BaseModel</u>. There are <u>many</u> <u>different</u> <u>attributes</u> you can configure using <u>Model.Meta</u>.

       3. Define a model class.

                 class User(BaseModel):
                     username = CharField(unique=True)

             Model  definition  uses the declarative style seen in other popular ORMs like SQLAlchemy or Django.
             Note that we are extending the <u>BaseModel</u>  class  so  the  <u>User</u>  model  will  inherit  the  database
             connection.

             We  have  explicitly defined a single <u>username</u> column with a unique constraint. Because we have not
             specified a primary key, peewee will automatically add an  auto-incrementing  integer  primary  key
             field named <u>id</u>.

       <b>NOTE:</b>
          If you would like to start using peewee with an existing database, you can use <u>pwiz,</u> <u>a</u> <u>model</u> <u>generator</u>
          to automatically generate model definitions.

   <b>Fields</b>
       The  <u>Field</u> class is used to describe the mapping of <u>Model</u> attributes to database columns. Each field type
       has a corresponding SQL storage class (i.e. varchar, int), and conversion between python data  types  and
       underlying storage is handled transparently.

       When  creating  a <u>Model</u> class, fields are defined as class attributes. This should look familiar to users
       of the django framework. Here's an example:

          class User(Model):
              username = CharField()
              join_date = DateTimeField()
              about_me = TextField()

       In  the  above  example,  because  none  of  the  fields  are  initialized  with   <b>primary_key=True</b>,   an
       auto-incrementing  primary  key  will  automatically  be created and named "id". Peewee uses <u>AutoField</u> to
       signify an auto-incrementing integer primary key, which implies <b>primary_key=True</b>.

       There is one  special  type  of  field,  <u>ForeignKeyField</u>,  which  allows  you  to  represent  foreign-key
       relationships between models in an intuitive way:

          class Message(Model):
              user = ForeignKeyField(User, backref='messages')
              body = TextField()
              send_date = DateTimeField(default=datetime.datetime.now)

       This allows you to write code like the following:

          &gt;&gt;&gt; print(some_message.user.username)
          Some User

          &gt;&gt;&gt; for message in some_user.messages:
          ...     print(message.body)
          some message
          another message
          yet another message

       <b>NOTE:</b>
          Refer  to  the  <u>Relationships</u> <u>and</u> <u>Joins</u> document for an in-depth discussion of foreign-keys, joins and
          relationships between models.

       For full documentation on fields, see the <u>Fields</u> <u>API</u> <u>notes</u>

   <b>Field</b> <b>types</b> <b>table</b>
                     ┌───────────────────┬───────────────┬──────────────────┬──────────────────┐
                     │ Field Type        │ Sqlite        │ Postgresql       │ MySQL            │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>AutoField</b>         │ integer       │ serial           │ integer          │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BigAutoField</b>      │ integer       │ bigserial        │ bigint           │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>IntegerField</b>      │ integer       │ integer          │ integer          │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BigIntegerField</b>   │ integer       │ bigint           │ bigint           │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>SmallIntegerField</b> │ integer       │ smallint         │ smallint         │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>IdentityField</b>     │ not supported │ int identity     │ not supported    │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>FloatField</b>        │ real          │ real             │ real             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>DoubleField</b>       │ real          │ double precision │ double precision │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>DecimalField</b>      │ decimal       │ numeric          │ numeric          │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>CharField</b>         │ varchar       │ varchar          │ varchar          │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>FixedCharField</b>    │ char          │ char             │ char             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>TextField</b>         │ text          │ text             │ text             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BlobField</b>         │ blob          │ bytea            │ blob             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BitField</b>          │ integer       │ bigint           │ bigint           │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BigBitField</b>       │ blob          │ bytea            │ blob             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>UUIDField</b>         │ text          │ uuid             │ <a href="../man40/varchar.40.html">varchar</a>(40)      │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BinaryUUIDField</b>   │ blob          │ bytea            │ <a href="../man16/varbinary.16.html">varbinary</a>(16)    │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>DateTimeField</b>     │ datetime      │ timestamp        │ datetime         │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>DateField</b>         │ date          │ date             │ date             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>TimeField</b>         │ time          │ time             │ time             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>TimestampField</b>    │ integer       │ integer          │ integer          │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>IPField</b>           │ integer       │ bigint           │ bigint           │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BooleanField</b>      │ integer       │ boolean          │ bool             │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>BareField</b>         │ untyped       │ not supported    │ not supported    │
                     ├───────────────────┼───────────────┼──────────────────┼──────────────────┤
                     │ <b>ForeignKeyField</b>   │ integer       │ integer          │ integer          │
                     └───────────────────┴───────────────┴──────────────────┴──────────────────┘

       <b>NOTE:</b>
          Don't see the field you're looking for in the above table? It's easy to create custom field types  and
          use them with your models.

          • <u>Creating</u> <u>a</u> <u>custom</u> <u>field</u>

          • <u>Database</u>, particularly the <b>fields</b> parameter.

   <b>Field</b> <b>initialization</b> <b>arguments</b>
       Parameters accepted by all field types and their default values:

       • <b>null</b> <b>=</b> <b>False</b> -- allow null values

       • <b>index</b> <b>=</b> <b>False</b> -- create an index on this column

       • <b>unique</b> <b>=</b> <b>False</b> -- create a unique index on this column. See also <u>adding</u> <u>composite</u> <u>indexes</u>.

       • <b>column_name</b> <b>=</b> <b>None</b> -- explicitly specify the column name in the database.

       • <b>default</b> <b>=</b> <b>None</b> -- any value or callable to use as a default for uninitialized models

       • <b>primary_key</b> <b>=</b> <b>False</b> -- primary key for the table

       • <b>constraints</b> <b>=</b> <b>None</b> - one or more constraints, e.g. <b>[Check('price</b> <b>&gt;</b> <b>0')]</b>

       • <b>sequence</b> <b>=</b> <b>None</b> -- sequence name (if backend supports it)

       • <b>collation</b> <b>=</b> <b>None</b> -- collation to use for ordering the field / index

       • <b>unindexed</b> <b>=</b> <b>False</b> -- indicate field on virtual table should be unindexed (<b>SQLite-only</b>)

       • <b>choices</b> <b>=</b> <b>None</b> -- optional iterable containing 2-tuples of <b>value</b>, <b>display</b>

       • <b>help_text</b> <b>=</b> <b>None</b> -- string representing any helpful text for this field

       • <b>verbose_name</b> <b>=</b> <b>None</b> -- string representing the "user-friendly" name of this field

       • <b>index_type</b> <b>=</b> <b>None</b> -- specify a custom index-type, e.g. for Postgres you might specify a <b>'BRIN'</b> or <b>'GIN'</b>
         index.

   <b>Some</b> <b>fields</b> <b>take</b> <b>special</b> <b>parameters...</b>
                             ┌─────────────────┬───────────────────────────────────────┐
                             │ Field type      │ Special Parameters                    │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>CharField</u>       │ <b>max_length</b>                            │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>FixedCharField</u>  │ <b>max_length</b>                            │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>DateTimeField</u>   │ <b>formats</b>                               │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>DateField</u>       │ <b>formats</b>                               │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>TimeField</u>       │ <b>formats</b>                               │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>TimestampField</u>  │ <b>resolution</b>, <b>utc</b>                       │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>DecimalField</u>    │ <b>max_digits</b>,           <b>decimal_places</b>, │
                             │                 │ <b>auto_round</b>, <b>rounding</b>                  │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>ForeignKeyField</u> │ <b>model</b>,  <b>field</b>,  <b>backref</b>,   <b>on_delete</b>, │
                             │                 │ <b>on_update</b>, <b>deferrable</b> <b>lazy_load</b>       │
                             ├─────────────────┼───────────────────────────────────────┤
                             │ <u>BareField</u>       │ <b>adapt</b>                                 │
                             └─────────────────┴───────────────────────────────────────┘

       <b>NOTE:</b>
          Both  <b>default</b>  and  <b>choices</b> could be implemented at the database level as <u>DEFAULT</u> and <u>CHECK</u> <u>CONSTRAINT</u>
          respectively, but any application change would require a schema change. Because of  this,  <b>default</b>  is
          implemented purely in python and <b>choices</b> are not validated but exist for metadata purposes only.

          To add database (server-side) constraints, use the <b>constraints</b> parameter.

   <b>Default</b> <b>field</b> <b>values</b>
       Peewee  can  provide  default  values  for  fields  when  objects  are  created.  For  example to have an
       <b>IntegerField</b> default to zero rather than <b>NULL</b>, you could declare the field with a default value:

          class Message(Model):
              context = TextField()
              read_count = IntegerField(default=0)

       In some instances it may make sense for the default value to be dynamic. A common scenario is  using  the
       current date and time. Peewee allows you to specify a function in these cases, whose return value will be
       used when the object is created. Note we only provide the function, we do not actually <u>call</u> it:

          class Message(Model):
              context = TextField()
              timestamp = DateTimeField(default=datetime.datetime.now)

       <b>NOTE:</b>
          If  you  are  using a field that accepts a mutable type (<u>list</u>, <u>dict</u>, etc), and would like to provide a
          default, it is a good idea to wrap your default value in a simple  function  so  that  multiple  model
          instances are not sharing a reference to the same underlying object:

              def house_defaults():
                  return {'beds': 0, 'baths': 0}

              class House(Model):
                  number = TextField()
                  street = TextField()
                  attributes = JSONField(default=house_defaults)

       The  database can also provide the default value for a field. While peewee does not explicitly provide an
       API for setting a server-side default value, you can use the <b>constraints</b> parameter to specify the  server
       default:

          class Message(Model):
              context = TextField()
              timestamp = DateTimeField(constraints=[SQL('DEFAULT CURRENT_TIMESTAMP')])

       <b>NOTE:</b>
          <b>Remember:</b>  when  using the <b>default</b> parameter, the values are set by Peewee rather than being a part of
          the actual table and column definition.

   <b>ForeignKeyField</b>
       <u>ForeignKeyField</u> is a special field type that allows one model to reference another. Typically  a  foreign
       key  will  contain the primary key of the model it relates to (but you can specify a particular column by
       specifying a <b>field</b>).

       Foreign keys allow data to be <u>normalized</u>.  In our example models, there is a foreign key  from  <b>Tweet</b>  to
       <b>User</b>. This means that all the users are stored in their own table, as are the tweets, and the foreign key
       from tweet to user allows each tweet to <u>point</u> to a particular user object.

       <b>NOTE:</b>
          Refer  to  the  <u>Relationships</u> <u>and</u> <u>Joins</u> document for an in-depth discussion of foreign keys, joins and
          relationships between models.

       In peewee, accessing the value of a <u>ForeignKeyField</u> will return the entire related object, e.g.:

          tweets = (Tweet
                    .select(Tweet, User)
                    .join(User)
                    .order_by(Tweet.created_date.desc()))
          for tweet in tweets:
              print(tweet.user.username, tweet.message)

       <b>NOTE:</b>
          In the example above the <b>User</b> data was selected as part of the  query.   For  more  examples  of  this
          technique, see the <u>Avoiding</u> <u>N+1</u> document.

       If  we  did not select the <b>User</b>, though, then an <b>additional</b> <b>query</b> would be issued to fetch the associated
       <b>User</b> data:

          tweets = Tweet.select().order_by(Tweet.created_date.desc())
          for tweet in tweets:
              # WARNING: an additional query will be issued for EACH tweet
              # to fetch the associated User data.
              print(tweet.user.username, tweet.message)

       Sometimes you only need the associated primary key value from the  foreign  key  column.  In  this  case,
       Peewee  follows the convention established by Django, of allowing you to access the raw foreign key value
       by appending <b>"_id"</b> to the foreign key field's name:

          tweets = Tweet.select()
          for tweet in tweets:
              # Instead of "tweet.user", we will just get the raw ID value stored
              # in the column.
              print(tweet.user_id, tweet.message)

       To prevent accidentally resolving a foreign-key  and  triggering  an  additional  query,  <u>ForeignKeyField</u>
       supports  an  initialization  parameter <b>lazy_load</b> which, when disabled, behaves like the <b>"_id"</b> attribute.
       For example:

          class Tweet(Model):
              # ... same fields, except we declare the user FK to have
              # lazy-load disabled:
              user = ForeignKeyField(User, backref='tweets', lazy_load=False)

          for tweet in Tweet.select():
              print(tweet.user, tweet.message)

          # With lazy-load disabled, accessing tweet.user will not perform an extra
          # query and the user ID value is returned instead.
          # e.g.:
          # 1  tweet from user1
          # 1  another from user1
          # 2  tweet from user2

          # However, if we eagerly load the related user object, then the user
          # foreign key will behave like usual:
          for tweet in Tweet.select(Tweet, User).join(User):
              print(tweet.user.username, tweet.message)

          # user1  tweet from user1
          # user1  another from user1
          # user2  tweet from user1

   <b>ForeignKeyField</b> <b>Back-references</b>
       <u>ForeignKeyField</u> allows for a backreferencing property to be bound to the target model.  Implicitly,  this
       property  will  be  named  <b>classname_set</b>,  where <b>classname</b> is the lowercase name of the class, but can be
       overridden using the parameter <b>backref</b>:

          class Message(Model):
              from_user = ForeignKeyField(User, backref='outbox')
              to_user = ForeignKeyField(User, backref='inbox')
              text = TextField()

          for message in some_user.outbox:
              # We are iterating over all Messages whose from_user is some_user.
              <a href="../manmessage/print.message.html">print</a>(message)

          for message in some_user.inbox:
              # We are iterating over all Messages whose to_user is some_user
              <a href="../manmessage/print.message.html">print</a>(message)

   <b>DateTimeField,</b> <b>DateField</b> <b>and</b> <b>TimeField</b>
       The three fields devoted to working with dates and times have special properties which  allow  access  to
       things like the year, month, hour, etc.

       <u>DateField</u> has properties for:

       • <b>year</b>

       • <b>month</b>

       • <b>day</b>

       <u>TimeField</u> has properties for:

       • <b>hour</b>

       • <b>minute</b>

       • <b>second</b>

       <u>DateTimeField</u> has all of the above.

       These  properties  can  be  used just like any other expression. Let's say we have an events calendar and
       want to highlight all the days in the current month that have an event attached:

          # Get the current time.
          now = datetime.datetime.now()

          # Get days that have events for the current month.
          Event.select(Event.event_date.day.alias('day')).where(
              (Event.event_date.year == now.year) &amp;
              (Event.event_date.month == now.month))

       <b>NOTE:</b>
          SQLite does not have a native date type, so dates are stored in formatted text columns. To ensure that
          comparisons work correctly, the dates need to be formatted so they are sorted lexicographically.  That
          is why they are stored, by default, as <b>YYYY-MM-DD</b> <b>HH:MM:SS</b>.

   <b>BitField</b> <b>and</b> <b>BigBitField</b>
       The  <u>BitField</u> and <u>BigBitField</u> are new as of 3.0.0. The former provides a subclass of <u>IntegerField</u> that is
       suitable for storing feature toggles as an integer bitmask. The latter is suitable for storing  a  bitmap
       for a large data-set, e.g. expressing membership or bitmap-type data.

       As  an  example of using <u>BitField</u>, let's say we have a <u>Post</u> model and we wish to store certain True/False
       flags about how the post. We could store all these feature toggles in their own <u>BooleanField</u> objects,  or
       we could use <u>BitField</u> instead:

          class Post(Model):
              content = TextField()
              flags = BitField()

              is_favorite = <a href="../man1/flags.flag.1.html">flags.flag</a>(1)
              is_sticky = <a href="../man2/flags.flag.2.html">flags.flag</a>(2)
              is_minimized = <a href="../man4/flags.flag.4.html">flags.flag</a>(4)
              is_deleted = <a href="../man8/flags.flag.8.html">flags.flag</a>(8)

       Using these flags is quite simple:

          &gt;&gt;&gt; p = Post()
          &gt;&gt;&gt; p.is_sticky = True
          &gt;&gt;&gt; p.is_minimized = True
          &gt;&gt;&gt; print(p.flags)  # Prints 4 | 2 --&gt; "6"
          6
          &gt;&gt;&gt; p.is_favorite
          False
          &gt;&gt;&gt; p.is_sticky
          True

       We can also use the flags on the Post class to build expressions in queries:

          # Generates a WHERE clause that looks like:
          # WHERE (post.flags &amp; 1 != 0)
          favorites = Post.select().where(Post.is_favorite)

          # Query for sticky + favorite posts:
          sticky_faves = Post.select().where(Post.is_sticky &amp; Post.is_favorite)

       Since  the <u>BitField</u> is stored in an integer, there is a maximum of 64 flags you can represent (64-bits is
       common size of integer column). For storing arbitrarily large bitmaps, you can instead  use  <u>BigBitField</u>,
       which uses an automatically managed buffer of bytes, stored in a <u>BlobField</u>.

       When  bulk-updating  one or more bits in a <u>BitField</u>, you can use bitwise operators to set or clear one or
       more bits:

          # Set the 4th bit on all Post objects.
          Post.update(flags=Post.flags | 8).execute()

          # Clear the 1st and 3rd bits on all Post objects.
          Post.update(flags=Post.flags &amp; ~(1 | 4)).execute()

       For simple operations, the flags provide handy <b>set()</b> and <b>clear()</b>  methods  for  setting  or  clearing  an
       individual bit:

          # Set the "is_deleted" bit on all posts.
          Post.update(flags=Post.is_deleted.set()).execute()

          # Clear the "is_deleted" bit on all posts.
          Post.update(flags=Post.is_deleted.clear()).execute()

       Example usage:

          class Bitmap(Model):
              data = BigBitField()

          bitmap = Bitmap()

          # Sets the ith bit, e.g. the 1st bit, the 11th bit, the 63rd, etc.
          bits_to_set = (1, 11, 63, 31, 55, 48, 100, 99)
          for bit_idx in bits_to_set:
              bitmap.data.set_bit(bit_idx)

          # We can test whether a bit is set using "is_set":
          assert <a href="../man11/bitmap.data.is_set.11.html">bitmap.data.is_set</a>(11)
          assert not <a href="../man12/bitmap.data.is_set.12.html">bitmap.data.is_set</a>(12)

          # We can clear a bit:
          <a href="../man11/bitmap.data.clear_bit.11.html">bitmap.data.clear_bit</a>(11)
          assert not <a href="../man11/bitmap.data.is_set.11.html">bitmap.data.is_set</a>(11)

          # We can also "toggle" a bit. Recall that the 63rd bit was set earlier.
          assert <a href="../man63/bitmap.data.toggle_bit.63.html">bitmap.data.toggle_bit</a>(63) is False
          assert <a href="../man63/bitmap.data.toggle_bit.63.html">bitmap.data.toggle_bit</a>(63) is True
          assert <a href="../man63/bitmap.data.is_set.63.html">bitmap.data.is_set</a>(63)

          # BigBitField supports item accessor by bit-number, e.g.:
          assert bitmap.data[63]
          bitmap.data[0] = 1
          del bitmap.data[0]

          # We can also combine bitmaps using bitwise operators, e.g.
          b = Bitmap(data=b'\x01')
          b.data |= b'\x02'
          assert list(b.data) == [1, 1, 0, 0, 0, 0, 0, 0]
          assert len(b.data) == 1

   <b>BareField</b>
       The  <u>BareField</u>  class  is  intended  to  be  used  only with SQLite. Since SQLite uses dynamic typing and
       data-types are not enforced, it can be perfectly fine to declare fields without <u>any</u> data-type.  In  those
       cases  you  can use <u>BareField</u>. It is also common for SQLite virtual tables to use meta-columns or untyped
       columns, so for those cases as well you may wish to use an untyped field (although for full-text  search,
       you should use <u>SearchField</u> instead!).

       <u>BareField</u>  accepts a special parameter <b>adapt</b>. This parameter is a function that takes a value coming from
       the database and converts it into the appropriate Python type. For instance, if you have a virtual  table
       with an un-typed column but you know that it will return <b>int</b> objects, you can specify <b>adapt=int</b>.

       Example:

          db = SqliteDatabase(':memory:')

          class Junk(Model):
              anything = BareField()

              class Meta:
                  database = db

          # Store multiple data-types in the Junk.anything column:
          Junk.create(anything='a string')
          Junk.create(anything=12345)
          Junk.create(anything=3.14159)

   <b>Creating</b> <b>a</b> <b>custom</b> <b>field</b>
       It  is  easy to add support for custom field types in peewee. In this example we will create a UUID field
       for postgresql (which has a native UUID column type).

       To add a custom field type you need to first identify what type of column the field data will  be  stored
       in.  If  you just want to add python behavior atop, say, a decimal field (for instance to make a currency
       field) you would just subclass <u>DecimalField</u>. On the other hand, if the database offers  a  custom  column
       type you will need to let peewee know. This is controlled by the <b>Field.field_type</b> attribute.

       <b>NOTE:</b>
          Peewee ships with a <u>UUIDField</u>, the following code is intended only as an example.

       Let's start by defining our UUID field:

          class UUIDField(Field):
              field_type = 'uuid'

       We  will  store the UUIDs in a native UUID column. Since psycopg2 treats the data as a string by default,
       we will add two methods to the field to handle:

       • The data coming out of the database to be used in our application

       • The data from our python app going into the database

          import uuid

          class UUIDField(Field):
              field_type = 'uuid'

              def db_value(self, value):
                  return value.hex  # convert UUID to hex string.

              def python_value(self, value):
                  return uuid.UUID(value) # convert hex string to UUID

       <b>This</b> <b>step</b> <b>is</b> <b>optional.</b> By default, the <b>field_type</b> value will be used for the  columns  data-type  in  the
       database  schema.  If  you  need  to  support  multiple databases which use different data-types for your
       field-data, we need to let the database know how to map this <u>uuid</u> label to an actual <u>uuid</u> column type  in
       the database. Specify the overrides in the <u>Database</u> constructor:

              # Postgres, we use UUID data-type.
              db = PostgresqlDatabase('my_db', field_types={'uuid': 'uuid'})

              # Sqlite doesn't have a UUID type, so we use text type.
              db = SqliteDatabase('my_db', field_types={'uuid': 'text'})

       That  is  it!  Some  fields  may  support exotic operations, like the postgresql HStore field acts like a
       key/value store and has custom operators for things like <u>contains</u> and  <u>update</u>.  You  can  specify  <u>custom</u>
       <u>operations</u>   as   well.   For   example  code,  check  out  the  source  code  for  the  <u>HStoreField</u>,  in
       <b>playhouse.postgres_ext</b>.

   <b>Field-naming</b> <b>conflicts</b>
       <u>Model</u>  classes  implement  a  number  of  class-  and  instance-methods,  for  example  <u>Model.save()</u>   or
       <u>Model.create()</u>. If you declare a field whose name coincides with a model method, it could cause problems.
       Consider:

          class LogEntry(Model):
              event = TextField()
              create = TimestampField()  # Uh-oh.
              update = TimestampField()  # Uh-oh.

       To  avoid  this  problem  while  still  using  the desired column name in the database schema, explicitly
       specify the <b>column_name</b> while providing an alternative name for the field attribute:

          class LogEntry(Model):
              event = TextField()
              create_ = TimestampField(column_name='create')
              update_ = TimestampField(column_name='update')

   <b>Creating</b> <b>model</b> <b>tables</b>
       In order to start using our models, its necessary to open a connection to the  database  and  create  the
       tables  first.  Peewee will run the necessary <u>CREATE</u> <u>TABLE</u> queries, additionally creating any constraints
       and indexes.

          # Connect to our database.
          db.connect()

          # Create the tables.
          db.create_tables([User, Tweet])

       <b>NOTE:</b>
          Strictly speaking, it is not necessary to call <u>connect()</u> but it is good practice to be explicit.  That
          way  if  something  goes  wrong, the error occurs at the connect step, rather than some arbitrary time
          later.

       <b>NOTE:</b>
          By default, Peewee includes an <b>IF</b> <b>NOT</b> <b>EXISTS</b> clause when creating tables. If you want to disable this,
          specify <b>safe=False</b>.

       After you have created your tables, if you choose to modify your database schema (by adding, removing  or
       otherwise changing the columns) you will need to either:

       • Drop the table and re-create it.

       • Run  one  or  more  <u>ALTER</u>  <u>TABLE</u>  queries.  Peewee comes with a schema migration tool which can greatly
         simplify this. Check the <u>schema</u> <u>migrations</u> docs for details.

   <b>Model</b> <b>options</b> <b>and</b> <b>table</b> <b>metadata</b>
       In order not to pollute the model namespace, model-specific configuration is placed in  a  special  class
       called <u>Meta</u> (a convention borrowed from the django framework):

          from peewee import *

          contacts_db = SqliteDatabase('contacts.db')

          class Person(Model):
              name = CharField()

              class Meta:
                  database = contacts_db

       This instructs peewee that whenever a query is executed on <u>Person</u> to use the contacts database.

       <b>NOTE:</b>
          Take  a  look  at  <u>the</u>  <u>sample</u>  <u>models</u>  - you will notice that we created a <b>BaseModel</b> that defined the
          database, and then extended. This is the preferred way to define a database and create models.

       Once the class is defined, you should not access <b>ModelClass.Meta</b>, but instead use <b>ModelClass._meta</b>:

          &gt;&gt;&gt; Person.Meta
          Traceback (most recent call last):
            File "&lt;stdin&gt;", line 1, in &lt;module&gt;
          AttributeError: type object 'Person' has no attribute 'Meta'

          &gt;&gt;&gt; Person._meta
          &lt;peewee.ModelOptions object at 0x7f51a2f03790&gt;

       The <b>ModelOptions</b> class implements several methods which may be of use for retrieving model metadata (such
       as lists of fields, foreign key relationships, and more).

          &gt;&gt;&gt; Person._meta.fields
          {'id': &lt;peewee.AutoField object at 0x7f51a2e92750&gt;,
           'name': &lt;peewee.CharField object at 0x7f51a2f0a510&gt;}

          &gt;&gt;&gt; Person._meta.primary_key
          &lt;peewee.AutoField object at 0x7f51a2e92750&gt;

          &gt;&gt;&gt; Person._meta.database
          &lt;peewee.SqliteDatabase object at 0x7f519bff6dd0&gt;

       There are several options you can specify as <b>Meta</b> attributes. While most options  are  inheritable,  some
       are table-specific and will not be inherited by subclasses.
                         ┌────────────────────┬──────────────────────────────┬──────────────┐
                         │ Option             │ Meaning                      │ Inheritable? │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>database</b>           │ database for model           │ yes          │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>table_name</b>         │ name  of  the table to store │ no           │
                         │                    │ data                         │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>table_function</b>     │ function to  generate  table │ yes          │
                         │                    │ name dynamically             │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>indexes</b>            │ a list of fields to index    │ yes          │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>primary_key</b>        │ a <u>CompositeKey</u> instance      │ yes          │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>constraints</b>        │ a list of table constraints  │ yes          │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>schema</b>             │ the  database schema for the │ yes          │
                         │                    │ model                        │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>only_save_dirty</b>    │ when  calling  model.save(), │ yes          │
                         │                    │ only save dirty fields       │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>options</b>            │ dictionary  of  options  for │ yes          │
                         │                    │ create table extensions      │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>table_settings</b>     │ list of setting  strings  to │ yes          │
                         │                    │ go after close parentheses   │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>temporary</b>          │ indicate temporary table     │ yes          │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>legacy_table_names</b> │ use    legacy   table   name │ yes          │
                         │                    │ generation    (enabled    by │              │
                         │                    │ default)                     │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>depends_on</b>         │ indicate  this table depends │ no           │
                         │                    │ on another for creation      │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>without_rowid</b>      │ indicate  table  should  not │ no           │
                         │                    │ have rowid (SQLite only)     │              │
                         ├────────────────────┼──────────────────────────────┼──────────────┤
                         │ <b>strict_tables</b>      │ indicate  strict  data-types │ yes          │
                         │                    │ (SQLite only, 3.37+)         │              │
                         └────────────────────┴──────────────────────────────┴──────────────┘

       Here is an example showing inheritable versus non-inheritable attributes:

          &gt;&gt;&gt; db = SqliteDatabase(':memory:')
          &gt;&gt;&gt; class ModelOne(Model):
          ...     class Meta:
          ...         database = db
          ...         table_name = 'model_one_tbl'
          ...
          &gt;&gt;&gt; class ModelTwo(ModelOne):
          ...     pass
          ...
          &gt;&gt;&gt; ModelOne._meta.database is ModelTwo._meta.database
          True
          &gt;&gt;&gt; ModelOne._meta.table_name == ModelTwo._meta.table_name
          False

   <b>Meta.primary_key</b>
       The <b>Meta.primary_key</b> attribute is used to specify either a <u>CompositeKey</u> or to indicate that the model has
       <u>no</u> primary key.  Composite primary keys are discussed in more detail here: <u>Composite</u> <u>primary</u> <u>keys</u>.

       To indicate that a model should not have a primary key, then set <b>primary_key</b> <b>=</b> <b>False</b>.

       Examples:

          class BlogToTag(Model):
              """A simple "through" table for many-to-many relationship."""
              blog = ForeignKeyField(Blog)
              tag = ForeignKeyField(Tag)

              class Meta:
                  primary_key = CompositeKey('blog', 'tag')

          class NoPrimaryKey(Model):
              data = IntegerField()

              class Meta:
                  primary_key = False

   <b>Table</b> <b>Names</b>
       By default Peewee will automatically generate a table name based on the name of your model class. The way
       the  table-name  is  generated  depends  on   the   value   of   <b>Meta.legacy_table_names</b>.   By   default,
       <b>legacy_table_names=True</b>  so as to avoid breaking backwards-compatibility. However, if you wish to use the
       new and improved table-name generation, you can specify <b>legacy_table_names=False</b>.

       This table shows the differences in how a model name is converted to a SQL table name, depending  on  the
       value of <b>legacy_table_names</b>:
                      ┌──────────────────┬─────────────────────────┬──────────────────────────┐
                      │ Model name       │ legacy_table_names=True │ legacy_table_names=False │
                      │                  │                         │ (new)                    │
                      ├──────────────────┼─────────────────────────┼──────────────────────────┤
                      │ User             │ user                    │ user                     │
                      ├──────────────────┼─────────────────────────┼──────────────────────────┤
                      │ UserProfile      │ userprofile             │ user_profile             │
                      ├──────────────────┼─────────────────────────┼──────────────────────────┤
                      │ APIResponse      │ apiresponse             │ api_response             │
                      ├──────────────────┼─────────────────────────┼──────────────────────────┤
                      │ WebHTTPRequest   │ webhttprequest          │ web_http_request         │
                      ├──────────────────┼─────────────────────────┼──────────────────────────┤
                      │ mixedCamelCase   │ mixedcamelcase          │ mixed_camel_case         │
                      ├──────────────────┼─────────────────────────┼──────────────────────────┤
                      │ Name2Numbers3XYZ │ name2numbers3xyz        │ name2_numbers3_xyz       │
                      └──────────────────┴─────────────────────────┴──────────────────────────┘

       <b>ATTENTION:</b>
          To    preserve    backwards-compatibility,    the    current    release    (Peewee    3.x)   specifies
          <b>legacy_table_names=True</b> by default.

          In the next major release (Peewee 4.0), <b>legacy_table_names</b> will have a default value of <b>False</b>.

       To explicitly specify the table name for a model class, use the <b>table_name</b> Meta option. This feature  can
       be useful for dealing with pre-existing database schemas that may have used awkward naming conventions:

          class UserProfile(Model):
              class Meta:
                  table_name = 'user_profile_tbl'

       If you wish to implement your own naming convention, you can specify the <b>table_function</b> Meta option. This
       function  will  be  called  with  your  model class and should return the desired table name as a string.
       Suppose our company specifies that table names  should  be  lower-cased  and  end  with  "_tbl",  we  can
       implement this as a table function:

          def <a href="../manmodel_class/make_table_name.model_class.html">make_table_name</a>(model_class):
              model_name = model_class.__name__
              return model_name.lower() + '_tbl'

          class BaseModel(Model):
              class Meta:
                  table_function = make_table_name

          class User(BaseModel):
              # table_name will be "user_tbl".

          class UserProfile(BaseModel):
              # table_name will be "userprofile_tbl".

   <b>Indexes</b> <b>and</b> <b>Constraints</b>
       Peewee can create indexes on single or multiple columns, optionally including a <u>UNIQUE</u> constraint. Peewee
       also supports user-defined constraints on both models and fields.

   <b>Single-column</b> <b>indexes</b> <b>and</b> <b>constraints</b>
       Single  column  indexes  are  defined using field initialization parameters. The following example adds a
       unique index on the <u>username</u> field, and a normal index on the <u>email</u> field:

          class User(Model):
              username = CharField(unique=True)
              email = CharField(index=True)

       To add a user-defined constraint on a column, you can pass it in using the <b>constraints</b> parameter. You may
       wish to specify a default value as part of the schema, or add a <b>CHECK</b> constraint, for example:

          class Product(Model):
              name = CharField(unique=True)
              price = DecimalField(constraints=[Check('price &lt; 10000')])
              created = DateTimeField(
                  constraints=[SQL("DEFAULT (datetime('now'))")])

   <b>Multi-column</b> <b>indexes</b>
       Multi-column indexes may be defined as <u>Meta</u> attributes using a nested tuple.  Each database  index  is  a
       2-tuple,  the  first  part  of  which  is  a  tuple of the names of the fields, the second part a boolean
       indicating whether the index should be unique.

          class Transaction(Model):
              from_acct = CharField()
              to_acct = CharField()
              amount = DecimalField()
              date = DateTimeField()

              class Meta:
                  indexes = (
                      # create a unique on from/to/date
                      (('from_acct', 'to_acct', 'date'), True),

                      # create a non-unique on from/to
                      (('from_acct', 'to_acct'), False),
                  )

       <b>NOTE:</b>
          Remember to add a <b>trailing</b> <b>comma</b> if your tuple of indexes contains only one item:

              class Meta:
                  indexes = (
                      (('first_name', 'last_name'), True),  # Note the trailing comma!
                  )

   <b>Advanced</b> <b>Index</b> <b>Creation</b>
       Peewee supports a more structured API for declaring indexes on a model using the <u>Model.add_index()</u> method
       or by directly using the <u>ModelIndex</u> helper class.

       Examples:

          class Article(Model):
              name = TextField()
              timestamp = TimestampField()
              status = IntegerField()
              flags = IntegerField()

          # Add an index on "name" and "timestamp" columns.
          Article.add_index(Article.name, Article.timestamp)

          # Add a partial index on name and timestamp where status = 1.
          Article.add_index(Article.name, Article.timestamp,
                            where=(Article.status == 1))

          # Create a unique index on timestamp desc, status &amp; 4.
          idx = Article.index(
              Article.timestamp.desc(),
              <a href="../man4/Article.flags.bin_and.4.html">Article.flags.bin_and</a>(4),
              unique=True)
          Article.add_index(idx)

       <b>WARNING:</b>
          SQLite does not support parameterized <b>CREATE</b> <b>INDEX</b> queries. This  means  that  when  using  SQLite  to
          create  an index that involves an expression or scalar value, you will need to declare the index using
          the <u>SQL</u> helper:

              # SQLite does not support parameterized CREATE INDEX queries, so
              # we declare it manually.
              Article.add_index(SQL('CREATE INDEX ...'))

          See <u>add_index()</u> for details.

       For more information, see:

       • <u>Model.add_index()</u>

       • <u>Model.index()</u>

       • <u>ModelIndex</u>

       • <u>Index</u>

   <b>Table</b> <b>constraints</b>
       Peewee allows you to add arbitrary constraints to your <u>Model</u>, that will be part of the  table  definition
       when the schema is created.

       For  instance,  suppose you have a <u>people</u> table with a composite primary key of two columns, the person's
       first and last name. You wish to have another table relate to the <u>people</u> table, and to do this, you  will
       need to define a foreign key constraint:

          class Person(Model):
              first = CharField()
              last = CharField()

              class Meta:
                  primary_key = CompositeKey('first', 'last')

          class Pet(Model):
              owner_first = CharField()
              owner_last = CharField()
              pet_name = CharField()

              class Meta:
                  constraints = [SQL('FOREIGN KEY(owner_first, owner_last) '
                                     'REFERENCES person(first, last)')]

       You can also implement <b>CHECK</b> constraints at the table level:

          class Product(Model):
              name = CharField(unique=True)
              price = DecimalField()

              class Meta:
                  constraints = [Check('price &lt; 10000')]

   <b>Primary</b> <b>Keys,</b> <b>Composite</b> <b>Keys</b> <b>and</b> <b>other</b> <b>Tricks</b>
       The  <u>AutoField</u>  is  used  to  identify  an auto-incrementing integer primary key. If you do not specify a
       primary key, Peewee will automatically create an auto-incrementing primary key named "id".

       To specify an auto-incrementing ID using a different field name, you can write:

          class Event(Model):
              event_id = AutoField()  # Event.event_id will be auto-incrementing PK.
              name = CharField()
              timestamp = DateTimeField(default=datetime.datetime.now)
              metadata = BlobField()

       You can identify a different field as the primary key, in which case an "id" column will not be  created.
       In this example we will use a person's email address as the primary key:

          class Person(Model):
              email = CharField(primary_key=True)
              name = TextField()
              dob = DateField()

       <b>WARNING:</b>
          I frequently see people write the following, expecting an auto-incrementing integer primary key:

              class MyModel(Model):
                  id = IntegerField(primary_key=True)

          Peewee  understands  the above model declaration as a model with an integer primary key, but the value
          of that ID is determined by the application. To create an auto-incrementing integer primary  key,  you
          would instead write:

              class MyModel(Model):
                  id = AutoField()  # primary_key=True is implied.

       Composite  primary  keys  can  be declared using <u>CompositeKey</u>. Note that doing this may cause issues with
       <u>ForeignKeyField</u>, as Peewee does not support the concept of a "composite foreign-key". As such, I've found
       it only advisable to use composite primary keys in a handful of situations, such as trivial  many-to-many
       junction tables:

          class Image(Model):
              filename = TextField()
              mimetype = CharField()

          class Tag(Model):
              label = CharField()

          class ImageTag(Model):  # Many-to-many relationship.
              image = ForeignKeyField(Image)
              tag = ForeignKeyField(Tag)

              class Meta:
                  primary_key = CompositeKey('image', 'tag')

       In the extremely rare case you wish to declare a model with <u>no</u> primary key, you can specify <b>primary_key</b> <b>=</b>
       <b>False</b> in the model <b>Meta</b> options.

   <b>Non-integer</b> <b>primary</b> <b>keys</b>
       If  you  would  like  use  a non-integer primary key (which I generally don't recommend), you can specify
       <b>primary_key=True</b> when creating a field. When you wish to create a  new  instance  for  a  model  using  a
       non-autoincrementing primary key, you need to be sure you <u>save()</u> specifying <b>force_insert=True</b>.

          from peewee import *

          class UUIDModel(Model):
              id = UUIDField(primary_key=True)

       Auto-incrementing  IDs are, as their name says, automatically generated for you when you insert a new row
       into the database. When you call <u>save()</u>, peewee determines whether to do an <u>INSERT</u> versus an <u>UPDATE</u> based
       on the presence of a primary key value. Since, with our uuid example, the database driver won't  generate
       a  new ID, we need to specify it manually. When we call save() for the first time, pass in <b>force_insert</b> <b>=</b>
       <b>True</b>:

          # This works because .create() will specify `force_insert=True`.
          obj1 = UUIDModel.create(id=uuid.uuid4())

          # This will not work, however. Peewee will attempt to do an update:
          obj2 = UUIDModel(id=uuid.uuid4())
          obj2.save() # WRONG

          obj2.save(force_insert=True) # CORRECT

          # Once the object has been created, you can call save() normally.
          obj2.save()

       <b>NOTE:</b>
          Any foreign keys to a model with a non-integer primary key will have a <b>ForeignKeyField</b>  use  the  same
          underlying storage type as the primary key they are related to.

   <b>Composite</b> <b>primary</b> <b>keys</b>
       Peewee  has  very  basic  support  for composite keys.  In order to use a composite key, you must set the
       <b>primary_key</b> attribute of the model options to a <u>CompositeKey</u> instance:

          class BlogToTag(Model):
              """A simple "through" table for many-to-many relationship."""
              blog = ForeignKeyField(Blog)
              tag = ForeignKeyField(Tag)

              class Meta:
                  primary_key = CompositeKey('blog', 'tag')

       <b>WARNING:</b>
          Peewee does not support foreign-keys to models that define a <u>CompositeKey</u> primary key. If you wish  to
          add  a  foreign-key  to a model that has a composite primary key, replicate the columns on the related
          model and add a custom accessor (e.g. a property).

   <b>Manually</b> <b>specifying</b> <b>primary</b> <b>keys</b>
       Sometimes you do not want the database to automatically  generate  a  value  for  the  primary  key,  for
       instance when bulk loading relational data. To handle this on a <u>one-off</u> basis, you can simply tell peewee
       to turn off <b>auto_increment</b> during the import:

          data = load_user_csv() # load up a bunch of data

          User._meta.auto_increment = False # turn off auto incrementing IDs
          with db.atomic():
              for row in data:
                  u = User(id=row[0], username=row[1])
                  u.save(force_insert=True) # &lt;-- force peewee to insert row

          User._meta.auto_increment = True

       Although   a   better  way  to  accomplish  the  above,  without  resorting  to  hacks,  is  to  use  the
       <u>Model.insert_many()</u> API:

          data = load_user_csv()
          fields = [User.id, User.username]
          with db.atomic():
              User.insert_many(data, fields=fields).execute()

       If you <u>always</u> want to have control over the primary key, simply do not use the <u>AutoField</u> field type,  but
       use a normal <u>IntegerField</u> (or other column type):

          class User(BaseModel):
              id = IntegerField(primary_key=True)
              username = CharField()

          &gt;&gt;&gt; u = User.create(id=999, username='somebody')
          &gt;&gt;&gt; u.id
          999
          &gt;&gt;&gt; User.get(User.username == 'somebody').id
          999

   <b>Models</b> <b>without</b> <b>a</b> <b>Primary</b> <b>Key</b>
       If  you wish to create a model with no primary key, you can specify <b>primary_key</b> <b>=</b> <b>False</b> in the inner <b>Meta</b>
       class:

          class MyData(BaseModel):
              timestamp = DateTimeField()
              value = IntegerField()

              class Meta:
                  primary_key = False

       This will yield the following DDL:

          CREATE TABLE "mydata" (
            "timestamp" DATETIME NOT NULL,
            "value" INTEGER NOT NULL
          )

       <b>WARNING:</b>
          Some model APIs may not work correctly for models without a  primary  key,  for  instance  <u>save()</u>  and
          <u>delete_instance()</u> (you can instead use <u>insert()</u>, <u>update()</u> and <u>delete()</u>).

   <b>Self-referential</b> <b>foreign</b> <b>keys</b>
       When  creating  a  hierarchical  structure it is necessary to create a self-referential foreign key which
       links a child object to its parent.  Because the model class is not defined at the time  you  instantiate
       the  self-referential  foreign  key, use the special string <b>'self'</b> to indicate a self-referential foreign
       key:

          class Category(Model):
              name = CharField()
              parent = ForeignKeyField('self', null=True, backref='children')

       As you can see, the foreign key points <u>upward</u> to the  parent  object  and  the  back-reference  is  named
       <u>children</u>.

       <b>ATTENTION:</b>
          Self-referential foreign-keys should always be <b>null=True</b>.

       When  querying  against  a  model  that contains a self-referential foreign key you may sometimes need to
       perform a self-join. In those cases you can use <u>Model.alias()</u> to create a table reference.  Here  is  how
       you might query the category and parent model using a self-join:

          Parent = Category.alias()
          GrandParent = Category.alias()
          query = (Category
                   .select(Category, Parent)
                   .join(Parent, on=(Category.parent == Parent.id))
                   .join(GrandParent, on=(Parent.parent == GrandParent.id))
                   .where(GrandParent.name == 'some category')
                   .order_by(Category.name))

   <b>Circular</b> <b>foreign</b> <b>key</b> <b>dependencies</b>
       Sometimes it happens that you will create a circular dependency between two tables.

       <b>NOTE:</b>
          My personal opinion is that circular foreign keys are a code smell and should be refactored (by adding
          an intermediary table, for instance).

       Adding  circular  foreign  keys  with  peewee is a bit tricky because at the time you are defining either
       foreign key, the model it points to will not have been defined yet, causing a <b>NameError</b>.

          class User(Model):
              username = CharField()
              favorite_tweet = ForeignKeyField(Tweet, null=True)  # NameError!!

          class Tweet(Model):
              message = TextField()
              user = ForeignKeyField(User, backref='tweets')

       One option is to simply use an <u>IntegerField</u> to store the raw ID:

          class User(Model):
              username = CharField()
              favorite_tweet_id = IntegerField(null=True)

       By using <u>DeferredForeignKey</u> we can get around the problem and still use a foreign key field:

          class User(Model):
              username = CharField()
              # Tweet has not been defined yet so use the deferred reference.
              favorite_tweet = DeferredForeignKey('Tweet', null=True)

          class Tweet(Model):
              message = TextField()
              user = ForeignKeyField(User, backref='tweets')

          # Now that Tweet is defined, "favorite_tweet" has been converted into
          # a ForeignKeyField.
          print(User.favorite_tweet)
          # &lt;ForeignKeyField: "user"."favorite_tweet"&gt;

       There is one more quirk to watch out for, though. When you call <u>create_table</u> we will again encounter  the
       same  issue.  For  this  reason  peewee  will  not  automatically create a foreign key constraint for any
       <u>deferred</u> foreign keys.

       To create the tables <u>and</u> the foreign-key constraint, you can use  the  <u>SchemaManager.create_foreign_key()</u>
       method to create the constraint after creating the tables:

          # Will create the User and Tweet tables, but does *not* create a
          # foreign-key constraint on User.favorite_tweet.
          db.create_tables([User, Tweet])

          # Create the foreign-key constraint:
          User._schema.create_foreign_key(User.favorite_tweet)

       <b>NOTE:</b>
          Because  SQLite  has limited support for altering tables, foreign-key constraints cannot be added to a
          table after it has been created.

   <b>Querying</b>
       This section will cover the basic CRUD operations commonly performed on a relational database:

       • <u>Model.create()</u>, for executing <u>INSERT</u> queries.

       • <u>Model.save()</u> and <u>Model.update()</u>, for executing <u>UPDATE</u> queries.

       • <u>Model.delete_instance()</u> and <u>Model.delete()</u>, for executing <u>DELETE</u> queries.

       • <u>Model.select()</u>, for executing <u>SELECT</u> queries.

       <b>NOTE:</b>
          There is also a large collection of example queries  taken  from  the  <u>Postgresql</u>  <u>Exercises</u>  website.
          Examples are listed on the <u>query</u> <u>examples</u> document.

   <b>Creating</b> <b>a</b> <b>new</b> <b>record</b>
       You  can  use <u>Model.create()</u> to create a new model instance. This method accepts keyword arguments, where
       the keys correspond to the names of the model's fields. A new instance is returned and a row is added  to
       the table.

          &gt;&gt;&gt; User.create(username='Charlie')
          &lt;__main__.User object at 0x2529350&gt;

       This  will <u>INSERT</u> a new row into the database. The primary key will automatically be retrieved and stored
       on the model instance.

       Alternatively, you can build up a model instance programmatically and then call <u>save()</u>:

          &gt;&gt;&gt; user = User(username='Charlie')
          &gt;&gt;&gt; user.save()  # save() returns the number of rows modified.
          1
          &gt;&gt;&gt; user.id
          1
          &gt;&gt;&gt; huey = User()
          &gt;&gt;&gt; huey.username = 'Huey'
          &gt;&gt;&gt; huey.save()
          1
          &gt;&gt;&gt; huey.id
          2

       When a model has a foreign key, you can directly assign a model instance to the foreign  key  field  when
       creating a new record.

          &gt;&gt;&gt; tweet = Tweet.create(user=huey, message='Hello!')

       You can also use the value of the related object's primary key:

          &gt;&gt;&gt; tweet = Tweet.create(user=2, message='Hello again!')

       If you simply wish to insert data and do not need to create a model instance, you can use <u>Model.insert()</u>:

          &gt;&gt;&gt; User.insert(username='Mickey').execute()
          3

       After executing the insert query, the primary key of the new row is returned.

       <b>NOTE:</b>
          There  are  several  ways  you  can speed up bulk insert operations. Check out the <u>Bulk</u> <u>inserts</u> recipe
          section for more information.

   <b>Bulk</b> <b>inserts</b>
       There are a couple of ways you can load lots of data quickly.  The  naive  approach  is  to  simply  call
       <u>Model.create()</u> in a loop:

          data_source = [
              {'field1': 'val1-1', 'field2': 'val1-2'},
              {'field1': 'val2-1', 'field2': 'val2-2'},
              # ...
          ]

          for data_dict in data_source:
              MyModel.create(**data_dict)

       The above approach is slow for a couple of reasons:

       1. If  you  are  not  wrapping  the  loop  in a transaction then each call to <u>create()</u> happens in its own
          transaction. That is going to be really slow!

       2. There is a decent amount of Python logic getting in your way, and each <b>InsertQuery</b> must  be  generated
          and parsed into SQL.

       3. That's a lot of data (in terms of raw bytes of SQL) you are sending to your database to parse.

       4. We are retrieving the <u>last</u> <u>insert</u> <u>id</u>, which causes an additional query to be executed in some cases.

       You can get a significant speedup by simply wrapping this in a transaction with <u>atomic()</u>.

          # This is much faster.
          with db.atomic():
              for data_dict in data_source:
                  MyModel.create(**data_dict)

       The above code still suffers from points 2, 3 and 4. We can get another big boost by using <u>insert_many()</u>.
       This method accepts a list of tuples or dictionaries, and inserts multiple rows in a single query:

          data_source = [
              {'field1': 'val1-1', 'field2': 'val1-2'},
              {'field1': 'val2-1', 'field2': 'val2-2'},
              # ...
          ]

          # Fastest way to INSERT multiple rows.
          MyModel.insert_many(data_source).execute()

       The  <u>insert_many()</u>  method also accepts a list of row-tuples, provided you also specify the corresponding
       fields:

          # We can INSERT tuples as well...
          data = [('val1-1', 'val1-2'),
                  ('val2-1', 'val2-2'),
                  ('val3-1', 'val3-2')]

          # But we need to indicate which fields the values correspond to.
          MyModel.insert_many(data, fields=[MyModel.field1, MyModel.field2]).execute()

       It is also a good practice to wrap the bulk insert in a transaction:

          # You can, of course, wrap this in a transaction as well:
          with db.atomic():
              MyModel.insert_many(data, fields=fields).execute()

       <b>NOTE:</b>
          SQLite users should be aware of some caveats when using  bulk  inserts.   Specifically,  your  SQLite3
          version  must  be 3.7.11.0 or newer to take advantage of the bulk insert API. Additionally, by default
          SQLite limits the number of bound variables in a SQL query to <b>999</b> for SQLite versions prior to  3.32.0
          (2020-05-22) and 32766 for SQLite versions after 3.32.0.

   <b>Inserting</b> <b>rows</b> <b>in</b> <b>batches</b>
       Depending  on  the number of rows in your data source, you may need to break it up into chunks. SQLite in
       particular typically has a <u>limit</u> <u>of</u> <u>999</u> <u>or</u> <u>32766</u> variables-per-query (batch size would then be 999 // row
       length or 32766 // row length).

       You can write a loop to batch your data into chunks (in which case it is <b>strongly</b> <b>recommended</b> you  use  a
       transaction):

          # Insert rows 100 at a time.
          with db.atomic():
              for idx in range(0, len(data_source), 100):
                  MyModel.insert_many(data_source[idx:idx+100]).execute()

       Peewee  comes  with  a  <u>chunked()</u>  helper  function  which you can use for <u>efficiently</u> chunking a generic
       iterable into a series of <u>batch</u>-sized iterables:

          from peewee import chunked

          # Insert rows 100 at a time.
          with db.atomic():
              for batch in chunked(data_source, 100):
                  MyModel.insert_many(batch).execute()

   <b>Alternatives</b>
       The <u>Model.bulk_create()</u> method behaves much like <u>Model.insert_many()</u>, but instead it accepts  a  list  of
       unsaved  model  instances  to  insert,  and  it  optionally  accepts  a  batch-size parameter. To use the
       <u>bulk_create()</u> API:

          # Read list of usernames from a file, for example.
          with open('user_list.txt') as fh:
              # Create a list of unsaved User instances.
              users = [User(username=line.strip()) for line in fh.readlines()]

          # Wrap the operation in a transaction and batch INSERT the users
          # 100 at a time.
          with db.atomic():
              User.bulk_create(users, batch_size=100)

       <b>NOTE:</b>
          If you are using Postgresql (which supports the <b>RETURNING</b> clause), then the  previously-unsaved  model
          instances will have their new primary key values automatically populated.

       In  addition, Peewee also offers <u>Model.bulk_update()</u>, which can efficiently update one or more columns on
       a list of models. For example:

          # First, create 3 users with usernames u1, u2, u3.
          u1, u2, u3 = [User.create(username='u%s' % i) for i in (1, 2, 3)]

          # Now we'll modify the user instances.
          u1.username = 'u1-x'
          u2.username = 'u2-y'
          u3.username = 'u3-z'

          # Update all three users with a single UPDATE query.
          User.bulk_update([u1, u2, u3], fields=[User.username])

       This will result in executing the following SQL:

          UPDATE "users" SET "username" = CASE "users"."id"
              WHEN 1 THEN "u1-x"
              WHEN 2 THEN "u2-y"
              WHEN 3 THEN "u3-z" END
          WHERE "users"."id" IN (1, 2, 3);

       <b>NOTE:</b>
          For large lists of objects,  you  should  specify  a  reasonable  batch_size  and  wrap  the  call  to
          <u>bulk_update()</u> with <u>Database.atomic()</u>:

              with database.atomic():
                  User.bulk_update(list_of_users, fields=['username'], batch_size=50)

       <b>WARNING:</b>
          <u>Model.bulk_update()</u>  may  not be the most efficient method for updating large numbers of records. This
          functionality is implemented such that we create a "mapping" of primary  key  to  corresponding  field
          values for all rows being updated using a SQL <b>CASE</b> statement.

       Alternatively,  you  can  use  the  <u>Database.batch_commit()</u>  helper  to  process  chunks  of  rows inside
       <u>batch</u>-sized transactions. This method also provides a workaround for databases besides  Postgresql,  when
       the primary-key of the newly-created rows must be obtained.

          # List of row data to insert.
          row_data = [{'username': 'u1'}, {'username': 'u2'}, ...]

          # Assume there are 789 items in row_data. The following code will result in
          # 8 total transactions (7x100 rows + 1x89 rows).
          for row in db.batch_commit(row_data, 100):
              User.create(**row)

   <b>Bulk-loading</b> <b>from</b> <b>another</b> <b>table</b>
       If  the  data  you would like to bulk load is stored in another table, you can also create <u>INSERT</u> queries
       whose source is a <u>SELECT</u> query. Use the <u>Model.insert_from()</u> method:

          res = (TweetArchive
                 .insert_from(
                     Tweet.select(Tweet.user, Tweet.message),
                     fields=[TweetArchive.user, TweetArchive.message])
                 .execute())

       The above query is equivalent to the following SQL:

          INSERT INTO "tweet_archive" ("user_id", "message")
          SELECT "user_id", "message" FROM "tweet";

   <b>Updating</b> <b>existing</b> <b>records</b>
       Once a model instance has a primary key, any subsequent call to <u>save()</u> will result in  an  <u>UPDATE</u>  rather
       than another <u>INSERT</u>.  The model's primary key will not change:

          &gt;&gt;&gt; user.save()  # save() returns the number of rows modified.
          1
          &gt;&gt;&gt; user.id
          1
          &gt;&gt;&gt; user.save()
          &gt;&gt;&gt; user.id
          1
          &gt;&gt;&gt; huey.save()
          1
          &gt;&gt;&gt; huey.id
          2

       If  you  want  to  update  multiple records, issue an <u>UPDATE</u> query. The following example will update all
       <b>Tweet</b> objects, marking them as <u>published</u>, if they  were  created  before  today.  <u>Model.update()</u>  accepts
       keyword arguments where the keys correspond to the model's field names:

          &gt;&gt;&gt; today = datetime.today()
          &gt;&gt;&gt; query = Tweet.update(is_published=True).where(Tweet.creation_date &lt; today)
          &gt;&gt;&gt; query.execute()  # Returns the number of rows that were updated.
          4

       For more information, see the documentation on <u>Model.update()</u>, <u>Update</u> and <u>Model.bulk_update()</u>.

       <b>NOTE:</b>
          If  you  would like more information on performing atomic updates (such as incrementing the value of a
          column), check out the <u>atomic</u> <u>update</u> recipes.

   <b>Atomic</b> <b>updates</b>
       Peewee allows you to perform atomic updates. Let's suppose we need to update  some  counters.  The  naive
       approach would be to write something like this:

          &gt;&gt;&gt; for stat in Stat.select().where(Stat.url == request.url):
          ...     stat.counter += 1
          ...     stat.save()

       <b>Do</b> <b>not</b> <b>do</b> <b>this!</b> Not only is this slow, but it is also vulnerable to race conditions if multiple processes
       are updating the counter at the same time.

       Instead, you can update the counters atomically using <u>update()</u>:

          &gt;&gt;&gt; query = Stat.update(counter=Stat.counter + 1).where(Stat.url == request.url)
          &gt;&gt;&gt; query.execute()

       You  can  make these update statements as complex as you like. Let's give all our employees a bonus equal
       to their previous bonus plus 10% of their salary:

          &gt;&gt;&gt; query = Employee.update(bonus=(Employee.bonus + (Employee.salary * .1)))
          &gt;&gt;&gt; query.execute()  # Give everyone a bonus!

       We can even use a subquery to update the value of a column. Suppose we had a denormalized column  on  the
       <b>User</b> model that stored the number of tweets a user had made, and we updated this value periodically. Here
       is how you might write such a query:

          &gt;&gt;&gt; subquery = Tweet.select(fn.COUNT(Tweet.id)).where(Tweet.user == User.id)
          &gt;&gt;&gt; update = User.update(num_tweets=subquery)
          &gt;&gt;&gt; update.execute()

   <b>Upsert</b>
       Peewee provides support for varying types of upsert functionality. With SQLite prior to 3.24.0 and MySQL,
       Peewee  offers  the  <u>replace()</u>,  which  allows  you  to  insert a record or, in the event of a constraint
       violation, replace the existing record. For Sqlite 3.24+ and Postgres, peewee provides full  support  for
       <b>ON</b> <b>CONFLICT</b> queries.

       Example of using <u>replace()</u> and <u>on_conflict_replace()</u>:

          class User(Model):
              username = TextField(unique=True)
              last_login = DateTimeField(null=True)

          # Insert or update the user. The "last_login" value will be updated
          # regardless of whether the user existed previously.
          user_id = (User
                     .replace(username='the-user', last_login=datetime.now())
                     .execute())

          # This query is equivalent:
          user_id = (User
                     .insert(username='the-user', last_login=datetime.now())
                     .on_conflict_replace()
                     .execute())

       <b>NOTE:</b>
          In   addition   to   <u>replace</u>,   SQLite,   MySQL   and   Postgresql  provide  an  <u>ignore</u>  action  (see:
          <u>on_conflict_ignore()</u>) if you simply wish to insert and ignore any potential constraint violation.

       <b>MySQL</b> supports upsert via the <u>ON</u> <u>DUPLICATE</u> <u>KEY</u> <u>UPDATE</u> clause. For example:

          class User(Model):
              username = TextField(unique=True)
              last_login = DateTimeField(null=True)
              login_count = IntegerField()

          # Insert a new user.
          User.create(username='huey', login_count=0)

          # Simulate the user logging in. The login count and timestamp will be
          # either created or updated correctly.
          now = datetime.now()
          rowid = (User
                   .insert(username='huey', last_login=now, login_count=1)
                   .on_conflict(
                       preserve=[User.last_login],  # Use the value we would have inserted.
                       update={User.login_count: User.login_count + 1})
                   .execute())

       In the above example, we could safely invoke the upsert query as many times as we wanted. The login count
       will be incremented atomically, the last login column will be updated, and  no  duplicate  rows  will  be
       created.

       <b>Postgresql</b> <b>and</b> <b>SQLite</b> (3.24.0 and newer) provide a different syntax that allows for more granular control
       over which constraint violation should trigger the conflict resolution, and what values should be updated
       or preserved.

       Example of using <u>on_conflict()</u> to perform a Postgresql-style upsert (or SQLite 3.24+):

          class User(Model):
              username = TextField(unique=True)
              last_login = DateTimeField(null=True)
              login_count = IntegerField()

          # Insert a new user.
          User.create(username='huey', login_count=0)

          # Simulate the user logging in. The login count and timestamp will be
          # either created or updated correctly.
          now = datetime.now()
          rowid = (User
                   .insert(username='huey', last_login=now, login_count=1)
                   .on_conflict(
                       conflict_target=[User.username],  # Which constraint?
                       preserve=[User.last_login],  # Use the value we would have inserted.
                       update={User.login_count: User.login_count + 1})
                   .execute())

       In the above example, we could safely invoke the upsert query as many times as we wanted. The login count
       will  be  incremented  atomically,  the  last login column will be updated, and no duplicate rows will be
       created.

       <b>NOTE:</b>
          The main difference between MySQL and Postgresql/SQLite is that Postgresql and SQLite require that you
          specify a <b>conflict_target</b>.

       Here is a more advanced (if contrived) example using the <u>EXCLUDED</u> namespace. The <u>EXCLUDED</u>  helper  allows
       us  to  reference  values in the conflicting data. For our example, we'll assume a simple table mapping a
       unique key (string) to a value (integer):

          class KV(Model):
              key = CharField(unique=True)
              value = IntegerField()

          # Create one row.
          KV.create(key='k1', value=1)

          # Demonstrate usage of EXCLUDED.
          # Here we will attempt to insert a new value for a given key. If that
          # key already exists, then we will update its value with the *sum* of its
          # original value and the value we attempted to insert -- provided that
          # the new value is larger than the original value.
          query = (KV.insert(key='k1', value=10)
                   .on_conflict(conflict_target=[KV.key],
                                update={KV.value: KV.value + EXCLUDED.value},
                                where=(EXCLUDED.value &gt; KV.value)))

          # Executing the above query will result in the following data being
          # present in the "kv" table:
          # (key='k1', value=11)
          query.execute()

          # If we attempted to execute the query *again*, then nothing would be
          # updated, as the new value (10) is now less than the value in the
          # original row (11).

       There are several important concepts to understand when using <b>ON</b> <b>CONFLICT</b>:

       • <b>conflict_target=</b>: which column(s) have the UNIQUE constraint. For a  user  table,  this  might  be  the
         user's email.

       • <b>preserve=</b>:  if  a conflict occurs, this parameter is used to indicate which values from the <b>new</b> data we
         wish to update.

       • <b>update=</b>: if a conflict occurs, this is a mapping of data to apply to the pre-existing row.

       • <b>EXCLUDED</b>: this "magic" namespace allows you to reference the new data that would have been inserted  if
         the constraint hadn't failed.

       Full example:

          class User(Model):
              email = CharField(unique=True)  # Unique identifier for user.
              last_login = DateTimeField()
              login_count = IntegerField(default=0)
              ip_log = TextField(default='')

          # Demonstrates the above 4 concepts.
          def login(email, ip):
              rowid = (User
                       .insert({User.email: email,
                                User.last_login: datetime.now(),
                                User.login_count: 1,
                                User.ip_log: ip})
                       .on_conflict(
                           # If the INSERT fails due to a constraint violation on the
                           # user email, then perform an UPDATE instead.
                           conflict_target=[User.email],

                           # Set the "last_login" to the value we would have inserted
                           # (our call to datetime.now()).
                           preserve=[User.last_login],

                           # Increment the user's login count and prepend the new IP
                           # to the user's ip history.
                           update={User.login_count: User.login_count + 1,
                                   User.ip_log: fn.CONCAT(EXCLUDED.ip_log, ',', User.ip_log)})
                       .execute())

              return rowid

          # This will insert the initial row, returning the new row id (1).
          print(login('<a href="mailto:test@example.com">test@example.com</a>', '127.1'))

          # Because <a href="mailto:test@example.com">test@example.com</a> exists, this will trigger the UPSERT. The row id
          # from above is returned again (1).
          print(login('<a href="mailto:test@example.com">test@example.com</a>', '127.2'))

          u = User.get()
          print(u.login_count, u.ip_log)

          # Prints "2 127.2,127.1"

       For more information, see <u>Insert.on_conflict()</u> and <u>OnConflict</u>.

   <b>Deleting</b> <b>records</b>
       To  delete  a  single model instance, you can use the <u>Model.delete_instance()</u> shortcut. <u>delete_instance()</u>
       will delete the given model instance and can optionally delete  any  dependent  objects  recursively  (by
       specifying <u>recursive=True</u>).

          &gt;&gt;&gt; user = User.get(User.id == 1)
          &gt;&gt;&gt; user.delete_instance()  # Returns the number of rows deleted.
          1

          &gt;&gt;&gt; User.get(User.id == 1)
          UserDoesNotExist: instance matching query does not exist:
          SQL: SELECT t1."id", t1."username" FROM "user" AS t1 WHERE t1."id" = ?
          PARAMS: [1]

       To  delete  an  arbitrary  set of rows, you can issue a <u>DELETE</u> query. The following will delete all <b>Tweet</b>
       objects that are over one year old:

          &gt;&gt;&gt; query = Tweet.delete().where(Tweet.creation_date &lt; one_year_ago)
          &gt;&gt;&gt; query.execute()  # Returns the number of rows deleted.
          7

       For more information, see the documentation on:

       • <u>Model.delete_instance()</u>

       • <u>Model.delete()</u>

       • <b>DeleteQuery</b>

   <b>Selecting</b> <b>a</b> <b>single</b> <b>record</b>
       You can use the <u>Model.get()</u>  method  to  retrieve  a  single  instance  matching  the  given  query.  For
       primary-key lookups, you can also use the shortcut method <u>Model.get_by_id()</u>.

       This  method is a shortcut that calls <u>Model.select()</u> with the given query, but limits the result set to a
       single row. Additionally, if no model matches the given query, a <b>DoesNotExist</b> exception will be raised.

          &gt;&gt;&gt; User.get(User.id == 1)
          &lt;__main__.User object at 0x25294d0&gt;

          &gt;&gt;&gt; <a href="../man1/User.get_by_id.1.html">User.get_by_id</a>(1)  # Same as above.
          &lt;__main__.User object at 0x252df10&gt;

          &gt;&gt;&gt; User[1]  # Also same as above.
          &lt;__main__.User object at 0x252dd10&gt;

          &gt;&gt;&gt; User.get(User.id == 1).username
          u'Charlie'

          &gt;&gt;&gt; User.get(User.username == 'Charlie')
          &lt;__main__.User object at 0x2529410&gt;

          &gt;&gt;&gt; User.get(User.username == 'nobody')
          UserDoesNotExist: instance matching query does not exist:
          SQL: SELECT t1."id", t1."username" FROM "user" AS t1 WHERE t1."username" = ?
          PARAMS: ['nobody']

       For more advanced operations, you can use <u>SelectBase.get()</u>. The  following  query  retrieves  the  latest
       tweet from the user named <u>charlie</u>:

          &gt;&gt;&gt; (Tweet
          ...  .select()
          ...  .join(User)
          ...  .where(User.username == 'charlie')
          ...  .order_by(Tweet.created_date.desc())
          ...  .get())
          &lt;__main__.Tweet object at 0x2623410&gt;

       For more information, see the documentation on:

       • <u>Model.get()</u>

       • <u>Model.get_by_id()</u>

       • <u>Model.get_or_none()</u> - if no matching row is found, return <b>None</b>.

       • <u>Model.select()</u>

       • <u>SelectBase.get()</u>

       • <u>SelectBase.first()</u> - return first record of result-set or <b>None</b>.

   <b>Create</b> <b>or</b> <b>get</b>
       Peewee  has  one  helper method for performing "get/create" type operations: <u>Model.get_or_create()</u>, which
       first attempts to retrieve the matching row. Failing that, a new row will be created.

       For "create or get" type logic, typically one would rely on a <u>unique</u> constraint or primary key to prevent
       the creation of duplicate objects. As an example, let's say we wish to implement registering a  new  user
       account using the <u>example</u> <u>User</u> <u>model</u>. The <u>User</u> model has a <u>unique</u> constraint on the username field, so we
       will rely on the database's integrity guarantees to ensure we don't end up with duplicate usernames:

          try:
              with db.atomic():
                  return User.create(username=username)
          except peewee.IntegrityError:
              # `username` is a unique column, so this username already exists,
              # making it safe to call .get().
              return User.get(User.username == username)

       You can easily encapsulate this type of logic as a <b>classmethod</b> on your own <b>Model</b> classes.

       The  above  example  first attempts at creation, then falls back to retrieval, relying on the database to
       enforce a unique constraint. If you prefer  to  attempt  to  retrieve  the  record  first,  you  can  use
       <u>get_or_create()</u>. This method is implemented along the same lines as the Django function of the same name.
       You  can  use  the  Django-style  keyword argument filters to specify your <b>WHERE</b> conditions. The function
       returns a 2-tuple containing the instance and a boolean value indicating if the object was created.

       Here is how you might implement user account creation using <u>get_or_create()</u>:

          user, created = User.get_or_create(username=username)

       Suppose we have a different model <b>Person</b> and would like to get  or  create  a  person  object.  The  only
       conditions  we  care  about  when  retrieving the <b>Person</b> are their first and last names, <b>but</b> if we end up
       needing to create a new record, we will also specify their date-of-birth and favorite color:

          person, created = Person.get_or_create(
              first_name=first_name,
              last_name=last_name,
              defaults={'dob': dob, 'favorite_color': 'green'})

       Any keyword argument passed to <u>get_or_create()</u> will be used in the <b>get()</b> portion of the logic, except for
       the <b>defaults</b> dictionary, which will be used to populate values on newly-created instances.

       For more details read the documentation for <u>Model.get_or_create()</u>.

   <b>Selecting</b> <b>multiple</b> <b>records</b>
       We can use <u>Model.select()</u> to retrieve rows from the  table.  When  you  construct  a  <u>SELECT</u>  query,  the
       database  will  return  any  rows  that correspond to your query. Peewee allows you to iterate over these
       rows, as well as use indexing and slicing operations:

          &gt;&gt;&gt; query = User.select()
          &gt;&gt;&gt; [user.username for user in query]
          ['Charlie', 'Huey', 'Peewee']

          &gt;&gt;&gt; query[1]
          &lt;__main__.User at 0x7f83e80f5550&gt;

          &gt;&gt;&gt; query[1].username
          'Huey'

          &gt;&gt;&gt; query[:2]
          [&lt;__main__.User at 0x7f83e80f53a8&gt;, &lt;__main__.User at 0x7f83e80f5550&gt;]

       <u>Select</u> queries are smart, in that you can iterate, index and slice the query multiple times but the query
       is only executed once.

       In the following example, we will simply call <u>select()</u> and iterate over the return  value,  which  is  an
       instance of <u>Select</u>.  This will return all the rows in the <u>User</u> table:

          &gt;&gt;&gt; for user in User.select():
          ...     print(user.username)
          ...
          Charlie
          Huey
          Peewee

       <b>NOTE:</b>
          Subsequent  iterations  of  the  same  query  will  not hit the database as the results are cached. To
          disable this behavior (to reduce memory usage), call <b>Select.iterator()</b> when iterating.

       When iterating over a model that contains a foreign key, be careful with the way  you  access  values  on
       related  models.  Accidentally  resolving  a foreign key or iterating over a back-reference can cause <u>N+1</u>
       <u>query</u> <u>behavior</u>.

       When you create a foreign key, such as <b>Tweet.user</b>, you can use the <u>backref</u>  to  create  a  back-reference
       (<b>User.tweets</b>). Back-references are exposed as <u>Select</u> instances:

          &gt;&gt;&gt; tweet = Tweet.get()
          &gt;&gt;&gt; tweet.user  # Accessing a foreign key returns the related model.
          &lt;tw.User at 0x7f3ceb017f50&gt;

          &gt;&gt;&gt; user = User.get()
          &gt;&gt;&gt; user.tweets  # Accessing a back-reference returns a query.
          &lt;peewee.ModelSelect at 0x7f73db3bafd0&gt;

       You can iterate over the <b>user.tweets</b> back-reference just like any other <u>Select</u>:

          &gt;&gt;&gt; for tweet in user.tweets:
          ...     print(tweet.message)
          ...
          hello world
          this is fun
          look at this picture of my food

       In addition to returning model instances, <u>Select</u> queries can return dictionaries, tuples and namedtuples.
       Depending on your use-case, you may find it easier to work with rows as dictionaries, for example:

          &gt;&gt;&gt; query = User.select().dicts()
          &gt;&gt;&gt; for row in query:
          ...     print(row)

          {'id': 1, 'username': 'Charlie'}
          {'id': 2, 'username': 'Huey'}
          {'id': 3, 'username': 'Peewee'}

       See <u>namedtuples()</u>, <u>tuples()</u>, <u>dicts()</u> for more information.

   <b>Iterating</b> <b>over</b> <b>large</b> <b>result-sets</b>
       By  default  peewee  will  cache  the  rows  returned  when  iterating  over  a  <u>Select</u> query. This is an
       optimization to allow multiple iterations as well as indexing  and  slicing  without  causing  additional
       queries. This caching can be problematic, however, when you plan to iterate over a large number of rows.

       To  reduce  the  amount  of memory used by peewee when iterating over a query, use the <u>iterator()</u> method.
       This method allows you to iterate without caching each  model  returned,  using  much  less  memory  when
       iterating over large result sets.

          # Let's assume we've got 10 million stat objects to dump to a csv file.
          stats = Stat.select()

          # Our imaginary serializer class
          serializer = CSVSerializer()

          # Loop over all the stats and serialize.
          for stat in stats.iterator():
              serializer.serialize_object(stat)

       For  simple queries you can see further speed improvements by returning rows as dictionaries, namedtuples
       or tuples. The following methods can be used on any <u>Select</u> query to change the result row type:

       • <u>dicts()</u>

       • <u>namedtuples()</u>

       • <u>tuples()</u>

       Don't forget to append the <u>iterator()</u> method call to also reduce memory  consumption.  For  example,  the
       above code might look like:

          # Let's assume we've got 10 million stat objects to dump to a csv file.
          stats = Stat.select()

          # Our imaginary serializer class
          serializer = CSVSerializer()

          # Loop over all the stats (rendered as tuples, without caching) and serialize.
          for stat_tuple in stats.tuples().iterator():
              serializer.serialize_tuple(stat_tuple)

       When  iterating  over  a  large  number  of  rows  that contain columns from multiple tables, peewee will
       reconstruct the model graph for each row returned. This operation can be slow  for  complex  graphs.  For
       example,  if we were selecting a list of tweets along with the username and avatar of the tweet's author,
       Peewee would have to create two objects for each row (a tweet and a  user).  In  addition  to  the  above
       row-types, there is a fourth method <u>objects()</u> which will return the rows as model instances, but will not
       attempt to resolve the model graph.

       For example:

          query = (Tweet
                   .select(Tweet, User)  # Select tweet and user data.
                   .join(User))

          # Note that the user columns are stored in a separate User instance
          # accessible at tweet.user:
          for tweet in query:
              print(tweet.user.username, tweet.content)

          # Using ".objects()" will not create the tweet.user object and assigns all
          # user attributes to the tweet instance:
          for tweet in query.objects():
              print(tweet.username, tweet.content)

       For  maximum  performance, you can execute queries and then iterate over the results using the underlying
       database cursor. <u>Database.execute()</u> accepts a query object, executes the query, and returns a DB-API  2.0
       <b>Cursor</b> object. The cursor will return the raw row-tuples:

          query = Tweet.select(Tweet.content, User.username).join(User)
          cursor = database.execute(query)
          for (content, username) in cursor:
              print(username, '-&gt;', content)

   <b>Filtering</b> <b>records</b>
       You  can  filter  for particular records using normal python operators. Peewee supports a wide variety of
       <u>query</u> <u>operators</u>.

          &gt;&gt;&gt; user = User.get(User.username == 'Charlie')
          &gt;&gt;&gt; for tweet in Tweet.select().where(Tweet.user == user, Tweet.is_published == True):
          ...     print(tweet.user.username, '-&gt;', tweet.message)
          ...
          Charlie -&gt; hello world
          Charlie -&gt; this is fun

          &gt;&gt;&gt; for tweet in Tweet.select().where(Tweet.created_date &lt; datetime.datetime(2011, 1, 1)):
          ...     print(tweet.message, tweet.created_date)
          ...
          Really old tweet 2010-01-01 00:00:00

       You can also filter across joins:

          &gt;&gt;&gt; for tweet in Tweet.select().join(User).where(User.username == 'Charlie'):
          ...     print(tweet.message)
          hello world
          this is fun
          look at this picture of my food

       If you want to express a complex query, use parentheses and python's bitwise <u>or</u> and <u>and</u> operators:

          &gt;&gt;&gt; Tweet.select().join(User).where(
          ...     (User.username == 'Charlie') |
          ...     (User.username == 'Peewee Herman'))

       <b>NOTE:</b>
          Note that Peewee uses <b>bitwise</b> operators (<b>&amp;</b> and <b>|</b>) rather than logical  operators  (<b>and</b>  and  <b>or</b>).  The
          reason for this is that Python coerces the return value of logical operations to a boolean value. This
          is also the reason why "IN" queries must be expressed using <b>.in_()</b> rather than the <b>in</b> operator.

       Check out <u>the</u> <u>table</u> <u>of</u> <u>query</u> <u>operations</u> to see what types of queries are possible.

       <b>NOTE:</b>
          A lot of fun things can go in the where clause of a query, such as:

          • A field expression, e.g. <b>User.username</b> <b>==</b> <b>'Charlie'</b>

          • A function expression, e.g. <b>fn.Lower(fn.Substr(User.username,</b> <b>1,</b> <b>1))</b> <b>==</b> <b>'a'</b>

          • A comparison of one column to another, e.g. <b>Employee.salary</b> <b>&lt;</b> <b>(Employee.tenure</b> <b>*</b> <b>1000)</b> <b>+</b> <b>40000</b>

          You can also nest queries, for example tweets by users whose username starts with "a":

              # get users whose username starts with "a"
              a_users = User.select().where(fn.Lower(fn.Substr(User.username, 1, 1)) == 'a')

              # the ".in_()" method signifies an "IN" query
              a_user_tweets = Tweet.select().where(Tweet.user.in_(a_users))

   <b>More</b> <b>query</b> <b>examples</b>
       <b>NOTE:</b>
          For  a  wide  range of example queries, see the <u>Query</u> <u>Examples</u> document, which shows how to implements
          queries from the <u>PostgreSQL</u> <u>Exercises</u> website.

       Get active users:

          User.select().where(User.active == True)

       Get users who are either staff or superusers:

          User.select().where(
              (User.is_staff == True) | (User.is_superuser == True))

       Get tweets by user named "charlie":

          Tweet.select().join(User).where(User.username == 'charlie')

       Get tweets by staff or superusers (assumes FK relationship):

          Tweet.select().join(User).where(
              (User.is_staff == True) | (User.is_superuser == True))

       Get tweets by staff or superusers using a subquery:

          staff_super = User.select(User.id).where(
              (User.is_staff == True) | (User.is_superuser == True))
          Tweet.select().where(Tweet.user.in_(staff_super))

   <b>Sorting</b> <b>records</b>
       To return rows in order, use the <u>order_by()</u> method:

          &gt;&gt;&gt; for t in Tweet.select().order_by(Tweet.created_date):
          ...     print(t.pub_date)
          ...
          2010-01-01 00:00:00
          2011-06-07 14:08:48
          2011-06-07 14:12:57

          &gt;&gt;&gt; for t in Tweet.select().order_by(Tweet.created_date.desc()):
          ...     print(t.pub_date)
          ...
          2011-06-07 14:12:57
          2011-06-07 14:08:48
          2010-01-01 00:00:00

       You can also use <b>+</b> and <b>-</b> prefix operators to indicate ordering:

          # The following queries are equivalent:
          Tweet.select().order_by(Tweet.created_date.desc())

          Tweet.select().order_by(-Tweet.created_date)  # Note the "-" prefix.

          # Similarly you can use "+" to indicate ascending order, though ascending
          # is the default when no ordering is otherwise specified.
          User.select().order_by(+User.username)

       You can also order across joins. Assuming you want to order tweets by the username of the author, then by
       created_date:

          query = (Tweet
                   .select()
                   .join(User)
                   .order_by(User.username, Tweet.created_date.desc()))

          SELECT t1."id", t1."user_id", t1."message", t1."is_published", t1."created_date"
          FROM "tweet" AS t1
          INNER JOIN "user" AS t2
            ON t1."user_id" = t2."id"
          ORDER BY t2."username", t1."created_date" DESC

       When sorting on a calculated value, you can either include the necessary SQL  expressions,  or  reference
       the alias assigned to the value. Here are two examples illustrating these methods:

          # Let's start with our base query. We want to get all usernames and the number of
          # tweets they've made. We wish to sort this list from users with most tweets to
          # users with fewest tweets.
          query = (User
                   .select(User.username, fn.COUNT(Tweet.id).alias('num_tweets'))
                   .join(Tweet, JOIN.LEFT_OUTER)
                   .group_by(User.username))

       You  can  order  using  the  same COUNT expression used in the <b>select</b> clause. In the example below we are
       ordering by the <b>COUNT()</b> of tweet ids descending:

          query = (User
                   .select(User.username, fn.COUNT(Tweet.id).alias('num_tweets'))
                   .join(Tweet, JOIN.LEFT_OUTER)
                   .group_by(User.username)
                   .order_by(fn.COUNT(Tweet.id).desc()))

       Alternatively, you can reference the alias assigned to the calculated value in the  <b>select</b>  clause.  This
       method  has  the benefit of being a bit easier to read. Note that we are not referring to the named alias
       directly, but are wrapping it using the <u>SQL</u> helper:

          query = (User
                   .select(User.username, fn.COUNT(Tweet.id).alias('num_tweets'))
                   .join(Tweet, JOIN.LEFT_OUTER)
                   .group_by(User.username)
                   .order_by(SQL('num_tweets').desc()))

       Or, to do things the "peewee" way:

          ntweets = fn.COUNT(Tweet.id)
          query = (User
                   .select(User.username, ntweets.alias('num_tweets'))
                   .join(Tweet, JOIN.LEFT_OUTER)
                   .group_by(User.username)
                   .order_by(ntweets.desc())

   <b>Getting</b> <b>random</b> <b>records</b>
       Occasionally you may want to pull a random record from the database. You can accomplish this by  ordering
       by the <u>random</u> or <u>rand</u> function (depending on your database):

       Postgresql and Sqlite use the <u>Random</u> function:

          # Pick 5 lucky winners:
          LotteryNumber.select().order_by(fn.Random()).<a href="../man5/limit.5.html">limit</a>(5)

       MySQL uses <u>Rand</u>:

          # Pick 5 lucky winners:
          LotteryNumber.select().order_by(fn.Rand()).<a href="../man5/limit.5.html">limit</a>(5)

   <b>Paginating</b> <b>records</b>
       The  <u>paginate()</u>  method  makes  it  easy  to  grab  a  <u>page</u>  or records. <u>paginate()</u> takes two parameters,
       <b>page_number</b>, and <b>items_per_page</b>.

       <b>ATTENTION:</b>
          Page numbers are 1-based, so the first page of results will be page 1.

          &gt;&gt;&gt; for tweet in Tweet.select().order_by(Tweet.id).paginate(2, 10):
          ...     print(tweet.message)
          ...
          tweet 10
          tweet 11
          tweet 12
          tweet 13
          tweet 14
          tweet 15
          tweet 16
          tweet 17
          tweet 18
          tweet 19

       If you would like more granular control, you can always use <u>limit()</u> and <u>offset()</u>.

   <b>Counting</b> <b>records</b>
       You can count the number of rows in any select query:

          &gt;&gt;&gt; Tweet.select().count()
          100
          &gt;&gt;&gt; Tweet.select().where(Tweet.id &gt; 50).count()
          50

       Peewee will wrap your query in an outer query that performs a count, which results in SQL like:

          SELECT <a href="../man1/COUNT.1.html">COUNT</a>(1) FROM ( ... your query ... );

   <b>Aggregating</b> <b>records</b>
       Suppose you have some users and want to get a list of them along with the count of tweets in each.

          query = (User
                   .select(User, fn.Count(Tweet.id).alias('count'))
                   .join(Tweet, JOIN.LEFT_OUTER)
                   .group_by(User))

       The resulting query will return <u>User</u>  objects  with  all  their  normal  attributes  plus  an  additional
       attribute <u>count</u> which will contain the count of tweets for each user. We use a left outer join to include
       users who have no tweets.

       Let's  assume  you have a tagging application and want to find tags that have a certain number of related
       objects. For this example we'll use some different models in a <u>many-to-many</u> configuration:

          class Photo(Model):
              image = CharField()

          class Tag(Model):
              name = CharField()

          class PhotoTag(Model):
              photo = ForeignKeyField(Photo)
              tag = ForeignKeyField(Tag)

       Now say we want to find tags that have at least 5 photos associated with them:

          query = (Tag
                   .select()
                   .join(PhotoTag)
                   .join(Photo)
                   .group_by(Tag)
                   .having(fn.Count(Photo.id) &gt; 5))

       This query is equivalent to the following SQL:

          SELECT t1."id", t1."name"
          FROM "tag" AS t1
          INNER JOIN "phototag" AS t2 ON t1."id" = t2."tag_id"
          INNER JOIN "photo" AS t3 ON t2."photo_id" = t3."id"
          GROUP BY t1."id", t1."name"
          HAVING Count(t3."id") &gt; 5

       Suppose we want to grab the associated count and store it on the tag:

          query = (Tag
                   .select(Tag, fn.Count(Photo.id).alias('count'))
                   .join(PhotoTag)
                   .join(Photo)
                   .group_by(Tag)
                   .having(fn.Count(Photo.id) &gt; 5))

   <b>Retrieving</b> <b>Scalar</b> <b>Values</b>
       You can retrieve scalar values by calling <b>Query.scalar()</b>. For instance:

          &gt;&gt;&gt; PageView.select(fn.Count(fn.Distinct(PageView.url))).scalar()
          100

       You can retrieve multiple scalar values by passing <b>as_tuple=True</b>:

          &gt;&gt;&gt; Employee.select(
          ...     fn.Min(Employee.salary), fn.Max(Employee.salary)
          ... ).scalar(as_tuple=True)
          (30000, 50000)

   <b>Window</b> <b>functions</b>
       A <u>Window</u> function refers to an aggregate function that operates on a sliding window of data that is being
       processed as part of a <b>SELECT</b> query.  Window functions make it possible to do things like:

       1. Perform aggregations against subsets of a result-set.

       2. Calculate a running total.

       3. Rank results.

       4. Compare a row value to a value in the preceding (or succeeding!) row(s).

       peewee comes with support for SQL window functions, which can be created by calling  <u>Function.over()</u>  and
       passing in your partitioning or ordering parameters.

       For the following examples, we'll use the following model and sample data:

          class Sample(Model):
              counter = IntegerField()
              value = FloatField()

          data = [(1, 10),
                  (1, 20),
                  (2, 1),
                  (2, 3),
                  (3, 100)]
          Sample.insert_many(data, fields=[Sample.counter, Sample.value]).execute()

       Our sample table now contains:
                                               ┌────┬─────────┬───────┐
                                               │ id │ counter │ value │
                                               ├────┼─────────┼───────┤
                                               │ 1  │ 1       │ 10.0  │
                                               ├────┼─────────┼───────┤
                                               │ 2  │ 1       │ 20.0  │
                                               ├────┼─────────┼───────┤
                                               │ 3  │ 2       │ 1.0   │
                                               ├────┼─────────┼───────┤
                                               │ 4  │ 2       │ 3.0   │
                                               ├────┼─────────┼───────┤
                                               │ 5  │ 3       │ 100.0 │
                                               └────┴─────────┴───────┘

   <b>Ordered</b> <b>Windows</b>
       Let's calculate a running sum of the <b>value</b> field. In order for it to be a "running" sum, we need it to be
       ordered, so we'll order with respect to the Sample's <b>id</b> field:

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.SUM(Sample.value).over(order_by=[Sample.id]).alias('total'))

          for sample in query:
              print(sample.counter, sample.value, sample.total)

          # 1    10.    10.
          # 1    20.    30.
          # 2     1.    31.
          # 2     3.    34.
          # 3   100    134.

       For  another  example,  we'll  calculate the difference between the current value and the previous value,
       when ordered by the <b>id</b>:

          difference = Sample.value - fn.LAG(Sample.value, 1).over(order_by=[Sample.id])
          query = Sample.select(
              Sample.counter,
              Sample.value,
              difference.alias('diff'))

          for sample in query:
              print(sample.counter, sample.value, sample.diff)

          # 1    10.   NULL
          # 1    20.    10.  -- (20 - 10)
          # 2     1.   -19.  -- (1 - 20)
          # 2     3.     2.  -- (3 - 1)
          # 3   100     97.  -- (100 - 3)

   <b>Partitioned</b> <b>Windows</b>
       Let's calculate the average <b>value</b> for each distinct "counter" value. Notice that there are three possible
       values for the <b>counter</b> field (1, 2, and 3).  We can do this by calculating the <b>AVG()</b> of the <b>value</b>  column
       over a window that is partitioned depending on the <b>counter</b> field:

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.AVG(Sample.value).over(partition_by=[Sample.counter]).alias('cavg'))

          for sample in query:
              print(sample.counter, sample.value, sample.cavg)

          # 1    10.    15.
          # 1    20.    15.
          # 2     1.     2.
          # 2     3.     2.
          # 3   100    100.

       We can use ordering within partitions by specifying both the <b>order_by</b> and <b>partition_by</b> parameters. For an
       example, let's rank the samples by value within each distinct <b>counter</b> group.

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.RANK().over(
                  order_by=[Sample.value],
                  partition_by=[Sample.counter]).alias('rank'))

          for sample in query:
              print(sample.counter, sample.value, sample.rank)

          # 1    10.    1
          # 1    20.    2
          # 2     1.    1
          # 2     3.    2
          # 3   100     1

   <b>Bounded</b> <b>windows</b>
       By  default,  window  functions  are evaluated using an <u>unbounded</u> <u>preceding</u> start for the window, and the
       <u>current</u> <u>row</u> as the end. We can change the bounds of the window our  aggregate  functions  operate  on  by
       specifying  a  <b>start</b>  and/or  <b>end</b>  in  the  call  to  <u>Function.over()</u>.  Additionally,  Peewee  comes with
       helper-methods on the <u>Window</u> object for generating the appropriate boundary references:

       • <u>Window.CURRENT_ROW</u> - attribute that references the current row.

       • <u>Window.preceding()</u> - specify number of row(s) preceding, or omit number to indicate <b>all</b> preceding rows.

       • <u>Window.following()</u> - specify number of row(s) following, or omit number to indicate <b>all</b> following rows.

       To examine how boundaries work, we'll calculate a running total of the <b>value</b> column, ordered with respect
       to <b>id</b>, <b>but</b> we'll only look the running total of the current row and it's two preceding rows:

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.SUM(Sample.value).over(
                  order_by=[Sample.id],
                  start=<a href="../man2/Window.preceding.2.html">Window.preceding</a>(2),
                  end=Window.CURRENT_ROW).alias('rsum'))

          for sample in query:
              print(sample.counter, sample.value, sample.rsum)

          # 1    10.    10.
          # 1    20.    30.  -- (20 + 10)
          # 2     1.    31.  -- (1 + 20 + 10)
          # 2     3.    24.  -- (3 + 1 + 20)
          # 3   100    104.  -- (100 + 3 + 1)

       <b>NOTE:</b>
          Technically we did not need to specify the <b>end=Window.CURRENT</b> because that  is  the  default.  It  was
          shown in the example for demonstration.

       Let's  look  at  another example. In this example we will calculate the "opposite" of a running total, in
       which the total sum of all values is decreased by the value of the samples, ordered by <b>id</b>. To  accomplish
       this, we'll calculate the sum from the current row to the last row.

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.SUM(Sample.value).over(
                  order_by=[Sample.id],
                  start=Window.CURRENT_ROW,
                  end=Window.following()).alias('rsum'))

          # 1    10.   134.  -- (10 + 20 + 1 + 3 + 100)
          # 1    20.   124.  -- (20 + 1 + 3 + 100)
          # 2     1.   104.  -- (1 + 3 + 100)
          # 2     3.   103.  -- (3 + 100)
          # 3   100    100.  -- (100)

   <b>Filtered</b> <b>Aggregates</b>
       Aggregate  functions  may also support filter functions (Postgres and Sqlite 3.25+), which get translated
       into a <b>FILTER</b> <b>(WHERE...)</b> clause.  Filter  expressions  are  added  to  an  aggregate  function  with  the
       <u>Function.filter()</u> method.

       For  an example, we will calculate the running sum of the <b>value</b> field with respect to the <b>id</b>, but we will
       filter-out any samples whose <b>counter=2</b>.

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.SUM(Sample.value).filter(Sample.counter != 2).over(
                  order_by=[Sample.id]).alias('csum'))

          for sample in query:
              print(sample.counter, sample.value, sample.csum)

          # 1    10.    10.
          # 1    20.    30.
          # 2     1.    30.
          # 2     3.    30.
          # 3   100    130.

       <b>NOTE:</b>
          The call to <u>filter()</u> must precede the call to <u>over()</u>.

   <b>Reusing</b> <b>Window</b> <b>Definitions</b>
       If you intend to use the same window definition for multiple aggregates, you can create a <u>Window</u>  object.
       The  <u>Window</u>  object  takes the same parameters as <u>Function.over()</u>, and can be passed to the <b>over()</b> method
       in-place of the individual parameters.

       Here we'll declare a single window, ordered with respect to  the  sample  <b>id</b>,  and  call  several  window
       functions using that window definition:

          win = Window(order_by=[Sample.id])
          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.LEAD(Sample.value).over(win),
              fn.LAG(Sample.value).over(win),
              fn.SUM(Sample.value).over(win)
          ).window(win)  # Include our window definition in query.

          for row in query.tuples():
              print(row)

          # counter  value  lead()  lag()  sum()
          # 1          10.     20.   NULL    10.
          # 1          20.      1.    10.    30.
          # 2           1.      3.    20.    31.
          # 2           3.    100.     1.    34.
          # 3         100.    NULL     3.   134.

   <b>Multiple</b> <b>window</b> <b>definitions</b>
       In  the  previous example, we saw how to declare a <u>Window</u> definition and re-use it for multiple different
       aggregations. You can include as many window definitions as you need in your queries, but it is necessary
       to ensure each window has a unique alias:

          w1 = Window(order_by=[Sample.id]).alias('w1')
          w2 = Window(partition_by=[Sample.counter]).alias('w2')
          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.SUM(Sample.value).over(w1).alias('rsum'),  # Running total.
              fn.AVG(Sample.value).over(w2).alias('cavg')   # Avg per category.
          ).window(w1, w2)  # Include our window definitions.

          for sample in query:
              print(sample.counter, sample.value, sample.rsum, sample.cavg)

          # counter  value   rsum     cavg
          # 1          10.     10.     15.
          # 1          20.     30.     15.
          # 2           1.     31.      2.
          # 2           3.     34.      2.
          # 3         100     134.    100.

       Similarly, if you have multiple window definitions that share similar  definitions,  it  is  possible  to
       extend a previously-defined window definition.  For example, here we will be partitioning the data-set by
       the  counter  value,  so we'll be doing our aggregations with respect to the counter. Then we'll define a
       second window that extends this partitioning, and adds an ordering clause:

          w1 = Window(partition_by=[Sample.counter]).alias('w1')

          # By extending w1, this window definition will also be partitioned
          # by "counter".
          w2 = Window(extends=w1, order_by=[Sample.value.desc()]).alias('w2')

          query = (Sample
                   .select(Sample.counter, Sample.value,
                           fn.SUM(Sample.value).over(w1).alias('group_sum'),
                           fn.RANK().over(w2).alias('revrank'))
                   .window(w1, w2)
                   .order_by(Sample.id))

          for sample in query:
              print(sample.counter, sample.value, sample.group_sum, sample.revrank)

          # counter  value   group_sum   revrank
          # 1        10.     30.         2
          # 1        20.     30.         1
          # 2        1.      4.          2
          # 2        3.      4.          1
          # 3        100.    100.        1

   <b>Frame</b> <b>types:</b> <b>RANGE</b> <b>vs</b> <b>ROWS</b> <b>vs</b> <b>GROUPS</b>
       Depending on the frame type, the database will process  ordered  groups  differently.  Let's  create  two
       additional <b>Sample</b> rows to visualize the difference:

          &gt;&gt;&gt; Sample.create(counter=1, value=20.)
          &lt;Sample 6&gt;
          &gt;&gt;&gt; Sample.create(counter=2, value=1.)
          &lt;Sample 7&gt;

       Our table now contains:
                                               ┌────┬─────────┬───────┐
                                               │ id │ counter │ value │
                                               ├────┼─────────┼───────┤
                                               │ 1  │ 1       │ 10.0  │
                                               ├────┼─────────┼───────┤
                                               │ 2  │ 1       │ 20.0  │
                                               ├────┼─────────┼───────┤
                                               │ 3  │ 2       │ 1.0   │
                                               ├────┼─────────┼───────┤
                                               │ 4  │ 2       │ 3.0   │
                                               ├────┼─────────┼───────┤
                                               │ 5  │ 3       │ 100.0 │
                                               ├────┼─────────┼───────┤
                                               │ 6  │ 1       │ 20.0  │
                                               ├────┼─────────┼───────┤
                                               │ 7  │ 2       │ 1.0   │
                                               └────┴─────────┴───────┘

       Let's  examine  the difference by calculating a "running sum" of the samples, ordered with respect to the
       <b>counter</b> and <b>value</b> fields. To specify the frame type, we can use either:

       • <u>Window.RANGE</u>

       • <u>Window.ROWS</u>

       • <u>Window.GROUPS</u>

       The behavior of <u>RANGE</u>, when there are logical duplicates, may lead to unexpected results:

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.SUM(Sample.value).over(
                  order_by=[Sample.counter, Sample.value],
                  frame_type=Window.RANGE).alias('rsum'))

          for sample in query.order_by(Sample.counter, Sample.value):
              print(sample.counter, sample.value, sample.rsum)

          # counter  value   rsum
          # 1          10.     10.
          # 1          20.     50.
          # 1          20.     50.
          # 2           1.     52.
          # 2           1.     52.
          # 2           3.     55.
          # 3         100     155.

       With the inclusion of the new rows we now have some rows that have duplicate <b>category</b> and  <b>value</b>  values.
       The <u>RANGE</u> frame type causes these duplicates to be evaluated together rather than separately.

       The more expected result can be achieved by using <u>ROWS</u> as the frame-type:

          query = Sample.select(
              Sample.counter,
              Sample.value,
              fn.SUM(Sample.value).over(
                  order_by=[Sample.counter, Sample.value],
                  frame_type=Window.ROWS).alias('rsum'))

          for sample in query.order_by(Sample.counter, Sample.value):
              print(sample.counter, sample.value, sample.rsum)

          # counter  value   rsum
          # 1          10.     10.
          # 1          20.     30.
          # 1          20.     50.
          # 2           1.     51.
          # 2           1.     52.
          # 2           3.     55.
          # 3         100     155.

       Peewee uses these rules for determining what frame-type to use:

       • If the user specifies a <b>frame_type</b>, that frame type will be used.

       • If <b>start</b> and/or <b>end</b> boundaries are specified Peewee will default to using <b>ROWS</b>.

       • If  the  user did not specify frame type or start/end boundaries, Peewee will use the database default,
         which is <b>RANGE</b>.

       The <u>Window.GROUPS</u> frame type looks at the window range specification in terms of groups of rows, based on
       the ordering term(s). Using <b>GROUPS</b>, we can define the frame so it  covers  distinct  groupings  of  rows.
       Let's look at an example:

          query = (Sample
                   .select(Sample.counter, Sample.value,
                           fn.SUM(Sample.value).over(
                              order_by=[Sample.counter, Sample.value],
                              frame_type=Window.GROUPS,
                              start=<a href="../man1/Window.preceding.1.html">Window.preceding</a>(1)).alias('gsum'))
                   .order_by(Sample.counter, Sample.value))

          for sample in query:
              print(sample.counter, sample.value, sample.gsum)

          #  counter   value    gsum
          #  1         10       10
          #  1         20       50
          #  1         20       50   (10) + (20+0)
          #  2         1        42
          #  2         1        42   (20+20) + (1+1)
          #  2         3        5    (1+1) + 3
          #  3         100      103  (3) + 100

       As you can hopefully infer, the window is grouped by its ordering term, which is <b>(counter,</b> <b>value)</b>. We are
       looking at a window that extends between one previous group and the current group.

       <b>NOTE:</b>
          For information about the window function APIs, see:

          • <u>Function.over()</u>

          • <u>Function.filter()</u>

          • <u>Window</u>

          For general information on window functions, read the postgres <u>window</u> <u>functions</u> <u>tutorial</u>

          Additionally, the <u>postgres</u> <u>docs</u> and the <u>sqlite</u> <u>docs</u> contain a lot of good information.

   <b>Retrieving</b> <b>row</b> <b>tuples</b> <b>/</b> <b>dictionaries</b> <b>/</b> <b>namedtuples</b>
       Sometimes  you  do  not need the overhead of creating model instances and simply want to iterate over the
       row data without needing all the APIs provided <u>Model</u>. To do this, use:

       • <u>dicts()</u>

       • <u>namedtuples()</u>

       • <u>tuples()</u>

       • <u>objects()</u> -- accepts an arbitrary constructor function which is called with the row tuple.

          stats = (Stat
                   .select(Stat.url, fn.Count(Stat.url))
                   .group_by(Stat.url)
                   .tuples())

          # iterate over a list of 2-tuples containing the url and count
          for stat_url, stat_count in stats:
              print(stat_url, stat_count)

       Similarly, you can return the rows from the cursor as dictionaries using <u>dicts()</u>:

          stats = (Stat
                   .select(Stat.url, fn.Count(Stat.url).alias('ct'))
                   .group_by(Stat.url)
                   .dicts())

          # iterate over a list of 2-tuples containing the url and count
          for stat in stats:
              print(stat['url'], stat['ct'])

   <b>Returning</b> <b>Clause</b>
       <u>PostgresqlDatabase</u> supports a <b>RETURNING</b> clause  on  <b>UPDATE</b>,  <b>INSERT</b>  and  <b>DELETE</b>  queries.  Specifying  a
       <b>RETURNING</b> clause allows you to iterate over the rows accessed by the query.

       By default, the return values upon execution of the different queries are:

       • <b>INSERT</b>  -  auto-incrementing  primary  key  value  of  the  newly-inserted  row.   When  not  using  an
         auto-incrementing primary key, Postgres will return the new row's primary key,  but  SQLite  and  MySQL
         will not.

       • <b>UPDATE</b> - number of rows modified

       • <b>DELETE</b> - number of rows deleted

       When  a  returning  clause  is  used  the  return value upon executing a query will be an iterable cursor
       object.

       Postgresql allows, via the <b>RETURNING</b> clause, to return data from the  rows  inserted  or  modified  by  a
       query.

       For  example,  let's  say  you  have  an <u>Update</u> that deactivates all user accounts whose registration has
       expired. After deactivating them, you want to send each user an email letting them know their account was
       deactivated.  Rather than writing two queries, a <b>SELECT</b> and an <b>UPDATE</b>, you can do this in a single <b>UPDATE</b>
       query with a <b>RETURNING</b> clause:

          query = (User
                   .update(is_active=False)
                   .where(User.registration_expired == True)
                   .returning(User))

          # Send an email to every user that was deactivated.
          for deactivate_user in query.execute():
              send_deactivation_email(deactivated_user.email)

       The <b>RETURNING</b> clause is also available on <u>Insert</u> and <u>Delete</u>. When used  with  <b>INSERT</b>,  the  newly-created
       rows will be returned. When used with <b>DELETE</b>, the deleted rows will be returned.

       The  only limitation of the <b>RETURNING</b> clause is that it can only consist of columns from tables listed in
       the query's <b>FROM</b> clause. To select all columns from a particular table, you can simply pass in the  <u>Model</u>
       class.

       As  another  example,  let's  add  a  user  and  set  their creation-date to the server-generated current
       timestamp. We'll create and retrieve the new user's ID, Email and the  creation  timestamp  in  a  single
       query:

          query = (User
                   .insert(email='<a href="mailto:foo@bar.com">foo@bar.com</a>', created=fn.now())
                   .returning(User))  # Shorthand for all columns on User.

          # When using RETURNING, execute() returns a cursor.
          cursor = query.execute()

          # Get the user object we just inserted and log the data:
          user = cursor[0]
          logger.info('Created user %s (id=%s) at %s', user.email, user.id, user.created)

       By default the cursor will return <u>Model</u> instances, but you can specify a different row type:

          data = [{'name': 'charlie'}, {'name': 'huey'}, {'name': 'mickey'}]
          query = (User
                   .insert_many(data)
                   .returning(User.id, User.username)
                   .dicts())

          for new_user in query.execute():
              print('Added user "%s", id=%s' % (new_user['username'], new_user['id']))

       Just as with <u>Select</u> queries, you can specify various <u>result</u> <u>row</u> <u>types</u>.

   <b>Common</b> <b>Table</b> <b>Expressions</b>
       Peewee  supports  the  inclusion  of common table expressions (CTEs) in all types of queries. CTEs may be
       useful for:

       • Factoring out a common subquery.

       • Grouping or filtering by a column derived in the CTE's result set.

       • Writing recursive queries.

       To declare a <u>Select</u> query for use as a CTE, use <b>cte()</b> method, which wraps the query in a <u>CTE</u>  object.  To
       indicate  that  a  <u>CTE</u>  should be included as part of a query, use the <u>Query.with_cte()</u> method, passing a
       list of CTE objects.

   <b>Simple</b> <b>Example</b>
       For an example, let's say we have some data points that consist of a  key  and  a  floating-point  value.
       Let's define our model and populate some test data:

          class Sample(Model):
              key = TextField()
              value = FloatField()

          data = (
              ('a', (1.25, 1.5, 1.75)),
              ('b', (2.1, 2.3, 2.5, 2.7, 2.9)),
              ('c', (3.5, 3.5)))

          # Populate data.
          for key, values in data:
              Sample.insert_many([(key, value) for value in values],
                                 fields=[Sample.key, Sample.value]).execute()

       Let's use a CTE to calculate, for each distinct key, which values were above-average for that key.

          # First we'll declare the query that will be used as a CTE. This query
          # simply determines the average value for each key.
          cte = (Sample
                 .select(Sample.key, fn.AVG(Sample.value).alias('avg_value'))
                 .group_by(Sample.key)
                 .cte('key_avgs', columns=('key', 'avg_value')))

          # Now we'll query the sample table, using our CTE to find rows whose value
          # exceeds the average for the given key. We'll calculate how far above the
          # average the given sample's value is, as well.
          query = (Sample
                   .select(Sample.key, Sample.value)
                   .join(cte, on=(Sample.key == cte.c.key))
                   .where(Sample.value &gt; cte.c.avg_value)
                   .order_by(Sample.value)
                   .with_cte(cte))

       We  can  iterate over the samples returned by the query to see which samples had above-average values for
       their given group:

          &gt;&gt;&gt; for sample in query:
          ...     print(sample.key, sample.value)

          # 'a', 1.75
          # 'b', 2.7
          # 'b', 2.9

   <b>Complex</b> <b>Example</b>
       For a more complete example, let's consider  the  following  query  which  uses  multiple  CTEs  to  find
       per-product sales totals in only the top sales regions.  Our model looks like this:

          class Order(Model):
              region = TextField()
              amount = FloatField()
              product = TextField()
              quantity = IntegerField()

       Here is how the query might be written in SQL. This example can be found in the <u>postgresql</u> <u>documentation</u>.

          WITH regional_sales AS (
              SELECT region, SUM(amount) AS total_sales
              FROM orders
              GROUP BY region
            ), top_regions AS (
              SELECT region
              FROM regional_sales
              WHERE total_sales &gt; (SELECT SUM(total_sales) / 10 FROM regional_sales)
            )
          SELECT region,
                 product,
                 SUM(quantity) AS product_units,
                 SUM(amount) AS product_sales
          FROM orders
          WHERE region IN (SELECT region FROM top_regions)
          GROUP BY region, product;

       With Peewee, we would write:

          reg_sales = (Order
                       .select(Order.region,
                               fn.SUM(Order.amount).alias('total_sales'))
                       .group_by(Order.region)
                       .cte('regional_sales'))

          top_regions = (reg_sales
                         .select(reg_sales.c.region)
                         .where(reg_sales.c.total_sales &gt; (
                             reg_sales.select(fn.SUM(reg_sales.c.total_sales) / 10)))
                         .cte('top_regions'))

          query = (Order
                   .select(Order.region,
                           Order.product,
                           fn.SUM(Order.quantity).alias('product_units'),
                           fn.SUM(Order.amount).alias('product_sales'))
                   .where(Order.region.in_(top_regions.select(top_regions.c.region)))
                   .group_by(Order.region, Order.product)
                   .with_cte(reg_sales, top_regions))

   <b>Recursive</b> <b>CTEs</b>
       Peewee  supports  recursive  CTEs.  Recursive  CTEs  can  be  useful  when,  for example, you have a tree
       data-structure represented by a parent-link foreign key.  Suppose, for example, that we have a  hierarchy
       of  categories  for  an  online  bookstore.  We wish to generate a table showing all categories and their
       absolute depths, along with the path from the root to the category.

       We'll assume the following model definition, in which each category has a foreign-key  to  its  immediate
       parent category:

          class Category(Model):
              name = TextField()
              parent = ForeignKeyField('self', backref='children', null=True)

       To list all categories along with their depth and parents, we can use a recursive CTE:

          # Define the base case of our recursive CTE. This will be categories that
          # have a null parent foreign-key.
          Base = Category.alias()
          level = <a href="../man1/Value.1.html">Value</a>(1).alias('level')
          path = Base.name.alias('path')
          base_case = (Base
                       .select(Base.id, Base.name, Base.parent, level, path)
                       .where(Base.parent.is_null())
                       .cte('base', recursive=True))

          # Define the recursive terms.
          RTerm = Category.alias()
          rlevel = (base_case.c.level + 1).alias('level')
          rpath = base_case.c.path.concat('-&gt;').concat(RTerm.name).alias('path')
          recursive = (RTerm
                       .select(RTerm.id, RTerm.name, RTerm.parent, rlevel, rpath)
                       .join(base_case, on=(RTerm.parent == base_case.c.id)))

          # The recursive CTE is created by taking the base case and UNION ALL with
          # the recursive term.
          cte = base_case.union_all(recursive)

          # We will now query from the CTE to get the categories, their levels,  and
          # their paths.
          query = (cte
                   .select_from(cte.c.name, cte.c.level, cte.c.path)
                   .order_by(cte.c.path))

          # We can now iterate over a list of all categories and print their names,
          # absolute levels, and path from root -&gt; category.
          for category in query:
              print(category.name, category.level, category.path)

          # Example output:
          # root, 1, root
          # p1, 2, root-&gt;p1
          # c1-1, 3, root-&gt;p1-&gt;c1-1
          # c1-2, 3, root-&gt;p1-&gt;c1-2
          # p2, 2, root-&gt;p2
          # c2-1, 3, root-&gt;p2-&gt;c2-1

   <b>Data-Modifying</b> <b>CTE</b>
       Peewee supports data-modifying CTE's.

       Example  of  using  a  data-modifying CTE to move data from one table to an archive table, using a single
       query:

          class Event(Model):
              name = CharField()
              timestamp = DateTimeField()

          class Archive(Model):
              name = CharField()
              timestamp = DateTimeField()

          # Move rows older than 24 hours from the Event table to the Archive.
          cte = (Event
                 .delete()
                 .where(Event.timestamp &lt; (datetime.now() - timedelta(days=1)))
                 .returning(Event)
                 .cte('moved_rows'))

          # Create a simple SELECT to get the resulting rows from the CTE.
          src = Select((cte,), (cte.c.id, cte.c.name, cte.c.timestamp))

          # Insert into the archive table whatever data was returned by the DELETE.
          res = (Archive
                 .insert_from(src, (Archive.id, Archive.name, Archive.timestamp))
                 .with_cte(cte)
                 .execute())

       The above corresponds to, roughly, the following SQL:

          WITH "moved_rows" AS (
              DELETE FROM "event" WHERE ("timestamp" &lt; XXXX-XX-XXTXX:XX:XX)
              RETURNING "id", "name", "timestamp")
          INSERT INTO "archive" ("id", "name", "timestamp")
          SELECT "moved_rows"."id", "moved_rows"."name", "moved_rows"."timestamp"
          FROM "moved_rows";

       For additional examples, refer to the tests in <b>models.py</b> and <b>sql.py</b>:

       • <u>https://github.com/coleifer/peewee/blob/master/tests/models.py</u>

       • <u>https://github.com/coleifer/peewee/blob/master/tests/sql.py</u>

   <b>Foreign</b> <b>Keys</b> <b>and</b> <b>Joins</b>
       This section has been moved into its own document: <u>Relationships</u> <u>and</u> <u>Joins</u>.

   <b>Query</b> <b>operators</b>
       The following types of comparisons are supported by peewee:
                                ┌────────────┬───────────────────────────────────────┐
                                │ Comparison │ Meaning                               │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>==</b>         │ x equals y                            │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>&lt;</b>          │ x is less than y                      │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>&lt;=</b>         │ x is less than or equal to y          │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>&gt;</b>          │ x is greater than y                   │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>&gt;=</b>         │ x is greater than or equal to y       │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>!=</b>         │ x is not equal to y                   │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>&lt;&lt;</b>         │ x IN y, where y is a list or query    │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>&gt;&gt;</b>         │ x IS y, where y is None/NULL          │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>%</b>          │ x  LIKE  y  where   y   may   contain │
                                │            │ wildcards                             │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>**</b>         │ x   ILIKE   y  where  y  may  contain │
                                │            │ wildcards                             │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>^</b>          │ x XOR y                               │
                                ├────────────┼───────────────────────────────────────┤
                                │ <b>~</b>          │ Unary negation (e.g., NOT x)          │
                                └────────────┴───────────────────────────────────────┘

       Because I ran out of operators to override, there are  some  additional  query  operations  available  as
       methods:
                           ┌─────────────────────┬───────────────────────────────────────┐
                           │ Method              │ Meaning                               │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.in_(value)</b>         │ IN lookup (identical to <b>&lt;&lt;</b>).          │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.not_in(value)</b>      │ NOT IN lookup.                        │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.is_null(is_null)</b>   │ IS  NULL  or  IS  NOT  NULL.  Accepts │
                           │                     │ boolean param.                        │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.contains(substr)</b>   │ Wild-card search for substring.       │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.startswith(prefix)</b> │ Search  for  values  beginning   with │
                           │                     │ <b>prefix</b>.                               │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.endswith(suffix)</b>   │ Search for values ending with <b>suffix</b>. │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.between(low,</b> <b>high)</b> │ Search where <b>low</b> <b>&lt;=</b> <b>value</b> <b>&lt;=</b> <b>high</b>.    │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.regexp(exp)</b>        │ Regular        expression       match │
                           │                     │ (case-sensitive).                     │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.iregexp(exp)</b>       │ Regular       expression        match │
                           │                     │ (case-insensitive).                   │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.bin_and(value)</b>     │ Binary AND.                           │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.bin_or(value)</b>      │ Binary OR.                            │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.concat(other)</b>      │ Concatenate  two  strings  or objects │
                           │                     │ using <b>||</b>.                             │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.distinct()</b>         │ Mark column for DISTINCT selection.   │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.collate(collation)</b> │ Specify   column   with   the   given │
                           │                     │ collation.                            │
                           ├─────────────────────┼───────────────────────────────────────┤
                           │ <b>.cast(type)</b>         │ Cast  the  value of the column to the │
                           │                     │ given type.                           │
                           └─────────────────────┴───────────────────────────────────────┘

       To combine clauses using logical operators, use:
                       ┌──────────┬──────────────────────┬────────────────────────────────────┐
                       │ Operator │ Meaning              │ Example                            │
                       ├──────────┼──────────────────────┼────────────────────────────────────┤
                       │ <b>&amp;</b>        │ AND                  │ <b>(User.is_active</b> <b>==</b>  <b>True)</b>  <b>&amp;</b>       │
                       │          │                      │ <b>(User.is_admin</b> <b>==</b> <b>True)</b>            │
                       ├──────────┼──────────────────────┼────────────────────────────────────┤
                       │ <b>|</b> (pipe) │ OR                   │ <b>(User.is_admin)</b>            <b>|</b>       │
                       │          │                      │ <b>(User.is_superuser)</b>                │
                       ├──────────┼──────────────────────┼────────────────────────────────────┤
                       │ <b>~</b>        │ NOT (unary negation) │ <b>~(User.username.contains('admin'))</b> │
                       └──────────┴──────────────────────┴────────────────────────────────────┘

       Here is how you might use some of these query operators:

          # Find the user whose username is "charlie".
          User.select().where(User.username == 'charlie')

          # Find the users whose username is in [charlie, huey, mickey]
          User.select().where(User.username.in_(['charlie', 'huey', 'mickey']))

          # Find users whose salary is between 50k and 60k (inclusive).
          Employee.select().where(Employee.salary.between(50000, 60000))

          Employee.select().where(Employee.name.startswith('C'))

          Blog.select().where(Blog.title.contains(search_string))

       Here is how you might combine expressions. Comparisons can be arbitrarily complex.

       <b>NOTE:</b>
          Note that the actual comparisons are wrapped in parentheses. Python's operator precedence necessitates
          that comparisons be wrapped in parentheses.

          # Find any users who are active administrations.
          User.select().where(
            (User.is_admin == True) &amp;
            (User.is_active == True))

          # Find any users who are either administrators or super-users.
          User.select().where(
            (User.is_admin == True) |
            (User.is_superuser == True))

          # Alternatively, use the boolean values directly. Here we query users who
          # are admins and NOT superusers.
          User.select().where(User.is_admin &amp; ~User.is_superuser)

          # Find any Tweets by users who are not admins (NOT IN).
          admins = User.select().where(User.is_admin == True)
          non_admin_tweets = Tweet.select().where(Tweet.user.not_in(admins))

          # Find any users who are not my friends (strangers).
          friends = User.select().where(User.username.in_(['charlie', 'huey', 'mickey']))
          strangers = User.select().where(User.id.not_in(friends))

       <b>WARNING:</b>
          Although you may be tempted to use python's  <b>in</b>,  <b>and</b>,  <b>or</b>,  <b>is</b>,  and  <b>not</b>  operators  in  your  query
          expressions, these <b>will</b> <b>not</b> <b>work.</b>  The return value of an <b>in</b> expression is always coerced to a boolean
          value.   Similarly,  <b>and</b>,  <b>or</b>  and  <b>not</b>  all  treat  their  arguments  as boolean values and cannot be
          overloaded.

          So just remember:

          • Use <b>.in_()</b> and <b>.not_in()</b> instead of <b>in</b> and <b>not</b> <b>in</b>

          • Use <b>&amp;</b> instead of <b>and</b>

          • Use <b>|</b> instead of <b>or</b>

          • Use <b>~</b> instead of <b>not</b>

          • Use <b>.is_null()</b> instead of <b>is</b> <b>None</b> or <b>==</b> <b>None</b>.

          • Use <b>==</b> and <b>!=</b> for comparing against <b>True</b> and <b>False</b>, or  you  may  use  the  implicit  value  of  the
            expression.

          • <b>Don't</b> <b>forget</b> <b>to</b> <b>wrap</b> <b>your</b> <b>comparisons</b> <b>in</b> <b>parentheses</b> <b>when</b> <b>using</b> <b>logical</b> <b>operators.</b>

       For more examples, see the <u>Expressions</u> section.

       <b>NOTE:</b>
          <b>LIKE</b> <b>and</b> <b>ILIKE</b> <b>with</b> <b>SQLite</b>

          Because  SQLite's  <b>LIKE</b>  operation  is  case-insensitive  by  default, peewee will use the SQLite <b>GLOB</b>
          operation for case-sensitive searches.  The glob operation uses asterisks for wildcards as opposed  to
          the  usual  percent-sign.  If  you  are  using SQLite and want case-sensitive partial string matching,
          remember to use asterisks for the wildcard.

   <b>Three</b> <b>valued</b> <b>logic</b>
       Because of the way SQL handles <b>NULL</b>, there are some special operations available for expressing:

       • <b>IS</b> <b>NULL</b>

       • <b>IS</b> <b>NOT</b> <b>NULL</b>

       • <b>IN</b>

       • <b>NOT</b> <b>IN</b>

       While it would be possible to use the <b>IS</b> <b>NULL</b> and <b>IN</b> operators with the negation operator (<b>~</b>),  sometimes
       to get the correct semantics you will need to explicitly use <b>IS</b> <b>NOT</b> <b>NULL</b> and <b>NOT</b> <b>IN</b>.

       The simplest way to use <b>IS</b> <b>NULL</b> and <b>IN</b> is to use the operator overloads:

          # Get all User objects whose last login is NULL.
          User.select().where(User.last_login &gt;&gt; None)

          # Get users whose username is in the given list.
          usernames = ['charlie', 'huey', 'mickey']
          User.select().where(User.username &lt;&lt; usernames)

       If you don't like operator overloads, you can call the Field methods instead:

          # Get all User objects whose last login is NULL.
          User.select().where(User.last_login.is_null(True))

          # Get users whose username is in the given list.
          usernames = ['charlie', 'huey', 'mickey']
          User.select().where(User.username.in_(usernames))

       To  negate  the  above queries, you can use unary negation, but for the correct semantics you may need to
       use the special <b>IS</b> <b>NOT</b> and <b>NOT</b> <b>IN</b> operators:

          # Get all User objects whose last login is *NOT* NULL.
          User.select().where(User.last_login.is_null(False))

          # Using unary negation instead.
          User.select().where(~(User.last_login &gt;&gt; None))

          # Get users whose username is *NOT* in the given list.
          usernames = ['charlie', 'huey', 'mickey']
          User.select().where(User.username.not_in(usernames))

          # Using unary negation instead.
          usernames = ['charlie', 'huey', 'mickey']
          User.select().where(~(User.username &lt;&lt; usernames))

   <b>Adding</b> <b>user-defined</b> <b>operators</b>
       Because I ran out of python operators to overload, there  are  some  missing  operators  in  peewee,  for
       instance  <b>modulo</b>.  If you find that you need to support an operator that is not in the table above, it is
       very easy to add your own.

       Here is how you might add support for <b>modulo</b> in SQLite:

          from peewee import *
          from peewee import Expression  # The building block for expressions.

          def mod(lhs, rhs):
              # Note: this works with Sqlite, but some drivers may use string-
              # formatting before sending the query to the database, so you may
              # need to use '%%' instead here.
              return Expression(lhs, '%', rhs)

       Now you can use these custom operators to build richer queries:

          # Users with even ids.
          User.select().where(mod(User.id, 2) == 0)

       For more examples check out the source to the <b>playhouse.postgresql_ext</b> module, as  it  contains  numerous
       operators specific to postgresql's hstore.

   <b>Expressions</b>
       Peewee  is  designed  to provide a simple, expressive, and pythonic way of constructing SQL queries. This
       section will provide a quick overview of some common types of expressions.

       There are two primary types of objects that can be composed to create expressions:

       • <u>Field</u> instances

       • SQL aggregations and functions using <u>fn</u>

       We will assume a simple "User" model with fields for username and other things.  It looks like this:

          class User(Model):
              username = CharField()
              is_admin = BooleanField()
              is_active = BooleanField()
              last_login = DateTimeField()
              login_count = IntegerField()
              failed_logins = IntegerField()

       Comparisons use the <u>Query</u> <u>operators</u>:

          # username is equal to 'charlie'
          User.username == 'charlie'

          # user has logged in less than 5 times
          User.login_count &lt; 5

       Comparisons can be combined using <b>bitwise</b> <u>and</u> and <u>or</u>. Operator precedence is  controlled  by  python  and
       comparisons can be nested to an arbitrary depth:

          # User is both and admin and has logged in today
          (User.is_admin == True) &amp; (User.last_login &gt;= today)

          # User's username is either charlie or charles
          (User.username == 'charlie') | (User.username == 'charles')

          # User is active and not a superuser.
          (User.is_active &amp; ~User.is_superuser)

       Comparisons can be used with functions as well:

          # user's username starts with a 'g' or a 'G':
          fn.Lower(fn.Substr(User.username, 1, 1)) == 'g'

       We  can  do  some  fairly  interesting  things, as expressions can be compared against other expressions.
       Expressions also support arithmetic operations:

          # users who entered the incorrect more than half the time and have logged
          # in at least 10 times
          (User.failed_logins &gt; (User.login_count * .5)) &amp; (User.login_count &gt; 10)

       Expressions allow us to do <u>atomic</u> <u>updates</u>:

          # when a user logs in we want to increment their login count:
          User.update(login_count=User.login_count + 1).where(User.id == user_id)

       Expressions can be used in all parts of a query, so experiment!

   <b>Row</b> <b>values</b>
       Many databases support <u>row</u> <u>values</u>, which are similar to Python <u>tuple</u> objects. In Peewee, it  is  possible
       to use row-values in expressions via <u>Tuple</u>. For example,

          # If for some reason your schema stores dates in separate columns ("year",
          # "month" and "day"), you can use row-values to find all rows that happened
          # in a given month:
          Tuple(Event.year, Event.month) == (2019, 1)

       The  more  common  use  for row-values is to compare against multiple columns from a subquery in a single
       expression. There are other ways to express these types of queries, but row-values may  offer  a  concise
       and readable approach.

       For  example,  assume  we have a table "EventLog" which contains an event type, an event source, and some
       metadata. We also have an "IncidentLog", which has incident type, incident source, and metadata  columns.
       We can use row-values to correlate incidents with certain events:

          class EventLog(Model):
              event_type = TextField()
              source = TextField()
              data = TextField()
              timestamp = TimestampField()

          class IncidentLog(Model):
              incident_type = TextField()
              source = TextField()
              traceback = TextField()
              timestamp = TimestampField()

          # Get a list of all the incident types and sources that have occurred today.
          incidents = (IncidentLog
                       .select(IncidentLog.incident_type, IncidentLog.source)
                       .where(IncidentLog.timestamp &gt;= datetime.date.today()))

          # Find all events that correlate with the type and source of the
          # incidents that occurred today.
          events = (EventLog
                    .select()
                    .where(Tuple(EventLog.event_type, EventLog.source).in_(incidents))
                    .order_by(EventLog.timestamp))

       Other  ways  to  express  this  type  of query would be to use a <u>join</u> or to <u>join</u> <u>on</u> <u>a</u> <u>subquery</u>. The above
       example is there just to give you and idea how <u>Tuple</u> might be used.

       You can also use row-values to update multiple columns in a table, when the new data is  derived  from  a
       subquery. For an example, see <u>here</u>.

   <b>SQL</b> <b>Functions</b>
       SQL functions, like <b>COUNT()</b> or <b>SUM()</b>, can be expressed using the <u>fn()</u> helper:

          # Get all users and the number of tweets they've authored. Sort the
          # results from most tweets -&gt; fewest tweets.
          query = (User
                   .select(User, fn.COUNT(Tweet.id).alias('tweet_count'))
                   .join(Tweet, JOIN.LEFT_OUTER)
                   .group_by(User)
                   .order_by(fn.COUNT(Tweet.id).desc()))
          for user in query:
              print('%s -- %s tweets' % (user.username, user.tweet_count))

       The  <b>fn</b>  helper  exposes  any  SQL function as if it were a method. The parameters can be fields, values,
       subqueries, or even nested functions.

   <b>Nesting</b> <b>function</b> <b>calls</b>
       Suppose you need to want to get a list of all users whose username begins with <u>a</u>. There are a couple ways
       to do this, but one method might be to use some SQL functions like <u>LOWER</u> and <u>SUBSTR</u>. To use arbitrary SQL
       functions, use the special <u>fn()</u> object to construct queries:

          # Select the user's id, username and the first letter of their username, lower-cased
          first_letter = fn.LOWER(fn.SUBSTR(User.username, 1, 1))
          query = User.select(User, first_letter.alias('first_letter'))

          # Alternatively we could select only users whose username begins with 'a'
          a_users = User.select().where(first_letter == 'a')

          &gt;&gt;&gt; for user in a_users:
          ...    print(user.username)

   <b>SQL</b> <b>Helper</b>
       There are times when you may want to simply pass in some arbitrary sql. You can do this using the special
       <u>SQL</u> class. One use-case is when referencing an alias:

          # We'll query the user table and annotate it with a count of tweets for
          # the given user
          query = (User
                   .select(User, fn.Count(Tweet.id).alias('ct'))
                   .join(Tweet)
                   .group_by(User))

          # Now we will order by the count, which was aliased to "ct"
          query = query.order_by(SQL('ct'))

          # You could, of course, also write this as:
          query = query.order_by(fn.COUNT(Tweet.id))

       There are two ways to execute hand-crafted SQL statements with peewee:

       1. <u>Database.execute_sql()</u> for executing any type of query

       2. <u>RawQuery</u> for executing <b>SELECT</b> queries and returning model instances.

   <b>Security</b> <b>and</b> <b>SQL</b> <b>Injection</b>
       By default peewee will parameterize queries, so any parameters passed in by the user will be escaped. The
       only exception to this rule is if you are writing a raw SQL query or are passing in a  <b>SQL</b>  object  which
       may  contain  untrusted data. To mitigate this, ensure that any user-defined data is passed in as a query
       parameter and not part of the actual SQL query:

          # Bad! DO NOT DO THIS!
          query = MyModel.raw('SELECT * FROM my_table WHERE data = %s' % (user_data,))

          # Good. `user_data` will be treated as a parameter to the query.
          query = MyModel.raw('SELECT * FROM my_table WHERE data = %s', user_data)

          # Bad! DO NOT DO THIS!
          query = MyModel.select().where(SQL('Some SQL expression %s' % user_data))

          # Good. `user_data` will be treated as a parameter.
          query = MyModel.select().where(SQL('Some SQL expression %s', user_data))

       <b>NOTE:</b>
          MySQL and Postgresql use <b>'%s'</b> to denote parameters. SQLite, on the other hand, uses <b>'?'</b>.  Be  sure  to
          use  the  character  appropriate  to  your  database.  You  can  also  find this parameter by checking
          <b>Database.param</b>.

   <b>Relationships</b> <b>and</b> <b>Joins</b>
       In this document we'll cover how Peewee handles relationships between models.

   <b>Model</b> <b>definitions</b>
       We'll use the following model definitions for our examples:

          import datetime
          from peewee import *

          db = SqliteDatabase(':memory:')

          class BaseModel(Model):
              class Meta:
                  database = db

          class User(BaseModel):
              username = TextField()

          class Tweet(BaseModel):
              content = TextField()
              timestamp = DateTimeField(default=datetime.datetime.now)
              user = ForeignKeyField(User, backref='tweets')

          class Favorite(BaseModel):
              user = ForeignKeyField(User, backref='favorites')
              tweet = ForeignKeyField(Tweet, backref='favorites')

       Peewee uses <u>ForeignKeyField</u> to define foreign-key relationships between models. Every  foreign-key  field
       has an implied back-reference, which is exposed as a pre-filtered <u>Select</u> query using the provided <b>backref</b>
       attribute.

   <b>Creating</b> <b>test</b> <b>data</b>
       To follow along with the examples, let's populate this database with some test data:

          def populate_test_data():
              db.create_tables([User, Tweet, Favorite])

              data = (
                  ('huey', ('meow', 'hiss', 'purr')),
                  ('mickey', ('woof', 'whine')),
                  ('zaizee', ()))
              for username, tweets in data:
                  user = User.create(username=username)
                  for tweet in tweets:
                      Tweet.create(user=user, content=tweet)

              # Populate a few favorites for our users, such that:
              favorite_data = (
                  ('huey', ['whine']),
                  ('mickey', ['purr']),
                  ('zaizee', ['meow', 'purr']))
              for username, favorites in favorite_data:
                  user = User.get(User.username == username)
                  for content in favorites:
                      tweet = Tweet.get(Tweet.content == content)
                      Favorite.create(user=user, tweet=tweet)

       This gives us the following:
                                         ┌────────┬───────┬────────────────┐
                                         │ User   │ Tweet │ Favorited by   │
                                         ├────────┼───────┼────────────────┤
                                         │ huey   │ meow  │ zaizee         │
                                         ├────────┼───────┼────────────────┤
                                         │ huey   │ hiss  │                │
                                         ├────────┼───────┼────────────────┤
                                         │ huey   │ purr  │ mickey, zaizee │
                                         ├────────┼───────┼────────────────┤
                                         │ mickey │ woof  │                │
                                         ├────────┼───────┼────────────────┤
                                         │ mickey │ whine │ huey           │
                                         └────────┴───────┴────────────────┘

       <b>ATTENTION:</b>
          In the following examples we will be executing a number of queries. If you are unsure how many queries
          are being executed, you can add the following code, which will log all queries to the console:

              import logging
              logger = logging.getLogger('peewee')
              logger.addHandler(logging.StreamHandler())
              logger.setLevel(logging.DEBUG)

       <b>NOTE:</b>
          In SQLite, foreign keys are not enabled by default. Most things, including the Peewee foreign-key API,
          will  work  fine, but ON DELETE behaviour will be ignored, even if you explicitly specify <b>on_delete</b> in
          your <u>ForeignKeyField</u>. In conjunction with the default <u>AutoField</u> behaviour (where  deleted  record  IDs
          can  be  reused),  this  can  lead  to  subtle  bugs.  To  avoid problems, I recommend that you enable
          foreign-key constraints when using SQLite, by setting <b>pragmas={'foreign_keys':</b> <b>1}</b> when you instantiate
          <u>SqliteDatabase</u>.

              # Ensure foreign-key constraints are enforced.
              db = SqliteDatabase('my_app.db', pragmas={'foreign_keys': 1})

   <b>Performing</b> <b>simple</b> <b>joins</b>
       As an exercise in learning how to perform joins with Peewee, let's write a query to  print  out  all  the
       tweets by "huey". To do this we'll select from the <b>Tweet</b> model and join on the <b>User</b> model, so we can then
       filter on the <b>User.username</b> field:

          &gt;&gt;&gt; query = Tweet.select().join(User).where(User.username == 'huey')
          &gt;&gt;&gt; for tweet in query:
          ...     print(tweet.content)
          ...
          meow
          hiss
          purr

       <b>NOTE:</b>
          We  did  not  have to explicitly specify the join predicate (the "ON" clause), because Peewee inferred
          from the models that when we joined from Tweet to User, we were joining on the <b>Tweet.user</b> foreign-key.

          The following code is equivalent, but more explicit:

              query = (Tweet
                       .select()
                       .join(User, on=(Tweet.user == User.id))
                       .where(User.username == 'huey'))

       If we already had a reference to the <b>User</b> object for "huey", we could use the <b>User.tweets</b>  back-reference
       to list all of huey's tweets:

          &gt;&gt;&gt; huey = User.get(User.username == 'huey')
          &gt;&gt;&gt; for tweet in huey.tweets:
          ...     print(tweet.content)
          ...
          meow
          hiss
          purr

       Taking a closer look at <b>huey.tweets</b>, we can see that it is just a simple pre-filtered <b>SELECT</b> query:

          &gt;&gt;&gt; huey.tweets
          &lt;peewee.ModelSelect at 0x7f0483931fd0&gt;

          &gt;&gt;&gt; huey.tweets.sql()
          ('SELECT "t1"."id", "t1"."content", "t1"."timestamp", "t1"."user_id"
            FROM "tweet" AS "t1" WHERE ("t1"."user_id" = ?)', [1])

   <b>Joining</b> <b>multiple</b> <b>tables</b>
       Let's  take another look at joins by querying the list of users and getting the count of how many tweet's
       they've authored that were favorited. This will require us to join twice: from user to  tweet,  and  from
       tweet  to  favorite.  We'll  add  the  additional  requirement that users should be included who have not
       created any tweets, as well as users whose tweets have not been favorited. The query, expressed  in  SQL,
       would be:

          SELECT user.username, COUNT(favorite.id)
          FROM user
          LEFT OUTER JOIN tweet ON tweet.user_id = user.id
          LEFT OUTER JOIN favorite ON favorite.tweet_id = tweet.id
          GROUP BY user.username

       <b>NOTE:</b>
          In  the  above  query both joins are LEFT OUTER, since a user may not have any tweets or, if they have
          tweets, none of them may have been favorited.

       Peewee has a concept of a <u>join</u> <u>context</u>,  meaning  that  whenever  we  call  the  <u>join()</u>  method,  we  are
       implicitly  joining  on  the  previously-joined  model  (or  if  this is the first call, the model we are
       selecting from). Since we are joining straight through, from user to tweet, then from tweet to  favorite,
       we can simply write:

          query = (User
                   .select(User.username, fn.COUNT(Favorite.id).alias('count'))
                   .join(Tweet, JOIN.LEFT_OUTER)  # Joins user -&gt; tweet.
                   .join(Favorite, JOIN.LEFT_OUTER)  # Joins tweet -&gt; favorite.
                   .group_by(User.username))

       Iterating over the results:

          &gt;&gt;&gt; for user in query:
          ...     print(user.username, user.count)
          ...
          huey 3
          mickey 1
          zaizee 0

       For  a  more complicated example involving multiple joins and switching join contexts, let's find all the
       tweets by Huey and the number of times they've been favorited. To do this we'll need to perform two joins
       and we'll also use an aggregate function to calculate the favorite count.

       Here is how we would write this query in SQL:

          SELECT tweet.content, COUNT(favorite.id)
          FROM tweet
          INNER JOIN user ON tweet.user_id = user.id
          LEFT OUTER JOIN favorite ON favorite.tweet_id = tweet.id
          WHERE user.username = 'huey'
          GROUP BY tweet.content;

       <b>NOTE:</b>
          We use a LEFT OUTER join from tweet to favorite since a tweet may not have any favorites, yet we still
          wish to display it's content (along with a count of zero) in the result set.

       With Peewee, the resulting Python code looks very similar to what we would write in SQL:

          query = (Tweet
                   .select(Tweet.content, fn.COUNT(Favorite.id).alias('count'))
                   .join(User)  # Join from tweet -&gt; user.
                   .switch(Tweet)  # Move "join context" back to tweet.
                   .join(Favorite, JOIN.LEFT_OUTER)  # Join from tweet -&gt; favorite.
                   .where(User.username == 'huey')
                   .group_by(Tweet.content))

       Note the call to <u>switch()</u> - that instructs Peewee to set the <u>join</u>  <u>context</u>  back  to  <b>Tweet</b>.  If  we  had
       omitted  the  explicit call to switch, Peewee would have used <b>User</b> (the last model we joined) as the join
       context and constructed the join from User to Favorite using the <b>Favorite.user</b> foreign-key,  which  would
       have given us incorrect results.

       If  we  wanted  to  omit  the  join-context  switching  we  could instead use the <u>join_from()</u> method. The
       following query is equivalent to the previous one:

          query = (Tweet
                   .select(Tweet.content, fn.COUNT(Favorite.id).alias('count'))
                   .join_from(Tweet, User)  # Join tweet -&gt; user.
                   .join_from(Tweet, Favorite, JOIN.LEFT_OUTER)  # Join tweet -&gt; favorite.
                   .where(User.username == 'huey')
                   .group_by(Tweet.content))

       We can iterate over the results of the above query to print the tweet's content and the favorite count:

          &gt;&gt;&gt; for tweet in query:
          ...     print('%s favorited %d times' % (tweet.content, tweet.count))
          ...
          meow favorited 1 times
          hiss favorited 0 times
          purr favorited 2 times

   <b>Selecting</b> <b>from</b> <b>multiple</b> <b>sources</b>
       If we wished to list all the tweets in the database, along with the username of their author,  you  might
       try writing this:

          &gt;&gt;&gt; for tweet in Tweet.select():
          ...     print(tweet.user.username, '-&gt;', tweet.content)
          ...
          huey -&gt; meow
          huey -&gt; hiss
          huey -&gt; purr
          mickey -&gt; woof
          mickey -&gt; whine

       There  is  a  big problem with the above loop: it executes an additional query for every tweet to look up
       the <b>tweet.user</b> foreign-key. For our small table the performance penalty isn't obvious, but we would  find
       the delays grew as the number of rows increased.

       If  you're  familiar  with  SQL,  you  might  remember that it's possible to SELECT from multiple tables,
       allowing us to get the tweet content <u>and</u> the username in a single query:

          SELECT tweet.content, user.username
          FROM tweet
          INNER JOIN user ON tweet.user_id = user.id;

       Peewee makes this quite easy. In fact, we only need to modify our query a little bit. We tell  Peewee  we
       wish  to  select  <b>Tweet.content</b>  as well as the <b>User.username</b> field, then we include a join from tweet to
       user.  To make it a bit more obvious that it's doing the correct thing, we can ask Peewee to  return  the
       rows as dictionaries.

          &gt;&gt;&gt; for row in Tweet.select(Tweet.content, User.username).join(User).dicts():
          ...     print(row)
          ...
          {'content': 'meow', 'username': 'huey'}
          {'content': 'hiss', 'username': 'huey'}
          {'content': 'purr', 'username': 'huey'}
          {'content': 'woof', 'username': 'mickey'}
          {'content': 'whine', 'username': 'mickey'}

       Now  we'll  leave  off  the  call  to ".dicts()" and return the rows as <b>Tweet</b> objects. Notice that Peewee
       assigns the <b>username</b> value to <b>tweet.user.username</b> -- NOT <b>tweet.username</b>!  Because there is a  foreign-key
       from tweet to user, and we have selected fields from both models, Peewee will reconstruct the model-graph
       for us:

          &gt;&gt;&gt; for tweet in Tweet.select(Tweet.content, User.username).join(User):
          ...     print(tweet.user.username, '-&gt;', tweet.content)
          ...
          huey -&gt; meow
          huey -&gt; hiss
          huey -&gt; purr
          mickey -&gt; woof
          mickey -&gt; whine

       If  we  wish  to,  we  can  control  where  Peewee  puts  the joined <b>User</b> instance in the above query, by
       specifying an <b>attr</b> in the <b>join()</b> method:

          &gt;&gt;&gt; query = Tweet.select(Tweet.content, User.username).join(User, attr='author')
          &gt;&gt;&gt; for tweet in query:
          ...     print(tweet.author.username, '-&gt;', tweet.content)
          ...
          huey -&gt; meow
          huey -&gt; hiss
          huey -&gt; purr
          mickey -&gt; woof
          mickey -&gt; whine

       Conversely, if we simply wish <u>all</u> attributes we select to be attributes of the <b>Tweet</b> instance, we can add
       a call to <u>objects()</u> at the end of our query (similar to how we called <b>dicts()</b>):

          &gt;&gt;&gt; for tweet in query.objects():
          ...     print(tweet.username, '-&gt;', tweet.content)
          ...
          huey -&gt; meow
          (etc)

   <b>More</b> <b>complex</b> <b>example</b>
       As a more complex example, in this query, we will write a single query that selects  all  the  favorites,
       along with the user who created the favorite, the tweet that was favorited, and that tweet's author.

       In SQL we would write:

          SELECT owner.username, tweet.content, author.username AS author
          FROM favorite
          INNER JOIN user AS owner ON (favorite.user_id = owner.id)
          INNER JOIN tweet ON (favorite.tweet_id = tweet.id)
          INNER JOIN user AS author ON (tweet.user_id = author.id);

       Note  that  we  are selecting from the user table twice - once in the context of the user who created the
       favorite, and again as the author of the tweet.

       With Peewee, we use <u>Model.alias()</u> to alias a model class so it can be referenced twice in a single query:

          Owner = User.alias()
          query = (Favorite
                   .select(Favorite, Tweet.content, User.username, Owner.username)
                   .join(Owner)  # Join favorite -&gt; user (owner of favorite).
                   .switch(Favorite)
                   .join(Tweet)  # Join favorite -&gt; tweet
                   .join(User))   # Join tweet -&gt; user

       We can iterate over the results and access the joined values in the following way. Note  how  Peewee  has
       resolved the fields from the various models we selected and reconstructed the model graph:

          &gt;&gt;&gt; for fav in query:
          ...     print(fav.user.username, 'liked', fav.tweet.content, 'by', fav.tweet.user.username)
          ...
          huey liked whine by mickey
          mickey liked purr by huey
          zaizee liked meow by huey
          zaizee liked purr by huey

   <b>Subqueries</b>
       Peewee  allows  you  to  join  on any table-like object, including subqueries or common table expressions
       (CTEs). To demonstrate joining on a subquery, let's query for all users and their latest tweet.

       Here is the SQL:

          SELECT tweet.*, user.*
          FROM tweet
          INNER JOIN (
              SELECT latest.user_id, MAX(latest.timestamp) AS max_ts
              FROM tweet AS latest
              GROUP BY latest.user_id) AS latest_query
          ON ((tweet.user_id = latest_query.user_id) AND (tweet.timestamp = latest_query.max_ts))
          INNER JOIN user ON (tweet.user_id = user.id)

       We'll do this by creating a subquery which selects each user and the timestamp  of  their  latest  tweet.
       Then we can query the tweets table in the outer query and join on the user and timestamp combination from
       the subquery.

          # Define our subquery first. We'll use an alias of the Tweet model, since
          # we will be querying from the Tweet model directly in the outer query.
          Latest = Tweet.alias()
          latest_query = (Latest
                          .select(Latest.user, fn.MAX(Latest.timestamp).alias('max_ts'))
                          .group_by(Latest.user)
                          .alias('latest_query'))

          # Our join predicate will ensure that we match tweets based on their
          # timestamp *and* user_id.
          predicate = ((Tweet.user == latest_query.c.user_id) &amp;
                       (Tweet.timestamp == latest_query.c.max_ts))

          # We put it all together, querying from tweet and joining on the subquery
          # using the above predicate.
          query = (Tweet
                   .select(Tweet, User)  # Select all columns from tweet and user.
                   .join(latest_query, on=predicate)  # Join tweet -&gt; subquery.
                   .join_from(Tweet, User))  # Join from tweet -&gt; user.

       Iterating over the query, we can see each user and their latest tweet.

          &gt;&gt;&gt; for tweet in query:
          ...     print(tweet.user.username, '-&gt;', tweet.content)
          ...
          huey -&gt; purr
          mickey -&gt; whine

       There  are  a  couple things you may not have seen before in the code we used to create the query in this
       section:

       • We used <u>join_from()</u> to explicitly specify the join context. We wrote <b>.join_from(Tweet,</b> <b>User)</b>, which  is
         equivalent to <b>.switch(Tweet).join(User)</b>.

       • We  referenced columns in the subquery using the magic <b>.c</b> attribute, for example <b>latest_query.c.max_ts</b>.
         The <b>.c</b> attribute is used to dynamically create column references.

       • Instead of passing individual fields to <b>Tweet.select()</b>, we passed the <b>Tweet</b> and <b>User</b>  models.  This  is
         shorthand for selecting all fields on the given model.

   <b>Common-table</b> <b>Expressions</b>
       In  the  previous  section  we joined on a subquery, but we could just as easily have used a <u>common-table</u>
       <u>expression</u> <u>(CTE)</u>. We will repeat the same query as before, listing users and  their  latest  tweets,  but
       this time we will do it using a CTE.

       Here is the SQL:

          WITH latest AS (
              SELECT user_id, MAX(timestamp) AS max_ts
              FROM tweet
              GROUP BY user_id)
          SELECT tweet.*, user.*
          FROM tweet
          INNER JOIN latest
              ON ((latest.user_id = tweet.user_id) AND (latest.max_ts = tweet.timestamp))
          INNER JOIN user
              ON (tweet.user_id = user.id)

       This example looks very similar to the previous example with the subquery:

          # Define our CTE first. We'll use an alias of the Tweet model, since
          # we will be querying from the Tweet model directly in the main query.
          Latest = Tweet.alias()
          cte = (Latest
                 .select(Latest.user, fn.MAX(Latest.timestamp).alias('max_ts'))
                 .group_by(Latest.user)
                 .cte('latest'))

          # Our join predicate will ensure that we match tweets based on their
          # timestamp *and* user_id.
          predicate = ((Tweet.user == cte.c.user_id) &amp;
                       (Tweet.timestamp == cte.c.max_ts))

          # We put it all together, querying from tweet and joining on the CTE
          # using the above predicate.
          query = (Tweet
                   .select(Tweet, User)  # Select all columns from tweet and user.
                   .join(cte, on=predicate)  # Join tweet -&gt; CTE.
                   .join_from(Tweet, User)  # Join from tweet -&gt; user.
                   .with_cte(cte))

       We can iterate over the result-set, which consists of the latest tweets for each user:

          &gt;&gt;&gt; for tweet in query:
          ...     print(tweet.user.username, '-&gt;', tweet.content)
          ...
          huey -&gt; purr
          mickey -&gt; whine

       <b>NOTE:</b>
          For more information about using CTEs, including information on writing recursive CTEs, see the <u>Common</u>
          <u>Table</u> <u>Expressions</u> section of the "Querying" document.

   <b>Multiple</b> <b>foreign-keys</b> <b>to</b> <b>the</b> <b>same</b> <b>Model</b>
       When  there  are multiple foreign keys to the same model, it is good practice to explicitly specify which
       field you are joining on.

       Referring back to the <u>example</u> <u>app's</u> <u>models</u>, consider the <u>Relationship</u> model, which is used to denote when
       one user follows another. Here is the model definition:

          class Relationship(BaseModel):
              from_user = ForeignKeyField(User, backref='relationships')
              to_user = ForeignKeyField(User, backref='related_to')

              class Meta:
                  indexes = (
                      # Specify a unique multi-column index on from/to-user.
                      (('from_user', 'to_user'), True),
                  )

       Since there are two foreign keys to <u>User</u>, we should always specify which field we are using in a join.

       For example, to determine which users I am following, I would write:

          (User
           .select()
           .join(Relationship, on=Relationship.to_user)
           .where(Relationship.from_user == charlie))

       On the other hand, if I wanted to determine which users are following me, I would  instead  join  on  the
       <u>from_user</u> column and filter on the relationship's <u>to_user</u>:

          (User
           .select()
           .join(Relationship, on=Relationship.from_user)
           .where(Relationship.to_user == charlie))

   <b>Joining</b> <b>on</b> <b>arbitrary</b> <b>fields</b>
       If  a  foreign  key does not exist between two tables you can still perform a join, but you must manually
       specify the join predicate.

       In the following example, there is no explicit foreign-key between <u>User</u> and <u>ActivityLog</u>, but there is  an
       implied  relationship  between  the  <u>ActivityLog.object_id</u>  field  and  <u>User.id</u>. Rather than joining on a
       specific <u>Field</u>, we will join using an <u>Expression</u>.

          user_log = (User
                      .select(User, ActivityLog)
                      .join(ActivityLog, on=(User.id == ActivityLog.object_id), attr='log')
                      .where(
                          (ActivityLog.activity_type == 'user_activity') &amp;
                          (User.username == 'charlie')))

          for user in user_log:
              print(user.username, user.log.description)

          #### Print something like ####
          charlie logged in
          charlie posted a tweet
          charlie retweeted
          charlie posted a tweet
          charlie logged out

       <b>NOTE:</b>
          Recall that we can control the attribute Peewee will assign the joined instance to by  specifying  the
          <b>attr</b> parameter in the <b>join()</b> method.  In the previous example, we used the following <u>join</u>:

              join(ActivityLog, on=(User.id == ActivityLog.object_id), attr='log')

          Then  when  iterating  over  the query, we were able to directly access the joined <u>ActivityLog</u> without
          incurring an additional query:

              for user in user_log:
                  print(user.username, user.log.description)

   <b>Self-joins</b>
       Peewee supports constructing queries containing a self-join.

   <b>Using</b> <b>model</b> <b>aliases</b>
       To join on the same model (table) twice, it is necessary to create a model alias to represent the  second
       instance of the table in a query. Consider the following model:

          class Category(Model):
              name = CharField()
              parent = ForeignKeyField('self', backref='children')

       What  if  we  wanted  to  query  all categories whose parent category is <u>Electronics</u>. One way would be to
       perform a self-join:

          Parent = Category.alias()
          query = (Category
                   .select()
                   .join(Parent, on=(Category.parent == Parent.id))
                   .where(Parent.name == 'Electronics'))

       When performing a join that uses a <u>ModelAlias</u>, it is necessary to specify the join condition using the <b>on</b>
       keyword argument. In this case we are joining the category with its parent category.

   <b>Using</b> <b>subqueries</b>
       Another less common approach involves the use of subqueries. Here is another way  we  might  construct  a
       query to get all the categories whose parent category is <u>Electronics</u> using a subquery:

          Parent = Category.alias()
          join_query = Parent.select().where(Parent.name == 'Electronics')

          # Subqueries used as JOINs need to have an alias.
          join_query = join_query.alias('jq')

          query = (Category
                   .select()
                   .join(join_query, on=(Category.parent == join_query.c.id)))

       This will generate the following SQL query:

          SELECT t1."id", t1."name", t1."parent_id"
          FROM "category" AS t1
          INNER JOIN (
            SELECT t2."id"
            FROM "category" AS t2
            WHERE (t2."name" = ?)) AS jq ON (t1."parent_id" = "jq"."id")

       To  access the <b>id</b> value from the subquery, we use the <b>.c</b> magic lookup which will generate the appropriate
       SQL expression:

          Category.parent == join_query.c.id
          # Becomes: (t1."parent_id" = "jq"."id")

   <b>Implementing</b> <b>Many</b> <b>to</b> <b>Many</b>
       Peewee provides a field for representing many-to-many relationships, much like Django does. This  feature
       was  added  due to many requests from users, but I strongly advocate against using it, since it conflates
       the idea of a field with a junction table and hidden joins. It's just a nasty hack to provide  convenient
       accessors.

       To  implement  many-to-many  <b>correctly</b>  with  peewee,  you  will  therefore create the intermediary table
       yourself and query through it:

          class Student(Model):
              name = CharField()

          class Course(Model):
              name = CharField()

          class StudentCourse(Model):
              student = ForeignKeyField(Student)
              course = ForeignKeyField(Course)

       To query, let's say we want to find students who are enrolled in math class:

          query = (Student
                   .select()
                   .join(StudentCourse)
                   .join(Course)
                   .where(Course.name == 'math'))
          for student in query:
              print(student.name)

       To query what classes a given student is enrolled in:

          courses = (Course
                     .select()
                     .join(StudentCourse)
                     .join(Student)
                     .where(Student.name == 'da vinci'))

          for course in courses:
              print(course.name)

       To efficiently iterate over a many-to-many  relation,  i.e.,  list  all  students  and  their  respective
       courses, we will query the <u>through</u> model <b>StudentCourse</b> and <u>precompute</u> the Student and Course:

          query = (StudentCourse
                   .select(StudentCourse, Student, Course)
                   .join(Course)
                   .switch(StudentCourse)
                   .join(Student)
                   .order_by(Student.name))

       To print a list of students and their courses you might do the following:

          for student_course in query:
              print(student_course.student.name, '-&gt;', student_course.course.name)

       Since we selected all fields from <b>Student</b> and <b>Course</b> in the <u>select</u> clause of the query, these foreign key
       traversals are "free" and we've done the whole iteration with just 1 query.

   <b>ManyToManyField</b>
       The  <u>ManyToManyField</u>  provides  a  <u>field-like</u>  API  over  many-to-many  fields.  For all but the simplest
       many-to-many situations, you're better off using the standard peewee APIs. But, if your models  are  very
       simple and your querying needs are not very complex, <u>ManyToManyField</u> may work.

       Modeling students and courses using <u>ManyToManyField</u>:

          from peewee import *

          db = SqliteDatabase('school.db')

          class BaseModel(Model):
              class Meta:
                  database = db

          class Student(BaseModel):
              name = CharField()

          class Course(BaseModel):
              name = CharField()
              students = ManyToManyField(Student, backref='courses')

          StudentCourse = Course.students.get_through_model()

          db.create_tables([
              Student,
              Course,
              StudentCourse])

          # Get all classes that "huey" is enrolled in:
          huey = Student.get(Student.name == 'Huey')
          for course in huey.courses.order_by(Course.name):
              print(course.name)

          # Get all students in "English 101":
          engl_101 = Course.get(Course.name == 'English 101')
          for student in engl_101.students:
              print(student.name)

          # When adding objects to a many-to-many relationship, we can pass
          # in either a single model instance, a list of models, or even a
          # query of models:
          huey.courses.add(Course.select().where(Course.name.contains('English')))

          engl_101.students.add(Student.get(Student.name == 'Mickey'))
          engl_101.students.add([
              Student.get(Student.name == 'Charlie'),
              Student.get(Student.name == 'Zaizee')])

          # The same rules apply for removing items from a many-to-many:
          huey.courses.remove(Course.select().where(Course.name.startswith('CS')))

          engl_101.students.remove(huey)

          # Calling .clear() will remove all associated objects:
          cs_150.students.clear()

       <b>ATTENTION:</b>
          Before  many-to-many  relationships  can  be added, the objects being referenced will need to be saved
          first. In order to create relationships in the many-to-many through table, Peewee needs  to  know  the
          primary keys of the models being referenced.

       <b>WARNING:</b>
          It  is  <b>strongly</b>  <b>recommended</b>  that  you  do not attempt to subclass models containing <u>ManyToManyField</u>
          instances.

          A <u>ManyToManyField</u>, despite its name, is not a field in the usual sense. Instead of being a column on a
          table, the many-to-many field covers the fact that behind-the-scenes there's actually a separate table
          with two foreign-key pointers (the <u>through</u> <u>table</u>).

          Therefore, when a subclass is created that inherits a many-to-many field, what actually  needs  to  be
          inherited  is  the <u>through</u> <u>table</u>. Because of the potential for subtle bugs, Peewee does not attempt to
          automatically  subclass  the  through  model  and  modify  its  foreign-key  pointers.  As  a  result,
          many-to-many fields typically will not work with inheritance.

       For more examples, see:

       • <u>ManyToManyField.add()</u>

       • <u>ManyToManyField.remove()</u>

       • <u>ManyToManyField.clear()</u>

       • <u>ManyToManyField.get_through_model()</u>

   <b>Avoiding</b> <b>the</b> <b>N+1</b> <b>problem</b>
       The  <u>N+1</u>  <u>problem</u>  refers  to a situation where an application performs a query, then for each row of the
       result set, the application performs at least one other query (another way to conceptualize this is as  a
       nested  loop).  In  many cases, these <u>n</u> queries can be avoided through the use of a SQL join or subquery.
       The database itself may do a nested loop, but it will usually be more performant than doing <u>n</u> queries  in
       your  application code, which involves latency communicating with the database and may not take advantage
       of indices or other optimizations employed by the database when joining or executing a subquery.

       Peewee provides several APIs for mitigating <u>N+1</u> query behavior. Recollecting the models  used  throughout
       this document, <u>User</u> and <u>Tweet</u>, this section will try to outline some common <u>N+1</u> scenarios, and how peewee
       can help you avoid them.

       <b>ATTENTION:</b>
          In  some  cases,  N+1  queries  will not result in a significant or measurable performance hit. It all
          depends on the data you are querying, the  database  you  are  using,  and  the  latency  involved  in
          executing  queries  and  retrieving  results.  As always when making optimizations, profile before and
          after to ensure the changes do what you expect them to.

   <b>List</b> <b>recent</b> <b>tweets</b>
       The twitter timeline displays a list of tweets from multiple users. In addition to the  tweet's  content,
       the username of the tweet's author is also displayed.  The N+1 scenario here would be:

       1. Fetch the 10 most recent tweets.

       2. For each tweet, select the author (10 queries).

       By selecting both tables and using a <u>join</u>, peewee makes it possible to accomplish this in a single query:

          query = (Tweet
                   .select(Tweet, User)  # Note that we are selecting both models.
                   .join(User)  # Use an INNER join because every tweet has an author.
                   .order_by(Tweet.id.desc())  # Get the most recent tweets.
                   .<a href="../man10/limit.10.html">limit</a>(10))

          for tweet in query:
              print(tweet.user.username, '-', tweet.message)

       Without  the  join,  accessing  <b>tweet.user.username</b>  would  trigger  a  query  to resolve the foreign key
       <b>tweet.user</b> and retrieve the associated user. But since we have selected and joined on <b>User</b>,  peewee  will
       automatically resolve the foreign-key for us.

       <b>NOTE:</b>
          This technique is discussed in more detail in <u>Selecting</u> <u>from</u> <u>multiple</u> <u>sources</u>.

   <b>List</b> <b>users</b> <b>and</b> <b>all</b> <b>their</b> <b>tweets</b>
       Let's  say  you  want  to build a page that shows several users and all of their tweets. The N+1 scenario
       would be:

       1. Fetch some users.

       2. For each user, fetch their tweets.

       This situation is similar to the previous example,  but  there  is  one  important  difference:  when  we
       selected  tweets,  they  only have a single associated user, so we could directly assign the foreign key.
       The reverse is not true, however, as one user may have any number of tweets (or none at all).

       Peewee provides an approach to avoiding <u>O(n)</u> queries in this situation. Fetch users first, then fetch all
       the tweets associated with those users.  Once peewee has the big list of tweets, it will assign them out,
       matching them with the appropriate user. This method is usually faster but will involve a query for  each
       table being selected.

   <b>Using</b> <b>prefetch</b>
       peewee  supports  pre-fetching  related data using sub-queries. This method requires the use of a special
       API, <u>prefetch()</u>. Prefetch, as its name implies, will eagerly load the appropriate tweets  for  the  given
       users  using  subqueries.  This  means  instead of <u>O(n)</u> queries for <u>n</u> rows, we will do <u>O(k)</u> queries for <u>k</u>
       tables.

       Here is an example of how we might fetch several users and any tweets they created within the past week.

          week_ago = datetime.date.today() - datetime.timedelta(days=7)
          users = User.select()
          tweets = (Tweet
                    .select()
                    .where(Tweet.timestamp &gt;= week_ago))

          # This will perform two queries.
          users_with_tweets = prefetch(users, tweets)

          for user in users_with_tweets:
              print(user.username)
              for tweet in user.tweets:
                  print('  ', tweet.message)

       <b>NOTE:</b>
          Note that neither the <b>User</b> query, nor the <b>Tweet</b> query contained a JOIN clause. When  using  <u>prefetch()</u>
          you do not need to specify the join.

       <u>prefetch()</u>  can  be  used  to  query  an arbitrary number of tables. Check the API documentation for more
       examples.

       Some things to consider when using <u>prefetch()</u>:

       • Foreign keys must exist between the models being prefetched.

       • <u>LIMIT</u> works as you'd expect on the outer-most query, but may be difficult  to  implement  correctly  if
         trying  to  limit the size of the sub-selects.  * The parameter <u>prefetch_type</u> may be used when <u>LIMIT</u> is
         not supported
            with the default query construction (e.g. with MySQL).

   <b>API</b> <b>Documentation</b>
       This document specifies Peewee's APIs.

   <b>Database</b>
       <b>class</b> <b>Database(database[,</b> <b>thread_safe=True[,</b> <b>field_types=None[,</b> <b>operations=None[,</b> <b>autoconnect=True[,</b>
       <b>**kwargs]]]]])</b>

              <b>Parameters</b>

                     • <b>database</b> (<u>str</u>) -- Database name or filename for SQLite (or <b>None</b> to <u>defer</u>  <u>initialization</u>,
                       in which case you must call <u>Database.init()</u>, specifying the database name).

                     • <b>thread_safe</b> (<u>bool</u>) -- Whether to store connection state in a thread-local.

                     • <b>field_types</b> (<u>dict</u>) -- A mapping of additional field types to support.

                     • <b>operations</b> (<u>dict</u>) -- A mapping of additional operations to support.

                     • <b>autoconnect</b>  (<u>bool</u>) -- Automatically connect to database if attempting to execute a query
                       on a closed database.

                     • <b>kwargs</b> -- Arbitrary keyword arguments that will be passed to the database driver  when  a
                       connection is created, for example <b>password</b>, <b>host</b>, etc.

              The <u>Database</u> is responsible for:

              • Executing queries

              • Managing connections

              • Transactions

              • Introspection

              <b>NOTE:</b>
                 The  database  can  be instantiated with <b>None</b> as the database name if the database is not known
                 until run-time. In this way you can create a database instance and then configure it  elsewhere
                 when the settings are known. This is called <u>deferred*</u> <u>initialization</u>.

              Examples:

                 # Sqlite database using WAL-mode and 32MB page-cache.
                 db = SqliteDatabase('app.db', pragmas={
                     'journal_mode': 'wal',
                     'cache_size': -32 * 1000})

                 # Postgresql database on remote host.
                 db = PostgresqlDatabase('my_app', user='postgres', host='10.1.0.3',
                                         password='secret')

              Deferred initialization example:

                 db = PostgresqlDatabase(None)

                 class BaseModel(Model):
                     class Meta:
                         database = db

                 # Read database connection info from env, for example:
                 db_name = os.environ['DATABASE']
                 db_host = os.environ['PGHOST']

                 # Initialize database.
                 db.init(db_name, host=db_host, user='postgres')

              <b>param</b> <b>=</b> <b>'?'</b>
                     String used as parameter placeholder in SQL queries.

              <b>quote</b> <b>=</b> <b>'"'</b>
                     Type of quotation-mark to use to denote entities such as tables or columns.

              <b>init(database[,</b> <b>**kwargs])</b>

                     <b>Parameters</b>

                            • <b>database</b> (<u>str</u>) -- Database name or filename for SQLite.

                            • <b>kwargs</b>  --  Arbitrary keyword arguments that will be passed to the database driver
                              when a connection is created, for example <b>password</b>, <b>host</b>, etc.

                     Initialize a <u>deferred</u> database. See <u>Run-time</u> <u>database</u> <u>configuration</u> for more info.

              <b>__enter__()</b>
                     The <u>Database</u> instance can be used as a context-manager, in which case a connection will  be
                     held open for the duration of the wrapped block.

                     Additionally, any SQL executed within the wrapped block will be executed in a transaction.

              <b>connection_context()</b>
                     Create  a  context-manager that will hold open a connection for the duration of the wrapped
                     block.

                     Example:

                        def on_app_startup():
                            # When app starts up, create the database tables, being sure
                            # the connection is closed upon completion.
                            with database.connection_context():
                                database.create_tables(APP_MODELS)

              <b>connect([reuse_if_open=False])</b>

                     <b>Parameters</b>
                            <b>reuse_if_open</b> (<u>bool</u>) -- Do not raise an exception if a connection is already opened.

                     <b>Returns</b>
                            whether a new connection was opened.

                     <b>Return</b> <b>type</b>
                            bool

                     <b>Raises</b> <b>OperationalError</b> if connection already open and <b>reuse_if_open</b> is not set to <b>True</b>.

                     Open a connection to the database.

              <b>close()</b>

                     <b>Returns</b>
                            Whether a connection was closed. If the database was already  closed,  this  returns
                            <b>False</b>.

                     <b>Return</b> <b>type</b>
                            bool

                     Close the connection to the database.

              <b>is_closed()</b>

                     <b>Returns</b>
                            return <b>True</b> if database is closed, <b>False</b> if open.

                     <b>Return</b> <b>type</b>
                            bool

              <b>connection()</b>
                     Return the open connection. If a connection is not open, one will be opened. The connection
                     will be whatever the underlying database-driver uses to encapsulate a database connection.

              <b>cursor([named_cursor=None])</b>

                     <b>Parameters</b>
                            <b>named_cursor</b> -- For internal use.

                     Return  a <b>cursor</b> object on the current connection. If a connection is not open, one will be
                     opened. The cursor will be whatever the underlying database-driver uses  to  encapsulate  a
                     database cursor.

              <b>execute_sql(sql[,</b> <b>params=None])</b>

                     <b>Parameters</b>

                            • <b>sql</b> (<u>str</u>) -- SQL string to execute.

                            • <b>params</b> (<u>tuple</u>) -- Parameters for query.

                     <b>Returns</b>
                            cursor object.

                     Execute a SQL query and return a cursor over the results.

              <b>execute(query[,</b> <b>**context_options])</b>

                     <b>Parameters</b>

                            • <b>query</b> -- A <u>Query</u> instance.

                            • <b>context_options</b> -- Arbitrary options to pass to the SQL generator.

                     <b>Returns</b>
                            cursor object.

                     Execute a SQL query by compiling a <b>Query</b> instance and executing the resulting SQL.

              <b>last_insert_id(cursor[,</b> <b>query_type=None])</b>

                     <b>Parameters</b>
                            <b>cursor</b> -- cursor object.

                     <b>Returns</b>
                            primary key of last-inserted row.

              <b>rows_affected(cursor)</b>

                     <b>Parameters</b>
                            <b>cursor</b> -- cursor object.

                     <b>Returns</b>
                            number of rows modified by query.

              <b>in_transaction()</b>

                     <b>Returns</b>
                            whether or not a transaction is currently open.

                     <b>Return</b> <b>type</b>
                            bool

              <b>atomic([...])</b>
                     Create  a  context-manager which runs any queries in the wrapped block in a transaction (or
                     save-point if blocks are nested).

                     Calls to <u>atomic()</u> can be nested.

                     <u>atomic()</u> can also be used as a decorator.

                     Database-specific parameters:

                     <u>PostgresqlDatabase</u> and <u>MySQLDatabase</u> accept an  <b>isolation_level</b>  parameter.  <u>SqliteDatabase</u>
                     accepts a <b>lock_type</b> parameter.

                     <b>Parameters</b>

                            • <b>isolation_level</b>   (<u>str</u>)  --  Isolation  strategy:  SERIALIZABLE,  READ  COMMITTED,
                              REPEATABLE READ, READ UNCOMMITTED

                            • <b>lock_type</b> (<u>str</u>) -- Locking strategy: DEFERRED, IMMEDIATE, EXCLUSIVE.

                     Example code:

                        with db.atomic() as txn:
                            perform_operation()

                            with db.atomic() as nested_txn:
                                perform_another_operation()

                     Transactions and save-points can be explicitly committed or rolled-back within the  wrapped
                     block. If this occurs, a new transaction or savepoint is begun after the commit/rollback.

                     Example:

                        with db.atomic() as txn:
                            User.create(username='mickey')
                            txn.commit()  # Changes are saved and a new transaction begins.

                            User.create(username='huey')
                            txn.rollback()  # "huey" will not be saved.

                            User.create(username='zaizee')

                        # Print the usernames of all users.
                        print([u.username for u in User.select()])

                        # Prints ["mickey", "zaizee"]

              <b>manual_commit()</b>
                     Create  a context-manager which disables all transaction management for the duration of the
                     wrapped block.

                     Example:

                        with db.manual_commit():
                            db.begin()  # Begin transaction explicitly.
                            try:
                                user.delete_instance(recursive=True)
                            except:
                                db.rollback()  # Rollback -- an error occurred.
                                raise
                            else:
                                try:
                                    db.commit()  # Attempt to commit changes.
                                except:
                                    db.rollback()  # Error committing, rollback.
                                    raise

                     The above code is equivalent to the following:

                        with db.atomic():
                            user.delete_instance(recursive=True)

              <b>session_start()</b>
                     Begin a new transaction (without using a context-manager or  decorator).   This  method  is
                     useful  if you intend to execute a sequence of operations inside a transaction, but using a
                     decorator or context-manager would not be appropriate.

                     <b>NOTE:</b>
                        It is strongly advised that you use the <u>Database.atomic()</u> method whenever  possible  for
                        managing  transactions/savepoints. The <b>atomic</b> method correctly manages nesting, uses the
                        appropriate construction (e.g., transaction-vs-savepoint), and always  cleans  up  after
                        itself.

                        The  <u>session_start()</u>  method  should only be used if the sequence of operations does not
                        easily lend itself to wrapping using either a context-manager or decorator.

                     <b>WARNING:</b>
                        You must <u>always</u> call either <u>session_commit()</u> or  <u>session_rollback()</u>  after  calling  the
                        <b>session_start</b> method.

              <b>session_commit()</b>
                     Commit any changes made during a transaction begun with <u>session_start()</u>.

              <b>session_rollback()</b>
                     Roll back any changes made during a transaction begun with <u>session_start()</u>.

              <b>transaction([...])</b>
                     Create a context-manager that runs all queries in the wrapped block in a transaction.

                     Database-specific parameters:

                     <u>PostgresqlDatabase</u>  and  <u>MySQLDatabase</u>  accept an <b>isolation_level</b> parameter. <u>SqliteDatabase</u>
                     accepts a <b>lock_type</b> parameter.

                     <b>Parameters</b>

                            • <b>isolation_level</b>  (<u>str</u>)  --  Isolation  strategy:  SERIALIZABLE,  READ   COMMITTED,
                              REPEATABLE READ, READ UNCOMMITTED

                            • <b>lock_type</b> (<u>str</u>) -- Locking strategy: DEFERRED, IMMEDIATE, EXCLUSIVE.

                     <b>WARNING:</b>
                        Calls  to  <b>transaction</b>  cannot  be  nested.  Only  the  top-most  call will take effect.
                        Rolling-back or committing a nested transaction context-manager has undefined behavior.

              <b>savepoint()</b>
                     Create a context-manager that runs all  queries  in  the  wrapped  block  in  a  savepoint.
                     Savepoints can be nested arbitrarily.

                     <b>WARNING:</b>
                        Calls to <b>savepoint</b> must occur inside of a transaction.

              <b>begin()</b>
                     Begin a transaction when using manual-commit mode.

                     <b>NOTE:</b>
                        This method should only be used in conjunction with the <u>manual_commit()</u> context manager.

              <b>commit()</b>
                     Manually commit the currently-active transaction.

                     <b>NOTE:</b>
                        This method should only be used in conjunction with the <u>manual_commit()</u> context manager.

              <b>rollback()</b>
                     Manually roll-back the currently-active transaction.

                     <b>NOTE:</b>
                        This method should only be used in conjunction with the <u>manual_commit()</u> context manager.

              <b>batch_commit(it,</b> <b>n)</b>

                     <b>Parameters</b>

                            • <b>it</b> (<u>iterable</u>) -- an iterable whose items will be yielded.

                            • <b>n</b> (<u>int</u>) -- commit every <u>n</u> items.

                     <b>Returns</b>
                            an equivalent iterable to the one provided, with the addition that groups of <u>n</u> items
                            will be yielded in a transaction.

                     The  purpose  of  this  method  is  to simplify batching large operations, such as inserts,
                     updates, etc. You pass in an iterable and the number of items-per-batch, and the items will
                     be returned by an equivalent iterator that wraps each batch in a transaction.

                     Example:

                        # Some list or iterable containing data to insert.
                        row_data = [{'username': 'u1'}, {'username': 'u2'}, ...]

                        # Insert all data, committing every 100 rows. If, for example,
                        # there are 789 items in the list, then there will be a total of
                        # 8 transactions (7x100 and 1x89).
                        for row in db.batch_commit(row_data, 100):
                            User.create(**row)

                     An alternative that may be more efficient is to batch the data into  a  multi-value  <b>INSERT</b>
                     statement (for example, using <u>Model.insert_many()</u>):

                        with db.atomic():
                            for idx in range(0, len(row_data), 100):
                                # Insert 100 rows at a time.
                                rows = row_data[idx:idx + 100]
                                User.insert_many(rows).execute()

              <b>table_exists(table[,</b> <b>schema=None])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table name.

                            • <b>schema</b> (<u>str</u>) -- Schema name (optional).

                     <b>Returns</b>
                            <b>bool</b> indicating whether table exists.

              <b>get_tables([schema=None])</b>

                     <b>Parameters</b>
                            <b>schema</b> (<u>str</u>) -- Schema name (optional).

                     <b>Returns</b>
                            a list of table names in the database.

              <b>get_indexes(table[,</b> <b>schema=None])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table name.

                            • <b>schema</b> (<u>str</u>) -- Schema name (optional).

                     Return a list of <b>IndexMetadata</b> tuples.

                     Example:

                        print(db.get_indexes('entry'))
                        [IndexMetadata(
                             name='entry_public_list',
                             sql='CREATE INDEX "entry_public_list" ...',
                             columns=['timestamp'],
                             unique=False,
                             table='entry'),
                         IndexMetadata(
                             name='entry_slug',
                             sql='CREATE UNIQUE INDEX "entry_slug" ON "entry" ("slug")',
                             columns=['slug'],
                             unique=True,
                             table='entry')]

              <b>get_columns(table[,</b> <b>schema=None])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table name.

                            • <b>schema</b> (<u>str</u>) -- Schema name (optional).

                     Return a list of <b>ColumnMetadata</b> tuples.

                     Example:

                        print(db.get_columns('entry'))
                        [ColumnMetadata(
                             name='id',
                             data_type='INTEGER',
                             null=False,
                             primary_key=True,
                             table='entry'),
                         ColumnMetadata(
                             name='title',
                             data_type='TEXT',
                             null=False,
                             primary_key=False,
                             table='entry'),
                         ...]

              <b>get_primary_keys(table[,</b> <b>schema=None])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table name.

                            • <b>schema</b> (<u>str</u>) -- Schema name (optional).

                     Return a list of column names that comprise the primary key.

                     Example:

                        print(db.get_primary_keys('entry'))
                        ['id']

              <b>get_foreign_keys(table[,</b> <b>schema=None])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table name.

                            • <b>schema</b> (<u>str</u>) -- Schema name (optional).

                     Return a list of <b>ForeignKeyMetadata</b> tuples for keys present on the table.

                     Example:

                        print(db.get_foreign_keys('entrytag'))
                        [ForeignKeyMetadata(
                             column='entry_id',
                             dest_table='entry',
                             dest_column='id',
                             table='entrytag'),
                         ...]

              <b>get_views([schema=None])</b>

                     <b>Parameters</b>
                            <b>schema</b> (<u>str</u>) -- Schema name (optional).

                     Return a list of <b>ViewMetadata</b> tuples for VIEWs present in the database.

                     Example:

                        print(db.get_views())
                        [ViewMetadata(
                             name='entries_public',
                             sql='CREATE VIEW entries_public AS SELECT ... '),
                         ...]

              <b>sequence_exists(seq)</b>

                     <b>Parameters</b>
                            <b>seq</b> (<u>str</u>) -- Name of sequence.

                     <b>Returns</b>
                            Whether sequence exists.

                     <b>Return</b> <b>type</b>
                            bool

              <b>create_tables(models[,</b> <b>**options])</b>

                     <b>Parameters</b>

                            • <b>models</b> (<u>list</u>) -- A list of <u>Model</u> classes.

                            • <b>options</b> -- Options to specify when calling <u>Model.create_table()</u>.

                     Create tables, indexes and associated metadata for the given list of models.

                     Dependencies are resolved so that tables are created in the appropriate order.

              <b>drop_tables(models[,</b> <b>**options])</b>

                     <b>Parameters</b>

                            • <b>models</b> (<u>list</u>) -- A list of <u>Model</u> classes.

                            • <b>kwargs</b> -- Options to specify when calling <u>Model.drop_table()</u>.

                     Drop tables, indexes and associated metadata for the given list of models.

                     Dependencies are resolved so that tables are dropped in the appropriate order.

              <b>bind(models[,</b> <b>bind_refs=True[,</b> <b>bind_backrefs=True]])</b>

                     <b>Parameters</b>

                            • <b>models</b> (<u>list</u>) -- One or more <u>Model</u> classes to bind.

                            • <b>bind_refs</b> (<u>bool</u>) -- Bind related models.

                            • <b>bind_backrefs</b> (<u>bool</u>) -- Bind back-reference related models.

                     Bind the given list of models, and specified relations, to the database.

              <b>bind_ctx(models[,</b> <b>bind_refs=True[,</b> <b>bind_backrefs=True]])</b>

                     <b>Parameters</b>

                            • <b>models</b> (<u>list</u>) -- List of models to bind to the database.

                            • <b>bind_refs</b> (<u>bool</u>) -- Bind models that are referenced using foreign-keys.

                            • <b>bind_backrefs</b>  (<u>bool</u>)  --  Bind  models  that  reference  the  given  model with a
                              foreign-key.

                     Create a context-manager that binds (associates) the given models with the current database
                     for the duration of the wrapped block.

                     Example:

                        MODELS = (User, Account, Note)

                        # Bind the given models to the db for the duration of wrapped block.
                        def use_test_database(fn):
                            @wraps(fn)
                            def inner(self):
                                with test_db.bind_ctx(MODELS):
                                    test_db.create_tables(MODELS)
                                    try:
                                        fn(self)
                                    finally:
                                        test_db.drop_tables(MODELS)
                            return inner

                        class TestSomething(TestCase):
                            @use_test_database
                            def test_something(self):
                                # ... models are bound to test database ...
                                pass

              <b>extract_date(date_part,</b> <b>date_field)</b>

                     <b>Parameters</b>

                            • <b>date_part</b> (<u>str</u>) -- date part to extract, e.g. 'year'.

                            • <b>date_field</b>  (<u>Node</u>)  --  a  SQL  node  containing  a  date/time,  for   example   a
                              <u>DateTimeField</u>.

                     <b>Returns</b>
                            a SQL node representing a function call that will return the provided date part.

                     Provides a compatible interface for extracting a portion of a datetime.

              <b>truncate_date(date_part,</b> <b>date_field)</b>

                     <b>Parameters</b>

                            • <b>date_part</b> (<u>str</u>) -- date part to truncate to, e.g. 'day'.

                            • <b>date_field</b>   (<u>Node</u>)   --  a  SQL  node  containing  a  date/time,  for  example  a
                              <u>DateTimeField</u>.

                     <b>Returns</b>
                            a SQL node representing a function call that will return the truncated date part.

                     Provides a compatible interface for truncating a datetime to the given resolution.

              <b>random()</b>

                     <b>Returns</b>
                            a SQL node representing a function call that returns a random value.

                     A compatible interface for  calling  the  appropriate  random  number  generation  function
                     provided  by  the database. For Postgres and Sqlite, this is equivalent to <b>fn.random()</b>, for
                     MySQL <b>fn.rand()</b>.

       <b>class</b> <b>SqliteDatabase(database[,</b> <b>pragmas=None[,</b> <b>timeout=5[,</b> <b>returning_clause=None[,</b> <b>**kwargs]]]])</b>

              <b>Parameters</b>

                     • <b>pragmas</b> -- Either a dictionary or a list of 2-tuples containing pragma key and  value  to
                       set every time a connection is opened.

                     • <b>timeout</b> -- Set the busy-timeout on the SQLite driver (in seconds).

                     • <b>returning_clause</b>  (<u>bool</u>)  --  Use  <u>RETURNING</u> clause automatically for bulk INSERT queries
                       (requires Sqlite 3.35 or newer).

              Sqlite database implementation. <u>SqliteDatabase</u> that provides some advanced features  only  offered
              by Sqlite.

              • Register custom aggregates, collations and functions

              • Load C extensions

              • Advanced transactions (specify lock type)

              • For even more features, see <u>SqliteExtDatabase</u>.

              Example of initializing a database and configuring some PRAGMAs:

                 db = SqliteDatabase('my_app.db', pragmas=(
                     ('cache_size', -16000),  # 16MB
                     ('journal_mode', 'wal'),  # Use write-ahead-log journal mode.
                 ))

                 # Alternatively, pragmas can be specified using a dictionary.
                 db = SqliteDatabase('my_app.db', pragmas={'journal_mode': 'wal'})

              <b>pragma(key[,</b> <b>value=SENTINEL[,</b> <b>permanent=False]])</b>

                     <b>Parameters</b>

                            • <b>key</b> -- Setting name.

                            • <b>value</b> -- New value for the setting (optional).

                            • <b>permanent</b> -- Apply this pragma whenever a connection is opened.

                     Execute a PRAGMA query once on the active connection. If a value is not specified, then the
                     current value will be returned.

                     If  <b>permanent</b>  is  specified,  then  the  PRAGMA query will also be executed whenever a new
                     connection is opened, ensuring it is always in-effect.

                     <b>NOTE:</b>
                        By default this only affects the current connection. If the PRAGMA being executed is not
                        persistent, then you must  specify  <b>permanent=True</b>  to  ensure  the  pragma  is  set  on
                        subsequent connections.

              <b>cache_size</b>
                     Get or set the cache_size pragma for the current connection.

              <b>foreign_keys</b>
                     Get or set the foreign_keys pragma for the current connection.

              <b>journal_mode</b>
                     Get or set the journal_mode pragma.

              <b>journal_size_limit</b>
                     Get or set the journal_size_limit pragma.

              <b>mmap_size</b>
                     Get or set the mmap_size pragma for the current connection.

              <b>page_size</b>
                     Get or set the page_size pragma.

              <b>read_uncommitted</b>
                     Get or set the read_uncommitted pragma for the current connection.

              <b>synchronous</b>
                     Get or set the synchronous pragma for the current connection.

              <b>wal_autocheckpoint</b>
                     Get or set the wal_autocheckpoint pragma for the current connection.

              <b>timeout</b>
                     Get or set the busy timeout (seconds).

              <b>register_aggregate(klass[,</b> <b>name=None[,</b> <b>num_params=-1]])</b>

                     <b>Parameters</b>

                            • <b>klass</b> -- Class implementing aggregate API.

                            • <b>name</b> (<u>str</u>) -- Aggregate function name (defaults to name of class).

                            • <b>num_params</b>  (<u>int</u>)  --  Number  of  parameters the aggregate accepts, or -1 for any
                              number.

                     Register a user-defined aggregate function.

                     The function will be registered each time a new connection is opened.  Additionally,  if  a
                     connection is already open, the aggregate will be registered with the open connection.

              <b>aggregate([name=None[,</b> <b>num_params=-1]])</b>

                     <b>Parameters</b>

                            • <b>name</b> (<u>str</u>) -- Name of the aggregate (defaults to class name).

                            • <b>num_params</b>  (<u>int</u>)  --  Number  of  parameters the aggregate accepts, or -1 for any
                              number.

                     Class decorator to register a user-defined aggregate function.

                     Example:

                        @db.aggregate('md5')
                        class MD5(object):
                            def initialize(self):
                                self.md5 = hashlib.md5()

                            def step(self, value):
                                self.md5.update(value)

                            def finalize(self):
                                return self.md5.hexdigest()

                        @db.aggregate()
                        class Product(object):
                            '''Like SUM() except calculates cumulative product.'''
                            def __init__(self):
                                self.product = 1

                            def step(self, value):
                                self.product *= value

                            def finalize(self):
                                return self.product

              <b>register_collation(fn[,</b> <b>name=None])</b>

                     <b>Parameters</b>

                            • <b>fn</b> -- The collation function.

                            • <b>name</b> (<u>str</u>) -- Name of collation (defaults to function name)

                     Register a user-defined collation. The  collation  will  be  registered  each  time  a  new
                     connection is opened.  Additionally, if a connection is already open, the collation will be
                     registered with the open connection.

              <b>collation([name=None])</b>

                     <b>Parameters</b>
                            <b>name</b> (<u>str</u>) -- Name of collation (defaults to function name)

                     Decorator to register a user-defined collation.

                     Example:

                        @db.collation('reverse')
                        def collate_reverse(s1, s2):
                            return -cmp(s1, s2)

                        # Usage:
                        Book.select().order_by(collate_reverse.collation(Book.title))

                        # Equivalent:
                        Book.select().order_by(Book.title.asc(collation='reverse'))

                     As  you  might  have noticed, the original <b>collate_reverse</b> function has a special attribute
                     called <b>collation</b> attached to it.  This extra attribute provides a shorthand way to generate
                     the SQL necessary to use our custom collation.

              <b>register_function(fn[,</b> <b>name=None[,</b> <b>num_params=-1[,</b> <b>deterministic=None]]])</b>

                     <b>Parameters</b>

                            • <b>fn</b> -- The user-defined scalar function.

                            • <b>name</b> (<u>str</u>) -- Name of function (defaults to function name)

                            • <b>num_params</b> (<u>int</u>) -- Number of arguments  the  function  accepts,  or  -1  for  any
                              number.

                            • <b>deterministic</b>  (<u>bool</u>)  --  Whether the function is deterministic for a given input
                              (this is required to use the function in  an  index).   Requires  Sqlite  3.20  or
                              newer, and <b>sqlite3</b> driver support (added to stdlib in Python 3.8).

                     Register  a  user-defined  scalar function. The function will be registered each time a new
                     connection is opened.  Additionally, if a connection is already open, the function will  be
                     registered with the open connection.

              <b>func([name=None[,</b> <b>num_params=-1[,</b> <b>deterministic=None]]])</b>

                     <b>Parameters</b>

                            • <b>name</b> (<u>str</u>) -- Name of the function (defaults to function name).

                            • <b>num_params</b>  (<u>int</u>)  --  Number  of  parameters  the function accepts, or -1 for any
                              number.

                            • <b>deterministic</b> (<u>bool</u>) -- Whether the function is deterministic for  a  given  input
                              (this  is  required  to  use  the  function in an index).  Requires Sqlite 3.20 or
                              newer, and <b>sqlite3</b> driver support (added to stdlib in Python 3.8).

                     Decorator to register a user-defined scalar function.

                     Example:

                        @db.func('title_case')
                        def title_case(s):
                            return s.title() if s else ''

                        # Usage:
                        title_case_books = Book.select(fn.title_case(Book.title))

              <b>register_window_function(klass[,</b> <b>name=None[,</b> <b>num_params=-1]])</b>

                     <b>Parameters</b>

                            • <b>klass</b> -- Class implementing window function API.

                            • <b>name</b> (<u>str</u>) -- Window function name (defaults to name of class).

                            • <b>num_params</b> (<u>int</u>) -- Number of parameters the  function  accepts,  or  -1  for  any
                              number.

                     Register a user-defined window function.

                     <b>ATTENTION:</b>
                        This feature requires SQLite &gt;= 3.25.0 <b>and</b> <u>pysqlite3</u> &gt;= 0.2.0.

                     The  window function will be registered each time a new connection is opened. Additionally,
                     if a connection is already open, the window function  will  be  registered  with  the  open
                     connection.

              <b>window_function([name=None[,</b> <b>num_params=-1]])</b>

                     <b>Parameters</b>

                            • <b>name</b> (<u>str</u>) -- Name of the window function (defaults to class name).

                            • <b>num_params</b>  (<u>int</u>)  --  Number  of  parameters  the function accepts, or -1 for any
                              number.

                     Class decorator to register a user-defined window function. Window  functions  must  define
                     the following methods:

                     • <b>step(&lt;params&gt;)</b> - receive values from a row and update state.

                     • <b>inverse(&lt;params&gt;)</b> - inverse of <b>step()</b> for the given values.

                     • <b>value()</b> - return the current value of the window function.

                     • <b>finalize()</b> - return the final value of the window function.

                     Example:

                        @db.window_function('my_sum')
                        class MySum(object):
                            def __init__(self):
                                self._value = 0

                            def step(self, value):
                                self._value += value

                            def inverse(self, value):
                                self._value -= value

                            def value(self):
                                return self._value

                            def finalize(self):
                                return self._value

              <b>table_function([name=None])</b>
                     Class-decorator for registering a <u>TableFunction</u>. Table functions are user-defined functions
                     that,  rather  than  returning  a  single,  scalar  value, can return any number of rows of
                     tabular data.

                     Example:

                        from playhouse.sqlite_ext import TableFunction

                        @db.table_function('series')
                        class Series(TableFunction):
                            columns = ['value']
                            params = ['start', 'stop', 'step']

                            def initialize(self, start=0, stop=None, step=1):
                                """
                                Table-functions declare an initialize() method, which is
                                called with whatever arguments the user has called the
                                function with.
                                """
                                self.start = self.current = start
                                self.stop = stop or float('Inf')
                                self.step = step

                            def iterate(self, idx):
                                """
                                Iterate is called repeatedly by the SQLite database engine
                                until the required number of rows has been read **or** the
                                function raises a `StopIteration` signalling no more rows
                                are available.
                                """
                                if self.current &gt; self.stop:
                                    raise StopIteration

                                ret, self.current = self.current, self.current + self.step
                                return (ret,)

                        # Usage:
                        cursor = db.execute_sql('SELECT * FROM series(?, ?, ?)', (0, 5, 2))
                        for value, in cursor:
                            print(value)

                        # Prints:
                        # 0
                        # 2
                        # 4

              <b>unregister_aggregate(name)</b>

                     <b>Parameters</b>
                            <b>name</b> -- Name of the user-defined aggregate function.

                     Unregister the user-defined aggregate function.

              <b>unregister_collation(name)</b>

                     <b>Parameters</b>
                            <b>name</b> -- Name of the user-defined collation.

                     Unregister the user-defined collation.

              <b>unregister_function(name)</b>

                     <b>Parameters</b>
                            <b>name</b> -- Name of the user-defined scalar function.

                     Unregister the user-defined scalar function.

              <b>unregister_table_function(name)</b>

                     <b>Parameters</b>
                            <b>name</b> -- Name of the user-defined table function.

                     <b>Returns</b>
                            True or False, depending on whether the function was removed.

                     Unregister the user-defined scalar function.

              <b>load_extension(extension_module)</b>
                     Load the given C extension. If a connection is currently open in the calling  thread,  then
                     the extension will be loaded for that connection as well as all subsequent connections.

                     For  example,  if  you've  compiled  the closure table extension and wish to use it in your
                     application, you might write:

                        db = SqliteExtDatabase('my_app.db')
                        db.load_extension('closure')

              <b>attach(filename,</b> <b>name)</b>

                     <b>Parameters</b>

                            • <b>filename</b> (<u>str</u>) -- Database to attach (or <b>:memory:</b> for in-memory)

                            • <b>name</b> (<u>str</u>) -- Schema name for attached database.

                     <b>Returns</b>
                            boolean indicating success

                     Register another database file that will be attached to every database connection.  If  the
                     main  database  is  currently  connected,  the  new  database  will be attached on the open
                     connection.

                     <b>NOTE:</b>
                        Databases that are attached using this method will be attached  every  time  a  database
                        connection is opened.

              <b>detach(name)</b>

                     <b>Parameters</b>
                            <b>name</b> (<u>str</u>) -- Schema name for attached database.

                     <b>Returns</b>
                            boolean indicating success

                     Unregister  another  database file that was attached previously with a call to <u>attach()</u>. If
                     the main database is currently connected, the attached database will be detached  from  the
                     open connection.

              <b>atomic([lock_type=None])</b>

                     <b>Parameters</b>
                            <b>lock_type</b> (<u>str</u>) -- Locking strategy: DEFERRED, IMMEDIATE, EXCLUSIVE.

                     Create  an  atomic  context-manager,  optionally  using  the specified locking strategy (if
                     unspecified, DEFERRED is used).

                     <b>NOTE:</b>
                        Lock type only applies to the outermost <b>atomic()</b> block.

              <b>transaction([lock_type=None])</b>

                     <b>Parameters</b>
                            <b>lock_type</b> (<u>str</u>) -- Locking strategy: DEFERRED, IMMEDIATE, EXCLUSIVE.

                     Create a transaction context-manager using the  specified  locking  strategy  (defaults  to
                     DEFERRED).

       <b>class</b> <b>PostgresqlDatabase(database[,</b> <b>register_unicode=True[,</b> <b>encoding=None[,</b> <b>isolation_level=None]]])</b>
              Postgresql database implementation.

              Additional optional keyword-parameters:

              <b>Parameters</b>

                     • <b>register_unicode</b> (<u>bool</u>) -- Register unicode types.

                     • <b>encoding</b> (<u>str</u>) -- Database encoding.

                     • <b>isolation_level</b>  (<u>int</u>)  --  Isolation  level constant, defined in the <b>psycopg2.extensions</b>
                       module.

              <b>set_time_zone(timezone)</b>

                     <b>Parameters</b>
                            <b>timezone</b> (<u>str</u>) -- timezone name, e.g. "US/Central".

                     <b>Returns</b>
                            no return value.

                     Set the timezone on the current connection. If no connection is  open,  then  one  will  be
                     opened.

              <b>atomic([isolation_level=None])</b>

                     <b>Parameters</b>
                            <b>isolation_level</b>   (<u>str</u>)   --   Isolation  strategy:  SERIALIZABLE,  READ  COMMITTED,
                            REPEATABLE READ, READ UNCOMMITTED

                     Create an atomic context-manager,  optionally  using  the  specified  isolation  level  (if
                     unspecified, the server default will be used).

                     <b>NOTE:</b>
                        Isolation level only applies to the outermost <b>atomic()</b> block.

              <b>transaction([isolation_level=None])</b>

                     <b>Parameters</b>
                            <b>isolation_level</b>   (<u>str</u>)   --   Isolation  strategy:  SERIALIZABLE,  READ  COMMITTED,
                            REPEATABLE READ, READ UNCOMMITTED

                     Create a transaction context-manager, optionally using the specified  isolation  level  (if
                     unspecified, the server default will be used).

       <b>class</b> <b>MySQLDatabase(database[,</b> <b>**kwargs])</b>
              MySQL database implementation.

              <b>atomic([isolation_level=None])</b>

                     <b>Parameters</b>
                            <b>isolation_level</b>   (<u>str</u>)   --   Isolation  strategy:  SERIALIZABLE,  READ  COMMITTED,
                            REPEATABLE READ, READ UNCOMMITTED

                     Create an atomic context-manager,  optionally  using  the  specified  isolation  level  (if
                     unspecified, the server default will be used).

                     <b>NOTE:</b>
                        Isolation level only applies to the outermost <b>atomic()</b> block.

              <b>transaction([isolation_level=None])</b>

                     <b>Parameters</b>
                            <b>isolation_level</b>   (<u>str</u>)   --   Isolation  strategy:  SERIALIZABLE,  READ  COMMITTED,
                            REPEATABLE READ, READ UNCOMMITTED

                     Create a transaction context-manager, optionally using the specified  isolation  level  (if
                     unspecified, the server default will be used).

   <b>Query-builder</b>
       <b>class</b> <b>Node</b>
              Base-class for all components which make up the AST for a SQL query.

              <b>static</b> <b><a href="../manmethod/copy.method.html">copy</a>(method)</b>
                     Decorator   to   use  with  Node  methods  that  mutate  the  node's  state.   This  allows
                     method-chaining, e.g.:

                        query = MyModel.select()
                        new_query = query.where(MyModel.field == 'value')

              <b>unwrap()</b>
                     API for recursively unwrapping "wrapped" nodes. Base case is to return self.

              <b>is_alias()</b>
                     API for determining if a node, at any point, has been explicitly aliased by the user.

       <b>class</b> <b>Source([alias=None])</b>
              A source of row tuples, for example a table, join, or select query. By default provides a  "magic"
              attribute named "c" that is a factory for column/attribute lookups, for example:

                 User = Table('users')
                 query = (User
                          .select(User.c.username)
                          .where(User.c.active == True)
                          .order_by(User.c.username))

              <b>alias(name)</b>
                     Returns a copy of the object with the given alias applied.

              <b>select(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b>  --  <u>Column</u> instances, expressions, functions, sub-queries, or anything else
                            that you would like to select.

                     Create a <u>Select</u> query on the table. If the table explicitly declares columns and no columns
                     are provided, then by default all the table's defined columns will be selected.

              <b>join(dest[,</b> <b>join_type='INNER'[,</b> <b>on=None]])</b>

                     <b>Parameters</b>

                            • <b>dest</b> (<u>Source</u>) -- Join the table with the given destination.

                            • <b>join_type</b> (<u>str</u>) -- Join type.

                            • <b>on</b> -- Expression to use as join predicate.

                     <b>Returns</b>
                            a <u>Join</u> instance.

                     Join type may be one of:

                     • <b>JOIN.INNER</b>

                     • <b>JOIN.LEFT_OUTER</b>

                     • <b>JOIN.RIGHT_OUTER</b>

                     • <b>JOIN.FULL</b>

                     • <b>JOIN.FULL_OUTER</b>

                     • <b>JOIN.CROSS</b>

              <b>left_outer_join(dest[,</b> <b>on=None])</b>

                     <b>Parameters</b>

                            • <b>dest</b> (<u>Source</u>) -- Join the table with the given destination.

                            • <b>on</b> -- Expression to use as join predicate.

                     <b>Returns</b>
                            a <u>Join</u> instance.

                     Convenience method for calling <u>join()</u> using a LEFT OUTER join.

       <b>class</b> <b>BaseTable</b>
              Base class for table-like objects, which support JOINs via operator overloading.

              <b>__and__(dest)</b>
                     Perform an INNER join on <b>dest</b>.

              <b>__add__(dest)</b>
                     Perform a LEFT OUTER join on <b>dest</b>.

              <b>__sub__(dest)</b>
                     Perform a RIGHT OUTER join on <b>dest</b>.

              <b>__or__(dest)</b>
                     Perform a FULL OUTER join on <b>dest</b>.

              <b>__mul__(dest)</b>
                     Perform a CROSS join on <b>dest</b>.

       <b>class</b> <b>Table(name[,</b> <b>columns=None[,</b> <b>primary_key=None[,</b> <b>schema=None[,</b> <b>alias=None]]]])</b>
              Represents a table in the database (or a table-like object such as a view).

              <b>Parameters</b>

                     • <b>name</b> (<u>str</u>) -- Database table name

                     • <b>columns</b> (<u>tuple</u>) -- List of column names (optional).

                     • <b>primary_key</b> (<u>str</u>) -- Name of primary key column.

                     • <b>schema</b> (<u>str</u>) -- Schema name used to access table (if necessary).

                     • <b>alias</b> (<u>str</u>) -- Alias to use for table in SQL queries.

              <b>NOTE:</b>
                 If columns are specified, the magic "c" attribute will be disabled.

              When columns are not explicitly defined, tables have a special attribute "c" which  is  a  factory
              that provides access to table columns dynamically.

              Example:

                 User = Table('users')
                 query = (User
                          .select(User.c.id, User.c.username)
                          .order_by(User.c.username))

              Equivalent example when columns <b>are</b> specified:

                 User = Table('users', ('id', 'username'))
                 query = (User
                          .select(User.id, User.username)
                          .order_by(User.username))

              <b>bind([database=None])</b>

                     <b>Parameters</b>
                            <b>database</b> -- <u>Database</u> object.

                     Bind this table to the given database (or unbind by leaving empty).

                     When a table is <u>bound</u> to a database, queries may be executed against it without the need to
                     specify the database in the query's execute method.

              <b>bind_ctx([database=None])</b>

                     <b>Parameters</b>
                            <b>database</b> -- <u>Database</u> object.

                     Return a context manager that will bind the table to the given database for the duration of
                     the wrapped block.

              <b>select(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b>  --  <u>Column</u> instances, expressions, functions, sub-queries, or anything else
                            that you would like to select.

                     Create a <u>Select</u> query on the table. If the table explicitly declares columns and no columns
                     are provided, then by default all the table's defined columns will be selected.

                     Example:

                        User = Table('users', ('id', 'username'))

                        # Because columns were defined on the Table, we will default to
                        # selecting both of the User table's columns.
                        # Evaluates to SELECT id, username FROM users
                        query = User.select()

                        Note = Table('notes')
                        query = (Note
                                 .select(Note.c.content, Note.c.timestamp, User.username)
                                 .join(User, on=(Note.c.user_id == User.id))
                                 .where(Note.c.is_published == True)
                                 .order_by(Note.c.timestamp.desc()))

                        # Using a function to select users and the number of notes they
                        # have authored.
                        query = (User
                                 .select(
                                    User.username,
                                    fn.COUNT(Note.c.id).alias('n_notes'))
                                 .join(
                                    Note,
                                    JOIN.LEFT_OUTER,
                                    on=(User.id == Note.c.user_id))
                                 .order_by(fn.COUNT(Note.c.id).desc()))

              <b>insert([insert=None[,</b> <b>columns=None[,</b> <b>**kwargs]]])</b>

                     <b>Parameters</b>

                            • <b>insert</b>  --  A  dictionary  mapping  column  to  value,  an  iterable  that  yields
                              dictionaries (i.e. list), or a <u>Select</u> query.

                            • <b>columns</b>  (<u>list</u>) -- The list of columns to insert into when the data being inserted
                              is not a dictionary.

                            • <b>kwargs</b> -- Mapping of column-name to value.

                     Create a <u>Insert</u> query into the table.

              <b>replace([insert=None[,</b> <b>columns=None[,</b> <b>**kwargs]]])</b>

                     <b>Parameters</b>

                            • <b>insert</b>  --  A  dictionary  mapping  column  to  value,  an  iterable  that  yields
                              dictionaries (i.e. list), or a <u>Select</u> query.

                            • <b>columns</b>  (<u>list</u>) -- The list of columns to insert into when the data being inserted
                              is not a dictionary.

                            • <b>kwargs</b> -- Mapping of column-name to value.

                     Create a <u>Insert</u> query into the table whose conflict resolution method is to replace.

              <b>update([update=None[,</b> <b>**kwargs]])</b>

                     <b>Parameters</b>

                            • <b>update</b> -- A dictionary mapping column to value.

                            • <b>kwargs</b> -- Mapping of column-name to value.

                     Create a <u>Update</u> query for the table.

              <b>delete()</b>
                     Create a <u>Delete</u> query for the table.

       <b>class</b> <b>Join(lhs,</b> <b>rhs[,</b> <b>join_type=JOIN.INNER[,</b> <b>on=None[,</b> <b>alias=None]]])</b>
              Represent a JOIN between to table-like objects.

              <b>Parameters</b>

                     • <b>lhs</b> -- Left-hand side of the join.

                     • <b>rhs</b> -- Right-hand side of the join.

                     • <b>join_type</b> -- Type of join. e.g. JOIN.INNER, JOIN.LEFT_OUTER, etc.

                     • <b>on</b> -- Expression describing the join predicate.

                     • <b>alias</b> (<u>str</u>) -- Alias to apply to joined data.

              <b>on(predicate)</b>

                     <b>Parameters</b>
                            <b>predicate</b> (<u>Expression</u>) -- join predicate.

                     Specify the predicate expression used for this join.

       <b>class</b> <b>ValuesList(values[,</b> <b>columns=None[,</b> <b>alias=None]])</b>
              Represent a values list that can be used like a table.

              <b>Parameters</b>

                     • <b>values</b> -- a list-of-lists containing the row data to represent.

                     • <b>columns</b> (<u>list</u>) -- the names to give to the columns in each row.

                     • <b>alias</b> (<u>str</u>) -- alias to use for values-list.

              Example:

                 data = [(1, 'first'), (2, 'second')]
                 vl = ValuesList(data, columns=('idx', 'name'))

                 query = (vl
                          .select(vl.c.idx, vl.c.name)
                          .order_by(vl.c.idx))
                 # Yields:
                 # SELECT t1.idx, t1.name
                 # FROM (VALUES (1, 'first'), (2, 'second')) AS t1(idx, name)
                 # ORDER BY t1.idx

              <b>columns(*names)</b>

                     <b>Parameters</b>
                            <b>names</b> -- names to apply to the columns of data.

                     Example:

                        vl = ValuesList([(1, 'first'), (2, 'second')])
                        vl = vl.columns('idx', 'name').alias('v')

                        query = vl.select(vl.c.idx, vl.c.name)
                        # Yields:
                        # SELECT v.idx, v.name
                        # FROM (VALUES (1, 'first'), (2, 'second')) AS v(idx, name)

       <b>class</b> <b>CTE(name,</b> <b>query[,</b> <b>recursive=False[,</b> <b>columns=None]])</b>
              Represent a common-table-expression. For example queries, see <u>Common</u> <u>Table</u> <u>Expressions</u>.

              <b>Parameters</b>

                     • <b>name</b> -- Name for the CTE.

                     • <b>query</b> -- <u>Select</u> query describing CTE.

                     • <b>recursive</b> (<u>bool</u>) -- Whether the CTE is recursive.

                     • <b>columns</b> (<u>list</u>) -- Explicit list of columns produced by CTE (optional).

              <b>select_from(*columns)</b>
                     Create a SELECT query that utilizes the given common table expression as the source  for  a
                     new query.

                     <b>Parameters</b>
                            <b>columns</b> -- One or more columns to select from the CTE.

                     <b>Returns</b>
                            <u>Select</u> query utilizing the common table expression

              <b>union_all(other)</b>
                     Used on the base-case CTE to construct the recursive term of the CTE.

                     <b>Parameters</b>
                            <b>other</b> -- recursive term, generally a <u>Select</u> query.

                     <b>Returns</b>
                            a recursive <u>CTE</u> with the given recursive term.

       <b>class</b> <b>ColumnBase</b>
              Base-class for column-like objects, attributes or expressions.

              Column-like objects can be composed using various operators and special methods.

              • <b>&amp;</b>: Logical AND

              • <b>|</b>: Logical OR

              • <b>+</b>: Addition

              • <b>-</b>: Subtraction

              • <b>*</b>: Multiplication

              • <b>/</b>: Division

              • <b>^</b>: Exclusive-OR

              • <b>==</b>: Equality

              • <b>!=</b>: Inequality

              • <b>&gt;</b>: Greater-than

              • <b>&lt;</b>: Less-than

              • <b>&gt;=</b>: Greater-than or equal

              • <b>&lt;=</b>: Less-than or equal

              • <b>&lt;&lt;</b>: <b>IN</b>

              • <b>&gt;&gt;</b>: <b>IS</b> (i.e. <b>IS</b> <b>NULL</b>)

              • <b>%</b>: <b>LIKE</b>

              • <b>**</b>: <b>ILIKE</b>

              • <b>bin_and()</b>: Binary AND

              • <b>bin_or()</b>: Binary OR

              • <b>in_()</b>: <b>IN</b>

              • <b>not_in()</b>: <b>NOT</b> <b>IN</b>

              • <b>regexp()</b>: <b>REGEXP</b>

              • <b>is_null(True/False)</b>: <b>IS</b> <b>NULL</b> or <b>IS</b> <b>NOT</b> <b>NULL</b>

              • <b>contains(s)</b>: <b>LIKE</b> <b>%s%</b>

              • <b>startswith(s)</b>: <b>LIKE</b> <b>s%</b>

              • <b>endswith(s)</b>: <b>LIKE</b> <b>%s</b>

              • <b>between(low,</b> <b>high)</b>: <b>BETWEEN</b> <b>low</b> <b>AND</b> <b>high</b>

              • <b>concat()</b>: <b>||</b>

              <b>alias(alias)</b>

                     <b>Parameters</b>
                            <b>alias</b> (<u>str</u>) -- Alias for the given column-like object.

                     <b>Returns</b>
                            a <u>Alias</u> object.

                     Indicate the alias that should be given to the specified column-like object.

              <b>cast(as_type)</b>

                     <b>Parameters</b>
                            <b>as_type</b> (<u>str</u>) -- Type name to cast to.

                     <b>Returns</b>
                            a <u>Cast</u> object.

                     Create a <b>CAST</b> expression.

              <b>asc([collation=None[,</b> <b>nulls=None]])</b>

                     <b>Parameters</b>

                            • <b>collation</b> (<u>str</u>) -- Collation name to use for sorting.

                            • <b>nulls</b> (<u>str</u>) -- Sort nulls (FIRST or LAST).

                     <b>Returns</b>
                            an ascending <u>Ordering</u> object for the column.

              <b>desc([collation=None[,</b> <b>nulls=None]])</b>

                     <b>Parameters</b>

                            • <b>collation</b> (<u>str</u>) -- Collation name to use for sorting.

                            • <b>nulls</b> (<u>str</u>) -- Sort nulls (FIRST or LAST).

                     <b>Returns</b>
                            an descending <u>Ordering</u> object for the column.

              <b>__invert__()</b>

                     <b>Returns</b>
                            a <u>Negated</u> wrapper for the column.

       <b>class</b> <b>Column(source,</b> <b>name)</b>

              <b>Parameters</b>

                     • <b>source</b> (<u>Source</u>) -- Source for column.

                     • <b>name</b> (<u>str</u>) -- Column name.

              Column on a table or a column returned by a sub-query.

       <b>class</b> <b>Alias(node,</b> <b>alias)</b>

              <b>Parameters</b>

                     • <b>node</b> (<u>Node</u>) -- a column-like object.

                     • <b>alias</b> (<u>str</u>) -- alias to assign to column.

              Create a named alias for the given column-like object.

              <b>alias([alias=None])</b>

                     <b>Parameters</b>
                            <b>alias</b> (<u>str</u>) -- new name (or None) for aliased column.

                     Create  a  new <u>Alias</u> for the aliased column-like object. If the new alias is <b>None</b>, then the
                     original column-like object is returned.

       <b>class</b> <b>Negated(node)</b>
              Represents a negated column-like object.

       <b>class</b> <b>Value(value[,</b> <b>converterNone[,</b> <b>unpack=True]])</b>

              <b>Parameters</b>

                     • <b>value</b> -- Python object or scalar value.

                     • <b>converter</b> -- Function used to convert value into type the database understands.

                     • <b>unpack</b> (<u>bool</u>) -- Whether lists or tuples should be unpacked into  a  list  of  values  or
                       treated as-is.

              Value  to  be used in a parameterized query. It is the responsibility of the caller to ensure that
              the value passed in can be adapted to a type the database driver understands.

       <b>AsIs(value)</b>
              Represents a <u>Value</u> that is treated as-is, and passed directly back to the  database  driver.  This
              may be useful if you are using database extensions that accept native Python data-types and you do
              not wish Peewee to impose any handling of the values.

       <b>class</b> <b>Cast(node,</b> <b>cast)</b>

              <b>Parameters</b>

                     • <b>node</b> -- A column-like object.

                     • <b>cast</b> (<u>str</u>) -- Type to cast to.

              Represents a <b>CAST(&lt;node&gt;</b> <b>AS</b> <b>&lt;cast&gt;)</b> expression.

       <b>class</b> <b>Ordering(node,</b> <b>direction[,</b> <b>collation=None[,</b> <b>nulls=None]])</b>

              <b>Parameters</b>

                     • <b>node</b> -- A column-like object.

                     • <b>direction</b> (<u>str</u>) -- ASC or DESC

                     • <b>collation</b> (<u>str</u>) -- Collation name to use for sorting.

                     • <b>nulls</b> (<u>str</u>) -- Sort nulls (FIRST or LAST).

              Represent ordering by a column-like object.

              Postgresql  supports  a non-standard clause ("NULLS FIRST/LAST"). Peewee will automatically use an
              equivalent <b>CASE</b> statement for databases that do not support this (Sqlite / MySQL).

              <b>collate([collation=None])</b>

                     <b>Parameters</b>
                            <b>collation</b> (<u>str</u>) -- Collation name to use for sorting.

       <b>Asc(node[,</b> <b>collation=None[,</b> <b>nulls=None]])</b>
              Short-hand for instantiating an ascending <u>Ordering</u> object.

       <b>Desc(node[,</b> <b>collation=None[,</b> <b>nulls=None]])</b>
              Short-hand for instantiating an descending <u>Ordering</u> object.

       <b>class</b> <b>Expression(lhs,</b> <b>op,</b> <b>rhs[,</b> <b>flat=True])</b>

              <b>Parameters</b>

                     • <b>lhs</b> -- Left-hand side.

                     • <b>op</b> -- Operation.

                     • <b>rhs</b> -- Right-hand side.

                     • <b>flat</b> (<u>bool</u>) -- Whether to wrap expression in parentheses.

              Represent a binary expression of the form (lhs op rhs), e.g. (foo + 1).

       <b>class</b> <b>Entity(*path)</b>

              <b>Parameters</b>
                     <b>path</b> -- Components that make up the dotted-path of the entity name.

              Represent a quoted entity in a query, such as a table, column, alias.  The  name  may  consist  of
              multiple components, e.g. "a_table"."column_name".

              <b>__getattr__(self,</b> <b>attr)</b>
                     Factory method for creating sub-entities.

       <b>class</b> <b>SQL(sql[,</b> <b>params=None])</b>

              <b>Parameters</b>

                     • <b>sql</b> (<u>str</u>) -- SQL query string.

                     • <b>params</b> (<u>tuple</u>) -- Parameters for query (optional).

              Represent a parameterized SQL query or query-fragment.

       <b>Check(constraint[,</b> <b>name=None])</b>

              <b>Parameters</b>

                     • <b>constraint</b> (<u>str</u>) -- Constraint SQL.

                     • <b>name</b> (<u>str</u>) -- constraint name.

              Represent a CHECK constraint.

              <b>WARNING:</b>
                 MySQL  may  not  support  a  <b>name</b>  parameter when inlining the constraint along with the column
                 definition.  The  solution  is  to  just  put  the  named  <b>Check</b>  constraint  in  the   model's
                 <b>Meta.constraints</b> list instead of in the field instances <b>constraints=[...]</b> list.

       <b>class</b> <b>Function(name,</b> <b>arguments[,</b> <b>coerce=True[,</b> <b>python_value=None]])</b>

              <b>Parameters</b>

                     • <b>name</b> (<u>str</u>) -- Function name.

                     • <b>arguments</b> (<u>tuple</u>) -- Arguments to function.

                     • <b>coerce</b>  (<u>bool</u>)  --  Whether  to coerce the function result to a particular data-type when
                       reading function return values from the cursor.

                     • <b>python_value</b> (<u>callable</u>) -- Function to use for  converting  the  return  value  from  the
                       cursor.

              Represent an arbitrary SQL function call.

              <b>NOTE:</b>
                 Rather than instantiating this class directly, it is recommended to use the <b>fn</b> helper.

              Example of using <b>fn</b> to call an arbitrary SQL function:

                 # Query users and count of tweets authored.
                 query = (User
                          .select(User.username, fn.COUNT(Tweet.id).alias('ct'))
                          .join(Tweet, JOIN.LEFT_OUTER, on=(User.id == Tweet.user_id))
                          .group_by(User.username)
                          .order_by(fn.COUNT(Tweet.id).desc()))

              <b>over([partition_by=None[,</b> <b>order_by=None[,</b> <b>start=None[,</b> <b>end=None[,</b> <b>window=None[,</b>
              <b>exclude=None]]]]]])</b>

                     <b>Parameters</b>

                            • <b>partition_by</b> (<u>list</u>) -- List of columns to partition by.

                            • <b>order_by</b> (<u>list</u>) -- List of columns / expressions to order window by.

                            • <b>start</b> -- A <u>SQL</u> instance or a string expressing the start of the window range.

                            • <b>end</b> -- A <u>SQL</u> instance or a string expressing the end of the window range.

                            • <b>frame_type</b> (<u>str</u>) -- <b>Window.RANGE</b>, <b>Window.ROWS</b> or <b>Window.GROUPS</b>.

                            • <b>window</b> (<u>Window</u>) -- A <u>Window</u> instance.

                            • <b>exclude</b>  --  Frame exclusion, one of <b>Window.CURRENT_ROW</b>, <b>Window.GROUP</b>, <b>Window.TIES</b>
                              or <b>Window.NO_OTHERS</b>.

                     <b>NOTE:</b>
                        For an in-depth guide to using window functions with Peewee, see  the  <u>Window</u>  <u>functions</u>
                        section.

                     Examples:

                        # Using a simple partition on a single column.
                        query = (Sample
                                 .select(
                                    Sample.counter,
                                    Sample.value,
                                    fn.AVG(Sample.value).over([Sample.counter]))
                                 .order_by(Sample.counter))

                        # Equivalent example Using a Window() instance instead.
                        window = Window(partition_by=[Sample.counter])
                        query = (Sample
                                 .select(
                                    Sample.counter,
                                    Sample.value,
                                    fn.AVG(Sample.value).over(window))
                                 .window(window)  # Note call to ".window()"
                                 .order_by(Sample.counter))

                        # Example using bounded window.
                        query = (Sample
                                 .select(Sample.value,
                                         fn.SUM(Sample.value).over(
                                            partition_by=[Sample.counter],
                                            start=Window.CURRENT_ROW,  # current row
                                            end=Window.following()))  # unbounded following
                                 .order_by(Sample.id))

              <b>filter(where)</b>

                     <b>Parameters</b>
                            <b>where</b> -- Expression for filtering aggregate.

                     Add  a <b>FILTER</b> <b>(WHERE...)</b> clause to an aggregate function. The where expression is evaluated
                     to determine which rows are fed to the aggregate function. This SQL  feature  is  supported
                     for Postgres and SQLite.

              <b>coerce([coerce=True])</b>

                     <b>Parameters</b>
                            <b>coerce</b>  (<u>bool</u>)  --  Whether  to  attempt  to coerce function-call result to a Python
                            data-type.

                     When coerce is <b>True</b>, the target data-type is inferred using several  heuristics.  Read  the
                     source for <b>BaseModelCursorWrapper._initialize_columns</b> method to see how this works.

              <b>python_value([func=None])</b>

                     <b>Parameters</b>
                            <b>python_value</b>  (<u>callable</u>) -- Function to use for converting the return value from the
                            cursor.

                     Specify a particular function to use  when  converting  values  returned  by  the  database
                     cursor. For example:

                        # Get user and a list of their tweet IDs. The tweet IDs are
                        # returned as a comma-separated string by the db, so we'll split
                        # the result string and convert the values to python ints.
                        convert_ids = lambda s: [int(i) for i in (s or '').split(',') if i]
                        tweet_ids = (fn
                                     .GROUP_CONCAT(Tweet.id)
                                     .python_value(convert_ids))

                        query = (User
                                 .select(User.username, tweet_ids.alias('tweet_ids'))
                                 .group_by(User.username))

                        for user in query:
                            print(user.username, user.tweet_ids)

                        # e.g.,
                        # huey [1, 4, 5, 7]
                        # mickey [2, 3, 6]
                        # zaizee []

       <b>fn()</b>   The  <u>fn()</u> helper is actually an instance of <u>Function</u> that implements a <b>__getattr__</b> hook to provide
              a nice API for calling SQL functions.

              To create a node representative of a SQL function call, use the function name as an  attribute  on
              <b>fn</b> and then provide the arguments as you would if calling a Python function:

                 # List users and the number of tweets they have authored,
                 # from highest-to-lowest:
                 sql_count = fn.COUNT(Tweet.id)
                 query = (User
                          .select(User, sql_count.alias('count'))
                          .join(Tweet, JOIN.LEFT_OUTER)
                          .group_by(User)
                          .order_by(sql_count.desc()))

                 # Get the timestamp of the most recent tweet:
                 query = Tweet.select(fn.MAX(Tweet.timestamp))
                 max_timestamp = query.scalar()  # Retrieve scalar result from query.

              Function calls can, like anything else, be composed and nested:

                 # Get users whose username begins with "A" or "a":
                 a_users = User.select().where(fn.LOWER(fn.SUBSTR(User.username, 1, 1)) == 'a')

       <b>class</b> <b>Window([partition_by=None[,</b> <b>order_by=None[,</b> <b>start=None[,</b> <b>end=None[,</b> <b>frame_type=None[,</b>
       <b>extends=None[,</b> <b>exclude=None[,</b> <b>alias=None]]]]]]]])</b>

              <b>Parameters</b>

                     • <b>partition_by</b> (<u>list</u>) -- List of columns to partition by.

                     • <b>order_by</b> (<u>list</u>) -- List of columns to order by.

                     • <b>start</b> -- A <u>SQL</u> instance or a string expressing the start of the window range.

                     • <b>end</b> -- A <u>SQL</u> instance or a string expressing the end of the window range.

                     • <b>frame_type</b> (<u>str</u>) -- <b>Window.RANGE</b>, <b>Window.ROWS</b> or <b>Window.GROUPS</b>.

                     • <b>extends</b> -- A <u>Window</u> definition to extend. Alternately, you may specify the window's alias
                       instead.

                     • <b>exclude</b>  --  Frame  exclusion,  one  of  <b>Window.CURRENT_ROW</b>, <b>Window.GROUP</b>, <b>Window.TIES</b> or
                       <b>Window.NO_OTHERS</b>.

                     • <b>alias</b> (<u>str</u>) -- Alias for the window.

              Represent a WINDOW clause.

              <b>NOTE:</b>
                 For an in-depth guide to using window functions with Peewee, see the <u>Window</u> <u>functions</u> section.

              <b>RANGE</b>

              <b>ROWS</b>

              <b>GROUPS</b> Specify the window <b>frame_type</b>. See <u>Frame</u> <u>types:</u> <u>RANGE</u> <u>vs</u> <u>ROWS</u> <u>vs</u> <u>GROUPS</u>.

              <b>CURRENT_ROW</b>
                     Reference to current row for use in start/end clause or the frame exclusion parameter.

              <b>NO_OTHERS</b>

              <b>GROUP</b>

              <b>TIES</b>   Specify the window frame exclusion parameter.

              <b>static</b> <b>preceding([value=None])</b>

                     <b>Parameters</b>
                            <b>value</b> -- Number of rows preceding. If <b>None</b> is UNBOUNDED.

                     Convenience method for generating SQL suitable for passing in as the <b>start</b> parameter for  a
                     window range.

              <b>static</b> <b>following([value=None])</b>

                     <b>Parameters</b>
                            <b>value</b> -- Number of rows following. If <b>None</b> is UNBOUNDED.

                     Convenience  method  for  generating SQL suitable for passing in as the <b>end</b> parameter for a
                     window range.

              <b>as_rows()</b>

              <b>as_range()</b>

              <b>as_groups()</b>
                     Specify the frame type.

              <b>extends([window=None])</b>

                     <b>Parameters</b>
                            <b>window</b> (<u>Window</u>) -- A <u>Window</u> definition to extend.  Alternately, you may specify  the
                            window's alias instead.

              <b>exclude([frame_exclusion=None])</b>

                     <b>Parameters</b>
                            <b>frame_exclusion</b>   --  Frame  exclusion,  one  of  <b>Window.CURRENT_ROW</b>,  <b>Window.GROUP</b>,
                            <b>Window.TIES</b> or <b>Window.NO_OTHERS</b>.

              <b>alias([alias=None])</b>

                     <b>Parameters</b>
                            <b>alias</b> (<u>str</u>) -- Alias to use for window.

       <b>Case(predicate,</b> <b>expression_tuples[,</b> <b>default=None]])</b>

              <b>Parameters</b>

                     • <b>predicate</b> -- Predicate for CASE query (optional).

                     • <b>expression_tuples</b> -- One or more cases to evaluate.

                     • <b>default</b> -- Default value (optional).

              <b>Returns</b>
                     Representation of CASE statement.

              Examples:

                 Number = Table('numbers', ('val',))

                 num_as_str = Case(Number.val, (
                     (1, 'one'),
                     (2, 'two'),
                     (3, 'three')), 'a lot')

                 query = Number.select(Number.val, num_as_str.alias('num_str'))

                 # The above is equivalent to:
                 # SELECT "val",
                 #   CASE "val"
                 #       WHEN 1 THEN 'one'
                 #       WHEN 2 THEN 'two'
                 #       WHEN 3 THEN 'three'
                 #       ELSE 'a lot' END AS "num_str"
                 # FROM "numbers"

                 num_as_str = Case(None, (
                     (Number.val == 1, 'one'),
                     (Number.val == 2, 'two'),
                     (Number.val == 3, 'three')), 'a lot')
                 query = Number.select(Number.val, num_as_str.alias('num_str'))

                 # The above is equivalent to:
                 # SELECT "val",
                 #   CASE
                 #       WHEN "val" = 1 THEN 'one'
                 #       WHEN "val" = 2 THEN 'two'
                 #       WHEN "val" = 3 THEN 'three'
                 #       ELSE 'a lot' END AS "num_str"
                 # FROM "numbers"

       <b>class</b> <b>NodeList(nodes[,</b> <b>glue='</b> <b>'[,</b> <b>parens=False]])</b>

              <b>Parameters</b>

                     • <b>nodes</b> (<u>list</u>) -- Zero or more nodes.

                     • <b>glue</b> (<u>str</u>) -- How to join the nodes when converting to SQL.

                     • <b>parens</b> (<u>bool</u>) -- Whether to wrap the resulting SQL in parentheses.

              Represent a list of nodes, a multi-part clause, a list of parameters, etc.

       <b>CommaNodeList(nodes)</b>

              <b>Parameters</b>
                     <b>nodes</b> (<u>list</u>) -- Zero or more nodes.

              <b>Returns</b>
                     a <u>NodeList</u>

              Represent a list of nodes joined by commas.

       <b>EnclosedNodeList(nodes)</b>

              <b>Parameters</b>
                     <b>nodes</b> (<u>list</u>) -- Zero or more nodes.

              <b>Returns</b>
                     a <u>NodeList</u>

              Represent a list of nodes joined by commas and wrapped in parentheses.

       <b>class</b> <b>DQ(**query)</b>

              <b>Parameters</b>
                     <b>query</b> -- Arbitrary filter expressions using Django-style lookups.

              Represent a composable Django-style filter expression suitable for use with the <u>Model.filter()</u>  or
              <u>ModelSelect.filter()</u> methods.

       <b>class</b> <b>Tuple(*args)</b>
              Represent a SQL <u>row</u> <u>value</u>.  Row-values are supported by most databases.

       <b>class</b> <b>OnConflict([action=None[,</b> <b>update=None[,</b> <b>preserve=None[,</b> <b>where=None[,</b> <b>conflict_target=None[,</b>
       <b>conflict_where=None[,</b> <b>conflict_constraint=None]]]]]]])</b>

              <b>Parameters</b>

                     • <b>action</b> (<u>str</u>) -- Action to take when resolving conflict.

                     • <b>update</b> -- A dictionary mapping column to new value.

                     • <b>preserve</b>  -- A list of columns whose values should be preserved from the original INSERT.
                       See also <u>EXCLUDED</u>.

                     • <b>where</b> -- Expression to restrict the conflict resolution.

                     • <b>conflict_target</b> -- Column(s) that comprise the constraint.

                     • <b>conflict_where</b> -- Expressions needed to match the constraint target if it  is  a  partial
                       index (index with a WHERE clause).

                     • <b>conflict_constraint</b> (<u>str</u>) -- Name of constraint to use for conflict resolution. Currently
                       only supported by Postgres.

              Represent a conflict resolution clause for a data-modification query.

              Depending on the database-driver being used, one or more of the above parameters may be required.

              <b>preserve(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b> -- Columns whose values should be preserved.

              <b>update([_data=None[,</b> <b>**kwargs]])</b>

                     <b>Parameters</b>

                            • <b>_data</b> (<u>dict</u>) -- Dictionary mapping column to new value.

                            • <b>kwargs</b> -- Dictionary mapping column name to new value.

                     The  <b>update()</b>  method supports being called with either a dictionary of column-to-value, <b>or</b>
                     keyword arguments representing the same.

              <b>where(*expressions)</b>

                     <b>Parameters</b>
                            <b>expressions</b> -- Expressions that restrict  the  action  of  the  conflict  resolution
                            clause.

              <b>conflict_target(*constraints)</b>

                     <b>Parameters</b>
                            <b>constraints</b> -- Column(s) to use as target for conflict resolution.

              <b>conflict_where(*expressions)</b>

                     <b>Parameters</b>
                            <b>expressions</b>  --  Expressions  that  match the conflict target index, in the case the
                            conflict target is a partial index.

              <b>conflict_constraint(constraint)</b>

                     <b>Parameters</b>
                            <b>constraint</b> (<u>str</u>) -- Name of constraints to use as target  for  conflict  resolution.
                            Currently only supported by Postgres.

       <b>class</b> <b>EXCLUDED</b>
              Helper  object  that  exposes  the  <b>EXCLUDED</b> namespace that is used with <b>INSERT</b> <b>...</b> <b>ON</b> <b>CONFLICT</b> to
              reference values in the conflicting data.  This is a "magic" helper, such  that  one  uses  it  by
              accessing attributes on it that correspond to a particular column.

              Example:

                 class KV(Model):
                     key = CharField(unique=True)
                     value = IntegerField()

                 # Create one row.
                 KV.create(key='k1', value=1)

                 # Demonstrate usage of EXCLUDED.
                 # Here we will attempt to insert a new value for a given key. If that
                 # key already exists, then we will update its value with the *sum* of its
                 # original value and the value we attempted to insert -- provided that
                 # the new value is larger than the original value.
                 query = (KV.insert(key='k1', value=10)
                          .on_conflict(conflict_target=[KV.key],
                                       update={KV.value: KV.value + EXCLUDED.value},
                                       where=(EXCLUDED.value &gt; KV.value)))

                 # Executing the above query will result in the following data being
                 # present in the "kv" table:
                 # (key='k1', value=11)
                 query.execute()

                 # If we attempted to execute the query *again*, then nothing would be
                 # updated, as the new value (10) is now less than the value in the
                 # original row (11).

       <b>class</b> <b>BaseQuery</b>
              The  parent  class  from  which  all other query classes are derived. While you will not deal with
              <u>BaseQuery</u> directly in your code, it implements some methods  that  are  common  across  all  query
              types.

              <b>default_row_type</b> <b>=</b> <b>ROW.DICT</b>

              <b>bind([database=None])</b>

                     <b>Parameters</b>
                            <b>database</b> (<u>Database</u>) -- Database to execute query against.

                     Bind the query to the given database for execution.

              <b>dicts([as_dict=True])</b>

                     <b>Parameters</b>
                            <b>as_dict</b> (<u>bool</u>) -- Specify whether to return rows as dictionaries.

                     Return rows as dictionaries.

              <b>tuples([as_tuples=True])</b>

                     <b>Parameters</b>
                            <b>as_tuple</b> (<u>bool</u>) -- Specify whether to return rows as tuples.

                     Return rows as tuples.

              <b>namedtuples([as_namedtuple=True])</b>

                     <b>Parameters</b>
                            <b>as_namedtuple</b> (<u>bool</u>) -- Specify whether to return rows as named tuples.

                     Return rows as named tuples.

              <b>objects([constructor=None])</b>

                     <b>Parameters</b>
                            <b>constructor</b> -- Function that accepts row dict and returns an arbitrary object.

                     Return rows as arbitrary objects using the given constructor.

              <b>sql()</b>

                     <b>Returns</b>
                            A 2-tuple consisting of the query's SQL and parameters.

              <b>execute(database)</b>

                     <b>Parameters</b>
                            <b>database</b>  (<u>Database</u>) -- Database to execute query against. Not required if query was
                            previously bound to a database.

                     Execute the query and return result (depends on type of query being executed). For example,
                     select queries the return result will be an iterator over the query results.

              <b>iterator([database=None])</b>

                     <b>Parameters</b>
                            <b>database</b> (<u>Database</u>) -- Database to execute query against. Not required if query  was
                            previously bound to a database.

                     Execute  the  query  and return an iterator over the result-set. For large result-sets this
                     method is preferable as rows are not cached in-memory during iteration.

                     <b>NOTE:</b>
                            Because rows are not cached, the query may only be iterated  over  once.  Subsequent
                            iterations will return empty result-sets as the cursor will have been consumed.

                        Example:

                            query = StatTbl.select().order_by(StatTbl.timestamp).tuples()
                            for row in query.iterator(db):
                                process_row(row)

              <b>__iter__()</b>
                     Execute the query and return an iterator over the result-set.

                     Unlike  <u>iterator()</u>,  this  method  will cause rows to be cached in order to allow efficient
                     iteration, indexing and slicing.

              <b>__getitem__(value)</b>

                     <b>Parameters</b>
                            <b>value</b> -- Either an integer index or a slice.

                     Retrieve a row or range of rows from the result-set.

              <b>__len__()</b>
                     Return the number of rows in the result-set.

                     <b>WARNING:</b>
                        This does not issue a <b>COUNT()</b> query. Instead, the result-set is loaded as  it  would  be
                        during normal iteration, and the length is determined from the size of the result set.

       <b>class</b> <b>RawQuery([sql=None[,</b> <b>params=None[,</b> <b>**kwargs]]])</b>

              <b>Parameters</b>

                     • <b>sql</b> (<u>str</u>) -- SQL query.

                     • <b>params</b> (<u>tuple</u>) -- Parameters (optional).

              Create a query by directly specifying the SQL to execute.

       <b>class</b> <b>Query([where=None[,</b> <b>order_by=None[,</b> <b>limit=None[,</b> <b>offset=None[,</b> <b>**kwargs]]]]])</b>

              <b>Parameters</b>

                     • <b>where</b> -- Representation of WHERE clause.

                     • <b>order_by</b> (<u>tuple</u>) -- Columns or values to order by.

                     • <b>limit</b> (<u>int</u>) -- Value of LIMIT clause.

                     • <b>offset</b> (<u>int</u>) -- Value of OFFSET clause.

              Base-class for queries that support method-chaining APIs.

              <b>with_cte(*cte_list)</b>

                     <b>Parameters</b>
                            <b>cte_list</b> -- zero or more <u>CTE</u> objects.

                     Include the given common-table expressions in the query. Any previously specified CTEs will
                     be overwritten. For examples of common-table expressions, see <u>Common</u> <u>Table</u> <u>Expressions</u>.

              <b>cte(name[,</b> <b>recursive=False[,</b> <b>columns=None]])</b>

                     <b>Parameters</b>

                            • <b>name</b> (<u>str</u>) -- Alias for common table expression.

                            • <b>recursive</b> (<u>bool</u>) -- Will this be a recursive CTE?

                            • <b>columns</b> (<u>list</u>) -- List of column names (as strings).

                     Indicate  that  a  query  will be used as a common table expression. For example, if we are
                     modelling a category tree and are using a parent-link foreign  key,  we  can  retrieve  all
                     categories and their absolute depths using a recursive CTE:

                        class Category(Model):
                            name = TextField()
                            parent = ForeignKeyField('self', backref='children', null=True)

                        # The base case of our recursive CTE will be categories that are at
                        # the root level -- in other words, categories without parents.
                        roots = (Category
                                 .select(Category.name, <a href="../man0/Value.0.html">Value</a>(0).alias('level'))
                                 .where(Category.parent.is_null())
                                 .cte(name='roots', recursive=True))

                        # The recursive term will select the category name and increment
                        # the depth, joining on the base term so that the recursive term
                        # consists of all children of the base category.
                        RTerm = Category.alias()
                        recursive = (RTerm
                                     .select(RTerm.name, (roots.c.level + 1).alias('level'))
                                     .join(roots, on=(RTerm.parent == roots.c.id)))

                        # Express &lt;base term&gt; UNION ALL &lt;recursive term&gt;.
                        cte = roots.union_all(recursive)

                        # Select name and level from the recursive CTE.
                        query = (cte
                                 .select_from(cte.c.name, cte.c.level)
                                 .order_by(cte.c.name))

                        for category in query:
                            print(category.name, category.level)

                     For more examples of CTEs, see <u>Common</u> <u>Table</u> <u>Expressions</u>.

              <b>where(*expressions)</b>

                     <b>Parameters</b>
                            <b>expressions</b> -- zero or more expressions to include in the WHERE clause.

                     Include  the  given  expressions  in the WHERE clause of the query. The expressions will be
                     AND-ed together with any previously-specified WHERE expressions.

                     Example selection users where the username is equal to 'somebody':

                        sq = User.select().where(User.username == 'somebody')

                     Example selecting tweets made by users who are either editors or administrators:

                        sq = Tweet.select().join(User).where(
                            (User.is_editor == True) |
                            (User.is_admin == True))

                     Example of deleting tweets by users who are no longer active:

                        inactive_users = User.select().where(User.active == False)
                        dq = (Tweet
                              .delete()
                              .where(Tweet.user.in_(inactive_users)))
                        dq.execute()  # Return number of tweets deleted.

                     <b>NOTE:</b>
                        <u>where()</u> calls are chainable.  Multiple calls will be "AND"-ed together.

              <b>orwhere(*expressions)</b>

                     <b>Parameters</b>
                            <b>expressions</b> -- zero or more expressions to include in the WHERE clause.

                     Include the given expressions in the WHERE clause of the query. This method is the same  as
                     the  <u>Query.where()</u>  method,  except  that  the  expressions will be OR-ed together with any
                     previously-specified WHERE expressions.

              <b>order_by(*values)</b>

                     <b>Parameters</b>
                            <b>values</b> -- zero or more Column-like objects to order by.

                     Define the ORDER BY clause. Any previously-specified values will be overwritten.

              <b>order_by_extend(*values)</b>

                     <b>Parameters</b>
                            <b>values</b> -- zero or more Column-like objects to order by.

                     Extend any previously-specified ORDER BY clause with the given values.

              <b>limit([value=None])</b>

                     <b>Parameters</b>
                            <b>value</b> (<u>int</u>) -- specify value for LIMIT clause.

              <b>offset([value=None])</b>

                     <b>Parameters</b>
                            <b>value</b> (<u>int</u>) -- specify value for OFFSET clause.

              <b>paginate(page[,</b> <b>paginate_by=20])</b>

                     <b>Parameters</b>

                            • <b>page</b> (<u>int</u>) -- Page number of results (starting from 1).

                            • <b>paginate_by</b> (<u>int</u>) -- Rows-per-page.

                     Convenience method for specifying the LIMIT and OFFSET in a more intuitive way.

                     This feature is designed with web-site pagination in mind, so the first  page  starts  with
                     <b>page=1</b>.

       <b>class</b> <b>SelectQuery</b>
              Select query helper-class that implements operator-overloads for creating compound queries.

              <b>select_from(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b> -- one or more columns to select from the inner query.

                     <b>Returns</b>
                            a new query that wraps the calling query.

                     Create  a new query that wraps the current (calling) query. For example, suppose you have a
                     simple <b>UNION</b> query, and need to apply an aggregation on the union result-set. To  do  this,
                     you need to write something like:

                        SELECT "u"."owner", COUNT("u"."id") AS "ct"
                        FROM (
                            SELECT "id", "owner", ... FROM "cars"
                            UNION
                            SELECT "id", "owner", ... FROM "motorcycles"
                            UNION
                            SELECT "id", "owner", ... FROM "boats") AS "u"
                        GROUP BY "u"."owner"

                     The <u>select_from()</u> method is designed to simplify constructing this type of query.

                     Example peewee code:

                        class Car(Model):
                            owner = ForeignKeyField(Owner, backref='cars')
                            # ... car-specific fields, etc ...

                        class Motorcycle(Model):
                            owner = ForeignKeyField(Owner, backref='motorcycles')
                            # ... motorcycle-specific fields, etc ...

                        class Boat(Model):
                            owner = ForeignKeyField(Owner, backref='boats')
                            # ... boat-specific fields, etc ...

                        cars = Car.select(Car.owner)
                        motorcycles = Motorcycle.select(Motorcycle.owner)
                        boats = Boat.select(Boat.owner)

                        union = cars | motorcycles | boats

                        query = (union
                                 .select_from(union.c.owner, fn.COUNT(union.c.id))
                                 .group_by(union.c.owner))

              <b>union_all(dest)</b>
                     Create a UNION ALL query with <b>dest</b>.

              <b>__add__(dest)</b>
                     Create a UNION ALL query with <b>dest</b>.

              <b>union(dest)</b>
                     Create a UNION query with <b>dest</b>.

              <b>__or__(dest)</b>
                     Create a UNION query with <b>dest</b>.

              <b>intersect(dest)</b>
                     Create an INTERSECT query with <b>dest</b>.

              <b>__and__(dest)</b>
                     Create an INTERSECT query with <b>dest</b>.

              <b>except_(dest)</b>
                     Create  an  EXCEPT  query with <b>dest</b>. Note that the method name has a trailing "_" character
                     since <b>except</b> is a Python reserved word.

              <b>__sub__(dest)</b>
                     Create an EXCEPT query with <b>dest</b>.

       <b>class</b> <b>SelectBase</b>
              Base-class for <u>Select</u> and <b>CompoundSelect</b> queries.

              <b>peek(database[,</b> <b>n=1])</b>

                     <b>Parameters</b>

                            • <b>database</b> (<u>Database</u>) -- database to execute query against.

                            • <b>n</b> (<u>int</u>) -- Number of rows to return.

                     <b>Returns</b>
                            A single row if n = 1, else a list of rows.

                     Execute the query and return the given number of rows from the start of  the  cursor.  This
                     function  may  be  called multiple times safely, and will always return the first N rows of
                     results.

              <b>first(database[,</b> <b>n=1])</b>

                     <b>Parameters</b>

                            • <b>database</b> (<u>Database</u>) -- database to execute query against.

                            • <b>n</b> (<u>int</u>) -- Number of rows to return.

                     <b>Returns</b>
                            A single row if n = 1, else a list of rows.

                     Like the <u>peek()</u> method, except a <b>LIMIT</b> is applied to the query to ensure that only  <b>n</b>  rows
                     are  returned.   Multiple  calls  for  the  same  value  of  <b>n</b>  will not result in multiple
                     executions.

                     The query is altered in-place so it is not possible to call <u>first()</u> and then later  iterate
                     over  the  full  result-set using the same query object. Again, this is done to ensure that
                     multiple calls to <b>first()</b> will not result in multiple query executions.

              <b>scalar(database[,</b> <b>as_tuple=False[,</b> <b>as_dict=False]])</b>

                     <b>Parameters</b>

                            • <b>database</b> (<u>Database</u>) -- database to execute query against.

                            • <b>as_tuple</b> (<u>bool</u>) -- Return the result as a tuple?

                            • <b>as_dict</b> (<u>bool</u>) -- Return the result as a dict?

                     <b>Returns</b>
                            Single scalar value. If <b>as_tuple</b> <b>=</b> <b>True</b>, a row tuple is returned. If <b>as_dict</b> <b>=</b> <b>True</b>,
                            a row dict is returned.

                     Return a scalar value from the  first  row  of  results.  If  multiple  scalar  values  are
                     anticipated   (e.g.  multiple  aggregations  in  a  single  query)  then  you  may  specify
                     <b>as_tuple=True</b> to get the row tuple.

                     Example:

                        query = Note.select(fn.MAX(Note.timestamp))
                        max_ts = query.scalar(db)

                        query = Note.select(fn.MAX(Note.timestamp), fn.COUNT(Note.id))
                        max_ts, n_notes = query.scalar(db, as_tuple=True)

                        query = Note.select(fn.COUNT(Note.id).alias('count'))
                        assert query.scalar(db, as_dict=True) == {'count': 123}

              <b>count(database[,</b> <b>clear_limit=False])</b>

                     <b>Parameters</b>

                            • <b>database</b> (<u>Database</u>) -- database to execute query against.

                            • <b>clear_limit</b> (<u>bool</u>) -- Clear any LIMIT clause when counting.

                     <b>Returns</b>
                            Number of rows in the query result-set.

                     Return number of rows in the query result-set.

                     Implemented by running SELECT <a href="../man1/COUNT.1.html">COUNT</a>(1) FROM (&lt;current query&gt;).

              <b>exists(database)</b>

                     <b>Parameters</b>
                            <b>database</b> (<u>Database</u>) -- database to execute query against.

                     <b>Returns</b>
                            Whether any results exist for the current query.

                     Return a boolean indicating whether the current query has any results.

              <b>get(database)</b>

                     <b>Parameters</b>
                            <b>database</b> (<u>Database</u>) -- database to execute query against.

                     <b>Returns</b>
                            A single row from the database or <b>None</b>.

                     Execute the query and return the first row, if it exists. Multiple  calls  will  result  in
                     multiple queries being executed.

       <b>class</b> <b>CompoundSelectQuery(lhs,</b> <b>op,</b> <b>rhs)</b>

              <b>Parameters</b>

                     • <b>lhs</b> (<u>SelectBase</u>) -- A Select or CompoundSelect query.

                     • <b>op</b> (<u>str</u>) -- Operation (e.g. UNION, INTERSECT, EXCEPT).

                     • <b>rhs</b> (<u>SelectBase</u>) -- A Select or CompoundSelect query.

              Class representing a compound SELECT query.

       <b>class</b> <b>Select([from_list=None[,</b> <b>columns=None[,</b> <b>group_by=None[,</b> <b>having=None[,</b> <b>distinct=None[,</b>
       <b>windows=None[,</b> <b>for_update=None[,</b> <b>for_update_of=None[,</b> <b>for_update_nowait=None[,</b> <b>**kwargs]]]]]]]]]])</b>

              <b>Parameters</b>

                     • <b>from_list</b> (<u>list</u>) -- List of sources for FROM clause.

                     • <b>columns</b> (<u>list</u>) -- Columns or values to select.

                     • <b>group_by</b> (<u>list</u>) -- List of columns or values to group by.

                     • <b>having</b> (<u>Expression</u>) -- Expression for HAVING clause.

                     • <b>distinct</b> -- Either a boolean or a list of column-like objects.

                     • <b>windows</b> (<u>list</u>) -- List of <u>Window</u> clauses.

                     • <b>for_update</b> -- Boolean or str indicating if SELECT...FOR UPDATE.

                     • <b>for_update_of</b> -- One or more tables for FOR UPDATE OF clause.

                     • <b>for_update_nowait</b> (<u>bool</u>) -- Specify NOWAIT locking.

              Class representing a SELECT query.

              <b>NOTE:</b>
                 Rather  than  instantiating  this  directly,  most-commonly  you will use a factory method like
                 <u>Table.select()</u> or <u>Model.select()</u>.

              Methods on the select query can be chained together.

              Example selecting some user instances from the database.  Only the <b>id</b>  and  <b>username</b>  columns  are
              selected.  When iterated, will return instances of the <b>User</b> model:

                 query = User.select(User.id, User.username)
                 for user in query:
                     print(user.username)

              Example  selecting  users  and  additionally  the  number  of  tweets  made by the user.  The <b>User</b>
              instances returned will have an additional attribute, 'count', that corresponds to the  number  of
              tweets made:

                 query = (User
                          .select(User, fn.COUNT(Tweet.id).alias('count'))
                          .join(Tweet, JOIN.LEFT_OUTER)
                          .group_by(User))
                 for user in query:
                     print(user.username, 'has tweeted', user.count, 'times')

              <b>NOTE:</b>
                 While  it  is  possible  to instantiate <u>Select</u> directly, more commonly you will build the query
                 using the method-chaining APIs.

              <b>columns(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b> -- Zero or more column-like objects to SELECT.

                     Specify which columns or column-like values to SELECT.

              <b>select(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b> -- Zero or more column-like objects to SELECT.

                     Same as <u>Select.columns()</u>, provided for backwards-compatibility.

              <b>select_extend(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b> -- Zero or more column-like objects to SELECT.

                     Extend the current selection with the given columns.

                     Example:

                        def get_users(with_count=False):
                            query = User.select()
                            if with_count:
                                query = (query
                                         .select_extend(fn.COUNT(Tweet.id).alias('count'))
                                         .join(Tweet, JOIN.LEFT_OUTER)
                                         .group_by(User))
                            return query

              <b>from_(*sources)</b>

                     <b>Parameters</b>
                            <b>sources</b> -- Zero or more sources for the FROM clause.

                     Specify which table-like objects should be used in the FROM clause.

                        User = Table('users')
                        Tweet = Table('tweets')
                        query = (User
                                 .select(User.c.username, Tweet.c.content)
                                 .from_(User, Tweet)
                                 .where(User.c.id == Tweet.c.user_id))
                        for row in query.execute(db):
                            print(row['username'], '-&gt;', row['content'])

              <b>join(dest[,</b> <b>join_type='INNER'[,</b> <b>on=None]])</b>

                     <b>Parameters</b>

                            • <b>dest</b> -- A table or table-like object.

                            • <b>join_type</b> (<u>str</u>) -- Type of JOIN, default is "INNER".

                            • <b>on</b> (<u>Expression</u>) -- Join predicate.

                     Join type may be one of:

                     • <b>JOIN.INNER</b>

                     • <b>JOIN.LEFT_OUTER</b>

                     • <b>JOIN.RIGHT_OUTER</b>

                     • <b>JOIN.FULL</b>

                     • <b>JOIN.FULL_OUTER</b>

                     • <b>JOIN.CROSS</b>

                     Express a JOIN:

                        User = Table('users', ('id', 'username'))
                        Note = Table('notes', ('id', 'user_id', 'content'))

                        query = (Note
                                 .select(Note.content, User.username)
                                 .join(User, on=(Note.user_id == User.id)))

              <b>group_by(*columns)</b>

                     <b>Parameters</b>
                            <b>values</b> -- zero or more Column-like objects to group by.

                     Define the GROUP BY clause. Any previously-specified values will be overwritten.

                     Additionally, to specify all columns on a given table, you can pass the table/model  object
                     in place of the individual columns.

                     Example:

                        query = (User
                                 .select(User, fn.Count(Tweet.id).alias('count'))
                                 .join(Tweet)
                                 .group_by(User))

              <b>group_by_extend(*columns)</b>

                     <b>Parameters</b>
                            <b>values</b> -- zero or more Column-like objects to group by.

                     Extend the GROUP BY clause with the given columns.

              <b>having(*expressions)</b>

                     <b>Parameters</b>
                            <b>expressions</b> -- zero or more expressions to include in the HAVING clause.

                     Include  the  given  expressions in the HAVING clause of the query. The expressions will be
                     AND-ed together with any previously-specified HAVING expressions.

              <b>distinct(*columns)</b>

                     <b>Parameters</b>
                            <b>columns</b> -- Zero or more column-like objects.

                     Indicate whether this query should use a DISTINCT clause. By specifying a single  value  of
                     <b>True</b>  the  query  will  use  a simple SELECT DISTINCT.  Specifying one or more columns will
                     result in a SELECT DISTINCT ON.

              <b>window(*windows)</b>

                     <b>Parameters</b>
                            <b>windows</b> -- zero or more <u>Window</u> objects.

                     Define the WINDOW clause. Any previously-specified values will be overwritten.

                     Example:

                        # Equivalent example Using a Window() instance instead.
                        window = Window(partition_by=[Sample.counter])
                        query = (Sample
                                 .select(
                                    Sample.counter,
                                    Sample.value,
                                    fn.AVG(Sample.value).over(window))
                                 .window(window)  # Note call to ".window()"
                                 .order_by(Sample.counter))

              <b>for_update([for_update=True[,</b> <b>of=None[,</b> <b>nowait=None]]])</b>

                     <b>Parameters</b>

                            • <b>for_update</b> -- Either a boolean or a string indicating the desired expression, e.g.
                              "FOR SHARE".

                            • <b>of</b> -- One or more models to restrict locking to.

                            • <b>nowait</b> (<u>bool</u>) -- Specify NOWAIT option when locking.

       <b>class</b> <b>_WriteQuery(table[,</b> <b>returning=None[,</b> <b>**kwargs]])</b>

              <b>Parameters</b>

                     • <b>table</b> (<u>Table</u>) -- Table to write to.

                     • <b>returning</b> (<u>list</u>) -- List of columns for RETURNING clause.

              Base-class for write queries.

              <b>returning(*returning)</b>

                     <b>Parameters</b>
                            <b>returning</b> -- Zero or more column-like objects for RETURNING clause

                     Specify the RETURNING clause of query (if supported by your database).

                        query = (User
                                 .insert_many([{'username': 'foo'},
                                               {'username': 'bar'},
                                               {'username': 'baz'}])
                                 .returning(User.id, User.username)
                                 .namedtuples())
                        data = query.execute()
                        for row in data:
                            print('added:', row.username, 'with id=', row.id)

       <b>class</b> <b>Update(table[,</b> <b>update=None[,</b> <b>**kwargs]])</b>

              <b>Parameters</b>

                     • <b>table</b> (<u>Table</u>) -- Table to update.

                     • <b>update</b> (<u>dict</u>) -- Data to update.

              Class representing an UPDATE query.

              Example:

                 PageView = Table('page_views')
                 query = (PageView
                          .update({PageView.c.page_views: PageView.c.page_views + 1})
                          .where(PageView.c.url == url))
                 query.execute(database)

              <b>from_(*sources)</b>

                     <b>Parameters</b>
                            <b>sources</b> (<u>Source</u>) -- one or more <u>Table</u>, <u>Model</u>, query, or <u>ValuesList</u> to join with.

                     Specify additional tables to join with using the UPDATE ... FROM syntax, which is supported
                     by Postgres. The <u>Postgres</u> <u>documentation</u> provides additional detail, but to summarize:
                        When a <b>FROM</b> clause is present, what essentially happens is  that  the  target  table  is
                        joined  to  the  tables  mentioned  in  the  from_list,  and each output row of the join
                        represents an update operation for the target table. When using <b>FROM</b> you  should  ensure
                        that the join produces at most one output row for each row to be modified.

                     Example:

                        # Update multiple users in a single query.
                        data = [('huey', True),
                                ('mickey', False),
                                ('zaizee', True)]
                        vl = ValuesList(data, columns=('username', 'is_admin'), alias='vl')

                        # Here we'll update the "is_admin" status of the above users,
                        # "joining" the VALUES() on the "username" column.
                        query = (User
                                 .update(is_admin=vl.c.is_admin)
                                 .from_(vl)
                                 .where(User.username == vl.c.username))

                     The above query produces the following SQL:

                        UPDATE "users" SET "is_admin" = "vl"."is_admin"
                        FROM (
                            VALUES ('huey', t), ('mickey', f), ('zaizee', t))
                            AS "vl"("username", "is_admin")
                        WHERE ("users"."username" = "vl"."username")

       <b>class</b> <b>Insert(table[,</b> <b>insert=None[,</b> <b>columns=None[,</b> <b>on_conflict=None[,</b> <b>**kwargs]]]])</b>

              <b>Parameters</b>

                     • <b>table</b> (<u>Table</u>) -- Table to INSERT data into.

                     • <b>insert</b> -- Either a dict, a list, or a query.

                     • <b>columns</b> (<u>list</u>) -- List of columns when <b>insert</b> is a list or query.

                     • <b>on_conflict</b> -- Conflict resolution strategy.

              Class representing an INSERT query.

              <b>as_rowcount([as_rowcount=True])</b>

                     <b>Parameters</b>
                            <b>as_rowcount</b>  (<u>bool</u>)  --  Whether to return the modified row count (as opposed to the
                            last-inserted row id).

                     By default, on databases that do <u>not</u> use  RETURNING  automatically  (currently  Sqlite  and
                     MySQL),  Peewee  versions  3.12  through  3.14.10  would return the modified row-count when
                     executing a bulk insert. This change has  been  reverted  so  that  bulk-inserts  will,  by
                     default, return the value of <b>cursor.lastrowid</b>.

                     If you prefer to receive the inserted row-count, then specify <b>as_rowcount()</b>:

                        db = MySQLDatabase(...)

                        query = User.insert_many([...])
                        # By default, the last rowid is returned:
                        #last_id = query.execute()

                        # To get the modified row-count:
                        rowcount = query.as_rowcount().execute()

              <b>on_conflict_ignore([ignore=True])</b>

                     <b>Parameters</b>
                            <b>ignore</b> (<u>bool</u>) -- Whether to add ON CONFLICT IGNORE clause.

                     Specify IGNORE conflict resolution strategy.

              <b>on_conflict_replace([replace=True])</b>

                     <b>Parameters</b>
                            <b>replace</b> (<u>bool</u>) -- Whether to add ON CONFLICT REPLACE clause.

                     Specify REPLACE conflict resolution strategy.

              <b>on_conflict([action=None[,</b> <b>update=None[,</b> <b>preserve=None[,</b> <b>where=None[,</b> <b>conflict_target=None[,</b>
              <b>conflict_where=None[,</b> <b>conflict_constraint=None]]]]]]])</b>

                     <b>Parameters</b>

                            • <b>action</b>  (<u>str</u>)  --  Action  to  take  when  resolving conflict. If blank, action is
                              assumed to be "update".

                            • <b>update</b> -- A dictionary mapping column to new value.

                            • <b>preserve</b> -- A list of columns whose values should be preserved from  the  original
                              INSERT.

                            • <b>where</b> -- Expression to restrict the conflict resolution.

                            • <b>conflict_target</b> -- Column(s) that comprise the constraint.

                            • <b>conflict_where</b>  --  Expressions  needed  to match the constraint target if it is a
                              partial index (index with a WHERE clause).

                            • <b>conflict_constraint</b> (<u>str</u>) -- Name of constraint to use  for  conflict  resolution.
                              Currently only supported by Postgres.

                     Specify the parameters for an <u>OnConflict</u> clause to use for conflict resolution.

                     Examples:

                        class User(Model):
                            username = TextField(unique=True)
                            last_login = DateTimeField(null=True)
                            login_count = IntegerField()

                        def log_user_in(username):
                            now = datetime.datetime.now()

                            # INSERT a new row for the user with the current timestamp and
                            # login count set to 1. If the user already exists, then we
                            # will preserve the last_login value from the "insert()" clause
                            # and atomically increment the login-count.
                            userid = (User
                                      .insert(username=username, last_login=now, login_count=1)
                                      .on_conflict(
                                          conflict_target=[User.username],
                                          preserve=[User.last_login],
                                          update={User.login_count: User.login_count + 1})
                                      .execute())
                            return userid

                     Example using the special <u>EXCLUDED</u> namespace:

                        class KV(Model):
                            key = CharField(unique=True)
                            value = IntegerField()

                        # Create one row.
                        KV.create(key='k1', value=1)

                        # Demonstrate usage of EXCLUDED.
                        # Here we will attempt to insert a new value for a given key. If that
                        # key already exists, then we will update its value with the *sum* of its
                        # original value and the value we attempted to insert -- provided that
                        # the new value is larger than the original value.
                        query = (KV.insert(key='k1', value=10)
                                 .on_conflict(conflict_target=[KV.key],
                                              update={KV.value: KV.value + EXCLUDED.value},
                                              where=(EXCLUDED.value &gt; KV.value)))

                        # Executing the above query will result in the following data being
                        # present in the "kv" table:
                        # (key='k1', value=11)
                        query.execute()

                        # If we attempted to execute the query *again*, then nothing would be
                        # updated, as the new value (10) is now less than the value in the
                        # original row (11).

       <b>class</b> <b>Delete</b>
              Class representing a DELETE query.

       <b>class</b> <b>Index(name,</b> <b>table,</b> <b>expressions[,</b> <b>unique=False[,</b> <b>safe=False[,</b> <b>where=None[,</b> <b>using=None]]]])</b>

              <b>Parameters</b>

                     • <b>name</b> (<u>str</u>) -- Index name.

                     • <b>table</b> (<u>Table</u>) -- Table to create index on.

                     • <b>expressions</b> -- List of columns to index on (or expressions).

                     • <b>unique</b> (<u>bool</u>) -- Whether index is UNIQUE.

                     • <b>safe</b> (<u>bool</u>) -- Whether to add IF NOT EXISTS clause.

                     • <b>where</b> (<u>Expression</u>) -- Optional WHERE clause for index.

                     • <b>using</b> (<u>str</u>) -- Index algorithm.

              <b>safe([_safe=True])</b>

                     <b>Parameters</b>
                            <b>_safe</b> (<u>bool</u>) -- Whether to add IF NOT EXISTS clause.

              <b>where(*expressions)</b>

                     <b>Parameters</b>
                            <b>expressions</b> -- zero or more expressions to include in the WHERE clause.

                     Include  the  given  expressions  in the WHERE clause of the index. The expressions will be
                     AND-ed together with any previously-specified WHERE expressions.

              <b>using([_using=None])</b>

                     <b>Parameters</b>
                            <b>_using</b> (<u>str</u>) -- Specify index algorithm for USING clause.

       <b>class</b> <b>ModelIndex(model,</b> <b>fields[,</b> <b>unique=False[,</b> <b>safe=True[,</b> <b>where=None[,</b> <b>using=None[,</b> <b>name=None]]]]])</b>

              <b>Parameters</b>

                     • <b>model</b> (<u>Model</u>) -- Model class to create index on.

                     • <b>fields</b> (<u>list</u>) -- Fields to index.

                     • <b>unique</b> (<u>bool</u>) -- Whether index is UNIQUE.

                     • <b>safe</b> (<u>bool</u>) -- Whether to add IF NOT EXISTS clause.

                     • <b>where</b> (<u>Expression</u>) -- Optional WHERE clause for index.

                     • <b>using</b> (<u>str</u>) -- Index algorithm or type, e.g. 'BRIN', 'GiST' or 'GIN'.

                     • <b>name</b> (<u>str</u>) -- Optional index name.

              Expressive method for declaring an index on a model.

              Examples:

                 class Article(Model):
                     name = TextField()
                     timestamp = TimestampField()
                     status = IntegerField()
                     flags = BitField()

                     is_sticky = <a href="../man1/flags.flag.1.html">flags.flag</a>(1)
                     is_favorite = <a href="../man2/flags.flag.2.html">flags.flag</a>(2)

                 # CREATE INDEX ... ON "article" ("name", "timestamp")
                 idx = ModelIndex(Article, (Article.name, Article.timestamp))

                 # CREATE INDEX ... ON "article" ("name", "timestamp") WHERE "status" = 1
                 idx = idx.where(Article.status == 1)

                 # CREATE UNIQUE INDEX ... ON "article" ("timestamp" DESC, "flags" &amp; 2) WHERE "status" = 1
                 idx = ModelIndex(
                     Article,
                     (Article.timestamp.desc(), <a href="../man2/Article.flags.bin_and.2.html">Article.flags.bin_and</a>(2)),
                     unique = True).where(Article.status == 1)

              You can also use <u>Model.index()</u>:

                 idx = Article.index(Article.name, Article.timestamp).where(Article.status == 1)

              To add an index to a model definition use <u>Model.add_index()</u>:

                 idx = Article.index(Article.name, Article.timestamp).where(Article.status == 1)

                 # Add above index definition to the model definition. When you call
                 # Article.create_table() (or database.create_tables([Article])), the
                 # index will be created.
                 Article.add_index(idx)

   <b>Fields</b>
       <b>class</b> <b>Field([null=False[,</b> <b>index=False[,</b> <b>unique=False[,</b> <b>column_name=None[,</b> <b>default=None[,</b>
       <b>primary_key=False[,</b> <b>constraints=None[,</b> <b>sequence=None[,</b> <b>collation=None[,</b> <b>unindexed=False[,</b> <b>choices=None[,</b>
       <b>help_text=None[,</b> <b>verbose_name=None[,</b> <b>index_type=None]]]]]]]]]]]]]])</b>

              <b>Parameters</b>

                     • <b>null</b> (<u>bool</u>) -- Field allows NULLs.

                     • <b>index</b> (<u>bool</u>) -- Create an index on field.

                     • <b>unique</b> (<u>bool</u>) -- Create a unique index on field.

                     • <b>column_name</b> (<u>str</u>) -- Specify column name for field.

                     • <b>default</b> -- Default value (enforced in Python, not on server).

                     • <b>primary_key</b> (<u>bool</u>) -- Field is the primary key.

                     • <b>constraints</b> (<u>list</u>) -- List of constraints to apply to column, for example:  <b>[Check('price</b>
                       <b>&gt;</b> <b>0')]</b>.

                     • <b>sequence</b> (<u>str</u>) -- Sequence name for field.

                     • <b>collation</b> (<u>str</u>) -- Collation name for field.

                     • <b>unindexed</b> (<u>bool</u>) -- Declare field UNINDEXED (sqlite only).

                     • <b>choices</b>  (<u>list</u>)  -- An iterable of 2-tuples mapping column values to display labels. Used
                       for metadata purposes only, to help when displaying  a  dropdown  of  choices  for  field
                       values, for example.

                     • <b>help_text</b> (<u>str</u>) -- Help-text for field, metadata purposes only.

                     • <b>verbose_name</b> (<u>str</u>) -- Verbose name for field, metadata purposes only.

                     • <b>index_type</b> (<u>str</u>) -- Specify index type (postgres only), e.g. 'BRIN'.

              Fields on a <u>Model</u> are analogous to columns on a table.

              <b>field_type</b> <b>=</b> <b>'&lt;some</b> <b>field</b> <b>type&gt;'</b>
                     Attribute  used to map this field to a column type, e.g. "INT". See the <b>FIELD</b> object in the
                     source for more information.

              <b>column</b> Retrieve a reference to the underlying <u>Column</u> object.

              <b>model</b>  The model the field is bound to.

              <b>name</b>   The name of the field.

              <b>db_value(value)</b>
                     Coerce a Python value into a value  suitable  for  storage  in  the  database.  Sub-classes
                     operating on special data-types will most likely want to override this method.

              <b>python_value(value)</b>
                     Coerce  a  value  from  the database into a Python object. Sub-classes operating on special
                     data-types will most likely want to override this method.

              <b>coerce(value)</b>
                     This method is a shorthand that is used, by default, by both <u>db_value()</u> and <u>python_value()</u>.

                     <b>Parameters</b>
                            <b>value</b> -- arbitrary data from app or backend

                     <b>Return</b> <b>type</b>
                            python data type

       <b>class</b> <b>IntegerField</b>
              Field class for storing integers.

       <b>class</b> <b>BigIntegerField</b>
              Field class for storing big integers (if supported by database).

       <b>class</b> <b>SmallIntegerField</b>
              Field class for storing small integers (if supported by database).

       <b>class</b> <b>AutoField</b>
              Field class for storing auto-incrementing primary keys.

              <b>NOTE:</b>
                 In SQLite, for performance reasons, the default primary key type simply uses the  max  existing
                 value  + 1 for new values, as opposed to the max ever value + 1. This means deleted records can
                 have their primary keys reused. In conjunction with SQLite  having  foreign  keys  disabled  by
                 default  (meaning  ON  DELETE  is ignored, even if you specify it explicitly), this can lead to
                 surprising and dangerous behaviour. To avoid  this,  you  may  want  to  use  one  or  both  of
                 <u>AutoIncrementField</u> and <b>pragmas=[('foreign_keys',</b> <b>'on')]</b> when you instantiate <u>SqliteDatabase</u>.

       <b>class</b> <b>BigAutoField</b>
              Field class for storing auto-incrementing primary keys using 64-bits.

       <b>class</b> <b>IdentityField([generate_always=False])</b>

              <b>Parameters</b>
                     <b>generate_always</b>  (<u>bool</u>)  --  if  specified, then the identity will always be generated (and
                     specifying the value explicitly during INSERT will raise a programming  error).  Otherwise,
                     the identity value is only generated as-needed.

              Field  class  for storing auto-incrementing primary keys using the new Postgres 10 <u>IDENTITY</u> column
              type. The column definition ends up looking like this:

                 id = IdentityField()
                 # "id" INT GENERATED BY DEFAULT AS IDENTITY NOT NULL PRIMARY KEY

              <b>ATTENTION:</b>
                 Only supported by Postgres 10.0 and newer.

       <b>class</b> <b>FloatField</b>
              Field class for storing floating-point numbers.

       <b>class</b> <b>DoubleField</b>
              Field class for storing double-precision floating-point numbers.

       <b>class</b> <b>DecimalField([max_digits=10[,</b> <b>decimal_places=5[,</b> <b>auto_round=False[,</b> <b>rounding=None[,</b> <b>**kwargs]]]]])</b>

              <b>Parameters</b>

                     • <b>max_digits</b> (<u>int</u>) -- Maximum digits to store.

                     • <b>decimal_places</b> (<u>int</u>) -- Maximum precision.

                     • <b>auto_round</b> (<u>bool</u>) -- Automatically round values.

                     • <b>rounding</b> --

                       Defaults to <b>decimal.DefaultContext.rounding</b>.

                       Field class for storing  decimal  numbers.  Values  are  represented  as  <b>decimal.Decimal</b>
                       objects.

       <b>class</b> <b>CharField([max_length=255])</b>
              Field class for storing strings.

              <b>NOTE:</b>
                 Values that exceed length are not truncated automatically.

       <b>class</b> <b>FixedCharField</b>
              Field class for storing fixed-length strings.

              <b>NOTE:</b>
                 Values that exceed length are not truncated automatically.

       <b>class</b> <b>TextField</b>
              Field class for storing text.

       <b>class</b> <b>BlobField</b>
              Field class for storing binary data.

       <b>class</b> <b>BitField</b>
              Field class for storing options in a 64-bit integer column.

              Usage:

                 class Post(Model):
                     content = TextField()
                     flags = BitField()

                     is_favorite = <a href="../man1/flags.flag.1.html">flags.flag</a>(1)
                     is_sticky = <a href="../man2/flags.flag.2.html">flags.flag</a>(2)
                     is_minimized = <a href="../man4/flags.flag.4.html">flags.flag</a>(4)
                     is_deleted = <a href="../man8/flags.flag.8.html">flags.flag</a>(8)

                 &gt;&gt;&gt; p = Post()
                 &gt;&gt;&gt; p.is_sticky = True
                 &gt;&gt;&gt; p.is_minimized = True
                 &gt;&gt;&gt; print(p.flags)  # Prints 4 | 2 --&gt; "6"
                 6
                 &gt;&gt;&gt; p.is_favorite
                 False
                 &gt;&gt;&gt; p.is_sticky
                 True

              We can use the flags on the Post class to build expressions in queries as well:

                 # Generates a WHERE clause that looks like:
                 # WHERE (post.flags &amp; 1 != 0)
                 query = Post.select().where(Post.is_favorite)

                 # Query for sticky + favorite posts:
                 query = Post.select().where(Post.is_sticky &amp; Post.is_favorite)

              When  bulk-updating  one or more bits in a <u>BitField</u>, you can use bitwise operators to set or clear
              one or more bits:

                 # Set the 4th bit on all Post objects.
                 Post.update(flags=Post.flags | 8).execute()

                 # Clear the 1st and 3rd bits on all Post objects.
                 Post.update(flags=Post.flags &amp; ~(1 | 4)).execute()

              For simple operations, the flags provide handy <b>set()</b> and <b>clear()</b> methods for setting  or  clearing
              an individual bit:

                 # Set the "is_deleted" bit on all posts.
                 Post.update(flags=Post.is_deleted.set()).execute()

                 # Clear the "is_deleted" bit on all posts.
                 Post.update(flags=Post.is_deleted.clear()).execute()

              <b>flag([value=None])</b>

                     <b>Parameters</b>
                            <b>value</b> (<u>int</u>) -- Value associated with flag, typically a power of 2.

                     Returns  a descriptor that can get or set specific bits in the overall value. When accessed
                     on the class itself, it returns a <u>Expression</u> object suitable for use in a query.

                     If the value is not provided, it is assumed that each flag will be an increasing  power  of
                     2, so if you had four flags, they would have the values 1, 2, 4, 8.

       <b>class</b> <b>BigBitField</b>
              Field  class  for  storing arbitrarily-large bitmaps in a <b>BLOB</b>. The field will grow the underlying
              buffer as necessary, ensuring there are enough bytes of data to support the number of bits of data
              being stored.

              Example usage:

                 class Bitmap(Model):
                     data = BigBitField()

                 bitmap = Bitmap()

                 # Sets the ith bit, e.g. the 1st bit, the 11th bit, the 63rd, etc.
                 bits_to_set = (1, 11, 63, 31, 55, 48, 100, 99)
                 for bit_idx in bits_to_set:
                     bitmap.data.set_bit(bit_idx)

                 # We can test whether a bit is set using "is_set":
                 assert <a href="../man11/bitmap.data.is_set.11.html">bitmap.data.is_set</a>(11)
                 assert not <a href="../man12/bitmap.data.is_set.12.html">bitmap.data.is_set</a>(12)

                 # We can clear a bit:
                 <a href="../man11/bitmap.data.clear_bit.11.html">bitmap.data.clear_bit</a>(11)
                 assert not <a href="../man11/bitmap.data.is_set.11.html">bitmap.data.is_set</a>(11)

                 # We can also "toggle" a bit. Recall that the 63rd bit was set earlier.
                 assert <a href="../man63/bitmap.data.toggle_bit.63.html">bitmap.data.toggle_bit</a>(63) is False
                 assert <a href="../man63/bitmap.data.toggle_bit.63.html">bitmap.data.toggle_bit</a>(63) is True
                 assert <a href="../man63/bitmap.data.is_set.63.html">bitmap.data.is_set</a>(63)

                 # BigBitField supports item accessor by bit-number, e.g.:
                 assert bitmap.data[63]
                 bitmap.data[0] = 1
                 del bitmap.data[0]

                 # We can also combine bitmaps using bitwise operators, e.g.
                 b = Bitmap(data=b'\x01')
                 b.data |= b'\x02'
                 assert list(b.data) == [1, 1, 0, 0, 0, 0, 0, 0]
                 assert len(b.data) == 1

              <b>clear()</b>
                     Clears the bitmap and sets length to 0.

              <b>set_bit(idx)</b>

                     <b>Parameters</b>
                            <b>idx</b> (<u>int</u>) -- Bit to set, indexed starting from zero.

                     Sets the <u>idx</u>-th bit in the bitmap.

              <b>clear_bit(idx)</b>

                     <b>Parameters</b>
                            <b>idx</b> (<u>int</u>) -- Bit to clear, indexed starting from zero.

                     Clears the <u>idx</u>-th bit in the bitmap.

              <b>toggle_bit(idx)</b>

                     <b>Parameters</b>
                            <b>idx</b> (<u>int</u>) -- Bit to toggle, indexed starting from zero.

                     <b>Returns</b>
                            Whether the bit is set or not.

                     Toggles the <u>idx</u>-th bit in the bitmap and returns whether the bit is set or not.

                     Example:

                        &gt;&gt;&gt; bitmap = Bitmap()
                        &gt;&gt;&gt; <a href="../man10/bitmap.data.toggle_bit.10.html">bitmap.data.toggle_bit</a>(10)  # Toggle the 10th bit.
                        True
                        &gt;&gt;&gt; <a href="../man10/bitmap.data.toggle_bit.10.html">bitmap.data.toggle_bit</a>(10)  # This will clear the 10th bit.
                        False

              <b>is_set(idx)</b>

                     <b>Parameters</b>
                            <b>idx</b> (<u>int</u>) -- Bit index, indexed starting from zero.

                     <b>Returns</b>
                            Whether the bit is set or not.

                     Returns boolean indicating whether the <u>idx</u>-th bit is set or not.

              <b>__getitem__(idx)</b>
                     Same as <u>is_set()</u>

              <b>__setitem__(idx,</b> <b>value)</b>
                     Set the bit at <b>idx</b> to value (True or False).

              <b>__delitem__(idx)</b>
                     Same as <u>clear_bit()</u>

              <b>__len__()</b>
                     Return the length of the bitmap <b>in</b> <b>bytes</b>.

              <b>__iter__()</b>
                     Returns an iterator yielding 1 or 0 for each bit in the bitmap.

              <b>__and__(other)</b>

                     <b>Parameters</b>
                            <b>other</b> -- Either <u>BigBitField</u>, <b>bytes</b>, <b>bytearray</b> or <b>memoryview</b> object.

                     <b>Returns</b>
                            bitwise <b>and</b> of two bitmaps.

              <b>__or__(other)</b>

                     <b>Parameters</b>
                            <b>other</b> -- Either <u>BigBitField</u>, <b>bytes</b>, <b>bytearray</b> or <b>memoryview</b> object.

                     <b>Returns</b>
                            bitwise <b>or</b> of two bitmaps.

              <b>__xor__(other)</b>

                     <b>Parameters</b>
                            <b>other</b> -- Either <u>BigBitField</u>, <b>bytes</b>, <b>bytearray</b> or <b>memoryview</b> object.

                     <b>Returns</b>
                            bitwise <b>xor</b> of two bitmaps.

       <b>class</b> <b>UUIDField</b>
              Field class for storing <b>uuid.UUID</b> objects. With Postgres, the underlying column's  data-type  will
              be  <u>UUID</u>.  Since  SQLite and MySQL do not have a native UUID type, the UUID is stored as a <u>VARCHAR</u>
              instead.

       <b>class</b> <b>BinaryUUIDField</b>
              Field class for storing <b>uuid.UUID</b> objects  efficiently  in  16-bytes.  Uses  the  database's  <u>BLOB</u>
              data-type (or <u>VARBINARY</u> in MySQL, or <u>BYTEA</u> in Postgres).

       <b>class</b> <b>DateTimeField([formats=None[,</b> <b>**kwargs]])</b>

              <b>Parameters</b>
                     <b>formats</b> (<u>list</u>) -- A list of format strings to use when coercing a string to a date-time.

              Field class for storing <b>datetime.datetime</b> objects.

              Accepts  a special parameter <b>formats</b>, which contains a list of formats the datetime can be encoded
              with (for databases that do not have  support  for  a  native  datetime  data-type).  The  default
              supported formats are:

                 '%Y-%m-%d %H:%M:%S.%f' # year-month-day hour-minute-second.microsecond
                 '%Y-%m-%d %H:%M:%S' # year-month-day hour-minute-second
                 '%Y-%m-%d' # year-month-day

              <b>NOTE:</b>
                 SQLite  does  not have a native datetime data-type, so datetimes are stored as strings. This is
                 handled transparently by Peewee, but if you have pre-existing data  you  should  ensure  it  is
                 stored as <b>YYYY-mm-dd</b> <b>HH:MM:SS</b> or one of the other supported formats.

              <b>year</b>   Reference the year of the value stored in the column in a query.

                        Blog.select().where(Blog.pub_date.year == 2018)

              <b>month</b>  Reference the month of the value stored in the column in a query.

              <b>day</b>    Reference the day of the value stored in the column in a query.

              <b>hour</b>   Reference the hour of the value stored in the column in a query.

              <b>minute</b> Reference the minute of the value stored in the column in a query.

              <b>second</b> Reference the second of the value stored in the column in a query.

              <b>to_timestamp()</b>
                     Method  that returns a database-specific function call that will allow you to work with the
                     given date-time value as a numeric timestamp. This can sometimes simplify tasks  like  date
                     math in a compatible way.

                     Example:

                        # Find all events that are exactly 1 hour long.
                        query = (Event
                                 .select()
                                 .where((Event.start.to_timestamp() + 3600) ==
                                        Event.stop.to_timestamp())
                                 .order_by(Event.start))

              <b>truncate(date_part)</b>

                     <b>Parameters</b>
                            <b>date_part</b> (<u>str</u>) -- year, month, day, hour, minute or second.

                     <b>Returns</b>
                            expression node to truncate date/time to given resolution.

                     Truncates  the value in the column to the given part. This method is useful for finding all
                     rows within a given month, for instance.

       <b>class</b> <b>DateField([formats=None[,</b> <b>**kwargs]])</b>

              <b>Parameters</b>
                     <b>formats</b> (<u>list</u>) -- A list of format strings to use when coercing a string to a date.

              Field class for storing <b>datetime.date</b> objects.

              Accepts a special parameter <b>formats</b>, which contains a list of formats the datetime can be  encoded
              with  (for  databases that do not have support for a native date data-type). The default supported
              formats are:

                 '%Y-%m-%d' # year-month-day
                 '%Y-%m-%d %H:%M:%S' # year-month-day hour-minute-second
                 '%Y-%m-%d %H:%M:%S.%f' # year-month-day hour-minute-second.microsecond

              <b>NOTE:</b>
                 If the incoming value does not match a format, it is returned as-is.

              <b>year</b>   Reference the year of the value stored in the column in a query.

                        Person.select().where(Person.dob.year == 1983)

              <b>month</b>  Reference the month of the value stored in the column in a query.

              <b>day</b>    Reference the day of the value stored in the column in a query.

              <b>to_timestamp()</b>
                     See <u>DateTimeField.to_timestamp()</u>.

              <b>truncate(date_part)</b>
                     See <u>DateTimeField.truncate()</u>. Note that only  <u>year</u>,  <u>month</u>,  and  <u>day</u>  are  meaningful  for
                     <u>DateField</u>.

       <b>class</b> <b>TimeField([formats=None[,</b> <b>**kwargs]])</b>

              <b>Parameters</b>
                     <b>formats</b> (<u>list</u>) -- A list of format strings to use when coercing a string to a time.

              Field class for storing <b>datetime.time</b> objects (not <b>timedelta</b>).

              Accepts  a special parameter <b>formats</b>, which contains a list of formats the datetime can be encoded
              with (for databases that do not have support for a native time data-type). The  default  supported
              formats are:

                 '%H:%M:%S.%f' # hour:minute:second.microsecond
                 '%H:%M:%S' # hour:minute:second
                 '%H:%M' # hour:minute
                 '%Y-%m-%d %H:%M:%S.%f' # year-month-day hour-minute-second.microsecond
                 '%Y-%m-%d %H:%M:%S' # year-month-day hour-minute-second

              <b>NOTE:</b>
                 If the incoming value does not match a format, it is returned as-is.

              <b>hour</b>   Reference the hour of the value stored in the column in a query.

                        evening_events = Event.select().where(Event.time.hour &gt; 17)

              <b>minute</b> Reference the minute of the value stored in the column in a query.

              <b>second</b> Reference the second of the value stored in the column in a query.

       <b>class</b> <b>TimestampField([resolution=1[,</b> <b>utc=False[,</b> <b>**kwargs]]])</b>

              <b>Parameters</b>

                     • <b>resolution</b>  --  Can be provided as either a power of 10, or as an exponent indicating how
                       many decimal places to store.

                     • <b>utc</b> (<u>bool</u>) -- Treat timestamps as UTC.

              Field class for storing date-times as integer timestamps. Sub-second resolution  is  supported  by
              multiplying by a power of 10 to get an integer.

              If  the  <b>resolution</b>  parameter  is <b>0</b> <u>or</u> <b>1</b>, then the timestamp is stored using second resolution. A
              resolution between <b>2</b> and <b>6</b>  is  treated  as  the  number  of  decimal  places,  e.g.  <b>resolution=3</b>
              corresponds  to milliseconds. Alternatively, the decimal can be provided as a multiple of 10, such
              that <b>resolution=10</b> will store 1/10th of a second resolution.

              The <b>resolution</b> parameter can be either 0-6  <u>or</u>  10,  100,  etc  up  to  1000000  (for  microsecond
              resolution).  This  allows sub-second precision while still using an <u>IntegerField</u> for storage. The
              default is second resolution.

              Also accepts a boolean parameter <b>utc</b>, used to indicate  whether  the  timestamps  should  be  UTC.
              Default is <b>False</b>.

              Finally,  the  field  <b>default</b>  is  the  current  timestamp. If you do not want this behavior, then
              explicitly pass in <b>default=None</b>.

       <b>class</b> <b>IPField</b>
              Field class for storing IPv4 addresses efficiently (as integers).

       <b>class</b> <b>BooleanField</b>
              Field class for storing boolean values.

       <b>class</b> <b>BareField([coerce=None[,</b> <b>**kwargs]])</b>

              <b>Parameters</b>
                     <b>coerce</b> -- Optional function to use for converting raw values into a specific format.

              Field class that does not specify a data-type (<b>SQLite-only</b>).

              Since data-types are not enforced, you can declare fields without <u>any</u> data-type. It is also common
              for SQLite virtual tables to use meta-columns or untyped columns, so for those cases as  well  you
              may wish to use an untyped field.

              Accepts  a  special  <b>coerce</b>  parameter, a function that takes a value coming from the database and
              converts it into the appropriate Python type.

       <b>class</b> <b>ForeignKeyField(model[,</b> <b>field=None[,</b> <b>backref=None[,</b> <b>on_delete=None[,</b> <b>on_update=None[,</b>
       <b>deferrable=None[,</b> <b>object_id_name=None[,</b> <b>lazy_load=True[,</b> <b>constraint_name=None[,</b> <b>**kwargs]]]]]]]]])</b>

              <b>Parameters</b>

                     • <b>model</b> (<u>Model</u>) -- Model to reference or the string 'self' if declaring a  self-referential
                       foreign key.

                     • <b>field</b> (<u>Field</u>) -- Field to reference on <b>model</b> (default is primary key).

                     • <b>backref</b>  (<u>str</u>)  -- Accessor name for back-reference, or "+" to disable the back-reference
                       accessor.

                     • <b>on_delete</b> (<u>str</u>) -- ON DELETE action, e.g. <b>'CASCADE'</b>..

                     • <b>on_update</b> (<u>str</u>) -- ON UPDATE action.

                     • <b>deferrable</b> (<u>str</u>) -- Control when constraint is enforced, e.g. <b>'INITIALLY</b> <b>DEFERRED'</b>.

                     • <b>object_id_name</b> (<u>str</u>) -- Name for object-id accessor.

                     • <b>lazy_load</b> (<u>bool</u>) -- Fetch the related object when  the  foreign-key  field  attribute  is
                       accessed  (if  it was not already loaded). If this is disabled, accessing the foreign-key
                       field will return the value stored in the foreign-key column.

                     • <b>constraint_name</b> (<u>str</u>) -- (optional) name to use for foreign-key constraint.

              Field class for storing a foreign key.

                 class User(Model):
                     name = TextField()

                 class Tweet(Model):
                     user = ForeignKeyField(User, backref='tweets')
                     content = TextField()

                 # "user" attribute
                 &gt;&gt;&gt; some_tweet.user
                 &lt;User: charlie&gt;

                 # "tweets" backref attribute
                 &gt;&gt;&gt; for tweet in charlie.tweets:
                 ...     print(tweet.content)
                 Some tweet
                 Another tweet
                 Yet another tweet

              For an in-depth discussion of foreign-keys, joins  and  relationships  between  models,  refer  to
              <u>Relationships</u> <u>and</u> <u>Joins</u>.

              <b>NOTE:</b>
                 Foreign  keys  do not have a particular <b>field_type</b> as they will take their field type depending
                 on the type of primary key on the model they are related to.

              <b>NOTE:</b>
                 If you manually specify a <b>field</b>, that field must be either a  primary  key  or  have  a  unique
                 constraint.

              <b>NOTE:</b>
                 Take  care  with  foreign  keys  in SQLite. By default, ON DELETE has no effect, which can have
                 surprising (and usually unwanted) effects on your database integrity. This can affect you  even
                 if  you  don't  specify  <b>on_delete</b>,  since  the  default  ON  DELETE behaviour (to fail without
                 modifying your data) does not happen, and your data can be silently relinked. The safest  thing
                 to do is to specify <b>pragmas={'foreign_keys':</b> <b>1}</b> when you instantiate <u>SqliteDatabase</u>.

       <b>class</b> <b>DeferredForeignKey(rel_model_name[,</b> <b>**kwargs])</b>

              <b>Parameters</b>
                     <b>rel_model_name</b> (<u>str</u>) -- Model name to reference.

              Field  class  for representing a deferred foreign key. Useful for circular foreign-key references,
              for example:

                 class Husband(Model):
                     name = TextField()
                     wife = DeferredForeignKey('Wife', deferrable='INITIALLY DEFERRED')

                 class Wife(Model):
                     name = TextField()
                     husband = ForeignKeyField(Husband, deferrable='INITIALLY DEFERRED')

              In the  above  example,  when  the  <b>Wife</b>  model  is  declared,  the  foreign-key  <b>Husband.wife</b>  is
              automatically resolved and turned into a regular <u>ForeignKeyField</u>.

              <b>WARNING:</b>
                 <u>DeferredForeignKey</u>  references  are  resolved when model classes are declared and created. This
                 means that if you declare a <u>DeferredForeignKey</u> to a model class that has already been  imported
                 and created, the deferred foreign key instance will never be resolved. For example:

                     class User(Model):
                         username = TextField()

                     class Tweet(Model):
                         # This will never actually be resolved, because the User
                         # model has already been declared.
                         user = DeferredForeignKey('user', backref='tweets')
                         content = TextField()

                 In  cases  like  these  you  should use the regular <u>ForeignKeyField</u> <u>or</u> you can manually resolve
                 deferred foreign keys like so:

                     # Tweet.user will be resolved into a ForeignKeyField:
                     DeferredForeignKey.resolve(User)

       <b>class</b> <b>ManyToManyField(model[,</b> <b>backref=None[,</b> <b>through_model=None[,</b> <b>on_delete=None[,</b> <b>on_update=None]]]])</b>

              <b>Parameters</b>

                     • <b>model</b> (<u>Model</u>) -- Model to create relationship with.

                     • <b>backref</b> (<u>str</u>) -- Accessor name for back-reference

                     • <b>through_model</b> (<u>Model</u>) -- <u>Model</u> to use for the intermediary  table.  If  not  provided,  a
                       simple through table will be automatically created.

                     • <b>on_delete</b>  (<u>str</u>)  --  ON  DELETE action, e.g. <b>'CASCADE'</b>. Will be used for foreign-keys in
                       through model.

                     • <b>on_update</b> (<u>str</u>) -- ON UPDATE action. Will be used for foreign-keys in through model.

              The <u>ManyToManyField</u> provides a simple  interface  for  working  with  many-to-many  relationships,
              inspired  by  Django.  A many-to-many relationship is typically implemented by creating a junction
              table with foreign keys to the two models being related. For instance,  if  you  were  building  a
              syllabus  manager  for  college  students,  the relationship between students and courses would be
              many-to-many. Here is the schema using standard APIs:

              <b>ATTENTION:</b>
                 This is not a field in the sense that there  is  no  column  associated  with  it.  Rather,  it
                 provides a convenient interface for accessing rows of data related via a through model.

              Standard way of declaring a many-to-many relationship (without the use of the <u>ManyToManyField</u>):

                 class Student(Model):
                     name = CharField()

                 class Course(Model):
                     name = CharField()

                 class StudentCourse(Model):
                     student = ForeignKeyField(Student)
                     course = ForeignKeyField(Course)

              To query the courses for a particular student, you would join through the junction table:

                 # List the courses that "Huey" is enrolled in:
                 courses = (Course
                            .select()
                            .join(StudentCourse)
                            .join(Student)
                            .where(Student.name == 'Huey'))
                 for course in courses:
                     print(course.name)

              The  <u>ManyToManyField</u>  is  designed  to  simplify  this  use-case by providing a <u>field-like</u> API for
              querying  and  modifying  data  in  the  junction  table.  Here  is  how  our  code  looks   using
              <u>ManyToManyField</u>:

                 class Student(Model):
                     name = CharField()

                 class Course(Model):
                     name = CharField()
                     students = ManyToManyField(Student, backref='courses')

              <b>NOTE:</b>
                 It does not matter from Peewee's perspective which model the <u>ManyToManyField</u> goes on, since the
                 back-reference  is just the mirror image. In order to write valid Python, though, you will need
                 to add the <b>ManyToManyField</b> on the second model so that the name of the first model  is  in  the
                 scope.

              We still need a junction table to store the relationships between students and courses. This model
              can be accessed by calling the <u>get_through_model()</u> method. This is useful when creating tables.

                 # Create tables for the students, courses, and relationships between
                 # the two.
                 db.create_tables([
                     Student,
                     Course,
                     Course.students.get_through_model()])

              When  accessed  from  a model instance, the <u>ManyToManyField</u> exposes a <u>ModelSelect</u> representing the
              set of related objects.  Let's use the interactive shell to see how all this works:

                 &gt;&gt;&gt; huey = Student.get(Student.name == 'huey')
                 &gt;&gt;&gt; [course.name for course in huey.courses]
                 ['English 101', 'CS 101']

                 &gt;&gt;&gt; engl_101 = Course.get(Course.name == 'English 101')
                 &gt;&gt;&gt; [student.name for student in engl_101.students]
                 ['Huey', 'Mickey', 'Zaizee']

              To add new relationships between objects, you can  either  assign  the  objects  directly  to  the
              <b>ManyToManyField</b> attribute, or call the <u>add()</u> method. The difference between the two is that simply
              assigning  will  clear  out  any  existing  relationships,  whereas  <b>add()</b>  can  preserve existing
              relationships.

                 &gt;&gt;&gt; huey.courses = Course.select().where(Course.name.contains('english'))
                 &gt;&gt;&gt; for course in huey.courses.order_by(Course.name):
                 ...     print(course.name)
                 English 101
                 English 151
                 English 201
                 English 221

                 &gt;&gt;&gt; cs_101 = Course.get(Course.name == 'CS 101')
                 &gt;&gt;&gt; cs_151 = Course.get(Course.name == 'CS 151')
                 &gt;&gt;&gt; huey.courses.add([cs_101, cs_151])
                 &gt;&gt;&gt; [course.name for course in huey.courses.order_by(Course.name)]
                 ['CS 101', 'CS151', 'English 101', 'English 151', 'English 201',
                  'English 221']

              This is quite a few courses, so let's remove the 200-level english courses.   To  remove  objects,
              use the <u>remove()</u> method.

                 &gt;&gt;&gt; huey.courses.remove(Course.select().where(Course.name.contains('2'))
                 2
                 &gt;&gt;&gt; [course.name for course in huey.courses.order_by(Course.name)]
                 ['CS 101', 'CS151', 'English 101', 'English 151']

              To  remove  all  relationships  from  a collection, you can use the <b>clear()</b> method. Let's say that
              English 101 is canceled, so we need to remove all the students from it:

                 &gt;&gt;&gt; engl_101 = Course.get(Course.name == 'English 101')
                 &gt;&gt;&gt; engl_101.students.clear()

              <b>NOTE:</b>
                 For an overview of implementing many-to-many relationships using standard  Peewee  APIs,  check
                 out  the  <u>Implementing</u>  <u>Many</u>  <u>to</u>  <u>Many</u>  section. For all but the most simple cases, you will be
                 better off implementing many-to-many using the standard APIs.

              <b>through_model</b>
                     The <u>Model</u> representing the many-to-many junction table.   Will  be  auto-generated  if  not
                     explicitly declared.

              <b>add(value[,</b> <b>clear_existing=True])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- Either a <u>Model</u> instance, a list of model instances, or a <u>SelectQuery</u>.

                            • <b>clear_existing</b> (<u>bool</u>) -- Whether to remove existing relationships.

                     Associate  <b>value</b> with the current instance. You can pass in a single model instance, a list
                     of model instances, or even a <u>ModelSelect</u>.

                     Example code:

                        # Huey needs to enroll in a bunch of courses, including all
                        # the English classes, and a couple Comp-Sci classes.
                        huey = Student.get(Student.name == 'Huey')

                        # We can add all the objects represented by a query.
                        english_courses = Course.select().where(
                            Course.name.contains('english'))
                        huey.courses.add(english_courses)

                        # We can also add lists of individual objects.
                        cs101 = Course.get(Course.name == 'CS 101')
                        cs151 = Course.get(Course.name == 'CS 151')
                        huey.courses.add([cs101, cs151])

              <b>remove(value)</b>

                     <b>Parameters</b>
                            <b>value</b> -- Either a <u>Model</u> instance, a list of model instances, or a <u>ModelSelect</u>.

                     Disassociate <b>value</b> from the current instance. Like <u>add()</u>, you can pass in a model instance,
                     a list of model instances, or even a <u>ModelSelect</u>.

                     Example code:

                        # Huey is currently enrolled in a lot of english classes
                        # as well as some Comp-Sci. He is changing majors, so we
                        # will remove all his courses.
                        english_courses = Course.select().where(
                            Course.name.contains('english'))
                        huey.courses.remove(english_courses)

                        # Remove the two Comp-Sci classes Huey is enrolled in.
                        cs101 = Course.get(Course.name == 'CS 101')
                        cs151 = Course.get(Course.name == 'CS 151')
                        huey.courses.remove([cs101, cs151])

              <b>clear()</b>
                     Remove all associated objects.

                     Example code:

                        # English 101 is canceled this semester, so remove all
                        # the enrollments.
                        english_101 = Course.get(Course.name == 'English 101')
                        english_101.students.clear()

              <b>get_through_model()</b>
                     Return the <u>Model</u> representing the  many-to-many  junction  table.  This  can  be  specified
                     manually  when  the  field  is  being  instantiated using the <b>through_model</b> parameter. If a
                     <b>through_model</b> is not specified, one will automatically be created.

                     When creating tables for an application that uses  <u>ManyToManyField</u>,  <b>you</b>  <b>must</b>  <b>create</b>  <b>the</b>
                     <b>through</b> <b>table</b> <b>expicitly</b>.

                        # Get a reference to the automatically-created through table.
                        StudentCourseThrough = Course.students.get_through_model()

                        # Create tables for our two models as well as the through model.
                        db.create_tables([
                            Student,
                            Course,
                            StudentCourseThrough])

       <b>class</b> <b>DeferredThroughModel</b>
              Place-holder  for a through-model in cases where, due to a dependency, you cannot declare either a
              model or a many-to-many field without introducing NameErrors.

              Example:

                 class Note(BaseModel):
                     content = TextField()

                 NoteThroughDeferred = DeferredThroughModel()

                 class User(BaseModel):
                     username = TextField()
                     notes = ManyToManyField(Note, through_model=NoteThroughDeferred)

                 # Cannot declare this before "User" since it has a foreign-key to
                 # the User model.
                 class NoteThrough(BaseModel):
                     note = ForeignKeyField(Note)
                     user = ForeignKeyField(User)

                 # Resolve dependencies.
                 NoteThroughDeferred.set_model(NoteThrough)

       <b>class</b> <b>CompositeKey(*field_names)</b>

              <b>Parameters</b>
                     <b>field_names</b> -- Names of fields that comprise the primary key.

              A primary key composed of multiple columns. Unlike the other fields, a composite key is defined in
              the model's <b>Meta</b> class after the fields have been defined. It takes as parameters the string names
              of the fields to use as the primary key:

                 class BlogTagThrough(Model):
                     blog = ForeignKeyField(Blog, backref='tags')
                     tag = ForeignKeyField(Tag, backref='blogs')

                     class Meta:
                         primary_key = CompositeKey('blog', 'tag')

   <b>Schema</b> <b>Manager</b>
       <b>class</b> <b>SchemaManager(model[,</b> <b>database=None[,</b> <b>**context_options]])</b>

              <b>Parameters</b>

                     • <b>model</b> (<u>Model</u>) -- Model class.

                     • <b>database</b> (<u>Database</u>) -- If unspecified defaults to model._meta.database.

              Provides methods for managing the creation and deletion of tables and indexes for the given model.

              <b>create_table([safe=True[,</b> <b>**options]])</b>

                     <b>Parameters</b>

                            • <b>safe</b> (<u>bool</u>) -- Specify IF NOT EXISTS clause.

                            • <b>options</b> -- Arbitrary options.

                     Execute CREATE TABLE query for the given model.

              <b>drop_table([safe=True[,</b> <b>drop_sequences=True[,</b> <b>**options]]])</b>

                     <b>Parameters</b>

                            • <b>safe</b> (<u>bool</u>) -- Specify IF EXISTS clause.

                            • <b>drop_sequences</b> (<u>bool</u>) -- Drop any sequences associated with  the  columns  on  the
                              table (postgres only).

                            • <b>options</b> -- Arbitrary options.

                     Execute DROP TABLE query for the given model.

              <b>truncate_table([restart_identity=False[,</b> <b>cascade=False]])</b>

                     <b>Parameters</b>

                            • <b>restart_identity</b> (<u>bool</u>) -- Restart the id sequence (postgres-only).

                            • <b>cascade</b> (<u>bool</u>) -- Truncate related tables as well (postgres-only).

                     Execute  TRUNCATE  TABLE  for  the  given  model. If the database is Sqlite, which does not
                     support TRUNCATE, then an equivalent DELETE query will be executed.

              <b>create_indexes([safe=True])</b>

                     <b>Parameters</b>
                            <b>safe</b> (<u>bool</u>) -- Specify IF NOT EXISTS clause.

                     Execute CREATE INDEX queries for the indexes defined for the model.

              <b>drop_indexes([safe=True])</b>

                     <b>Parameters</b>
                            <b>safe</b> (<u>bool</u>) -- Specify IF EXISTS clause.

                     Execute DROP INDEX queries for the indexes defined for the model.

              <b>create_sequence(field)</b>

                     <b>Parameters</b>
                            <b>field</b> (<u>Field</u>) -- Field instance which specifies a sequence.

                     Create sequence for the given <u>Field</u>.

              <b>drop_sequence(field)</b>

                     <b>Parameters</b>
                            <b>field</b> (<u>Field</u>) -- Field instance which specifies a sequence.

                     Drop sequence for the given <u>Field</u>.

              <b>create_foreign_key(field)</b>

                     <b>Parameters</b>
                            <b>field</b> (<u>ForeignKeyField</u>) -- Foreign-key field constraint to add.

                     Add a foreign-key constraint for the given field. This method should not  be  necessary  in
                     most cases, as foreign-key constraints are created as part of table creation. The exception
                     is  when you are creating a circular foreign-key relationship using <u>DeferredForeignKey</u>.  In
                     those cases, it is necessary to first create the tables, then add the  constraint  for  the
                     deferred foreign-key:

                        class Language(Model):
                            name = TextField()
                            selected_snippet = DeferredForeignKey('Snippet')

                        class Snippet(Model):
                            code = TextField()
                            language = ForeignKeyField(Language, backref='snippets')

                        # Creates both tables but does not create the constraint for the
                        # Language.selected_snippet foreign key (because of the circular
                        # dependency).
                        db.create_tables([Language, Snippet])

                        # Explicitly create the constraint:
                        Language._schema.create_foreign_key(Language.selected_snippet)

                     For more information, see documentation on <u>Circular</u> <u>foreign</u> <u>key</u> <u>dependencies</u>.

                     <b>WARNING:</b>
                        Because  SQLite  has limited support for altering existing tables, it is not possible to
                        add a foreign-key constraint to an existing SQLite table.

              <b>create_all([safe=True[,</b> <b>**table_options]])</b>

                     <b>Parameters</b>
                            <b>safe</b> (<u>bool</u>) -- Whether to specify IF NOT EXISTS.

                     Create sequence(s), index(es) and table for the model.

              <b>drop_all([safe=True[,</b> <b>drop_sequences=True[,</b> <b>**options]]])</b>

                     <b>Parameters</b>

                            • <b>safe</b> (<u>bool</u>) -- Whether to specify IF EXISTS.

                            • <b>drop_sequences</b> (<u>bool</u>) -- Drop any sequences associated with  the  columns  on  the
                              table (postgres only).

                            • <b>options</b> -- Arbitrary options.

                     Drop table for the model and associated indexes.

   <b>Model</b>
       <b>class</b> <b>Metadata(model[,</b> <b>database=None[,</b> <b>table_name=None[,</b> <b>indexes=None[,</b> <b>primary_key=None[,</b>
       <b>constraints=None[,</b> <b>schema=None[,</b> <b>only_save_dirty=False[,</b> <b>depends_on=None[,</b> <b>options=None[,</b>
       <b>without_rowid=False[,</b> <b>strict_tables=False[,</b> <b>**kwargs]]]]]]]]]]]]])</b>

              <b>Parameters</b>

                     • <b>model</b> (<u>Model</u>) -- Model class.

                     • <b>database</b> (<u>Database</u>) -- database model is bound to.

                     • <b>table_name</b> (<u>str</u>) -- Specify table name for model.

                     • <b>indexes</b> (<u>list</u>) -- List of <u>ModelIndex</u> objects.

                     • <b>primary_key</b>  --  Primary key for model (only specified if this is a <u>CompositeKey</u> or <b>False</b>
                       for no primary key.

                     • <b>constraints</b> (<u>list</u>) -- List of table constraints.

                     • <b>schema</b> (<u>str</u>) -- Schema table exists in.

                     • <b>only_save_dirty</b> (<u>bool</u>) -- When <u>save()</u> is called, only save the  fields  which  have  been
                       modified.

                     • <b>options</b> (<u>dict</u>) -- Arbitrary options for the model.

                     • <b>without_rowid</b> (<u>bool</u>) -- Specify WITHOUT ROWID (sqlite only).

                     • <b>strict_tables</b> (<u>bool</u>) -- Specify STRICT (sqlite only, requires 3.37+).

                     • <b>kwargs</b> -- Arbitrary setting attributes and values.

              Store metadata for a <u>Model</u>.

              This  class  should  not  be  instantiated directly, but is instantiated using the attributes of a
              <u>Model</u> class' inner <b>Meta</b> class. Metadata attributes are then available on <b>Model._meta</b>.

              <b>table</b>  Return a reference to the underlying <u>Table</u> object.

              <b>model_graph([refs=True[,</b> <b>backrefs=True[,</b> <b>depth_first=True]]])</b>

                     <b>Parameters</b>

                            • <b>refs</b> (<u>bool</u>) -- Follow foreign-key references.

                            • <b>backrefs</b> (<u>bool</u>) -- Follow foreign-key back-references.

                            • <b>depth_first</b> (<u>bool</u>) -- Do a depth-first search (<b>False</b> for breadth-first).

                     Traverse the model graph and return a list of 3-tuples, consisting of <b>(foreign</b>  <b>key</b>  <b>field,</b>
                     <b>model</b> <b>class,</b> <b>is_backref)</b>.

              <b>set_database(database)</b>

                     <b>Parameters</b>
                            <b>database</b> (<u>Database</u>) -- database object to bind Model to.

                     Bind the model class to the given <u>Database</u> instance.

                     <b>WARNING:</b>
                        This  API  should  not need to be used. Instead, to change a <u>Model</u> database at run-time,
                        use one of the following:

                        • <u>Model.bind()</u>

                        • <u>Model.bind_ctx()</u> (bind for scope of a context manager).

                        • <u>Database.bind()</u>

                        • <u>Database.bind_ctx()</u>

              <b>set_table_name(table_name)</b>

                     <b>Parameters</b>
                            <b>table_name</b> (<u>str</u>) -- table name to bind Model to.

                     Bind the model class to the given table name at run-time.

       <b>class</b> <b>SubclassAwareMetadata</b>
              Metadata subclass that tracks <u>Model</u> subclasses. Useful for when you need to track all models in  a
              project.

              Example:

                 from peewee import SubclassAwareMetadata

                 class Base(Model):
                     class Meta:
                         database = db
                         model_metadata_class = SubclassAwareMetadata

                 # Create 3 model classes that inherit from Base.
                 class A(Base): pass
                 class B(Base): pass
                 class C(Base): pass

                 # Now let's make a helper for changing the `schema` for each Model.
                 def change_schema(schema):
                     def <a href="../manmodel/_update.model.html">_update</a>(model):
                         model._meta.schema = schema
                     return _update

                 # Set all models to use "schema1", e.g. "schema1.a", "schema1.b", etc.
                 # Will apply the function to every subclass of Base.
                 Base._meta.map_models(change_schema('schema1'))

                 # Set all models to use "schema2", e.g. "schema2.a", "schema2.b", etc.
                 Base._meta.map_models(change_schema('schema2'))

              <b>map_models(fn)</b>
                     Apply a function to all subclasses.

       <b>class</b> <b>Model(**kwargs)</b>

              <b>Parameters</b>
                     <b>kwargs</b> -- Mapping of field-name to value to initialize model with.

              Model  class  provides  a  high-level  abstraction  for working with database tables. Models are a
              one-to-one mapping with a database table (or a table-like object, such as a view).  Subclasses  of
              <b>Model</b>  declare  any  number  of  <u>Field</u>  instances  as class attributes. These fields correspond to
              columns on the table.

              Table-level operations, such as <u>select()</u>, <u>update()</u>,  <u>insert()</u>  and  <u>delete()</u>  are  implemented  as
              classmethods.  Row-level  operations,  such  as  <u>save()</u>  and  <u>delete_instance()</u> are implemented as
              instancemethods.

              Example:

                 db = SqliteDatabase(':memory:')

                 class User(Model):
                     username = TextField()
                     join_date = DateTimeField(default=datetime.datetime.now)
                     is_admin = BooleanField(default=False)

                 admin = User(username='admin', is_admin=True)
                 admin.save()

              <b>classmethod</b> <b>alias([alias=None])</b>

                     <b>Parameters</b>
                            <b>alias</b> (<u>str</u>) -- Optional name for alias.

                     <b>Returns</b>
                            <u>ModelAlias</u> instance.

                     Create an alias to the model-class. Model aliases allow you to  reference  the  same  <u>Model</u>
                     multiple times in a query, for example when doing a self-join or sub-query.

                     Example:

                        Parent = Category.alias()
                        sq = (Category
                              .select(Category, Parent)
                              .join(Parent, on=(Category.parent == Parent.id))
                              .where(Parent.name == 'parent category'))

              <b>classmethod</b> <b>select(*fields)</b>

                     <b>Parameters</b>
                            <b>fields</b>  -- A list of model classes, field instances, functions or expressions. If no
                            arguments are provided, all columns for the given model will be selected by default.

                     <b>Returns</b>
                            <u>ModelSelect</u> query.

                     Create a SELECT query. If no fields are explicitly provided,  the  query  will  by  default
                     SELECT  all the fields defined on the model, unless you are using the query as a sub-query,
                     in which case only the primary key will be selected by default.

                     Example of selecting all columns:

                        query = User.select().where(User.active == True).order_by(User.username)

                     Example of selecting all columns on <u>Tweet</u> and the parent model, <u>User</u>. When the <b>user</b> foreign
                     key is accessed on a <u>Tweet</u> instance no additional query will be needed (see  <u>N+1</u>  for  more
                     details):

                        query = (Tweet
                                 .select(Tweet, User)
                                 .join(User)
                                 .order_by(Tweet.created_date.desc()))

                        for tweet in query:
                            print(tweet.user.username, '-&gt;', tweet.content)

                     Example of subquery only selecting the primary key:

                        inactive_users = User.select().where(User.active == False)

                        # Here, instead of defaulting to all columns, Peewee will default
                        # to only selecting the primary key.
                        Tweet.delete().where(Tweet.user.in_(inactive_users)).execute()

              <b>classmethod</b> <b>update([__data=None[,</b> <b>**update]])</b>

                     <b>Parameters</b>

                            • <b>__data</b> (<u>dict</u>) -- <b>dict</b> of fields to values.

                            • <b>update</b> -- Field-name to value mapping.

                     Create an UPDATE query.

                     Example showing users being marked inactive if their registration has expired:

                        q = (User
                             .update({User.active: False})
                             .where(User.registration_expired == True))
                        q.execute()  # Execute the query, returning number of rows updated.

                     Example showing an atomic update:

                        q = (PageView
                             .update({PageView.count: PageView.count + 1})
                             .where(PageView.url == url))
                        q.execute()  # Execute the query.

                     <b>NOTE:</b>
                        When an update query is executed, the number of rows modified will be returned.

              <b>classmethod</b> <b>insert([__data=None[,</b> <b>**insert]])</b>

                     <b>Parameters</b>

                            • <b>__data</b> (<u>dict</u>) -- <b>dict</b> of fields to values to insert.

                            • <b>insert</b> -- Field-name to value mapping.

                     Create an INSERT query.

                     Insert  a  new row into the database. If any fields on the model have default values, these
                     values will be used if the fields are not explicitly set in the <b>insert</b> dictionary.

                     Example showing creation of a new user:

                        q = User.insert(username='admin', active=True, registration_expired=False)
                        q.execute()  # perform the insert.

                     You can also use <u>Field</u> objects as the keys:

                        new_id = User.insert({User.username: 'admin'}).execute()

                     If you have a model with a default value on one of  the  fields,  and  that  field  is  not
                     specified in the <b>insert</b> parameter, the default will be used:

                        class User(Model):
                            username = CharField()
                            active = BooleanField(default=True)

                        # This INSERT query will automatically specify `active=True`:
                        User.insert(username='charlie')

                     <b>NOTE:</b>
                        When  an  insert query is executed on a table with an auto-incrementing primary key, the
                        primary key of the new row will be returned.

              <b>classmethod</b> <b>insert_many(rows[,</b> <b>fields=None])</b>

                     <b>Parameters</b>

                            • <b>rows</b> -- An iterable that yields rows to insert.

                            • <b>fields</b> (<u>list</u>) -- List of fields being inserted.

                     <b>Returns</b>
                            number of rows modified (see note).

                     INSERT multiple rows of data.

                     The <b>rows</b> parameter must be an iterable  that  yields  dictionaries  or  tuples,  where  the
                     ordering of the tuple values corresponds to the fields specified in the <b>fields</b> argument. As
                     with  <u>insert()</u>,  fields  that  are  not  specified in the dictionary will use their default
                     value, if one exists.

                     <b>NOTE:</b>
                        Due to the nature of bulk inserts, each row must contain the same fields. The  following
                        will not work:

                            Person.insert_many([
                                {'first_name': 'Peewee', 'last_name': 'Herman'},
                                {'first_name': 'Huey'},  # Missing "last_name"!
                            ]).execute()

                     Example of inserting multiple Users:

                        data = [
                            ('charlie', True),
                            ('huey', False),
                            ('zaizee', False)]
                        query = User.insert_many(data, fields=[User.username, User.is_admin])
                        query.execute()

                     Equivalent example using dictionaries:

                        data = [
                            {'username': 'charlie', 'is_admin': True},
                            {'username': 'huey', 'is_admin': False},
                            {'username': 'zaizee', 'is_admin': False}]

                        # Insert new rows.
                        User.insert_many(data).execute()

                     Because the <b>rows</b> parameter can be an arbitrary iterable, you can also use a generator:

                        def get_usernames():
                            for username in ['charlie', 'huey', 'peewee']:
                                yield {'username': username}
                        User.insert_many(get_usernames()).execute()

                     <b>WARNING:</b>
                        If  you  are  using  SQLite, your SQLite library must be version 3.7.11 or newer to take
                        advantage of bulk inserts.

                     <b>NOTE:</b>
                        SQLite has a default limit of bound variables per statement. This limit can be  modified
                        at  compile-time  or  at  run-time, <b>but</b> if modifying at run-time, you can only specify a
                        <u>lower</u> value than the default limit.

                        For more information, check out the following SQLite documents:

                        • <u>Max</u> <u>variable</u> <u>number</u> <u>limit</u>

                        • <u>Changing</u> <u>run-time</u> <u>limits</u>

                        • <u>SQLite</u> <u>compile-time</u> <u>flags</u>

                     <b>NOTE:</b>
                        The default return value is the number of rows modified. However, when  using  Postgres,
                        Peewee  will  return  a  cursor  by default that yields the primary-keys of the inserted
                        rows. To disable this functionality with Postgres, use <b>as_rowcount()</b>.

              <b>classmethod</b> <b>insert_from(query,</b> <b>fields)</b>

                     <b>Parameters</b>

                            • <b>query</b> (<u>Select</u>) -- SELECT query to use as source of data.

                            • <b>fields</b> -- Fields to insert data into.

                     <b>Returns</b>
                            number of rows modified (see note).

                     INSERT data using a SELECT query as the source. This API should be used for queries of  the
                     form <u>INSERT</u> <u>INTO</u> <u>...</u> <u>SELECT</u> <u>FROM</u> <u>...</u>.

                     Example of inserting data across tables for denormalization purposes:

                        source = (User
                                  .select(User.username, fn.COUNT(Tweet.id))
                                  .join(Tweet, JOIN.LEFT_OUTER)
                                  .group_by(User.username))

                        UserTweetDenorm.insert_from(
                            source,
                            [UserTweetDenorm.username, UserTweetDenorm.num_tweets]).execute()

                     <b>NOTE:</b>
                        The  default  return value is the number of rows modified. However, when using Postgres,
                        Peewee will return a cursor by default that yields  the  primary-keys  of  the  inserted
                        rows. To disable this functionality with Postgres, use <b>as_rowcount()</b>.

              <b>classmethod</b> <b>replace([__data=None[,</b> <b>**insert]])</b>

                     <b>Parameters</b>

                            • <b>__data</b> (<u>dict</u>) -- <b>dict</b> of fields to values to insert.

                            • <b>insert</b> -- Field-name to value mapping.

                     Create an INSERT query that uses REPLACE for conflict-resolution.

                     See <u>Model.insert()</u> for examples.

              <b>classmethod</b> <b>replace_many(rows[,</b> <b>fields=None])</b>

                     <b>Parameters</b>

                            • <b>rows</b> -- An iterable that yields rows to insert.

                            • <b>fields</b> (<u>list</u>) -- List of fields being inserted.

                     INSERT multiple rows of data using REPLACE for conflict-resolution.

                     See <u>Model.insert_many()</u> for examples.

              <b>classmethod</b> <b>raw(sql,</b> <b>*params)</b>

                     <b>Parameters</b>

                            • <b>sql</b> (<u>str</u>) -- SQL query to execute.

                            • <b>params</b> -- Parameters for query.

                     Execute a SQL query directly.

                     Example selecting rows from the User table:

                        q = User.raw('select id, username from users')
                        for user in q:
                            print(user.id, user.username)

                     <b>NOTE:</b>
                        Generally  the  use  of  <b>raw</b>  is  reserved  for  those cases where you can significantly
                        optimize a select query. It is useful for select queries since it will return  instances
                        of the model.

              <b>classmethod</b> <b>delete()</b>
                     Create a DELETE query.

                     Example showing the deletion of all inactive users:

                        q = User.delete().where(User.active == False)
                        q.execute()  # Remove the rows, return number of rows removed.

                     <b>WARNING:</b>
                        This  method  performs  a  delete  on the <u>entire</u> <u>table</u>. To delete a single instance, see
                        <u>Model.delete_instance()</u>.

              <b>classmethod</b> <b>create(**query)</b>

                     <b>Parameters</b>
                            <b>query</b> -- Mapping of field-name to value.

                     INSERT new row into table and return corresponding model instance.

                     Example showing the creation of a user (a row will be added to the database):

                        user = User.create(username='admin', password='test')

                     <b>NOTE:</b>
                        The create() method is a shorthand for instantiate-then-save.

              <b>classmethod</b> <b>bulk_create(model_list[,</b> <b>batch_size=None])</b>

                     <b>Parameters</b>

                            • <b>model_list</b> (<u>iterable</u>) -- a list or other iterable of unsaved <u>Model</u> instances.

                            • <b>batch_size</b> (<u>int</u>) -- number of rows to batch per insert. If unspecified, all models
                              will be inserted in a single query.

                     <b>Returns</b>
                            no return value.

                     Efficiently  INSERT  multiple  unsaved  model  instances   into   the   database.    Unlike
                     <u>insert_many()</u>,  which  accepts  row  data  as  a list of either dictionaries or lists, this
                     method accepts a list of unsaved model instances.

                     Example:

                        # List of 10 unsaved users.
                        user_list = [User(username='u%s' % i) for i in <a href="../man10/range.10.html">range</a>(10)]

                        # All 10 users are inserted in a single query.
                        User.bulk_create(user_list)

                     Batches:

                        user_list = [User(username='u%s' % i) for i in <a href="../man10/range.10.html">range</a>(10)]

                        with database.atomic():
                            # Will execute 4 INSERT queries (3 batches of 3, 1 batch of 1).
                            User.bulk_create(user_list, batch_size=3)

                     <b>WARNING:</b>

                        • The primary-key value for the newly-created models will only be set if you  are  using
                          Postgresql (which supports the <b>RETURNING</b> clause).

                        • SQLite  generally  has  a  limit of bound parameters for a query, so the maximum batch
                          size should be param-limit / number-of-fields.  This limit is typically 999 for Sqlite
                          &lt; 3.32.0, and 32766 for newer versions.

                        • When a batch-size is provided it is <b>strongly</b> <b>recommended</b> that you wrap the call  in  a
                          transaction  or  savepoint  using  <u>Database.atomic()</u>.  Otherwise  an  error in a batch
                          mid-way through could leave the database in an inconsistent state.

              <b>classmethod</b> <b>bulk_update(model_list,</b> <b>fields[,</b> <b>batch_size=None])</b>

                     <b>Parameters</b>

                            • <b>model_list</b> (<u>iterable</u>) -- a list or other iterable of <u>Model</u> instances.

                            • <b>fields</b> (<u>list</u>) -- list of fields to update.

                            • <b>batch_size</b> (<u>int</u>) -- number of rows to batch per insert. If unspecified, all models
                              will be inserted in a single query.

                     <b>Returns</b>
                            total number of rows updated.

                     Efficiently UPDATE multiple model instances.

                     Example:

                        # First, create 3 users.
                        u1, u2, u3 = [User.create(username='u%s' % i) for i in (1, 2, 3)]

                        # Now let's modify their usernames.
                        u1.username = 'u1-x'
                        u2.username = 'u2-y'
                        u3.username = 'u3-z'

                        # Update all three rows using a single UPDATE query.
                        User.bulk_update([u1, u2, u3], fields=[User.username])

                     This will result in executing the following SQL:

                        UPDATE "users" SET "username" = CASE "users"."id"
                            WHEN 1 THEN "u1-x"
                            WHEN 2 THEN "u2-y"
                            WHEN 3 THEN "u3-z" END
                        WHERE "users"."id" IN (1, 2, 3);

                     If you have a large number of objects to  update,  it  is  strongly  recommended  that  you
                     specify a <b>batch_size</b> and wrap the operation in a transaction:

                        with database.atomic():
                            User.bulk_update(user_list, fields=['username'], batch_size=50)

                     <b>WARNING:</b>

                        • SQLite generally has a limit of bound parameters for a query.  This limit is typically
                          999 for Sqlite &lt; 3.32.0, and 32766 for newer versions.

                        • When  a  batch-size is provided it is <b>strongly</b> <b>recommended</b> that you wrap the call in a
                          transaction or savepoint using  <u>Database.atomic()</u>.  Otherwise  an  error  in  a  batch
                          mid-way through could leave the database in an inconsistent state.

              <b>classmethod</b> <b>get(*query,</b> <b>**filters)</b>

                     <b>Parameters</b>

                            • <b>query</b> -- Zero or more <u>Expression</u> objects.

                            • <b>filters</b> -- Mapping of field-name to value for Django-style filter.

                     <b>Raises</b> <b>DoesNotExist</b>

                     <b>Returns</b>
                            Model instance matching the specified filters.

                     Retrieve  a  single  model  instance matching the given filters. If no model is returned, a
                     <b>DoesNotExist</b> is raised.

                        user = User.get(User.username == username, User.active == True)

                     This method is also exposed via the <u>SelectQuery</u>, though it takes no parameters:

                        active = User.select().where(User.active == True)
                        try:
                            user = active.where(
                                (User.username == username) &amp;
                                (User.active == True)
                            ).get()
                        except User.DoesNotExist:
                            user = None

                     <b>NOTE:</b>
                        The <u>get()</u> method is shorthand for selecting with a limit of 1. It has the added behavior
                        of raising an exception when no matching row is found. If more than one  row  is  found,
                        the first row returned by the database cursor will be used.

              <b>classmethod</b> <b>get_or_none(*query,</b> <b>**filters)</b>
                     Identical to <u>Model.get()</u> but returns <b>None</b> if no model matches the given filters.

              <b>classmethod</b> <b>get_by_id(pk)</b>

                     <b>Parameters</b>
                            <b>pk</b> -- Primary-key value.

                     Short-hand   for  calling  <u>Model.get()</u>  specifying  a  lookup  by  primary  key.  Raises  a
                     <b>DoesNotExist</b> if instance with the given primary key value does not exist.

                     Example:

                        user = <a href="../man1/User.get_by_id.1.html">User.get_by_id</a>(1)  # Returns user with id = 1.

              <b>classmethod</b> <b>set_by_id(key,</b> <b>value)</b>

                     <b>Parameters</b>

                            • <b>key</b> -- Primary-key value.

                            • <b>value</b> (<u>dict</u>) -- Mapping of field to value to update.

                     Short-hand for updating the data with the given primary-key. If  no  row  exists  with  the
                     given primary key, no exception will be raised.

                     Example:

                        # Set "is_admin" to True on user with id=3.
                        User.set_by_id(3, {'is_admin': True})

              <b>classmethod</b> <b>delete_by_id(pk)</b>

                     <b>Parameters</b>
                            <b>pk</b> -- Primary-key value.

                     Short-hand for deleting the row with the given primary-key. If no row exists with the given
                     primary key, no exception will be raised.

              <b>classmethod</b> <b>get_or_create(**kwargs)</b>

                     <b>Parameters</b>

                            • <b>kwargs</b> -- Mapping of field-name to value.

                            • <b>defaults</b> -- Default values to use if creating a new row.

                     <b>Returns</b>
                            Tuple of <u>Model</u> instance and boolean indicating if a new object was created.

                     Attempt  to  get  the row matching the given filters. If no matching row is found, create a
                     new row.

                     <b>WARNING:</b>
                        Race-conditions are possible when using this method.

                     Example <b>without</b> <b>get_or_create</b>:

                        # Without `get_or_create`, we might write:
                        try:
                            person = Person.get(
                                (Person.first_name == 'John') &amp;
                                (Person.last_name == 'Lennon'))
                        except Person.DoesNotExist:
                            person = Person.create(
                                first_name='John',
                                last_name='Lennon',
                                birthday=datetime.date(1940, 10, 9))

                     Equivalent code using <b>get_or_create</b>:

                        person, created = Person.get_or_create(
                            first_name='John',
                            last_name='Lennon',
                            defaults={'birthday': datetime.date(1940, 10, 9)})

              <b>classmethod</b> <b>filter(*dq_nodes,</b> <b>**filters)</b>

                     <b>Parameters</b>

                            • <b>dq_nodes</b> -- Zero or more <u>DQ</u> objects.

                            • <b>filters</b> -- Django-style filters.

                     <b>Returns</b>
                            <u>ModelSelect</u> query.

              <b>get_id()</b>

                     <b>Returns</b>
                            The primary-key of the model instance.

              <b>save([force_insert=False[,</b> <b>only=None]])</b>

                     <b>Parameters</b>

                            • <b>force_insert</b> (<u>bool</u>) -- Force INSERT query.

                            • <b>only</b> (<u>list</u>) -- Only save the given <u>Field</u> instances.

                     <b>Returns</b>
                            Number of rows modified.

                     Save the data in the model instance. By default, the presence of a primary-key  value  will
                     cause an UPDATE query to be executed.

                     Example showing saving a model instance:

                        user = User()
                        user.username = 'some-user'  # does not touch the database
                        user.save()  # change is persisted to the db

              <b>dirty_fields</b>
                     Return list of fields that have been modified.

                     <b>Return</b> <b>type</b>
                            list

                     <b>NOTE:</b>
                        If     you    just    want    to    persist    modified    fields,    you    can    call
                        <b>model.save(only=model.dirty_fields)</b>.

                        If you <b>always</b> want to only save a model's dirty fields, you  can  use  the  Meta  option
                        <b>only_save_dirty</b>  <b>=</b> <b>True</b>. Then, any time you call <u>Model.save()</u>, by default only the dirty
                        fields will be saved, e.g.

                            class Person(Model):
                                first_name = CharField()
                                last_name = CharField()
                                dob = DateField()

                                class Meta:
                                    database = db
                                    only_save_dirty = True

                     <b>WARNING:</b>
                        Peewee determines whether a field is "dirty" by observing when the  field  attribute  is
                        set  on  a  model  instance.  If  the  field contains a value that is mutable, such as a
                        dictionary instance, and that dictionary is then modified, Peewee will  not  notice  the
                        change.

              <b>is_dirty()</b>
                     Return boolean indicating whether any fields were manually set.

              <b>delete_instance([recursive=False[,</b> <b>delete_nullable=False]])</b>

                     <b>Parameters</b>

                            • <b>recursive</b> (<u>bool</u>) -- Delete related models.

                            • <b>delete_nullable</b>  (<u>bool</u>)  -- Delete related models that have a null foreign key. If
                              <b>False</b> nullable relations will be set to NULL.

                     Delete the given instance.  Any foreign keys set to  cascade  on  delete  will  be  deleted
                     automatically.   For  more programmatic control, you can specify <b>recursive=True</b>, which will
                     delete any non-nullable related models (those that <u>are</u> nullable will be set to  NULL).   If
                     you  wish  to  delete  all  dependencies  regardless  of  whether  they  are  nullable, set
                     <b>delete_nullable=True</b>.

                     example:

                        some_obj.delete_instance()  # it is gone forever

              <b>classmethod</b> <b>bind(database[,</b> <b>bind_refs=True[,</b> <b>bind_backrefs=True]])</b>

                     <b>Parameters</b>

                            • <b>database</b> (<u>Database</u>) -- database to bind to.

                            • <b>bind_refs</b> (<u>bool</u>) -- Bind related models.

                            • <b>bind_backrefs</b> (<u>bool</u>) -- Bind back-reference related models.

                     Bind the model (and specified relations) to the given database.

                     See also: <u>Database.bind()</u>.

              <b>classmethod</b> <b>bind_ctx(database[,</b> <b>bind_refs=True[,</b> <b>bind_backrefs=True]])</b>
                     Like <u>bind()</u>, but returns a context manager that only binds the models for the  duration  of
                     the wrapped block.

                     See also: <u>Database.bind_ctx()</u>.

              <b>classmethod</b> <b>table_exists()</b>

                     <b>Returns</b>
                            boolean indicating whether the table exists.

              <b>classmethod</b> <b>create_table([safe=True[,</b> <b>**options]])</b>

                     <b>Parameters</b>
                            <b>safe</b>  (<u>bool</u>) -- If set to <b>True</b>, the create table query will include an <b>IF</b> <b>NOT</b> <b>EXISTS</b>
                            clause.

                     Create the model table, indexes, constraints and sequences.

                     Example:

                        with database:
                            SomeModel.create_table()  # Execute the create table query.

              <b>classmethod</b> <b>drop_table([safe=True[,</b> <b>**options]])</b>

                     <b>Parameters</b>
                            <b>safe</b> (<u>bool</u>) -- If set to <b>True</b>, the create table query  will  include  an  <b>IF</b>  <b>EXISTS</b>
                            clause.

                     Drop the model table.

              <b>truncate_table([restart_identity=False[,</b> <b>cascade=False]])</b>

                     <b>Parameters</b>

                            • <b>restart_identity</b> (<u>bool</u>) -- Restart the id sequence (postgres-only).

                            • <b>cascade</b> (<u>bool</u>) -- Truncate related tables as well (postgres-only).

                     Truncate (delete all rows) for the model.

              <b>classmethod</b> <b>index(*fields[,</b> <b>unique=False[,</b> <b>safe=True[,</b> <b>where=None[,</b> <b>using=None[,</b> <b>name=None]]]]])</b>

                     <b>Parameters</b>

                            • <b>fields</b> -- Fields to index.

                            • <b>unique</b> (<u>bool</u>) -- Whether index is UNIQUE.

                            • <b>safe</b> (<u>bool</u>) -- Whether to add IF NOT EXISTS clause.

                            • <b>where</b> (<u>Expression</u>) -- Optional WHERE clause for index.

                            • <b>using</b> (<u>str</u>) -- Index algorithm.

                            • <b>name</b> (<u>str</u>) -- Optional index name.

                     Expressive  method for declaring an index on a model. Wraps the declaration of a <u>ModelIndex</u>
                     instance.

                     Examples:

                        class Article(Model):
                            name = TextField()
                            timestamp = TimestampField()
                            status = IntegerField()
                            flags = BitField()

                            is_sticky = <a href="../man1/flags.flag.1.html">flags.flag</a>(1)
                            is_favorite = <a href="../man2/flags.flag.2.html">flags.flag</a>(2)

                        # CREATE INDEX ... ON "article" ("name", "timestamp" DESC)
                        idx = Article.index(Article.name, Article.timestamp.desc())

                        # Be sure to add the index to the model:
                        Article.add_index(idx)

                        # CREATE UNIQUE INDEX ... ON "article" ("timestamp" DESC, "flags" &amp; 2)
                        # WHERE ("status" = 1)
                        idx = (Article
                               .index(Article.timestamp.desc(),
                                      <a href="../man2/Article.flags.bin_and.2.html">Article.flags.bin_and</a>(2),
                                      unique=True)
                               .where(Article.status == 1))

                        # Add index to model:
                        Article.add_index(idx)

              <b>classmethod</b> <b>add_index(*args,</b> <b>**kwargs)</b>

                     <b>Parameters</b>

                            • <b>args</b> -- a <u>ModelIndex</u> instance, Field(s) to index, or a <u>SQL</u> instance that  contains
                              the SQL for creating the index.

                            • <b>kwargs</b> -- Keyword arguments passed to <u>ModelIndex</u> constructor.

                     Add an index to the model's definition.

                     <b>NOTE:</b>
                        This  method  does  not  actually create the index in the database.  Rather, it adds the
                        index definition to the model's metadata, so that a subsequent  call  to  <u>create_table()</u>
                        will create the new index (along with the table).

                     Examples:

                        class Article(Model):
                            name = TextField()
                            timestamp = TimestampField()
                            status = IntegerField()
                            flags = BitField()

                            is_sticky = <a href="../man1/flags.flag.1.html">flags.flag</a>(1)
                            is_favorite = <a href="../man2/flags.flag.2.html">flags.flag</a>(2)

                        # CREATE INDEX ... ON "article" ("name", "timestamp") WHERE "status" = 1
                        idx = Article.index(Article.name, Article.timestamp).where(Article.status == 1)
                        Article.add_index(idx)

                        # CREATE UNIQUE INDEX ... ON "article" ("timestamp" DESC, "flags" &amp; 2)
                        ts_flags_idx = Article.index(
                            Article.timestamp.desc(),
                            <a href="../man2/Article.flags.bin_and.2.html">Article.flags.bin_and</a>(2),
                            unique=True)
                        Article.add_index(ts_flags_idx)

                        # You can also specify a list of fields and use the same keyword
                        # arguments that the ModelIndex constructor accepts:
                        Article.add_index(
                            Article.name,
                            Article.timestamp.desc(),
                            where=(Article.status == 1))

                        # Or even specify a SQL query directly:
                        Article.add_index(SQL('CREATE INDEX ...'))

              <b>dependencies([search_nullable=False])</b>

                     <b>Parameters</b>
                            <b>search_nullable</b> (<u>bool</u>) -- Search models related via a nullable foreign key

                     <b>Return</b> <b>type</b>
                            Generator expression yielding queries and foreign key fields.

                     Generate  a  list of queries of dependent models. Yields a 2-tuple containing the query and
                     corresponding foreign key field.  Useful for searching dependencies of a model, i.e. things
                     that would be orphaned in the event of a delete.

              <b>__iter__()</b>

                     <b>Returns</b>
                            a <u>ModelSelect</u> for the given class.

                     Convenience function for iterating over all instances of a model.

                     Example:

                        Setting.insert_many([
                            {'key': 'host', 'value': '192.168.1.2'},
                            {'key': 'port': 'value': '1337'},
                            {'key': 'user': 'value': 'nuggie'}]).execute()

                        # Load settings from db into dict.
                        settings = {setting.key: setting.value for setting in Setting}

              <b>__len__()</b>

                     <b>Returns</b>
                            Count of rows in table.

                     Example:

                        n_accounts = len(Account)

                        # Is equivalent to:
                        n_accounts = Account.select().count()

       <b>class</b> <b>ModelAlias(model[,</b> <b>alias=None])</b>

              <b>Parameters</b>

                     • <b>model</b> (<u>Model</u>) -- Model class to reference.

                     • <b>alias</b> (<u>str</u>) -- (optional) name for alias.

              Provide a separate reference to a model in a query.

       <b>class</b> <b>ModelSelect(model,</b> <b>fields_or_models)</b>

              <b>Parameters</b>

                     • <b>model</b> (<u>Model</u>) -- Model class to select.

                     • <b>fields_or_models</b> -- List of fields or model classes to select.

              Model-specific implementation of SELECT query.

              <b>switch([ctx=None])</b>

                     <b>Parameters</b>
                            <b>ctx</b> -- A <u>Model</u>, <u>ModelAlias</u>, subquery, or other object that was joined-on.

                     Switch the <u>join</u> <u>context</u> - the source which  subsequent  calls  to  <u>join()</u>  will  be  joined
                     against. Used for specifying multiple joins against a single table.

                     If the <b>ctx</b> is not given, then the query's model will be used.

                     The following example selects from tweet and joins on both user and tweet-flag:

                        sq = Tweet.select().join(User).switch(Tweet).join(TweetFlag)

                        # Equivalent (since Tweet is the query's model)
                        sq = Tweet.select().join(User).switch().join(TweetFlag)

              <b>objects([constructor=None])</b>

                     <b>Parameters</b>
                            <b>constructor</b> -- Constructor (defaults to returning model instances)

                     Return  result rows as objects created using the given constructor. The default behavior is
                     to create model instances.

                     <b>NOTE:</b>
                        This method can be used, when selecting field data from multiple sources/models, to make
                        all data available as attributes on the model being queried (as opposed to  constructing
                        the  graph of joined model instances). For very complex queries this can have a positive
                        performance impact, especially iterating large result sets.

                        Similarly, you  can  use  <u>dicts()</u>,  <u>tuples()</u>  or  <u>namedtuples()</u>  to  achieve  even  more
                        performance.

              <b>join(dest[,</b> <b>join_type='INNER'[,</b> <b>on=None[,</b> <b>src=None[,</b> <b>attr=None]]]])</b>

                     <b>Parameters</b>

                            • <b>dest</b> -- A <u>Model</u>, <u>ModelAlias</u>, <u>Select</u> query, or other object to join to.

                            • <b>join_type</b> (<u>str</u>) -- Join type, defaults to INNER.

                            • <b>on</b> -- Join predicate or a <u>ForeignKeyField</u> to join on.

                            • <b>src</b>  --  Explicitly  specify  the  source  of  the join. If not specified then the
                              current <u>join</u> <u>context</u> will be used.

                            • <b>attr</b> (<u>str</u>) -- Attribute to use when projecting columns from the joined model.

                     Join with another table-like object.

                     Join type may be one of:

                     • <b>JOIN.INNER</b>

                     • <b>JOIN.LEFT_OUTER</b>

                     • <b>JOIN.RIGHT_OUTER</b>

                     • <b>JOIN.FULL</b>

                     • <b>JOIN.FULL_OUTER</b>

                     • <b>JOIN.CROSS</b>

                     Example selecting tweets and joining on user in order to restrict to only those tweets made
                     by "admin" users:

                        sq = Tweet.select().join(User).where(User.is_admin == True)

                     Example selecting users and joining on a particular foreign key field.  See the <u>example</u> <u>app</u>
                     for a real-life usage:

                        sq = User.select().join(Relationship, on=Relationship.to_user)

                     For an in-depth discussion of foreign-keys, joins and relationships between  models,  refer
                     to <u>Relationships</u> <u>and</u> <u>Joins</u>.

              <b>join_from(src,</b> <b>dest[,</b> <b>join_type='INNER'[,</b> <b>on=None[,</b> <b>attr=None]]])</b>

                     <b>Parameters</b>

                            • <b>src</b> -- Source for join.

                            • <b>dest</b> -- Table to join to.

                     Use  same  parameter  order  as the non-model-specific <u>join()</u>. Bypasses the <u>join</u> <u>context</u> by
                     requiring the join source to be specified.

              <b>filter(*args,</b> <b>**kwargs)</b>

                     <b>Parameters</b>

                            • <b>args</b> -- Zero or more <u>DQ</u> objects.

                            • <b>kwargs</b> -- Django-style keyword-argument filters.

                     Use Django-style filters to express a WHERE clause.  Joins  can  be  followed  by  chaining
                     foreign-key fields. The supported operations are:

                     • <b>eq</b> - equals

                     • <b>ne</b> - not equals

                     • <b>lt</b>, <b>lte</b> - less-than, less-than or equal-to

                     • <b>gt</b>, <b>gte</b> - greater-than, greater-than or equal-to

                     • <b>in</b> - IN set of values

                     • <b>is</b> - IS (e.g. IS NULL).

                     • <b>like</b>, <b>ilike</b> - LIKE and ILIKE (case-insensitive)

                     • <b>regexp</b> - regular expression match

                     Examples:

                        # Get all tweets by user with username="peewee".
                        q = Tweet.filter(user__username='peewee')

                        # Get all posts that are draft or published, and written after 2023.
                        q = Post.filter(
                            (DQ(status='draft') | DQ(status='published')),
                            timestamp__gte=datetime.date(2023, 1, 1))

              <b>prefetch(*subqueries[,</b> <b>prefetch_type=PREFETCH_TYPE.WHERE])</b>

                     <b>Parameters</b>

                            • <b>subqueries</b> -- A list of <u>Model</u> classes or select queries to prefetch.

                            • <b>prefetch_type</b> -- Query type to use for the subqueries.

                     <b>Returns</b>
                            a list of models with selected relations prefetched.

                     Execute the query, prefetching the given additional resources.

                     Prefetch type may be one of:

                     • <b>PREFETCH_TYPE.WHERE</b>

                     • <b>PREFETCH_TYPE.JOIN</b>

                     See also <u>prefetch()</u> standalone function.

                     Example:

                        # Fetch all Users and prefetch their associated tweets.
                        query = User.select().prefetch(Tweet)
                        for user in query:
                            print(user.username)
                            for tweet in user.tweets:
                                print('  *', tweet.content)

                     <b>NOTE:</b>
                        Because <b>prefetch</b> must reconstruct a graph of models, it is necessary to be sure that the
                        foreign-key/primary-key  of any related models are selected, so that the related objects
                        can be mapped correctly.

       <b>prefetch(sq,</b> <b>*subqueries[,</b> <b>prefetch_type=PREFETCH_TYPE.WHERE])</b>

              <b>Parameters</b>

                     • <b>sq</b> -- Query to use as starting-point.

                     • <b>subqueries</b> -- One or more models or <u>ModelSelect</u> queries to eagerly fetch.

                     • <b>prefetch_type</b> -- Query type to use for the subqueries.

              <b>Returns</b>
                     a list of models with selected relations prefetched.

              Eagerly fetch related objects, allowing efficient querying of multiple  tables  when  a  1-to-many
              relationship  exists.  The  prefetch  type changes how the subqueries are constructed which may be
              desirable dependending on the database engine in use.
                 Prefetch type may be one of:

                 • <b>PREFETCH_TYPE.WHERE</b>

                 • <b>PREFETCH_TYPE.JOIN</b>

              For example, it is simple to query a many-to-1 relationship efficiently:

                 query = (Tweet
                          .select(Tweet, User)
                          .join(User))
                 for tweet in query:
                     # Looking up tweet.user.username does not require a query since
                     # the related user's columns were selected.
                     print(tweet.user.username, '-&gt;', tweet.content)

              To efficiently do the inverse, query users and their tweets, you can use prefetch:

                 query = User.select()
                 for user in prefetch(query, Tweet):
                     print(user.username)
                     for tweet in user.tweets:  # Does not require additional query.
                         print('    ', tweet.content)

              <b>NOTE:</b>
                 Because <b>prefetch</b> must reconstruct a graph of models, it  is  necessary  to  be  sure  that  the
                 foreign-key/primary-key  of any related models are selected, so that the related objects can be
                 mapped correctly.

   <b>Query-builder</b> <b>Internals</b>
       <b>class</b> <b>AliasManager</b>
              Manages the aliases assigned to <u>Source</u> objects  in  SELECT  queries,  so  as  to  avoid  ambiguous
              references when multiple sources are used in a single query.

              <b>add(source)</b>
                     Add  a  source to the AliasManager's internal registry at the current scope. The alias will
                     be automatically generated using the following scheme  (where  each  level  of  indentation
                     refers to a new scope):

                     <b>Parameters</b>
                            <b>source</b> (<u>Source</u>) -- Make the manager aware of a new source. If the source has already
                            been added, the call is a no-op.

              <b>get(source[,</b> <b>any_depth=False])</b>
                     Return the alias for the source in the current scope. If the source does not have an alias,
                     it will be given the next available alias.

                     <b>Parameters</b>
                            <b>source</b> (<u>Source</u>) -- The source whose alias should be retrieved.

                     <b>Returns</b>
                            The alias already assigned to the source, or the next available alias.

                     <b>Return</b> <b>type</b>
                            str

              <b>__setitem__(source,</b> <b>alias)</b>
                     Manually set the alias for the source at the current scope.

                     <b>Parameters</b>
                            <b>source</b> (<u>Source</u>) -- The source for which we set the alias.

              <b>push()</b> Push a new scope onto the stack.

              <b>pop()</b>  Pop scope from the stack.

       <b>class</b> <b>State(scope[,</b> <b>parentheses=False[,</b> <b>subquery=False[,</b> <b>**kwargs]]])</b>
              Lightweight object for representing the state at a given scope. During SQL generation, each object
              visited by the <u>Context</u> can inspect the state. The <u>State</u> class allows Peewee to do things like:

              • Use a common interface for field types or SQL expressions, but use vendor-specific data-types or
                operators.

              • Compile  a <u>Column</u> instance into a fully-qualified attribute, as a named alias, etc, depending on
                the value of the <b>scope</b>.

              • Ensure parentheses are used appropriately.

              <b>Parameters</b>

                     • <b>scope</b> (<u>int</u>) -- The scope rules to be applied while the state is active.

                     • <b>parentheses</b> (<u>bool</u>) -- Wrap the contained SQL in parentheses.

                     • <b>subquery</b> (<u>bool</u>) -- Whether the current state is a child of an outer query.

                     • <b>kwargs</b> (<u>dict</u>) -- Arbitrary settings which should be applied in the current state.

       <b>class</b> <b>Context(**settings)</b>
              Converts Peewee structures into parameterized SQL queries.

              Peewee structures should all implement a <b>__</b><u>sql</u><b>__</b> method, which will be called by the <u>Context</u> class
              during SQL generation. The <b>__</b><u>sql</u><b>__</b> method accepts a single parameter, the <u>Context</u> instance,  which
              allows for recursive descent and introspection of scope and state.

              <b>scope</b>  Return the currently-active scope rules.

              <b>parentheses</b>
                     Return whether the current state is wrapped in parentheses.

              <b>subquery</b>
                     Return whether the current state is the child of another query.

              <b>scope_normal([**kwargs])</b>
                     The  default  scope.  Sources  are  referred  to  by alias, columns by dotted-path from the
                     source.

              <b>scope_source([**kwargs])</b>
                     Scope used when defining sources, e.g. in the column list  and  FROM  clause  of  a  SELECT
                     query. This scope is used for defining the fully-qualified name of the source and assigning
                     an alias.

              <b>scope_values([**kwargs])</b>
                     Scope  used  for UPDATE, INSERT or DELETE queries, where instead of referencing a source by
                     an alias, we refer to it directly. Similarly, since there is a single table, columns do not
                     need to be referenced by dotted-path.

              <b>scope_cte([**kwargs])</b>
                     Scope used when generating the contents of a common-table-expression.  Used  after  a  WITH
                     statement,  when  generating  the definition for a CTE (as opposed to merely a reference to
                     one).

              <b>scope_column([**kwargs])</b>
                     Scope used when generating SQL for a column. Ensures that the column is rendered with  it's
                     correct  alias.  Was  needed because when referencing the inner projection of a sub-select,
                     Peewee would render the full SELECT query as the "source" of the  column  (instead  of  the
                     query's  alias  + . + column).  This scope allows us to avoid rendering the full query when
                     we only need the alias.

              <b>sql(obj)</b>
                     Append a composable Node object, sub-context, or other object  to  the  query  AST.  Python
                     values, such as integers, strings, floats, etc. are treated as parameterized values.

                     <b>Returns</b>
                            The updated Context object.

              <b>literal(keyword)</b>
                     Append a string-literal to the current query AST.

                     <b>Returns</b>
                            The updated Context object.

              <b>parse(node)</b>

                     <b>Parameters</b>
                            <b>node</b> (<u>Node</u>) -- Instance of a Node subclass.

                     <b>Returns</b>
                            a 2-tuple consisting of (sql, parameters).

                     Convert  the  given  node to a SQL AST and return a 2-tuple consisting of the SQL query and
                     the parameters.

              <b>query()</b>

                     <b>Returns</b>
                            a 2-tuple consisting of (sql, parameters) for the context.

   <b>Constants</b> <b>and</b> <b>Helpers</b>
       <b>class</b> <b>Proxy</b>
              Create a proxy or placeholder for another object.

              <b>initialize(obj)</b>

                     <b>Parameters</b>
                            <b>obj</b> -- Object to proxy to.

                     Bind the proxy to the given object. Afterwards all attribute lookups and  method  calls  on
                     the proxy will be sent to the given object.

                     Any callbacks that have been registered will be called.

              <b>attach_callback(callback)</b>

                     <b>Parameters</b>
                            <b>callback</b> -- A function that accepts a single parameter, the bound object.

                     <b>Returns</b>
                            self

                     Add a callback to be executed when the proxy is initialized.

       <b>class</b> <b>DatabaseProxy</b>
              Proxy subclass that is suitable to use as a placeholder for a <u>Database</u> instance.

              See <u>Dynamically</u> <u>defining</u> <u>a</u> <u>database</u> for details on usage.

       <b>chunked(iterable,</b> <b>n)</b>

              <b>Parameters</b>

                     • <b>iterable</b> -- an iterable that is the source of the data to be chunked.

                     • <b>n</b> (<u>int</u>) -- chunk size

              <b>Returns</b>
                     a new iterable that yields <u>n</u>-length chunks of the source data.

              Efficient implementation for breaking up large lists of data into smaller-sized chunks.

              Usage:

                 it = <a href="../man10/range.10.html">range</a>(10)  # An iterable that yields 0...9.

                 # Break the iterable into chunks of length 4.
                 for chunk in chunked(it, 4):
                     print(', '.join(str(num) for num in chunk))

                 # PRINTS:
                 # 0, 1, 2, 3
                 # 4, 5, 6, 7
                 # 8, 9

   <b>SQLite</b> <b>Extensions</b>
       The default <u>SqliteDatabase</u> already includes many SQLite-specific features:

       • <u>General</u> <u>notes</u> <u>on</u> <u>using</u> <u>SQLite</u>.

       • <u>Configuring</u> <u>SQLite</u> <u>using</u> <u>PRAGMA</u> <u>statements</u>.

       • <u>User-defined</u> <u>functions,</u> <u>aggregate</u> <u>and</u> <u>collations</u>.

       • <u>Locking</u> <u>modes</u> <u>for</u> <u>transactions</u>.

       The <b>playhouse.sqlite_ext</b> includes even more SQLite features, including:

       • <u>Full-text</u> <u>search</u>

       • <u>JSON</u> <u>extension</u> <u>integration</u>

       • <u>Closure</u> <u>table</u> <u>extension</u> <u>support</u>

       • <u>LSM1</u> <u>extension</u> <u>support</u>

       • <u>User-defined</u> <u>table</u> <u>functions</u>

       • Support for online backups using backup API: <u>backup_to_file()</u>

       • <u>BLOB</u> <u>API</u> <u>support,</u> <u>for</u> <u>efficient</u> <u>binary</u> <u>data</u> <u>storage</u>.

       • <u>Additional</u> <u>helpers</u>, including bloom filter, more.

   <b>Getting</b> <b>started</b>
       To  get  started with the features described in this document, you will want to use the <u>SqliteExtDatabase</u>
       class from the <b>playhouse.sqlite_ext</b> module. Furthermore, some features require the  <b>playhouse._sqlite_ext</b>
       C extension -- these features will be noted in the documentation.

       Instantiating a <u>SqliteExtDatabase</u>:

          from playhouse.sqlite_ext import SqliteExtDatabase

          db = SqliteExtDatabase('my_app.db', pragmas=(
              ('cache_size', -1024 * 64),  # 64MB page-cache.
              ('journal_mode', 'wal'),  # Use WAL-mode (you should always use this!).
              ('foreign_keys', 1)))  # Enforce foreign-key constraints.

   <b>APIs</b>
       <b>class</b> <b>SqliteExtDatabase(database[,</b> <b>pragmas=None[,</b> <b>timeout=5[,</b> <b>c_extensions=None[,</b> <b>rank_functions=True[,</b>
       <b>hash_functions=False[,</b> <b>regexp_function=False[,</b> <b>bloomfilter=False]]]]]]])</b>

              <b>Parameters</b>

                     • <b>pragmas</b>  (<u>list</u>) -- A list of 2-tuples containing pragma key and value to set every time a
                       connection is opened.

                     • <b>timeout</b> -- Set the busy-timeout on the SQLite driver (in seconds).

                     • <b>c_extensions</b> (<u>bool</u>) -- Declare that C extension speedups must/must-not be used. If set to
                       <b>True</b> and the extension module  is  not  available,  will  raise  an  <b>ImproperlyConfigured</b>
                       exception.

                     • <b>rank_functions</b> (<u>bool</u>) -- Make search result ranking functions available.

                     • <b>hash_functions</b> (<u>bool</u>) -- Make hashing functions available (md5, sha1, etc).

                     • <b>regexp_function</b> (<u>bool</u>) -- Make the REGEXP function available.

                     • <b>bloomfilter</b> (<u>bool</u>) -- Make the <u>bloom</u> <u>filter</u> available.

              Extends <u>SqliteDatabase</u> and inherits methods for declaring user-defined functions, pragmas, etc.

       <b>class</b> <b>CSqliteExtDatabase(database[,</b> <b>pragmas=None[,</b> <b>timeout=5[,</b> <b>c_extensions=None[,</b> <b>rank_functions=True[,</b>
       <b>hash_functions=False[,</b> <b>regexp_function=False[,</b> <b>bloomfilter=False[,</b> <b>replace_busy_handler=False]]]]]]]])</b>

              <b>Parameters</b>

                     • <b>pragmas</b>  (<u>list</u>) -- A list of 2-tuples containing pragma key and value to set every time a
                       connection is opened.

                     • <b>timeout</b> -- Set the busy-timeout on the SQLite driver (in seconds).

                     • <b>c_extensions</b> (<u>bool</u>) -- Declare that C extension speedups must/must-not be used. If set to
                       <b>True</b> and the extension module  is  not  available,  will  raise  an  <b>ImproperlyConfigured</b>
                       exception.

                     • <b>rank_functions</b> (<u>bool</u>) -- Make search result ranking functions available.

                     • <b>hash_functions</b> (<u>bool</u>) -- Make hashing functions available (md5, sha1, etc).

                     • <b>regexp_function</b> (<u>bool</u>) -- Make the REGEXP function available.

                     • <b>bloomfilter</b> (<u>bool</u>) -- Make the <u>bloom</u> <u>filter</u> available.

                     • <b>replace_busy_handler</b> (<u>bool</u>) -- Use a smarter busy-handler implementation.

              Extends  <u>SqliteExtDatabase</u>  and  requires  that  the  <b>playhouse._sqlite_ext</b>  extension  module  be
              available.

              <b>on_commit(fn)</b>
                     Register a callback to be executed whenever a  transaction  is  committed  on  the  current
                     connection. The callback accepts no parameters and the return value is ignored.

                     However,  if  the  callback  raises  a  <b>ValueError</b>,  the  transaction  will  be aborted and
                     rolled-back.

                     Example:

                        db = CSqliteExtDatabase(':memory:')

                        @db.on_commit
                        def on_commit():
                            logger.info('COMMITing changes')

              <b>on_rollback(fn)</b>
                     Register a callback to be executed whenever a transaction is rolled  back  on  the  current
                     connection. The callback accepts no parameters and the return value is ignored.

                     Example:

                        @db.on_rollback
                        def on_rollback():
                            logger.info('Rolling back changes')

              <b>on_update(fn)</b>
                     Register  a  callback  to  be  executed whenever the database is written to (via an <u>UPDATE</u>,
                     <u>INSERT</u> or <u>DELETE</u> query). The callback should accept the following parameters:

                     • <b>query</b> - the type of query, either <u>INSERT</u>, <u>UPDATE</u> or <u>DELETE</u>.

                     • database name - the default database is named <u>main</u>.

                     • table name - name of table being modified.

                     • rowid - the rowid of the row being modified.

                     The callback's return value is ignored.

                     Example:

                        db = CSqliteExtDatabase(':memory:')

                        @db.on_update
                        def on_update(query_type, db, table, rowid):
                            # e.g. INSERT row 3 into table users.
                            logger.info('%s row %s into table %s', query_type, rowid, table)

              <b>changes()</b>
                     Return the number of rows modified in the currently-open transaction.

              <b>autocommit</b>
                     Property which returns a boolean indicating if autocommit is  enabled.   By  default,  this
                     value will be <b>True</b> except when inside a transaction (or <u>atomic()</u> block).

                     Example:

                        &gt;&gt;&gt; db = CSqliteExtDatabase(':memory:')
                        &gt;&gt;&gt; db.autocommit
                        True
                        &gt;&gt;&gt; with db.atomic():
                        ...     print(db.autocommit)
                        ...
                        False
                        &gt;&gt;&gt; db.autocommit
                        True

              <b>backup(destination[,</b> <b>pages=None,</b> <b>name=None,</b> <b>progress=None])</b>

                     <b>Parameters</b>

                            • <b>destination</b>  (<u>SqliteDatabase</u>)  --  Database object to serve as destination for the
                              backup.

                            • <b>pages</b> (<u>int</u>) -- Number of pages per iteration. Default value of  -1  indicates  all
                              pages should be backed-up in a single step.

                            • <b>name</b>  (<u>str</u>)  -- Name of source database (may differ if you used ATTACH DATABASE to
                              load multiple databases). Defaults to "main".

                            • <b>progress</b> -- Progress callback, called with three parameters: the number  of  pages
                              remaining, the total page count, and whether the backup is complete.

                     Example:

                        master = CSqliteExtDatabase('master.db')
                        replica = CSqliteExtDatabase('replica.db')

                        # Backup the contents of master to replica.
                        master.backup(replica)

              <b>backup_to_file(filename[,</b> <b>pages,</b> <b>name,</b> <b>progress])</b>

                     <b>Parameters</b>

                            • <b>filename</b> -- Filename to store the database backup.

                            • <b>pages</b>  (<u>int</u>)  --  Number of pages per iteration. Default value of -1 indicates all
                              pages should be backed-up in a single step.

                            • <b>name</b> (<u>str</u>) -- Name of source database (may differ if you used ATTACH  DATABASE  to
                              load multiple databases). Defaults to "main".

                            • <b>progress</b>  --  Progress callback, called with three parameters: the number of pages
                              remaining, the total page count, and whether the backup is complete.

                     Backup the current database to a file. The backed-up data is not a database  dump,  but  an
                     actual SQLite database file.

                     Example:

                        db = CSqliteExtDatabase('app.db')

                        def nightly_backup():
                            filename = 'backup-%s.db' % (datetime.date.today())
                            db.backup_to_file(filename)

              <b>blob_open(table,</b> <b>column,</b> <b>rowid[,</b> <b>read_only=False])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of table containing data.

                            • <b>column</b> (<u>str</u>) -- Name of column containing data.

                            • <b>rowid</b> (<u>int</u>) -- ID of row to retrieve.

                            • <b>read_only</b> (<u>bool</u>) -- Open the blob for reading only.

                     <b>Returns</b>
                            <u>Blob</u> instance which provides efficient access to the underlying binary data.

                     <b>Return</b> <b>type</b>
                            <u>Blob</u>

                     See <u>Blob</u> and <u>ZeroBlob</u> for more information.

                     Example:

                        class Image(Model):
                            filename = TextField()
                            data = BlobField()

                        buf_size = 1024 * 1024 * 8  # Allocate 8MB for storing file.
                        rowid = Image.insert({Image.filename: 'thefile.jpg',
                                              Image.data: ZeroBlob(buf_size)}).execute()

                        # Open the blob, returning a file-like object.
                        blob = db.blob_open('image', 'data', rowid)

                        # Write some data to the blob.
                        blob.write(image_data)
                        img_size = blob.tell()

                        # Read the data back out of the blob.
                        <a href="../man0/blob.seek.0.html">blob.seek</a>(0)
                        image_data = blob.read(img_size)

       <b>class</b> <b>RowIDField</b>
              Primary-key field that corresponds to the SQLite <b>rowid</b> field. For more information, see the SQLite
              documentation on <u>rowid</u> <u>tables</u>..

              Example:

                 class Note(Model):
                     rowid = RowIDField()  # Will be primary key.
                     content = TextField()
                     timestamp = TimestampField()

       <b>class</b> <b>DocIDField</b>
              Subclass of <u>RowIDField</u> for use on virtual tables that specifically use the convention of <b>docid</b> for
              the  primary  key. As far as I know this only pertains to tables using the FTS3 and FTS4 full-text
              search extensions.

              <b>ATTENTION:</b>
                 In FTS3 and FTS4, "docid" is simply an alias for "rowid". To reduce  confusion,  it's  probably
                 best to just always use <u>RowIDField</u> and never use <u>DocIDField</u>.

                 class NoteIndex(FTSModel):
                     docid = DocIDField()  # "docid" is used as an alias for "rowid".
                     content = SearchField()

                     class Meta:
                         database = db

       <b>class</b> <b>AutoIncrementField</b>
              SQLite,  by  default,  may  reuse  primary  key  values after rows are deleted. To ensure that the
              primary  key  is  <u>always</u>  monotonically  increasing,  regardless  of  deletions,  you  should  use
              <u>AutoIncrementField</u>.  There is a small performance cost for this feature. For more information, see
              the SQLite docs on <u>autoincrement</u>.

       <b>class</b> <b>JSONField(json_dumps=None,</b> <b>json_loads=None,</b> <b>...)</b>
              Field  class  suitable for storing JSON data, with special methods designed to work with the <u>json1</u>
              <u>extension</u>.

              SQLite 3.9.0 added <u>JSON</u> <u>support</u> in the form of an extension library. The  SQLite  json1  extension
              provides  a  number  of  helper  functions  for  working with JSON data. These APIs are exposed as
              methods of a special field-type, <u>JSONField</u>.

              To access or modify specific object keys or array indexes in a JSON structure, you can  treat  the
              <u>JSONField</u> as if it were a dictionary/list.

              <b>Parameters</b>

                     • <b>json_dumps</b>  -- (optional) function for serializing data to JSON strings. If not provided,
                       will use the stdlib <b>json.dumps</b>.

                     • <b>json_loads</b> -- (optional) function for de-serializing  JSON  to  Python  objects.  If  not
                       provided, will use the stdlib <b>json.loads</b>.

              <b>NOTE:</b>
                 To  customize  the  JSON serialization or de-serialization, you can specify a custom <b>json_dumps</b>
                 and <b>json_loads</b> callables. These functions should accept  a  single  parameter:  the  object  to
                 serialize,  and  the  JSON  string,  respectively.  To modify the parameters of the stdlib JSON
                 functions, you can use <b>functools.partial</b>:

                     # Do not escape unicode code-points.
                     my_json_dumps = functools.partial(json.dumps, ensure_ascii=False)

                     class SomeModel(Model):
                         # Specify our custom serialization function.
                         json_data = JSONField(json_dumps=my_json_dumps)

              Let's look at some examples of using the SQLite json1 extension with Peewee. Here we'll prepare  a
              database and a simple model for testing the <u>json1</u> <u>extension</u>:

                 &gt;&gt;&gt; from playhouse.sqlite_ext import *
                 &gt;&gt;&gt; db = SqliteExtDatabase(':memory:')
                 &gt;&gt;&gt; class KV(Model):
                 ...     key = TextField()
                 ...     value = JSONField()
                 ...     class Meta:
                 ...         database = db
                 ...

                 &gt;&gt;&gt; KV.create_table()

              Storing  data  works  as  you  might expect. There's no need to serialize dictionaries or lists as
              JSON, as this is done automatically by Peewee:

                 &gt;&gt;&gt; KV.create(key='a', value={'k1': 'v1'})
                 &lt;KV: 1&gt;
                 &gt;&gt;&gt; KV.get(KV.key == 'a').value
                 {'k1': 'v1'}

              We can access specific parts of the JSON data using dictionary lookups:

                 &gt;&gt;&gt; KV.get(KV.value['k1'] == 'v1').key
                 'a'

              It's possible to update a JSON value in-place using the <u>update()</u>  method.  Note  that  "k1=v1"  is
              preserved:

                 &gt;&gt;&gt; KV.update(value=KV.value.update({'k2': 'v2', 'k3': 'v3'})).execute()
                 1
                 &gt;&gt;&gt; KV.get(KV.key == 'a').value
                 {'k1': 'v1', 'k2': 'v2', 'k3': 'v3'}

              We can also update existing data atomically, or remove keys by setting their value to <b>None</b>. In the
              following example, we'll update the value of "k1" and remove "k3" ("k2" will not be modified):

                 &gt;&gt;&gt; KV.update(value=KV.value.update({'k1': 'v1-x', 'k3': None})).execute()
                 1
                 &gt;&gt;&gt; KV.get(KV.key == 'a').value
                 {'k1': 'v1-x', 'k2': 'v2'}

              We can also set individual parts of the JSON data using the <u>set()</u> method:

                 &gt;&gt;&gt; KV.update(value=KV.value['k1'].set('v1')).execute()
                 1
                 &gt;&gt;&gt; KV.get(KV.key == 'a').value
                 {'k1': 'v1', 'k2': 'v2'}

              The <u>set()</u> method can also be used with objects, in addition to scalar values:

                 &gt;&gt;&gt; KV.update(value=KV.value['k2'].set({'x2': 'y2'})).execute()
                 1
                 &gt;&gt;&gt; KV.get(KV.key == 'a').value
                 {'k1': 'v1', 'k2': {'x2': 'y2'}}

              Individual parts of the JSON data can be removed atomically as well, using <u>remove()</u>:

                 &gt;&gt;&gt; KV.update(value=KV.value['k2'].remove()).execute()
                 1
                 &gt;&gt;&gt; KV.get(KV.key == 'a').value
                 {'k1': 'v1'}

              We  can  also  get  the  type  of  value  stored at a specific location in the JSON data using the
              <u>json_type()</u> method:

                 &gt;&gt;&gt; KV.select(KV.value.json_type(), KV.value['k1'].json_type()).tuples()[:]
                 [('object', 'text')]

              Let's add a nested value and then see how to iterate through it's contents recursively  using  the
              <u>tree()</u> method:

                 &gt;&gt;&gt; KV.create(key='b', value={'x1': {'y1': 'z1', 'y2': 'z2'}, 'x2': [1, 2]})
                 &lt;KV: 2&gt;
                 &gt;&gt;&gt; tree = KV.value.tree().alias('tree')
                 &gt;&gt;&gt; query = KV.select(KV.key, tree.c.fullkey, tree.c.value).from_(KV, tree)
                 &gt;&gt;&gt; query.tuples()[:]
                 [('a', '$', {'k1': 'v1'}),
                  ('a', '$.k1', 'v1'),
                  ('b', '$', {'x1': {'y1': 'z1', 'y2': 'z2'}, 'x2': [1, 2]}),
                  ('b', '$.x2', [1, 2]),
                  ('b', '$.x2[0]', 1),
                  ('b', '$.x2[1]', 2),
                  ('b', '$.x1', {'y1': 'z1', 'y2': 'z2'}),
                  ('b', '$.x1.y1', 'z1'),
                  ('b', '$.x1.y2', 'z2')]

              The  <u>tree()</u>  and <u>children()</u> methods are powerful. For more information on how to utilize them, see
              the <u>json1</u> <u>extension</u> <u>documentation</u>.

              Also note, that <u>JSONField</u> lookups can be chained:

                 &gt;&gt;&gt; query = KV.select().where(KV.value['x1']['y1'] == 'z1')
                 &gt;&gt;&gt; for obj in query:
                 ...     print(obj.key, obj.value)
                 ...

                 'b', {'x1': {'y1': 'z1', 'y2': 'z2'}, 'x2': [1, 2]}

              For more information, refer to the <u>sqlite</u> <u>json1</u> <u>documentation</u>.

              <b>__getitem__(item)</b>

                     <b>Parameters</b>
                            <b>item</b> -- Access a specific key or array index in the JSON data.

                     <b>Returns</b>
                            a special object exposing access to the JSON data.

                     <b>Return</b> <b>type</b>
                            <u>JSONPath</u>

                     Access a specific key or array index in the JSON data. Returns  a  <u>JSONPath</u>  object,  which
                     exposes convenient methods for reading or modifying a particular part of a JSON object.

                     Example:

                        # If metadata contains {"tags": ["list", "of", "tags"]}, we can
                        # extract the first tag in this way:
                        Post.select(Post, Post.metadata['tags'][0].alias('first_tag'))

                     For more examples see the <u>JSONPath</u> API documentation.

              <b>extract(*paths)</b>

                     <b>Parameters</b>
                            <b>paths</b> -- One or more JSON paths to extract.

                     Extract  the  value(s)  at  the  specified JSON paths. If multiple paths are provided, then
                     Sqlite will return the values as a <b>list</b>.

              <b>extract_json(path)</b>

                     <b>Parameters</b>
                            <b>path</b> (<u>str</u>) -- JSON path

                     Extract the value at the specified path as a JSON data-type. This  corresponds  to  the  <b>-&gt;</b>
                     operator added in Sqlite 3.38.

              <b>extract_text(path)</b>

                     <b>Parameters</b>
                            <b>path</b> (<u>str</u>) -- JSON path

                     Extract  the  value  at  the specified path as a SQL data-type. This corresponds to the <b>-&gt;&gt;</b>
                     operator added in Sqlite 3.38.

              <b>set(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b> (<u>bool</u>) -- force the value to be treated as JSON, in which case it will  be
                              serialized  as  JSON  in Python beforehand. By default, lists and dictionaries are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Set the value stored in a <u>JSONField</u>.

                     Uses the <u>json_set()</u> function from the json1 extension.

              <b>replace(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b> (<u>bool</u>) -- force the value to be treated as JSON, in which case it will  be
                              serialized  as  JSON  in Python beforehand. By default, lists and dictionaries are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Replace the existing value stored in a <u>JSONField</u>.

                     Uses the <u>json_replace()</u> function from the json1 extension.

              <b>insert(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b> (<u>bool</u>) -- force the value to be treated as JSON, in which case it will  be
                              serialized  as  JSON  in Python beforehand. By default, lists and dictionaries are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Insert value into <u>JSONField</u>.

                     Uses the <u>json_insert()</u> function from the json1 extension.

              <b>append(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b> (<u>bool</u>) -- force the value to be treated as JSON, in which case it will  be
                              serialized  as  JSON  in Python beforehand. By default, lists and dictionaries are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Append to the array stored in a <u>JSONField</u>.

                     Uses the <u>json_set()</u> function from the json1 extension.

              <b>update(data)</b>

                     <b>Parameters</b>
                            <b>data</b> -- a scalar value, list or dictionary to merge with the data  currently  stored
                            in  a  <u>JSONField</u>.  To  remove  a particular key, set that key to <b>None</b> in the updated
                            data.

                     Merge new data into the JSON value using the RFC-7396 MergePatch algorithm to apply a patch
                     (<b>data</b> parameter) against the column data. MergePatch can add, modify, or delete elements of
                     a JSON object, which means <u>update()</u>  is  a  generalized  replacement  for  both  <u>set()</u>  and
                     <u>remove()</u>.   MergePatch treats JSON array objects as atomic, so <b>update()</b> cannot append to an
                     array, nor modify individual elements of an array.

                     For  more  information  as  well  as  examples,  see  the  SQLite   <u>json_patch()</u>   function
                     documentation.

              <b>remove()</b>
                     Remove the data stored in the <u>JSONField</u>.

                     Uses the <u>json_remove</u> function from the json1 extension.

              <b>json_type()</b>
                     Return a string identifying the type of value stored in the column.

                     The type returned will be one of:

                     • object

                     • array

                     • integer

                     • real

                     • true

                     • false

                     • text

                     • null  &lt;-- the string "null" means an actual NULL value

                     • NULL  &lt;-- an actual NULL value means the path was not found

                     Uses the <u>json_type</u> function from the json1 extension.

              <b>length()</b>
                     Return the length of the array stored in the column.

                     Uses the <u>json_array_length</u> function from the json1 extension.

              <b>children()</b>
                     The <b>children</b> function corresponds to <b>json_each</b>, a table-valued function that walks the JSON
                     value  provided  and  returns the immediate children of the top-level array or object. If a
                     path is specified, then that path is treated as the top-most element.

                     The rows returned by calls to <b>children()</b> have the following attributes:

                     • <b>key</b>: the key of the current element relative to its parent.

                     • <b>value</b>: the value of the current element.

                     • <b>type</b>: one of the data-types (see <u>json_type()</u>).

                     • <b>atom</b>: the scalar value for primitive types, <b>NULL</b> for arrays and objects.

                     • <b>id</b>: a unique ID referencing the current node in the tree.

                     • <b>parent</b>: the ID of the containing node.

                     • <b>fullkey</b>: the full path describing the current element.

                     • <b>path</b>: the path to the container of the current row.

                     Internally this method uses the <u>json_each</u> (documentation  link)  function  from  the  json1
                     extension.

                     Example usage (compare to <u>tree()</u> method):

                        class KeyData(Model):
                            key = TextField()
                            data = JSONField()

                        KeyData.create(key='a', data={'k1': 'v1', 'x1': {'y1': 'z1'}})
                        KeyData.create(key='b', data={'x1': {'y1': 'z1', 'y2': 'z2'}})

                        # We will query the KeyData model for the key and all the
                        # top-level keys and values in it's data field.
                        kd = KeyData.data.children().alias('children')
                        query = (KeyData
                                 .select(kd.c.key, kd.c.value, kd.c.fullkey)
                                 .from_(KeyData, kd)
                                 .order_by(kd.c.key)
                                 .tuples())
                        print(query[:])

                        # PRINTS:
                        [('a', 'k1', 'v1',                    '$.k1'),
                         ('a', 'x1', '{"y1":"z1"}',           '$.x1'),
                         ('b', 'x1', '{"y1":"z1","y2":"z2"}', '$.x1')]

              <b>tree()</b> The  <b>tree</b> function corresponds to <b>json_tree</b>, a table-valued function that recursively walks
                     the JSON value provided and returns information about the keys at each level. If a path  is
                     specified, then that path is treated as the top-most element.

                     The  rows returned by calls to <b>tree()</b> have the same attributes as rows returned by calls to
                     <u>children()</u>:

                     • <b>key</b>: the key of the current element relative to its parent.

                     • <b>value</b>: the value of the current element.

                     • <b>type</b>: one of the data-types (see <u>json_type()</u>).

                     • <b>atom</b>: the scalar value for primitive types, <b>NULL</b> for arrays and objects.

                     • <b>id</b>: a unique ID referencing the current node in the tree.

                     • <b>parent</b>: the ID of the containing node.

                     • <b>fullkey</b>: the full path describing the current element.

                     • <b>path</b>: the path to the container of the current row.

                     Internally this method uses the <u>json_tree</u> (documentation  link)  function  from  the  json1
                     extension.

                     Example usage:

                        class KeyData(Model):
                            key = TextField()
                            data = JSONField()

                        KeyData.create(key='a', data={'k1': 'v1', 'x1': {'y1': 'z1'}})
                        KeyData.create(key='b', data={'x1': {'y1': 'z1', 'y2': 'z2'}})

                        # We will query the KeyData model for the key and all the
                        # keys and values in it's data field, recursively.
                        kd = KeyData.data.tree().alias('tree')
                        query = (KeyData
                                 .select(kd.c.key, kd.c.value, kd.c.fullkey)
                                 .from_(KeyData, kd)
                                 .order_by(kd.c.key)
                                 .tuples())
                        print(query[:])

                        # PRINTS:
                        [('a',  None,  '{"k1":"v1","x1":{"y1":"z1"}}', '$'),
                         ('b',  None,  '{"x1":{"y1":"z1","y2":"z2"}}', '$'),
                         ('a',  'k1',  'v1',                           '$.k1'),
                         ('a',  'x1',  '{"y1":"z1"}',                  '$.x1'),
                         ('b',  'x1',  '{"y1":"z1","y2":"z2"}',        '$.x1'),
                         ('a',  'y1',  'z1',                           '$.x1.y1'),
                         ('b',  'y1',  'z1',                           '$.x1.y1'),
                         ('b',  'y2',  'z2',                           '$.x1.y2')]

       <b>class</b> <b>JSONPath(field[,</b> <b>path=None])</b>

              <b>Parameters</b>

                     • <b>field</b> (<u>JSONField</u>) -- the field object we intend to access.

                     • <b>path</b> (<u>tuple</u>) -- Components comprising the JSON path.

              A convenient, Pythonic way of representing JSON paths for use with <u>JSONField</u>.

              The  <b>JSONPath</b>  object implements <b>__getitem__</b>, accumulating path components, which it can turn into
              the corresponding json-path expression.

              <b>__getitem__(item)</b>

                     <b>Parameters</b>
                            <b>item</b> -- Access a sub-key key or array index.

                     <b>Returns</b>
                            a <u>JSONPath</u> representing the new path.

                     Access a sub-key or array index in the JSON data. Returns a <u>JSONPath</u> object, which  exposes
                     convenient methods for reading or modifying a particular part of a JSON object.

                     Example:

                        # If metadata contains {"tags": ["list", "of", "tags"]}, we can
                        # extract the first tag in this way:
                        first_tag = Post.metadata['tags'][0]
                        query = (Post
                                 .select(Post, first_tag.alias('first_tag'))
                                 .order_by(first_tag))

              <b>set(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b>  (<u>bool</u>) -- force the value to be treated as JSON, in which case it will be
                              serialized as JSON in Python beforehand. By default, lists  and  dictionaries  are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Set the value at the given location in the JSON data.

                     Uses the <u>json_set()</u> function from the json1 extension.

              <b>replace(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b>  (<u>bool</u>) -- force the value to be treated as JSON, in which case it will be
                              serialized as JSON in Python beforehand. By default, lists  and  dictionaries  are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Replace the existing value at the given location in the JSON data.

                     Uses the <u>json_replace()</u> function from the json1 extension.

              <b>insert(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b>  (<u>bool</u>) -- force the value to be treated as JSON, in which case it will be
                              serialized as JSON in Python beforehand. By default, lists  and  dictionaries  are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Insert a new value at the given location in the JSON data.

                     Uses the <u>json_insert()</u> function from the json1 extension.

              <b>append(value[,</b> <b>as_json=None])</b>

                     <b>Parameters</b>

                            • <b>value</b> -- a scalar value, list, or dictionary.

                            • <b>as_json</b>  (<u>bool</u>) -- force the value to be treated as JSON, in which case it will be
                              serialized as JSON in Python beforehand. By default, lists  and  dictionaries  are
                              treated as JSON to be serialized, while strings and integers are passed as-is.

                     Append to the array stored at the given location in the JSON data.

                     Uses the <u>json_set()</u> function from the json1 extension.

              <b>update(data)</b>

                     <b>Parameters</b>
                            <b>data</b>  --  a  scalar  value,  list  or dictionary to merge with the data at the given
                            location in the JSON data. To remove a particular key, set that key to <b>None</b>  in  the
                            updated data.

                     Merge new data into the JSON value using the RFC-7396 MergePatch algorithm to apply a patch
                     (<b>data</b> parameter) against the column data. MergePatch can add, modify, or delete elements of
                     a  JSON  object,  which  means  <u>update()</u>  is  a  generalized replacement for both <u>set()</u> and
                     <u>remove()</u>.  MergePatch treats JSON array objects as atomic, so <b>update()</b> cannot append to  an
                     array, nor modify individual elements of an array.

                     For   more   information  as  well  as  examples,  see  the  SQLite  <u>json_patch()</u>  function
                     documentation.

              <b>remove()</b>
                     Remove the data stored in at the given location in the JSON data.

                     Uses the <u>json_type</u> function from the json1 extension.

              <b>json_type()</b>
                     Return a string identifying the type of value stored at the  given  location  in  the  JSON
                     data.

                     The type returned will be one of:

                     • object

                     • array

                     • integer

                     • real

                     • true

                     • false

                     • text

                     • null  &lt;-- the string "null" means an actual NULL value

                     • NULL  &lt;-- an actual NULL value means the path was not found

                     Uses the <u>json_type</u> function from the json1 extension.

              <b>length()</b>
                     Return the length of the array stored at the given location in the JSON data.

                     Uses the <u>json_array_length</u> function from the json1 extension.

              <b>children()</b>
                     Table-valued  function  that  exposes  the direct descendants of a JSON object at the given
                     location. See also <u>JSONField.children()</u>.

              <b>tree()</b> Table-valued function that exposes all descendants, recursively, of a JSON  object  at  the
                     given location. See also <u>JSONField.tree()</u>.

       <b>class</b> <b>JSONBField(json_dumps=None,</b> <b>json_loads=None,</b> <b>...)</b>
              Field-class  suitable  for use with data stored on-disk in <b>jsonb</b> format (available starting Sqlite
              3.45.0). This field-class should be used with care, as the data may be returned  in  it's  encoded
              format depending on how you query it. For example:

                 &gt;&gt;&gt; KV.create(key='a', value={'k1': 'v1'})
                 &lt;KV: 1&gt;
                 &gt;&gt;&gt; KV.get(KV.key == 'a').value
                 b"l'k1'v1"

              To get the JSON value, it is necessary to use <b>fn.json()</b> or the helper <b>JSONBField.json()</b> method:

                 &gt;&gt;&gt; kv = KV.select(KV.value.json()).get()
                 &gt;&gt;&gt; kv.value
                 {'k1': 'v1'}

       <b>class</b> <b>JSONBPath(field[,</b> <b>path=None])</b>
              Subclass of <u>JSONPath</u> for working with <b>jsonb</b> data.

       <b>class</b> <b>SearchField([unindexed=False[,</b> <b>column_name=None]])</b>
              Field-class  to  be  used  for columns on models representing full-text search virtual tables. The
              full-text search extensions prohibit the specification of any typing or  constraints  on  columns.
              This  behavior  is  enforced by the <u>SearchField</u>, which raises an exception if any configuration is
              attempted that would be incompatible with the full-text search extensions.

              Example model for document search index (timestamp is stored in the table but  it's  data  is  not
              searchable):

                 class DocumentIndex(FTSModel):
                     title = SearchField()
                     content = SearchField()
                     tags = SearchField()
                     timestamp = SearchField(unindexed=True)

              <b>match(term)</b>

                     <b>Parameters</b>
                            <b>term</b> (<u>str</u>) -- full-text search query/terms

                     <b>Returns</b>
                            a <u>Expression</u> corresponding to the <b>MATCH</b> operator.

                     Sqlite's  full-text  search supports searching either the full table, including all indexed
                     columns, <b>or</b> searching individual columns. The <u>match()</u> method can be used to restrict search
                     to a single column:

                        class SearchIndex(FTSModel):
                            title = SearchField()
                            body = SearchField()

                        # Search *only* the title field and return results ordered by
                        # relevance, using bm25.
                        query = (SearchIndex
                                 .select(SearchIndex, SearchIndex.bm25().alias('score'))
                                 .where(SearchIndex.title.match('python'))
                                 .order_by(SearchIndex.bm25()))

                     To instead search <u>all</u> indexed columns, use the <u>FTSModel.match()</u> method:

                        # Searches *both* the title and body and return results ordered by
                        # relevance, using bm25.
                        query = (SearchIndex
                                 .select(SearchIndex, SearchIndex.bm25().alias('score'))
                                 .where(SearchIndex.match('python'))
                                 .order_by(SearchIndex.bm25()))

              <b>highlight(left,</b> <b>right)</b>

                     <b>Parameters</b>

                            • <b>left</b> (<u>str</u>) -- opening tag for highlight, e.g. <b>'&lt;b&gt;'</b>

                            • <b>right</b> (<u>str</u>) -- closing tag for highlight, e.g. <b>'&lt;/b&gt;'</b>

                     When performing a search using the  <b>MATCH</b>  operator,  FTS5  can  return  text  highlighting
                     matches in a given column.

                        # Search for items matching string 'python' and return the title
                        # highlighted with square brackets.
                        query = (SearchIndex
                                 .search('python')
                                 .select(SearchIndex.title.highlight('[', ']').alias('hi')))

                        for result in query:
                            print(result.hi)

                        # For example, might print:
                        # Learn [python] the hard way

              <b>snippet(left,</b> <b>right,</b> <b>over_length='...',</b> <b>max_tokens=16)</b>

                     <b>Parameters</b>

                            • <b>left</b> (<u>str</u>) -- opening tag for highlight, e.g. <b>'&lt;b&gt;'</b>

                            • <b>right</b> (<u>str</u>) -- closing tag for highlight, e.g. <b>'&lt;/b&gt;'</b>

                            • <b>over_length</b>  (<u>str</u>)  --  text to prepend or append when snippet exceeds the maximum
                              number of tokens.

                            • <b>max_tokens</b> (<u>int</u>) -- max tokens returned, <b>must</b> <b>be</b> <b>1</b> <b>-</b> <b>64</b>.

                     When performing a search using the <b>MATCH</b> operator, FTS5 can  return  text  with  a  snippet
                     containing the highlighted match in a given column.

                        # Search for items matching string 'python' and return the title
                        # highlighted with square brackets.
                        query = (SearchIndex
                                 .search('python')
                                 .select(SearchIndex.title.snippet('[', ']').alias('snip')))

                        for result in query:
                            print(result.snip)

       <b>class</b> <b>VirtualModel</b>
              Model  class  designed  to  be used to represent virtual tables. The default metadata settings are
              slightly different, to match those frequently used by virtual tables.

              Metadata options:

              • <b>arguments</b> - arguments passed to the virtual table constructor.

              • <b>extension_module</b> - name of extension to use for virtual table.

              •

                <b>options</b> <b>-</b> <b>a</b> <b>dictionary</b> <b>of</b> <b>settings</b> <b>to</b> <b>apply</b> <b>in</b> <b>virtual</b> <b>table</b>
                       constructor.

              • <b>primary_key</b> - defaults to <b>False</b>, indicating no primary key.

              These all are combined in the following way:

                 CREATE VIRTUAL TABLE &lt;table_name&gt;
                 USING &lt;extension_module&gt;
                 ([prefix_arguments, ...] fields, ... [arguments, ...], [options...])

       <b>class</b> <b>FTSModel</b>
              Subclass of <u>VirtualModel</u> to be used with the <u>FTS3</u> <u>and</u> <u>FTS4</u> full-text search extensions.

              FTSModel subclasses should be defined normally, however there are a couple caveats:

              • Unique constraints, not null constraints, check constraints and foreign keys are not supported.

              • Indexes on fields and multi-column indexes are ignored completely

              • Sqlite will treat all column types as <b>TEXT</b> (although you can store other data types, Sqlite will
                treat them as text).

              • FTS models contain a <b>rowid</b> field which is automatically created and managed  by  SQLite  (unless
                you  choose  to  explicitly  set  it during model creation). Lookups on this column <b>are</b> <b>fast</b> <b>and</b>
                <b>efficient</b>.

              Given these constraints, it is strongly recommended  that  all  fields  declared  on  an  <b>FTSModel</b>
              subclass  be  instances  of  <u>SearchField</u>  (though  an exception is made for explicitly declaring a
              <u>RowIDField</u>). Using  <u>SearchField</u>  will  help  prevent  you  accidentally  creating  invalid  column
              constraints.  If  you  wish to store metadata in the index but would not like it to be included in
              the full-text index, then specify <b>unindexed=True</b> when instantiating the <u>SearchField</u>.

              The only exception to the above is for  the  <b>rowid</b>  primary  key,  which  can  be  declared  using
              <u>RowIDField</u>.  Lookups  on  the  <b>rowid</b>  are  very  efficient. If you are using FTS4 you can also use
              <u>DocIDField</u>, which is an alias for the rowid (though there is no benefit to doing so).

              Because of the lack of secondary indexes, it usually makes sense to use the <b>rowid</b> primary key as a
              pointer to a row in a regular table. For example:

                 class Document(Model):
                     # Canonical source of data, stored in a regular table.
                     author = ForeignKeyField(User, backref='documents')
                     title = TextField(null=False, unique=True)
                     content = TextField(null=False)
                     timestamp = DateTimeField()

                     class Meta:
                         database = db

                 class DocumentIndex(FTSModel):
                     # Full-text search index.
                     rowid = RowIDField()
                     title = SearchField()
                     content = SearchField()

                     class Meta:
                         database = db
                         # Use the porter stemming algorithm to tokenize content.
                         options = {'tokenize': 'porter'}

              To store a document in the document index, we will <b>INSERT</b> a  row  into  the  <b>DocumentIndex</b>  table,
              manually setting the <b>rowid</b> so that it matches the primary-key of the corresponding <b>Document</b>:

                 def store_document(document):
                     DocumentIndex.insert({
                         DocumentIndex.rowid: document.id,
                         DocumentIndex.title: document.title,
                         DocumentIndex.content: document.content}).execute()

              To  perform  a  search  and return ranked results, we can query the <b>Document</b> table and join on the
              <b>DocumentIndex</b>. This join will be efficient because lookups on an FTSModel's <b>rowid</b> field are fast:

                 def search(phrase):
                     # Query the search index and join the corresponding Document
                     # object on each search result.
                     return (Document
                             .select()
                             .join(
                                 DocumentIndex,
                                 on=(Document.id == DocumentIndex.rowid))
                             .where(DocumentIndex.match(phrase))
                             .order_by(DocumentIndex.bm25()))

              <b>WARNING:</b>
                 All SQL queries on <b>FTSModel</b> classes will be full-table  scans  <b>except</b>  full-text  searches  and
                 <b>rowid</b> lookups.

              If  the  primary  source  of the content you are indexing exists in a separate table, you can save
              some disk space by instructing SQLite to not store an additional copy of the search index content.
              SQLite will still create the metadata and  data-structures  needed  to  perform  searches  on  the
              content, but the content itself will not be stored in the search index.

              To  accomplish  this,  you  can  specify  a  table  or  column  using the <b>content</b> option. The <u>FTS4</u>
              <u>documentation</u> has more information.

              Here is a short example illustrating how to implement this with peewee:

                 class Blog(Model):
                     title = TextField()
                     pub_date = DateTimeField(default=datetime.datetime.now)
                     content = TextField()  # We want to search this.

                     class Meta:
                         database = db

                 class BlogIndex(FTSModel):
                     content = SearchField()

                     class Meta:
                         database = db
                         options = {'content': Blog.content}  # &lt;-- specify data source.

                 db.create_tables([Blog, BlogIndex])

                 # Now, we can manage content in the BlogIndex. To populate the
                 # search index:
                 BlogIndex.rebuild()

                 # Optimize the index.
                 BlogIndex.optimize()

              The <b>content</b> option accepts either a single <u>Field</u> or a <u>Model</u> and can reduce the amount  of  storage
              used  by the database file. However, content will need to be manually moved to/from the associated
              <b>FTSModel</b>.

              <b>classmethod</b> <b>match(term)</b>

                     <b>Parameters</b>
                            <b>term</b> -- Search term or expression.

                     Generate a SQL expression representing a search for the given term  or  expression  in  the
                     table. SQLite uses the <b>MATCH</b> operator to indicate a full-text search.

                     Example:

                        # Search index for "search phrase" and return results ranked
                        # by relevancy using the BM25 algorithm.
                        query = (DocumentIndex
                                 .select()
                                 .where(DocumentIndex.match('search phrase'))
                                 .order_by(DocumentIndex.bm25()))
                        for result in query:
                            print('Result: %s' % result.title)

              <b>classmethod</b> <b>search(term[,</b> <b>weights=None[,</b> <b>with_score=False[,</b> <b>score_alias='score'[,</b>
              <b>explicit_ordering=False]]]])</b>

                     <b>Parameters</b>

                            • <b>term</b> (<u>str</u>) -- Search term to use.

                            • <b>weights</b> -- A list of weights for the columns, ordered with respect to the column's
                              position  in  the  table.  <b>Or</b>,  a  dictionary keyed by the field or field name and
                              mapped to a value.

                            • <b>with_score</b> -- Whether  the  score  should  be  returned  as  part  of  the  <b>SELECT</b>
                              statement.

                            • <b>score_alias</b>  (<u>str</u>)  --  Alias  to  use for the calculated rank score.  This is the
                              attribute you will use to access the score if <b>with_score=True</b>.

                            • <b>explicit_ordering</b> (<u>bool</u>) -- Order using full SQL function to  calculate  rank,  as
                              opposed to simply referencing the score alias in the ORDER BY clause.

                     Shorthand way of searching for a term and sorting results by the quality of the match.

                     <b>NOTE:</b>
                        This  method  uses a simplified algorithm for determining the relevance rank of results.
                        For more sophisticated result ranking, use the <u>search_bm25()</u> method.

                        # Simple search.
                        docs = DocumentIndex.search('search term')
                        for result in docs:
                            print(result.title)

                        # More complete example.
                        docs = DocumentIndex.search(
                            'search term',
                            weights={'title': 2.0, 'content': 1.0},
                            with_score=True,
                            score_alias='search_score')
                        for result in docs:
                            print(result.title, result.search_score)

              <b>classmethod</b> <b>search_bm25(term[,</b> <b>weights=None[,</b> <b>with_score=False[,</b> <b>score_alias='score'[,</b>
              <b>explicit_ordering=False]]]])</b>

                     <b>Parameters</b>

                            • <b>term</b> (<u>str</u>) -- Search term to use.

                            • <b>weights</b> -- A list of weights for the columns, ordered with respect to the column's
                              position in the table. <b>Or</b>, a dictionary keyed by  the  field  or  field  name  and
                              mapped to a value.

                            • <b>with_score</b>  --  Whether  the  score  should  be  returned  as  part  of the <b>SELECT</b>
                              statement.

                            • <b>score_alias</b> (<u>str</u>) -- Alias to use for the calculated  rank  score.   This  is  the
                              attribute you will use to access the score if <b>with_score=True</b>.

                            • <b>explicit_ordering</b>  (<u>bool</u>)  --  Order using full SQL function to calculate rank, as
                              opposed to simply referencing the score alias in the ORDER BY clause.

                     Shorthand way of searching for a term and sorting results by the quality of the match using
                     the BM25 algorithm.

                     <b>ATTENTION:</b>
                        The BM25 ranking algorithm is only available for FTS4. If you are using  FTS3,  use  the
                        <u>search()</u> method instead.

              <b>classmethod</b> <b>search_bm25f(term[,</b> <b>weights=None[,</b> <b>with_score=False[,</b> <b>score_alias='score'[,</b>
              <b>explicit_ordering=False]]]])</b>
                     Same as <u>FTSModel.search_bm25()</u>, but using the BM25f variant of the BM25 ranking algorithm.

              <b>classmethod</b> <b>search_lucene(term[,</b> <b>weights=None[,</b> <b>with_score=False[,</b> <b>score_alias='score'[,</b>
              <b>explicit_ordering=False]]]])</b>
                     Same  as  <u>FTSModel.search_bm25()</u>,  but  using  the result ranking algorithm from the Lucene
                     search engine.

              <b>classmethod</b> <b>rank([col1_weight,</b> <b>col2_weight...coln_weight])</b>

                     <b>Parameters</b>
                            <b>col_weight</b> (<u>float</u>) -- (Optional) weight to give to the <u>ith</u> column of the  model.  By
                            default all columns have a weight of <b>1.0</b>.

                     Generate an expression that will calculate and return the quality of the search match. This
                     <b>rank</b> can be used to sort the search results.  A higher rank score indicates a better match.

                     The  <b>rank</b>  function  accepts  optional parameters that allow you to specify weights for the
                     various columns. If  no  weights  are  specified,  all  columns  are  considered  of  equal
                     importance.

                     <b>NOTE:</b>
                        The  algorithm  used  by  <u>rank()</u>  is simple and relatively quick. For more sophisticated
                        result ranking, use:

                        • <u>bm25()</u>

                        • <u>bm25f()</u>

                        • <u>lucene()</u>

                        query = (DocumentIndex
                                 .select(
                                     DocumentIndex,
                                     DocumentIndex.rank().alias('score'))
                                 .where(DocumentIndex.match('search phrase'))
                                 .order_by(DocumentIndex.rank()))

                        for search_result in query:
                            print(search_result.title, search_result.score)

              <b>classmethod</b> <b>bm25([col1_weight,</b> <b>col2_weight...coln_weight])</b>

                     <b>Parameters</b>
                            <b>col_weight</b> (<u>float</u>) -- (Optional) weight to give to the <u>ith</u> column of the  model.  By
                            default all columns have a weight of <b>1.0</b>.

                     Generate an expression that will calculate and return the quality of the search match using
                     the  <u>BM25</u> <u>algorithm</u>.  This value can be used to sort the search results, with higher scores
                     corresponding to better matches.

                     Like <u>rank()</u>, <b>bm25</b> function accepts optional parameters that allow you  to  specify  weights
                     for  the various columns.  If no weights are specified, all columns are considered of equal
                     importance.

                     <b>ATTENTION:</b>
                        The BM25 result ranking algorithm requires FTS4. If  you  are  using  FTS3,  use  <u>rank()</u>
                        instead.

                        query = (DocumentIndex
                                 .select(
                                     DocumentIndex,
                                     DocumentIndex.bm25().alias('score'))
                                 .where(DocumentIndex.match('search phrase'))
                                 .order_by(DocumentIndex.bm25()))

                        for search_result in query:
                            print(search_result.title, search_result.score)

                     <b>NOTE:</b>
                        The above code example is equivalent to calling the <u>search_bm25()</u> method:

                            query = DocumentIndex.search_bm25('search phrase', with_score=True)
                            for search_result in query:
                                print(search_result.title, search_result.score)

              <b>classmethod</b> <b>bm25f([col1_weight,</b> <b>col2_weight...coln_weight])</b>
                     Identical to <u>bm25()</u>, except that it uses the BM25f variant of the BM25 ranking algorithm.

              <b>classmethod</b> <b>lucene([col1_weight,</b> <b>col2_weight...coln_weight])</b>
                     Identical to <u>bm25()</u>, except that it uses the Lucene search result ranking algorithm.

              <b>classmethod</b> <b>rebuild()</b>
                     Rebuild  the  search  index -- this only works when the <b>content</b> option was specified during
                     table creation.

              <b>classmethod</b> <b>optimize()</b>
                     Optimize the search index.

       <b>class</b> <b>FTS5Model</b>
              Subclass of <u>VirtualModel</u> to be used with the <u>FTS5</u> full-text search extensions.

              FTS5Model subclasses should be defined normally, however there are a couple caveats:

              • FTS5 explicitly disallows specification of any constraints, data-type or indexes on columns. For
                that reason, all columns <b>must</b> be instances of <u>SearchField</u>.

              • FTS5 models contain a <b>rowid</b> field which is automatically created and managed by  SQLite  (unless
                you  choose  to  explicitly  set  it during model creation). Lookups on this column <b>are</b> <b>fast</b> <b>and</b>
                <b>efficient</b>.

              • Indexes on fields and multi-column indexes are not supported.

              The <b>FTS5</b> extension comes with a built-in implementation of the BM25 ranking  function.  Therefore,
              the  <b>search</b>  and  <b>search_bm25</b>  methods  have  been overridden to use the builtin ranking functions
              rather than user-defined functions.

              <b>classmethod</b> <b>fts5_installed()</b>
                     Return a boolean indicating  whether  the  FTS5  extension  is  installed.  If  it  is  not
                     installed, an attempt will be made to load the extension.

              <b>classmethod</b> <b>search(term[,</b> <b>weights=None[,</b> <b>with_score=False[,</b> <b>score_alias='score']]])</b>

                     <b>Parameters</b>

                            • <b>term</b> (<u>str</u>) -- Search term to use.

                            • <b>weights</b> -- A list of weights for the columns, ordered with respect to the column's
                              position  in  the  table.  <b>Or</b>,  a  dictionary keyed by the field or field name and
                              mapped to a value.

                            • <b>with_score</b> -- Whether  the  score  should  be  returned  as  part  of  the  <b>SELECT</b>
                              statement.

                            • <b>score_alias</b>  (<u>str</u>)  --  Alias  to  use for the calculated rank score.  This is the
                              attribute you will use to access the score if <b>with_score=True</b>.

                            • <b>explicit_ordering</b> (<u>bool</u>) -- Order using full SQL function to  calculate  rank,  as
                              opposed to simply referencing the score alias in the ORDER BY clause.

                     Shorthand  way of searching for a term and sorting results by the quality of the match. The
                     <b>FTS5</b> extension provides a built-in implementation of the BM25 algorithm, which is  used  to
                     rank the results by relevance.

                     Higher scores correspond to better matches.

                        # Simple search.
                        docs = DocumentIndex.search('search term')
                        for result in docs:
                            print(result.title)

                        # More complete example.
                        docs = DocumentIndex.search(
                            'search term',
                            weights={'title': 2.0, 'content': 1.0},
                            with_score=True,
                            score_alias='search_score')
                        for result in docs:
                            print(result.title, result.search_score)

              <b>classmethod</b> <b>search_bm25(term[,</b> <b>weights=None[,</b> <b>with_score=False[,</b> <b>score_alias='score']]])</b>
                     With FTS5, <u>search_bm25()</u> is identical to the <u>search()</u> method.

              <b>classmethod</b> <b>rank([col1_weight,</b> <b>col2_weight...coln_weight])</b>

                     <b>Parameters</b>
                            <b>col_weight</b>  (<u>float</u>)  -- (Optional) weight to give to the <u>ith</u> column of the model. By
                            default all columns have a weight of <b>1.0</b>.

                     Generate an expression that will calculate and return the quality of the search match using
                     the <u>BM25</u> <u>algorithm</u>.  This value can be used to sort the search results, with higher  scores
                     corresponding to better matches.

                     The  <u>rank()</u>  function accepts optional parameters that allow you to specify weights for the
                     various columns.  If no  weights  are  specified,  all  columns  are  considered  of  equal
                     importance.

                        query = (DocumentIndex
                                 .select(
                                     DocumentIndex,
                                     DocumentIndex.rank().alias('score'))
                                 .where(DocumentIndex.match('search phrase'))
                                 .order_by(DocumentIndex.rank()))

                        for search_result in query:
                            print(search_result.title, search_result.score)

                     <b>NOTE:</b>
                        The above code example is equivalent to calling the <u>search()</u> method:

                            query = DocumentIndex.search('search phrase', with_score=True)
                            for search_result in query:
                                print(search_result.title, search_result.score)

              <b>classmethod</b> <b>bm25([col1_weight,</b> <b>col2_weight...coln_weight])</b>
                     Because  FTS5  provides  built-in  support  for BM25, the <u>bm25()</u> method is identical to the
                     <u>rank()</u> method.

              <b>classmethod</b> <b>VocabModel([table_type='row'|'col'|'instance'[,</b> <b>table_name=None]])</b>

                     <b>Parameters</b>

                            • <b>table_type</b> (<u>str</u>) -- Either 'row', 'col' or 'instance'.

                            • <b>table_name</b>  --  Name  for  the  vocab   table.   If   not   specified,   will   be
                              "fts5tablename_v".

                     Generate  a model class suitable for accessing the <u>vocab</u> <u>table</u> corresponding to FTS5 search
                     index.

       <b>class</b> <b>TableFunction</b>
              Implement a user-defined table-valued function. Unlike a  simple  <u>scalar</u>  <u>or</u>  <u>aggregate</u>  function,
              which  returns  a  single  scalar  value, a table-valued function can return any number of rows of
              tabular data.

              Simple example:

                 from playhouse.sqlite_ext import TableFunction

                 class Series(TableFunction):
                     # Name of columns in each row of generated data.
                     columns = ['value']

                     # Name of parameters the function may be called with.
                     params = ['start', 'stop', 'step']

                     def initialize(self, start=0, stop=None, step=1):
                         """
                         Table-functions declare an initialize() method, which is
                         called with whatever arguments the user has called the
                         function with.
                         """
                         self.start = self.current = start
                         self.stop = stop or float('Inf')
                         self.step = step

                     def iterate(self, idx):
                         """
                         Iterate is called repeatedly by the SQLite database engine
                         until the required number of rows has been read **or** the
                         function raises a `StopIteration` signalling no more rows
                         are available.
                         """
                         if self.current &gt; self.stop:
                             raise StopIteration

                         ret, self.current = self.current, self.current + self.step
                         return (ret,)

                 # Register the table-function with our database, which ensures it
                 # is declared whenever a connection is opened.
                 db.table_function('series')(Series)

                 # Usage:
                 cursor = db.execute_sql('SELECT * FROM series(?, ?, ?)', (0, 5, 2))
                 for value, in cursor:
                     print(value)

              <b>NOTE:</b>
                 A <u>TableFunction</u> must be registered with a database connection before it can be used. To  ensure
                 the  table  function  is  always  available,  you  can  use the <u>SqliteDatabase.table_function()</u>
                 decorator to register the function with the database.

              <u>TableFunction</u> implementations must provide two attributes and  implement  two  methods,  described
              below.

              <b>columns</b>
                     A  list  containing  the  names  of  the columns for the data returned by the function. For
                     example, a function that is used to split a string on a delimiter might specify 3  columns:
                     <b>[substring,</b> <b>start_idx,</b> <b>end_idx]</b>.

              <b>params</b> The  names  of  the  parameters  the function may be called with. All parameters, including
                     optional parameters, should be listed. For example, a function that  is  used  to  split  a
                     string on a delimiter might specify 2 params: <b>[string,</b> <b>delimiter]</b>.

              <b>name</b>   <u>Optional</u>  -  specify  the  name for the table function. If not provided, name will be taken
                     from the class name.

              <b>print_tracebacks</b> <b>=</b> <b>True</b>
                     Print a full traceback for any errors that occur in the table-function's callback  methods.
                     When set to False, only the generic OperationalError will be visible.

              <b>initialize(**parameter_values)</b>

                     <b>Parameters</b>
                            <b>parameter_values</b> -- Parameters the function was called with.

                     <b>Returns</b>
                            No return value.

                     The  <b>initialize</b>  method  is called to initialize the table function with the parameters the
                     user specified when calling the function.

              <b>iterate(idx)</b>

                     <b>Parameters</b>
                            <b>idx</b> (<u>int</u>) -- current iteration step

                     <b>Returns</b>
                            A tuple of row data corresponding to the columns named in the <u>columns</u> attribute.

                     <b>Raises</b> <b>StopIteration</b> -- To signal that no more rows are available.

                     This function is called repeatedly and returns successive rows of data.  The  function  may
                     terminate  before  all  rows  are consumed (especially if the user specified a <b>LIMIT</b> on the
                     results). Alternatively, the function can signal that no more data is available by  raising
                     a <b>StopIteration</b> exception.

              <b>classmethod</b> <b>register(conn)</b>

                     <b>Parameters</b>
                            <b>conn</b> -- A <b>sqlite3.Connection</b> object.

                     Register  the  table  function  with  a  DB-API 2.0 <b>sqlite3.Connection</b> object. Table-valued
                     functions <b>must</b> be registered before they can be used in a query.

                     Example:

                        class MyTableFunction(TableFunction):
                            name = 'my_func'
                            # ... other attributes and methods ...

                        db = SqliteDatabase(':memory:')
                        db.connect()

                        MyTableFunction.register(db.connection())

                     To ensure the <u>TableFunction</u> is registered every  time  a  connection  is  opened,  use  the
                     <u>table_function()</u> decorator.

       <b>ClosureTable(model_class[,</b> <b>foreign_key=None[,</b> <b>referencing_class=None[,</b> <b>referencing_key=None]]])</b>

              <b>Parameters</b>

                     • <b>model_class</b> -- The model class containing the nodes in the tree.

                     • <b>foreign_key</b>  --  The  self-referential  parent-node  field  on  the  model  class. If not
                       provided, peewee will introspect the model to find a suitable key.

                     • <b>referencing_class</b> -- Intermediate table for a many-to-many relationship.

                     • <b>referencing_key</b> -- For a many-to-many relationship, the originating side of the relation.

              <b>Returns</b>
                     Returns a <u>VirtualModel</u> for working with a closure table.

              Factory function for creating a model class suitable for working with a <u>transitive</u> <u>closure</u>  table.
              Closure tables are <u>VirtualModel</u> subclasses that work with the transitive closure SQLite extension.
              These  special  tables  are  designed  to make it easy to efficiently query hierarchical data. The
              SQLite extension manages an AVL tree behind-the-scenes, transparently updating the tree when  your
              table changes and making it easy to perform common queries on hierarchical data.

              To use the closure table extension in your project, you need:

              1. A  copy  of the SQLite extension. The source code can be found in the <u>SQLite</u> <u>code</u> <u>repository</u> or
                 by cloning <u>this</u> <u>gist</u>:

                    $ git clone https://gist.github.com/coleifer/7f3593c5c2a645913b92 closure
                    $ cd closure/

              2. Compile the extension as a shared library, e.g.

                    $ gcc -g -fPIC -shared closure.c -o closure.so

              3. Create a model for your hierarchical data. The only requirement here is that the model  has  an
                 integer primary key and a self-referential foreign key. Any additional fields are fine.

                    class Category(Model):
                        name = CharField()
                        metadata = TextField()
                        parent = ForeignKeyField('self', index=True, null=True)  # Required.

                    # Generate a model for the closure virtual table.
                    CategoryClosure = ClosureTable(Category)

                 The  self-referentiality  can  also  be  achieved via an intermediate table (for a many-to-many
                 relation).

                    class User(Model):
                        name = CharField()

                    class UserRelations(Model):
                        user = ForeignKeyField(User)
                        knows = ForeignKeyField(User, backref='_known_by')

                        class Meta:
                            primary_key = CompositeKey('user', 'knows') # Alternatively, a unique index on both columns.

                    # Generate a model for the closure virtual table, specifying the UserRelations as the referencing table
                    UserClosure = ClosureTable(
                        User,
                        referencing_class=UserRelations,
                        foreign_key=UserRelations.knows,
                        referencing_key=UserRelations.user)

              4. In your application code, make sure you load the extension when you instantiate  your  <u>Database</u>
                 object. This is done by passing the path to the shared library to the <b>load_extension()</b> method.

                    db = SqliteExtDatabase('my_database.db')
                    db.load_extension('/path/to/closure')

              <b>WARNING:</b>
                 There  are  two  caveats  you  should  be aware of when using the <b>transitive_closure</b> extension.
                 First, it requires that your <u>source</u> <u>model</u> have an integer primary key. Second, it  is  strongly
                 recommended that you create an index on the self-referential foreign key.

              Example:

                 class Category(Model):
                     name = CharField()
                     metadata = TextField()
                     parent = ForeignKeyField('self', index=True, null=True)  # Required.

                 # Generate a model for the closure virtual table.
                 CategoryClosure = ClosureTable(Category)

                  # Create the tables if they do not exist.
                  db.create_tables([Category, CategoryClosure], True)

              It is now possible to perform interesting queries using the data from the closure table:

                 # Get all ancestors for a particular node.
                 laptops = Category.get(Category.name == 'Laptops')
                 for parent in Closure.ancestors(laptops):
                     print(parent.name)

                 # Computer Hardware
                 # Computers
                 # Electronics
                 # All products

                 # Get all descendants for a particular node.
                 hardware = Category.get(Category.name == 'Computer Hardware')
                 for node in Closure.descendants(hardware):
                     print(node.name)

                 # Laptops
                 # Desktops
                 # Hard-drives
                 # Monitors
                 # LCD Monitors
                 # LED Monitors

              API of the <u>VirtualModel</u> returned by <u>ClosureTable()</u>.

              <b>class</b> <b>BaseClosureTable</b>

                     <b>id</b>     A field for the primary key of the given node.

                     <b>depth</b>  A field representing the relative depth of the given node.

                     <b>root</b>   A field representing the relative root node.

                     <b>descendants(node[,</b> <b>depth=None[,</b> <b>include_node=False]])</b>
                            Retrieve  all  descendants of the given node. If a depth is specified, only nodes at
                            that depth (relative to the given node) will be returned.

                               node = Category.get(Category.name == 'Electronics')

                               # Direct child categories.
                               children = CategoryClosure.descendants(node, depth=1)

                               # Grand-child categories.
                               children = CategoryClosure.descendants(node, depth=2)

                               # Descendants at all depths.
                               all_descendants = CategoryClosure.descendants(node)

                     <b>ancestors(node[,</b> <b>depth=None[,</b> <b>include_node=False]])</b>
                            Retrieve all ancestors of the given node. If a depth is  specified,  only  nodes  at
                            that depth (relative to the given node) will be returned.

                               node = Category.get(Category.name == 'Laptops')

                               # All ancestors.
                               all_ancestors = CategoryClosure.ancestors(node)

                               # Grand-parent category.
                               grandparent = CategoryClosure.ancestores(node, depth=2)

                     <b>siblings(node[,</b> <b>include_node=False])</b>
                            Retrieve all nodes that are children of the specified node's parent.

              <b>NOTE:</b>
                 For  an  in-depth  discussion  of  the SQLite transitive closure extension, check out this blog
                 post, <u>Querying</u> <u>Tree</u> <u>Structures</u> <u>in</u> <u>SQLite</u> <u>using</u> <u>Python</u> <u>and</u> <u>the</u> <u>Transitive</u> <u>Closure</u> <u>Extension</u>.

       <b>class</b> <b>LSMTable</b>
              <u>VirtualModel</u> subclass suitable for working with the <u>lsm1</u> <u>extension</u> The <u>lsm1</u> extension is a virtual
              table that provides a SQL interface to the <u>lsm</u> <u>key/value</u> <u>storage</u> <u>engine</u> <u>from</u> <u>SQLite4</u>.

              <b>NOTE:</b>
                 The LSM1 extension has not been released yet (SQLite version  3.22  at  time  of  writing),  so
                 consider this feature experimental with potential to change in subsequent releases.

              LSM  tables  define  one  primary  key  column and an arbitrary number of additional value columns
              (which are serialized and stored in a single value field in the storage engine). The  primary  key
              must be all of the same type and use one of the following field types:

              • <u>IntegerField</u>

              • <u>TextField</u>

              • <u>BlobField</u>

              Since  the  LSM  storage  engine  is  a key/value store, primary keys (including integers) must be
              specified by the application.

              <b>ATTENTION:</b>
                 Secondary indexes are not supported by the LSM engine, so the only efficient  queries  will  be
                 lookups  (or  range  queries) on the primary key.  Other fields can be queried and filtered on,
                 but may result in a full table-scan.

              Example model declaration:

                 db = SqliteExtDatabase('my_app.db')
                 db.load_extension('lsm.so')  # Load shared library.

                 class EventLog(LSMTable):
                     timestamp = IntegerField(primary_key=True)
                     action = TextField()
                     sender = TextField()
                     target = TextField()

                     class Meta:
                         database = db
                         filename = 'eventlog.ldb'  # LSM data is stored in separate db.

                 # Declare virtual table.
                 EventLog.create_table()

              Example queries:

                 # Use dictionary operators to get, set and delete rows from the LSM
                 # table. Slices may be passed to represent a range of key values.
                 def get_timestamp():
                     # Return time as integer expressing time in microseconds.
                     return int(time.time() * 1000000)

                 # Create a new row, at current timestamp.
                 ts = get_timestamp()
                 EventLog[ts] = ('pageview', 'search', '/blog/some-post/')

                 # Retrieve row from event log.
                 log = EventLog[ts]
                 print(log.action, log.sender, log.target)
                 # Prints ("pageview", "search", "/blog/some-post/")

                 # Delete the row.
                 del EventLog[ts]

                 # We can also use the "create()" method.
                 EventLog.create(
                     timestamp=get_timestamp(),
                     action='signup',
                     sender='newsletter',
                     target='sqlite-news')

              Simple key/value model declaration:

                 class KV(LSMTable):
                     key = TextField(primary_key=True)
                     value = TextField()

                     class Meta:
                         database = db
                         filename = 'kv.ldb'

                 db.create_tables([KV])

              For tables consisting of a single value field, Peewee will return the value directly when  getting
              a  single  item. You can also request slices of rows, in which case Peewee returns a corresponding
              <u>Select</u> query, which can be iterated over. Below are some examples:

                 &gt;&gt;&gt; KV['k0'] = 'v0'
                 &gt;&gt;&gt; print(KV['k0'])
                 'v0'

                 &gt;&gt;&gt; data = [{'key': 'k%d' % i, 'value': 'v%d' % i} for i in <a href="../man20/range.20.html">range</a>(20)]
                 &gt;&gt;&gt; KV.insert_many(data).execute()

                 &gt;&gt;&gt; KV.select().count()
                 20

                 &gt;&gt;&gt; KV['k8']
                 'v8'

                 &gt;&gt;&gt; list(KV['k4.1':'k7.x']
                 [Row(key='k5', value='v5'),
                  Row(key='k6', value='v6'),
                  Row(key='k7', value='v7')]

                 &gt;&gt;&gt; list(KV['k6xxx':])
                 [Row(key='k7', value='v7'),
                  Row(key='k8', value='v8'),
                  Row(key='k9', value='v9')]

              You can also index the <u>LSMTable</u> using expressions:

                 &gt;&gt;&gt; list(KV[KV.key &gt; 'k6'])
                 [Row(key='k7', value='v7'),
                  Row(key='k8', value='v8'),
                  Row(key='k9', value='v9')]

                 &gt;&gt;&gt; list(KV[(KV.key &gt; 'k6') &amp; (KV.value != 'v8')])
                 [Row(key='k7', value='v7'),
                  Row(key='k9', value='v9')]

              You can delete single rows using <b>del</b> or multiple rows using slices or expressions:

                 &gt;&gt;&gt; del KV['k1']
                 &gt;&gt;&gt; del KV['k3x':'k8']
                 &gt;&gt;&gt; del KV[KV.key.between('k10', 'k18')]

                 &gt;&gt;&gt; list(KV[:])
                 [Row(key='k0', value='v0'),
                  Row(key='k19', value='v19'),
                  Row(key='k2', value='v2'),
                  Row(key='k3', value='v3'),
                  Row(key='k9', value='v9')]

              Attempting to get a single non-existant key will result in a <b>DoesNotExist</b>,  but  slices  will  not
              raise an exception:

                 &gt;&gt;&gt; KV['k1']
                 ...
                 KV.DoesNotExist: &lt;Model:KV&gt; instance matching query does not exist: ...

                 &gt;&gt;&gt; list(KV['k1':'k1'])
                 []

       <b>class</b> <b>ZeroBlob(length)</b>

              <b>Parameters</b>
                     <b>length</b> (<u>int</u>) -- Size of blob in bytes.

              <u>ZeroBlob</u>  is used solely to reserve space for storing a BLOB that supports incremental I/O. To use
              the <u>SQLite</u> <u>BLOB-store</u> it is necessary to first insert a ZeroBlob of the desired size into the  row
              you wish to use with incremental I/O.

              For example, see <u>Blob</u>.

       <b>class</b> <b>Blob(database,</b> <b>table,</b> <b>column,</b> <b>rowid[,</b> <b>read_only=False])</b>

              <b>Parameters</b>

                     • <b>database</b> -- <u>SqliteExtDatabase</u> instance.

                     • <b>table</b> (<u>str</u>) -- Name of table being accessed.

                     • <b>column</b> (<u>str</u>) -- Name of column being accessed.

                     • <b>rowid</b> (<u>int</u>) -- Primary-key of row being accessed.

                     • <b>read_only</b> (<u>bool</u>) -- Prevent any modifications to the blob data.

              Open  a  blob, stored in the given table/column/row, for incremental I/O.  To allocate storage for
              new data, you can use the <u>ZeroBlob</u>, which is very efficient.

                 class RawData(Model):
                     data = BlobField()

                 # Allocate 100MB of space for writing a large file incrementally:
                 query = RawData.insert({'data': ZeroBlob(1024 * 1024 * 100)})
                 rowid = query.execute()

                 # Now we can open the row for incremental I/O:
                 blob = Blob(db, 'rawdata', 'data', rowid)

                 # Read from the file and write to the blob in chunks of 4096 bytes.
                 while True:
                     data = <a href="../man4096/file_handle.read.4096.html">file_handle.read</a>(4096)
                     if not data:
                         break
                     blob.write(data)

                 bytes_written = blob.tell()
                 blob.close()

              <b>read([n=None])</b>

                     <b>Parameters</b>
                            <b>n</b> (<u>int</u>) -- Only read up to <u>n</u> bytes from current position in file.

                     Read up to <u>n</u> bytes from the current position in the blob file. If <u>n</u> is not  specified,  the
                     entire blob will be read.

              <b>seek(offset[,</b> <b>whence=0])</b>

                     <b>Parameters</b>

                            • <b>offset</b> (<u>int</u>) -- Seek to the given offset in the file.

                            • <b>whence</b> (<u>int</u>) -- Seek relative to the specified frame of reference.

                     Values for <b>whence</b>:

                     • <b>0</b>: beginning of file

                     • <b>1</b>: current position

                     • <b>2</b>: end of file

              <b>tell()</b> Return current offset within the file.

              <b>write(data)</b>

                     <b>Parameters</b>
                            <b>data</b> (<u>bytes</u>) -- Data to be written

                     Writes the given data, starting at the current position in the file.

              <b>close()</b>
                     Close the file and free associated resources.

              <b>reopen(rowid)</b>

                     <b>Parameters</b>
                            <b>rowid</b> (<u>int</u>) -- Primary key of row to open.

                     If a blob has already been opened for a given table/column, you can use the <u>reopen()</u> method
                     to re-use the same <u>Blob</u> object for accessing multiple rows in the table.

   <b>Additional</b> <b>Features</b>
       The  <u>SqliteExtDatabase</u>  accepts  an  initialization option to register support for a simple <u>bloom</u> <u>filter</u>.
       The bloom filter, once initialized, can then be used for efficient membership queries  on  large  set  of
       data.

       Here's an example:

          db = CSqliteExtDatabase(':memory:', bloomfilter=True)

          # Create and define a table to store some data.
          db.execute_sql('CREATE TABLE "register" ("data" TEXT)')
          Register = Table('register', ('data',)).bind(db)

          # Populate the database with a bunch of text.
          with db.atomic():
              for i in 'abcdefghijklmnopqrstuvwxyz':
                  keys = [i * j for j in range(1, 10)]  # a, aa, aaa, ... aaaaaaaaa
                  Register.insert([{'data': key} for key in keys]).execute()

          # Collect data into a 16KB bloomfilter.
          query = Register.select(fn.bloomfilter(Register.data, 16 * 1024).alias('buf'))
          row = query.get()
          buf = row['buf']

          # Use bloomfilter buf to test whether other keys are members.
          test_keys = (
              ('aaaa', True),
              ('abc', False),
              ('zzzzzzz', True),
              ('zyxwvut', False))
          for key, is_present in test_keys:
              query = Register.select(fn.bloomfilter_contains(key, buf).alias('is_member'))
              answer = query.get()['is_member']
              assert answer == is_present

       The <u>SqliteExtDatabase</u> can also register other useful functions:

       • <b>rank_functions</b>  (enabled  by default): registers functions for ranking search results, such as <u>bm25</u> and
         <u>lucene</u>.

       • <b>hash_functions</b>: registers md5, sha1, sha256, adler32, crc32 and murmurhash functions.

       • <b>regexp_function</b>: registers a regexp function.

       Examples:

          def create_new_user(username, password):
              # DO NOT DO THIS IN REAL LIFE. PLEASE.
              query = User.insert({'username': username, 'password': fn.sha1(password)})
              new_user_id = query.execute()

       You can use the <u>murmurhash</u> function to hash bytes to an integer for compact storage:

          &gt;&gt;&gt; db = SqliteExtDatabase(':memory:', hash_functions=True)
          &gt;&gt;&gt; db.execute_sql('SELECT murmurhash(?)', ('abcdefg',)).fetchone()
          (4188131059,)

   <b>Playhouse,</b> <b>extensions</b> <b>to</b> <b>Peewee</b>
       Peewee comes with numerous extension modules which are collected under the <b>playhouse</b>  namespace.  Despite
       the  silly  name,  there  are some very useful extensions, particularly those that expose vendor-specific
       database features like the <u>SQLite</u> <u>Extensions</u> and <u>Postgresql</u> <u>Extensions</u> extensions.

       Below you will find a loosely organized listing of the various modules that make up the <b>playhouse</b>.

       <b>Database</b> <b>drivers</b> <b>/</b> <b>vendor-specific</b> <b>database</b> <b>functionality</b>

       • <u>SQLite</u> <u>Extensions</u> (on its own page)

       • <u>SqliteQ</u>

       • <u>Sqlite</u> <u>User-Defined</u> <u>Functions</u>

       • <u>apsw,</u> <u>an</u> <u>advanced</u> <u>sqlite</u> <u>driver</u>

       • <u>Sqlcipher</u> <u>backend</u>

       • <u>Postgresql</u> <u>Extensions</u>

       • <u>Cockroach</u> <u>Database</u>

       • <u>MySQL</u> <u>Extensions</u>

       <b>High-level</b> <b>features</b>

       • <u>Fields</u>

       • <u>Shortcuts</u>

       • <u>Hybrid</u> <u>Attributes</u>

       • <u>Key/Value</u> <u>Store</u>

       • <u>Signal</u> <u>support</u>

       • <u>DataSet</u>

       <b>Database</b> <b>management</b> <b>and</b> <b>framework</b> <b>integration</b>

       • <u>pwiz,</u> <u>a</u> <u>model</u> <u>generator</u>

       • <u>Schema</u> <u>Migrations</u>

       • <u>Connection</u> <u>pool</u>

       • <u>Reflection</u>

       • <u>Database</u> <u>URL</u>

       • <u>Test</u> <u>Utils</u>

       • <u>Flask</u> <u>Utils</u>

   <b>Sqlite</b> <b>Extensions</b>
       The Sqlite extensions have been moved to <u>their</u> <u>own</u> <u>page</u>.

   <b>SqliteQ</b>
       The <b>playhouse.sqliteq</b> module provides a subclass of <u>SqliteExtDatabase</u>,  that  will  serialize  concurrent
       writes  to  a  SQLite  database. <b>SqliteQueueDatabase</b> can be used as a drop-in replacement for the regular
       <u>SqliteDatabase</u> if you want simple <b>read</b> <b>and</b> <b>write</b> access to a SQLite database from <b>multiple</b> <b>threads</b>.

       SQLite only allows one connection to write to the database at any given time.  As a result, if you have a
       multi-threaded application (like a web-server, for example) that needs to write to the database, you  may
       see occasional errors when one or more of the threads attempting to write cannot acquire the lock.

       <b>SqliteQueueDatabase</b>  is  designed  to  simplify  things  by  sending  all write queries through a single,
       long-lived connection. The benefit is that you get the appearance of  multiple  threads  writing  to  the
       database  without  conflicts  or  timeouts.  The  downside,  however,  is  that  you  cannot  issue write
       transactions that encompass multiple queries -- all writes run in autocommit mode, essentially.

       <b>NOTE:</b>
          The module gets its name from the fact that all write queries get put  into  a  thread-safe  queue.  A
          single worker thread listens to the queue and executes all queries that are sent to it.

   <b>Transactions</b>
       Because  all  queries  are  serialized  and  executed  by  a  single  worker  thread,  it is possible for
       transactional SQL from  separate  threads  to  be  executed  out-of-order.  In  the  example  below,  the
       transaction started by thread "B" is rolled back by thread "A" (with bad consequences!):

       • Thread A: UPDATE transplants SET organ='liver', ...;

       • Thread B: BEGIN TRANSACTION;

       • Thread B: UPDATE life_support_system SET timer += 60 ...;

       • Thread A: ROLLBACK; -- Oh no....

       Since  there  is  a potential for queries from separate transactions to be interleaved, the <b>transaction()</b>
       and <b>atomic()</b> methods are disabled on <b>SqliteQueueDatabase</b>.

       For cases when you wish to temporarily write to the database from a different thread,  you  can  use  the
       <b>pause()</b>  and  <b>unpause()</b>  methods. These methods block the caller until the writer thread is finished with
       its current workload. The writer then disconnects and the caller takes over until <b>unpause</b> is called.

       The <b>stop()</b>, <b>start()</b>, and <b>is_stopped()</b> methods can also be used to control the writer thread.

       <b>NOTE:</b>
          Take a look at SQLite's  <u>isolation</u>  documentation  for  more  information  about  how  SQLite  handles
          concurrent connections.

   <b>Code</b> <b>sample</b>
       Creating  a database instance does not require any special handling. The <b>SqliteQueueDatabase</b> accepts some
       special parameters which you should be aware of, though. If  you  are  using  <u>gevent</u>,  you  must  specify
       <b>use_gevent=True</b>  when  instantiating  your  database  -- this way Peewee will know to use the appropriate
       objects for handling queueing, thread creation, and locking.

          from playhouse.sqliteq import SqliteQueueDatabase

          db = SqliteQueueDatabase(
              'my_app.db',
              use_gevent=False,  # Use the standard library "threading" module.
              autostart=False,  # The worker thread now must be started manually.
              queue_max_size=64,  # Max. # of pending writes that can accumulate.
              results_timeout=5.0)  # Max. time to wait for query to be executed.

       If <b>autostart=False</b>, as in the above example, you will need to call <b>start()</b> to bring up the worker threads
       that will do the actual write query execution.

          @app.before_first_request
          def _start_worker_threads():
              db.start()

       If you plan on performing SELECT queries or generally wanting to access the database, you  will  need  to
       call <u>connect()</u> and <u>close()</u> as you would with any other database instance.

       When  your  application  is  ready to terminate, use the <b>stop()</b> method to shut down the worker thread. If
       there was a backlog of work, then this method will block until all pending work is  finished  (though  no
       new work is allowed).

          import atexit

          @atexit.register
          def _stop_worker_threads():
              db.stop()

       Lastly, the <b>is_stopped()</b> method can be used to determine whether the database writer is up and running.

   <b>Sqlite</b> <b>User-Defined</b> <b>Functions</b>
       The <b>sqlite_udf</b> playhouse module contains a number of user-defined functions, aggregates, and table-valued
       functions,  which  you  may  find  useful.  The functions are grouped in collections and you can register
       these user-defined extensions individually, by collection, or register everything.

       Scalar functions are functions which take a number of parameters and return a single value. For  example,
       converting a string to upper-case, or calculating the MD5 hex digest.

       Aggregate  functions  are like scalar functions that operate on multiple rows of data, producing a single
       result. For example, calculating the sum of a list of integers,  or  finding  the  smallest  value  in  a
       particular column.

       Table-valued  functions  are  simply  functions  that  can  return  multiple rows of data. For example, a
       regular-expression search function that returns all the matches in a given string,  or  a  function  that
       accepts two dates and generates all the intervening days.

       <b>NOTE:</b>
          To use table-valued functions, you will need to build the <b>playhouse._sqlite_ext</b> C extension.

       Registering user-defined functions:

          db = SqliteDatabase('my_app.db')

          # Register *all* functions.
          register_all(db)

          # Alternatively, you can register individual groups. This will just
          # register the DATE and MATH groups of functions.
          register_groups(db, 'DATE', 'MATH')

          # If you only wish to register, say, the aggregate functions for a
          # particular group or groups, you can:
          register_aggregate_groups(db, 'DATE')

          # If you only wish to register a single function, then you can:
          from playhouse.sqlite_udf import gzip, gunzip
          db.register_function(gzip, 'gzip')
          db.register_function(gunzip, 'gunzip')

       Using a library function ("hostname"):

          # Assume we have a model, Link, that contains lots of arbitrary URLs.
          # We want to discover the most common hosts that have been linked.
          query = (Link
                   .select(fn.hostname(Link.url).alias('host'), fn.COUNT(Link.id))
                   .group_by(fn.hostname(Link.url))
                   .order_by(fn.COUNT(Link.id).desc())
                   .tuples())

          # Print the hostname along with number of links associated with it.
          for host, count in query:
              print('%s: %s' % (host, count))

   <b>Functions,</b> <b>listed</b> <b>by</b> <b>collection</b> <b>name</b>
       Scalar functions are indicated by <b>(f)</b>, aggregate functions by <b>(a)</b>, and table-valued functions by <b>(t)</b>.

       <b>CONTROL_FLOW</b>

       <b>if_then_else(cond,</b> <b>truthy[,</b> <b>falsey=None])</b>
              Simple ternary-type operator, where, depending on the truthiness of the <b>cond</b> parameter, either the
              <b>truthy</b> or <b>falsey</b> value will be returned.

       <b>DATE</b>

       <b>strip_tz(date_str)</b>

              <b>Parameters</b>
                     <b>date_str</b> -- A datetime, encoded as a string.

              <b>Returns</b>
                     The datetime with any timezone info stripped off.

              The time is not adjusted in any way, the timezone is simply removed.

       <b>humandelta(nseconds[,</b> <b>glue=',</b> <b>'])</b>

              <b>Parameters</b>

                     • <b>nseconds</b> (<u>int</u>) -- Number of seconds, total, in timedelta.

                     • <b>glue</b> (<u>str</u>) -- Fragment to join values.

              <b>Returns</b>
                     Easy-to-read description of timedelta.

              Example, 86471 -&gt; "1 day, 1 minute, 11 seconds"

       <b>mintdiff(datetime_value)</b>

              <b>Parameters</b>
                     <b>datetime_value</b> -- A date-time.

              <b>Returns</b>
                     Minimum difference between any two values in list.

              Aggregate function that computes the minimum difference between any two datetimes.

       <b>avgtdiff(datetime_value)</b>

              <b>Parameters</b>
                     <b>datetime_value</b> -- A date-time.

              <b>Returns</b>
                     Average difference between values in list.

              Aggregate function that computes the average difference between consecutive values in the list.

       <b>duration(datetime_value)</b>

              <b>Parameters</b>
                     <b>datetime_value</b> -- A date-time.

              <b>Returns</b>
                     Duration from smallest to largest value in list, in seconds.

              Aggregate  function that computes the duration from the smallest to the largest value in the list,
              returned in seconds.

       <b>date_series(start,</b> <b>stop[,</b> <b>step_seconds=86400])</b>

              <b>Parameters</b>

                     • <b>start</b> (<u>datetime</u>) -- Start datetime

                     • <b>stop</b> (<u>datetime</u>) -- Stop datetime

                     • <b>step_seconds</b> (<u>int</u>) -- Number of seconds comprising a step.

              Table-value function that returns rows consisting of the date/+time values  encountered  iterating
              from start to stop, <b>step_seconds</b> at a time.

              Additionally, if start does not have a time component and step_seconds is greater-than-or-equal-to
              one  day  (86400 seconds), the values returned will be dates. Conversely, if start does not have a
              date component, values will be returned as times. Otherwise values are returned as datetimes.

              Example:

                 SELECT * FROM date_series('2017-01-28', '2017-02-02');

                 value
                 -----
                 2017-01-28
                 2017-01-29
                 2017-01-30
                 2017-01-31
                 2017-02-01
                 2017-02-02

       <b>FILE</b>

       <b>file_ext(filename)</b>

              <b>Parameters</b>
                     <b>filename</b> (<u>str</u>) -- Filename to extract extension from.

              <b>Returns</b>
                     Returns the file extension, including the leading ".".

       <b>file_read(filename)</b>

              <b>Parameters</b>
                     <b>filename</b> (<u>str</u>) -- Filename to read.

              <b>Returns</b>
                     Contents of the file.

       <b>HELPER</b>

       <b>gzip(data[,</b> <b>compression=9])</b>

              <b>Parameters</b>

                     • <b>data</b> (<u>bytes</u>) -- Data to compress.

                     • <b>compression</b> (<u>int</u>) -- Compression level (9 is max).

              <b>Returns</b>
                     Compressed binary data.

       <b>gunzip(data)</b>

              <b>Parameters</b>
                     <b>data</b> (<u>bytes</u>) -- Compressed data.

              <b>Returns</b>
                     Uncompressed binary data.

       <b>hostname(url)</b>

              <b>Parameters</b>
                     <b>url</b> (<u>str</u>) -- URL to extract hostname from.

              <b>Returns</b>
                     hostname portion of URL

       <b>toggle(key)</b>

              <b>Parameters</b>
                     <b>key</b> -- Key to toggle.

              Toggle a key between True/False state. Example:

                 &gt;&gt;&gt; toggle('my-key')
                 True
                 &gt;&gt;&gt; toggle('my-key')
                 False
                 &gt;&gt;&gt; toggle('my-key')
                 True

       <b>setting(key[,</b> <b>value=None])</b>

              <b>Parameters</b>

                     • <b>key</b> -- Key to set/retrieve.

                     • <b>value</b> -- Value to set.

              <b>Returns</b>
                     Value associated with key.

              Store/retrieve a setting in memory and persist during lifetime of application. To get the  current
              value, only specify the key. To set a new value, call with key and new value.

       <b>clear_toggles()</b>
              Clears all state associated with the <u>toggle()</u> function.

       <b>clear_settings()</b>
              Clears all state associated with the <u>setting()</u> function.

       <b>MATH</b>

       <b>randomrange(start[,</b> <b>stop=None[,</b> <b>step=None]])</b>

              <b>Parameters</b>

                     • <b>start</b> (<u>int</u>) -- Start of range (inclusive)

                     • <b>end</b> (<u>int</u>) -- End of range(not inclusive)

                     • <b>step</b> (<u>int</u>) -- Interval at which to return a value.

              Return a random integer between <b>[start,</b> <b>end)</b>.

       <b>gauss_distribution(mean,</b> <b>sigma)</b>

              <b>Parameters</b>

                     • <b>mean</b> (<u>float</u>) -- Mean value

                     • <b>sigma</b> (<u>float</u>) -- Standard deviation

       <b>sqrt(n)</b>
              Calculate the square root of <b>n</b>.

       <b>tonumber(s)</b>

              <b>Parameters</b>
                     <b>s</b> (<u>str</u>) -- String to convert to number.

              <b>Returns</b>
                     Integer, floating-point or NULL on failure.

       <b>mode(val)</b>

              <b>Parameters</b>
                     <b>val</b> -- Numbers in list.

              <b>Returns</b>
                     The mode, or most-common, number observed.

              Aggregate function which calculates <u>mode</u> of values.

       <b>minrange(val)</b>

              <b>Parameters</b>
                     <b>val</b> -- Value

              <b>Returns</b>
                     Min difference between two values.

              Aggregate function which calculates the minimal distance between two numbers in the sequence.

       <b>avgrange(val)</b>

              <b>Parameters</b>
                     <b>val</b> -- Value

              <b>Returns</b>
                     Average difference between values.

              Aggregate  function  which  calculates the average distance between two consecutive numbers in the
              sequence.

       <b>range(val)</b>

              <b>Parameters</b>
                     <b>val</b> -- Value

              <b>Returns</b>
                     The range from the smallest to largest value in sequence.

              Aggregate function which returns range of values observed.

       <b>median(val)</b>

              <b>Parameters</b>
                     <b>val</b> -- Value

              <b>Returns</b>
                     The median, or middle, value in a sequence.

              Aggregate function which calculates the middle value in a sequence.

              <b>NOTE:</b>
                 Only available if you compiled the <b>_sqlite_udf</b> extension.

       <b>STRING</b>

       <b>substr_count(haystack,</b> <b>needle)</b>
              Returns number of times <b>needle</b> appears in <b>haystack</b>.

       <b>strip_chars(haystack,</b> <b>chars)</b>
              Strips any characters in <b>chars</b> from beginning and end of <b>haystack</b>.

       <b>damerau_levenshtein_dist(s1,</b> <b>s2)</b>
              Computes the edit distance from s1 to s2 using the damerau variant of the levenshtein algorithm.

              <b>NOTE:</b>
                 Only available if you compiled the <b>_sqlite_udf</b> extension.

       <b>levenshtein_dist(s1,</b> <b>s2)</b>
              Computes the edit distance from s1 to s2 using the levenshtein algorithm.

              <b>NOTE:</b>
                 Only available if you compiled the <b>_sqlite_udf</b> extension.

       <b>str_dist(s1,</b> <b>s2)</b>
              Computes the edit distance from s1 to s2 using the standard library SequenceMatcher's algorithm.

              <b>NOTE:</b>
                 Only available if you compiled the <b>_sqlite_udf</b> extension.

       <b>regex_search(regex,</b> <b>search_string)</b>

              <b>Parameters</b>

                     • <b>regex</b> (<u>str</u>) -- Regular expression

                     • <b>search_string</b> (<u>str</u>) -- String to search for instances of regex.

              Table-value function that searches a string for substrings that match the provided <b>regex</b>.  Returns
              rows for each match found.

              Example:

                 SELECT * FROM regex_search('\w+', 'extract words, ignore! symbols');

                 value
                 -----
                 extract
                 words
                 ignore
                 symbols

   <b>apsw,</b> <b>an</b> <b>advanced</b> <b>sqlite</b> <b>driver</b>
       The <b>apsw_ext</b> module contains a database class suitable for use with the apsw sqlite driver.

       APSW Project page: <u>https://github.com/rogerbinns/apsw</u>

       APSW  is  a  really  neat  library that provides a thin wrapper on top of SQLite's C interface, making it
       possible to use all of SQLite's advanced features.

       Here are just a few reasons to use APSW, taken from the documentation:

       • APSW gives all functionality of SQLite, including  virtual  tables,  virtual  file  system,  blob  i/o,
         backups and file control.

       • Connections can be shared across threads without any additional locking.

       • Transactions are managed explicitly by your code.

       • APSW can handle nested transactions.

       • Unicode is handled correctly.

       • APSW is faster.

       For more information on the differences between apsw and pysqlite, check <u>the</u> <u>apsw</u> <u>docs</u>.

   <b>How</b> <b>to</b> <b>use</b> <b>the</b> <b>APSWDatabase</b>
          from apsw_ext import *

          db = APSWDatabase(':memory:')

          class BaseModel(Model):
              class Meta:
                  database = db

          class SomeModel(BaseModel):
              col1 = CharField()
              col2 = DateTimeField()

   <b>apsw_ext</b> <b>API</b> <b>notes</b>
       <u>APSWDatabase</u> extends the <u>SqliteExtDatabase</u> and inherits its advanced features.

       <b>class</b> <b>APSWDatabase(database,</b> <b>**connect_kwargs)</b>

              <b>Parameters</b>

                     • <b>database</b> (<u>string</u>) -- filename of sqlite database

                     • <b>connect_kwargs</b> -- keyword arguments passed to apsw when opening a connection

              <b>register_module(mod_name,</b> <b>mod_inst)</b>
                     Provides  a  way  of  globally  registering  a  module.  For  more  information,  see the ‐
                     <u>documentation</u> <u>on</u> <u>virtual</u> <u>tables</u>.

                     <b>Parameters</b>

                            • <b>mod_name</b> (<u>string</u>) -- name to use for module

                            • <b>mod_inst</b> (<u>object</u>) -- an object implementing the <u>Virtual</u> <u>Table</u> interface

              <b><a href="../manmod_name/unregister_module.mod_name.html">unregister_module</a>(mod_name)</b>
                     Unregister a module.

                     <b>Parameters</b>
                            <b>mod_name</b> (<u>string</u>) -- name to use for module

       <b>NOTE:</b>
          Be sure to use the <b>Field</b> subclasses defined in the <b>apsw_ext</b>  module,  as  they  will  properly  handle
          adapting the data types for storage.

          For   example,   instead   of  using  <b>peewee.DateTimeField</b>,  be  sure  you  are  importing  and  using
          <b>playhouse.apsw_ext.DateTimeField</b>.

   <b>Sqlcipher</b> <b>backend</b>
       <b>NOTE:</b>
          Although this extention's code is short, it has not been  properly  peer-reviewed  yet  and  may  have
          introduced vulnerabilities.

       Also  note  that this code relies on <u>sqlcipher3</u> (python bindings) and <u>sqlcipher</u>, and the code there might
       have vulnerabilities as well, but since these are widely used crypto modules, we can expect  "short  zero
       days" there.

   <b>sqlcipher_ext</b> <b>API</b> <b>notes</b>
       <b>class</b> <b>SqlCipherDatabase(database,</b> <b>passphrase,</b> <b>**kwargs)</b>
              Subclass  of  <u>SqliteDatabase</u>  that  stores the database encrypted. Instead of the standard <b>sqlite3</b>
              backend, it uses <u>sqlcipher3</u>: a python wrapper for <u>sqlcipher</u>, which -- in turn -- is  an  encrypted
              wrapper  around  <b>sqlite3</b>,  so  the  API  is  <u>identical</u>  to  <u>SqliteDatabase</u>'s,  except  for  object
              construction parameters:

              <b>Parameters</b>

                     • <b>database</b> -- Path to encrypted database filename to open [or create].

                     • <b>passphrase</b> -- Database encryption passphrase: should be at least 8 character long, but it
                       is  <u>strongly</u>  <u>advised</u>  to  enforce  better   <u>passphrase</u>   <u>strength</u>   criteria   in   your
                       implementation.

              • If  the  <b>database</b>  file  doesn't exist, it will be <u>created</u> with encryption by a key derived from
                <b>passhprase</b>.

              • When trying to open an existing database, <b>passhprase</b> should be identical to the ones  used  when
                it was created. If the passphrase is incorrect, an error will be raised when first attempting to
                access the database.

              <b>rekey(passphrase)</b>

                     <b>Parameters</b>
                            <b>passphrase</b> (<u>str</u>) -- New passphrase for database.

                     Change the passphrase for database.

       <b>NOTE:</b>
          SQLCipher  can  be  configured  using  a  number  of  extension PRAGMAs. The list of PRAGMAs and their
          descriptions can be found in the <u>SQLCipher</u> <u>documentation</u>.

          For example to specify the number of PBKDF2 iterations for the key derivation (64K in  SQLCipher  3.x,
          256K in SQLCipher 4.x by default):

              # Use 1,000,000 iterations.
              db = SqlCipherDatabase('my_app.db', pragmas={'kdf_iter': 1000000})

          To use a cipher page-size of 16KB and a cache-size of 10,000 pages:

              db = SqlCipherDatabase('my_app.db', passphrase='secret!!!', pragmas={
                  'cipher_page_size': 1024 * 16,
                  'cache_size': 10000})  # 10,000 16KB pages, or 160MB.

       Example of prompting the user for a passphrase:

          db = SqlCipherDatabase(None)

          class BaseModel(Model):
              """Parent for all app's models"""
              class Meta:
                  # We won't have a valid db until user enters passhrase.
                  database = db

          # Derive our model subclasses
          class Person(BaseModel):
              name = TextField(primary_key=True)

          right_passphrase = False
          while not right_passphrase:
              db.init(
                  'testsqlcipher.db',
                  passphrase=get_passphrase_from_user())

              try:  # Actually execute a query against the db to test passphrase.
                  db.get_tables()
              except DatabaseError as exc:
                  # This error indicates the password was wrong.
                  if exc.args[0] == 'file is encrypted or is not a database':
                      tell_user_the_passphrase_was_wrong()
                      db.init(None)  # Reset the db.
                  else:
                      raise exc
              else:
                  # The password was correct.
                  right_passphrase = True

       See also: a slightly more elaborate <u>example</u>.

   <b>Postgresql</b> <b>Extensions</b>
       The postgresql extensions module provides a number of "postgres-only" functions, currently:

       • <u>json</u> <u>support</u>, including <u>jsonb</u> for Postgres 9.4.

       • <u>hstore</u> <u>support</u>

       • <u>server-side</u> <u>cursors</u>

       • <u>full-text</u> <u>search</u>

       • <u>ArrayField</u> field type, for storing arrays.

       • <u>HStoreField</u> field type, for storing key/value pairs.

       • <u>IntervalField</u> field type, for storing <b>timedelta</b> objects.

       • <u>JSONField</u> field type, for storing JSON data.

       • <u>BinaryJSONField</u> field type for the <b>jsonb</b> JSON data type.

       • <u>TSVectorField</u> field type, for storing full-text search data.

       • <u>DateTimeTZField</u> field type, a timezone-aware datetime field.

       In  the  future  I would like to add support for more of postgresql's features.  If there is a particular
       feature you would like to see added, please <u>open</u> <u>a</u> <u>Github</u> <u>issue</u>.

       <b>WARNING:</b>
          In order  to  start  using  the  features  described  below,  you  will  need  to  use  the  extension
          <u>PostgresqlExtDatabase</u> class instead of <u>PostgresqlDatabase</u>.

       The code below will assume you are using the following database and base model:

          from playhouse.postgres_ext import *

          ext_db = PostgresqlExtDatabase('peewee_test', user='postgres')

          class BaseExtModel(Model):
              class Meta:
                  database = ext_db

   <b>JSON</b> <b>Support</b>
       peewee  has  basic  support  for Postgres' native JSON data type, in the form of <u>JSONField</u>. As of version
       2.4.7, peewee also supports the Postgres 9.4 binary json <b>jsonb</b> type, via <u>BinaryJSONField</u>.

       <b>WARNING:</b>
          Postgres supports a JSON data type natively as of 9.2 (full support in 9.3).  In  order  to  use  this
          functionality you must be using the correct version of Postgres with <u>psycopg2</u> version 2.5 or greater.

          To use <u>BinaryJSONField</u>, which has many performance and querying advantages, you must have Postgres 9.4
          or later.

       <b>NOTE:</b>
          You must be sure your database is an instance of <u>PostgresqlExtDatabase</u> in order to use the <u>JSONField</u>.

       Here is an example of how you might declare a model with a JSON field:

          import json
          import urllib2
          from playhouse.postgres_ext import *

          db = PostgresqlExtDatabase('my_database')

          class APIResponse(Model):
              url = CharField()
              response = JSONField()

              class Meta:
                  database = db

              @classmethod
              def request(cls, url):
                  fh = urllib2.urlopen(url)
                  return cls.create(url=url, response=json.loads(fh.read()))

          APIResponse.create_table()

          # Store a JSON response.
          offense = APIResponse.request('<a href="http://crime-api.com/api/offense/">http://crime-api.com/api/offense/</a>')
          booking = APIResponse.request('<a href="http://crime-api.com/api/booking/">http://crime-api.com/api/booking/</a>')

          # Query a JSON data structure using a nested key lookup:
          offense_responses = APIResponse.select().where(
              APIResponse.response['meta']['model'] == 'offense')

          # Retrieve a sub-key for each APIResponse. By calling .as_json(), the
          # data at the sub-key will be returned as Python objects (dicts, lists,
          # etc) instead of serialized JSON.
          q = (APIResponse
               .select(
                 APIResponse.data['booking']['person'].as_json().alias('person'))
               .where(APIResponse.data['meta']['model'] == 'booking'))

          for result in q:
              print(result.person['name'], result.person['dob'])

       The  <u>BinaryJSONField</u>  works  the  same  and  supports  the  same operations as the regular <u>JSONField</u>, but
       provides several additional operations for testing <b>containment</b>. Using the binary json field, you can test
       whether  your  JSON  data  contains  other   partial   JSON   structures   (<u>contains()</u>,   <u>contains_any()</u>,
       <u>contains_all()</u>), or whether it is a subset of a larger JSON document (<u>contained_by()</u>).

       For more examples, see the <u>JSONField</u> and <u>BinaryJSONField</u> API documents below.

   <b>hstore</b> <b>support</b>
       <u>Postgresql</u> <u>hstore</u> is an embedded key/value store. With hstore, you can store arbitrary key/value pairs in
       your database alongside structured relational data.

       To use <b>hstore</b>, you need to specify an additional parameter when instantiating your <u>PostgresqlExtDatabase</u>:

          # Specify "register_hstore=True":
          db = PostgresqlExtDatabase('my_db', register_hstore=True)

       Currently the <b>postgres_ext</b> module supports the following operations:

       • Store and retrieve arbitrary dictionaries

       • Filter by key(s) or partial dictionary

       • Update/add one or more keys to an existing dictionary

       • Delete one or more keys from an existing dictionary

       • Select keys, values, or zip keys and values

       • Retrieve a slice of keys/values

       • Test for the existence of a key

       • Test that a key has a non-NULL value

   <b>Using</b> <b>hstore</b>
       To  start  with,  you  will  need  to  import  the  custom  database  class and the hstore functions from
       <b>playhouse.postgres_ext</b> (see above code snippet). Then, it is as simple as adding a  <u>HStoreField</u>  to  your
       model:

          class House(BaseExtModel):
              address = CharField()
              features = HStoreField()

       You can now store arbitrary key/value pairs on <b>House</b> instances:

          &gt;&gt;&gt; h = House.create(
          ...     address='123 Main St',
          ...     features={'garage': '2 cars', 'bath': '2 bath'})
          ...
          &gt;&gt;&gt; h_from_db = House.get(House.id == h.id)
          &gt;&gt;&gt; h_from_db.features
          {'bath': '2 bath', 'garage': '2 cars'}

       You can filter by individual key, multiple keys or partial dictionary:

          &gt;&gt;&gt; query = House.select()
          &gt;&gt;&gt; garage = query.where(House.features.contains('garage'))
          &gt;&gt;&gt; garage_and_bath = query.where(House.features.contains(['garage', 'bath']))
          &gt;&gt;&gt; twocar = query.where(House.features.contains({'garage': '2 cars'}))

       Suppose you want to do an atomic update to the house:

          &gt;&gt;&gt; new_features = House.features.update({'bath': '2.5 bath', 'sqft': '1100'})
          &gt;&gt;&gt; query = House.update(features=new_features)
          &gt;&gt;&gt; query.where(House.id == h.id).execute()
          1
          &gt;&gt;&gt; h = House.get(House.id == h.id)
          &gt;&gt;&gt; h.features
          {'bath': '2.5 bath', 'garage': '2 cars', 'sqft': '1100'}

       Or, alternatively an atomic delete:

          &gt;&gt;&gt; query = House.update(features=House.features.delete('bath'))
          &gt;&gt;&gt; query.where(House.id == h.id).execute()
          1
          &gt;&gt;&gt; h = House.get(House.id == h.id)
          &gt;&gt;&gt; h.features
          {'garage': '2 cars', 'sqft': '1100'}

       Multiple keys can be deleted at the same time:

          &gt;&gt;&gt; query = House.update(features=House.features.delete('garage', 'sqft'))

       You can select just keys, just values, or zip the two:

          &gt;&gt;&gt; for h in House.select(House.address, House.features.keys().alias('keys')):
          ...     print(h.address, h.keys)

          123 Main St [u'bath', u'garage']

          &gt;&gt;&gt; for h in House.select(House.address, House.features.values().alias('vals')):
          ...     print(h.address, h.vals)

          123 Main St [u'2 bath', u'2 cars']

          &gt;&gt;&gt; for h in House.select(House.address, House.features.items().alias('mtx')):
          ...     print(h.address, h.mtx)

          123 Main St [[u'bath', u'2 bath'], [u'garage', u'2 cars']]

       You can retrieve a slice of data, for example, all the garage data:

          &gt;&gt;&gt; query = House.select(House.address, House.features.slice('garage').alias('garage_data'))
          &gt;&gt;&gt; for house in query:
          ...     print(house.address, house.garage_data)

          123 Main St {'garage': '2 cars'}

       You can check for the existence of a key and filter rows accordingly:

          &gt;&gt;&gt; has_garage = House.features.exists('garage')
          &gt;&gt;&gt; for house in House.select(House.address, has_garage.alias('has_garage')):
          ...     print(house.address, house.has_garage)

          123 Main St True

          &gt;&gt;&gt; for house in House.select().where(House.features.exists('garage')):
          ...     print(house.address, house.features['garage'])  # &lt;-- just houses w/garage data

          123 Main St 2 cars

   <b>Interval</b> <b>support</b>
       Postgres supports durations through the <b>INTERVAL</b> data-type (<u>docs</u>).

       <b>class</b> <b>IntervalField([null=False[,</b> <b>...]])</b>
              Field class capable of storing Python <b>datetime.timedelta</b> instances.

              Example:

                 from datetime import timedelta

                 from playhouse.postgres_ext import *

                 db = PostgresqlExtDatabase('my_db')

                 class Event(Model):
                     location = CharField()
                     duration = IntervalField()
                     start_time = DateTimeField()

                     class Meta:
                         database = db

                     @classmethod
                     def get_long_meetings(cls):
                         return cls.select().where(cls.duration &gt; timedelta(hours=1))

   <b>Server-side</b> <b>cursors</b>
       When  psycopg2  executes  a  query,  normally  all  results are fetched and returned to the client by the
       backend. This can cause your application to use  a  lot  of  memory  when  making  large  queries.  Using
       server-side  cursors,  results  are  returned  a  little  at  a  time  (by default 2000 records). For the
       definitive reference, please see the <u>psycopg2</u> <u>documentation</u>.

       <b>NOTE:</b>
          To use server-side (or named) cursors, you must be using <u>PostgresqlExtDatabase</u>.

       To execute a query using a server-side cursor, simply wrap  your  select  query  using  the  <u>ServerSide()</u>
       helper:

          large_query = PageView.select()  # Build query normally.

          # Iterate over large query inside a transaction.
          for page_view in ServerSide(large_query):
              # do some interesting analysis here.
              pass

          # Server-side resources are released.

       If you would like all <b>SELECT</b> queries to automatically use a server-side cursor, you can specify this when
       creating your <u>PostgresqlExtDatabase</u>:

          from postgres_ext import PostgresqlExtDatabase

          ss_db = PostgresqlExtDatabase('my_db', server_side_cursors=True)

       <b>NOTE:</b>
          Server-side  cursors  live  only  as  long  as  the  transaction,  so  for this reason peewee will not
          automatically call <b>commit()</b> after executing a <b>SELECT</b> query. If you do not <b>commit</b> after  you  are  done
          iterating,  you  will  not  release  the  server-side resources until the connection is closed (or the
          transaction is committed later). Furthermore, since peewee will by default cache rows returned by  the
          cursor, you should always call <b>.iterator()</b> when iterating over a large query.

          If  you  are  using  the  <u>ServerSide()</u>  helper, the transaction and call to <b>iterator()</b> will be handled
          transparently.

   <b>Full-text</b> <b>search</b>
       Postgresql provides <u>sophisticated</u> <u>full-text</u> <u>search</u>  using  special  data-types  (<b>tsvector</b>  and  <b>tsquery</b>).
       Documents  should  be stored or converted to the <b>tsvector</b> type, and search queries should be converted to
       <b>tsquery</b>.

       For simple cases, you can  simply  use  the  <u>Match()</u>  function,  which  will  automatically  perform  the
       appropriate conversions, and requires no schema changes:

          def blog_search(search_term):
              return Blog.select().where(
                  (Blog.status == Blog.STATUS_PUBLISHED) &amp;
                  Match(Blog.content, search_term))

       The  <u>Match()</u>  function will automatically convert the left-hand operand to a <b>tsvector</b>, and the right-hand
       operand to a <b>tsquery</b>. For better performance, it is recommended you create a <b>GIN</b> index on the column  you
       plan to search:

          CREATE INDEX blog_full_text_search ON blog USING gin(to_tsvector(content));

       Alternatively, you can use the <u>TSVectorField</u> to maintain a dedicated column for storing <b>tsvector</b> data:

          class Blog(Model):
              content = TextField()
              search_content = TSVectorField()

       <b>NOTE:</b>
          <u>TSVectorField</u>, will automatically be created with a GIN index.

       You  will  need  to  explicitly convert the incoming text data to <b>tsvector</b> when inserting or updating the
       <b>search_content</b> field:

          content = 'Excellent blog post about peewee ORM.'
          blog_entry = Blog.create(
              content=content,
              search_content=fn.to_tsvector(content))

       To perform a full-text search, use <u>TSVectorField.match()</u>:

          terms = 'python &amp; (sqlite | postgres)'
          results = Blog.select().where(Blog.search_content.match(terms))

       For more information, see the <u>Postgres</u> <u>full-text</u> <u>search</u> <u>docs</u>.

   <b>postgres_ext</b> <b>API</b> <b>notes</b>
       <b>class</b> <b>PostgresqlExtDatabase(database[,</b> <b>server_side_cursors=False[,</b> <b>register_hstore=False[,</b> <b>...]]])</b>
              Identical to <u>PostgresqlDatabase</u> but required in order to support:

              <b>Parameters</b>

                     • <b>database</b> (<u>str</u>) -- Name of database to connect to.

                     • <b>server_side_cursors</b> (<u>bool</u>) -- Whether <b>SELECT</b> queries should utilize server-side cursors.

                     • <b>register_hstore</b> (<u>bool</u>) -- Register the HStore extension with the connection.

              • <u>Server-side</u> <u>cursors</u>

              • <u>ArrayField</u>

              • <u>DateTimeTZField</u>

              • <u>JSONField</u>

              • <u>BinaryJSONField</u>

              • <u>HStoreField</u>

              • <u>TSVectorField</u>

              If you wish to use the HStore extension, you must specify <b>register_hstore=True</b>.

              If using <b>server_side_cursors</b>, also be sure to wrap your queries with <u>ServerSide()</u>.

       <b>ServerSide(select_query)</b>

              <b>Parameters</b>
                     <b>select_query</b> -- a <u>SelectQuery</u> instance.

              <b>Rtype</b> <b>generator</b>

              Wrap the given select query in a transaction, and call its <b>iterator()</b> method to avoid caching  row
              instances. In order for the server-side resources to be released, be sure to exhaust the generator
              (iterate over all the rows).

              Usage:

                 large_query = PageView.select()
                 for page_view in ServerSide(large_query):
                     # Do something interesting.
                     pass

                 # At this point server side resources are released.

       <b>class</b> <b>ArrayField([field_class=IntegerField[,</b> <b>field_kwargs=None[,</b> <b>dimensions=1[,</b> <b>convert_values=False]]]])</b>

              <b>Parameters</b>

                     • <b>field_class</b> -- a subclass of <u>Field</u>, e.g. <u>IntegerField</u>.

                     • <b>field_kwargs</b> (<u>dict</u>) -- arguments to initialize <b>field_class</b>.

                     • <b>dimensions</b> (<u>int</u>) -- dimensions of array.

                     • <b>convert_values</b> (<u>bool</u>) -- apply <b>field_class</b> value conversion to array data.

              Field capable of storing arrays of the provided <u>field_class</u>.

              <b>NOTE:</b>
                 By  default  ArrayField  will  use  a  GIN  index.  To  disable this, initialize the field with
                 <b>index=False</b>.

              You can store and retrieve lists (or lists-of-lists):

                 class BlogPost(BaseModel):
                     content = TextField()
                     tags = ArrayField(CharField)

                 post = BlogPost(content='awesome', tags=['foo', 'bar', 'baz'])

              Additionally, you can use the <b>__getitem__</b> API to query values or slices in the database:

                 # Get the first tag on a given blog post.
                 first_tag = (BlogPost
                              .select(BlogPost.tags[0].alias('first_tag'))
                              .where(BlogPost.id == 1)
                              .dicts()
                              .get())

                 # first_tag = {'first_tag': 'foo'}

              Get a slice of values:

                 # Get the first two tags.
                 two_tags = (BlogPost
                             .select(BlogPost.tags[:2].alias('two'))
                             .dicts()
                             .get())
                 # two_tags = {'two': ['foo', 'bar']}

              <b>contains(*items)</b>

                     <b>Parameters</b>
                            <b>items</b> -- One or more items that must be in the given array field.

                        # Get all blog posts that are tagged with both "python" and "django".
                        Blog.select().where(Blog.tags.contains('python', 'django'))

              <b>contains_any(*items)</b>

                     <b>Parameters</b>
                            <b>items</b> -- One or more items to search for in the given array field.

                     Like <u>contains()</u>, except will match rows where the array contains <u>any</u> of the given items.

                        # Get all blog posts that are tagged with "flask" and/or "django".
                        Blog.select().where(Blog.tags.contains_any('flask', 'django'))

       <b>class</b> <b>DateTimeTZField(*args,</b> <b>**kwargs)</b>
              A timezone-aware subclass of <u>DateTimeField</u>.

       <b>class</b> <b>HStoreField(*args,</b> <b>**kwargs)</b>
              A field for storing and retrieving arbitrary key/value pairs. For details  on  usage,  see  <u>hstore</u>
              <u>support</u>.

              <b>ATTENTION:</b>
                 To  use  the  <u>HStoreField</u>  you will need to be sure the <u>hstore</u> extension is registered with the
                 connection.    To    accomplish    this,    instantiate    the    <u>PostgresqlExtDatabase</u>    with
                 <b>register_hstore=True</b>.

              <b>NOTE:</b>
                 By  default  <b>HStoreField</b>  will  use  a  <u>GiST</u>  index. To disable this, initialize the field with
                 <b>index=False</b>.

              <b>keys()</b> Returns the keys for a given row.

                        &gt;&gt;&gt; for h in House.select(House.address, House.features.keys().alias('keys')):
                        ...     print(h.address, h.keys)

                        123 Main St [u'bath', u'garage']

              <b>values()</b>
                     Return the values for a given row.

                        &gt;&gt;&gt; for h in House.select(House.address, House.features.values().alias('vals')):
                        ...     print(h.address, h.vals)

                        123 Main St [u'2 bath', u'2 cars']

              <b>items()</b>
                     Like python's <b>dict</b>, return the keys and values in a list-of-lists:

                        &gt;&gt;&gt; for h in House.select(House.address, House.features.items().alias('mtx')):
                        ...     print(h.address, h.mtx)

                        123 Main St [[u'bath', u'2 bath'], [u'garage', u'2 cars']]

              <b>slice(*args)</b>
                     Return a slice of data given a list of keys.

                        &gt;&gt;&gt; for h in House.select(House.address, House.features.slice('garage').alias('garage_data')):
                        ...     print(h.address, h.garage_data)

                        123 Main St {'garage': '2 cars'}

              <b>exists(key)</b>
                     Query for whether the given key exists.

                        &gt;&gt;&gt; for h in House.select(House.address, House.features.exists('garage').alias('has_garage')):
                        ...     print(h.address, h.has_garage)

                        123 Main St True

                        &gt;&gt;&gt; for h in House.select().where(House.features.exists('garage')):
                        ...     print(h.address, h.features['garage']) # &lt;-- just houses w/garage data

                        123 Main St 2 cars

              <b>defined(key)</b>
                     Query for whether the given key has a value associated with it.

              <b>update(**data)</b>
                     Perform an atomic update to the keys/values for a given row or rows.

                        &gt;&gt;&gt; query = House.update(features=House.features.update(
                        ...     sqft=2000,
                        ...     year_built=2012))
                        &gt;&gt;&gt; query.where(House.id == 1).execute()

              <b>delete(*keys)</b>
                     Delete the provided keys for a given row or rows.

                     <b>NOTE:</b>
                        We will use an <b>UPDATE</b> query.

                     &gt;&gt;&gt; query = House.update(features=House.features.delete(
                     ...     'sqft', 'year_built'))
                     &gt;&gt;&gt; query.where(House.id == 1).execute()

              <b>contains(value)</b>

                     <b>Parameters</b>
                            <b>value</b> -- Either a <b>dict</b>, a <b>list</b> of keys, or a single key.

                     Query rows for the existence of either:

                     • a partial dictionary.

                     • a list of keys.

                     • a single key.

                        &gt;&gt;&gt; query = House.select()
                        &gt;&gt;&gt; has_garage = query.where(House.features.contains('garage'))
                        &gt;&gt;&gt; garage_bath = query.where(House.features.contains(['garage', 'bath']))
                        &gt;&gt;&gt; twocar = query.where(House.features.contains({'garage': '2 cars'}))

              <b>contains_any(*keys)</b>

                     <b>Parameters</b>
                            <b>keys</b> -- One or more keys to search for.

                     Query rows for the existence of <u>any</u> key.

       <b>class</b> <b>JSONField(dumps=None,</b> <b>*args,</b> <b>**kwargs)</b>

              <b>Parameters</b>
                     <b>dumps</b> -- The default is to call json.dumps() or the dumps function.  You can override  this
                     method to create a customized JSON wrapper.

              Field  class suitable for storing and querying arbitrary JSON. When using this on a model, set the
              field's value to a Python object (either a <b>dict</b> or a <b>list</b>). When you retrieve your value from  the
              database it will be returned as a Python data structure.

              <b>NOTE:</b>
                 You must be using Postgres 9.2 / psycopg2 2.5 or greater.

              <b>NOTE:</b>
                 If you are using Postgres 9.4, strongly consider using the <u>BinaryJSONField</u> instead as it offers
                 better performance and more powerful querying options.

              Example model declaration:

                 db = PostgresqlExtDatabase('my_db')

                 class APIResponse(Model):
                     url = CharField()
                     response = JSONField()

                     class Meta:
                         database = db

              Example of storing JSON data:

                 url = '<a href="http://foo.com/api/resource/">http://foo.com/api/resource/</a>'
                 resp = json.loads(urllib2.urlopen(url).read())
                 APIResponse.create(url=url, response=resp)

                 APIResponse.create(url='<a href="http://foo.com/baz/">http://foo.com/baz/</a>', response={'key': 'value'})

              To query, use Python's <b>[]</b> operators to specify nested key or array lookups:

                 APIResponse.select().where(
                     APIResponse.response['key1']['nested-key'] == 'some-value')

              To  illustrate  the  use  of  the  <b>[]</b>  operators,  imagine we have the following data stored in an
              <b>APIResponse</b>:

                 {
                   "foo": {
                     "bar": ["i1", "i2", "i3"],
                     "baz": {
                       "huey": "mickey",
                       "peewee": "nugget"
                     }
                   }
                 }

              Here are the results of a few queries:

                 def get_data(expression):
                     # Helper function to just retrieve the results of a
                     # particular expression.
                     query = (APIResponse
                              .select(expression.alias('my_data'))
                              .dicts()
                              .get())
                     return query['my_data']

                 # Accessing the foo -&gt; bar subkey will return a JSON
                 # representation of the list.
                 get_data(APIResponse.data['foo']['bar'])
                 # '["i1", "i2", "i3"]'

                 # In order to retrieve this list as a Python list,
                 # we will call .as_json() on the expression.
                 get_data(APIResponse.data['foo']['bar'].as_json())
                 # ['i1', 'i2', 'i3']

                 # Similarly, accessing the foo -&gt; baz subkey will
                 # return a JSON representation of the dictionary.
                 get_data(APIResponse.data['foo']['baz'])
                 # '{"huey": "mickey", "peewee": "nugget"}'

                 # Again, calling .as_json() will return an actual
                 # python dictionary.
                 get_data(APIResponse.data['foo']['baz'].as_json())
                 # {'huey': 'mickey', 'peewee': 'nugget'}

                 # When dealing with simple values, either way works as
                 # you expect.
                 get_data(APIResponse.data['foo']['bar'][0])
                 # 'i1'

                 # Calling .as_json() when the result is a simple value
                 # will return the same thing as the previous example.
                 get_data(APIResponse.data['foo']['bar'][0].as_json())
                 # 'i1'

       <b>class</b> <b>BinaryJSONField(dumps=None,</b> <b>*args,</b> <b>**kwargs)</b>

              <b>Parameters</b>
                     <b>dumps</b> -- The default is to call json.dumps() or the dumps function.  You can override  this
                     method to create a customized JSON wrapper.

              Store  and query arbitrary JSON documents. Data should be stored using normal Python <b>dict</b> and <b>list</b>
              objects, and when data is returned from the database, it will be returned using <b>dict</b> and  <b>list</b>  as
              well.

              For  examples  of  basic  query  operations, see the above code samples for <u>JSONField</u>. The example
              queries below will use the same <b>APIResponse</b> model described above.

              <b>NOTE:</b>
                 By default BinaryJSONField will use a GiST index. To disable this, initialize  the  field  with
                 <b>index=False</b>.

              <b>NOTE:</b>
                 You  must  be using Postgres 9.4 / psycopg2 2.5 or newer. If you are using Postgres 9.2 or 9.3,
                 you can use the regular <u>JSONField</u> instead.

              <b>contains(other)</b>
                     Test whether the given JSON data contains the given JSON fragment or key.

                     Example:

                        search_fragment = {
                            'foo': {'bar': ['i2']}
                        }
                        query = (APIResponse
                                 .select()
                                 .where(APIResponse.data.contains(search_fragment)))

                        # If we're searching for a list, the list items do not need to
                        # be ordered in a particular way:
                        query = (APIResponse
                                 .select()
                                 .where(APIResponse.data.contains({
                                     'foo': {'bar': ['i2', 'i1']}})))

                     We can pass in simple keys as well. To find APIResponses that contain the key  <b>foo</b>  at  the
                     top-level:

                        APIResponse.select().where(APIResponse.data.contains('foo'))

                     We can also search sub-keys using square-brackets:

                        APIResponse.select().where(
                            APIResponse.data['foo']['bar'].contains(['i2', 'i1']))

              <b>contains_any(*items)</b>
                     Search for the presence of one or more of the given items.

                        APIResponse.select().where(
                            APIResponse.data.contains_any('foo', 'baz', 'nugget'))

                     Like <u>contains()</u>, we can also search sub-keys:

                        APIResponse.select().where(
                            APIResponse.data['foo']['bar'].contains_any('i2', 'ix'))

              <b>contains_all(*items)</b>
                     Search for the presence of all of the given items.

                        APIResponse.select().where(
                            APIResponse.data.contains_all('foo'))

                     Like <u>contains_any()</u>, we can also search sub-keys:

                        APIResponse.select().where(
                            APIResponse.data['foo']['bar'].contains_all('i1', 'i2', 'i3'))

              <b>contained_by(other)</b>
                     Test  whether  the  given  JSON  document  is  contained by (is a subset of) the given JSON
                     document. This method is the inverse of <u>contains()</u>.

                        big_doc = {
                            'foo': {
                                'bar': ['i1', 'i2', 'i3'],
                                'baz': {
                                    'huey': 'mickey',
                                    'peewee': 'nugget',
                                }
                            },
                            'other_key': ['nugget', 'bear', 'kitten'],
                        }
                        APIResponse.select().where(
                            APIResponse.data.contained_by(big_doc))

              <b>concat(data)</b>
                     Concatenate two field data and the provided data. Note that this operation does  not  merge
                     or do a "deep concat".

              <b>has_key(key)</b>
                     Test whether the key exists at the top-level of the JSON object.

              <b>remove(*keys)</b>
                     Remove one or more keys from the top-level of the JSON object.

       <b>Match(field,</b> <b>query)</b>
              Generate  a  full-text  search  expression,  automatically  converting  the left-hand operand to a
              <b>tsvector</b>, and the right-hand operand to a <b>tsquery</b>.

              Example:

                 def blog_search(search_term):
                     return Blog.select().where(
                         (Blog.status == Blog.STATUS_PUBLISHED) &amp;
                         Match(Blog.content, search_term))

       <b>class</b> <b>TSVectorField</b>
              Field type suitable for storing <b>tsvector</b> data. This field will automatically be created with a <b>GIN</b>
              index for improved search performance.

              <b>NOTE:</b>
                 Data stored in this field will still need to be manually converted to the <b>tsvector</b> type.

              <b>NOTE:</b>
                     By default TSVectorField will use a GIN index. To disable this, initialize the  field  with
                     <b>index=False</b>.

                 Example usage:

                     class Blog(Model):
                         content = TextField()
                         search_content = TSVectorField()

                     content = 'this is a sample blog entry.'
                     blog_entry = Blog.create(
                         content=content,
                         search_content=fn.to_tsvector(content))  # Note `to_tsvector()`.

              <b>match(query[,</b> <b>language=None[,</b> <b>plain=False]])</b>

                     <b>Parameters</b>

                            • <b>query</b> (<u>str</u>) -- the full-text search query.

                            • <b>language</b> (<u>str</u>) -- language name (optional).

                            • <b>plain</b> (<u>bool</u>) -- parse search query using plain (simple) parser.

                     <b>Returns</b>
                            an expression representing full-text search/match.

                     Example:

                        # Perform a search using the "match" method.
                        terms = 'python &amp; (sqlite | postgres)'
                        results = Blog.select().where(Blog.search_content.match(terms))

   <b>Cockroach</b> <b>Database</b>
       <u>CockroachDB</u> (CRDB) is well supported by peewee.

          from playhouse.cockroachdb import CockroachDatabase

          db = CockroachDatabase('my_app', user='root', host='10.1.0.8')

       If  you  are  using  <u>Cockroach</u> <u>Cloud</u>, you may find it easier to specify the connection parameters using a
       connection-string:

          db = CockroachDatabase('postgresql:/<a href="file:/root">/root</a>:secret@host:26257/defaultdb...')

       <b>NOTE:</b>
          CockroachDB requires the <b>psycopg2</b> (postgres) Python driver.

       <b>NOTE:</b>
          CockroachDB    installation    and    getting-started    guide    can     be     found     here:     ‐
          <u>https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html</u>

   <b>SSL</b> <b>Configuration</b>
       SSL  certificates  are  strongly  recommended  when  running  a Cockroach cluster.  Psycopg2 supports SSL
       out-of-the-box, but you may need to specify some additional options when initializing your database:

          db = CockroachDatabase(
              'my_app',
              user='root',
              host='10.1.0.8',
              sslmode='verify-full',  # Verify the cert common-name.
              sslrootcert='/path/to/root.crt')

          # Or, alternatively, specified as part of a connection-string:
          db = CockroachDatabase('postgresql:/<a href="file:/root">/root</a>:secret@host:26257/dbname'
                                 '?sslmode=verify-full&amp;sslrootcert=/path/to/root.crt'
                                 '&amp;options=--cluster=my-cluster-xyz')

       More details about client verification can be found on the <u>libpq</u> <u>docs</u>.

   <b>Cockroach</b> <b>Extension</b> <b>APIs</b>
       The <b>playhouse.cockroachdb</b> extension module provides the following classes and helpers:

       • <u>CockroachDatabase</u> - a subclass of <u>PostgresqlDatabase</u>, designed specifically for working with CRDB.

       • <u>PooledCockroachDatabase</u> - like the above, but implements connection-pooling.

       • <u>run_transaction()</u> - runs a function inside a  transaction  and  provides  automatic  client-side  retry
         logic.

       Special field-types that may be useful when using CRDB:

       • <u>UUIDKeyField</u>  -  a  primary-key  field  implementation  that  uses  CRDB's  <b>UUID</b>  type  with  a default
         randomly-generated UUID.

       • <u>RowIDField</u>  -  a  primary-key  field  implementation  that  uses  CRDB's  <b>INT</b>  type  with   a   default
         <b>unique_rowid()</b>.

       • <u>JSONField</u> - same as the Postgres <u>BinaryJSONField</u>, as CRDB treats JSON as JSONB.

       • <u>ArrayField</u> - same as the Postgres extension (but does not support multi-dimensional arrays).

       CRDB  is  compatible  with  Postgres'  wire  protocol  and exposes a very similar SQL interface, so it is
       possible (though <b>not</b> <b>recommended</b>) to use <u>PostgresqlDatabase</u> with CRDB:

       1. CRDB does not support nested transactions (savepoints), so the <u>atomic()</u> method has been implemented to
          enforce this when using <u>CockroachDatabase</u>. For more info <u>CRDB</u> <u>Transactions</u>.

       2. CRDB may have subtle differences in field-types, date functions and introspection from Postgres.

       3. CRDB-specific features are exposed by the <u>CockroachDatabase</u>, such as specifying a transaction priority
          or the <b>AS</b> <b>OF</b> <b>SYSTEM</b> <b>TIME</b> clause.

   <b>CRDB</b> <b>Transactions</b>
       CRDB does not support nested transactions (savepoints), so the <u>atomic()</u> method on  the  <u>CockroachDatabase</u>
       has  been  modified  to  raise an exception if an invalid nesting is encountered. If you would like to be
       able to nest transactional code, you can use  the  <u>transaction()</u>  method,  which  will  ensure  that  the
       outer-most  block  will  manage  the  transaction  (e.g.,  exiting a nested-block will not cause an early
       commit).

       Example:

          @db.transaction()
          def create_user(username):
              return User.create(username=username)

          def some_other_function():
              with db.transaction() as txn:
                  # do some stuff...

                  # This function is wrapped in a transaction, but the nested
                  # transaction will be ignored and folded into the outer
                  # transaction, as we are already in a wrapped-block (via the
                  # context manager).
                  create_user('<a href="mailto:some_user@example.com">some_user@example.com</a>')

                  # do other stuff.

              # At this point we have exited the outer-most block and the transaction
              # will be committed.
              return

       CRDB provides client-side transaction retries, which are  available  using  a  special  <u>run_transaction()</u>
       helper.  This  helper  method  accepts  a  callable, which is responsible for executing any transactional
       statements that may need to be retried.

       Simplest possible example of <u>run_transaction()</u>:

          def create_user(email):
              # Callable that accepts a single argument (the database instance) and
              # which is responsible for executing the transactional SQL.
              def callback(db_ref):
                  return User.create(email=email)

              return db.run_transaction(callback, max_attempts=10)

          huey = create_user('<a href="mailto:huey@example.com">huey@example.com</a>')

       <b>NOTE:</b>
          The <b>cockroachdb.ExceededMaxAttempts</b> exception will be raised if the transaction  cannot  be  committed
          after  the  given  number of attempts. If the SQL is mal-formed, violates a constraint, etc., then the
          function will raise the exception to the caller.

       Example of using <u>run_transaction()</u> to implement client-side retries for a transaction that  transfers  an
       amount from one account to another:

          from playhouse.cockroachdb import CockroachDatabase

          db = CockroachDatabase('my_app')

          def transfer_funds(from_id, to_id, amt):
              """
              Returns a 3-tuple of (success?, from balance, to balance). If there are
              not sufficient funds, then the original balances are returned.
              """
              def thunk(db_ref):
                  src, dest = (Account
                               .select()
                               .where(Account.id.in_([from_id, to_id])))
                  if src.id != from_id:
                      src, dest = dest, src  # Swap order.

                  # Cannot perform transfer, insufficient funds!
                  if src.balance &lt; amt:
                      return False, src.balance, dest.balance

                  # Update each account, returning the new balance.
                  src, = (Account
                          .update(balance=Account.balance - amt)
                          .where(Account.id == from_id)
                          .returning(Account.balance)
                          .execute())
                  dest, = (Account
                           .update(balance=Account.balance + amt)
                           .where(Account.id == to_id)
                           .returning(Account.balance)
                           .execute())
                  return True, src.balance, dest.balance

              # Perform the queries that comprise a logical transaction. In the
              # event the transaction fails due to contention, it will be auto-
              # matically retried (up to 10 times).
              return db.run_transaction(thunk, max_attempts=10)

   <b>CRDB</b> <b>APIs</b>
       <b>class</b> <b>CockroachDatabase(database[,</b> <b>**kwargs])</b>
              CockroachDB implementation, based on the <u>PostgresqlDatabase</u> and using the <b>psycopg2</b> driver.

              Additional keyword arguments are passed to the psycopg2 connection constructor, and may be used to
              specify the database <b>user</b>, <b>port</b>, etc.

              Alternatively, the connection details can be specified in URL-form.

              <b>run_transaction(callback[,</b> <b>max_attempts=None[,</b> <b>system_time=None[,</b> <b>priority=None]]])</b>

                     <b>Parameters</b>

                            • <b>callback</b>  --  callable  that  accepts  a  single  <b>db</b>  parameter (which will be the
                              database instance this method is called from).

                            • <b>max_attempts</b> (<u>int</u>) -- max number of times to try before giving up.

                            • <b>system_time</b> (<u>datetime</u>) -- execute the transaction <b>AS</b> <b>OF</b> <b>SYSTEM</b> <b>TIME</b>  with  respect
                              to the given value.

                            • <b>priority</b> (<u>str</u>) -- either "low", "normal" or "high".

                     <b>Returns</b>
                            returns the value returned by the callback.

                     <b>Raises</b> <b>ExceededMaxAttempts</b> if <b>max_attempts</b> is exceeded.

                     Run SQL in a transaction with automatic client-side retries.

                     User-provided <b>callback</b>:

                     • <b>Must</b> accept one parameter, the <b>db</b> instance representing the connection the transaction is
                       running under.

                     • <b>Must</b> not attempt to commit, rollback or otherwise manage the transaction.

                     • <b>May</b> be called more than one time.

                     • <b>Should</b> ideally only contain SQL operations.

                     Additionally, the database must not have any open transactions at the time this function is
                     called,  as  CRDB  does  not  support nested transactions. Attempting to do so will raise a
                     <b>NotImplementedError</b>.

                     Simplest possible example:

                        def create_user(email):
                            def callback(db_ref):
                                return User.create(email=email)

                            return db.run_transaction(callback, max_attempts=10)

                        user = create_user('<a href="mailto:huey@example.com">huey@example.com</a>')

       <b>class</b> <b>PooledCockroachDatabase(database[,</b> <b>**kwargs])</b>
              CockroachDB connection-pooling implementation, based on <u>PooledPostgresqlDatabase</u>.  Implements  the
              same APIs as <u>CockroachDatabase</u>, but will do client-side connection pooling.

       <b>run_transaction(db,</b> <b>callback[,</b> <b>max_attempts=None[,</b> <b>system_time=None[,</b> <b>priority=None]]])</b>
              Run     SQL     in     a     transaction     with     automatic     client-side    retries.    See
              <u>CockroachDatabase.run_transaction()</u> for details.

              <b>Parameters</b>

                     • <b>db</b> (<u>CockroachDatabase</u>) -- database instance.

                     • <b>callback</b> -- callable that accepts a single <b>db</b> parameter (which will be the  same  as  the
                       value passed above).

              <b>NOTE:</b>
                 This function is equivalent to the identically-named method on the <u>CockroachDatabase</u> class.

       <b>class</b> <b>UUIDKeyField</b>
              UUID primary-key field that uses the CRDB <b>gen_random_uuid()</b> function to automatically populate the
              initial value.

       <b>class</b> <b>RowIDField</b>
              Auto-incrementing  integer  primary-key  field  that  uses  the  CRDB  <b>unique_rowid()</b>  function to
              automatically populate the initial value.

       See also:

       • <u>BinaryJSONField</u> from the Postgresql extension (available  in  the  <b>cockroachdb</b>  extension  module,  and
         aliased to <b>JSONField</b>).

       • <u>ArrayField</u> from the Postgresql extension.

   <b>MySQL</b> <b>Extensions</b>
       Peewee  provides  an  alternate  database  implementation  for  using the <u>mysql-connector</u> driver or the ‐
       <u>mariadb-connector</u>.  The implementations can be found in <b>playhouse.mysql_ext</b>.

       <b>class</b> <b>MySQLConnectorDatabase(database,</b> <b>**kwargs)</b>
              Database implementation using <u>mysql-connector</u>.  Full list of supported <u>connection</u> <u>parameters</u>.

              Example usage of mysql-connector:

                 from playhouse.mysql_ext import MySQLConnectorDatabase

                 # MySQL database implementation that utilizes mysql-connector driver.
                 db = MySQLConnectorDatabase('my_database', host='1.2.3.4', user='mysql')

       <b>class</b> <b>MariaDBConnectorDatabase(database,</b> <b>**kwargs)</b>
              Database implementation using <u>mariadb-connector</u>.  Full list of supported <u>connection</u> <u>parameters</u>.

              Example usage of mariadb-connector:

                 from playhouse.mysql_ext import MariaDBConnectorDatabase

                 # MySQL database implementation that utilizes mysql-connector driver.
                 db = MariaDBConnectorDatabase('my_database', host='1.2.3.4', user='mysql')

              <b>NOTE:</b>
                 The <u>MariaDBConnectorDatabase</u> does <b>not</b> accept the following parameters:

                 • <b>charset</b> (it is always utf8mb4)

                 • <b>sql_mode</b>

                 • <b>use_unicode</b>

       Additional MySQL-specific helpers:

       <b>class</b> <b>JSONField</b>
              Extends <u>TextField</u> and implements transparent JSON encoding and decoding in Python.

              <b>extract(path)</b>

                     <b>Parameters</b>
                            <b>path</b> (<u>str</u>) -- a JSON path, e.g. <b>$.key1</b>

                     Extract a value from a JSON document at the given path.

       <b>Match(columns,</b> <b>expr[,</b> <b>modifier=None])</b>

              <b>Parameters</b>

                     • <b>columns</b> -- a single <u>Field</u> or a tuple of multiple fields.

                     • <b>expr</b> (<u>str</u>) -- the full-text search expression.

                     • <b>modifier</b> (<u>str</u>) -- optional modifiers for the search, e.g. <u>'in</u> <u>boolean</u> <u>mode'</u>.

              Helper class for constructing MySQL full-text search queries of the form:

                 MATCH (columns, ...) AGAINST (expr[ modifier])

   <b>DataSet</b>
       The <u>dataset</u> module contains a high-level API for working with databases modeled after the popular <u>project</u>
       <u>of</u> <u>the</u> <u>same</u> <u>name</u>.  The aims of the <u>dataset</u> module are to provide:

       • A simplified API for working with relational data, along the lines of working with JSON.

       • An easy way to export relational data as JSON or CSV.

       • An easy way to import JSON or CSV data into a relational database.

       A minimal data-loading script might look like this:

          from playhouse.dataset import DataSet

          db = DataSet('sqlite:///:memory:')

          table = db['sometable']
          table.insert(name='Huey', age=3)
          table.insert(name='Mickey', age=5, gender='male')

          huey = table.find_one(name='Huey')
          print(huey)
          # {'age': 3, 'gender': None, 'id': 1, 'name': 'Huey'}

          for obj in table:
              print(obj)
          # {'age': 3, 'gender': None, 'id': 1, 'name': 'Huey'}
          # {'age': 5, 'gender': 'male', 'id': 2, 'name': 'Mickey'}

       You can insert, update or delete using the dictionary APIs as well:

          huey = table.find_one(name='Huey')
          # {'age': 3, 'gender': None, 'id': 1, 'name': 'Huey'}

          # Perform an update by supplying a partial record of changes.
          table[1] = {'gender': 'male', 'age': 4}
          print(table[1])
          # {'age': 4, 'gender': 'male', 'id': 1, 'name': 'Huey'}

          # Or insert a new record:
          table[3] = {'name': 'Zaizee', 'age': 2}
          print(table[3])
          # {'age': 2, 'gender': None, 'id': 3, 'name': 'Zaizee'}

          # Or delete a record:
          del table[3]  # Remove the row we just added.

       You can export or import data using <u>freeze()</u> and <u>thaw()</u>:

          # Export table content to the `users.json` file.
          db.freeze(table.all(), format='json', filename='users.json')

          # Import data from a CSV file into a new table. Columns will be automatically
          # created for each field in the CSV file.
          new_table = db['stats']
          new_table.thaw(format='csv', filename='monthly_stats.csv')

   <b>Getting</b> <b>started</b>
       <u>DataSet</u>   objects   are   initialized   by   passing    in    a    database    URL    of    the    format
       <b>dialect://user:password@host/dbname</b>.  See  the <u>Database</u> <u>URL</u> section for examples of connecting to various
       databases.

          # Create an in-memory SQLite database.
          db = DataSet('sqlite:///:memory:')

   <b>Storing</b> <b>data</b>
       To store data, we must first obtain a reference to a table. If the table  does  not  exist,  it  will  be
       created automatically:

          # Get a table reference, creating the table if it does not exist.
          table = db['users']

       We  can  now  <u>insert()</u>  new  rows  into  the  table.  If  the  columns do not exist, they will be created
       automatically:

          table.insert(name='Huey', age=3, color='white')
          table.insert(name='Mickey', age=5, gender='male')

       To update existing entries in the table, pass in a  dictionary  containing  the  new  values  and  filter
       conditions.  The  list  of  columns  to use as filters is specified in the <u>columns</u> argument. If no filter
       columns are specified, then all rows will be updated.

          # Update the gender for "Huey".
          table.update(name='Huey', gender='male', columns=['name'])

          # Update all records. If the column does not exist, it will be created.
          table.update(favorite_orm='peewee')

   <b>Importing</b> <b>data</b>
       To import data from an external source, such as a JSON or CSV file, you can use  the  <u>thaw()</u>  method.  By
       default, new columns will be created for any attributes encountered. If you wish to only populate columns
       that are already defined on a table, you can pass in <b>strict=True</b>.

          # Load data from a JSON file containing a list of objects.
          table = dataset['stock_prices']
          table.thaw(filename='stocks.json', format='json')
          table.all()[:3]

          # Might print...
          [{'id': 1, 'ticker': 'GOOG', 'price': 703},
           {'id': 2, 'ticker': 'AAPL', 'price': 109},
           {'id': 3, 'ticker': 'AMZN', 'price': 300}]

   <b>Using</b> <b>transactions</b>
       DataSet supports nesting transactions using a simple context manager.

          table = db['users']
          with db.transaction() as txn:
              table.insert(name='Charlie')

              with db.transaction() as nested_txn:
                  # Set Charlie's favorite ORM to Django.
                  table.update(name='Charlie', favorite_orm='django', columns=['name'])

                  # jk/lol
                  nested_txn.rollback()

   <b>Inspecting</b> <b>the</b> <b>database</b>
       You can use the <b>tables()</b> method to list the tables in the current database:

          &gt;&gt;&gt; print(db.tables)
          ['sometable', 'user']

       And for a given table, you can print the columns:

          &gt;&gt;&gt; table = db['user']
          &gt;&gt;&gt; print(table.columns)
          ['id', 'age', 'name', 'gender', 'favorite_orm']

       We can also find out how many rows are in a table:

          &gt;&gt;&gt; print(len(db['user']))
          3

   <b>Reading</b> <b>data</b>
       To retrieve all rows, you can use the <u>all()</u> method:

          # Retrieve all the users.
          users = db['user'].all()

          # We can iterate over all rows without calling `.all()`
          for user in db['user']:
              print(user['name'])

       Specific objects can be retrieved using <u>find()</u> and <u>find_one()</u>.

          # Find all the users who like peewee.
          peewee_users = db['user'].find(favorite_orm='peewee')

          # Find Huey.
          huey = db['user'].find_one(name='Huey')

   <b>Exporting</b> <b>data</b>
       To export data, use the <u>freeze()</u> method, passing in the query you wish to export:

          peewee_users = db['user'].find(favorite_orm='peewee')
          db.freeze(peewee_users, format='json', filename='peewee_users.json')

   <b>API</b>
       <b>class</b> <b>DataSet(url,</b> <b>**kwargs)</b>

              <b>Parameters</b>

                     • <b>url</b>  --  A  database URL or a <u>Database</u> instance. For details on using a URL, see <u>Database</u>
                       <u>URL</u> for examples.

                     • <b>kwargs</b> -- additional keyword  arguments  passed  to  <u>Introspector.generate_models()</u>  when
                       introspecting the db.

              The <u>DataSet</u> class provides a high-level API for working with relational databases.

              <b>tables</b> Return a list of tables stored in the database. This list is computed dynamically each time
                     it is accessed.

              <b>__getitem__(table_name)</b>
                     Provide  a  <u>Table</u> reference to the specified table. If the table does not exist, it will be
                     created.

              <b>query(sql[,</b> <b>params=None[,</b> <b>commit=True]])</b>

                     <b>Parameters</b>

                            • <b>sql</b> (<u>str</u>) -- A SQL query.

                            • <b>params</b> (<u>list</u>) -- Optional parameters for the query.

                            • <b>commit</b> (<u>bool</u>) -- Whether the query should be committed upon execution.

                     <b>Returns</b>
                            A database cursor.

                     Execute the provided query against the database.

              <b>transaction()</b>
                     Create a context manager representing a new transaction (or savepoint).

              <b>freeze(query[,</b> <b>format='csv'[,</b> <b>filename=None[,</b> <b>file_obj=None[,</b> <b>encoding='utf8'[,</b> <b>**kwargs]]]]])</b>

                     <b>Parameters</b>

                            • <b>query</b> -- A <u>SelectQuery</u>, generated using <u>all()</u> or <u>~Table.find</u>.

                            • <b>format</b> -- Output format. By default, <u>csv</u> and <u>json</u> are supported.

                            • <b>filename</b> -- Filename to write output to.

                            • <b>file_obj</b> -- File-like object to write output to.

                            • <b>encoding</b> (<u>str</u>) -- File encoding.

                            • <b>kwargs</b> -- Arbitrary parameters for export-specific functionality.

              <b>thaw(table[,</b> <b>format='csv'[,</b> <b>filename=None[,</b> <b>file_obj=None[,</b> <b>strict=False[,</b> <b>encoding='utf8'[,</b>
              <b>**kwargs]]]]]])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- The name of the table to load data into.

                            • <b>format</b> -- Input format. By default, <u>csv</u> and <u>json</u> are supported.

                            • <b>filename</b> -- Filename to read data from.

                            • <b>file_obj</b> -- File-like object to read data from.

                            • <b>strict</b> (<u>bool</u>) -- Whether to store values for columns that do not already exist  on
                              the table.

                            • <b>encoding</b> (<u>str</u>) -- File encoding.

                            • <b>kwargs</b> -- Arbitrary parameters for import-specific functionality.

              <b>connect()</b>
                     Open a connection to the underlying database. If a connection is not opened explicitly, one
                     will be opened the first time a query is executed.

              <b>close()</b>
                     Close the connection to the underlying database.

       <b>class</b> <b>Table(dataset,</b> <b>name,</b> <b>model_class)</b>

              <b>Noindex</b>

              Provides a high-level API for working with rows in a given table.

              <b>columns</b>
                     Return a list of columns in the given table.

              <b>model_class</b>
                     A dynamically-created <u>Model</u> class.

              <b>create_index(columns[,</b> <b>unique=False])</b>
                     Create an index on the given columns:

                        # Create a unique index on the `username` column.
                        db['users'].create_index(['username'], unique=True)

              <b>insert(**data)</b>
                     Insert the given data dictionary into the table, creating new columns as needed.

              <b>update(columns=None,</b> <b>conjunction=None,</b> <b>**data)</b>
                     Update  the  table  using  the  provided  data. If one or more columns are specified in the
                     <u>columns</u> parameter, then those columns' values in  the  <u>data</u>  dictionary  will  be  used  to
                     determine which rows to update.

                        # Update all rows.
                        db['users'].update(favorite_orm='peewee')

                        # Only update Huey's record, setting his age to 3.
                        db['users'].update(name='Huey', age=3, columns=['name'])

              <b>find(**query)</b>
                     Query  the  table  for  rows  matching  the  specified  equality conditions. If no query is
                     specified, then all rows are returned.

                        peewee_users = db['users'].find(favorite_orm='peewee')

              <b>find_one(**query)</b>
                     Return a single row matching the specified equality conditions. If no matching row is found
                     then <b>None</b> will be returned.

                        huey = db['users'].find_one(name='Huey')

              <b>all()</b>  Return all rows in the given table.

              <b>delete(**query)</b>
                     Delete all rows matching the given equality conditions. If no query is provided,  then  all
                     rows will be deleted.

                        # Adios, Django!
                        db['users'].delete(favorite_orm='Django')

                        # Delete all the secret messages.
                        db['secret_messages'].delete()

              <b>freeze([format='csv'[,</b> <b>filename=None[,</b> <b>file_obj=None[,</b> <b>**kwargs]]]])</b>

                     <b>Parameters</b>

                            • <b>format</b> -- Output format. By default, <u>csv</u> and <u>json</u> are supported.

                            • <b>filename</b> -- Filename to write output to.

                            • <b>file_obj</b> -- File-like object to write output to.

                            • <b>kwargs</b> -- Arbitrary parameters for export-specific functionality.

              <b>thaw([format='csv'[,</b> <b>filename=None[,</b> <b>file_obj=None[,</b> <b>strict=False[,</b> <b>**kwargs]]]]])</b>

                     <b>Parameters</b>

                            • <b>format</b> -- Input format. By default, <u>csv</u> and <u>json</u> are supported.

                            • <b>filename</b> -- Filename to read data from.

                            • <b>file_obj</b> -- File-like object to read data from.

                            • <b>strict</b>  (<u>bool</u>) -- Whether to store values for columns that do not already exist on
                              the table.

                            • <b>kwargs</b> -- Arbitrary parameters for import-specific functionality.

   <b>Fields</b>
       These fields can be found in the <b>playhouse.fields</b> module.

       <b>class</b> <b>CompressedField([compression_level=6[,</b> <b>algorithm='zlib'[,</b> <b>**kwargs]]])</b>

              <b>Parameters</b>

                     • <b>compression_level</b> (<u>int</u>) -- A value from 0 to 9.

                     • <b>algorithm</b> (<u>str</u>) -- Either <b>'zlib'</b> or <b>'bz2'</b>.

              Stores compressed data using the specified algorithm. This field extends <u>BlobField</u>,  transparently
              storing a compressed representation of the data in the database.

       <b>class</b> <b>PickleField</b>
              Stores  arbitrary  Python data by transparently pickling and un-pickling data stored in the field.
              This field extends <u>BlobField</u>. If the <b>cPickle</b> module is available, it will be used.

   <b>Hybrid</b> <b>Attributes</b>
       Hybrid attributes encapsulate functionality that operates at both the Python <u>and</u> SQL levels. The idea for
       hybrid attributes comes from a feature of the <u>same</u> <u>name</u> <u>in</u> <u>SQLAlchemy</u>.  Consider the following example:

          class Interval(Model):
              start = IntegerField()
              end = IntegerField()

              @hybrid_property
              def length(self):
                  return self.end - self.start

              @hybrid_method
              def contains(self, point):
                  return (self.start &lt;= point) &amp; (point &lt; self.end)

       The <u>hybrid</u> <u>attribute</u> gets its name from the fact  that  the  <b>length</b>  attribute  will  behave  differently
       depending on whether it is accessed via the <b>Interval</b> class or an <b>Interval</b> instance.

       If accessed via an instance, then it behaves just as you would expect.

       If accessed via the <b>Interval.length</b> class attribute, however, the length calculation will be expressed as
       a SQL expression. For example:

          query = Interval.select().where(Interval.length &gt; 5)

       This query will be equivalent to the following SQL:

          SELECT "t1"."id", "t1"."start", "t1"."end"
          FROM "interval" AS t1
          WHERE (("t1"."end" - "t1"."start") &gt; 5)

       The  <b>playhouse.hybrid</b>  module  also contains a decorator for implementing hybrid methods which can accept
       parameters. As with hybrid properties, when accessed via a model instance,  then  the  function  executes
       normally  as-written.   When  the  hybrid  method is called on the class, however, it will generate a SQL
       expression.

       Example:

          query = Interval.select().where(<a href="../man2/Interval.contains.2.html">Interval.contains</a>(2))

       This query is equivalent to the following SQL:

          SELECT "t1"."id", "t1"."start", "t1"."end"
          FROM "interval" AS t1
          WHERE (("t1"."start" &lt;= 2) AND (2 &lt; "t1"."end"))

       There is an additional API for situations where the python implementation differs slightly from  the  SQL
       implementation.  Let's  add  a  <b>radius</b>  method  to  the <b>Interval</b> model. Because this method calculates an
       absolute value, we will use the Python <b>abs()</b> function for the  instance  portion  and  the  <b>fn.ABS()</b>  SQL
       function for the class portion.

          class Interval(Model):
              start = IntegerField()
              end = IntegerField()

              @hybrid_property
              def length(self):
                  return self.end - self.start

              @hybrid_property
              def radius(self):
                  return abs(self.length) / 2

              @radius.expression
              def radius(cls):
                  return fn.ABS(cls.length) / 2

       What  is neat is that both the <b>radius</b> implementations refer to the <b>length</b> hybrid attribute! When accessed
       via an <b>Interval</b> instance, the radius calculation will be executed in Python. When invoked via an <b>Interval</b>
       class, we will get the appropriate SQL.

       Example:

          query = Interval.select().where(Interval.radius &lt; 3)

       This query is equivalent to the following SQL:

          SELECT "t1"."id", "t1"."start", "t1"."end"
          FROM "interval" AS t1
          WHERE ((abs("t1"."end" - "t1"."start") / 2) &lt; 3)

       Pretty neat, right? Thanks for the cool idea, SQLAlchemy!

   <b>Hybrid</b> <b>API</b>
       <b>class</b> <b>hybrid_method(func[,</b> <b>expr=None])</b>
              Method decorator that allows the definition of a Python object method with both instance-level and
              class-level behavior.

              Example:

                 class Interval(Model):
                     start = IntegerField()
                     end = IntegerField()

                     @hybrid_method
                     def contains(self, point):
                         return (self.start &lt;= point) &amp; (point &lt; self.end)

              When called with an <b>Interval</b> instance, the <b>contains</b> method will behave as you would  expect.  When
              called as a classmethod, though, a SQL expression will be generated:

                 query = Interval.select().where(<a href="../man2/Interval.contains.2.html">Interval.contains</a>(2))

              Would generate the following SQL:

                 SELECT "t1"."id", "t1"."start", "t1"."end"
                 FROM "interval" AS t1
                 WHERE (("t1"."start" &lt;= 2) AND (2 &lt; "t1"."end"))

              <b>expression(expr)</b>
                     Method decorator for specifying the SQL-expression producing method.

       <b>class</b> <b>hybrid_property(fget[,</b> <b>fset=None[,</b> <b>fdel=None[,</b> <b>expr=None]]])</b>
              Method  decorator  that allows the definition of a Python object property with both instance-level
              and class-level behavior.

              Examples:

                 class Interval(Model):
                     start = IntegerField()
                     end = IntegerField()

                     @hybrid_property
                     def length(self):
                         return self.end - self.start

                     @hybrid_property
                     def radius(self):
                         return abs(self.length) / 2

                     @radius.expression
                     def radius(cls):
                         return fn.ABS(cls.length) / 2

              When accessed on an <b>Interval</b> instance, the <b>length</b> and <b>radius</b> properties will behave as  you  would
              expect. When accessed as class attributes, though, a SQL expression will be generated instead:

                 query = (Interval
                          .select()
                          .where(
                              (Interval.length &gt; 6) &amp;
                              (Interval.radius &gt;= 3)))

              Would generate the following SQL:

                 SELECT "t1"."id", "t1"."start", "t1"."end"
                 FROM "interval" AS t1
                 WHERE (
                     (("t1"."end" - "t1"."start") &gt; 6) AND
                     ((abs("t1"."end" - "t1"."start") / 2) &gt;= 3)
                 )

   <b>Key/Value</b> <b>Store</b>
       The <b>playhouse.kv</b> module contains the implementation of a persistent dictionary.

       <b>class</b> <b>KeyValue([key_field=None[,</b> <b>value_field=None[,</b> <b>ordered=False[,</b> <b>database=None[,</b>
       <b>table_name='keyvalue']]]]])</b>

              <b>Parameters</b>

                     • <b>key_field</b>   (<u>Field</u>)   --  field  to  use  for  key.  Defaults  to  <u>CharField</u>.  <b>Must</b>  <b>have</b>
                       <b>primary_key=True</b>.

                     • <b>value_field</b> (<u>Field</u>) -- field to use for value. Defaults to <u>PickleField</u>.

                     • <b>ordered</b> (<u>bool</u>) -- data should be returned in key-sorted order.

                     • <b>database</b> (<u>Database</u>) -- database where key/value data is  stored.  If  not  specified,  an
                       in-memory SQLite database will be used.

                     • <b>table_name</b> (<u>str</u>) -- table name for data storage.

              Dictionary-like API for storing key/value data. Like dictionaries, supports the expected APIs, but
              also has the added capability of accepting expressions for getting, setting and deleting items.

              Table is created automatically (if it doesn't exist) when the <b>KeyValue</b> is instantiated.

              Uses efficient upsert implementation for setting and updating/overwriting key/value pairs.

              Basic examples:

                 # Create a key/value store, which uses an in-memory SQLite database
                 # for data storage.
                 KV = KeyValue()

                 # Set (or overwrite) the value for "k1".
                 KV['k1'] = 'v1'

                 # Set (or update) multiple keys at once (uses an efficient upsert).
                 KV.update(k2='v2', k3='v3')

                 # Getting values works as you'd expect.
                 assert KV['k2'] == 'v2'

                 # We can also do this:
                 for value in KV[KV.key &gt; 'k1']:
                     print(value)

                 # 'v2'
                 # 'v3'

                 # Update multiple values at once using expression:
                 KV[KV.key &gt; 'k1'] = 'vx'

                 # What's stored in the KV?
                 print(dict(KV))

                 # {'k1': 'v1', 'k2': 'vx', 'k3': 'vx'}

                 # Delete a single item.
                 del KV['k2']

                 # How many items are stored in the KV?
                 print(len(KV))
                 # 2

                 # Delete items that match the given condition.
                 del KV[KV.key &gt; 'k1']

              <b>__contains__(expr)</b>

                     <b>Parameters</b>
                            <b>expr</b> -- a single key or an expression

                     <b>Returns</b>
                            Boolean whether key/expression exists.

                     Example:

                        &gt;&gt;&gt; kv = KeyValue()
                        &gt;&gt;&gt; kv.update(k1='v1', k2='v2')

                        &gt;&gt;&gt; 'k1' in kv
                        True
                        &gt;&gt;&gt; 'kx' in kv
                        False

                        &gt;&gt;&gt; (KV.key &lt; 'k2') in KV
                        True
                        &gt;&gt;&gt; (KV.key &gt; 'k2') in KV
                        False

              <b>__len__()</b>

                     <b>Returns</b>
                            Count of items stored.

              <b>__getitem__(expr)</b>

                     <b>Parameters</b>
                            <b>expr</b> -- a single key or an expression.

                     <b>Returns</b>
                            value(s) corresponding to key/expression.

                     <b>Raises</b> <b>KeyError</b> if single key given and not found.

                     Examples:

                        &gt;&gt;&gt; KV = KeyValue()
                        &gt;&gt;&gt; KV.update(k1='v1', k2='v2', k3='v3')

                        &gt;&gt;&gt; KV['k1']
                        'v1'
                        &gt;&gt;&gt; KV['kx']
                        KeyError: "kx" not found

                        &gt;&gt;&gt; KV[KV.key &gt; 'k1']
                        ['v2', 'v3']
                        &gt;&gt;&gt; KV[KV.key &lt; 'k1']
                        []

              <b>__setitem__(expr,</b> <b>value)</b>

                     <b>Parameters</b>

                            • <b>expr</b> -- a single key or an expression.

                            • <b>value</b> -- value to set for key(s)

                     Set  value  for  the  given  key.  If  <b>expr</b>  is  an  expression, then any keys matching the
                     expression will have their value updated.

                     Example:

                        &gt;&gt;&gt; KV = KeyValue()
                        &gt;&gt;&gt; KV.update(k1='v1', k2='v2', k3='v3')

                        &gt;&gt;&gt; KV['k1'] = 'v1-x'
                        &gt;&gt;&gt; print(KV['k1'])
                        'v1-x'

                        &gt;&gt;&gt; KV[KV.key &gt;= 'k2'] = 'v99'
                        &gt;&gt;&gt; dict(KV)
                        {'k1': 'v1-x', 'k2': 'v99', 'k3': 'v99'}

              <b>__delitem__(expr)</b>

                     <b>Parameters</b>
                            <b>expr</b> -- a single key or an expression.

                     Delete the given key. If an expression is given, delete all keys that match the expression.

                     Example:

                        &gt;&gt;&gt; KV = KeyValue()
                        &gt;&gt;&gt; KV.update(k1=1, k2=2, k3=3)

                        &gt;&gt;&gt; del KV['k1']  # Deletes "k1".
                        &gt;&gt;&gt; del KV['k1']
                        KeyError: "k1" does not exist

                        &gt;&gt;&gt; del KV[KV.key &gt; 'k2']  # Deletes "k3".
                        &gt;&gt;&gt; del KV[KV.key &gt; 'k99']  # Nothing deleted, no keys match.

              <b>keys()</b>

                     <b>Returns</b>
                            an iterable of all keys in the table.

              <b>values()</b>

                     <b>Returns</b>
                            an iterable of all values in the table.

              <b>items()</b>

                     <b>Returns</b>
                            an iterable of all key/value pairs in the table.

              <b>update([__data=None[,</b> <b>**mapping]])</b>
                     Efficiently bulk-insert or replace the given key/value pairs.

                     Example:

                        &gt;&gt;&gt; KV = KeyValue()
                        &gt;&gt;&gt; KV.update(k1=1, k2=2)  # Sets 'k1'=1, 'k2'=2.

                        &gt;&gt;&gt; dict(KV)
                        {'k1': 1, 'k2': 2}

                        &gt;&gt;&gt; KV.update(k2=22, k3=3)  # Updates 'k2'-&gt;22, sets 'k3'=3.

                        &gt;&gt;&gt; dict(KV)
                        {'k1': 1, 'k2': 22, 'k3': 3}

                        &gt;&gt;&gt; KV.update({'k2': -2, 'k4': 4})  # Also can pass a dictionary.

                        &gt;&gt;&gt; dict(KV)
                        {'k1': 1, 'k2': -2, 'k3': 3, 'k4': 4}

              <b>get(expr[,</b> <b>default=None])</b>

                     <b>Parameters</b>

                            • <b>expr</b> -- a single key or an expression.

                            • <b>default</b> -- default value if key not found.

                     <b>Returns</b>
                            value of given key/expr or default if single key not found.

                     Get the value at the given key. If the key does not exist, the default value  is  returned,
                     unless the key is an expression in which case an empty list will be returned.

              <b>pop(expr[,</b> <b>default=Sentinel])</b>

                     <b>Parameters</b>

                            • <b>expr</b> -- a single key or an expression.

                            • <b>default</b> -- default value if key does not exist.

                     <b>Returns</b>
                            value of given key/expr or default if single key not found.

                     Get  value  and  delete  the  given  key.  If  the key does not exist, the default value is
                     returned, unless the key is an expression in which case an empty list is returned.

              <b>clear()</b>
                     Remove all items from the key-value table.

   <b>Shortcuts</b>
       This module contains helper functions for expressing things that would otherwise be somewhat  verbose  or
       cumbersome  using  peewee's  APIs.  There  are  also  helpers  for serializing models to dictionaries and
       vice-versa.

       <b>model_to_dict(model[,</b> <b>recurse=True[,</b> <b>backrefs=False[,</b> <b>only=None[,</b> <b>exclude=None[,</b> <b>extra_attrs=None[,</b>
       <b>fields_from_query=None[,</b> <b>max_depth=None[,</b> <b>manytomany=False]]]]]]]])</b>

              <b>Parameters</b>

                     • <b>recurse</b> (<u>bool</u>) -- Whether foreign-keys should be recursed.

                     • <b>backrefs</b> (<u>bool</u>) -- Whether lists of related objects should be recursed.

                     • <b>only</b> -- A list (or set) of field  instances  which  should  be  included  in  the  result
                       dictionary.

                     • <b>exclude</b>  --  A  list (or set) of field instances which should be excluded from the result
                       dictionary.

                     • <b>extra_attrs</b> -- A list of attribute or method  names  on  the  instance  which  should  be
                       included in the dictionary.

                     • <b>fields_from_query</b>  (<u>Select</u>) -- The <u>SelectQuery</u> that created this model instance. Only the
                       fields and values explicitly selected by the query will be serialized.

                     • <b>max_depth</b> (<u>int</u>) -- Maximum depth when recursing.

                     • <b>manytomany</b> (<u>bool</u>) -- Process many-to-many fields.

              Convert a model instance (and optionally any related instances) to a dictionary.

              Examples:

                 &gt;&gt;&gt; user = User.create(username='charlie')
                 &gt;&gt;&gt; model_to_dict(user)
                 {'id': 1, 'username': 'charlie'}

                 &gt;&gt;&gt; model_to_dict(user, backrefs=True)
                 {'id': 1, 'tweets': [], 'username': 'charlie'}

                 &gt;&gt;&gt; t1 = Tweet.create(user=user, message='tweet-1')
                 &gt;&gt;&gt; t2 = Tweet.create(user=user, message='tweet-2')
                 &gt;&gt;&gt; model_to_dict(user, backrefs=True)
                 {
                   'id': 1,
                   'tweets': [
                     {'id': 1, 'message': 'tweet-1'},
                     {'id': 2, 'message': 'tweet-2'},
                   ],
                   'username': 'charlie'
                 }

                 &gt;&gt;&gt; model_to_dict(t1)
                 {
                   'id': 1,
                   'message': 'tweet-1',
                   'user': {
                     'id': 1,
                     'username': 'charlie'
                   }
                 }

                 &gt;&gt;&gt; model_to_dict(t2, recurse=False)
                 {'id': 1, 'message': 'tweet-2', 'user': 1}

              The implementation of <b>model_to_dict</b> is fairly complex, owing to the various usages it attempts  to
              support.  If you have a special usage, I strongly advise that you do <b>not</b> attempt to shoe-horn some
              crazy combination of parameters into this function. Just write a simple function that accomplishes
              exactly what you're attempting to do.

       <b>dict_to_model(model_class,</b> <b>data[,</b> <b>ignore_unknown=False])</b>

              <b>Parameters</b>

                     • <b>model_class</b> (<u>Model</u>) -- The model class to construct.

                     • <b>data</b> (<u>dict</u>) -- A dictionary of data. Foreign keys can be included as nested dictionaries,
                       and back-references as lists of dictionaries.

                     • <b>ignore_unknown</b> (<u>bool</u>) -- Whether to allow unrecognized (non-field) attributes.

              Convert a dictionary of data to a model instance, creating related instances where appropriate.

              Examples:

                 &gt;&gt;&gt; user_data = {'id': 1, 'username': 'charlie'}
                 &gt;&gt;&gt; user = dict_to_model(User, user_data)
                 &gt;&gt;&gt; user
                 &lt;__main__.User at 0x7fea8fa4d490&gt;

                 &gt;&gt;&gt; user.username
                 'charlie'

                 &gt;&gt;&gt; note_data = {'id': 2, 'text': 'note text', 'user': user_data}
                 &gt;&gt;&gt; note = dict_to_model(Note, note_data)
                 &gt;&gt;&gt; note.text
                 'note text'
                 &gt;&gt;&gt; note.user.username
                 'charlie'

                 &gt;&gt;&gt; user_with_notes = {
                 ...     'id': 1,
                 ...     'username': 'charlie',
                 ...     'notes': [{'id': 1, 'text': 'note-1'}, {'id': 2, 'text': 'note-2'}]}
                 &gt;&gt;&gt; user = dict_to_model(User, user_with_notes)
                 &gt;&gt;&gt; user.notes[0].text
                 'note-1'
                 &gt;&gt;&gt; user.notes[0].user.username
                 'charlie'

       <b>update_model_from_dict(instance,</b> <b>data[,</b> <b>ignore_unknown=False])</b>

              <b>Parameters</b>

                     • <b>instance</b> (<u>Model</u>) -- The model instance to update.

                     • <b>data</b> (<u>dict</u>) -- A dictionary of data. Foreign keys can be included as nested dictionaries,
                       and back-references as lists of dictionaries.

                     • <b>ignore_unknown</b> (<u>bool</u>) -- Whether to allow unrecognized (non-field) attributes.

              Update a model instance with the given data dictionary.

       <b>resolve_multimodel_query(query[,</b> <b>key='_model_identifier'])</b>

              <b>Parameters</b>

                     • <b>query</b> -- a compound select query.

                     • <b>key</b> (<u>str</u>) -- key to use for storing model identifier

              <b>Returns</b>
                     an iteratable cursor that yields the proper model instance for each  row  selected  in  the
                     compound select query.

              Helper  for resolving rows returned in a compound select query to the correct model instance type.
              For example, if you have a union of two different tables, this helper will resolve each row to the
              proper model when iterating over the query results.

       <b>class</b> <b>ThreadSafeDatabaseMetadata</b>
              Model <u>Metadata</u> implementation that provides thread-safe access to the <b>database</b> attribute, allowing
              applications to swap the database at run-time safely in a multi-threaded application.

              Usage:

                 from playhouse.shortcuts import ThreadSafeDatabaseMetadata

                 # Our multi-threaded application will sometimes swap out the primary
                 # for the read-replica at run-time.
                 primary = PostgresqlDatabase(...)
                 read_replica = PostgresqlDatabase(...)

                 class BaseModel(Model):
                     class Meta:
                         database = primary
                         model_metadata_class = ThreadSafeDatabaseMetadata

   <b>Signal</b> <b>support</b>
       Models with hooks for signals (a-la django) are provided in <b>playhouse.signals</b>. To use  the  signals,  you
       will  need  all of your project's models to be a subclass of <b>playhouse.signals.Model</b>, which overrides the
       necessary methods to provide support for the various signals.

          from playhouse.signals import Model, post_save

          class MyModel(Model):
              data = IntegerField()

          @post_save(sender=MyModel)
          def on_save_handler(model_class, instance, created):
              put_data_in_cache(instance.data)

       <b>WARNING:</b>
          For what I hope are obvious reasons, Peewee signals do not  work  when  you  use  the  <u>Model.insert()</u>,
          <u>Model.update()</u>,  or  <u>Model.delete()</u>  methods.  These  methods generate queries that execute beyond the
          scope of the ORM, and the ORM does not know about which model instances might or might not be affected
          when the query executes.

          Signals   work   by   hooking   into   the   higher-level   peewee   APIs   like   <u>Model.save()</u>    and
          <u>Model.delete_instance()</u>, where the affected model instance is known ahead of time.

       The following signals are provided:

       <b>pre_save</b>
              Called  immediately  before  an  object  is  saved to the database. Provides an additional keyword
              argument <b>created</b>, indicating whether the model is being saved for the first time or updated.

       <b>post_save</b>
              Called immediately after an object is saved  to  the  database.  Provides  an  additional  keyword
              argument <b>created</b>, indicating whether the model is being saved for the first time or updated.

       <b>pre_delete</b>
              Called  immediately  before an object is deleted from the database when <u>Model.delete_instance()</u> is
              used.

       <b>post_delete</b>
              Called immediately after an object is deleted from the database  when  <u>Model.delete_instance()</u>  is
              used.

       <b>pre_init</b>
              Called when a model class is first instantiated

   <b>Connecting</b> <b>handlers</b>
       Whenever a signal is dispatched, it will call any handlers that have been registered. This allows totally
       separate code to respond to events like model save and delete.

       The <u>Signal</u> class provides a <u>connect()</u> method, which takes a callback function and two optional parameters
       for  "sender"  and "name". If specified, the "sender" parameter should be a single model class and allows
       your callback to only receive signals from that one model class.  The  "name"  parameter  is  used  as  a
       convenient alias in the event you wish to unregister your signal handler.

       Example usage:

          from playhouse.signals import *

          def post_save_handler(sender, instance, created):
              print('%s was just saved' % instance)

          # our handler will only be called when we save instances of SomeModel
          post_save.connect(post_save_handler, sender=SomeModel)

       All  signal  handlers  accept as their first two arguments <b>sender</b> and <b>instance</b>, where <b>sender</b> is the model
       class and <b>instance</b> is the actual model being acted upon.

       If you'd like, you can also use a decorator to connect signal handlers. This is  functionally  equivalent
       to the above example:

          @post_save(sender=SomeModel)
          def post_save_handler(sender, instance, created):
              print('%s was just saved' % instance)

   <b>Signal</b> <b>API</b>
       <b>class</b> <b>Signal</b>
              Stores a list of receivers (callbacks) and calls them when the "send" method is invoked.

              <b>connect(receiver[,</b> <b>name=None[,</b> <b>sender=None]])</b>

                     <b>Parameters</b>

                            • <b>receiver</b>  (<u>callable</u>) -- a callable that takes at least two parameters, a "sender",
                              which is the Model subclass that triggered the signal, and an "instance", which is
                              the actual model instance.

                            • <b>name</b> (<u>string</u>) -- a short alias

                            • <b>sender</b> (<u>Model</u>) -- if specified, only instances of this model  class  will  trigger
                              the receiver callback.

                     Add  the  receiver  to  the  internal  list of receivers, which will be called whenever the
                     signal is sent.

                        from playhouse.signals import post_save
                        from project.handlers import cache_buster

                        post_save.connect(cache_buster, name='project.cache_buster')

              <b>disconnect([receiver=None[,</b> <b>name=None[,</b> <b>sender=None]]])</b>

                     <b>Parameters</b>

                            • <b>receiver</b> (<u>callable</u>) -- the callback to disconnect

                            • <b>name</b> (<u>string</u>) -- a short alias

                            • <b>sender</b> (<u>Model</u>) -- disconnect model-specific handler.

                     Disconnect the given receiver (or the receiver with the given name alias)  so  that  it  no
                     longer is called. Either the receiver or the name must be provided.

                        post_save.disconnect(name='project.cache_buster')

              <b>send(instance,</b> <b>*args,</b> <b>**kwargs)</b>

                     <b>Parameters</b>
                            <b>instance</b> -- a model instance

                     Iterates  over  the receivers and will call them in the order in which they were connected.
                     If the receiver specified a sender, it will only be called if the instance is  an  instance
                     of the sender.

   <b>pwiz,</b> <b>a</b> <b>model</b> <b>generator</b>
       <b>pwiz</b>  is  a little script that ships with peewee and is capable of introspecting an existing database and
       generating model code suitable for interacting with the underlying data. If you have a database  already,
       pwiz  can  give  you  a nice boost by generating skeleton code with correct column affinities and foreign
       keys.

       If you install peewee using <b>setup.py</b> <b>install</b>, pwiz will be installed as a "script" and you can just run:

          python -m pwiz -e postgresql -u postgres my_postgres_db

       This will print a bunch of models to standard output. So you can do this:

          python -m pwiz -e postgresql my_postgres_db &gt; mymodels.py
          python # &lt;-- fire up an interactive shell

          &gt;&gt;&gt; from mymodels import Blog, Entry, Tag, Whatever
          &gt;&gt;&gt; print([blog.name for blog in Blog.select()])

   <b>Command-line</b> <b>options</b>
       pwiz accepts the following command-line options:
                       ┌────────┬──────────────────────────────┬──────────────────────────────┐
                       │ Option │ Meaning                      │ Example                      │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -h     │ show help                    │                              │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -e     │ database backend             │ -e mysql                     │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -H     │ host to connect to           │ -H remote.db.server          │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -p     │ port to connect on           │ -p 9001                      │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -u     │ database user                │ -u postgres                  │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -P     │ database password            │ -P  (will  be  prompted  for │
                       │        │                              │ password)                    │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -s     │ schema                       │ -s public                    │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -t     │ tables to generate           │ -t tweet,users,relationships │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -v     │ generate models for VIEWs    │ (no argument)                │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -i     │ add    info    metadata   to │ (no argument)                │
                       │        │ generated file               │                              │
                       ├────────┼──────────────────────────────┼──────────────────────────────┤
                       │ -o     │ table   column   order    is │ (no argument)                │
                       │        │ preserved                    │                              │
                       └────────┴──────────────────────────────┴──────────────────────────────┘

       The following are valid parameters for the <b>engine</b> (<b>-e</b>):

       • sqlite

       • mysql

       • postgresql

       <b>WARNING:</b>
          If  a  password  is  required to access your database, you will be prompted to enter it using a secure
          prompt.

          <b>The</b> <b>password</b> <b>will</b> <b>be</b> <b>included</b> <b>in</b> <b>the</b> <b>output</b>. Specifically, at the top of the file a <u>Database</u>  will  be
          defined along with any required parameters -- including the password.

   <b>pwiz</b> <b>examples</b>
       Examples of introspecting various databases:

          # Introspect a Sqlite database.
          python -m pwiz -e sqlite path/to/sqlite_database.db

          # Introspect a MySQL database, logging in as root. You will be prompted
          # for a password ("-P").
          python -m pwiz -e mysql -u root -P mysql_db_name

          # Introspect a Postgresql database on a remote server.
          python -m pwiz -e postgres -u postgres -H 10.1.0.3 pg_db_name

       Full example:

          $ sqlite3 example.db &lt;&lt; EOM
          CREATE TABLE "user" ("id" INTEGER NOT NULL PRIMARY KEY, "username" TEXT NOT NULL);
          CREATE TABLE "tweet" (
              "id" INTEGER NOT NULL PRIMARY KEY,
              "content" TEXT NOT NULL,
              "timestamp" DATETIME NOT NULL,
              "user_id" INTEGER NOT NULL,
              FOREIGN KEY ("user_id") REFERENCES "user" ("id"));
          CREATE UNIQUE INDEX "user_username" ON "user" ("username");
          EOM

          $ python -m pwiz -e sqlite example.db

       Produces the following output:

          from peewee import *

          database = SqliteDatabase('example.db', **{})

          class UnknownField(object):
              def __init__(self, *_, **__): pass

          class BaseModel(Model):
              class Meta:
                  database = database

          class User(BaseModel):
              username = TextField(unique=True)

              class Meta:
                  table_name = 'user'

          class Tweet(BaseModel):
              content = TextField()
              timestamp = DateTimeField()
              user = ForeignKeyField(column_name='user_id', field='id', model=User)

              class Meta:
                  table_name = 'tweet'

       Observations:

       • The foreign-key <b>Tweet.user_id</b> is detected and mapped correctly.

       • The <b>User.username</b> UNIQUE constraint is detected.

       • Each model explicitly declares its table name, even in cases where it is not necessary (as Peewee would
         automatically translate the class name into the appropriate table name).

       • All  the  parameters  of  the  <u>ForeignKeyField</u>  are  explicitly  declared,  even though they follow the
         conventions Peewee uses by default.

       <b>NOTE:</b>
          The <b>UnknownField</b> is a placeholder that is used in the event your schema contains a column  declaration
          that Peewee doesn't know how to map to a field class.

   <b>Schema</b> <b>Migrations</b>
       Peewee  now supports schema migrations, with well-tested support for Postgresql, SQLite and MySQL. Unlike
       other schema migration tools, peewee's migrations do not handle introspection and database  "versioning".
       Rather,  peewee  provides  a  number  of  helper  functions  for  generating  and running schema-altering
       statements. This engine provides the basis on which a more sophisticated tool could some day be built.

       Migrations can be written as simple  python  scripts  and  executed  from  the  command-line.  Since  the
       migrations  only  depend  on your applications <u>Database</u> object, it should be easy to manage changing your
       model definitions and maintaining a set of migration scripts without introducing dependencies.

   <b>Example</b> <b>usage</b>
       Begin by importing the helpers from the <u>migrate</u> module:

          from playhouse.migrate import *

       Instantiate  a  <b>migrator</b>.  The  <u>SchemaMigrator</u>  class  is  responsible  for  generating  schema  altering
       operations, which can then be run sequentially by the <u>migrate()</u> helper.

          # Postgres example:
          my_db = PostgresqlDatabase(...)
          migrator = <a href="../manmy_db/PostgresqlMigrator.my_db.html">PostgresqlMigrator</a>(my_db)

          # SQLite example:
          my_db = SqliteDatabase('my_database.db')
          migrator = <a href="../manmy_db/SqliteMigrator.my_db.html">SqliteMigrator</a>(my_db)

       Use <u>migrate()</u> to execute one or more operations:

          title_field = CharField(default='')
          status_field = IntegerField(null=True)

          migrate(
              migrator.add_column('some_table', 'title', title_field),
              migrator.add_column('some_table', 'status', status_field),
              migrator.drop_column('some_table', 'old_column'),
          )

       <b>WARNING:</b>
          Migrations  are  not  run  inside a transaction. If you wish the migration to run in a transaction you
          will need to wrap the call to <u>migrate</u> in a <u>atomic()</u> context-manager, e.g.

              with my_db.atomic():
                  migrate(...)

   <b>Supported</b> <b>Operations</b>
       Add new field(s) to an existing model:

          # Create your field instances. For non-null fields you must specify a
          # default value.
          pubdate_field = DateTimeField(null=True)
          comment_field = TextField(default='')

          # Run the migration, specifying the database table, field name and field.
          migrate(
              migrator.add_column('comment_tbl', 'pub_date', pubdate_field),
              migrator.add_column('comment_tbl', 'comment', comment_field),
          )

       <b>NOTE:</b>
          Peewee follows the Django convention of, by default, appending <b>_id</b> to the  column  name  for  a  given
          <u>ForeignKeyField</u>.  When  adding  a  foreign-key,  you will want to ensure you give it the proper column
          name. For example, if I want to add a <b>user</b> foreign-key to a <b>Tweet</b> model:

              # Our desired model will look like this:
              class Tweet(BaseModel):
                  user = ForeignKeyField(User)  # I want to add this field.
                  # ... other fields ...

              # Migration code:
              user = ForeignKeyField(User, field=User.id, null=True)
              migrate(
                  # Note that the column name given is "user_id".
                  migrator.add_column(Tweet._meta.table_name, 'user_id', user),
              )

       Renaming a field:

          # Specify the table, original name of the column, and its new name.
          migrate(
              migrator.rename_column('story', 'pub_date', 'publish_date'),
              migrator.rename_column('story', 'mod_date', 'modified_date'),
          )

       Dropping a field:

          migrate(
              migrator.drop_column('story', 'some_old_field'),
          )

       Making a field nullable or not nullable:

          # Note that when making a field not null that field must not have any
          # NULL values present.
          migrate(
              # Make `pub_date` allow NULL values.
              migrator.drop_not_null('story', 'pub_date'),

              # Prevent `modified_date` from containing NULL values.
              migrator.add_not_null('story', 'modified_date'),
          )

       Altering a field's data-type:

          # Change a <a href="../man50/VARCHAR.50.html">VARCHAR</a>(50) field to a TEXT field.
          migrate(
              migrator.alter_column_type('person', 'email', TextField())
          )

       Renaming a table:

          migrate(
              migrator.rename_table('story', 'stories_tbl'),
          )

       Adding an index:

          # Specify the table, column names, and whether the index should be
          # UNIQUE or not.
          migrate(
              # Create an index on the `pub_date` column.
              migrator.add_index('story', ('pub_date',), False),

              # Create a multi-column index on the `pub_date` and `status` fields.
              migrator.add_index('story', ('pub_date', 'status'), False),

              # Create a unique index on the category and title fields.
              migrator.add_index('story', ('category_id', 'title'), True),
          )

       Dropping an index:

          # Specify the index name.
          migrate(migrator.drop_index('story', 'story_pub_date_status'))

       Adding or dropping table constraints:

          # Add a CHECK() constraint to enforce the price cannot be negative.
          migrate(migrator.add_constraint(
              'products',
              'price_check',
              Check('price &gt;= 0')))

          # Remove the price check constraint.
          migrate(migrator.drop_constraint('products', 'price_check'))

          # Add a UNIQUE constraint on the first and last names.
          migrate(migrator.add_unique('person', 'first_name', 'last_name'))

       Adding or dropping a database-level default value for a column:

          # Add a default value for a status column.
          migrate(migrator.add_column_default(
              'entries',
              'status',
              'draft'))

          # Remove the default.
          migrate(migrator.drop_column_default('entries', 'status'))

          # Use a function for the default value (does not work with Sqlite):
          migrate(migrator.add_column_default(
              'entries',
              'timestamp',
              fn.now()))

          # Or alternatively (works with Sqlite):
          migrate(migrator.add_column_default(
              'entries',
              'timestamp',
              'now()'))

       <b>NOTE:</b>
          Postgres users may need to set the search-path when using a non-standard schema. This can be  done  as
          follows:

              new_field = TextField(default='', null=False)
              migrator = PostgresqlMigrator(db)
              migrate(migrator.set_search_path('my_schema_name'),
                      migrator.add_column('table', 'field_name', new_field))

   <b>Migrations</b> <b>API</b>
       <b>migrate(*operations)</b>
              Execute one or more schema altering operations.

              Usage:

                 migrate(
                     migrator.add_column('some_table', 'new_column', CharField(default='')),
                     migrator.create_index('some_table', ('new_column',)),
                 )

       <b>class</b> <b>SchemaMigrator(database)</b>

              <b>Parameters</b>
                     <b>database</b> -- a <u>Database</u> instance.

              The <u>SchemaMigrator</u> is responsible for generating schema-altering statements.

              <b>add_column(table,</b> <b>column_name,</b> <b>field)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of the table to add column to.

                            • <b>column_name</b> (<u>str</u>) -- Name of the new column.

                            • <b>field</b> (<u>Field</u>) -- A <u>Field</u> instance.

                     Add  a  new  column  to the provided table. The <b>field</b> provided will be used to generate the
                     appropriate column definition.

                     <b>NOTE:</b>
                        If the field is not nullable it must specify a default value.

                     <b>NOTE:</b>
                        For non-null fields, the field will initially be added as a null field, then  an  <b>UPDATE</b>
                        statement  will  be executed to populate the column with the default value. Finally, the
                        column will be marked as not null.

              <b>drop_column(table,</b> <b>column_name[,</b> <b>cascade=True])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of the table to drop column from.

                            • <b>column_name</b> (<u>str</u>) -- Name of the column to drop.

                            • <b>cascade</b> (<u>bool</u>) -- Whether the column should be dropped with <u>CASCADE</u>.

              <b>rename_column(table,</b> <b>old_name,</b> <b>new_name)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of the table containing column to rename.

                            • <b>old_name</b> (<u>str</u>) -- Current name of the column.

                            • <b>new_name</b> (<u>str</u>) -- New name for the column.

              <b>add_not_null(table,</b> <b>column)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of table containing column.

                            • <b>column</b> (<u>str</u>) -- Name of the column to make not nullable.

              <b>drop_not_null(table,</b> <b>column)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of table containing column.

                            • <b>column</b> (<u>str</u>) -- Name of the column to make nullable.

              <b>add_column_default(table,</b> <b>column,</b> <b>default)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of table containing column.

                            • <b>column</b> (<u>str</u>) -- Name of the column to add default to.

                            • <b>default</b> -- New default value for column. See notes below.

                     Peewee attempts to properly quote the default  if  it  appears  to  be  a  string  literal.
                     Otherwise the default will be treated literally.  Postgres and MySQL support specifying the
                     default  as  a  peewee  expression,  e.g.  <b>fn.NOW()</b>,  but  Sqlite  users  will  need to use
                     <b>default='now()'</b> instead.

              <b>drop_column_default(table,</b> <b>column)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of table containing column.

                            • <b>column</b> (<u>str</u>) -- Name of the column to remove default from.

              <b>alter_column_type(table,</b> <b>column,</b> <b>field[,</b> <b>cast=None])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of the table.

                            • <b>column_name</b> (<u>str</u>) -- Name of the column to modify.

                            • <b>field</b> (<u>Field</u>) -- <u>Field</u> instance representing new data type.

                            • <b>cast</b>  --  (postgres-only)  specify  a  cast  expression  if  the  data-types   are
                              incompatible,  e.g. <b>column_name::int</b>. Can be provided as either a string or a <u>Cast</u>
                              instance.

                     Alter the data-type  of  a  column.  This  method  should  be  used  with  care,  as  using
                     incompatible types may not be well-supported by your database.

              <b>rename_table(old_name,</b> <b>new_name)</b>

                     <b>Parameters</b>

                            • <b>old_name</b> (<u>str</u>) -- Current name of the table.

                            • <b>new_name</b> (<u>str</u>) -- New name for the table.

              <b>add_index(table,</b> <b>columns[,</b> <b>unique=False[,</b> <b>using=None]])</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of table on which to create the index.

                            • <b>columns</b> (<u>list</u>) -- List of columns which should be indexed.

                            • <b>unique</b> (<u>bool</u>) -- Whether the new index should specify a unique constraint.

                            • <b>using</b> (<u>str</u>) -- Index type (where supported), e.g. GiST or GIN.

              <b>drop_index(table,</b> <b>index_name)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Name of the table containing the index to be dropped.

                            • <b>index_name</b> (<u>str</u>) -- Name of the index to be dropped.

              <b>add_constraint(table,</b> <b>name,</b> <b>constraint)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table to add constraint to.

                            • <b>name</b> (<u>str</u>) -- Name used to identify the constraint.

                            • <b>constraint</b>  --  either  a <u>Check()</u> constraint or for adding an arbitrary constraint
                              use <u>SQL</u>.

              <b>drop_constraint(table,</b> <b>name)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table to drop constraint from.

                            • <b>name</b> (<u>str</u>) -- Name of constraint to drop.

              <b>add_unique(table,</b> <b>*column_names)</b>

                     <b>Parameters</b>

                            • <b>table</b> (<u>str</u>) -- Table to add constraint to.

                            • <b>column_names</b> (<u>str</u>) -- One or more columns for UNIQUE constraint.

       <b>class</b> <b>PostgresqlMigrator(database)</b>
              Generate migrations for Postgresql databases.

              <b>set_search_path(schema_name)</b>

                     <b>Parameters</b>
                            <b>schema_name</b> (<u>str</u>) -- Schema to use.

                     Set the search path (schema) for the subsequent operations.

       <b>class</b> <b>SqliteMigrator(database)</b>
              Generate migrations for SQLite databases.

              SQLite has limited support for <b>ALTER</b> <b>TABLE</b> queries, so the following operations are currently  not
              supported for SQLite:

              • <b>add_constraint</b>

              • <b>drop_constraint</b>

              • <b>add_unique</b>

       <b>class</b> <b>MySQLMigrator(database)</b>
              Generate migrations for MySQL databases.

   <b>Reflection</b>
       The  reflection  module  contains  helpers  for  introspecting  existing  databases.  This module is used
       internally by several other modules in the playhouse, including <u>DataSet</u> and <u>pwiz,</u> <u>a</u> <u>model</u> <u>generator</u>.

       <b>generate_models(database[,</b> <b>schema=None[,</b> <b>**options]])</b>

              <b>Parameters</b>

                     • <b>database</b> (<u>Database</u>) -- database instance to introspect.

                     • <b>schema</b> (<u>str</u>) -- optional schema to introspect.

                     • <b>options</b> -- arbitrary options, see <u>Introspector.generate_models()</u> for details.

              <b>Returns</b>
                     a <b>dict</b> mapping table names to model classes.

              Generate models for the tables in the given database. For an example of how to use this  function,
              see the section <u>Using</u> <u>Peewee</u> <u>Interactively</u>.

              Example:

                 &gt;&gt;&gt; from peewee import *
                 &gt;&gt;&gt; from playhouse.reflection import generate_models
                 &gt;&gt;&gt; db = PostgresqlDatabase('my_app')
                 &gt;&gt;&gt; models = generate_models(db)
                 &gt;&gt;&gt; list(models.keys())
                 ['account', 'customer', 'order', 'orderitem', 'product']

                 &gt;&gt;&gt; globals().<a href="../manmodels/update.models.html">update</a>(models)  # Inject models into namespace.
                 &gt;&gt;&gt; for cust in customer.select():  # Query using generated model.
                 ...     print(cust.name)
                 ...

                 Huey Kitty
                 Mickey Dog

       <b><a href="../manmodel/print_model.model.html">print_model</a>(model)</b>

              <b>Parameters</b>
                     <b>model</b> (<u>Model</u>) -- model class to print

              <b>Returns</b>
                     no return value

              Print  a  user-friendly  description  of  a  model class, useful for debugging or interactive use.
              Currently this prints the table name, and all fields along with their data-types. The <u>Using</u> <u>Peewee</u>
              <u>Interactively</u> section contains an example.

              Example output:

                 &gt;&gt;&gt; from playhouse.reflection import print_model
                 &gt;&gt;&gt; print_model(User)
                 user
                   id AUTO PK
                   email TEXT
                   name TEXT
                   dob DATE

                 index(es)
                   email UNIQUE

                 &gt;&gt;&gt; print_model(Tweet)
                 tweet
                   id AUTO PK
                   user INT FK: User.id
                   title TEXT
                   content TEXT
                   timestamp DATETIME
                   is_published BOOL

                 index(es)
                   user_id
                   is_published, timestamp

       <b><a href="../manmodel/print_table_sql.model.html">print_table_sql</a>(model)</b>

              <b>Parameters</b>
                     <b>model</b> (<u>Model</u>) -- model to print

              <b>Returns</b>
                     no return value

              Prints the SQL <b>CREATE</b> <b>TABLE</b> for the given model class,  which  may  be  useful  for  debugging  or
              interactive  use.  See the <u>Using</u> <u>Peewee</u> <u>Interactively</u> section for example usage. Note that indexes
              and constraints are not included in the output of this function.

              Example output:

                 &gt;&gt;&gt; from playhouse.reflection import print_table_sql
                 &gt;&gt;&gt; print_table_sql(User)
                 CREATE TABLE IF NOT EXISTS "user" (
                   "id" INTEGER NOT NULL PRIMARY KEY,
                   "email" TEXT NOT NULL,
                   "name" TEXT NOT NULL,
                   "dob" DATE NOT NULL
                 )

                 &gt;&gt;&gt; print_table_sql(Tweet)
                 CREATE TABLE IF NOT EXISTS "tweet" (
                   "id" INTEGER NOT NULL PRIMARY KEY,
                   "user_id" INTEGER NOT NULL,
                   "title" TEXT NOT NULL,
                   "content" TEXT NOT NULL,
                   "timestamp" DATETIME NOT NULL,
                   "is_published" INTEGER NOT NULL,
                   FOREIGN KEY ("user_id") REFERENCES "user" ("id")
                 )

       <b>class</b> <b>Introspector(metadata[,</b> <b>schema=None])</b>
              Metadata can  be  extracted  from  a  database  by  instantiating  an  <u>Introspector</u>.  Rather  than
              instantiating this class directly, it is recommended to use the factory method <u>from_database()</u>.

              <b>classmethod</b> <b>from_database(database[,</b> <b>schema=None])</b>

                     <b>Parameters</b>

                            • <b>database</b> -- a <u>Database</u> instance.

                            • <b>schema</b> (<u>str</u>) -- an optional schema (supported by some databases).

                     Creates an <u>Introspector</u> instance suitable for use with the given database.

                     Usage:

                        db = SqliteDatabase('my_app.db')
                        introspector = Introspector.from_database(db)
                        models = introspector.generate_models()

                        # User and Tweet (assumed to exist in the database) are
                        # peewee Model classes generated from the database schema.
                        User = models['user']
                        Tweet = models['tweet']

              <b>generate_models([skip_invalid=False[,</b> <b>table_names=None[,</b> <b>literal_column_names=False[,</b>
              <b>bare_fields=False[,</b> <b>include_views=False]]]]])</b>

                     <b>Parameters</b>

                            • <b>skip_invalid</b> (<u>bool</u>) -- Skip tables whose names are invalid python identifiers.

                            • <b>table_names</b>  (<u>list</u>) -- List of table names to generate. If unspecified, models are
                              generated for all tables.

                            • <b>literal_column_names</b> (<u>bool</u>) -- Use column-names as-is. By  default,  column  names
                              are "python-ized", i.e. mixed-case becomes lower-case.

                            • <b>bare_fields</b> -- <b>SQLite-only</b>. Do not specify data-types for introspected columns.

                            • <b>include_views</b> -- generate models for VIEWs as well.

                     <b>Returns</b>
                            A dictionary mapping table-names to model classes.

                     Introspect  the database, reading in the tables, columns, and foreign key constraints, then
                     generate a dictionary mapping each database table to a dynamically-generated <u>Model</u> class.

   <b>Database</b> <b>URL</b>
       This module contains a helper function to generate a database connection from a URL connection string.

       <b>connect(url,</b> <b>**connect_params)</b>
              Create a <u>Database</u> instance from the given connection URL.

              Examples:

              • <u>sqlite:///my_database.db</u> will create a <u>SqliteDatabase</u> instance for the  file  <b>my_database.db</b>  in
                the current directory.

              • <u>sqlite:///:memory:</u> will create an in-memory <u>SqliteDatabase</u> instance.

              • <u>postgresql://postgres:my_password@localhost:5432/my_database</u>  will  create  a <u>PostgresqlDatabase</u>
                instance. A username and password are provided, as well as the host and port to connect to.

              • <u>mysql://user:passwd@ip:port/my_db</u> will create a  <u>MySQLDatabase</u>  instance  for  the  local  MySQL
                database <u>my_db</u>.

              • <u>mysql+pool://user:passwd@ip:port/my_db?max_connections=20&amp;stale_timeout=300</u>    will   create   a
                <u>PooledMySQLDatabase</u> instance for the local MySQL database <u>my_db</u> with max_connections set  to  20
                and a stale_timeout setting of 300 seconds.

              Supported schemes:

              • <b>apsw</b>: <u>APSWDatabase</u>

              • <b>cockroachdb</b>: <u>CockroachDatabase</u>

              • <b>cockroachdb+pool</b>: <u>PooledCockroachDatabase</u>

              • <b>mysql</b>: <u>MySQLDatabase</u>

              • <b>mysql+pool</b>: <u>PooledMySQLDatabase</u>

              • <b>postgres</b>: <u>PostgresqlDatabase</u>

              • <b>postgres+pool</b>: <u>PooledPostgresqlDatabase</u>

              • <b>postgresext</b>: <u>PostgresqlExtDatabase</u>

              • <b>postgresext+pool</b>: <u>PooledPostgresqlExtDatabase</u>

              • <b>psycopg3</b>: <b>Psycopg3Database</b>

              • <b>psycopg3+pool</b>: <b>PooledPsycopg3Database</b>

              • <b>sqlite</b>: <u>SqliteDatabase</u>

              • <b>sqliteext</b>: <u>SqliteExtDatabase</u>

              • <b>sqlite+pool</b>: <u>PooledSqliteDatabase</u>

              • <b>sqliteext+pool</b>: <u>PooledSqliteExtDatabase</u>

              Usage:

                 import os
                 from playhouse.db_url import connect

                 # Connect to the database URL defined in the environment, falling
                 # back to a local Sqlite database if no database URL is specified.
                 db = connect(os.environ.get('DATABASE') or 'sqlite:///default.db')

       <b>parse(url)</b>
              Parse  the  information  in  the given URL into a dictionary containing <b>database</b>, <b>host</b>, <b>port</b>, <b>user</b>
              and/or <b>password</b>. Additional connection arguments can be passed in the URL query string.

              If you are using a custom database class, you can use the <b>parse()</b> function to extract  information
              from a URL which can then be passed in to your database object.

       <b>register_database(db_class,</b> <b>*names)</b>

              <b>Parameters</b>

                     • <b>db_class</b> -- A subclass of <u>Database</u>.

                     • <b>names</b> -- A list of names to use as the scheme in the URL, e.g. 'sqlite' or 'firebird'

              Register  additional database class under the specified names. This function can be used to extend
              the <b>connect()</b> function to support additional schemes. Suppose you have a custom database class for
              <b>Firebird</b> named <b>FirebirdDatabase</b>.

                 from playhouse.db_url import connect, register_database

                 register_database(FirebirdDatabase, 'firebird')
                 db = connect('firebird://my-firebird-db')

   <b>Connection</b> <b>pool</b>
       The <b>pool</b> module contains a number of <u>Database</u> classes that provide  connection  pooling  for  PostgreSQL,
       MySQL  and SQLite databases. The pool works by overriding the methods on the <u>Database</u> class that open and
       close connections to the backend. The pool can specify a timeout after which connections are recycled, as
       well as an upper bound on the number of open connections.

       In a multi-threaded application, up to <u>max_connections</u> will be opened. Each thread (or, if using  gevent,
       greenlet) will have its own connection.

       In  a  single-threaded  application, only one connection will be created. It will be continually recycled
       until either it exceeds the stale timeout or is closed explicitly (using <u>.manual_close()</u>).

       <b>By</b> <b>default,</b> <b>all</b> <b>your</b> <b>application</b> <b>needs</b> <b>to</b> <b>do</b> <b>is</b> <b>ensure</b> <b>that</b> <b>connections</b> <b>are</b> <b>closed</b> <b>when</b> <b>you</b> <b>are</b>  <b>finished</b>
       <b>with</b>  <b>them,</b> <b>and</b> <b>they</b> <b>will</b> <b>be</b> <b>returned</b> <b>to</b> <b>the</b> <b>pool</b>. For web applications, this typically means that at the
       beginning of a request, you will open a connection, and when you return a response, you  will  close  the
       connection.

       Simple Postgres pool example code:

          # Use the special postgresql extensions.
          from playhouse.pool import PooledPostgresqlExtDatabase

          db = PooledPostgresqlExtDatabase(
              'my_app',
              max_connections=32,
              stale_timeout=300,  # 5 minutes.
              user='postgres')

          class BaseModel(Model):
              class Meta:
                  database = db

       That's it! If you would like finer-grained control over the pool of connections, check out the <u>Connection</u>
       <u>Management</u> section.

   <b>Pool</b> <b>APIs</b>
       <b>class</b> <b>PooledDatabase(database[,</b> <b>max_connections=20[,</b> <b>stale_timeout=None[,</b> <b>timeout=None[,</b> <b>**kwargs]]]])</b>

              <b>Parameters</b>

                     • <b>database</b> (<u>str</u>) -- The name of the database or database file.

                     • <b>max_connections</b> (<u>int</u>) -- Maximum number of connections. Provide <b>None</b> for unlimited.

                     • <b>stale_timeout</b> (<u>int</u>) -- Number of seconds to allow connections to be used.

                     • <b>timeout</b> (<u>int</u>) -- Number of seconds to block when pool is full. By default peewee does not
                       block  when  the  pool  is full but simply throws an exception. To block indefinitely set
                       this value to <b>0</b>.

                     • <b>kwargs</b> -- Arbitrary keyword arguments passed to database class.

              Mixin class intended to be used with a subclass of <u>Database</u>.

              <b>NOTE:</b>
                 Connections will not be closed exactly when they exceed  their  <u>stale_timeout</u>.  Instead,  stale
                 connections are only closed when a new connection is requested.

              <b>NOTE:</b>
                 If the number of open connections exceeds <u>max_connections</u>, a <u>ValueError</u> will be raised.

              <b>manual_close()</b>
                     Close the currently-open connection without returning it to the pool.

              <b>close_idle()</b>
                     Close all idle connections. This does not include any connections that are currently in-use
                     -- only those that were previously created but have since been returned back to the pool.

              <b>close_stale([age=600])</b>

                     <b>Parameters</b>
                            <b>age</b> (<u>int</u>) -- Age at which a connection should be considered stale.

                     <b>Returns</b>
                            Number of connections closed.

                     Close  connections which are in-use but exceed the given age. <b>Use</b> <b>caution</b> <b>when</b> <b>calling</b> <b>this</b>
                     <b>method!</b>

              <b>close_all()</b>
                     Close all connections. This includes any connections that may be in use at  the  time.  <b>Use</b>
                     <b>caution</b> <b>when</b> <b>calling</b> <b>this</b> <b>method!</b>

       <b>class</b> <b>PooledPostgresqlDatabase</b>
              Subclass of <u>PostgresqlDatabase</u> that mixes in the <u>PooledDatabase</u> helper.

       <b>class</b> <b>PooledPostgresqlExtDatabase</b>
              Subclass    of    <u>PostgresqlExtDatabase</u>   that   mixes   in   the   <u>PooledDatabase</u>   helper.   The
              <u>PostgresqlExtDatabase</u> is a part of the <u>Postgresql</u> <u>Extensions</u> module and provides support for  many
              Postgres-specific features.

       <b>class</b> <b>PooledMySQLDatabase</b>
              Subclass of <u>MySQLDatabase</u> that mixes in the <u>PooledDatabase</u> helper.

       <b>class</b> <b>PooledSqliteDatabase</b>
              Persistent connections for SQLite apps.

       <b>class</b> <b>PooledSqliteExtDatabase</b>
              Persistent  connections  for  SQLite  apps,  using  the <u>SQLite</u> <u>Extensions</u> advanced database driver
              <u>SqliteExtDatabase</u>.

   <b>Test</b> <b>Utils</b>
       Contains utilities helpful when testing peewee projects.

       <b>class</b> <b>count_queries([only_select=False])</b>
              Context manager that will count the number of queries executed within the context.

              <b>Parameters</b>
                     <b>only_select</b> (<u>bool</u>) -- Only count <u>SELECT</u> queries.

                 with count_queries() as counter:
                     huey = User.get(User.username == 'huey')
                     huey_tweets = [tweet.message for tweet in huey.tweets]

                 assert counter.count == 2

              <b>count</b>  The number of queries executed.

              <b>get_queries()</b>
                     Return a list of 2-tuples consisting of the SQL query and a list of parameters.

       <b>assert_query_count(expected[,</b> <b>only_select=False])</b>
              Function or method decorator that will raise an <b>AssertionError</b> if the number of  queries  executed
              in the decorated function does not equal the expected number.

                 class TestMyApp(unittest.TestCase):
                     @<a href="../man1/assert_query_count.1.html">assert_query_count</a>(1)
                     def test_get_popular_blogs(self):
                         popular_blogs = Blog.get_popular()
                         self.assertEqual(
                             [blog.title for blog in popular_blogs],
                             ["Peewee's Playhouse!", "All About Huey", "Mickey's Adventures"])

              This function can also be used as a context manager:

                 class TestMyApp(unittest.TestCase):
                     def test_expensive_operation(self):
                         with <a href="../man1/assert_query_count.1.html">assert_query_count</a>(1):
                             perform_expensive_operation()

   <b>Flask</b> <b>Utils</b>
       The  <b>playhouse.flask_utils</b>  module  contains  several  helpers  for integrating peewee with the <u>Flask</u> web
       framework.

   <b>Database</b> <b>Wrapper</b>
       The <b>FlaskDB</b> class is a wrapper for configuring and referencing a Peewee  database  from  within  a  Flask
       application.  Don't  let  its  name  fool  you: it is <b>not</b> <b>the</b> <b>same</b> <b>thing</b> <b>as</b> <b>a</b> <b>peewee</b> <b>database</b>. <b>FlaskDB</b> is
       designed to remove the following boilerplate from your flask app:

       • Dynamically create a Peewee database instance based on app config data.

       • Create a base class from which all your application's models will descend.

       • Register hooks at the start and end of a request to handle opening and closing a database connection.

       Basic usage:

          import datetime
          from flask import Flask
          from peewee import *
          from playhouse.flask_utils import FlaskDB

          DATABASE = 'postgresql://postgres:password@localhost:5432/my_database'

          # If we want to exclude particular views from the automatic connection
          # management, we list them this way:
          FLASKDB_EXCLUDED_ROUTES = ('logout',)

          app = Flask(__name__)
          app.config.from_object(__name__)

          db_wrapper = FlaskDB(app)

          class User(db_wrapper.Model):
              username = CharField(unique=True)

          class Tweet(db_wrapper.Model):
              user = ForeignKeyField(User, backref='tweets')
              content = TextField()
              timestamp = DateTimeField(default=datetime.datetime.now)

       The above code example will create and instantiate a peewee <u>PostgresqlDatabase</u>  specified  by  the  given
       database  URL. Request hooks will be configured to establish a connection when a request is received, and
       automatically close the connection when the response  is  sent.  Lastly,  the  <b>FlaskDB</b>  class  exposes  a
       <b>FlaskDB.Model</b> property which can be used as a base for your application's models.

       Here is how you can access the wrapped Peewee database instance that is configured for you by the <b>FlaskDB</b>
       wrapper:

          # Obtain a reference to the Peewee database instance.
          peewee_db = db_wrapper.database

          @app.route('/transfer-funds/', methods=['POST'])
          def transfer_funds():
              with peewee_db.atomic():
                  # ...

              return jsonify({'transfer-id': xid})

       <b>NOTE:</b>
          The actual peewee database can be accessed using the <b>FlaskDB.database</b> attribute.

       Here is another way to configure a Peewee database using <b>FlaskDB</b>:

          app = Flask(__name__)
          db_wrapper = FlaskDB(app, 'sqlite:///my_app.db')

       While the above examples show using a database URL, for more advanced usages you can specify a dictionary
       of configuration options, or simply pass in a peewee <u>Database</u> instance:

          DATABASE = {
              'name': 'my_app_db',
              'engine': 'playhouse.pool.PooledPostgresqlDatabase',
              'user': 'postgres',
              'max_connections': 32,
              'stale_timeout': 600,
          }

          app = Flask(__name__)
          app.config.from_object(__name__)

          wrapper = FlaskDB(app)
          pooled_postgres_db = wrapper.database

       Using a peewee <u>Database</u> object:

          peewee_db = PostgresqlExtDatabase('my_app')
          app = Flask(__name__)
          db_wrapper = FlaskDB(app, peewee_db)

   <b>Database</b> <b>with</b> <b>Application</b> <b>Factory</b>
       If you prefer to use the <u>application</u> <u>factory</u> <u>pattern</u>, the <b>FlaskDB</b> class implements an <b>init_app()</b> method.

       Using as a factory:

          db_wrapper = FlaskDB()

          # Even though the database is not yet initialized, you can still use the
          # `Model` property to create model classes.
          class User(db_wrapper.Model):
              username = CharField(unique=True)

          def create_app():
              app = Flask(__name__)
              app.config['DATABASE'] = 'sqlite:////home/code/apps/my-database.db'
              db_wrapper.init_app(app)
              return app

   <b>Query</b> <b>utilities</b>
       The  <b>flask_utils</b>  module  provides  several  helpers  for  managing  queries in your web app. Some common
       patterns include:

       <b>get_object_or_404(query_or_model,</b> <b>*query)</b>

              <b>Parameters</b>

                     • <b>query_or_model</b> -- Either a <u>Model</u> class or a pre-filtered <u>SelectQuery</u>.

                     • <b>query</b> -- An arbitrarily complex peewee expression.

              Retrieve the object matching the given query, or  return  a  404  not  found  response.  A  common
              use-case  might  be  a detail page for a weblog. You want to either retrieve the post matching the
              given URL, or return a 404.

              Example:

                 @app.route('/blog/&lt;slug&gt;/')
                 def post_detail(slug):
                     public_posts = Post.select().where(Post.published == True)
                     post = get_object_or_404(public_posts, (Post.slug == slug))
                     return render_template('post_detail.html', post=post)

       <b>object_list(template_name,</b> <b>query[,</b> <b>context_variable='object_list'[,</b> <b>paginate_by=20[,</b> <b>page_var='page'[,</b>
       <b>check_bounds=True[,</b> <b>**kwargs]]]]])</b>

              <b>Parameters</b>

                     • <b>template_name</b> -- The name of the template to render.

                     • <b>query</b> -- A <u>SelectQuery</u> instance to paginate.

                     • <b>context_variable</b> -- The context variable name to use for the paginated object list.

                     • <b>paginate_by</b> -- Number of objects per-page.

                     • <b>page_var</b> -- The name of the <b>GET</b> argument which contains the page.

                     • <b>check_bounds</b> -- Whether to check that the given page is a valid page. If <b>check_bounds</b>  is
                       <b>True</b> and an invalid page is specified, then a 404 will be returned.

                     • <b>kwargs</b> -- Arbitrary key/value pairs to pass into the template context.

              Retrieve  a paginated list of objects specified by the given query. The paginated object list will
              be dropped into the context using the given  <b>context_variable</b>,  as  well  as  metadata  about  the
              current  page  and  total  number  of  pages,  and  finally  any  arbitrary context data passed as
              keyword-arguments.

              The page is specified using the <b>page</b> <b>GET</b> argument, e.g.  <b>/my-object-list/?page=3</b> would return  the
              third page of objects.

              Example:

                 @app.route('/blog/')
                 def post_index():
                     public_posts = (Post
                                     .select()
                                     .where(Post.published == True)
                                     .order_by(Post.timestamp.desc()))

                     return object_list(
                         'post_index.html',
                         query=public_posts,
                         context_variable='post_list',
                         paginate_by=10)

              The template will have the following context:

              • <b>post_list</b>, which contains a list of up to 10 posts.

              • <b>page</b>, which contains the current page based on the value of the <b>page</b> <b>GET</b> parameter.

              • <b>pagination</b>, a <u>PaginatedQuery</u> instance.

       <b>class</b> <b>PaginatedQuery(query_or_model,</b> <b>paginate_by[,</b> <b>page_var='page'[,</b> <b>check_bounds=False]])</b>

              <b>Parameters</b>

                     • <b>query_or_model</b>  --  Either a <u>Model</u> or a <u>SelectQuery</u> instance containing the collection of
                       records you wish to paginate.

                     • <b>paginate_by</b> -- Number of objects per-page.

                     • <b>page_var</b> -- The name of the <b>GET</b> argument which contains the page.

                     • <b>check_bounds</b> -- Whether to check that the given page is a valid page. If <b>check_bounds</b>  is
                       <b>True</b> and an invalid page is specified, then a 404 will be returned.

              Helper class to perform pagination based on <b>GET</b> arguments.

              <b>get_page()</b>
                     Return  the  currently  selected  page,  as  indicated  by  the  value  of the <b>page_var</b> <b>GET</b>
                     parameter. If no page is explicitly selected, then this method will  return  1,  indicating
                     the first page.

              <b>get_page_count()</b>
                     Return the total number of possible pages.

              <b>get_object_list()</b>
                     Using the value of <u>get_page()</u>, return the page of objects requested by the user. The return
                     value is a <u>SelectQuery</u> with the appropriate <b>LIMIT</b> and <b>OFFSET</b> clauses.

                     If <b>check_bounds</b> was set to <b>True</b> and the requested page contains no objects, then a 404 will
                     be raised.

   <b>Query</b> <b>Examples</b>
       These  query examples are taken from the site <u>PostgreSQL</u> <u>Exercises</u>. A sample data-set can be found on the
       <u>getting</u> <u>started</u> <u>page</u>.

       Here is a visual representation of the schema used in these examples: [image]

   <b>Model</b> <b>Definitions</b>
       To begin working with the data, we'll define the model classes that  correspond  to  the  tables  in  the
       diagram.

       <b>NOTE:</b>
          In  some  cases  we explicitly specify column names for a particular field.  This is so our models are
          compatible with the database schema used for the postgres exercises.

          from functools import partial
          from peewee import *

          db = PostgresqlDatabase('peewee_test')

          class BaseModel(Model):
              class Meta:
                  database = db

          class Member(BaseModel):
              memid = AutoField()  # Auto-incrementing primary key.
              surname = CharField()
              firstname = CharField()
              address = CharField(max_length=300)
              zipcode = IntegerField()
              telephone = CharField()
              recommendedby = ForeignKeyField('self', backref='recommended',
                                              column_name='recommendedby', null=True)
              joindate = DateTimeField()

              class Meta:
                  table_name = 'members'

          # Conveniently declare decimal fields suitable for storing currency.
          MoneyField = partial(DecimalField, decimal_places=2)

          class Facility(BaseModel):
              facid = AutoField()
              name = CharField()
              membercost = MoneyField()
              guestcost = MoneyField()
              initialoutlay = MoneyField()
              monthlymaintenance = MoneyField()

              class Meta:
                  table_name = 'facilities'

          class Booking(BaseModel):
              bookid = AutoField()
              facility = ForeignKeyField(Facility, column_name='facid')
              member = ForeignKeyField(Member, column_name='memid')
              starttime = DateTimeField()
              slots = IntegerField()

              class Meta:
                  table_name = 'bookings'

   <b>Schema</b> <b>Creation</b>
       If you downloaded the SQL file from the PostgreSQL Exercises site, then you can  load  the  data  into  a
       PostgreSQL database using the following commands:

          createdb peewee_test
          psql -U postgres -f clubdata.sql -d peewee_test -x -q

       To create the schema using Peewee, without loading the sample data, you can run the following:

          # Assumes you have created the database "peewee_test" already.
          db.create_tables([Member, Facility, Booking])

   <b>Basic</b> <b>Exercises</b>
       This category deals with the basics of SQL. It covers select and where clauses, case expressions, unions,
       and a few other odds and ends.

   <b>Retrieve</b> <b>everything</b>
       Retrieve all information from facilities table.

          SELECT * FROM facilities

          # By default, when no fields are explicitly passed to select(), all fields
          # will be selected.
          query = Facility.select()

   <b>Retrieve</b> <b>specific</b> <b>columns</b> <b>from</b> <b>a</b> <b>table</b>
       Retrieve names of facilities and cost to members.

          SELECT name, membercost FROM facilities;

          query = Facility.select(Facility.name, Facility.membercost)

          # To iterate:
          for facility in query:
              print(facility.name)

   <b>Control</b> <b>which</b> <b>rows</b> <b>are</b> <b>retrieved</b>
       Retrieve list of facilities that have a cost to members.

          SELECT * FROM facilities WHERE membercost &gt; 0

          query = Facility.select().where(Facility.membercost &gt; 0)

   <b>Control</b> <b>which</b> <b>rows</b> <b>are</b> <b>retrieved</b> <b>-</b> <b>part</b> <b>2</b>
       Retrieve  list of facilities that have a cost to members, and that fee is less than 1/50th of the monthly
       maintenance cost. Return id, name, cost and monthly-maintenance.

          SELECT facid, name, membercost, monthlymaintenance
          FROM facilities
          WHERE membercost &gt; 0 AND membercost &lt; (monthlymaintenance / 50)

          query = (Facility
                   .select(Facility.facid, Facility.name, Facility.membercost,
                           Facility.monthlymaintenance)
                   .where(
                       (Facility.membercost &gt; 0) &amp;
                       (Facility.membercost &lt; (Facility.monthlymaintenance / 50))))

   <b>Basic</b> <b>string</b> <b>searches</b>
       How can you produce a list of all facilities with the word 'Tennis' in their name?

          SELECT * FROM facilities WHERE name ILIKE '%tennis%';

          query = Facility.select().where(Facility.name.contains('tennis'))

          # OR use the exponent operator. Note: you must include wildcards here:
          query = Facility.select().where(Facility.name ** '%tennis%')

   <b>Matching</b> <b>against</b> <b>multiple</b> <b>possible</b> <b>values</b>
       How can you retrieve the details of facilities with ID 1 and 5?  Try  to  do  it  without  using  the  OR
       operator.

          SELECT * FROM facilities WHERE facid IN (1, 5);

          query = Facility.select().where(Facility.facid.in_([1, 5]))

          # OR:
          query = Facility.select().where((Facility.facid == 1) |
                                          (Facility.facid == 5))

   <b>Classify</b> <b>results</b> <b>into</b> <b>buckets</b>
       How  can  you  produce a list of facilities, with each labelled as 'cheap' or 'expensive' depending on if
       their monthly maintenance cost is more than $100?   Return  the  name  and  monthly  maintenance  of  the
       facilities in question.

          SELECT name,
          CASE WHEN monthlymaintenance &gt; 100 THEN 'expensive' ELSE 'cheap' END
          FROM facilities;

          cost = Case(None, [(Facility.monthlymaintenance &gt; 100, 'expensive')], 'cheap')
          query = Facility.select(Facility.name, cost.alias('cost'))

       <b>NOTE:</b>
          See documentation <u>Case</u> for more examples.

   <b>Working</b> <b>with</b> <b>dates</b>
       How  can  you  produce  a list of members who joined after the start of September 2012? Return the memid,
       surname, firstname, and joindate of the members in question.

          SELECT memid, surname, firstname, joindate FROM members
          WHERE joindate &gt;= '2012-09-01';

          query = (Member
                   .select(Member.memid, Member.surname, Member.firstname, Member.joindate)
                   .where(Member.joindate &gt;= datetime.date(2012, 9, 1)))

   <b>Removing</b> <b>duplicates,</b> <b>and</b> <b>ordering</b> <b>results</b>
       How can you produce an ordered list of the first 10 surnames in the members  table?  The  list  must  not
       contain duplicates.

          SELECT DISTINCT surname FROM members ORDER BY surname LIMIT 10;

          query = (Member
                   .select(Member.surname)
                   .order_by(Member.surname)
                   .<a href="../man10/limit.10.html">limit</a>(10)
                   .distinct())

   <b>Combining</b> <b>results</b> <b>from</b> <b>multiple</b> <b>queries</b>
       You, for some reason, want a combined list of all surnames and all facility names.

          SELECT surname FROM members UNION SELECT name FROM facilities;

          lhs = Member.select(Member.surname)
          rhs = Facility.select(Facility.name)
          query = lhs | rhs

       Queries can be composed using the following operators:

       • <b>|</b> - <b>UNION</b>

       • <b>+</b> - <b>UNION</b> <b>ALL</b>

       • <b>&amp;</b> - <b>INTERSECT</b>

       • <b>-</b> - <b>EXCEPT</b>

   <b>Simple</b> <b>aggregation</b>
       You'd like to get the signup date of your last member. How can you retrieve this information?

          SELECT MAX(join_date) FROM members;

          query = Member.select(fn.MAX(Member.joindate))
          # To conveniently obtain a single scalar value, use "scalar()":
          # max_join_date = query.scalar()

   <b>More</b> <b>aggregation</b>
       You'd like to get the first and last name of the last member(s) who signed up - not just the date.

          SELECT firstname, surname, joindate FROM members
          WHERE joindate = (SELECT MAX(joindate) FROM members);

          # Use "alias()" to reference the same table multiple times in a query.
          MemberAlias = Member.alias()
          subq = MemberAlias.select(fn.MAX(MemberAlias.joindate))
          query = (Member
                   .select(Member.firstname, Member.surname, Member.joindate)
                   .where(Member.joindate == subq))

   <b>Joins</b> <b>and</b> <b>Subqueries</b>
       This  category  deals  primarily  with  a  foundational  concept in relational database systems: joining.
       Joining allows you to combine related information from multiple tables to answer a question.  This  isn't
       just beneficial for ease of querying: a lack of join capability encourages denormalisation of data, which
       increases the complexity of keeping your data internally consistent.

       This  topic covers inner, outer, and self joins, as well as spending a little time on subqueries (queries
       within queries).

   <b>Retrieve</b> <b>the</b> <b>start</b> <b>times</b> <b>of</b> <b>members'</b> <b>bookings</b>
       How can you produce a list of the start times for bookings by members named 'David Farrell'?

          SELECT starttime FROM bookings
          INNER JOIN members ON (bookings.memid = members.memid)
          WHERE surname = 'Farrell' AND firstname = 'David';

          query = (Booking
                   .select(Booking.starttime)
                   .join(Member)
                   .where((Member.surname == 'Farrell') &amp;
                          (Member.firstname == 'David')))

   <b>Work</b> <b>out</b> <b>the</b> <b>start</b> <b>times</b> <b>of</b> <b>bookings</b> <b>for</b> <b>tennis</b> <b>courts</b>
       How can you produce a list of the start times for bookings for tennis courts, for the date  '2012-09-21'?
       Return a list of start time and facility name pairings, ordered by the time.

          SELECT starttime, name
          FROM bookings
          INNER JOIN facilities ON (bookings.facid = facilities.facid)
          WHERE date_trunc('day', starttime) = '2012-09-21':: date
            AND name ILIKE 'tennis%'
          ORDER BY starttime, name;

          query = (Booking
                   .select(Booking.starttime, Facility.name)
                   .join(Facility)
                   .where(
                       (fn.date_trunc('day', Booking.starttime) == datetime.date(2012, 9, 21)) &amp;
                       Facility.name.startswith('Tennis'))
                   .order_by(Booking.starttime, Facility.name))

          # To retrieve the joined facility's name when iterating:
          for booking in query:
              print(booking.starttime, booking.facility.name)

   <b>Produce</b> <b>a</b> <b>list</b> <b>of</b> <b>all</b> <b>members</b> <b>who</b> <b>have</b> <b>recommended</b> <b>another</b> <b>member</b>
       How  can  you output a list of all members who have recommended another member?  Ensure that there are no
       duplicates in the list, and that results are ordered by (surname, firstname).

          SELECT DISTINCT m.firstname, m.surname
          FROM members AS m2
          INNER JOIN members AS m ON (m.memid = m2.recommendedby)
          ORDER BY m.surname, m.firstname;

          MA = Member.alias()
          query = (Member
                   .select(Member.firstname, Member.surname)
                   .join(MA, on=(MA.recommendedby == Member.memid))
                   .order_by(Member.surname, Member.firstname))

   <b>Produce</b> <b>a</b> <b>list</b> <b>of</b> <b>all</b> <b>members,</b> <b>along</b> <b>with</b> <b>their</b> <b>recommender</b>
       How can you output a list of all members, including the individual who recommended them (if any)?  Ensure
       that results are ordered by (surname, firstname).

          SELECT m.firstname, m.surname, r.firstname, r.surname
          FROM members AS m
          LEFT OUTER JOIN members AS r ON (m.recommendedby = r.memid)
          ORDER BY m.surname, m.firstname

          MA = Member.alias()
          query = (Member
                   .select(Member.firstname, Member.surname, MA.firstname, MA.surname)
                   .join(MA, JOIN.LEFT_OUTER, on=(Member.recommendedby == MA.memid))
                   .order_by(Member.surname, Member.firstname))

          # To display the recommender's name when iterating:
          for m in query:
              print(m.firstname, m.surname)
              if m.recommendedby:
                  print('  ', m.recommendedby.firstname, m.recommendedby.surname)

   <b>Produce</b> <b>a</b> <b>list</b> <b>of</b> <b>all</b> <b>members</b> <b>who</b> <b>have</b> <b>used</b> <b>a</b> <b>tennis</b> <b>court</b>
       How  can you produce a list of all members who have used a tennis court?  Include in your output the name
       of the court, and the name of the member formatted as a single column.  Ensure  no  duplicate  data,  and
       order by the member name.

          SELECT DISTINCT m.firstname || ' ' || m.surname AS member, f.name AS facility
          FROM members AS m
          INNER JOIN bookings AS b ON (m.memid = b.memid)
          INNER JOIN facilities AS f ON (b.facid = f.facid)
          WHERE f.name LIKE 'Tennis%'
          ORDER BY member, facility;

          fullname = Member.firstname + ' ' + Member.surname
          query = (Member
                   .select(fullname.alias('member'), Facility.name.alias('facility'))
                   .join(Booking)
                   .join(Facility)
                   .where(Facility.name.startswith('Tennis'))
                   .order_by(fullname, Facility.name)
                   .distinct())

   <b>Produce</b> <b>a</b> <b>list</b> <b>of</b> <b>costly</b> <b>bookings</b>
       How  can  you  produce  a list of bookings on the day of 2012-09-14 which will cost the member (or guest)
       more than $30? Remember that guests have different costs to members (the listed costs are  per  half-hour
       'slot'),  and the guest user is always ID 0. Include in your output the name of the facility, the name of
       the member formatted as a single column, and the cost. Order by descending  cost,  and  do  not  use  any
       subqueries.

          SELECT m.firstname || ' ' || m.surname AS member,
                 f.name AS facility,
                 (CASE WHEN m.memid = 0 THEN f.guestcost * b.slots
                  ELSE f.membercost * b.slots END) AS cost
          FROM members AS m
          INNER JOIN bookings AS b ON (m.memid = b.memid)
          INNER JOIN facilities AS f ON (b.facid = f.facid)
          WHERE (date_trunc('day', b.starttime) = '2012-09-14') AND
           ((m.memid = 0 AND b.slots * f.guestcost &gt; 30) OR
            (m.memid &gt; 0 AND b.slots * f.membercost &gt; 30))
          ORDER BY cost DESC;

          cost = Case(Member.memid, (
              (0, Booking.slots * Facility.guestcost),
          ), (Booking.slots * Facility.membercost))
          fullname = Member.firstname + ' ' + Member.surname

          query = (Member
                   .select(fullname.alias('member'), Facility.name.alias('facility'),
                           cost.alias('cost'))
                   .join(Booking)
                   .join(Facility)
                   .where(
                       (fn.date_trunc('day', Booking.starttime) == datetime.date(2012, 9, 14)) &amp;
                       (cost &gt; 30))
                   .order_by(SQL('cost').desc()))

          # To iterate over the results, it might be easiest to use namedtuples:
          for row in query.namedtuples():
              print(row.member, row.facility, row.cost)

   <b>Produce</b> <b>a</b> <b>list</b> <b>of</b> <b>all</b> <b>members,</b> <b>along</b> <b>with</b> <b>their</b> <b>recommender,</b> <b>using</b> <b>no</b> <b>joins.</b>
       How can you output a list of all members, including the individual who recommended them (if any), without
       using  any  joins?  Ensure  that  there  are no duplicates in the list, and that each firstname + surname
       pairing is formatted as a column and ordered.

          SELECT DISTINCT m.firstname || ' ' || m.surname AS member,
             (SELECT r.firstname || ' ' || r.surname
              FROM cd.members AS r
              WHERE m.recommendedby = r.memid) AS recommended
          FROM members AS m ORDER BY member;

          MA = Member.alias()
          subq = (MA
                  .select(MA.firstname + ' ' + MA.surname)
                  .where(Member.recommendedby == MA.memid))
          query = (Member
                   .select(fullname.alias('member'), subq.alias('recommended'))
                   .order_by(fullname))

   <b>Produce</b> <b>a</b> <b>list</b> <b>of</b> <b>costly</b> <b>bookings,</b> <b>using</b> <b>a</b> <b>subquery</b>
       The "Produce a list of costly bookings" exercise contained some messy logic:  we  had  to  calculate  the
       booking  cost  in  both  the  WHERE clause and the CASE statement. Try to simplify this calculation using
       subqueries.

          SELECT member, facility, cost from (
            SELECT
            m.firstname || ' ' || m.surname as member,
            f.name as facility,
            CASE WHEN m.memid = 0 THEN b.slots * f.guestcost
            ELSE b.slots * f.membercost END AS cost
            FROM members AS m
            INNER JOIN bookings AS b ON m.memid = b.memid
            INNER JOIN facilities AS f ON b.facid = f.facid
            WHERE date_trunc('day', b.starttime) = '2012-09-14'
          ) as bookings
          WHERE cost &gt; 30
          ORDER BY cost DESC;

          cost = Case(Member.memid, (
              (0, Booking.slots * Facility.guestcost),
          ), (Booking.slots * Facility.membercost))

          iq = (Member
                .select(fullname.alias('member'), Facility.name.alias('facility'),
                        cost.alias('cost'))
                .join(Booking)
                .join(Facility)
                .where(fn.date_trunc('day', Booking.starttime) == datetime.date(2012, 9, 14)))

          query = (Member
                   .select(iq.c.member, iq.c.facility, iq.c.cost)
                   .from_(iq)
                   .where(iq.c.cost &gt; 30)
                   .order_by(SQL('cost').desc()))

          # To iterate, try using dicts:
          for row in query.dicts():
              print(row['member'], row['facility'], row['cost'])

   <b>Modifying</b> <b>Data</b>
       Querying data is all well and good, but at some point you're probably going to want to put data into your
       database! This section deals with inserting, updating, and deleting information.  Operations  that  alter
       your data like this are collectively known as Data Manipulation Language, or DML.

       In  previous  sections, we returned to you the results of the query you've performed. Since modifications
       like the ones we're making in this section don't return any  query  results,  we  instead  show  you  the
       updated content of the table you're supposed to be working on.

   <b>Insert</b> <b>some</b> <b>data</b> <b>into</b> <b>a</b> <b>table</b>
       The club is adding a new facility - a spa. We need to add it into the facilities table. Use the following
       values:  facid: 9, Name: 'Spa', membercost: 20, guestcost: 30, initialoutlay: 100000, monthlymaintenance:
       800

          INSERT INTO "facilities" ("facid", "name", "membercost", "guestcost",
          "initialoutlay", "monthlymaintenance") VALUES (9, 'Spa', 20, 30, 100000, 800)

          res = Facility.insert({
              Facility.facid: 9,
              Facility.name: 'Spa',
              Facility.membercost: 20,
              Facility.guestcost: 30,
              Facility.initialoutlay: 100000,
              Facility.monthlymaintenance: 800}).execute()

          # OR:
          res = (Facility
                 .insert(facid=9, name='Spa', membercost=20, guestcost=30,
                         initialoutlay=100000, monthlymaintenance=800)
                 .execute())

   <b>Insert</b> <b>multiple</b> <b>rows</b> <b>of</b> <b>data</b> <b>into</b> <b>a</b> <b>table</b>
       In the previous exercise, you learned how to add a facility. Now you're going to add multiple  facilities
       in one command. Use the following values:

       facid: 9, Name: 'Spa', membercost: 20, guestcost: 30, initialoutlay: 100000, monthlymaintenance: 800.

       facid:   10,   Name:   'Squash   Court   2',  membercost:  3.5,  guestcost:  17.5,  initialoutlay:  5000,
       monthlymaintenance: 80.

          -- see above --

          data = [
              {'facid': 9, 'name': 'Spa', 'membercost': 20, 'guestcost': 30,
               'initialoutlay': 100000, 'monthlymaintenance': 800},
              {'facid': 10, 'name': 'Squash Court 2', 'membercost': 3.5,
               'guestcost': 17.5, 'initialoutlay': 5000, 'monthlymaintenance': 80}]
          res = Facility.insert_many(data).execute()

   <b>Insert</b> <b>calculated</b> <b>data</b> <b>into</b> <b>a</b> <b>table</b>
       Let's try adding the spa to the facilities table again. This  time,  though,  we  want  to  automatically
       generate  the value for the next facid, rather than specifying it as a constant. Use the following values
       for  everything  else:   Name:   'Spa',   membercost:   20,   guestcost:   30,   initialoutlay:   100000,
       monthlymaintenance: 800.

          INSERT INTO "facilities" ("facid", "name", "membercost", "guestcost",
            "initialoutlay", "monthlymaintenance")
          SELECT (SELECT (MAX("facid") + 1) FROM "facilities") AS _,
                  'Spa', 20, 30, 100000, 800;

          maxq = Facility.select(fn.MAX(Facility.facid) + 1)
          subq = Select(columns=(maxq, 'Spa', 20, 30, 100000, 800))
          res = Facility.insert_from(subq, Facility._meta.sorted_fields).execute()

   <b>Update</b> <b>some</b> <b>existing</b> <b>data</b>
       We made a mistake when entering the data for the second tennis court. The initial outlay was 10000 rather
       than 8000: you need to alter the data to fix the error.

          UPDATE facilities SET initialoutlay = 10000 WHERE name = 'Tennis Court 2';

          res = (Facility
                 .update({Facility.initialoutlay: 10000})
                 .where(Facility.name == 'Tennis Court 2')
                 .execute())

          # OR:
          res = (Facility
                 .update(initialoutlay=10000)
                 .where(Facility.name == 'Tennis Court 2')
                 .execute())

   <b>Update</b> <b>multiple</b> <b>rows</b> <b>and</b> <b>columns</b> <b>at</b> <b>the</b> <b>same</b> <b>time</b>
       We  want to increase the price of the tennis courts for both members and guests. Update the costs to be 6
       for members, and 30 for guests.

          UPDATE facilities SET membercost=6, guestcost=30 WHERE name ILIKE 'Tennis%';

          nrows = (Facility
                   .update(membercost=6, guestcost=30)
                   .where(Facility.name.startswith('Tennis'))
                   .execute())

   <b>Update</b> <b>a</b> <b>row</b> <b>based</b> <b>on</b> <b>the</b> <b>contents</b> <b>of</b> <b>another</b> <b>row</b>
       We want to alter the price of the second tennis court so that it costs 10% more than the first  one.  Try
       to  do  this  without using constant values for the prices, so that we can reuse the statement if we want
       to.

          UPDATE facilities SET
          membercost = (SELECT membercost * 1.1 FROM facilities WHERE facid = 0),
          guestcost = (SELECT guestcost * 1.1 FROM facilities WHERE facid = 0)
          WHERE facid = 1;

          -- OR --
          WITH new_prices (nmc, ngc) AS (
            SELECT membercost * 1.1, guestcost * 1.1
            FROM facilities WHERE name = 'Tennis Court 1')
          UPDATE facilities
          SET membercost = new_prices.nmc, guestcost = new_prices.ngc
          FROM new_prices
          WHERE name = 'Tennis Court 2'

          sq1 = Facility.select(Facility.membercost * 1.1).where(Facility.facid == 0)
          sq2 = Facility.select(Facility.guestcost * 1.1).where(Facility.facid == 0)

          res = (Facility
                 .update(membercost=sq1, guestcost=sq2)
                 .where(Facility.facid == 1)
                 .execute())

          # OR:
          cte = (Facility
                 .select(Facility.membercost * 1.1, Facility.guestcost * 1.1)
                 .where(Facility.name == 'Tennis Court 1')
                 .cte('new_prices', columns=('nmc', 'ngc')))
          res = (Facility
                 .update(membercost=SQL('new_prices.nmc'), guestcost=SQL('new_prices.ngc'))
                 .with_cte(cte)
                 .from_(cte)
                 .where(Facility.name == 'Tennis Court 2')
                 .execute())

   <b>Delete</b> <b>all</b> <b>bookings</b>
       As part of a clearout of our database, we want to delete all bookings from the bookings table.

          DELETE FROM bookings;

          nrows = Booking.delete().execute()

   <b>Delete</b> <b>a</b> <b>member</b> <b>from</b> <b>the</b> <b>cd.members</b> <b>table</b>
       We want to remove member 37, who has never made a booking, from our database.

          DELETE FROM members WHERE memid = 37;

          nrows = Member.delete().where(Member.memid == 37).execute()

   <b>Delete</b> <b>based</b> <b>on</b> <b>a</b> <b>subquery</b>
       How can we make that more general, to delete all members who have never made a booking?

          DELETE FROM members WHERE NOT EXISTS (
            SELECT * FROM bookings WHERE bookings.memid = members.memid);

          subq = Booking.select().where(Booking.member == Member.memid)
          nrows = Member.delete().where(~fn.EXISTS(subq)).execute()

   <b>Aggregation</b>
       Aggregation is one of those capabilities that really make you appreciate the power of relational database
       systems. It allows you to move beyond merely persisting  your  data,  into  the  realm  of  asking  truly
       interesting  questions  that  can  be used to inform decision making. This category covers aggregation at
       length, making use of standard grouping as well as more recent window functions.

   <b>Count</b> <b>the</b> <b>number</b> <b>of</b> <b>facilities</b>
       For our first foray into aggregates, we're going to stick to something simple. We want to know  how  many
       facilities exist - simply produce a total count.

          SELECT COUNT(facid) FROM facilities;

          query = Facility.select(fn.COUNT(Facility.facid))
          count = query.scalar()

          # OR:
          count = Facility.select().count()

   <b>Count</b> <b>the</b> <b>number</b> <b>of</b> <b>expensive</b> <b>facilities</b>
       Produce a count of the number of facilities that have a cost to guests of 10 or more.

          SELECT COUNT(facid) FROM facilities WHERE guestcost &gt;= 10

          query = Facility.select(fn.COUNT(Facility.facid)).where(Facility.guestcost &gt;= 10)
          count = query.scalar()

          # OR:
          # count = Facility.select().where(Facility.guestcost &gt;= 10).count()

   <b>Count</b> <b>the</b> <b>number</b> <b>of</b> <b>recommendations</b> <b>each</b> <b>member</b> <b>makes.</b>
       Produce a count of the number of recommendations each member has made. Order by member ID.

          SELECT recommendedby, <a href="../manmemid/COUNT.memid.html">COUNT</a>(memid) FROM members
          WHERE recommendedby IS NOT NULL
          GROUP BY recommendedby
          ORDER BY recommendedby

          query = (Member
                   .select(Member.recommendedby, fn.COUNT(Member.memid))
                   .where(Member.recommendedby.is_null(False))
                   .group_by(Member.recommendedby)
                   .order_by(Member.recommendedby))

   <b>List</b> <b>the</b> <b>total</b> <b>slots</b> <b>booked</b> <b>per</b> <b>facility</b>
       Produce  a  list  of the total number of slots booked per facility. For now, just produce an output table
       consisting of facility id and slots, sorted by facility id.

          SELECT facid, SUM(slots) FROM bookings GROUP BY facid ORDER BY facid;

          query = (Booking
                   .select(Booking.facid, fn.SUM(Booking.slots))
                   .group_by(Booking.facid)
                   .order_by(Booking.facid))

   <b>List</b> <b>the</b> <b>total</b> <b>slots</b> <b>booked</b> <b>per</b> <b>facility</b> <b>in</b> <b>a</b> <b>given</b> <b>month</b>
       Produce a list of the total number of slots booked per facility in the month of September  2012.  Produce
       an output table consisting of facility id and slots, sorted by the number of slots.

          SELECT facid, SUM(slots)
          FROM bookings
          WHERE (date_trunc('month', starttime) = '2012-09-01'::dates)
          GROUP BY facid
          ORDER BY SUM(slots)

          query = (Booking
                   .select(Booking.facility, fn.SUM(Booking.slots))
                   .where(fn.date_trunc('month', Booking.starttime) == datetime.date(2012, 9, 1))
                   .group_by(Booking.facility)
                   .order_by(fn.SUM(Booking.slots)))

   <b>List</b> <b>the</b> <b>total</b> <b>slots</b> <b>booked</b> <b>per</b> <b>facility</b> <b>per</b> <b>month</b>
       Produce a list of the total number of slots booked per facility per month in the year of 2012. Produce an
       output table consisting of facility id and slots, sorted by the id and month.

          SELECT facid, date_part('month', starttime), SUM(slots)
          FROM bookings
          WHERE date_part('year', starttime) = 2012
          GROUP BY facid, date_part('month', starttime)
          ORDER BY facid, date_part('month', starttime)

          month = fn.date_part('month', Booking.starttime)
          query = (Booking
                   .select(Booking.facility, month, fn.SUM(Booking.slots))
                   .where(fn.date_part('year', Booking.starttime) == 2012)
                   .group_by(Booking.facility, month)
                   .order_by(Booking.facility, month))

   <b>Find</b> <b>the</b> <b>count</b> <b>of</b> <b>members</b> <b>who</b> <b>have</b> <b>made</b> <b>at</b> <b>least</b> <b>one</b> <b>booking</b>
       Find the total number of members who have made at least one booking.

          SELECT COUNT(DISTINCT memid) FROM bookings

          -- OR --
          SELECT <a href="../man1/COUNT.1.html">COUNT</a>(1) FROM (SELECT DISTINCT memid FROM bookings) AS _

          query = Booking.select(fn.COUNT(Booking.member.distinct()))

          # OR:
          query = Booking.select(Booking.member).distinct()
          count = query.count()  # count() wraps in SELECT <a href="../man1/COUNT.1.html">COUNT</a>(1) FROM (...)

   <b>List</b> <b>facilities</b> <b>with</b> <b>more</b> <b>than</b> <b>1000</b> <b>slots</b> <b>booked</b>
       Produce  a  list  of  facilities  with more than 1000 slots booked. Produce an output table consisting of
       facility id and hours, sorted by facility id.

          SELECT facid, SUM(slots) FROM bookings
          GROUP BY facid
          HAVING SUM(slots) &gt; 1000
          ORDER BY facid;

          query = (Booking
                   .select(Booking.facility, fn.SUM(Booking.slots))
                   .group_by(Booking.facility)
                   .having(fn.SUM(Booking.slots) &gt; 1000)
                   .order_by(Booking.facility))

   <b>Find</b> <b>the</b> <b>total</b> <b>revenue</b> <b>of</b> <b>each</b> <b>facility</b>
       Produce a list of facilities along with their total revenue. The output table should consist of  facility
       name and revenue, sorted by revenue. Remember that there's a different cost for guests and members!

          SELECT f.name, SUM(b.slots * (
          CASE WHEN b.memid = 0 THEN f.guestcost ELSE f.membercost END)) AS revenue
          FROM bookings AS b
          INNER JOIN facilities AS f ON b.facid = f.facid
          GROUP BY f.name
          ORDER BY revenue;

          revenue = fn.SUM(Booking.slots * Case(None, (
              (Booking.member == 0, Facility.guestcost),
          ), Facility.membercost))

          query = (Facility
                   .select(Facility.name, revenue.alias('revenue'))
                   .join(Booking)
                   .group_by(Facility.name)
                   .order_by(SQL('revenue')))

   <b>Find</b> <b>facilities</b> <b>with</b> <b>a</b> <b>total</b> <b>revenue</b> <b>less</b> <b>than</b> <b>1000</b>
       Produce  a  list of facilities with a total revenue less than 1000. Produce an output table consisting of
       facility name and revenue, sorted by revenue.  Remember that there's a  different  cost  for  guests  and
       members!

          SELECT f.name, SUM(b.slots * (
          CASE WHEN b.memid = 0 THEN f.guestcost ELSE f.membercost END)) AS revenue
          FROM bookings AS b
          INNER JOIN facilities AS f ON b.facid = f.facid
          GROUP BY f.name
          HAVING SUM(b.slots * ...) &lt; 1000
          ORDER BY revenue;

          # Same definition as previous example.
          revenue = fn.SUM(Booking.slots * Case(None, (
              (Booking.member == 0, Facility.guestcost),
          ), Facility.membercost))

          query = (Facility
                   .select(Facility.name, revenue.alias('revenue'))
                   .join(Booking)
                   .group_by(Facility.name)
                   .having(revenue &lt; 1000)
                   .order_by(SQL('revenue')))

   <b>Output</b> <b>the</b> <b>facility</b> <b>id</b> <b>that</b> <b>has</b> <b>the</b> <b>highest</b> <b>number</b> <b>of</b> <b>slots</b> <b>booked</b>
       Output the facility id that has the highest number of slots booked.

          SELECT facid, SUM(slots) FROM bookings
          GROUP BY facid
          ORDER BY SUM(slots) DESC
          LIMIT 1

          query = (Booking
                   .select(Booking.facility, fn.SUM(Booking.slots))
                   .group_by(Booking.facility)
                   .order_by(fn.SUM(Booking.slots).desc())
                   .<a href="../man1/limit.1.html">limit</a>(1))

          # Retrieve multiple scalar values by calling scalar() with as_tuple=True.
          facid, nslots = query.scalar(as_tuple=True)

   <b>List</b> <b>the</b> <b>total</b> <b>slots</b> <b>booked</b> <b>per</b> <b>facility</b> <b>per</b> <b>month,</b> <b>part</b> <b>2</b>
       Produce  a  list  of the total number of slots booked per facility per month in the year of 2012. In this
       version, include output rows containing totals for all months per facility, and a total  for  all  months
       for all facilities. The output table should consist of facility id, month and slots, sorted by the id and
       month.  When  calculating  the aggregated values for all months and all facids, return null values in the
       month and facid columns.

       Postgres ONLY.

          SELECT facid, date_part('month', starttime), SUM(slots)
          FROM booking
          WHERE date_part('year', starttime) = 2012
          GROUP BY ROLLUP(facid, date_part('month', starttime))
          ORDER BY facid, date_part('month', starttime)

          month = fn.date_part('month', Booking.starttime)
          query = (Booking
                   .select(Booking.facility,
                           month.alias('month'),
                           fn.SUM(Booking.slots))
                   .where(fn.date_part('year', Booking.starttime) == 2012)
                   .group_by(fn.ROLLUP(Booking.facility, month))
                   .order_by(Booking.facility, month))

   <b>List</b> <b>the</b> <b>total</b> <b>hours</b> <b>booked</b> <b>per</b> <b>named</b> <b>facility</b>
       Produce a list of the total number of hours booked per facility, remembering that a slot  lasts  half  an
       hour. The output table should consist of the facility id, name, and hours booked, sorted by facility id.

          SELECT f.facid, f.name, SUM(b.slots) * .5
          FROM facilities AS f
          INNER JOIN bookings AS b ON (f.facid = b.facid)
          GROUP BY f.facid, f.name
          ORDER BY f.facid

          query = (Facility
                   .select(Facility.facid, Facility.name, fn.SUM(Booking.slots) * .5)
                   .join(Booking)
                   .group_by(Facility.facid, Facility.name)
                   .order_by(Facility.facid))

   <b>List</b> <b>each</b> <b>member's</b> <b>first</b> <b>booking</b> <b>after</b> <b>September</b> <b>1st</b> <b>2012</b>
       Produce a list of each member name, id, and their first booking after September 1st 2012. Order by member
       ID.

          SELECT m.surname, m.firstname, m.memid, min(b.starttime) as starttime
          FROM members AS m
          INNER JOIN bookings AS b ON b.memid = m.memid
          WHERE starttime &gt;= '2012-09-01'
          GROUP BY m.surname, m.firstname, m.memid
          ORDER BY m.memid;

          query = (Member
                   .select(Member.surname, Member.firstname, Member.memid,
                           fn.MIN(Booking.starttime).alias('starttime'))
                   .join(Booking)
                   .where(Booking.starttime &gt;= datetime.date(2012, 9, 1))
                   .group_by(Member.surname, Member.firstname, Member.memid)
                   .order_by(Member.memid))

   <b>Produce</b> <b>a</b> <b>list</b> <b>of</b> <b>member</b> <b>names,</b> <b>with</b> <b>each</b> <b>row</b> <b>containing</b> <b>the</b> <b>total</b> <b>member</b> <b>count</b>
       Produce a list of member names, with each row containing the total member count. Order by join date.

       Postgres ONLY (as written).

          SELECT COUNT(*) OVER(), firstname, surname
          FROM members ORDER BY joindate

          query = (Member
                   .select(fn.COUNT(Member.memid).over(), Member.firstname,
                           Member.surname)
                   .order_by(Member.joindate))

   <b>Produce</b> <b>a</b> <b>numbered</b> <b>list</b> <b>of</b> <b>members</b>
       Produce  a  monotonically increasing numbered list of members, ordered by their date of joining. Remember
       that member IDs are not guaranteed to be sequential.

       Postgres ONLY (as written).

          SELECT row_number() OVER (ORDER BY joindate), firstname, surname
          FROM members ORDER BY joindate;

          query = (Member
                   .select(fn.row_number().over(order_by=[Member.joindate]),
                           Member.firstname, Member.surname)
                   .order_by(Member.joindate))

   <b>Output</b> <b>the</b> <b>facility</b> <b>id</b> <b>that</b> <b>has</b> <b>the</b> <b>highest</b> <b>number</b> <b>of</b> <b>slots</b> <b>booked,</b> <b>again</b>
       Output the facility id that has the highest number of slots booked. Ensure that in the event  of  a  tie,
       all tieing results get output.

       Postgres ONLY (as written).

          SELECT facid, total FROM (
            SELECT facid, SUM(slots) AS total,
                   rank() OVER (order by SUM(slots) DESC) AS rank
            FROM bookings
            GROUP BY facid
          ) AS ranked WHERE rank = 1

          rank = fn.rank().over(order_by=[fn.SUM(Booking.slots).desc()])

          subq = (Booking
                  .select(Booking.facility, fn.SUM(Booking.slots).alias('total'),
                          rank.alias('rank'))
                  .group_by(Booking.facility))

          # Here we use a plain Select() to create our query.
          query = (Select(columns=[subq.c.facid, subq.c.total])
                   .from_(subq)
                   .where(subq.c.rank == 1)
                   .bind(db))  # We must bind() it to the database.

          # To iterate over the query results:
          for facid, total in query.tuples():
              print(facid, total)

   <b>Rank</b> <b>members</b> <b>by</b> <b>(rounded)</b> <b>hours</b> <b>used</b>
       Produce  a  list  of members, along with the number of hours they've booked in facilities, rounded to the
       nearest ten hours. Rank them by this rounded figure, producing output of  first  name,  surname,  rounded
       hours, rank. Sort by rank, surname, and first name.

       Postgres ONLY (as written).

          SELECT firstname, surname,
          ((SUM(bks.slots)+10)/20)*10 as hours,
          rank() over (order by ((sum(bks.slots)+10)/20)*10 desc) as rank
          FROM members AS mems
          INNER JOIN bookings AS bks ON mems.memid = bks.memid
          GROUP BY mems.memid
          ORDER BY rank, surname, firstname;

          hours = ((fn.SUM(Booking.slots) + 10) / 20) * 10
          query = (Member
                   .select(Member.firstname, Member.surname, hours.alias('hours'),
                           fn.rank().over(order_by=[hours.desc()]).alias('rank'))
                   .join(Booking)
                   .group_by(Member.memid)
                   .order_by(SQL('rank'), Member.surname, Member.firstname))

   <b>Find</b> <b>the</b> <b>top</b> <b>three</b> <b>revenue</b> <b>generating</b> <b>facilities</b>
       Produce  a list of the top three revenue generating facilities (including ties). Output facility name and
       rank, sorted by rank and facility name.

       Postgres ONLY (as written).

          SELECT name, rank FROM (
              SELECT f.name, RANK() OVER (ORDER BY SUM(
                  CASE WHEN memid = 0 THEN slots * f.guestcost
                  ELSE slots * f.membercost END) DESC) AS rank
              FROM bookings
              INNER JOIN facilities AS f ON bookings.facid = f.facid
              GROUP BY f.name) AS subq
          WHERE rank &lt;= 3
          ORDER BY rank;

          total_cost = fn.SUM(Case(None, (
              (Booking.member == 0, Booking.slots * Facility.guestcost),
          ), (Booking.slots * Facility.membercost)))

          subq = (Facility
                  .select(Facility.name,
                          fn.RANK().over(order_by=[total_cost.desc()]).alias('rank'))
                  .join(Booking)
                  .group_by(Facility.name))

          query = (Select(columns=[subq.c.name, subq.c.rank])
                   .from_(subq)
                   .where(subq.c.rank &lt;= 3)
                   .order_by(subq.c.rank)
                   .bind(db))  # Here again we used plain Select, and call bind().

   <b>Classify</b> <b>facilities</b> <b>by</b> <b>value</b>
       Classify facilities into equally sized groups of high, average, and low based on their revenue. Order  by
       classification and facility name.

       Postgres ONLY (as written).

          SELECT name,
            CASE class WHEN 1 THEN 'high' WHEN 2 THEN 'average' ELSE 'low' END
          FROM (
            SELECT f.name, <a href="../man3/ntile.3.html">ntile</a>(3) OVER (ORDER BY SUM(
              CASE WHEN memid = 0 THEN slots * f.guestcost ELSE slots * f.membercost
              END) DESC) AS class
            FROM bookings INNER JOIN facilities AS f ON bookings.facid = f.facid
            GROUP BY f.name
          ) AS subq
          ORDER BY class, name;

          cost = fn.SUM(Case(None, (
              (Booking.member == 0, Booking.slots * Facility.guestcost),
          ), (Booking.slots * Facility.membercost)))
          subq = (Facility
                  .select(Facility.name,
                          <a href="../man3/fn.NTILE.3.html">fn.NTILE</a>(3).over(order_by=[cost.desc()]).alias('klass'))
                  .join(Booking)
                  .group_by(Facility.name))

          klass_case = Case(subq.c.klass, [(1, 'high'), (2, 'average')], 'low')
          query = (Select(columns=[subq.c.name, klass_case])
                   .from_(subq)
                   .order_by(subq.c.klass, subq.c.name)
                   .bind(db))

   <b>Recursion</b>
       Common  Table Expressions allow us to, effectively, create our own temporary tables for the duration of a
       query - they're largely a convenience to help us  make  more  readable  SQL.  Using  the  WITH  RECURSIVE
       modifier,  however, it's possible for us to create recursive queries. This is enormously advantageous for
       working with tree and graph-structured data - imagine retrieving all of the relations of a graph node  to
       a given depth, for example.

   <b>Find</b> <b>the</b> <b>upward</b> <b>recommendation</b> <b>chain</b> <b>for</b> <b>member</b> <b>ID</b> <b>27</b>
       Find  the upward recommendation chain for member ID 27: that is, the member who recommended them, and the
       member who recommended that member, and so on.  Return member ID,  first  name,  and  surname.  Order  by
       descending member id.

          WITH RECURSIVE recommenders(recommender) as (
            SELECT recommendedby FROM members WHERE memid = 27
            UNION ALL
            SELECT mems.recommendedby
            FROM recommenders recs
            INNER JOIN members AS mems ON mems.memid = recs.recommender
          )
          SELECT recs.recommender, mems.firstname, mems.surname
          FROM recommenders AS recs
          INNER JOIN members AS mems ON recs.recommender = mems.memid
          ORDER By memid DESC;

          # Base-case of recursive CTE. Get member recommender where memid=27.
          base = (Member
                  .select(Member.recommendedby)
                  .where(Member.memid == 27)
                  .cte('recommenders', recursive=True, columns=('recommender',)))

          # Recursive term of CTE. Get recommender of previous recommender.
          MA = Member.alias()
          recursive = (MA
                       .select(MA.recommendedby)
                       .join(base, on=(MA.memid == base.c.recommender)))

          # Combine the base-case with the recursive term.
          cte = base.union_all(recursive)

          # Select from the recursive CTE, joining on member to get name info.
          query = (cte
                   .select_from(cte.c.recommender, Member.firstname, Member.surname)
                   .join(Member, on=(cte.c.recommender == Member.memid))
                   .order_by(Member.memid.desc()))

   <b>Query</b> <b>Builder</b>
       Peewee's  high-level <u>Model</u> and <u>Field</u> APIs are built upon lower-level <u>Table</u> and <u>Column</u> counterparts. While
       these lower-level APIs are not documented in as  much  detail  as  their  high-level  counterparts,  this
       document will present an overview with examples that should hopefully allow you to experiment.

       We'll use the following schema:

          CREATE TABLE "person" (
              "id" INTEGER NOT NULL PRIMARY KEY,
              "first" TEXT NOT NULL,
              "last" TEXT NOT NULL);

          CREATE TABLE "note" (
              "id" INTEGER NOT NULL PRIMARY KEY,
              "person_id" INTEGER NOT NULL,
              "content" TEXT NOT NULL,
              "timestamp" DATETIME NOT NULL,
              FOREIGN KEY ("person_id") REFERENCES "person" ("id"));

          CREATE TABLE "reminder" (
              "id" INTEGER NOT NULL PRIMARY KEY,
              "note_id" INTEGER NOT NULL,
              "alarm" DATETIME NOT NULL,
              FOREIGN KEY ("note_id") REFERENCES "note" ("id"));

   <b>Declaring</b> <b>tables</b>
       There are two ways we can declare <u>Table</u> objects for working with these tables:

          # Explicitly declare columns
          Person = Table('person', ('id', 'first', 'last'))

          Note = Table('note', ('id', 'person_id', 'content', 'timestamp'))

          # Do not declare columns, they will be accessed using magic ".c" attribute
          Reminder = Table('reminder')

       Typically  we  will  want  to  <u>bind()</u> our tables to a database. This saves us having to pass the database
       explicitly every time we wish to execute a query on the table:

          db = SqliteDatabase('my_app.db')
          Person = Person.bind(db)
          Note = Note.bind(db)
          Reminder = Reminder.bind(db)

   <b>Select</b> <b>queries</b>
       To select the first three notes and print their content, we can write:

          query = Note.select().order_by(Note.timestamp).<a href="../man3/limit.3.html">limit</a>(3)
          for note_dict in query:
              print(note_dict['content'])

       <b>NOTE:</b>
          By default, rows will be returned  as  dictionaries.  You  can  use  the  <u>tuples()</u>,  <u>namedtuples()</u>  or
          <u>objects()</u> methods to specify a different container for the row data, if you wish.

       Because we didn't specify any columns, all the columns we defined in the note's <u>Table</u> constructor will be
       selected. This won't work for Reminder, as we didn't specify any columns at all.

       To  select all notes published in 2018 along with the name of the creator, we will use <b>join()</b>. We'll also
       request that rows be returned as <u>namedtuple</u> objects:

          query = (Note
                   .select(Note.content, Note.timestamp, Person.first, Person.last)
                   .join(Person, on=(Note.person_id == Person.id))
                   .where(Note.timestamp &gt;= datetime.date(2018, 1, 1))
                   .order_by(Note.timestamp)
                   .namedtuples())

          for row in query:
              print(row.timestamp, '-', row.content, '-', row.first, row.last)

       Let's query for the most prolific people, that is, get the people who have created the most  notes.  This
       introduces calling a SQL function (COUNT), which is accomplished using the <b>fn</b> object:

          name = Person.first.concat(' ').concat(Person.last)
          query = (Person
                   .select(name.alias('name'), fn.COUNT(Note.id).alias('count'))
                   .join(Note, JOIN.LEFT_OUTER, on=(Note.person_id == Person.id))
                   .group_by(name)
                   .order_by(fn.COUNT(Note.id).desc()))
          for row in query:
              print(row['name'], row['count'])

       There are a couple things to note in the above query:

       • We store an expression in a variable (<b>name</b>), then use it in the query.

       • We  call  SQL  functions  using  <b>fn.&lt;function&gt;(...)</b>  passing  arguments  as  if it were a normal Python
         function.

       • The <u>alias()</u> method is used to specify the name used for a column or calculation.

       As a more complex example, we'll generate a list of all people and the contents and  timestamp  of  their
       most recently-published note. To do this, we will end up using the Note table twice in different contexts
       within the same query, which will require us to use a table alias.

          # Start with the query that calculates the timestamp of the most recent
          # note for each person.
          NA = Note.alias('na')
          max_note = (NA
                      .select(NA.person_id, fn.MAX(NA.timestamp).alias('max_ts'))
                      .group_by(NA.person_id)
                      .alias('max_note'))

          # Now we'll select from the note table, joining on both the subquery and
          # on the person table to construct the result set.
          query = (Note
                   .select(Note.content, Note.timestamp, Person.first, Person.last)
                   .join(max_note, on=((max_note.c.person_id == Note.person_id) &amp;
                                       (max_note.c.max_ts == Note.timestamp)))
                   .join(Person, on=(Note.person_id == Person.id))
                   .order_by(Person.first, Person.last))

          for row in query.namedtuples():
              print(row.first, row.last, ':', row.timestamp, '-', row.content)

       In  the  join  predicate  for the join on the <u>max_note</u> subquery, we can reference columns in the subquery
       using the magical ".c" attribute. So, <u>max_note.c.max_ts</u> is translated into "the max_ts column value  from
       the max_note subquery".

       We  can also use the ".c" magic attribute to access columns on tables that do not explicitly define their
       columns, like we did with the Reminder table.  Here's a simple query to  get  all  reminders  for  today,
       along with their associated note content:

          today = datetime.date.today()
          tomorrow = today + datetime.timedelta(days=1)

          query = (Reminder
                   .select(Reminder.c.alarm, Note.content)
                   .join(Note, on=(Reminder.c.note_id == Note.id))
                   .where(Reminder.c.alarm.between(today, tomorrow))
                   .order_by(Reminder.c.alarm))
          for row in query:
              print(row['alarm'], row['content'])

       <b>NOTE:</b>
          The ".c" attribute will not work on tables that explicitly define their columns, to prevent confusion.

   <b>Insert</b> <b>queries</b>
       Inserting  data is straightforward. We can specify data to <u>insert()</u> in two different ways (in both cases,
       the ID of the new row is returned):

          # Using keyword arguments:
          zaizee_id = Person.insert(first='zaizee', last='cat').execute()

          # Using column: value mappings:
          Note.insert({
              Note.person_id: zaizee_id,
              Note.content: 'meeeeowwww',
              Note.timestamp: datetime.datetime.now()}).execute()

       It is easy to bulk-insert data, just pass in either:

       • A list of dictionaries (all must have the same keys/columns).

       • A list of tuples, if the columns are specified explicitly.

       Examples:

          people = [
              {'first': 'Bob', 'last': 'Foo'},
              {'first': 'Herb', 'last': 'Bar'},
              {'first': 'Nuggie', 'last': 'Bar'}]

          # Inserting multiple rows returns the ID of the last-inserted row.
          last_id = Person.insert(people).execute()

          # We can also specify row tuples, so long as we tell Peewee which
          # columns the tuple values correspond to:
          people = [
              ('Bob', 'Foo'),
              ('Herb', 'Bar'),
              ('Nuggie', 'Bar')]
          Person.insert(people, columns=[Person.first, Person.last]).execute()

   <b>Update</b> <b>queries</b>
       <u>update()</u> queries accept either keyword arguments or a dictionary  mapping  column  to  value,  just  like
       <u>insert()</u>.

       Examples:

          # "Bob" changed his last name from "Foo" to "Baze".
          nrows = (Person
                   .update(last='Baze')
                   .where((Person.first == 'Bob') &amp;
                          (Person.last == 'Foo'))
                   .execute())

          # Use dictionary mapping column to value.
          nrows = (Person
                   .update({Person.last: 'Baze'})
                   .where((Person.first == 'Bob') &amp;
                          (Person.last == 'Foo'))
                   .execute())

       You  can  also use expressions as the value to perform an atomic update. Imagine we have a <u>PageView</u> table
       and we need to atomically increment the page-view count for some URL:

          # Do an atomic update:
          (PageView
           .update({PageView.count: PageView.count + 1})
           .where(PageView.url == some_url)
           .execute())

   <b>Delete</b> <b>queries</b>
       <u>delete()</u> queries are simplest of all, as they do not accept any arguments:

          # Delete all notes created before 2018, returning number deleted.
          n = Note.delete().where(Note.timestamp &lt; datetime.date(2018, 1, 1)).execute()

       Because DELETE (and UPDATE) queries do not support joins, we can use subqueries to delete rows  based  on
       values  in  related tables. For example, here is how you would delete all notes by anyone whose last name
       is "Foo":

          # Get the id of all people whose last name is "Foo".
          foo_people = Person.select(Person.id).where(Person.last == 'Foo')

          # Delete all notes by any person whose ID is in the previous query.
          Note.delete().where(Note.person_id.in_(foo_people)).execute()

   <b>Query</b> <b>Objects</b>
       One of the fundamental limitations of the abstractions provided by Peewee 2.x was the absence of a  class
       that represented a structured query with no relation to a given model class.

       An  example of this might be computing aggregate values over a subquery. For example, the <u>count()</u> method,
       which returns the count of rows in an arbitrary query, is implemented by wrapping the query:

          SELECT <a href="../man1/COUNT.1.html">COUNT</a>(1) FROM (...)

       To accomplish this with Peewee, the implementation is written in this way:

          def count(query):
              # Select([source1, ... sourcen], [column1, ...columnn])
              wrapped = Select(from_list=[query], columns=[fn.COUNT(SQL('1'))])
              curs = wrapped.tuples().execute(db)
              return curs[0][0]  # Return first column from first row of result.

       We can actually express this more concisely using the <u>scalar()</u> method, which is  suitable  for  returning
       values from aggregate queries:

          def count(query):
              wrapped = Select(from_list=[query], columns=[fn.COUNT(SQL('1'))])
              return wrapped.scalar(db)

       The <u>Query</u> <u>Examples</u> document has a more complex example, in which we write a query for a facility with the
       highest number of available slots booked:

       The SQL we wish to express is:

          SELECT facid, total FROM (
            SELECT facid, SUM(slots) AS total,
                   rank() OVER (order by SUM(slots) DESC) AS rank
            FROM bookings
            GROUP BY facid
          ) AS ranked
          WHERE rank = 1

       We can express this fairly elegantly by using a plain <u>Select</u> for the outer query:

          # Store rank expression in variable for readability.
          rank_expr = fn.rank().over(order_by=[fn.SUM(Booking.slots).desc()])

          subq = (Booking
                  .select(Booking.facility, fn.SUM(Booking.slots).alias('total'),
                          rank_expr.alias('rank'))
                  .group_by(Booking.facility))

          # Use a plain "Select" to create outer query.
          query = (Select(columns=[subq.c.facid, subq.c.total])
                   .from_(subq)
                   .where(subq.c.rank == 1)
                   .tuples())

          # Iterate over the resulting facility ID(s) and total(s):
          for facid, total in query.execute(db):
              print(facid, total)

       For another example, let's create a recursive common table expression to calculate the first 10 fibonacci
       numbers:

          base = Select(columns=(
              <a href="../man1/Value.1.html">Value</a>(1).alias('n'),
              <a href="../man0/Value.0.html">Value</a>(0).alias('fib_n'),
              <a href="../man1/Value.1.html">Value</a>(1).alias('next_fib_n'))).cte('fibonacci', recursive=True)

          n = (base.c.n + 1).alias('n')
          recursive_term = Select(columns=(
              n,
              base.c.next_fib_n,
              base.c.fib_n + base.c.next_fib_n)).from_(base).where(n &lt; 10)

          fibonacci = base.union_all(recursive_term)
          query = fibonacci.select_from(fibonacci.c.n, fibonacci.c.fib_n)

          results = list(query.execute(db))

          # Generates the following result list:
          [{'fib_n': 0, 'n': 1},
           {'fib_n': 1, 'n': 2},
           {'fib_n': 1, 'n': 3},
           {'fib_n': 2, 'n': 4},
           {'fib_n': 3, 'n': 5},
           {'fib_n': 5, 'n': 6},
           {'fib_n': 8, 'n': 7},
           {'fib_n': 13, 'n': 8},
           {'fib_n': 21, 'n': 9},
           {'fib_n': 34, 'n': 10}]

   <b>More</b>
       For  a  description  of  the  various  classes  used  to  describe  a  SQL AST, see the <u>query</u> <u>builder</u> <u>API</u>
       <u>documentation</u>.

       If you're interested in learning more, you can also check out the <u>project</u> <u>source</u> <u>code</u>.

   <b>Hacks</b>
       Collected hacks using peewee. Have a cool hack you'd like to share? Open <u>an</u> <u>issue</u> <u>on</u>  <u>GitHub</u>  or  <u>contact</u>
       <u>me</u>.

   <b>Optimistic</b> <b>Locking</b>
       Optimistic  locking  is  useful  in  situations where you might ordinarily use a <u>SELECT</u> <u>FOR</u> <u>UPDATE</u> (or in
       SQLite, <u>BEGIN</u> <u>IMMEDIATE</u>). For example, you might fetch  a  user  record  from  the  database,  make  some
       modifications,  then  save the modified user record. Typically this scenario would require us to lock the
       user record for the duration of the transaction, from the moment we select it, to the moment we save  our
       changes.

       In  optimistic  locking,  on  the  other hand, we do <u>not</u> acquire any lock and instead rely on an internal
       <u>version</u> column in the row we're modifying. At read time, we see what version the row is currently at, and
       on save, we ensure that the update takes place only if the version is the same as the  one  we  initially
       read. If the version is higher, then some other process must have snuck in and changed the row -- to save
       our modified version could result in the loss of important changes.

       It's  quite  simple to implement optimistic locking in Peewee, here is a base class that you can use as a
       starting point:

          from peewee import *

          class ConflictDetectedException(Exception): pass

          class BaseVersionedModel(Model):
              version = IntegerField(default=1, index=True)

              def save_optimistic(self):
                  if not self.id:
                      # This is a new record, so the default logic is to perform an
                      # INSERT. Ideally your model would also have a unique
                      # constraint that made it impossible for two INSERTs to happen
                      # at the same time.
                      return self.save()

                  # Update any data that has changed and bump the version counter.
                  field_data = dict(self.__data__)
                  current_version = field_data.pop('version', 1)
                  self._populate_unsaved_relations(field_data)
                  field_data = self._prune_fields(field_data, self.dirty_fields)
                  if not field_data:
                      raise ValueError('No changes have been made.')

                  ModelClass = type(self)
                  field_data['version'] = ModelClass.version + 1  # Atomic increment.

                  query = ModelClass.update(**field_data).where(
                      (ModelClass.version == current_version) &amp;
                      (ModelClass.id == self.id))
                  if query.execute() == 0:
                      # No rows were updated, indicating another process has saved
                      # a new version. How you handle this situation is up to you,
                      # but for simplicity I'm just raising an exception.
                      raise ConflictDetectedException()
                  else:
                      # Increment local version to match what is now in the db.
                      self.version += 1
                      return True

       Here's an example of how this works. Let's assume we have  the  following  model  definition.  Note  that
       there's  a  unique  constraint  on  the  username  --  this  is important as it provides a way to prevent
       double-inserts.

          class User(BaseVersionedModel):
              username = CharField(unique=True)
              favorite_animal = CharField()

       Example:

          &gt;&gt;&gt; u = User(username='charlie', favorite_animal='cat')
          &gt;&gt;&gt; u.save_optimistic()
          True

          &gt;&gt;&gt; u.version
          1

          &gt;&gt;&gt; u.save_optimistic()
          Traceback (most recent call last):
            File "&lt;stdin&gt;", line 1, in &lt;module&gt;
            File "x.py", line 18, in save_optimistic
              raise ValueError('No changes have been made.')
          ValueError: No changes have been made.

          &gt;&gt;&gt; u.favorite_animal = 'kitten'
          &gt;&gt;&gt; u.save_optimistic()
          True

          # Simulate a separate thread coming in and updating the model.
          &gt;&gt;&gt; u2 = User.get(User.username == 'charlie')
          &gt;&gt;&gt; u2.favorite_animal = 'macaw'
          &gt;&gt;&gt; u2.save_optimistic()
          True

          # Now, attempt to change and re-save the original instance:
          &gt;&gt;&gt; u.favorite_animal = 'little parrot'
          &gt;&gt;&gt; u.save_optimistic()
          Traceback (most recent call last):
            File "&lt;stdin&gt;", line 1, in &lt;module&gt;
            File "x.py", line 30, in save_optimistic
              raise ConflictDetectedException()
          ConflictDetectedException: current version is out of sync

   <b>Top</b> <b>object</b> <b>per</b> <b>group</b>
       These examples describe several ways to query the single top item per group. For a  thorough  discuss  of
       various  techniques,  check  out  my blog post <u>Querying</u> <u>the</u> <u>top</u> <u>item</u> <u>by</u> <u>group</u> <u>with</u> <u>Peewee</u> <u>ORM</u>. If you are
       interested in the more general problem of querying the top <u>N</u> items, see the section below <u>Top</u>  <u>N</u>  <u>objects</u>
       <u>per</u> <u>group</u>.

       In these examples we will use the <u>User</u> and <u>Tweet</u> models to find each user and their most-recent tweet.

       The most efficient method I found in my testing uses the <b>MAX()</b> aggregate function.

       We  will perform the aggregation in a non-correlated subquery, so we can be confident this method will be
       performant. The idea is that we will select the posts, grouped by their author, whose timestamp is  equal
       to the max observed timestamp for that user.

          # When referencing a table multiple times, we'll call Model.alias() to create
          # a secondary reference to the table.
          TweetAlias = Tweet.alias()

          # Create a subquery that will calculate the maximum Tweet created_date for each
          # user.
          subquery = (TweetAlias
                      .select(
                          TweetAlias.user,
                          fn.MAX(TweetAlias.created_date).alias('max_ts'))
                      .group_by(TweetAlias.user)
                      .alias('tweet_max_subquery'))

          # Query for tweets and join using the subquery to match the tweet's user
          # and created_date.
          query = (Tweet
                   .select(Tweet, User)
                   .join(User)
                   .switch(Tweet)
                   .join(subquery, on=(
                       (Tweet.created_date == subquery.c.max_ts) &amp;
                       (Tweet.user == subquery.c.user_id))))

       SQLite  and  MySQL  are  a bit more lax and permit grouping by a subset of the columns that are selected.
       This means we can do away with the subquery and express it quite concisely:

          query = (Tweet
                   .select(Tweet, User)
                   .join(User)
                   .group_by(Tweet.user)
                   .having(Tweet.created_date == fn.MAX(Tweet.created_date)))

   <b>Top</b> <b>N</b> <b>objects</b> <b>per</b> <b>group</b>
       These examples describe several ways to query the top <u>N</u> items per group  reasonably  efficiently.  For  a
       thorough  discussion  of  various techniques, check out my blog post <u>Querying</u> <u>the</u> <u>top</u> <u>N</u> <u>objects</u> <u>per</u> <u>group</u>
       <u>with</u> <u>Peewee</u> <u>ORM</u>.

       In these examples we will use the <u>User</u> and <u>Tweet</u> models to find each user  and  their  three  most-recent
       tweets.

   <b>Postgres</b> <b>lateral</b> <b>joins</b>
       <u>Lateral</u> <u>joins</u> are a neat Postgres feature that allow reasonably efficient correlated subqueries. They are
       often described as SQL <b>for</b> <b>each</b> loops.

       The desired SQL is:

          SELECT * FROM
            (SELECT id, username FROM user) AS uq
             LEFT JOIN LATERAL
            (SELECT message, created_date
             FROM tweet
             WHERE (user_id = uq.id)
             ORDER BY created_date DESC LIMIT 3)
            AS pq ON true

       To accomplish this with peewee is quite straightforward:

          subq = (Tweet
                  .select(Tweet.message, Tweet.created_date)
                  .where(Tweet.user == User.id)
                  .order_by(Tweet.created_date.desc())
                  .<a href="../man3/limit.3.html">limit</a>(3))

          query = (User
                   .select(User, subq.c.content, subq.c.created_date)
                   .join(subq, JOIN.LEFT_LATERAL)
                   .order_by(User.username, subq.c.created_date.desc()))

          # We queried from the "perspective" of user, so the rows are User instances
          # with the addition of a "content" and "created_date" attribute for each of
          # the (up-to) 3 most-recent tweets for each user.
          for row in query:
              print(row.username, row.content, row.created_date)

       To implement an equivalent query from the "perspective" of the Tweet model, we can instead write:

          # subq is the same as the above example.
          subq = (Tweet
                  .select(Tweet.message, Tweet.created_date)
                  .where(Tweet.user == User.id)
                  .order_by(Tweet.created_date.desc())
                  .<a href="../man3/limit.3.html">limit</a>(3))

          query = (Tweet
                   .select(User.username, subq.c.content, subq.c.created_date)
                   .from_(User)
                   .join(subq, JOIN.LEFT_LATERAL)
                   .order_by(User.username, subq.c.created_date.desc()))

          # Each row is a "tweet" instance with an additional "username" attribute.
          # This will print the (up-to) 3 most-recent tweets from each user.
          for tweet in query:
              print(tweet.username, tweet.content, tweet.created_date)

   <b>Window</b> <b>functions</b>
       <u>Window</u> <u>functions</u>, which are <u>supported</u> <u>by</u> <u>peewee</u>, provide scalable, efficient performance.

       The desired SQL is:

          SELECT subq.message, subq.username
          FROM (
              SELECT
                  t2.message,
                  t3.username,
                  RANK() OVER (
                      PARTITION BY t2.user_id
                      ORDER BY t2.created_date DESC
                  ) AS rnk
              FROM tweet AS t2
              INNER JOIN user AS t3 ON (t2.user_id = t3.id)
          ) AS subq
          WHERE (subq.rnk &lt;= 3)

       To  accomplish  this  with  peewee,  we  will  wrap the ranked Tweets in an outer query that performs the
       filtering.

          TweetAlias = Tweet.alias()

          # The subquery will select the relevant data from the Tweet and
          # User table, as well as ranking the tweets by user from newest
          # to oldest.
          subquery = (TweetAlias
                      .select(
                          TweetAlias.message,
                          User.username,
                          fn.RANK().over(
                              partition_by=[TweetAlias.user],
                              order_by=[TweetAlias.created_date.desc()]).alias('rnk'))
                      .join(User, on=(TweetAlias.user == User.id))
                      .alias('subq'))

          # Since we can't filter on the rank, we are wrapping it in a query
          # and performing the filtering in the outer query.
          query = (Tweet
                   .select(subquery.c.message, subquery.c.username)
                   .from_(subquery)
                   .where(subquery.c.rnk &lt;= 3))

   <b>Other</b> <b>methods</b>
       If you're not using Postgres, then unfortunately you're left with options  that  exhibit  less-than-ideal
       performance.  For  a  more  complete  overview  of common methods, check out <u>this</u> <u>blog</u> <u>post</u>. Below I will
       summarize the approaches and the corresponding SQL.

       Using <b>COUNT</b>, we can get all tweets where there exist less than <u>N</u> tweets with more recent timestamps:

          TweetAlias = Tweet.alias()

          # Create a correlated subquery that calculates the number of
          # tweets with a higher (newer) timestamp than the tweet we're
          # looking at in the outer query.
          subquery = (TweetAlias
                      .select(fn.COUNT(TweetAlias.id))
                      .where(
                          (TweetAlias.created_date &gt;= Tweet.created_date) &amp;
                          (TweetAlias.user == Tweet.user)))

          # Wrap the subquery and filter on the count.
          query = (Tweet
                   .select(Tweet, User)
                   .join(User)
                   .where(subquery &lt;= 3))

       We can achieve similar results by doing a self-join and performing the filtering in the <b>HAVING</b> clause:

          TweetAlias = Tweet.alias()

          # Use a self-join and join predicates to count the number of
          # newer tweets.
          query = (Tweet
                   .select(Tweet.id, Tweet.message, Tweet.user, User.username)
                   .join(User)
                   .switch(Tweet)
                   .join(TweetAlias, on=(
                       (TweetAlias.user == Tweet.user) &amp;
                       (TweetAlias.created_date &gt;= Tweet.created_date)))
                   .group_by(Tweet.id, Tweet.content, Tweet.user, User.username)
                   .having(fn.COUNT(Tweet.id) &lt;= 3))

       The last example uses a <b>LIMIT</b> clause in a correlated subquery.

          TweetAlias = Tweet.alias()

          # The subquery here will calculate, for the user who created the
          # tweet in the outer loop, the three newest tweets. The expression
          # will evaluate to `True` if the outer-loop tweet is in the set of
          # tweets represented by the inner query.
          query = (Tweet
                   .select(Tweet, User)
                   .join(User)
                   .where(Tweet.id &lt;&lt; (
                       TweetAlias
                       .select(TweetAlias.id)
                       .where(TweetAlias.user == Tweet.user)
                       .order_by(TweetAlias.created_date.desc())
                       .<a href="../man3/limit.3.html">limit</a>(3))))

   <b>Writing</b> <b>custom</b> <b>functions</b> <b>with</b> <b>SQLite</b>
       SQLite is very easy to extend with custom functions written in Python, that are then callable  from  your
       SQL  statements. By using the <u>SqliteExtDatabase</u> and the <b>func()</b> decorator, you can very easily define your
       own functions.

       Here is an example function that generates a hashed version of a user-supplied password. We can also  use
       this to implement <b>login</b> functionality for matching a user and password.

          from hashlib import sha1
          from random import random
          from playhouse.sqlite_ext import SqliteExtDatabase

          db = SqliteExtDatabase('my-blog.db')

          def get_hexdigest(salt, raw_password):
              data = salt + raw_password
              return sha1(data.encode('utf8')).hexdigest()

          @db.func()
          def make_password(raw_password):
              salt = get_hexdigest(str(random()), str(random()))[:5]
              hsh = get_hexdigest(salt, raw_password)
              return '%s$%s' % (salt, hsh)

          @db.func()
          def check_password(raw_password, enc_password):
              salt, hsh = enc_password.split('$', 1)
              return hsh == get_hexdigest(salt, raw_password)

       Here is how you can use the function to add a new user, storing a hashed password:

          query = User.insert(
              username='charlie',
              password=fn.make_password('testing')).execute()

       If we retrieve the user from the database, the password that's stored is hashed and salted:

          &gt;&gt;&gt; user = User.get(User.username == 'charlie')
          &gt;&gt;&gt; print(user.password)
          b76fa$88be1adcde66a1ac16054bc17c8a297523170949

       To implement <b>login</b>-type functionality, you could write something like this:

          def login(username, password):
              try:
                  return (User
                          .select()
                          .where(
                              (User.username == username) &amp;
                              (fn.check_password(password, User.password) == True))
                          .get())
              except User.DoesNotExist:
                  # Incorrect username and/or password.
                  return False

   <b>Date</b> <b>math</b>
       Each  of  the  databases  supported  by  Peewee  implement  their  own set of functions and semantics for
       date/time arithmetic.

       This section will provide a short scenario and example code demonstrating how you might utilize Peewee to
       do dynamic date manipulation in SQL.

       Scenario: we need to run certain tasks every <u>X</u>  seconds,  and  both  the  task  intervals  and  the  task
       themselves  are  defined  in  the  database.  We need to write some code that will tell us which tasks we
       should run at a given time:

          class Schedule(Model):
              interval = IntegerField()  # Run this schedule every X seconds.

          class Task(Model):
              schedule = ForeignKeyField(Schedule, backref='tasks')
              command = TextField()  # Run this command.
              last_run = DateTimeField()  # When was this run last?

       Our logic will essentially boil down to:

          # e.g., if the task was last run at 12:00:05, and the associated interval
          # is 10 seconds, the next occurrence should be 12:00:15. So we check
          # whether the current time (now) is 12:00:15 or later.
          now &gt;= task.last_run + schedule.interval

       So we can write the following code:

          next_occurrence = something  # ??? how do we define this ???

          # We can express the current time as a Python datetime value, or we could
          # alternatively use the appropriate SQL function/name.
          now = Value(datetime.datetime.now())  # Or SQL('current_timestamp'), e.g.

          query = (Task
                   .select(Task, Schedule)
                   .join(Schedule)
                   .where(now &gt;= next_occurrence))

       For Postgresql we will multiple a static 1-second interval to calculate the offsets dynamically:

          second = SQL("INTERVAL '1 second'")
          next_occurrence = Task.last_run + (Schedule.interval * second)

       For MySQL we can reference the schedule's interval directly:

          from peewee import NodeList  # Needed to construct sql entity.

          interval = NodeList((SQL('INTERVAL'), Schedule.interval, SQL('SECOND')))
          next_occurrence = fn.date_add(Task.last_run, interval)

       For SQLite, things are slightly tricky because SQLite does not have a dedicated  datetime  type.  So  for
       SQLite,  we  convert  to  a  unix  timestamp, add the schedule seconds, then convert back to a comparable
       datetime representation:

          next_ts = fn.strftime('%s', Task.last_run) + Schedule.interval
          next_occurrence = fn.datetime(next_ts, 'unixepoch')

   <b>Changes</b> <b>in</b> <b>3.0</b>
       This document describes changes to be aware of when switching from 2.x to 3.x.

   <b>Backwards-incompatible</b>
       I tried to keep changes backwards-compatible as much as possible. In some places, APIs that have  changed
       will trigger a <b>DeprecationWarning</b>.

   <b>Database</b>
       • <b>get_conn()</b> has changed to <u>Database.connection()</u>

       • <b>get_cursor()</b> has changed to <u>Database.cursor()</u>

       • <b>execution_context()</b> is replaced by simply using the database instance as a context-manager.

       • For a connection context <u>without</u> a transaction, use <u>Database.connection_context()</u>.

       • <u>Database.create_tables()</u>    and   <u>Database.drop_tables()</u>,   as   well   as   <u>Model.create_table()</u>   and
         <u>Model.drop_table()</u> all default to <b>safe=True</b> (<b>create_table</b> will create if not  exists,  <b>drop_table</b>  will
         drop if exists).

       • <b>connect_kwargs</b> attribute has been renamed to <b>connect_params</b>

       • initialization parameter for custom field-type definitions has changed from <b>fields</b> to <b>field_types</b>.

   <b>Model</b> <b>Meta</b> <b>options</b>
       • <b>db_table</b> has changed to <b>table_name</b>

       • <b>db_table_func</b> has changed to <b>table_function</b>

       • <b>order_by</b> has been removed (used for specifying a default ordering to be applied to SELECT queries).

       • <b>validate_backrefs</b> has been removed. Back-references are no longer validated.

   <b>Models</b>
       • <b>BaseModel</b> has been renamed to <b>ModelBase</b>

       • Accessing raw model data is now done using <b>__data__</b> instead of <b>_data</b>

       • The <b>_prepare_instance()</b> Model method has been removed.

       • The  <b>sqlall()</b>  method,  which output the DDL statements to generate a model and its associated indexes,
         has been removed.

   <b>Fields</b>
       • <b>db_column</b> has changed to <b>column_name</b>

       • <b>db_field</b> class attribute changed to <b>field_type</b> (used if you are implementing custom field subclasses)

       • <b>model_class</b> attribute has changed to <b>model</b>

       • <b>PrimaryKeyField</b> has been renamed to <u>AutoField</u>

       • <u>ForeignKeyField</u> constructor has the following changes:

         • <b>rel_model</b> has changed to <b>model</b>

         • <b>to_field</b> has changed to <b>field</b>

         • <b>related_name</b> has changed to <b>backref</b>

       • <u>ManyToManyField</u> is now included in the main <b>peewee.py</b> module

       • Removed the extension fields <b>PasswordField</b>, <b>PickledField</b> and <b>AESEncryptedField</b>.

   <b>Querying</b>
       <b>JOIN_INNER</b>, <b>JOIN_LEFT_OUTER</b>, etc are now <b>JOIN.INNER</b>, <b>JOIN.LEFT_OUTER</b>, etc.

       The C extension that contained implementations of the query result wrappers has been removed.

       Additionally, <b>Select.aggregate_rows()</b> has been removed. This helper was used  to  de-duplicate  left-join
       queries  to  give the appearance of efficiency when iterating a model and its relations. In practice, the
       complexity of the code and its somewhat limited usefulness convinced me to scrap it. You can instead  use
       <u>prefetch()</u> to achieve the same result.

       • <u>Select</u> query attribute <b>_select</b> has changed to <b>_returning</b>

       • The  <b>naive()</b>  method  is now <u>objects()</u>, which defaults to using the model class as the constructor, but
         accepts any callable to use as an alternate constructor.

       • The <b>annotate()</b> query method is no longer supported.

       The <u>Case()</u> helper has moved from the <b>playhouse.shortcuts</b> module into the main peewee module.

       The <b>cast()</b> method is no longer a function, but instead is a method on all column-like objects.

       The  <b>InsertQuery.return_id_list()</b>  method  has  been  replaced  by  a  more  general  pattern  of   using
       <b>_</b><u>WriteQuery.returning()</u>.

       The  <b>InsertQuery.upsert()</b>  method has been replaced by the more general and flexible <u>Insert.on_conflict()</u>
       method.

       When using <u>prefetch()</u>, the collected instances will be stored in the same attribute as the  foreign-key's
       <b>backref</b>. Previously, you would access joined instances using <b>(backref)_prefetch</b>.

       The  <u>SQL</u>  object,  used  to  create  a  composable a SQL string, now expects the second parameter to be a
       list/tuple of parameters.

   <b>Removed</b> <b>Extensions</b>
       The following extensions are no longer included in the <b>playhouse</b>:

       • <b>berkeleydb</b>

       • <b>csv_utils</b>

       • <b>djpeewee</b>

       • <b>gfk</b>

       • <b>kv</b>

       • <b>pskel</b>

       • <b>read_slave</b>

   <b>SQLite</b> <b>Extension</b>
       The SQLite extension module's <u>VirtualModel</u> class accepts slightly different <b>Meta</b> options:

       • <b>arguments</b> - used to specify arbitrary arguments appended after any columns being defined on the virtual
         table. Should be a list of strings.

       • <b>extension_module</b> (unchanged)

       • <b>options</b> (replaces <b>extension_options</b>) - arbitrary options  for  the  virtual  table  that  appear  after
         columns and <b>arguments</b>.

       • <b>prefix_arguments</b>  - a list of strings that should appear before any arguments or columns in the virtual
         table declaration.

       So, when declaring a model for a virtual table, it will be constructed roughly like this:

          CREATE VIRTUAL TABLE "table name" USING extension_module (
              prefix arguments,
              field definitions,
              arguments,
              options)

   <b>Postgresql</b> <b>Extension</b>
       The <u>PostgresqlExtDatabase</u> no longer registers  the  <u>hstore</u>  extension  by  default.  To  use  the  <u>hstore</u>
       extension in 3.0 and onwards, pass <u>register_hstore=True</u> when initializing the database object.

   <b>Signals</b> <b>Extension</b>
       The <b>post_init</b> signal has been removed.

   <b>New</b> <b>stuff</b>
       The  query-builder has been rewritten from the ground-up to be more flexible and powerful. There is now a
       generic, <u>lower-level</u> <u>API</u> for constructing queries.

   <b>SQLite</b>
       Many SQLite-specific features have been moved from the <b>playhouse.sqlite_ext</b> module into <b>peewee</b>, such as:

       • User-defined functions, aggregates, collations, and table-functions.

       • Loading extensions.

       • Specifying pragmas.

       See the <u>"Using</u> <u>SQLite"</u> <u>section</u> and <u>"SQLite</u> <u>extensions"</u> documents for more details.

   <b>SQLite</b> <b>Extension</b>
       The virtual-table implementation from <u>sqlite-vtfunc</u> has been folded into the peewee codebase.

       • Support for SQLite online backup API.

       • Murmurhash implementation has been corrected.

       • Couple small quirks in the BM25 ranking code have been addressed.

       • Numerous user-defined functions for hashing and ranking are now included.

       • <b>BloomFilter</b> implementation.

       • Incremental <u>Blob</u> I/O support.

       • Support for update, commit and rollback hooks.

       • <u>LSMTable</u> implementation to support the lsm1 extension.

</pre><h4><b>NOTE</b></h4><pre>
       If you find any bugs, odd behavior, or have an idea for a new feature please don't hesitate  to  <u>open</u>  <u>an</u>
       <u>issue</u> on GitHub or <u>contact</u> <u>me</u>.

       • <u>Index</u>

       • <u>Module</u> <u>Index</u>

       • <u>Search</u> <u>Page</u>

</pre><h4><b>AUTHOR</b></h4><pre>
       charles leifer

</pre><h4><b>COPYRIGHT</b></h4><pre>
       charles leifer

3.17.7                                            Mar 04, 2025                                         <u><a href="../man1/PEEWEE.1.html">PEEWEE</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>