<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>mlpack_nca - neighborhood components analysis (nca)</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/mlpack-bin">mlpack-bin_4.5.1-1build2_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>mlpack_nca</b> - neighborhood components analysis (nca)

</pre><h4><b>SYNOPSIS</b></h4><pre>
        <b>mlpack_nca</b> <b>-i</b> <u>unknown</u> [<b>-A</b> <u>double</u>] [<b>-b</b> <u>int</u>] [<b>-l</b> <u>unknown</u>] [<b>-L</b> <u>bool</u>] [<b>-n</b> <u>int</u>] [<b>-T</b> <u>int</u>] [<b>-M</b> <u>double</u>] [<b>-m</b> <u>double</u>] [<b>-N</b> <u>bool</u>] [<b>-B</b> <u>int</u>] [<b>-O</b> <u>string</u>] [<b>-s</b> <u>int</u>] [<b>-a</b> <u>double</u>] [<b>-t</b> <u>double</u>] [<b>-V</b> <u>bool</u>] [<b>-w</b> <u>double</u>] [<b>-o</b> <u>unknown</u>] [<b>-h</b> <b>-v</b>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This  program  implements  Neighborhood  Components  Analysis,  both  a  linear  dimensionality reduction
       technique  and  a  distance  learning  technique.  The  method  seeks   to   improve   k-nearest-neighbor
       classification  on a dataset by scaling the dimensions. The method is nonparametric, and does not require
       a value of k. It  works  by  using  stochastic  ("soft")  neighbor  assignments  and  using  optimization
       techniques over the gradient of the accuracy of the neighbor assignments.

       To  work,  this  algorithm  needs  labeled  data.  It  can  be given as the last row of the input dataset
       (specified  with  '<b>--input_file</b>  (<b>-i</b>)'),  or  alternatively  as  a  separate   matrix   (specified   with
       '<b>--labels_file</b> (<b>-l</b>)').

       This  implementation  of NCA uses stochastic gradient descent, mini-batch stochastic gradient descent, or
       the L_BFGS optimizer. These optimizers do not guarantee global  convergence  for  a  nonconvex  objective
       function (NCA's objective function is nonconvex), so the final results could depend on the random seed or
       other optimizer parameters.

       Stochastic  gradient  descent, specified by the value 'sgd' for the parameter ’<b>--optimizer</b> (<b>-O</b>)', depends
       primarily on three parameters: the  step  size  (specified  with  '<b>--step_size</b>  (<b>-a</b>)'),  the  batch  size
       (specified   with   ’<b>--batch_size</b>   (<b>-b</b>)'),   and  the  maximum  number  of  iterations  (specified  with
       ’<b>--max_iterations</b> (<b>-n</b>)'). In addition, a  normalized  starting  point  can  be  used  by  specifying  the
       '<b>--normalize</b>  (<b>-N</b>)' parameter, which is necessary if many warnings of the form 'Denominator of p_i is 0!'
       are given. Tuning the step size can be a tedious affair. In general, the step size is too  large  if  the
       objective  is  not  mostly uniformly decreasing, or if zero-valued denominator warnings are being issued.
       The step size is too small if the objective is changing very slowly. Setting  the  termination  condition
       can  be done easily once a good step size parameter is found; either increase the maximum iterations to a
       large number and allow SGD to find a minimum, or set the  maximum  iterations  to  0  (allowing  infinite
       iterations)  and  set  the  tolerance  (specified  by  '<b>--tolerance</b>  (<b>-t</b>)') to define the maximum allowed
       difference between objectives for SGD to terminate. Be careful-<b>--setting</b> the  tolerance  instead  of  the
       maximum iterations can take a very long time and may actually never converge due to the properties of the
       SGD  optimizer.  Note  that  a single iteration of SGD refers to a single point, so to take a single pass
       over the dataset, set the value of the '<b>--max_iterations</b> (<b>-n</b>)' parameter equal to the number of points in
       the dataset.

       The L-BFGS optimizer, specified by the value 'lbfgs' for the parameter ’<b>--optimizer</b> (<b>-O</b>)', uses  a  back-
       tracking  line  search  algorithm  to  minimize  a function. The following parameters are used by L-BFGS:
       '<b>--num_basis</b> (<b>-B</b>)' (specifies the number of memory  points  used  by  L-BFGS),  '<b>--max_iterations</b>  (<b>-n</b>)',
       '<b>--armijo_constant</b>  (<b>-A</b>)',  '<b>--wolfe</b>  (<b>-w</b>)',  '<b>--tolerance</b> (<b>-t</b>)' (the optimization is terminated when the
       gradient norm is below this value), ’<b>--max_line_search_trials</b> (<b>-T</b>)', '<b>--min_step</b> (<b>-m</b>)',  and  '<b>--max_step</b>
       (<b>-M</b>)'  (which  both  refer to the line search routine). For more details on the L-BFGS optimizer, consult
       either the mlpack L-BFGS documentation (in lbfgs.hpp) or the vast set of published literature on L-BFGS.

       By default, the SGD optimizer is used.

</pre><h4><b>REQUIRED</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--input_file</b> <b>(-i)</b> <b>[</b><u>unknown</u><b>]</b>
              Input dataset to run NCA on.

</pre><h4><b>OPTIONAL</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--armijo_constant</b> <b>(-A)</b> <b>[</b><u>double</u><b>]</b>
              Armijo constant for L-BFGS. Default value 0.0001.

       <b>--batch_size</b> <b>(-b)</b> <b>[</b><u>int</u><b>]</b>
              Batch size for mini-batch SGD. Default value 50.

       <b>--help</b> <b>(-h)</b> <b>[</b><u>bool</u><b>]</b>
              Default help info.

       <b>--info</b> <b>[</b><u>string</u><b>]</b>
              Print help on a specific option. Default value ''.  <b>--labels_file</b> (<b>-l</b>) [<u>unknown</u>] Labels for  input
              dataset.

       <b>--linear_scan</b> <b>(-L)</b> <b>[</b><u>bool</u><b>]</b>
              Don't shuffle the order in which data points are visited for SGD or mini-batch SGD.

       <b>--max_iterations</b> <b>(-n)</b> <b>[</b><u>int</u><b>]</b>
              Maximum number of iterations for SGD or L-BFGS (0 indicates no limit). Default value 500000.

       <b>--max_line_search_trials</b> <b>(-T)</b> <b>[</b><u>int</u><b>]</b>
              Maximum number of line search trials for L-BFGS. Default value 50.

       <b>--max_step</b> <b>(-M)</b> <b>[</b><u>double</u><b>]</b>
              Maximum step of line search for L-BFGS. Default value 1e+20.

       <b>--min_step</b> <b>(-m)</b> <b>[</b><u>double</u><b>]</b>
              Minimum step of line search for L-BFGS. Default value 1e-20.

       <b>--normalize</b> <b>(-N)</b> <b>[</b><u>bool</u><b>]</b>
              Use a normalized starting point for optimization. This is useful for when points are far apart, or
              when SGD is returning NaN.

       <b>--num_basis</b> <b>(-B)</b> <b>[</b><u>int</u><b>]</b>
              Number of memory points to be stored for L-BFGS. Default value 5.

       <b>--optimizer</b> <b>(-O)</b> <b>[</b><u>string</u><b>]</b>
              Optimizer to use; 'sgd' or 'lbfgs'. Default value 'sgd'.

       <b>--seed</b> <b>(-s)</b> <b>[</b><u>int</u><b>]</b>
              Random seed. If 0, 'std::time(NULL)' is used.  Default value 0.

       <b>--step_size</b> <b>(-a)</b> <b>[</b><u>double</u><b>]</b>
              Step size for stochastic gradient descent (alpha). Default value 0.01.

       <b>--tolerance</b> <b>(-t)</b> <b>[</b><u>double</u><b>]</b>
              Maximum tolerance for termination of SGD or L-BFGS. Default value 1e-07.

       <b>--verbose</b> <b>(-v)</b> <b>[</b><u>bool</u><b>]</b>
              Display informational messages and the full list of parameters and timers at the end of execution.

       <b>--version</b> <b>(-V)</b> <b>[</b><u>bool</u><b>]</b>
              Display the version of mlpack.

       <b>--wolfe</b> <b>(-w)</b> <b>[</b><u>double</u><b>]</b>
              Wolfe condition parameter for L-BFGS. Default value 0.9.

</pre><h4><b>OPTIONAL</b> <b>OUTPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--output_file</b> (<b>-o</b>) [<u>unknown</u>] Output matrix for learned distance matrix.

</pre><h4><b>ADDITIONAL</b> <b>INFORMATION</b></h4><pre>
       For  further  information,  including  relevant  papers, citations, and theory, consult the documentation
       found at <a href="http://www.mlpack.org">http://www.mlpack.org</a> or included with your distribution of mlpack.

mlpack-4.5.1                                     29 January 2025                                   <u><a href="../man1/mlpack_nca.1.html">mlpack_nca</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>