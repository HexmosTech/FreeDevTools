<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>zstd - zstd, zstdmt, unzstd, zstdcat - Compress or decompress .zst files</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/zstd">zstd_1.5.6+dfsg-2_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>zstd</b> - zstd, zstdmt, unzstd, zstdcat - Compress or decompress .zst files

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>zstd</b> [<u>OPTIONS</u>] [-|<u>INPUT-FILE</u>] [-o <u>OUTPUT-FILE</u>]

       <b>zstdmt</b> is equivalent to <b>zstd</b> <b>-T0</b>

       <b>unzstd</b> is equivalent to <b>zstd</b> <b>-d</b>

       <b>zstdcat</b> is equivalent to <b>zstd</b> <b>-dcf</b>

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <b>zstd</b> is a fast lossless compression algorithm and data compression tool, with command line syntax similar
       to  <b><a href="../man1/gzip.1.html">gzip</a></b>(1)  and  <b><a href="../man1/xz.1.html">xz</a></b>(1).  It  is  based on the <b>LZ77</b> family, with further FSE &amp; huff0 entropy stages. <b>zstd</b>
       offers highly configurable compression speed, from fast modes at &gt; 200 MB/s per  core,  to  strong  modes
       with excellent compression ratios. It also features a very fast decoder, with speeds &gt; 500 MB/s per core,
       which remains roughly stable at all compression settings.

       <b>zstd</b> command line syntax is generally similar to gzip, but features the following few differences:

       •   Source  files  are preserved by default. It´s possible to remove them automatically by using the <b>--rm</b>
           command.

       •   When compressing a single file, <b>zstd</b> displays progress notifications and result summary  by  default.
           Use <b>-q</b> to turn them off.

       •   <b>zstd</b> displays a short help page when command line is an error. Use <b>-q</b> to turn it off.

       •   <b>zstd</b> does not accept input from console, though it does accept <b>stdin</b> when it´s not the console.

       •   <b>zstd</b> does not store the input´s filename or attributes, only its contents.

       <b>zstd</b>  processes  each  <u>file</u> according to the selected operation mode. If no <u>files</u> are given or <u>file</u> is <b>-</b>,
       <b>zstd</b> reads from standard input and writes the processed data to standard  output.  <b>zstd</b>  will  refuse  to
       write  compressed  data to standard output if it is a terminal: it will display an error message and skip
       the file. Similarly, <b>zstd</b> will refuse to read compressed data from standard input if it is a terminal.

       Unless <b>--stdout</b> or <b>-o</b> is specified, <u>files</u> are written to a new file whose name is derived from the source
       <u>file</u> name:

       •   When compressing, the suffix <b>.zst</b> is appended to the source filename to get the target filename.

       •   When decompressing, the <b>.zst</b> suffix is removed from the source filename to get the target filename

   <b>Concatenation</b> <b>with</b> <b>.zst</b> <b>Files</b>
       It is possible to concatenate multiple <b>.zst</b> files. <b>zstd</b> will decompress such agglomerated file as  if  it
       was a single <b>.zst</b> file.

</pre><h4><b>OPTIONS</b></h4><pre>
   <b>Integer</b> <b>Suffixes</b> <b>and</b> <b>Special</b> <b>Values</b>
       In  most places where an integer argument is expected, an optional suffix is supported to easily indicate
       large integers. There must be no space between the integer and the suffix.

       <b>KiB</b>    Multiply the integer by 1,024 (2^10). <b>Ki</b>, <b>K</b>, and <b>KB</b> are accepted as synonyms for <b>KiB</b>.

       <b>MiB</b>    Multiply the integer by 1,048,576 (2^20). <b>Mi</b>, <b>M</b>, and <b>MB</b> are accepted as synonyms for <b>MiB</b>.

   <b>Operation</b> <b>Mode</b>
       If multiple operation mode options are given, the last one takes effect.

       <b>-z</b>, <b>--compress</b>
              Compress. This is the default operation mode when no operation mode option  is  specified  and  no
              other operation mode is implied from the command name (for example, <b>unzstd</b> implies <b>--decompress</b>).

       <b>-d</b>, <b>--decompress</b>, <b>--uncompress</b>
              Decompress.

       <b>-t</b>, <b>--test</b>
              Test  the  integrity  of  compressed  <u>files</u>.  This option is equivalent to <b>--decompress</b> <b>--stdout</b> <b>&gt;</b>
              <b>/dev/null</b>, decompressed data is discarded and checksummed for errors.  No  files  are  created  or
              removed.

       <b>-b#</b>    Benchmark  file(s)  using  compression  level  <u>#</u>.  See  <u>BENCHMARK</u>  below for a description of this
              operation.

       <b>--train</b> <b>FILES</b>
              Use <u>FILES</u> as a training set to create a dictionary. The training set should contain a lot of small
              files (&gt; 100). See <u>DICTIONARY</u> <u>BUILDER</u> below for a description of this operation.

       <b>-l</b>, <b>--list</b>
              Display information related to a zstd compressed file, such as size, ratio, and checksum. Some  of
              these fields may not be available. This command´s output can be augmented with the <b>-v</b> modifier.

   <b>Operation</b> <b>Modifiers</b>
       •   <b>-#</b>:  selects  <b>#</b>  compression  level  [1-19] (default: 3). Higher compression levels <u>generally</u> produce
           higher compression ratio at the expense  of  speed  and  memory.  A  rough  rule  of  thumb  is  that
           compression speed is expected to be divided by 2 every 2 levels. Technically, each level is mapped to
           a  set  of  advanced  parameters  (that  can  also  be modified individually, see below). Because the
           compressor´s behavior highly depends on the content to compress, there´s no  guarantee  of  a  smooth
           progression from one level to another.

       •   <b>--ultra</b>:  unlocks  high  compression  levels  20+  (maximum  22),  using a lot more memory. Note that
           decompression will also require more memory when using these levels.

       •   <b>--fast[=#]</b>: switch to ultra-fast compression levels. If <b>=#</b> is not present,  it  defaults  to  <b>1</b>.  The
           higher  the  value,  the  faster  the  compression speed, at the cost of some compression ratio. This
           setting overwrites compression level if one was set previously. Similarly, if a compression level  is
           set after <b>--fast</b>, it overrides it.

       •   <b>-T#</b>, <b>--threads=#</b>: Compress using <b>#</b> working threads (default: 1). If <b>#</b> is 0, attempt to detect and use
           the  number of physical CPU cores. In all cases, the nb of threads is capped to <b>ZSTDMT_NBWORKERS_MAX</b>,
           which is either 64 in 32-bit mode, or 256 for 64-bit environments. This modifier does nothing if <b>zstd</b>
           is compiled without multithread support.

       •   <b>--single-thread</b>: Use a single thread for both I/O and compression. As compression is serialized  with
           I/O, this can be slightly slower. Single-thread mode features significantly lower memory usage, which
           can be useful for systems with limited amount of memory, such as 32-bit systems.

           Note 1: this mode is the only available one when multithread support is disabled.

           Note  2:  this  mode  is  different from <b>-T1</b>, which spawns 1 compression thread in parallel with I/O.
           Final compressed result is also slightly different from <b>-T1</b>.

       •   <b>--auto-threads={physical,logical}</b> <b>(default:</b> <b>physical)</b>: When using a default  amount  of  threads  via
           <b>-T0</b>, choose the default based on the number of detected physical or logical cores.

       •   <b>--adapt[=min=#,max=#]</b>:  <b>zstd</b>  will  dynamically  adapt compression level to perceived I/O conditions.
           Compression level adaptation can be observed live by using command <b>-v</b>. Adaptation can be  constrained
           between  supplied <b>min</b> and <b>max</b> levels. The feature works when combined with multi-threading and <b>--long</b>
           mode. It does not work with <b>--single-thread</b>. It sets window size to 8 MiB by default (can be  changed
           manually,  see  <b>wlog</b>).  Due  to  the  chaotic  nature of dynamic adaptation, compressed result is not
           reproducible.

           <u>Note</u>: at the time of this writing, <b>--adapt</b> can remain stuck at low speed when combined with  multiple
           worker threads (&gt;=2).

       •   <b>--long[=#]</b>:  enables  long distance matching with <b>#</b> <b>windowLog</b>, if <b>#</b> is not present it defaults to <b>27</b>.
           This increases the window size (<b>windowLog</b>) and memory usage for both the compressor and decompressor.
           This setting is designed to improve the compression ratio for files with  long  matches  at  a  large
           distance.

           Note:  If  <b>windowLog</b>  is  set  to larger than 27, <b>--long=windowLog</b> or <b>--memory=windowSize</b> needs to be
           passed to the decompressor.

       •   <b>-D</b> <b>DICT</b>: use <b>DICT</b> as Dictionary to compress or decompress FILE(s)

       •   <b>--patch-from</b> <b>FILE</b>: Specify the file to be used as a reference point for zstd´s diff engine.  This  is
           effectively dictionary compression with some convenient parameter selection, namely that <u>windowSize</u> &gt;
           <u>srcSize</u>.

           Note: cannot use both this and <b>-D</b> together.

           Note:  <b>--long</b> mode will be automatically activated if <u>chainLog</u> &lt; <u>fileLog</u> (<u>fileLog</u> being the <u>windowLog</u>
           required to cover the whole file). You can also manually force it.

           Note: for all levels, you can use <b>--patch-from</b> in <b>--single-thread</b> mode to improve  compression  ratio
           at the cost of speed.

           Note:  for  level  19,  you  can  get  increased compression ratio at the cost of speed by specifying
           <b>--zstd=targetLength=</b> to be something large (i.e. 4096), and by setting a large <b>--zstd=chainLog=</b>.

       •   <b>--rsyncable</b>: <b>zstd</b> will periodically synchronize the compression state to  make  the  compressed  file
           more  rsync-friendly.  There  is  a negligible impact to compression ratio, and a potential impact to
           compression speed, perceptible at higher speeds, for example when  combining  <b>--rsyncable</b>  with  many
           parallel  worker threads. This feature does not work with <b>--single-thread</b>. You probably don´t want to
           use it with long range mode, since it will decrease the effectiveness of the synchronization  points,
           but your mileage may vary.

       •   <b>-C</b>, <b>--[no-]check</b>: add integrity check computed from uncompressed data (default: enabled)

       •   <b>--[no-]content-size</b>:  enable  / disable whether or not the original size of the file is placed in the
           header of the compressed file. The default option is <b>--content-size</b> (meaning that the  original  size
           will be placed in the header).

       •   <b>--no-dictID</b>:  do  not  store  dictionary ID within frame header (dictionary compression). The decoder
           will have to rely on implicit knowledge about which dictionary to use, it won´t be able to  check  if
           it´s correct.

       •   <b>-M#</b>,  <b>--memory=#</b>:  Set  a  memory usage limit. By default, <b>zstd</b> uses 128 MiB for decompression as the
           maximum amount of memory the decompressor is allowed to use, but you can override  this  manually  if
           need be in either direction (i.e. you can increase or decrease it).

           This  is  also  used  during  compression when using with <b>--patch-from=</b>. In this case, this parameter
           overrides that maximum size allowed for a dictionary. (128 MiB).

           Additionally, this can be used to limit memory for dictionary training. This parameter overrides  the
           default limit of 2 GiB. zstd will load training samples up to the memory limit and ignore the rest.

       •   <b>--stream-size=#</b>:  Sets  the  pledged  source  size  of input coming from a stream. This value must be
           exact, as it will be included in the produced frame header. Incorrect  stream  sizes  will  cause  an
           error.  This  information will be used to better optimize compression parameters, resulting in better
           and potentially faster compression, especially for smaller source sizes.

       •   <b>--size-hint=#</b>: When handling input from a stream, <b>zstd</b> must guess how large the source size  will  be
           when  optimizing  compression parameters. If the stream size is relatively small, this guess may be a
           poor one, resulting in a higher compression ratio than expected. This feature allows for  controlling
           the  guess  when  needed.  Exact guesses result in better compression ratios. Overestimates result in
           slightly degraded compression ratios, while underestimates may result in significant degradation.

       •   <b>--target-compressed-block-size=#</b>: Attempt to produce compressed blocks of  approximately  this  size.
           This  will  split  larger blocks in order to approach this target. This feature is notably useful for
           improved latency, when the receiver can leverage receiving  early  incomplete  data.  This  parameter
           defines  a  loose target: compressed blocks will target this size "on average", but individual blocks
           can still be larger or smaller. Enabling this feature can decrease compression speed by up to ~10% at
           level 1. Higher levels will see smaller relative  speed  regression,  becoming  invisible  at  higher
           settings.

       •   <b>-f</b>,  <b>--force</b>: disable input and output checks. Allows overwriting existing files, input from console,
           output to stdout, operating on links, block devices, etc. During decompression and  when  the  output
           destination is stdout, pass-through unrecognized formats as-is.

       •   <b>-c</b>,  <b>--stdout</b>:  write  to  standard  output (even if it is the console); keep original files (disable
           <b>--rm</b>).

       •   <b>-o</b> <b>FILE</b>: save result into <b>FILE</b>. Note that this operation is in conflict with <b>-c</b>. If  both  operations
           are present on the command line, the last expressed one wins.

       •   <b>--[no-]sparse</b>:  enable  /  disable sparse FS support, to make files with many zeroes smaller on disk.
           Creating sparse files may save disk space and speed up decompression by reducing the amount  of  disk
           I/O.  default:  enabled  when output is into a file, and disabled when output is stdout. This setting
           overrides default and can force sparse mode over stdout.

       •   <b>--[no-]pass-through</b> enable / disable passing through uncompressed files as-is.  During  decompression
           when pass-through is enabled, unrecognized formats will be copied as-is from the input to the output.
           By  default,  pass-through will occur when the output destination is stdout and the force (<b>-f</b>) option
           is set.

       •   <b>--rm</b>: remove source file(s) after successful compression or decompression. This command  is  silently
           ignored  if  output  is <b>stdout</b>. If used in combination with <b>-o</b>, triggers a confirmation prompt (which
           can be silenced with <b>-f</b>), as this is a destructive operation.

       •   <b>-k</b>, <b>--keep</b>: keep source file(s) after successful compression or decompression. This  is  the  default
           behavior.

       •   <b>-r</b>:  operate  recursively  on  directories.  It  selects all files in the named directory and all its
           subdirectories. This can be useful both to reduce  command  line  typing,  and  to  circumvent  shell
           expansion  limitations, when there are a lot of files and naming breaks the maximum size of a command
           line.

       •   <b>--filelist</b> <b>FILE</b> read a list of files to process as content from <b>FILE</b>. Format is  compatible  with  <b>ls</b>
           output, with one file per line.

       •   <b>--output-dir-flat</b>  <b>DIR</b>:  resulting  files  are  stored  into  target  <b>DIR</b>  directory, instead of same
           directory as origin file. Be aware that this command can introduce name collision issues, if multiple
           files, from different directories, end up having the same name. Collision  resolution  ensures  first
           file  with  a  given name will be present in <b>DIR</b>, while in combination with <b>-f</b>, the last file will be
           present instead.

       •   <b>--output-dir-mirror</b> <b>DIR</b>: similar to <b>--output-dir-flat</b>, the output files are stored underneath  target
           <b>DIR</b> directory, but this option will replicate input directory hierarchy into output <b>DIR</b>.

           If  input directory contains "..", the files in this directory will be ignored. If input directory is
           an absolute directory (i.e. "/var/tmp/abc"), it will be stored into the "output-dir/var/tmp/abc".  If
           there  are  multiple input files or directories, name collision resolution will follow the same rules
           as <b>--output-dir-flat</b>.

       •   <b>--format=FORMAT</b>: compress and decompress in  other  formats.  If  compiled  with  support,  zstd  can
           compress  to  or  decompress from other compression algorithm formats. Possibly available options are
           <b>zstd</b>, <b>gzip</b>, <b>xz</b>, <b>lzma</b>, and <b>lz4</b>. If no such format is provided, <b>zstd</b> is the default.

       •   <b>-h</b>/<b>-H</b>, <b>--help</b>: display help/long help and exit

       •   <b>-V</b>, <b>--version</b>: display version number  and  immediately  exit.  note  that,  since  it  exits,  flags
           specified  after <b>-V</b> are effectively ignored. Advanced: <b>-vV</b> also displays supported formats. <b>-vvV</b> also
           displays POSIX support. <b>-qV</b> will only display the version number, suitable for machine reading.

       •   <b>-v</b>, <b>--verbose</b>: verbose mode, display more information

       •   <b>-q</b>, <b>--quiet</b>: suppress warnings, interactivity, and notifications. specify twice  to  suppress  errors
           too.

       •   <b>--no-progress</b>: do not display the progress bar, but keep all other messages.

       •   <b>--show-default-cparams</b>:  shows  the default compression parameters that will be used for a particular
           input file, based on the provided compression level and the input size. If the provided file is not a
           regular file (e.g. a pipe), this flag will output the parameters used for inputs of unknown size.

       •   <b>--exclude-compressed</b>: only compress files that are not already compressed.

       •   <b>--</b>: All arguments after <b>--</b> are treated as files

   <b>gzip</b> <b>Operation</b> <b>Modifiers</b>
       When invoked via a <b>gzip</b> symlink, <b>zstd</b> will  support  further  options  that  intend  to  mimic  the  <b>gzip</b>
       behavior:

       <b>-n</b>, <b>--no-name</b>
              do  not  store  the  original filename and timestamps when compressing a file. This is the default
              behavior and hence a no-op.

       <b>--best</b> alias to the option <b>-9</b>.

   <b>Environment</b> <b>Variables</b>
       Employing environment variables to set parameters has security implications. Therefore,  this  avenue  is
       intentionally  limited. Only <b>ZSTD_CLEVEL</b> and <b>ZSTD_NBTHREADS</b> are currently supported. They set the default
       compression level and number of threads to use during compression, respectively.

       <b>ZSTD_CLEVEL</b> can be used to set the level between  1  and  19  (the  "normal"  range).  If  the  value  of
       <b>ZSTD_CLEVEL</b>  is not a valid integer, it will be ignored with a warning message. <b>ZSTD_CLEVEL</b> just replaces
       the default compression level (<b>3</b>).

       <b>ZSTD_NBTHREADS</b> can be used to set the number of threads <b>zstd</b> will attempt to use during  compression.  If
       the  value  of <b>ZSTD_NBTHREADS</b> is not a valid unsigned integer, it will be ignored with a warning message.
       <b>ZSTD_NBTHREADS</b> has a default value of (<b>1</b>), and is  capped  at  ZSTDMT_NBWORKERS_MAX==200.  <b>zstd</b>  must  be
       compiled with multithread support for this variable to have any effect.

       They can both be overridden by corresponding command line arguments: <b>-#</b> for compression level and <b>-T#</b> for
       number of compression threads.

</pre><h4><b>ADVANCED</b> <b>COMPRESSION</b> <b>OPTIONS</b></h4><pre>
       <b>zstd</b>  provides  22  predefined  regular  compression  levels plus the fast levels. A compression level is
       translated internally into multiple advanced parameters that control the behavior of the compressor  (one
       can observe the result of this translation with <b>--show-default-cparams</b>). These advanced parameters can be
       overridden using advanced compression options.

   <b>--zstd[=options]:</b>
       The  <u>options</u>  are provided as a comma-separated list. You may specify only the options you want to change
       and the rest will be taken from the selected or default compression level. The list of available <u>options</u>:

       <b>strategy</b>=<u>strat</u>, <b>strat</b>=<u>strat</u>
              Specify a strategy used by a match finder.

              There are 9 strategies numbered from 1 to 9, from fastest to strongest: 1=<b>ZSTD_fast</b>, 2=<b>ZSTD_dfast</b>,
              3=<b>ZSTD_greedy</b>,   4=<b>ZSTD_lazy</b>,   5=<b>ZSTD_lazy2</b>,   6=<b>ZSTD_btlazy2</b>,   7=<b>ZSTD_btopt</b>,    8=<b>ZSTD_btultra</b>,
              9=<b>ZSTD_btultra2</b>.

       <b>windowLog</b>=<u>wlog</u>, <b>wlog</b>=<u>wlog</u>
              Specify the maximum number of bits for a match distance.

              The  higher  number  of  increases  the  chance to find a match which usually improves compression
              ratio. It also increases memory requirements for the compressor and decompressor. The minimum <u>wlog</u>
              is 10 (1 KiB) and the maximum is 30 (1  GiB)  on  32-bit  platforms  and  31  (2  GiB)  on  64-bit
              platforms.

              Note:  If  <b>windowLog</b> is set to larger than 27, <b>--long=windowLog</b> or <b>--memory=windowSize</b> needs to be
              passed to the decompressor.

       <b>hashLog</b>=<u>hlog</u>, <b>hlog</b>=<u>hlog</u>
              Specify the maximum number of bits for a hash table.

              Bigger hash tables cause fewer collisions which usually makes  compression  faster,  but  requires
              more memory during compression.

              The minimum <u>hlog</u> is 6 (64 entries / 256 B) and the maximum is 30 (1B entries / 4 GiB).

       <b>chainLog</b>=<u>clog</u>, <b>clog</b>=<u>clog</u>
              Specify  the  maximum number of bits for the secondary search structure, whose form depends on the
              selected <b>strategy</b>.

              Higher numbers of bits increases the chance to find a match  which  usually  improves  compression
              ratio.  It  also  slows  down compression speed and increases memory requirements for compression.
              This option is ignored for the <b>ZSTD_fast</b> <b>strategy</b>, which only has the primary hash table.

              The minimum <u>clog</u> is 6 (64 entries / 256 B) and the maximum is 29 (512M entries / 2 GiB) on  32-bit
              platforms and 30 (1B entries / 4 GiB) on 64-bit platforms.

       <b>searchLog</b>=<u>slog</u>, <b>slog</b>=<u>slog</u>
              Specify the maximum number of searches in a hash chain or a binary tree using logarithmic scale.

              More  searches  increases the chance to find a match which usually increases compression ratio but
              decreases compression speed.

              The minimum <u>slog</u> is 1 and the maximum is ´windowLog´ - 1.

       <b>minMatch</b>=<u>mml</u>, <b>mml</b>=<u>mml</u>
              Specify the minimum searched length of a match in a hash table.

              Larger search lengths usually decrease compression ratio but improve decompression speed.

              The minimum <u>mml</u> is 3 and the maximum is 7.

       <b>targetLength</b>=<u>tlen</u>, <b>tlen</b>=<u>tlen</u>
              The impact of this field vary depending on selected strategy.

              For <b>ZSTD_btopt</b>, <b>ZSTD_btultra</b> and <b>ZSTD_btultra2</b>, it specifies the minimum match length that  causes
              match  finder  to  stop  searching.  A  larger <b>targetLength</b> usually improves compression ratio but
              decreases compression speed.

              For <b>ZSTD_fast</b>, it triggers ultra-fast mode when &gt; 0. The  value  represents  the  amount  of  data
              skipped  between  match  sampling. Impact is reversed: a larger <b>targetLength</b> increases compression
              speed but decreases compression ratio.

              For all other strategies, this field has no impact.

              The minimum <u>tlen</u> is 0 and the maximum is 128 KiB.

       <b>overlapLog</b>=<u>ovlog</u>, <b>ovlog</b>=<u>ovlog</u>
              Determine <b>overlapSize</b>, amount of data reloaded from previous job. This parameter is only available
              when multithreading is enabled. Reloading more data  improves  compression  ratio,  but  decreases
              speed.

              The  minimum  <u>ovlog</u> is 0, and the maximum is 9. 1 means "no overlap", hence completely independent
              jobs. 9 means "full overlap", meaning up to <b>windowSize</b> is reloaded  from  previous  job.  Reducing
              <u>ovlog</u>  by  1 reduces the reloaded amount by a factor 2. For example, 8 means "windowSize/2", and 6
              means "windowSize/8". Value 0 is special and means "default": <u>ovlog</u> is automatically determined by
              <b>zstd</b>. In which case, <u>ovlog</u> will range from 6 to 9, depending on selected <u>strat</u>.

       <b>ldmHashLog</b>=<u>lhlog</u>, <b>lhlog</b>=<u>lhlog</u>
              Specify the maximum size for a hash table used for long distance matching.

              This option is ignored unless long distance matching is enabled.

              Bigger hash tables usually improve  compression  ratio  at  the  expense  of  more  memory  during
              compression and a decrease in compression speed.

              The minimum <u>lhlog</u> is 6 and the maximum is 30 (default: 20).

       <b>ldmMinMatch</b>=<u>lmml</u>, <b>lmml</b>=<u>lmml</u>
              Specify the minimum searched length of a match for long distance matching.

              This option is ignored unless long distance matching is enabled.

              Larger/very small values usually decrease compression ratio.

              The minimum <u>lmml</u> is 4 and the maximum is 4096 (default: 64).

       <b>ldmBucketSizeLog</b>=<u>lblog</u>, <b>lblog</b>=<u>lblog</u>
              Specify the size of each bucket for the hash table used for long distance matching.

              This option is ignored unless long distance matching is enabled.

              Larger bucket sizes improve collision resolution but decrease compression speed.

              The minimum <u>lblog</u> is 1 and the maximum is 8 (default: 3).

       <b>ldmHashRateLog</b>=<u>lhrlog</u>, <b>lhrlog</b>=<u>lhrlog</u>
              Specify the frequency of inserting entries into the long distance matching hash table.

              This option is ignored unless long distance matching is enabled.

              Larger  values  will  improve  compression speed. Deviating far from the default value will likely
              result in a decrease in compression ratio.

              The default value is <b>wlog</b> <b>-</b> <b>lhlog</b>.

   <b>Example</b>
       The following parameters sets advanced compression options to something similar to  predefined  level  19
       for files bigger than 256 KB:

       <b>--zstd</b>=wlog=23,clog=23,hlog=22,slog=6,mml=3,tlen=48,strat=6

   <b>-B#:</b>
       Specify  the  size  of  each  compression  job.  This parameter is only available when multi-threading is
       enabled. Each compression job is run in parallel, so this value  indirectly  impacts  the  nb  of  active
       threads.  Default job size varies depending on compression level (generally <b>4</b> <b>*</b> <b>windowSize</b>). <b>-B#</b> makes it
       possible to manually select a custom size. Note that job size must  respect  a  minimum  value  which  is
       enforced  transparently.  This  minimum is either 512 KB, or <b>overlapSize</b>, whichever is largest. Different
       job sizes will lead to non-identical compressed frames.

</pre><h4><b>DICTIONARY</b> <b>BUILDER</b></h4><pre>
       <b>zstd</b> offers <u>dictionary</u> compression, which greatly improves efficiency on small files and  messages.  It´s
       possible  to  train  <b>zstd</b>  with  a  set  of  samples,  the  result of which is saved into a file called a
       <b>dictionary</b>. Then, during compression and decompression, reference the same dictionary, using  command  <b>-D</b>
       <b>dictionaryFileName</b>. Compression of small files similar to the sample set will be greatly improved.

       <b>--train</b> <b>FILEs</b>
              Use FILEs as training set to create a dictionary. The training set should ideally contain a lot of
              samples  (&gt;  100), and weight typically 100x the target dictionary size (for example, ~10 MB for a
              100 KB dictionary). <b>--train</b> can be combined with <b>-r</b> to indicate a directory  rather  than  listing
              all the files, which can be useful to circumvent shell expansion limits.

              Since  dictionary  compression  is  mostly  effective for small files, the expectation is that the
              training set will only contain small files. In the case where some samples  happen  to  be  large,
              only the first 128 KiB of these samples will be used for training.

              <b>--train</b>  supports  multithreading if <b>zstd</b> is compiled with threading support (default). Additional
              advanced parameters can be specified with <b>--train-fastcover</b>. The legacy dictionary builder can  be
              accessed   with  <b>--train-legacy</b>.  The  slower  cover  dictionary  builder  can  be  accessed  with
              <b>--train-cover</b>. Default <b>--train</b> is equivalent to <b>--train-fastcover=d=8,steps=4</b>.

       <b>-o</b> <b>FILE</b>
              Dictionary saved into <b>FILE</b> (default name: dictionary).

       <b>--maxdict=#</b>
              Limit dictionary to specified size (default: 112640 bytes). As usual, quantities are expressed  in
              bytes by default, and it´s possible to employ suffixes (like <b>KB</b> or <b>MB</b>) to specify larger values.

       <b>-#</b>     Use  <b>#</b>  compression  level  during  training  (optional).  Will generate statistics more tuned for
              selected compression level, resulting in a <u>small</u> compression ratio improvement for this level.

       <b>-B#</b>    Split input files into blocks of size # (default: no split)

       <b>-M#</b>, <b>--memory=#</b>
              Limit the amount of sample data loaded for training (default: 2 GB). Note that the default (2  GB)
              is also the maximum. This parameter can be useful in situations where the training set size is not
              well  controlled  and  could  be  potentially  very  large. Since speed of the training process is
              directly correlated to the size of the training sample set, a smaller sample set leads  to  faster
              training.

              In  situations  where the training set is larger than maximum memory, the CLI will randomly select
              samples among the available ones, up to the maximum  allowed  memory  budget.  This  is  meant  to
              improve  dictionary  relevance by mitigating the potential impact of clustering, such as selecting
              only files from the beginning of a list sorted by modification date,  or  sorted  by  alphabetical
              order.  The randomization process is deterministic, so training of the same list of files with the
              same parameters will lead to the creation of the same dictionary.

       <b>--dictID=#</b>
              A dictionary ID is a locally unique ID. The decoder will use this value to verify it is using  the
              right  dictionary.  By  default,  zstd  will  create  a 4-bytes random number ID. It´s possible to
              provide an explicit number ID instead. It´s up to the dictionary manager to not assign  twice  the
              same  ID  to 2 different dictionaries. Note that short numbers have an advantage: an ID &lt; 256 will
              only need 1 byte in the compressed frame header, and an ID &lt; 65536 will only need  2  bytes.  This
              compares favorably to 4 bytes default.

              Note  that  RFC8878 reserves IDs less than 32768 and greater than or equal to 2^31, so they should
              not be used in public.

       <b>--train-cover[=k#,d=#,steps=#,split=#,shrink[=#]]</b>
              Select parameters for the default dictionary builder algorithm named cover. If <u>d</u> is not specified,
              then it tries <u>d</u> = 6 and <u>d</u> = 8. If <u>k</u> is not specified, then it tries <u>steps</u> values in the range [50,
              2000]. If <u>steps</u> is not specified, then the default value of 40 is used. If <u>split</u> is not  specified
              or  split &lt;= 0, then the default value of 100 is used. Requires that <u>d</u> &lt;= <u>k</u>. If <u>shrink</u> flag is not
              used, then the default value for <u>shrinkDict</u> of 0 is used. If <u>shrink</u> is  not  specified,  then  the
              default value for <u>shrinkDictMaxRegression</u> of 1 is used.

              Selects  segments of size <u>k</u> with highest score to put in the dictionary. The score of a segment is
              computed by the sum of the frequencies of all the subsegments of size <u>d</u>. Generally <u>d</u> should be  in
              the  range  [6,  8],  occasionally  up  to 16, but the algorithm will run faster with d &lt;= <u>8</u>. Good
              values for <u>k</u> vary widely based on the input data, but a safe range is [2 * <u>d</u>, 2000]. If  <u>split</u>  is
              100,  all  input  samples  are used for both training and testing to find optimal <u>d</u> and <u>k</u> to build
              dictionary. Supports multithreading if <b>zstd</b> is compiled  with  threading  support.  Having  <u>shrink</u>
              enabled  takes  a truncated dictionary of minimum size and doubles in size until compression ratio
              of the truncated dictionary is at most <u>shrinkDictMaxRegression%</u> worse than the  compression  ratio
              of the largest dictionary.

              Examples:

              <b>zstd</b> <b>--train-cover</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-cover=k=50,d=8</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-cover=d=8,steps=500</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-cover=k=50</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-cover=k=50,split=60</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-cover=shrink</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-cover=shrink=2</b> <b>FILEs</b>

       <b>--train-fastcover[=k#,d=#,f=#,steps=#,split=#,accel=#]</b>
              Same  as cover but with extra parameters <u>f</u> and <u>accel</u> and different default value of split If <u>split</u>
              is not specified, then it tries <u>split</u> = 75. If <u>f</u> is not specified, then it tries <u>f</u> = 20.  Requires
              that  0  &lt;  <u>f</u> &lt; 32. If <u>accel</u> is not specified, then it tries <u>accel</u> = 1. Requires that 0 &lt; <u>accel</u> &lt;=
              10. Requires that <u>d</u> = 6 or <u>d</u> = 8.

              <u>f</u> is log of size of array that keeps track of frequency of subsegments of size <u>d</u>.  The  subsegment
              is  hashed  to  an index in the range [0,2^<u>f</u> - 1]. It is possible that 2 different subsegments are
              hashed to the same index, and they are considered as the same subsegment when computing frequency.
              Using a higher <u>f</u> reduces collision but takes longer.

              Examples:

              <b>zstd</b> <b>--train-fastcover</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-fastcover=d=8,f=15,accel=2</b> <b>FILEs</b>

       <b>--train-legacy[=selectivity=#]</b>
              Use legacy dictionary builder algorithm with the given dictionary <u>selectivity</u>  (default:  9).  The
              smaller  the  <u>selectivity</u>  value, the denser the dictionary, improving its efficiency but reducing
              its achievable maximum size. <b>--train-legacy=s=#</b> is also accepted.

              Examples:

              <b>zstd</b> <b>--train-legacy</b> <b>FILEs</b>

              <b>zstd</b> <b>--train-legacy=selectivity=8</b> <b>FILEs</b>

</pre><h4><b>BENCHMARK</b></h4><pre>
       The <b>zstd</b> CLI provides a  benchmarking  mode  that  can  be  used  to  easily  find  suitable  compression
       parameters,  or  alternatively  to  benchmark  a computer´s performance. Note that the results are highly
       dependent on the content being compressed.

       <b>-b#</b>    benchmark file(s) using compression level #

       <b>-e#</b>    benchmark file(s) using multiple compression levels, from <b>-b#</b> to <b>-e#</b> (inclusive)

       <b>-d</b>     benchmark decompression speed only (requires providing an already zstd-compressed content)

       <b>-i#</b>    minimum evaluation time, in seconds (default: 3s), benchmark mode only

       <b>-B#</b>, <b>--block-size=#</b>
              cut file(s) into independent chunks of size # (default: no chunking)

       <b>--priority=rt</b>
              set process priority to real-time (Windows)

       <b>Output</b> <b>Format:</b> CompressionLevel#Filename: InputSize -&gt; OutputSize  (CompressionRatio),  CompressionSpeed,
       DecompressionSpeed

       <b>Methodology:</b>  For  both  compression and decompression speed, the entire input is compressed/decompressed
       in-memory to  measure  speed.  A  run  lasts  at  least  1  sec,  so  when  files  are  small,  they  are
       compressed/decompressed several times per run, in order to improve measurement accuracy.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man1/zstdgrep.1.html">zstdgrep</a></b>(1), <b><a href="../man1/zstdless.1.html">zstdless</a></b>(1), <b><a href="../man1/gzip.1.html">gzip</a></b>(1), <b><a href="../man1/xz.1.html">xz</a></b>(1)

       The  <u>zstandard</u>  format is specified in Y. Collet, "Zstandard Compression and the ´application/zstd´ Media
       Type", https://www.ietf.org/rfc/rfc8878.txt, Internet RFC 8878 (February 2021).

</pre><h4><b>BUGS</b></h4><pre>
       Report bugs at: https://github.com/facebook/zstd/issues

</pre><h4><b>AUTHOR</b></h4><pre>
       Yann Collet

zstd 1.5.6                                         March 2024                                            <u><a href="../man1/ZSTD.1.html">ZSTD</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>