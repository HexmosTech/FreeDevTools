<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>mlpack_gmm_train - gaussian mixture model (gmm) training</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/mlpack-bin">mlpack-bin_4.5.1-1build2_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>mlpack_gmm_train</b> - gaussian mixture model (gmm) training

</pre><h4><b>SYNOPSIS</b></h4><pre>
        <b>mlpack_gmm_train</b> <b>-g</b> <u>int</u> <b>-i</b> <u>unknown</u> [<b>-d</b> <u>bool</u>] [<b>-m</b> <u>unknown</u>] [<b>-k</b> <u>int</u>] [<b>-n</b> <u>int</u>] [<b>-P</b> <u>bool</u>] [<b>-N</b> <u>double</u>] [<b>-p</b> <u>double</u>] [<b>-r</b> <u>bool</u>] [<b>-S</b> <u>int</u>] [<b>-s</b> <u>int</u>] [<b>-T</b> <u>double</u>] [<b>-t</b> <u>int</u>] [<b>-V</b> <u>bool</u>] [<b>-M</b> <u>unknown</u>] [<b>-h</b> <b>-v</b>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This program takes a parametric estimate of a Gaussian mixture model (GMM) using the EM algorithm to find
       the maximum likelihood estimate. The model may be saved and reused by other mlpack GMM tools.

       The  input  data  to train on must be specified with the '<b>--input_file</b> (<b>-i</b>)' parameter, and the number of
       Gaussians in the model must be specified with the ’<b>--gaussians</b> (<b>-g</b>)' parameter. Optionally,  many  trials
       with  different  random  initializations  may  be  run, and the result with highest log-likelihood on the
       training data will be taken. The number of trials to run is specified with the '<b>--trials</b> (<b>-t</b>)' parameter.
       By default, only one trial is run.

       The tolerance for convergence and maximum number of iterations of the EM algorithm are specified with the
       '<b>--tolerance</b> (<b>-T</b>)' and '<b>--max_iterations</b> (<b>-n</b>)' parameters, respectively. The GMM may be  initialized  for
       training  with  another  model,  specified  with the '<b>--input_model_file</b> (<b>-m</b>)' parameter.  Otherwise, the
       model is initialized by running k-means on  the  data.  The  k-means  clustering  initialization  can  be
       controlled  with  the  ’<b>--kmeans_max_iterations</b>  (<b>-k</b>)',  '<b>--refined_start</b>  (<b>-r</b>)', '<b>--samplings</b> (<b>-S</b>)', and
       '<b>--percentage</b> (<b>-p</b>)' parameters. If '<b>--refined_start</b> (<b>-r</b>)' is specified, then the  Bradley-Fayyad  refined
       start initialization will be used. This can often lead to better clustering results.

       The  'diagonal_covariance'  flag  will  cause  the  learned  covariances  to  be  diagonal matrices. This
       significantly simplifies the model itself and causes training to be faster, but restricts the ability  to
       fit more complex GMMs.

       If  GMM training fails with an error indicating that a covariance matrix could not be inverted, make sure
       that the '<b>--no_force_positive</b> (<b>-P</b>)' parameter is not specified. Alternately, adding  a  small  amount  of
       Gaussian noise (using the '<b>--noise</b> (<b>-N</b>)' parameter) to the entire dataset may help prevent Gaussians with
       zero  variance  in  a  particular  dimension,  which  is  usually  the cause of non-invertible covariance
       matrices.

       The '<b>--no_force_positive</b> (<b>-P</b>)' parameter, if set, will avoid the checks after each iteration  of  the  EM
       algorithm  which ensure that the covariance matrices are positive definite. Specifying the flag can cause
       faster runtime, but may also cause non-positive  definite  covariance  matrices,  which  will  cause  the
       program to crash.

       As an example, to train a 6-Gaussian GMM on the data in 'data.csv' with a maximum of 100 iterations of EM
       and 3 trials, saving the trained GMM to ’gmm.bin', the following command can be used:

       $ <b>mlpack_gmm_train</b> <b>--input_file</b> data.csv <b>--gaussians</b> 6 <b>--trials</b> 3 <b>--output_model_file</b> gmm.bin

       To re-train that GMM on another set of data 'data2.csv', the following command may be used:

       $  <b>mlpack_gmm_train</b>  <b>--input_model_file</b>  gmm.bin <b>--input_file</b> data2.csv <b>--gaussians</b> 6 <b>--output_model_file</b>
       new_gmm.bin

</pre><h4><b>REQUIRED</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--gaussians</b> <b>(-g)</b> <b>[</b><u>int</u><b>]</b>
              Number of Gaussians in the GMM.

       <b>--input_file</b> <b>(-i)</b> <b>[</b><u>unknown</u><b>]</b>
              The training data on which the model will be fit.

</pre><h4><b>OPTIONAL</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--diagonal_covariance</b> <b>(-d)</b> <b>[</b><u>bool</u><b>]</b>
              Force the covariance  of  the  Gaussians  to  be  diagonal.  This  can  accelerate  training  time
              significantly.

       <b>--help</b> <b>(-h)</b> <b>[</b><u>bool</u><b>]</b>
              Default help info.

       <b>--info</b> <b>[string]</b>
              Print help on a specific option. Default value ''.

       <b>--input_model_file</b> <b>(-m)</b> <b>[</b><u>unknown</u><b>]</b>
              Initial input GMM model to start training with.

       <b>--kmeans_max_iterations</b> <b>(-k)</b> <b>[</b><u>int</u><b>]</b>
              Maximum  number  of  iterations  for  the k-means algorithm (used to initialize EM). Default value
              1000.

       <b>--max_iterations</b> <b>(-n)</b> <b>[</b><u>int</u><b>]</b>
              Maximum number of iterations of EM algorithm (passing 0 will run until convergence). Default value
              250.

       <b>--no_force_positive</b> <b>(-P)</b> <b>[</b><u>bool</u><b>]</b>
              Do not force the covariance matrices to be positive definite.

       <b>--noise</b> <b>(-N)</b> <b>[</b><u>double</u><b>]</b>
              Variance of zero-mean Gaussian noise to add to data. Default value 0.

       <b>--percentage</b> <b>(-p)</b> <b>[</b><u>double</u><b>]</b>
              If using <b>--refined_start</b>, specify the percentage of the dataset used for each sampling (should  be
              between 0.0 and 1.0). Default value 0.02.

       <b>--refined_start</b> <b>(-r)</b> <b>[</b><u>bool</u><b>]</b>
              During  the  initialization,  use  refined  initial  positions for k-means clustering (Bradley and
              Fayyad, 1998).

       <b>--samplings</b> <b>(-S)</b> <b>[</b><u>int</u><b>]</b>
              If using <b>--refined_start</b>, specify the number of samplings used for initial points.  Default  value
              100.

       <b>--seed</b> <b>(-s)</b> <b>[</b><u>int</u><b>]</b>
              Random seed. If 0, 'std::time(NULL)' is used.  Default value 0.

       <b>--tolerance</b> <b>(-T)</b> <b>[</b><u>double</u><b>]</b>
              Tolerance for convergence of EM. Default value 1e-10.

       <b>--trials</b> <b>(-t)</b> <b>[</b><u>int</u><b>]</b>
              Number of trials to perform in training GMM.  Default value 1.

       <b>--verbose</b> <b>(-v)</b> <b>[</b><u>bool</u><b>]</b>
              Display informational messages and the full list of parameters and timers at the end of execution.

       <b>--version</b> <b>(-V)</b> <b>[</b><u>bool</u><b>]</b>
              Display the version of mlpack.

</pre><h4><b>OPTIONAL</b> <b>OUTPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--output_model_file</b> <b>(-M)</b> <b>[</b><u>unknown</u><b>]</b>
              Output for trained GMM model.

</pre><h4><b>ADDITIONAL</b> <b>INFORMATION</b></h4><pre>
       For  further  information,  including  relevant  papers, citations, and theory, consult the documentation
       found at <a href="http://www.mlpack.org">http://www.mlpack.org</a> or included with your distribution of mlpack.

mlpack-4.5.1                                     29 January 2025                             <u><a href="../man1/mlpack_gmm_train.1.html">mlpack_gmm_train</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>