<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>URLEXTRACTOR - Information gathering and website reconnaissance</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/urlextractor">urlextractor_0.2.0-2.1_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       URLEXTRACTOR - Information gathering and website reconnaissance

</pre><h4><b>SYNOPSIS</b></h4><pre>
       urlextractor [URL]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       urlextractor gathers information from the specified URL and prints it to STDOUT
        gathering the following information:
         - IP and hosting info like city and country (using FreegeoIP)
         - DNS servers (using dig)
         - ASN, Network range, ISP name (using RISwhois)
         - Load balancer test
         - Whois for abuse mail (using Spamcop)
         - PAC (Proxy Auto Configuration) file
         - Compares hashes to diff code
         - robots.txt (recursively looking for hidden stuff)
         - Source code (looking for passwords and users)
         - External links (frames from other websites)
         - Directory FUZZ (like Dirbuster and Wfuzz - using Dirbuster) directory list)
         - URLvoid API - checks Google page rank, Alexa rank and possible blacklists
         - Provides useful links at other websites to correlate with IP/ASN
         - Option to open ALL results in browser at the end

</pre><h4><b>FILES</b></h4><pre>
        urlextractor at runtime wil check if the directory <b>$HOME/.urlextractor</b>
        exists if the directory does not exists the directory will be created.
        The previous behaviour has been added in Debian Systems in order to have a better
        user experience

       <b>$HOME/.urlextractor/config</b>
               The configuration file used to customize default program settings.
               After the directory <b>$HOME/.urlextractor</b> is created a default configuration file is
               copied from the package examples directory <b>/usr/share/doc/urlextractor/examples/config</b>
               containing a default configuration to enable urlextractor to work.
               For more information about the configuration check the example file.

       <b>$HOME/.urlextractor/log.csv</b>
               Save the scanned sites for future reference.

</pre><h4><b>AUTHOR</b></h4><pre>
       Eduardo Schultze &lt;<a href="mailto:eduardo.schultze@gmail.com">eduardo.schultze@gmail.com</a>&gt; (2016).

</pre><h4><b>NOTES</b></h4><pre>
       This  manual  page has been written by Josue Ortega &lt;<a href="mailto:josue@debian.org">josue@debian.org</a>&gt; for the Debian project (and may be
       used by others).

</pre><h4><b>LICENSE</b></h4><pre>
       The MIT License (MIT)

Version 0.2.0                                   FEBRUARY 27, 2021                                <u><a href="../man1/URLEXTRACTOR.1.html">URLEXTRACTOR</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>