<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>make_combined_log.pl - make combined logfile from SQL database</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/libapache2-mod-log-sql">libapache2-mod-log-sql_1.100-16.4build1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       make_combined_log.pl - make combined logfile from SQL database

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>make_combined_log.pl</b> <u>&lt;days&gt;</u> <u>&lt;virtual</u> <u>host&gt;</u>

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This perl script extracts the httpd access data from a MySQL database and formats it properly for parsing
       by 3rd-party log analysis tools.

       The  script  is intended to be run out by cron. Its commandline arguments tell it how many days' worth of
       access records to extract, and which virtual_host you are interested in (because many people log  several
       virthosts  to  one  MySQL  db.)  This  permits  you to run it daily, weekly, every 9 days -- whatever you
       decide.

</pre><h4><b>NOTE</b></h4><pre>
       By "days" I mean "chunks of 24 hours prior to the moment this script is run." So if you run  it  at  4:34
       p.m. on the 12th, it will go back through 4:34 p.m. on the 11th.

</pre><h4><b>KNOWN</b> <b>ISSUES</b></h4><pre>
       Because  GET  and  POST  are  not discriminated in the MySQL log, we'll just assume that all requests are
       GETs. This should have negligible effect on any analysis software. This could be remedied IF  you  stored
       the  full  HTTP  request  in your database instead of just the URI, but that's going to cost you a LOT of
       space really quickly...

       Because this is somewhat of a quick hack it doesn't do the most robust error checking in the  world.  Run
       it by hand to confirm your usage before putting it in crontab.

</pre><h4><b>AUTHOR</b></h4><pre>
       Edward Rudd &lt;<a href="mailto:eddie@omegaware.com">eddie@omegaware.com</a>&gt;

</pre><h4><b>MAN</b> <b>PAGE</b> <b>CREATED</b> <b>BY</b></h4><pre>
       Michael A. Toth &lt;<a href="mailto:lirul.lists@gmail.com">lirul.lists@gmail.com</a>&gt; - based on comments of script

</pre><h4><b>COMMENTS</b></h4><pre>
       This man page was written using <b>xml2man</b> <b>(1)</b> by the same author.

Manuals                                               User                               <u><a href="../man1/make_combined_log.pl.1.html">make_combined_log.pl</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>