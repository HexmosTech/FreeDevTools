<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>clfmerge - merge Common-Log Format web logs based on time-stamps</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/logtools">logtools_0.13e+nmu3_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       clfmerge - merge Common-Log Format web logs based on time-stamps

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>clfmerge</b> <b>[--help</b> <b>|</b> <b>-h]</b> <b>[-b</b> <b>size]</b> <b>[-d]</b> <b>[-v]</b> <b>[file</b> <b>names]</b>

</pre><h4><b>DESCRIPTION</b></h4><pre>
       The  <b>clfmerge</b>  program is designed to avoid using sort to merge multiple web log files.  Web logs for big
       sites consist of multiple files in the &gt;100M size range from a number of machines.  For such files it  is
       not practical to use a program such as gnusort to merge the files because the data is not always entirely
       in order (so the merge option of gnusort doesn't work so well), but it is not in random order (so doing a
       complete sort would be a waste).  Also the date field that is being sorted on is not particularly easy to
       specify for gnusort (I have seen it done but it was messy).

       This  program  is designed to simply and quickly sort multiple large log files with no need for temporary
       storage space or overly large buffers in memory (the memory footprint is generally only a few megs).

</pre><h4><b>OVERVIEW</b></h4><pre>
       It will take a number (from 0 to n) of file-names on the command line, it will open them for reading  and
       read CLF format web log data from them all.  Lines which don't appear to be in CLF format (NB they aren't
       parsed  fully, only minimal parsing to determine the date is performed) will be rejected and displayed on
       standard-error.

       If zero files are specified then there will be no error, it will just silently output  nothing,  this  is
       for  scripts  which  use the <b>find</b> command to find log files and which can't be counted on to find any log
       files, it saves doing an extra check in your shell scripts.

       If one file is specified then the data will be read into a 1000 line buffer and it will be  removed  from
       the  buffer  (and displayed on standard output) in date order.  This is to handle the case of web servers
       which date entries on the connection time but write them to the log at completion time and thus  generate
       log  files that aren't in order (Netscape web server does this - I haven't checked what other web servers
       do).

       If more than one file is specified then a line will be read  from  each  file,  the  file  that  had  the
       earliest  time  stamp  will be read from until it returns a time stamp later than one of the other files.
       Then the file with the earlier time stamp will be read.  With multiple files  the  buffer  size  is  1000
       lines  or  100  * the number of files (whichever is larger).  When the buffer becomes full the first line
       will be removed and displayed on standard output.

</pre><h4><b>OPTIONS</b></h4><pre>
       <b>-b</b> <b>buffer-size</b>
              Specify the buffer-size to use, if 0 is specified then it  means  to  disable  the  sliding-window
              sorting of the data which improves the speed.

       <b>-d</b>     Set  domain-name  mangling  to  on.  This means that if a line starts with as the name of the site
              that was requested then that would be removed from the start of the line and the <b>GET</b>  <b>/</b>  would  be
              changed to <b>GET</b> <b><a href="http://www.company.com/">http://www.company.com/</a></b> which allows programs like Webalizer to produce good graphs
              for large hosting sites.  Also it will make the domain name in lower case.

       <b>-v</b>     Be more verbose.

</pre><h4><b>EXIT</b> <b>STATUS</b></h4><pre>
       <b>0</b> No errors

       <b>1</b> Bad parameters

       <b>2</b> Can't open one of the specified files

       <b>3</b> Can't write to output

</pre><h4><b>AUTHOR</b></h4><pre>
       This   program,   its   manual   page,   and   the   Debian   package   were  written  by  Russell  Coker
       &lt;<a href="mailto:russell@coker.com.au">russell@coker.com.au</a>&gt;.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man1/clfsplit.1.html">clfsplit</a></b>(1),<b><a href="../man1/clfdomainsplit.1.html">clfdomainsplit</a></b>(1)

Russell Coker &lt;<a href="mailto:russell@coker.com.au">russell@coker.com.au</a>&gt;                  0.06                                           <u><a href="../man1/clfmerge.1.html">clfmerge</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>