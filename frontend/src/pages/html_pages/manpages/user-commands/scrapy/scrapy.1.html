<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>scrapy - the Scrapy command-line tool</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/python3-scrapy">python3-scrapy_2.12.0-2_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       scrapy - the Scrapy command-line tool

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>scrapy</b> [<u>command</u>] [<u>OPTIONS</u>] ...

</pre><h4><b>DESCRIPTION</b></h4><pre>
       Scrapy  is  controlled  through  the  <b>scrapy</b> command-line tool. The script provides several commands, for
       different purposes. Each command supports its  own  particular  syntax.  In  other  words,  each  command
       supports a different set of arguments and options.

</pre><h4><b>OPTIONS</b></h4><pre>
   <b>fetch</b> [<u><b>OPTION</b></u>] <u><b>URL</b></u>
       Fetch a URL using the Scrapy downloader

       <u>--headers</u>
              Print response HTTP headers instead of body

   <b>runspider</b> [<u><b>OPTION</b></u>] <u><b>spiderfile</b></u>
       Run a spider

       <u>--output=FILE</u>
              Store scraped items to FILE in XML format

   <b>settings</b> <b>[</b><u><b>OPTION</b></u>]
       Query Scrapy settings

       <u>--get=SETTING</u>
              Print raw setting value

       <u>--getbool=SETTING</u>
              Print setting value, interpreted as a boolean

       <u>--getint=SETTING</u>
              Print setting value, interpreted as an integer

       <u>--getfloat=SETTING</u>
              Print setting value, interpreted as a float

       <u>--getlist=SETTING</u>
              Print setting value, interpreted as a float

       <u>--init</u> Print initial setting value (before loading extensions and spiders)

   <b>shell</b> <u><b>URL</b></u> | <u><b>file</b></u>
       Launch the interactive scraping console

   <b>startproject</b> <u><b>projectname</b></u>
       Create new project with an initial project template

   <b>--help,</b> <b>-h</b>
       Print command help and options

   <b>--logfile=FILE</b>
       Log file. if omitted stderr will be used

   <b>--loglevel=LEVEL,</b> <b>-L</b> <b>LEVEL</b>
       Log level (default: None)

   <b>--nolog</b>
       Disable logging completely

   <b>--spider=SPIDER</b>
       Always use this spider when arguments are urls

   <b>--profile=FILE</b>
       Write python cProfile stats to FILE

   <b>--lsprof=FILE</b>
       Write lsprof profiling stats to FILE

   <b>--pidfile=FILE</b>
       Write process ID to FILE

   <b>--set=NAME=VALUE,</b> <b>-s</b> <b>NAME=VALUE</b>
       Set/override setting (may be repeated)

</pre><h4><b>AUTHOR</b></h4><pre>
       Scrapy was written by the Scrapy Developers.

       This  manual  page was written by Ignace Mouzannar &lt;<a href="mailto:mouzannar@gmail.com">mouzannar@gmail.com</a>&gt;, for the Debian project (but may
       be used by others).

                                                October 17, 2009                                       <u><a href="../man1/SCRAPY.1.html">SCRAPY</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>