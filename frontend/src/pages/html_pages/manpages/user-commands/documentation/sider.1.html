<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>sider - sideRETRO Documentation</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/sideretro">sideretro_1.1.6-1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       sider - sideRETRO Documentation

</pre><h4><b>GENERAL</b> <b>SYNTAX</b></h4><pre>
       <b>sideRETRO</b>  has  a  very straightforward syntax. Basically, there are three main commands, each one with a
       plethora of available options:

       • <b>process-sample</b>

       • <b>merge-call</b>

       • <b>make-vcf</b>

       So, in order to test the installation process and run a first example,  user  can  call  it  without  any
       argument from the command line, like this:

          $ sider
          Usage: sider [-hv]
                 sider &lt;command&gt; [options]

          A pipeline for detecting
          Somatic Insertion of DE novo RETROcopies

          Options:
             -h, --help            Show help options
             -v, --version         Show current version
             -c, --cite            Show citation in BibTeX

          Commands:
             ps,  process-sample   Extract alignments related
                                   an event of retrocopy
             mc,  merge-call       Discover and annotate
                                   retrocopies
             vcf, make-vcf         Generate VCF file with all
                                   annotate retrocopies

       In the above situation, if <b>sideRETRO</b> was correctly installed, it will give that default <u>usage</u> help.

       Another classical example is to print <b>sideRETRO</b>'s installed version using the <b>-v</b> option:

          $ sider --version
          sideRETRO 1.0.0

       And,  if  the  user  need further help, he can find it both at the <b>sideRETRO</b>'s <u>readthedocs</u> <u>page</u> or in the
       already installed software documentation, from command line:

          $ sider --help

       Please, see <u>A</u> <u>Practical</u> <u>Workflow</u> and <u>Running</u> <u>with</u> <u>Docker</u> sections for more examples and  tips  for  using
       with <b>Docker</b>.

       Now,  to  get  more  familiar with <b>sideRETRO</b> main commands and results, let's try some basic examples for
       each command.

</pre><h4><b>COMMAND</b> <b>PROCESS-SAMPLE</b></h4><pre>
       The first one is <b>process-sample</b> or <b>ps</b> for short, and was intended to act  as  the  <u>"evidence's</u>  <u>grounding</u>
       <u>faith"</u>  for  <b>sideRETRO</b>.  Here,  we're  saying  "first" because of an order in which the user must run the
       commands. The file resultant from this command will become the input to the next one, <b>merge-call</b>.

       As explained in the <u>Introduction</u> section, the command <b>process-sample</b> creates a database of abnormal reads
       from a SAM/BAM file set.  To do this, there are some mandatory options the  user  must  supply  to  do  a
       correct  search.  Calling the command <b>process-sample</b> without any argument will give a specific help where
       user can know all the mandatory options for this command:

          $ sider process-sample

       <b>Arguments:</b>
              One or more alignment file in SAM/BAM format

       <b>Mandatory</b> <b>Options:</b>

              <b>-a</b>, <b>--annotation-file</b>
                     Gene annotation on the reference genome in GTF/GFF3 format. sider will look for 'exon' with
                     the attribute 'transcript_type=protein_coding'.  The attributes 'gene_name', 'gene_id'  and
                     'exon_id' are also required

              <b>-i</b>, <b>--input-file</b>
                     File  containing  a newline separated list of alignment files in SAM/BAM/CRAM format.  This
                     option is not mandatory if one or more SAM/BAM/CRAM  files  are  passed  as  argument.   If
                     'input-file'  and arguments are set concomitantly, then the union of all alignment files is
                     used

       <b>Input/Output</b> <b>Options:</b>

              <b>-h</b>, <b>--help</b>
                     Show help options

              <b>-q</b>, <b>--quiet</b>
                     Decrease verbosity to error messages only or suppress terminal outputs at all if 'log-file'
                     is passed

              <b>--silent</b>
                     Same as '--quiet'

              <b>-d</b>, <b>--debug</b>
                     Increase verbosity to debug level

              <b>-l</b>, <b>--log-file</b>
                     Print log messages to a file

              <b>-o</b>, <b>--output-dir</b>
                     Output directory. Create the directory if it does not exist [default:"."]

              <b>-p</b>, <b>--prefix</b>
                     Prefix output files [default:"out"]

       <b>SQLite3</b> <b>Options:</b>

              <b>-c</b>, <b>--cache-size</b>
                     Set SQLite3 cache size in KiB [default:"200000"]

       <b>Read</b> <b>Quality</b> <b>Options:</b>

              <b>-Q</b>, <b>--phred-quality</b>
                     Minimum mapping quality of the reads required [default:"8"]

              <b>-M</b>, <b>--max-base-freq</b>
                     Maximum base frequency fraction allowed [default:"0.75"]

              <b>-D</b>, <b>--deduplicate</b>
                     Remove duplicated reads. Reads are considered  duplicates  when  they  share  the  5  prime
                     positions of both reads and read-pairs

       <b>Processing</b> <b>Options:</b>

              <b>-s</b>, <b>--sorted</b>
                     Assume  all  reads  are  grouped  by queryname, even if there is no SAM/BAM/CRAM header tag
                     'SO:queryname'

              <b>-t</b>, <b>--threads</b>
                     Number of threads [default:"1"]

              <b>-m</b>, <b>--max-distance</b>
                     Maximum distance allowed between paired-end reads [default:"10000"]

              <b>-f</b>, <b>--exon-frac</b>
                     Minimum overlap required as a fraction of exon [default:"1e-09"; 1 base]

              <b>-F</b>, <b>--alignment-frac</b>
                     Minimum overlap required as a fraction of alignment [default:"1e-09"; 1 base]

              <b>-e</b>, <b>--either</b>
                     The minimum fraction must be satisfied for at least exon OR alignment. Without  '-e',  both
                     fractions would have to be satisfied

              <b>-r</b>, <b>--reciprocal</b>
                     The  fraction  overlap must be reciprocal for exon and alignment. If '-f' is 0.5, then '-F'
                     will be set to 0.5 as well

       So, supposing that the user has three files: <u>f1.bam</u>, <u>f2.bam</u>, <u>f3.sam</u>, he can type:

          $ sider process-sample f2.bam f2.bam f3.sam \
              -a annotation_file.gtf

       Note the mandatory <b>-a</b> option specifying the annotation file. And, in this unique exception, we suppressed
       the <b>-i</b> mandatory option cause all the files were explicitly called.

       Let's see another example that shows the convenient use of the <b>-i</b> option to call a list  of  input  files
       (e.g. <u>my_files_list.txt</u>) instead of them directly:

          $ sider process-sample \
              -i my_files_list.txt \
              -a annotation_file.gtf

       Both  commands  above will produce only one output database file <u>out.db</u> containing all relevant reads for
       non-fixed retrocopies search, whose prefix <u>out</u> can be easily changed with the  <b>-p</b>  option.  The  abnormal
       reads  from all input files will be merged in just one table. To produce one database for each input file
       separately, user must run one distinct instance of <b>sideRETRO</b> per file.

       Some options' values can affect drastically the output. Let's play a little bit with some of  them  while
       using the short version of the command <b>ps</b>:

          $ sider ps \
              -i my_files_list.txt \
              -a annotation_file.gtf \
              -o output_dir \
              -p my_reads_database \
              -l my_log_file.log \
              -c 2000000 \
              -Q 20 \
              -F 0.9 \
              -t 3

       Wow! The number of options can be overwhelming.

       Here used <b>-o</b> option to specify the directory <u>output_dir</u> to write our database as <u>my_reads_database.db</u> (<b>-p</b>
       option). Also, we chose to save the log messages in <u>my_log_file.log</u> file (<b>-l</b> option), a cache size of 2Gb
       (<b>-c</b>  option),  a  minimum phred score cutoff of 20 for alignments (<b>-Q</b> option), a minimum overlap ratio of
       0.9 for read alignments over exonic regions (<b>-F</b> option) and 3 threads to process those files in  parallel
       (<b>-t</b> option).

       To  see  another  example of the <b>process-sample</b> command chained in a real workflow, please refer to the <u>A</u>
       <u>Practical</u> <u>Workflow</u> section.

</pre><h4><b>COMMAND</b> <b>MERGE-CALL</b></h4><pre>
       The second step in the <b>sideRETRO</b>'s <u>"journey</u> <u>for</u> <u>the</u> <u>truth</u> <u>of</u> <u>retrocopies"</u> is the command <b>merge-call</b> or <b>mc</b>
       for short. The aim of this command is to take the database created by <b>process-sample</b> step  as  input  and
       populate  more  tables  in  it,  with information risen from a clustering process over the abnormal reads
       regions.

       Like <b>process-sample</b>, <b>merge-call</b> has some mandatory options, which can be known by calling it without  any
       argument:

          $ sider merge-call

       <b>Arguments:</b>
              One or more SQLite3 databases generated in the <u>process-sample</u> step

       <b>Mandatory</b> <b>Options:</b>

              <b>-i</b>, <b>--input-file</b>
                     File  containing a newline separated list of SQLite3 databases to be processed. This option
                     is not mandatory if one or more SQLite3 databases are passed as argument.  If  'input-file'
                     and arguments are set concomitantly, then the union of all files is used

       <b>Input/Output</b> <b>Options:</b>

              <b>-h</b>, <b>--help</b>
                     Show help options

              <b>-q</b>, <b>--quiet</b>
                     Decrease verbosity to error messages only or suppress terminal outputs at all if 'log-file'
                     is passed

              <b>--silent</b>
                     Same as '--quiet'

              <b>-d</b>, <b>--debug</b>
                     Increase verbosity to debug level

              <b>-l</b>, <b>--log-file</b>
                     Print log messages to a file

              <b>-o</b>, <b>--output-dir</b>
                     Output directory. Create the directory if it does not exist [default:"."]

              <b>-p</b>, <b>--prefix</b>
                     Prefix output files [default:"out"]

              <b>-I</b>, <b>--in-place</b>
                     Merge all databases with the first one of the list, instead of creating a new file

       <b>SQLite3</b> <b>Options:</b>

              <b>-c</b>, <b>--cache-size</b>
                     Set SQLite3 cache size in KiB [default:"200000"]

       <b>Clustering</b> <b>Options:</b>

              <b>-e</b>, <b>--epsilon</b>
                     DBSCAN: Maximum distance between two alignments inside a cluster [default:"300"]

              <b>-m</b>, <b>--min-pts</b>
                     DBSCAN: Minimum number of points required to form a dense region [default:"10"]

       <b>Filter</b> <b>&amp;</b> <b>Annotation</b> <b>Options:</b>

              <b>-b</b>, <b>--blacklist-chr</b>
                     Avoid  clustering  from  and  to  this chromosome. This option can be passed multiple times
                     [default:"chrM"]

              <b>-B</b>, <b>--blacklist-region</b>
                     GTF/GFF3/BED blacklisted regions. If the file is in GTF/GFF3 format, the user may  indicate
                     the 'feature' (third column), the 'attribute' (ninth column) and its values

              <b>-P</b>, <b>--blacklist-padding</b>
                     Increase the blacklisted regions ranges (left and right) by N bases [default:"0"]

              <b>-T</b>, <b>--gff-feature</b>
                     The value of 'feature' (third column) for GTF/GFF3 file [default:"gene"]

              <b>-H</b>, <b>--gff-hard-attribute</b>
                     The  'attribute' (ninth column) for GTF/GFF3 file. It may be passed in the format key=value
                     (e.g. gene_type=pseudogene). Each value will match as regex, so  'pseudogene'  can  capture
                     IG_C_pseudogene,  IG_V_pseudogene etc. This option can be passed multiple times and must be
                     true in all of them

              <b>-S</b>, <b>--gff-soft-attribute</b>
                     Works as 'gff-hard-attribute'. The difference is if this option is passed  multiple  times,
                     it needs to be true only once [default:"gene_type=processed_pseudogene tag=retrogene"]

              <b>-x</b>, <b>--parental-distance</b>
                     Minimum   distance   allowed   between   a   cluster   and   its   putative  parental  gene
                     [default:"1000000"]

              <b>-g</b>, <b>--genotype-support</b>
                     Minimum number of reads  coming  from  a  given  source  (SAM/BAM/CRAM)  within  a  cluster
                     [default:"3"]

              <b>-n</b>, <b>--near-gene-rank</b>
                     Minimum ranked distance between genes in order to consider them close [default:"3"]

       <b>Genotyping</b> <b>Options:</b>

              <b>-t</b>, <b>--threads</b>
                     Number of threads [default:"1"]

              <b>-Q</b>, <b>--phred-quality</b>
                     Minimum mapping quality used to define reference allele reads [default:"8"]

       And likewise, user can call a set of database files directly, or using a list of files:

          $ sider merge-call database1.db database2.db -I

       or

          $ sider merge-call -i my_databases_list.txt -I

       <b>NOTE:</b>
          Again,  note  the  <b>-I</b>  option  that  is not mandatory but would lead the creation of duplicated output
          databases if absent. This option do the clustering "in place" over the input files,  overwriting  them
          (so be careful). If user do not use the <b>-p</b> or <b>-I</b> options, the output files will be named <u>out.db</u>.

       In  a  more  sophisticated  example,  we  will  use  the short version of the command <b>mc</b>, with many other
       options:

          $ sider mc \
              -i my_databases_list.txt \
              -o output_dir \
              -p my_database \
              -l my_log_file.log \
              -I \
              -c 2000000 \
              -B my_black_list.bed \
              -x 1000000 \
              -g 5 \
              -Q 20 \
              -C 15 \
              -t 3

       Here, options <b>-i</b>, <b>-o</b>, <b>-p</b>, <b>-l</b>, <b>-I</b>, <b>-c</b>, <b>-Q</b> and <b>-t</b> keeps the same meaning as they have in the <b>process-sample</b>
       command.  The others need some explanation. All we've done here was to ask for  a  minimum  number  of  5
       reads  of  contribution  from  each  input  SAM/BAM  file  to consider a clustering region as a retrocopy
       candidate (with <b>-g</b> option); a minimum distance of 1000000 bp from  the  parental  gene  to  resolve  some
       doubtful overlaps (<b>-x</b> option), a minimum number of 15 crossing reads over the putative insertion point to
       consider heterozygosis evidence (<b>-C</b>) and, importantly, a BED file with a list of regions to be ignored at
       the  clustering process called <u>my_black_list.txt</u> (<b>-B</b> option). This last option's file can describe entire
       chromosomes (like chrM) and many chromosomal regions with poor insertion evidences taken literature, like
       centromers. All specified regions won't be targets for clustering.

       To see another example of the <b>merge-call</b> command chained in a  real  workflow,  please  refer  to  the  <u>A</u>
       <u>Practical</u> <u>Workflow</u> section.

</pre><h4><b>COMMAND</b> <b>MAKE-VCF</b></h4><pre>
       The  third  and  last step to the <b>sideRETRO</b>'s <u>"crusade</u> <u>to</u> <u>retrocopies"</u> is the <b>make-vcf</b> command or <b>vcf</b> for
       short. This command takes the already clustered tables in the database files populated at the  <b>merge-call</b>
       step  and  creates  one  VCF  file with all statistically significant retrocopy insertions annotated in a
       convenient format.

       This command has no mandatory options, but it is worth try to discover the others:

          $ sider make-vcf

       <b>Arguments:</b>
              SQLite3 database generated at <u>process-sample</u> and <u>merge-call</u> steps

       <b>Input/Output</b> <b>Options:</b>

              <b>-h</b>, <b>--help</b>
                     Show help options

              <b>-q</b>, <b>--quiet</b>
                     Decrease verbosity to error messages only or suppress terminal outputs at all if 'log-file'
                     is passed

              <b>--silent</b>
                     Same as '--quiet'

              <b>-d</b>, <b>--debug</b>
                     Increase verbosity to debug level

              <b>-l</b>, <b>--log-file</b>
                     Print log messages to a file

              <b>-o</b>, <b>--output-dir</b>
                     Output directory. Create the directory if it does not exist [default:"."]

              <b>-p</b>, <b>--prefix</b>
                     Prefix output files [default:"out"]

       <b>Filter</b> <b>&amp;</b> <b>Annotation</b> <b>Options:</b>

              <b>-n</b>, <b>--near-gene-dist</b>
                     Minimum distance between genes in order to consider them close [default:"10000"]

              <b>-e</b>, <b>--orientation-error</b>
                     Maximum error allowed for orientation rho [default:"0.05"]

              <b>-r</b>, <b>--reference-file</b>
                     FASTA file for the reference genome

       So, in order to produce a VCF file from a database input file like <u>my_database.db</u>, just type:

          $ sider make-vcf my_database.db

       This will produce a <u>out.vcf</u> output file.

       Let's add more options to customize it to our needs (with the short  version  of  the  command  only  for
       symmetry):

          $ sider vcf my_database.db \
              -o output_dir \
              -p my_retrocopies \
              -l my_log_file.log \
              -r my_reference_genome.fa \
              -n 50000

       Command  <b>make-vcf</b>  is  very simple and don't allow the user to use threads.  The only new options are <b>-r</b>,
       which must specify the reference genome in FASTA format (like <b>gencode</b>'s <u>Hg38.fa</u>) and <b>-n</b>, where  user  can
       establish  a  distance threshold for genes surrounding insertion points for additional information in the
       output VCF file.

</pre><h4><b>DEALING</b> <b>WITH</b> <b>CRAM</b> <b>FORMAT</b></h4><pre>
       Working with CRAM files may be a little <b>tricky</b>, mainly if you have downloaded  the  data  from  a  public
       repository. Let's take a look at two possible cases:

       • Local alignment

       • External alignment

   <b>Local</b> <b>alignment</b>
       In order to generate an alignment file in the CRAM format, first we need to index the reference genome:

          # Inde for BWA: .fa.amb, .fa.ann, .fa.bwt, .fa.pac, .fa.sa files
          bwa index hg38.fa

          # Index reference genome for CRAM: .fa.fai file
          samtools faidx hg38.fa

       Then, we can align with <b>bwa</b>:

          # Align with BWA and generate a CRAM
          bwa mem hg38.fa file_R1.fastq file_R2.fastq | \
             samtools view -T hg38.fa -C -o file.cram -

       The  alignment <b>file.cram</b> can be processed with <b>sider</b>, as long as we don't change the reference genome and
       its index (<b>.fa.fai</b>) path. If so, we need to set the environment variables  <b>REF_PATH</b>  and  <b>REF_CACHE</b>,  see
       <u>External</u> <u>alignment</u>.

   <b>External</b> <b>alignment</b>
       When  we download public data already aligned in the CRAM format, we may be concerned about the reference
       genome index. Probably,  we won't have the required genome index  to  read  the  <b>.cram</b>,  and  the  <b>htslib</b>
       library - used by <b>sider</b> and <b>samtools</b> - is able to download the index from the <u>CRAM</u> <u>Reference</u> <u>Registry</u>.

       However,  in  order  to  <b>htslib</b>  be able to accomplish this task, we need to compile the library with the
       required flags and also we need to have the reqeuired dependencies (as <u>libcurl</u>).  Therefore to be able to
       read these files, without depending on these details, we need to generate a new local index and  set  the
       environment variables - <b>REF_PATH</b> and <b>REF_CACHE</b> - to the correct path:

          # Create cache dir
          mkdir -p /my/cache

          # Construct the index
          perl seq_cache_populate.pl -root /my/cache hg38.fa

          # Now before running samtools or sider, we need to
          # set the environment variables REF_PATH and REF_CACHE
          export REF_PATH=/my/cache/%2s/%2s/%s:<a href="http://www.ebi.ac.uk/ena/cram">http://www.ebi.ac.uk/ena/cram</a>
          export REF_CACHE=/my/cache/%2s/%2s/%s

          # So ...
          sider ps -a annot.gff3.gz -o result file.cram

       The script <b>seq_cache_populate.pl</b> can be found in the <b>samtools</b>, or at <u>seq_cache_populate.pl</u>.

       For more information, see <u>Samtools</u> <u>Worflow</u>.

</pre><h4><b>A</b> <b>PRACTICAL</b> <b>WORKFLOW</b></h4><pre>
       Now,  let's  do  an  interesting  exercise,  with  real  experimental data from the <u>1000</u> <u>Genomes</u> <u>Project</u>.
       (Warning: This example requires 16GB of RAM)

       In order to run <b>siderRETRO</b> searching for retrocopies, we will  download  2  whole-genome  sequenced  CRAM
       files, both aligned on the <b>gencode</b>'s <u>hg38</u> genome: <u>NA12878</u> and <u>NA12778</u>.

       At the beginning of a run, the files listed below must be at the same directory where the user is running
       <b>sideRETRO</b> or their correct paths must be supplied at the correspondent option. Files are:

       1. A GTF gene annotation file from gencode project (here <b>gencode.v32.annotation.gtf</b>).

       2. A    FASTA    file    with    the    gencode's    Human    reference    genome,   version   38   (here
          <b>GRCh38_full_analysis_set_plus_decoy_hla.fa</b>).

       3. A  custom  perl  script,  <b>seq_cache_populate.pl</b>,   to   construct   a   new   local   index   .    The
          <b>seq_cache_populate.pl</b> script can be found in <u>seq_cache_populate.pl</u>.

       4. A custom perl script, <b>analyser.pl</b>, to do the final analysis over the VCF file and produce the TSV file
          in a tabular format. The <b>analyser.pl</b> script can be downloaded <b>here</b>.

       Also,  we  will  set the environment variables <b>REF_PATH</b> and <b>REF_CACHE</b>, as a requirement to work with CRAM
       files - more information at <u>Dealing</u> <u>with</u> <u>CRAM</u> <u>format</u>.

       See the complete command sequence below for the whole analysis.

       Tip: Copy and paste line by line in your terminal.

       Tip 2: If you are running line by line in your terminal don't paste the "$" character. It is  already  in
       your terminal.

          # Do things inside a clean directory.
          # Average time: irrelevant
          $ mkdir -p sider_test
          $ cd sider_test

          # Download annotation from gencode
          wget <a href="ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.annotation.gtf.gz">ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.annotation.gtf.gz</a>

          # Download the reference genome from 1000 genomes
          wget <a href="ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/GRCh38_full_analysis_set_plus_decoy_hla.fa">ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/GRCh38_full_analysis_set_plus_decoy_hla.fa</a>

          # Make the CRAM index
          # Create cache dir
          mkdir -p cache

          # create index
          perl seq_cache_populate.pl -root cache GRCh38_full_analysis_set_plus_decoy_hla.fa

          # Set environment variables
          export REF_PATH=$PWD/cache/%2s/%2s/%s:<a href="http://www.ebi.ac.uk/ena/cram">http://www.ebi.ac.uk/ena/cram</a>
          export REF_CACHE=$PWD/cache/%2s/%2s/%s

          # Create a download list (WGS.list) containing all files of interest.
          # Average time: irrelevant
          $ echo "<a href="ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR323/ERR3239334/NA12878.final.cram">ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR323/ERR3239334/NA12878.final.cram</a>" &gt; WGS_download.list
          $ echo "<a href="ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR323/ERR3239484/NA12778.final.cram">ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR323/ERR3239484/NA12778.final.cram</a>" &gt;&gt; WGS_download.list

          # Download all files: NA12878 and NA12778.
          # Average time: network dependent
          $ wget -c -i WGS_download.list

          # Create the list of BAM files.
          # Average time: irrelevant
          $ ls *.cram &gt; WGS_genomes.list

          # First sideRETRO step: process-sample
          # Input file: WGS_genomes.list
          # Output file: 1000_genomes.db
          # Average time: 62m34.541
          $ sider process-sample \
              -i WGS_genomes.list \
              -a gencode.v32.annotation.gtf.gz \
              -p 1000_genomes \
              -c 2000000 \
              -Q 20 \
              -F 0.9 \
              -t 2

          # Second sideRETRO step: merge-call
          # Input file: 1000_genomes.db
          # Output file: 1000_genomes.db (same file)
          # Average time: 62m34.541
          $ sider merge-call 1000_genomes.db \
              -c 2000000 \
              -x 1000000 \
              -g 5 \
              -I \
              -t 2

          # Second sideRETRO step: merge-call
          # Input file: 1000_genomes.db
          # Output file: 1000_genomes.vcf
          # Average time: 62m34.541
          $ sider make-vcf 1000_genomes.db \
              -p 1000_genomes \
              -r GRCh38_full_analysis_set_plus_decoy_hla.fa

          # Some analysis over the final VCF file.
          # Input file: 1000_genomes.vcf
          # Output file: 1000_genomes.tsv
          # Average time: 62m34.541
          $ perl analyser.pl 1000_genomes.vcf &gt; 1000_genomes.tsv

       This  was  a  simple  but complete pipeline to obtain a final TSV file with all the relevant results in a
       tabular format ready to import in a R or Python script and plot some graphics.

</pre><h4><b>RUNNING</b> <b>WITH</b> <b>DOCKER</b></h4><pre>
       Notwithstanding <b>sideRETRO</b>'s native run, user can happily run it  from  a  <b>Docker</b>  image  just  prepending
       <b>Docker</b>'s  directives  to  any  example  shown.   That is, supposing the user has <u>Docker</u> installed and has
       pulled the image <u>galantelab/sider:latest</u>  from  <u>DockerHub</u>,  he  can  just  prepend  <b>docker</b>  <b>--rm</b>  <b>-ti</b>  <b>-v</b>
       <b>$(pwd):/home/sider</b> <b>-w</b> <b>/home/sider</b> <b>galantelab/sider</b> to the ordinary <b>sider</b> command, like:

          $ docker --rm -ti -v $(pwd):/home/sider -w /home/sider galantelab/sider \
            sider ps \
                -i my_files_list.txt \
                -a annotation_file.gtf \
                -o output_dir \
                -p my_reads_database \
                -l my_log_file.log \
                -c 2000000 \
                -Q 20 \
                -F 0.9 \
                -t 3

</pre><h4><b>AUTHOR</b></h4><pre>
       Thiago L. A. Miller

</pre><h4><b>COPYRIGHT</b></h4><pre>
       2020, The sideRETRO Team

                                                  Nov 12, 2024                                          <u><a href="../man1/SIDER.1.html">SIDER</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>