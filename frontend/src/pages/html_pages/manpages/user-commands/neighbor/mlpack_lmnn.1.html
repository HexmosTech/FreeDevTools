<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>mlpack_lmnn - large margin nearest neighbors (lmnn)</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/mlpack-bin">mlpack-bin_4.5.1-1build2_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>mlpack_lmnn</b> - large margin nearest neighbors (lmnn)

</pre><h4><b>SYNOPSIS</b></h4><pre>
        <b>mlpack_lmnn</b> <b>-i</b> <u>unknown</u> [<b>-b</b> <u>int</u>] [<b>-C</b> <u>bool</u>] [<b>-d</b> <u>unknown</u>] [<b>-k</b> <u>int</u>] [<b>-l</b> <u>unknown</u>] [<b>-L</b> <u>bool</u>] [<b>-n</b> <u>int</u>] [<b>-N</b> <u>bool</u>] [<b>-O</b> <u>string</u>] [<b>-p</b> <u>int</u>] [<b>-P</b> <u>bool</u>] [<b>-A</b> <u>int</u>] [<b>-r</b> <u>double</u>] [<b>-s</b> <u>int</u>] [<b>-a</b> <u>double</u>] [<b>-t</b> <u>double</u>] [<b>-R</b> <u>int</u>] [<b>-V</b> <u>bool</u>] [<b>-c</b> <u>unknown</u>] [<b>-o</b> <u>unknown</u>] [<b>-D</b> <u>unknown</u>] [<b>-h</b> <b>-v</b>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This  program  implements Large Margin Nearest Neighbors, a distance learning technique. The method seeks
       to improve k-nearest-neighbor classification on a dataset. The method employes the strategy  of  reducing
       distance  between  similar  labeled  data points (a.k.a target neighbors) and increasing distance between
       differently labeled points (a.k.a impostors) using standard optimization techniques over the gradient  of
       the distance between data points.

       To  work,  this  algorithm  needs  labeled  data.  It  can  be given as the last row of the input dataset
       (specified  with  '<b>--input_file</b>  (<b>-i</b>)'),  or  alternatively  as  a  separate   matrix   (specified   with
       '<b>--labels_file</b>  (<b>-l</b>)').  Additionally, a starting point for optimization (specified with '<b>--distance_file</b>
       (<b>-d</b>)'can be given, having (r x d) dimensionality. Here r should satisfy 1 &lt;= r &lt;= d, Consequently a  Low-
       Rank  matrix will be optimized. Alternatively, Low-Rank distance can be learned by specifying the '<b>--rank</b>
       (<b>-A</b>)'parameter (A Low-Rank matrix with uniformly distributed values will  be  used  as  initial  learning
       point).

       The  program  also  requires  number  of  targets  neighbors to work with ( specified with '<b>--k</b> (<b>-k</b>)'), A
       regularization parameter can also be passed, It acts as a trade of between the pulling and pushing  terms
       (specified  with  ’<b>--regularization</b> (<b>-r</b>)'), In addition, this implementation of LMNN includes a parameter
       to decide the interval after which impostors must be  re-calculated  (specified  with  '<b>--update_interval</b>
       (<b>-R</b>)').

       Output  can  either  be  the  learned  distance  matrix  (specified  with  ’<b>--output_file</b>  (<b>-o</b>)'), or the
       transformed dataset (specified with ’<b>--transformed_data_file</b> (<b>-D</b>)'), or both. Additionally  mean-centered
       dataset (specified with '<b>--centered_data_file</b> (<b>-c</b>)') can be accessed given mean-centering (specified with
       '<b>--center</b>  (<b>-C</b>)') is performed on the dataset.  Accuracy on initial dataset and final transformed dataset
       can be printed by specifying the '<b>--print_accuracy</b> (<b>-P</b>)'parameter.

       This  implementation  of  LMNN  uses  AdaGrad,  BigBatch_SGD,  stochastic  gradient  descent,  mini-batch
       stochastic gradient descent, or the L_BFGS optimizer.

       AdaGrad,  specified  by  the  value  'adagrad' for the parameter '<b>--optimizer</b> (<b>-O</b>)', uses maximum of past
       squared gradients. It primarily on six parameters: the step size (specified with '<b>--step_size</b> (<b>-a</b>)'), the
       batch size (specified with '<b>--batch_size</b> (<b>-b</b>)'), the maximum number of passes (specified  with  ’<b>--passes</b>
       (<b>-p</b>)').  Inaddition,  a  normalized  starting  point  can  be  used  by specifying the '<b>--normalize</b> (<b>-N</b>)'
       parameter.

       BigBatch_SGD, specified by the value 'bbsgd' for the parameter '<b>--optimizer</b> (<b>-O</b>)', depends  primarily  on
       four  parameters:  the  step  size  (specified  with  ’<b>--step_size</b> (<b>-a</b>)'), the batch size (specified with
       '<b>--batch_size</b> (<b>-b</b>)'), the maximum number of passes (specified  with  '<b>--passes</b>  (<b>-p</b>)').  In  addition,  a
       normalized starting point can be used by specifying the '<b>--normalize</b> (<b>-N</b>)' parameter.

       Stochastic  gradient  descent, specified by the value 'sgd' for the parameter ’<b>--optimizer</b> (<b>-O</b>)', depends
       primarily on three parameters: the  step  size  (specified  with  '<b>--step_size</b>  (<b>-a</b>)'),  the  batch  size
       (specified  with ’<b>--batch_size</b> (<b>-b</b>)'), and the maximum number of passes (specified with ’<b>--passes</b> (<b>-p</b>)').
       In addition, a normalized starting point can be used by  specifying  the  '<b>--normalize</b>  (<b>-N</b>)'  parameter.
       Furthermore, mean-centering can be performed on the dataset by specifying the '<b>--center</b> (<b>-C</b>)'parameter.

       The  L-BFGS  optimizer, specified by the value 'lbfgs' for the parameter ’<b>--optimizer</b> (<b>-O</b>)', uses a back-
       tracking line search algorithm to minimize a function. The  following  parameters  are  used  by  L-BFGS:
       '<b>--max_iterations</b>  (<b>-n</b>)',  '<b>--tolerance</b>  (<b>-t</b>)'(the  optimization  is terminated when the gradient norm is
       below this value).  For  more  details  on  the  L-BFGS  optimizer,  consult  either  the  mlpack  L-BFGS
       documentation (in lbfgs.hpp) or the vast set of published literature on L-BFGS. In addition, a normalized
       starting point can be used by specifying the '<b>--normalize</b> (<b>-N</b>)' parameter.

       By default, the AMSGrad optimizer is used.

       Example  -  Let's  say  we  want  to  learn  distance  on  iris dataset with number of targets as 3 using
       BigBatch_SGD optimizer. A simple call for the same will look like:

       $ <b>mlpack_lmnn</b> <b>--input_file</b> iris.csv <b>--labels_file</b> iris_labels.csv <b>--k</b> 3 <b>--optimizer</b>  bbsgd  <b>--output_file</b>
       output.csv

       Another  program call making use of update interval &amp; regularization parameter with dataset having labels
       as last column can be made as:

       $ <b>mlpack_lmnn</b>  <b>--input_file</b>  letter_recognition.csv  <b>--k</b>  5  <b>--update_interval</b>  10  <b>--regularization</b>  0.4
       <b>--output_file</b> output.csv

</pre><h4><b>REQUIRED</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--input_file</b> <b>(-i)</b> <b>[</b><u>unknown</u><b>]</b>
              Input dataset to run LMNN on.

</pre><h4><b>OPTIONAL</b> <b>INPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--batch_size</b> <b>(-b)</b> <b>[</b><u>int</u><b>]</b>
              Batch size for mini-batch SGD. Default value 50.

       <b>--center</b> <b>(-C)</b> <b>[</b><u>bool</u><b>]</b>
              Perform  mean-centering on the dataset. It is useful when the centroid of the data is far from the
              origin.

       <b>--distance_file</b> <b>(-d)</b> <b>[</b><u>unknown</u><b>]</b>
              Initial distance matrix to be used as starting point

       <b>--help</b> <b>(-h)</b> <b>[</b><u>bool</u><b>]</b>
              Default help info.

       <b>--info</b> <b>[</b><u>string</u><b>]</b>
              Print help on a specific option. Default value ''.

       <b>--k</b> <b>(-k)</b> <b>[</b><u>int</u><b>]</b>
              Number of target neighbors to use  for  each  datapoint.  Default  value  1.   <b>--labels_file</b>  (<b>-l</b>)
              [<u>unknown</u>] Labels for input dataset.

       <b>--linear_scan</b> <b>(-L)</b> <b>[</b><u>bool</u><b>]</b>
              Don't shuffle the order in which data points are visited for SGD or mini-batch SGD.

       <b>--max_iterations</b> <b>(-n)</b> <b>[</b><u>int</u><b>]</b>
              Maximum number of iterations for L-BFGS (0 indicates no limit). Default value 100000.

       <b>--normalize</b> <b>(-N)</b> <b>[</b><u>bool</u><b>]</b>
              Use  a  normalized  starting point for optimization. Itis useful for when points are far apart, or
              when SGD is returning NaN.

       <b>--optimizer</b> <b>(-O)</b> <b>[</b><u>string</u><b>]</b>
              Optimizer to use; 'amsgrad', 'bbsgd', 'sgd', or 'lbfgs'. Default value 'amsgrad'.

       <b>--passes</b> <b>(-p)</b> <b>[</b><u>int</u><b>]</b>
              Maximum number of full passes over  dataset  for  AMSGrad,  BB_SGD  and  SGD.  Default  value  50.
              <b>--print_accuracy</b> (<b>-P</b>) [<u>bool</u>] Print accuracies on initial and transformed dataset

       <b>--rank</b> <b>(-A)</b> <b>[</b><u>int</u><b>]</b>
              Rank of distance matrix to be optimized.  Default value 0.

       <b>--regularization</b> <b>(-r)</b> <b>[</b><u>double</u><b>]</b>
              Regularization for LMNN objective function  Default value 0.5.

       <b>--seed</b> <b>(-s)</b> <b>[</b><u>int</u><b>]</b>
              Random seed. If 0, 'std::time(NULL)' is used.  Default value 0.

       <b>--step_size</b> <b>(-a)</b> <b>[</b><u>double</u><b>]</b>
              Step size for AMSGrad, BB_SGD and SGD (alpha).  Default value 0.01.

       <b>--tolerance</b> <b>(-t)</b> <b>[</b><u>double</u><b>]</b>
              Maximum  tolerance  for  termination  of  AMSGrad,  BB_SGD,  SGD  or  L-BFGS. Default value 1e-07.
              <b>--update_interval</b> (<b>-R</b>) [<u>int</u>] Number of iterations after which impostors need to  be  recalculated.
              Default value 1.

       <b>--verbose</b> <b>(-v)</b> <b>[</b><u>bool</u><b>]</b>
              Display informational messages and the full list of parameters and timers at the end of execution.

       <b>--version</b> <b>(-V)</b> <b>[</b><u>bool</u><b>]</b>
              Display the version of mlpack.

</pre><h4><b>OPTIONAL</b> <b>OUTPUT</b> <b>OPTIONS</b></h4><pre>
       <b>--centered_data_file</b> <b>(-c)</b> <b>[</b><u>unknown</u><b>]</b>
              Output  matrix  for mean-centered dataset.  <b>--output_file</b> (<b>-o</b>) [<u>unknown</u>] Output matrix for learned
              distance matrix.

       <b>--transformed_data_file</b> <b>(-D)</b> <b>[</b><u>unknown</u><b>]</b>
              Output matrix for transformed dataset.

</pre><h4><b>ADDITIONAL</b> <b>INFORMATION</b></h4><pre>
       For further information, including relevant papers, citations,  and  theory,  consult  the  documentation
       found at <a href="http://www.mlpack.org">http://www.mlpack.org</a> or included with your distribution of mlpack.

mlpack-4.5.1                                     29 January 2025                                  <u><a href="../man1/mlpack_lmnn.1.html">mlpack_lmnn</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>