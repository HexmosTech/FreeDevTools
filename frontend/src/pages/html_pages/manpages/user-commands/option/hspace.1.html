<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>hspace - Cluster space analyzer for Ganeti</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/ganeti-htools-3.1">ganeti-htools-3.1_3.1.0~rc2-2_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       hspace - Cluster space analyzer for Ganeti

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>hspace</b>  {backend options...} [algorithm options...]  [request options...]  [output options...]  [-v...  |
       -q]

       <b>hspace</b> --version

       Backend options:

       { <b>-m</b> <u>cluster</u> | <b>-L[</b> <u>path</u> <b>]</b> | <b>-t</b> <u>data-file</u> | <b>--simulate</b> <u>spec</u> | <b>-I</b> <u>path</u> }

       Algorithm options:

       <b>[</b> <b>--max-cpu</b> <b>*cpu-ratio*</b> <b>]</b> <b>[</b> <b>--min-disk</b> <b>*disk-ratio*</b> <b>]</b>  <b>[</b>  <b>-O</b>  <b>*name...*</b>  <b>]</b>  <b>[</b>  <b>--independent-groups</b>  <b>]</b>  <b>[</b>
       <b>--no-capacity-checks</b> <b>]</b>

       Request options:

       <b>[--disk-template</b> <u>template</u> <b>]</b>

       <b>[--standard-alloc</b> <u>disk,ram,cpu</u> <b>]</b>

       <b>[--tiered-alloc</b> <u>disk,ram,cpu</u> <b>]</b>

       Output options:

       <b>[--machine-readable</b>[=*CHOICE*] <b>]</b> <b>[-p</b>[<u>fields</u>]<b>]</b>

</pre><h4><b>DESCRIPTION</b></h4><pre>
       hspace computes how many additional instances can be fit on a cluster, while maintaining N+1 status.

       The  program  will try to place instances, all of the same size, on the cluster, until the point where we
       don't have any N+1 possible allocation.  It  uses  the  exact  same  allocation  algorithm  as  the  hail
       iallocator plugin in <u>allocate</u> mode.

       The  output  of  the program is designed either for human consumption (the default) or, when enabled with
       the --machine-readable option (described further below), for machine consumption.  In the latter case, it
       is intended to interpreted as a shell fragment (or parsed as a <u>key=value</u> file).  Options which extend the
       output (e.g.  -p, -v) will output the additional information on stderr (such that  the  stdout  is  still
       parseable).

       By  default,  the instance specifications will be read from the cluster; the options --standard-alloc and
       --tiered-alloc can be used to override them.

       The following keys are available in the machine-readable output of the script (all prefixed with <u>HTS</u><b>_</b>):

       SPEC_MEM, SPEC_DSK, SPEC_CPU, SPEC_RQN, SPEC_DISK_TEMPLATE, SPEC_SPN
              These represent the specifications of the instance model used for allocation  (the  memory,  disk,
              cpu, requested nodes, disk template, spindles).

       TSPEC_INI_MEM, TSPEC_INI_DSK, TSPEC_INI_CPU, ...
              Only  defined  when  the  tiered  mode  allocation  is  enabled,  these  are  similar to the above
              specifications but show the initial starting spec for tiered allocation.

       CLUSTER_MEM, CLUSTER_DSK, CLUSTER_CPU, CLUSTER_NODES, CLUSTER_SPN
              These represent the total memory, disk, CPU count, total nodes, and total spindles in the cluster.

       INI_SCORE, FIN_SCORE
              These are the initial (current) and final cluster score (see the hbal man page for  details  about
              the scoring algorithm).

       INI_INST_CNT, FIN_INST_CNT
              The initial and final instance count.

       INI_MEM_FREE, FIN_MEM_FREE
              The  initial  and  final  total  free  memory  in  the  cluster (but this doesn't necessarily mean
              available for use).

       INI_MEM_AVAIL, FIN_MEM_AVAIL
              The initial and final total available  memory  for  allocation  in  the  cluster.   If  allocating
              redundant  instances,  new  instances could increase the reserved memory so it doesn't necessarily
              mean the entirety of this memory can be used for new instance allocations.

       INI_MEM_RESVD, FIN_MEM_RESVD
              The initial and final reserved memory (for redundancy/N+1 purposes).

       INI_MEM_INST, FIN_MEM_INST
              The initial and final memory used for instances (actual runtime used RAM).

       INI_MEM_OVERHEAD, FIN_MEM_OVERHEAD
              The initial and final memory overhead, i.e.  memory used  for  the  node  itself  and  unaccounted
              memory (e.g.  due to hypervisor overhead).

       INI_MEM_EFF, HTS_INI_MEM_EFF
              The initial and final memory efficiency, represented as instance memory divided by total memory.

       INI_DSK_FREE, INI_DSK_AVAIL, INI_DSK_RESVD, INI_DSK_INST, INI_DSK_EFF
              Initial disk stats, similar to the memory ones.

       FIN_DSK_FREE, FIN_DSK_AVAIL, FIN_DSK_RESVD, FIN_DSK_INST, FIN_DSK_EFF
              Final disk stats, similar to the memory ones.

       INI_SPN_FREE, ..., FIN_SPN_FREE, ..
              Initial and final spindles stats, similar to memory ones.

       INI_CPU_INST, FIN_CPU_INST
              Initial and final number of virtual CPUs used by instances.

       INI_CPU_EFF, FIN_CPU_EFF
              The initial and final CPU efficiency, represented as the count of virtual instance CPUs divided by
              the total physical CPU count.

       INI_MNODE_MEM_AVAIL, FIN_MNODE_MEM_AVAIL
              The  initial and final maximum per-node available memory.  This is not very useful as a metric but
              can give an impression of the status of the nodes; as an example, this value restricts the maximum
              instance size that can be still created on the cluster.

       INI_MNODE_DSK_AVAIL, FIN_MNODE_DSK_AVAIL
              Like the above but for disk.

       TSPEC  This parameter holds the pairs of specifications and counts of instances that can  be  created  in
              the  <u>tiered</u> <u>allocation</u> mode.  The value of the key is a space-separated list of values; each value
              is of the form <u>memory,disk,vcpu,spindles=count</u> where the memory, disk and vcpu are the values  for
              the  current  spec, and count is how many instances of this spec can be created.  A complete value
              for this variable could be: <b>4096,102400,2,1=225</b> <b>2560,102400,2,1=20</b> <b>512,102400,2,1=21</b>.

       KM_USED_CPU, KM_USED_NPU, KM_USED_MEM, KM_USED_DSK
              These represents the metrics of used resources at the start of the computation  (only  for  tiered
              allocation  mode).   The  NPU  value  is  "normalized" CPU count, i.e.  the number of virtual CPUs
              divided by the maximum ratio of the virtual to physical CPUs.

       KM_POOL_CPU, KM_POOL_NPU, KM_POOL_MEM, KM_POOL_DSK
              These represents the total resources allocated during the tiered allocation process.   In  effect,
              they represent how much is readily available for allocation.

       KM_UNAV_CPU, KM_POOL_NPU, KM_UNAV_MEM, KM_UNAV_DSK
              These represents the resources left over (either free as in unallocable or allocable on their own)
              after  the  tiered  allocation  has  been completed.  They represent better the actual unallocable
              resources, because some other resource has been exhausted.  For example, the cluster  might  still
              have 100GiB disk free, but with no memory left for instances, we cannot allocate another instance,
              so  in  effect  the disk space is unallocable.  Note that the CPUs here represent instance virtual
              CPUs, and in case the <u>--max-cpu</u> option hasn't been specified this will be -1.

       ALLOC_USAGE
              The current usage represented  as  initial  number  of  instances  divided  per  final  number  of
              instances.

       ALLOC_COUNT
              The number of instances allocated (delta between FIN_INST_CNT and INI_INST_CNT).

       ALLOC_FAIL*_CNT
              For  the  last attempt at allocations (which would have increased FIN_INST_CNT with one, if it had
              succeeded), this is the count of the failure reasons  per  failure  type;  currently  defined  are
              FAILMEM,  FAILDISK and FAILCPU which represent errors due to not enough memory, disk and CPUs, and
              FAILN1 which represents a non N+1 compliant cluster on which we can't allocate instances at all.

       ALLOC_FAIL_REASON
              The reason for most of the failures, being one of the above FAIL* strings.

       OK     A marker representing the successful end of the computation, and having value "1".  If this key is
              not present in the output it means that the computation failed and any values present  should  not
              be relied upon.

       Many of the INI_/FIN_ metrics will be also displayed with a TRL_ prefix, and denote the cluster status at
       the end of the tiered allocation run.

       The human output format should be self-explanatory, so it is not described further.

</pre><h4><b>OPTIONS</b></h4><pre>
       The options that can be passed to the program are as follows:

       --disk-template <u>template</u>
              Overrides  the  disk  template  for  the  instance  read  from the cluster; one of the Ganeti disk
              templates (e.g.  plain, drbd, so on) should be passed in.

       --spindle-use <u>spindles</u>
              Override the spindle use for the instance read from the cluster.  The value can be 0 (for  example
              for instances that use very low I/O), but not negative.  For shared storage the value is ignored.

       --max-cpu=*cpu-ratio*
              The  maximum  virtual  to  physical cpu ratio, as a floating point number greater than or equal to
              one.  For example, specifying <u>cpu-ratio</u> as <b>2.5</b> means that, for a 4-cpu machine, a  maximum  of  10
              virtual  cpus  should be allowed to be in use for primary instances.  A value of exactly one means
              there will be no over-subscription of CPU (except for the CPU time used by the node  itself),  and
              values  below  one  do  not  make sense, as that means other resources (e.g.  disk) won't be fully
              utilised due to CPU restrictions.

       --min-disk=*disk-ratio*
              The minimum amount of free disk space  remaining,  as  a  floating  point  number.   For  example,
              specifying <u>disk-ratio</u> as <b>0.25</b> means that at least one quarter of disk space should be left free on
              nodes.

       --independent-groups
              Consider  all  groups  independent.  That is, if a node that is not N+1 happy is found, ignore its
              group, but still do allocation in the other groups.  The default is to not try allocation at  all,
              if some not N+1 happy node is found.

       --accept-existing-errors
              This  is  a  strengthened form of --independent-groups.  It tells hspace to ignore the presence of
              not N+1 happy nodes and just allocate on all other nodes without introducing new  N+1  violations.
              Note  that  this tends to overestimate the capacity, as instances still have to be moved away from
              the existing not N+1 happy nodes.

       --no-capacity-checks
              Normally, hspace will  only  consider  those  allocations  where  all  instances  of  a  node  can
              immediately  restarted  should that node fail.  With this option given, hspace will check only N+1
              redundancy for DRBD instances.

       -l <u>rounds</u>, --max-length=*rounds*
              Restrict the number of instance allocations to this length.  This is not very useful in  practice,
              but can be used for testing hspace itself, or to limit the runtime for very big clusters.

       -p, --print-nodes
              Prints  the before and after node status, in a format designed to allow the user to understand the
              node's most important parameters.  See the man page <b><a href="../man1/htools.1.html">htools</a></b>(1) for more details about this option.

       -O <u>name</u>
              This option (which can be given multiple times) will mark nodes as being <u>offline</u>.   This  means  a
              couple of things:

              • instances  won't  be placed on these nodes, not even temporarily; e.g.  the <u>replace</u> <u>primary</u> move
                is not available if the secondary node is offline, since this move requires a failover.

              • these nodes will not be included  in  the  score  calculation  (except  for  the  percentage  of
                instances on offline nodes)

              Note that the algorithm will also mark as offline any nodes which are reported by RAPI as such, or
              that have "?" in file-based input in any numeric fields.

       -S <u>filename</u>, --save-cluster=*filename*
              If  given,  the  state  of  the  cluster  at  the  end  of the allocation is saved to a file named
              <u>filename.alloc</u>, and if tiered allocation is enabled, the state after  tiered  allocation  will  be
              saved  to <u>filename.tiered</u>.  This allows re-feeding the cluster state to either hspace itself (with
              different parameters) or for example hbal, via the -t option.

       -t <u>datafile</u>, --text-data=*datafile*
              Backend specification: the name of  the  file  holding  node  and  instance  information  (if  not
              collecting  via RAPI or LUXI).  This or one of the other backends must be selected.  The option is
              described in the man page <b><a href="../man1/htools.1.html">htools</a></b>(1).

       -m <u>cluster</u>
              Backend specification: collect data directly from the <u>cluster</u> given as an argument via RAPI.   The
              option is described in the man page <b><a href="../man1/htools.1.html">htools</a></b>(1).

       -L [<u>path</u>]
              Backend  specification: collect data directly from the master daemon, which is to be contacted via
              LUXI (an internal Ganeti protocol).  The option is described in the man page <b><a href="../man1/htools.1.html">htools</a></b>(1).

       --simulate <u>description</u>
              Backend specification: similar to the <b>-t</b> option, this allows overriding the cluster  data  with  a
              simulated cluster.  For details about the description, see the man page <b><a href="../man1/htools.1.html">htools</a></b>(1).

       --standard-alloc <u>disk,ram,cpu</u>
              This  option  overrides  the instance size read from the cluster for the <u>standard</u> allocation mode,
              where we simply allocate instances of the same, fixed size until the cluster runs out of space.

              The specification given is similar to the <u>--simulate</u> option and it holds:

              • the disk size of the instance (units can be used)

              • the memory size of the instance (units can be used)

              • the vcpu count for the instance

              An example description would be <u>100G,4g,2</u> describing an instance specification of  100GB  of  disk
              space, 4GiB of memory and 2 VCPUs.

       --tiered-alloc <u>disk,ram,cpu</u>
              This  option  overrides  the  instance  size  for  the  <u>tiered</u> allocation mode.  In this mode, the
              algorithm starts from the given specification and allocates until there is no more space; then  it
              decreases  the  specification  and tries the allocation again.  The decrease is done on the metric
              that  last  failed  during  allocation.   The  argument  should  have  the  same  format  as   for
              --standard-alloc.

              Also  note  that  the  normal allocation and the tiered allocation are independent, and both start
              from the initial cluster state; as such, the instance count for these two modes  are  not  related
              one to another.

       --machine-readable[=*choice*]
              By  default, the output of the program is in "human-readable" format, i.e.  text descriptions.  By
              passing this  flag  you  can  either  enable  (--machine-readable  or  --machine-readable=yes)  or
              explicitly disable (--machine-readable=no) the machine readable format described above.

       -v, --verbose
              Increase  the  output verbosity.  Each usage of this option will increase the verbosity (currently
              more than 2 doesn't make sense) from the default of one.

       -q, --quiet
              Decrease the output verbosity.  Each usage of this option will decrease the verbosity  (less  than
              zero doesn't make sense) from the default of one.

       -V, --version
              Just show the program version and exit.

   <b>UNITS</b>
       By  default,  all  unit-accepting  options use mebibytes.  Using the lower-case letters of <u>m</u>, <u>g</u> and <u>t</u> (or
       their longer equivalents of <u>mib</u>, <u>gib</u>, <u>tib</u>, for which case doesn't matter) explicit binary  units  can  be
       selected.   Units  in  the SI system can be selected using the upper-case letters of <u>M</u>, <u>G</u> and <u>T</u> (or their
       longer equivalents of <u>MB</u>, <u>GB</u>, <u>TB</u>, for which case doesn't matter).

       More details about the difference between the SI and binary systems can be read in the <b><a href="../man7/units.7.html">units</a></b>(7) man page.

</pre><h4><b>EXIT</b> <b>STATUS</b></h4><pre>
       The exist status of the command will be zero, unless for some reason the algorithm fatally  failed  (e.g.
       wrong node or instance data).

</pre><h4><b>BUGS</b></h4><pre>
       The  algorithm  is  highly  dependent  on  the number of nodes; its runtime grows exponentially with this
       number, and as such is impractical for really big clusters.

       The algorithm doesn't rebalance the cluster or try to get the optimal fit; it just allocates in the  best
       place for the current step, without taking into consideration the impact on future placements.

</pre><h4><b>REPORTING</b> <b>BUGS</b></h4><pre>
       Report bugs to the project's issue tracker or contact the developers using the Ganeti mailing list.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       Ganeti  overview  and  specifications:  <b><a href="../man7/ganeti.7.html">ganeti</a></b>(7)  (general  overview),  <b><a href="../man7/ganeti-os-interface.7.html">ganeti-os-interface</a></b>(7) (guest OS
       definitions), <b><a href="../man7/ganeti-extstorage-interface.7.html">ganeti-extstorage-interface</a></b>(7) (external storage providers).

       Ganeti commands: <b><a href="../man8/gnt-cluster.8.html">gnt-cluster</a></b>(8) (cluster-wide commands), <b><a href="../man8/gnt-job.8.html">gnt-job</a></b>(8) (job-related  commands),  <b><a href="../man8/gnt-node.8.html">gnt-node</a></b>(8)
       (node-related   commands),   <b><a href="../man8/gnt-instance.8.html">gnt-instance</a></b>(8)   (instance   commands),   <b><a href="../man8/gnt-os.8.html">gnt-os</a></b>(8)  (guest  OS  commands),
       <b><a href="../man8/gnt-storage.8.html">gnt-storage</a></b>(8)  (storage  commands),  <b><a href="../man8/gnt-group.8.html">gnt-group</a></b>(8)  (node  group   commands),   <b><a href="../man8/gnt-backup.8.html">gnt-backup</a></b>(8)   (instance
       import/export commands), <b><a href="../man8/gnt-debug.8.html">gnt-debug</a></b>(8) (debug commands).

       Ganeti  daemons: <b><a href="../man8/ganeti-watcher.8.html">ganeti-watcher</a></b>(8) (automatic instance restarter), <b><a href="../man8/ganeti-cleaner.8.html">ganeti-cleaner</a></b>(8) (job queue cleaner),
       <b><a href="../man8/ganeti-noded.8.html">ganeti-noded</a></b>(8) (node daemon), <b><a href="../man8/ganeti-rapi.8.html">ganeti-rapi</a></b>(8) (remote API daemon).

       Ganeti htools: <b><a href="../man1/htools.1.html">htools</a></b>(1) (generic binary), <b><a href="../man1/hbal.1.html">hbal</a></b>(1) (cluster balancer), <b><a href="../man1/hspace.1.html">hspace</a></b>(1) (capacity  calculation),
       <b><a href="../man1/hail.1.html">hail</a></b>(1) (IAllocator plugin), <b><a href="../man1/hscan.1.html">hscan</a></b>(1) (data gatherer from remote clusters), <b><a href="../man1/hinfo.1.html">hinfo</a></b>(1) (cluster information
       printer), <b><a href="../man7/mon-collector.7.html">mon-collector</a></b>(7) (data collectors interface).

</pre><h4><b>COPYRIGHT</b></h4><pre>
       Copyright (C) 2006-2015 Google Inc.  All rights reserved.

       Redistribution  and  use in source and binary forms, with or without modification, are permitted provided
       that the following conditions are met:

       1.  Redistributions of source code must retain the above copyright notice, this list  of  conditions  and
       the following disclaimer.

       2.  Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
       the following disclaimer in the documentation and/or other materials provided with the distribution.

       THIS  SOFTWARE  IS  PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED
       WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND  FITNESS  FOR  A
       PARTICULAR  PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
       ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,  EXEMPLARY,  OR  CONSEQUENTIAL  DAMAGES  (INCLUDING,  BUT  NOT
       LIMITED  TO,  PROCUREMENT  OF  SUBSTITUTE  GOODS  OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
       INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,  STRICT  LIABILITY,  OR
       TORT  (INCLUDING  NEGLIGENCE  OR  OTHERWISE)  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
       ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Ganeti                                                                                                 <u><a href="../man1/HSPACE.1.html">HSPACE</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>