<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>sambamba-markdup - finding duplicate reads in BAM file</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/sambamba">sambamba_1.0.1+dfsg-2build1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>sambamba-markdup</b> - finding duplicate reads in BAM file

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>sambamba</b> <b>markdup</b> <u>OPTIONS</u> &lt;input.bam&gt; &lt;output.bam&gt;

</pre><h4><b>DESCRIPTION</b></h4><pre>
       Marks  (by default) or removes duplicate reads. For determining whether a read is a duplicate or not, the
       same     `sum      of      base      qualitiesÂ´      method      is      used      as      in      Picard
       <u>https://broadinstitute.github.io/picard/picard-metric-definitions.html</u>.

</pre><h4><b>OPTIONS</b></h4><pre>
       <b>-r</b>, <b>--remove-duplicates</b>
              remove duplicates instead of just marking them

       <b>-t</b>, <b>--nthreads</b>=<u>NTHREADS</u>
              number of threads to use

       <b>-l</b>, <b>--compression-level</b>=<u>N</u>
              specify compression level of the resulting file (from 0 to 9)");

       <b>-p</b>, <b>--show-progress</b>
              show progressbar in STDERR

       <b>--tmpdir</b>=<u>TMPDIR</u>
              specify directory for temporary files; default is <b><a href="file:/tmp">/tmp</a></b>

       <b>--hash-table-size</b>=<u>HASHTABLESIZE</u>
              size  of  hash table for finding read pairs (default is 262144 reads); will be rounded down to the
              nearest power of two; should be <b>&gt;</b> <b>(average</b> <b>coverage)</b> <b>*</b> <b>(insert</b> <b>size)</b> for good performance

       <b>--overflow-list-size</b>=<u>OVERFLOWLISTSIZE</u>
              size of the overflow list where reads, thrown away from the hash table, get  a  second  chance  to
              meet  their  pairs  (default is 200000 reads); increasing the size reduces the number of temporary
              files created

       <b>--io-buffer-size</b>=<u>BUFFERSIZE</u>
              controls sizes of two buffers of BUFFERSIZE <u>megabytes</u> each,  used  for  reading  and  writing  BAM
              during the second pass (default is 128)

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       Picard   <u>https://broadinstitute.github.io/picard/picard-metric-definitions.html</u>  metric  definitions  for
       removing duplicates.

</pre><h4><b>BUGS</b></h4><pre>
       External sort is not implemented. Thus, memory consumption grows by 2Gb per each 100M reads.  Check  that
       you have enough RAM before running the tool.

                                                  February 2015                              <u><a href="../man1/SAMBAMBA-MARKDUP.1.html">SAMBAMBA-MARKDUP</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>