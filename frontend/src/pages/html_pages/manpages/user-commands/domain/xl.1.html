<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>xl - Xen management tool, based on libxenlight</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/xen-utils-common">xen-utils-common_4.20.0+68-g35cb38b222-1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       xl - Xen management tool, based on libxenlight

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>xl</b> <u>subcommand</u> [<u>args</u>]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       The <b>xl</b> program is the new tool for managing Xen guest domains. The program can be used to create, pause,
       and shutdown domains. It can also be used to list current domains, enable or pin VCPUs, and attach or
       detach virtual block devices.

       The basic structure of every <b>xl</b> command is almost always:

         <b>xl</b> <u>subcommand</u> [<u>OPTIONS</u>] <u>domain-id</u>

       Where <u>subcommand</u> is one of the subcommands listed below, <u>domain-id</u> is the numeric domain id, or the
       domain name (which will be internally translated to domain id), and <u>OPTIONS</u> are subcommand specific
       options.  There are a few exceptions to this rule in the cases where the subcommand in question acts on
       all domains, the entire machine, or directly on the Xen hypervisor.  Those exceptions will be clear for
       each of those subcommands.

</pre><h4><b>NOTES</b></h4><pre>
       start the script <b>/etc/init.d/xencommons</b> at boot time
           Most   <b>xl</b>   operations  rely  upon  <b>xenstored</b>  and  <b>xenconsoled</b>:  make  sure  you  start  the  script
           <b>/etc/init.d/xencommons</b> at boot time to initialize all the daemons needed by <b>xl</b>.

       setup a <b>xenbr0</b> bridge in dom0
           In the most common network configuration, you need to setup a bridge in dom0 named <b>xenbr0</b> in order to
           have a working network in the guest domains.   Please  refer  to  the  documentation  of  your  Linux
           distribution to know how to setup the bridge.

       <b>autoballoon</b>
           If  you  specify  the amount of memory dom0 has, passing <b>dom0_mem</b> to Xen, it is highly recommended to
           disable <b>autoballoon</b>. Edit <b>/etc/xen/xl.conf</b> and set it to 0.

       run xl as <b>root</b>
           Most <b>xl</b> commands require root privileges to run due to the communications channels used  to  talk  to
           the hypervisor.  Running as non root will return an error.

</pre><h4><b>GLOBAL</b> <b>OPTIONS</b></h4><pre>
       Some global options are always available:

       <b>-v</b>  Verbose.

       <b>-N</b>  Dry run: do not actually execute the command.

       <b>-f</b>  Force  execution:  xl  will refuse to run some commands if it detects that xend is also running, this
           option will force the execution of those commands, even though it is unsafe.

       <b>-t</b>  Always use carriage-return-based overwriting for displaying progress messages without  scrolling  the
           screen.  Without -t, this is done only if stderr is a tty.

       <b>-T</b>  Include timestamps and pid of the xl process in output.

</pre><h4><b>DOMAIN</b> <b>SUBCOMMANDS</b></h4><pre>
       The  following subcommands manipulate domains directly.  As stated previously, most commands take <u>domain-</u>
       <u>id</u> as the first parameter.

       <b>button-press</b> <u>domain-id</u> <u>button</u>
           <u>This</u> <u>command</u> <u>is</u> <u>deprecated.</u> <u>Please</u> <u>use</u> <u>"xl</u> <u>trigger"</u> <u>instead.</u>

           Indicate an ACPI button press to the domain, where <u>button</u> can be 'power' or 'sleep'. This command  is
           only available for HVM domains.

       <b>create</b> [<u>configfile</u>] [<u>OPTIONS</u>]
           The  create  subcommand  takes a config file as its first argument: see <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) for full details of
           the file format and possible options.  If <u>configfile</u> is missing <b>xl</b> creates the  domain  assuming  the
           default values for every option.

           <u>configfile</u> has to be an absolute path to a file.

           Create  will  return <b>as</b> <b>soon</b> as the domain is started.  This <b>does</b> <b>not</b> mean the guest OS in the domain
           has actually booted, or is available for input.

           If the <u>-F</u> option is specified, create will start the domain and not return until its death.

           <b>OPTIONS</b>

           <b>-q</b>, <b>--quiet</b>
               No console output.

           <b>-f=FILE</b>, <b>--defconfig=FILE</b>
               Use the given configuration file.

           <b>-p</b>  Leave the domain paused after it is created.

           <b>-F</b>  Run in foreground until death of the domain.

           <b>-V</b>, <b>--vncviewer</b>
               Attach to domain's VNC server, forking a vncviewer process.

           <b>-A</b>, <b>--vncviewer-autopass</b>
               Pass the VNC password to vncviewer via stdin.

           <b>-c</b>  Attach console to the domain as soon as it has started.  This is useful  for  determining  issues
               with  crashing domains and just as a general convenience since you often want to watch the domain
               boot.

           <b>key=value</b>
               It is possible to pass <u>key=value</u> pairs on the command line to provide options  as  if  they  were
               written in the configuration file; these override whatever is in the <u>configfile</u>.

               NB:  Many  config  options require characters such as quotes or brackets which are interpreted by
               the shell (and often discarded) before being passed to xl, resulting in xl being unable to  parse
               the  value  correctly.   A  simple work-around is to put all extra options within a single set of
               quotes, separated by semicolons.  (See below for an example.)

           <b>EXAMPLES</b>

           <u>with</u> <u>extra</u> <u>parameters</u>
                 xl create hvm.cfg 'cpus="0-3"; pci=["01:05.1","01:05.2"]'

               This creates a domain with the file hvm.cfg, but additionally pins it to  cpus  0-3,  and  passes
               through two PCI devices.

       <b>config-update</b> <u>domain-id</u> [<u>configfile</u>] [<u>OPTIONS</u>]
           Update the saved configuration for a running domain. This has no immediate effect but will be applied
           when the guest is next restarted. This command is useful to ensure that runtime modifications made to
           the guest will be preserved when the guest is restarted.

           Since  Xen  4.5  xl has improved capabilities to handle dynamic domain configuration changes and will
           preserve any changes made at runtime when necessary. Therefore it should not normally be necessary to
           use this command any more.

           <u>configfile</u> has to be an absolute path to a file.

           <b>OPTIONS</b>

           <b>-f=FILE</b>, <b>--defconfig=FILE</b>
               Use the given configuration file.

           <b>key=value</b>
               It is possible to pass <u>key=value</u> pairs on the command line to provide options  as  if  they  were
               written  in the configuration file; these override whatever is in the <u>configfile</u>.  Please see the
               note under <u>create</u> on handling special characters when passing  <u>key=value</u>  pairs  on  the  command
               line.

       <b>console</b> [<u>OPTIONS</u>] <u>domain-id</u>
           Attach  to  the  console of a domain specified by <u>domain-id</u>.  If you've set up your domains to have a
           traditional login console this will look much like a normal text login screen.

           Use the escape character key combination (default Ctrl+]) to detach from the domain console.

           <b>OPTIONS</b>

           <u>-t</u> <u>[pv|serial]</u>
               Connect to a PV console or connect to an emulated serial  console.   PV  consoles  are  the  only
               consoles  available  for  PV  domains  while  HVM  domains  can  have both. If this option is not
               specified it defaults to emulated serial for HVM guests and PV console for PV guests.

           <u>-n</u> <u>NUM</u>
               Connect to console number <u>NUM</u>. Console numbers start from 0.

           <u>-e</u> <u>escapechar</u>
               Customize the escape sequence used to detach from  the  domain  console  to  <u>escapechar</u>.  If  not
               specified, the value "^]" is used.

       <b>destroy</b> [<u>OPTIONS</u>] <u>domain-id</u>
           Immediately  terminate the domain specified by <u>domain-id</u>.  This doesn't give the domain OS any chance
           to react, and is the equivalent of ripping the power cord out on a physical machine.  In  most  cases
           you will want to use the <b>shutdown</b> command instead.

           <b>OPTIONS</b>

           <u>-f</u>  Allow  domain  0  to be destroyed.  Because a domain cannot destroy itself, this is only possible
               when using a disaggregated toolstack, and is most useful when using a hardware  domain  separated
               from domain 0.

       <b>domid</b> <u>domain-name</u>
           Converts a domain name to a domain id.

       <b>domname</b> <u>domain-id</u>
           Converts a domain id to a domain name.

       <b>rename</b> <u>domain-id</u> <u>new-name</u>
           Change the domain name of a domain specified by <u>domain-id</u> to <u>new-name</u>.

       <b>dump-core</b> <u>domain-id</u> [<u>filename</u>]
           Dumps  the  virtual  machine's  memory  for  the  specified domain to the <u>filename</u> specified, without
           pausing the domain.  The dump file will be written to a  distribution  specific  directory  for  dump
           files, for example: /var/lib/xen/dump/dump.

       <b>help</b> [<u>--long</u>]
           Displays the short help message (i.e. common commands) by default.

           If  the  <u>--long</u>  option  is  specified,  it  displays  the complete set of <b>xl</b> subcommands, grouped by
           function.

       <b>list</b> [<u>OPTIONS</u>] [<u>domain-id</u> ...]
           Displays information about one or more domains.  If no domains are specified it displays  information
           about all domains.

           <b>OPTIONS</b>

           <b>-l</b>, <b>--long</b>
               The output for <b>xl</b> <b>list</b> is not the table view shown below, but instead presents the data as a JSON
               data structure.

           <b>-Z</b>, <b>--context</b>
               Also displays the security labels.

           <b>-v</b>, <b>--verbose</b>
               Also displays the domain UUIDs, the shutdown reason and security labels.

           <b>-c</b>, <b>--cpupool</b>
               Also displays the cpupool the domain belongs to.

           <b>-n</b>, <b>--numa</b>
               Also displays the domain NUMA node affinity.

           <b>EXAMPLE</b>

           An example format for the list is as follows:

               Name                                        ID   Mem VCPUs      State   Time(s)
               Domain-0                                     0   750     4     r-----   11794.3
               win                                          1  1019     1     r-----       0.3
               linux                                        2  2048     2     r-----    5624.2

           Name  is  the  name of the domain.  ID the numeric domain id.  Mem is the desired amount of memory to
           allocate to the domain (although it may not be the currently allocated amount).  VCPUs is the  number
           of  virtual CPUs allocated to the domain.  State is the run state (see below).  Time is the total run
           time of the domain as accounted for by Xen.

           <b>STATES</b>

           The State field lists 6 states for a Xen domain, and which ones the current domain is in.

           <b>r</b> <b>-</b> <b>running</b>
               The domain is currently running on a CPU.

           <b>b</b> <b>-</b> <b>blocked</b>
               The domain is blocked, and not running or runnable.  This can be because the domain is waiting on
               IO (a traditional wait state) or has gone to sleep because there was nothing else for it to do.

           <b>p</b> <b>-</b> <b>paused</b>
               The domain has been paused, usually occurring through the administrator running <b>xl</b>  <b>pause</b>.   When
               in  a  paused state the domain will still consume allocated resources (like memory), but will not
               be eligible for scheduling by the Xen hypervisor.

           <b>s</b> <b>-</b> <b>shutdown</b>
               The guest OS has shut down (SCHEDOP_shutdown has been called) but the domain is not dying yet.

           <b>c</b> <b>-</b> <b>crashed</b>
               The domain has crashed, which is always a violent ending.  Usually this state only occurs if  the
               domain has been configured not to restart on a crash.  See <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) for more info.

           <b>d</b> <b>-</b> <b>dying</b>
               The domain is in the process of dying, but hasn't completely shut down or crashed.

           <b>NOTES</b>

               The  Time  column  is  deceptive.   Virtual  IO  (network  and block devices) used by the domains
               requires coordination by Domain0, which means that Domain0 is actually charged for  much  of  the
               time  that  a  DomainU is doing IO.  Use of this time value to determine relative utilizations by
               domains is thus very unreliable, as a high IO workload may show as less utilized than a high  CPU
               workload.  Consider yourself warned.

       <b>mem-set</b> <u>domain-id</u> <u>mem</u>
           Set the target for the domain's balloon driver.

           The  default  unit is kiB.  Add 't' for TiB, 'g' for GiB, 'm' for MiB, 'k' for kiB, and 'b' for bytes
           (e.g., `2048m` for 2048 MiB).

           This must be less than the initial <b>maxmem</b> parameter in the domain's configuration.

           Note that this operation requests the guest operating system's balloon driver  to  reach  the  target
           amount  of  memory.   The  guest  may  fail to reach that amount of memory for any number of reasons,
           including:

           •   The guest doesn't have a balloon driver installed

           •   The guest's balloon driver is buggy

           •   The guest's balloon driver cannot create free guest memory due to guest memory pressure

           •   The guest's balloon driver cannot allocate memory from Xen because of hypervisor memory pressure

           •   The guest administrator has disabled the balloon driver

           <b>Warning:</b> There is no good way to know in advance how small of a mem-set will make a  domain  unstable
           and cause it to crash.  Be very careful when using this command on running domains.

       <b>mem-max</b> <u>domain-id</u> <u>mem</u>
           Specify the limit Xen will place on the amount of memory a guest may allocate.

           The  default  unit is kiB.  Add 't' for TiB, 'g' for GiB, 'm' for MiB, 'k' for kiB, and 'b' for bytes
           (e.g., `2048m` for 2048 MiB).

           <u>mem</u> can't be set lower than the current memory target for <u>domain-id</u>.  It is allowed to be higher than
           the configured maximum memory size of the domain (<b>maxmem</b> parameter in the domain's configuration).

           Setting the maximum memory size above the configured maximum memory size will require  special  guest
           support (memory hotplug) in order to be usable by the guest.

           The domain will not receive any signal regarding the changed memory limit.

       <b>migrate</b> [<u>OPTIONS</u>] <u>domain-id</u> <u>host</u>
           Migrate  a  domain  to  another  host  machine.  By default <b>xl</b> relies on ssh as a transport mechanism
           between the two hosts.

           <b>OPTIONS</b>

           <b>-s</b> <u>sshcommand</u>
               Use &lt;sshcommand&gt; instead of ssh.  String will be passed to sh. If empty, run  &lt;host&gt;  instead  of
               ssh &lt;host&gt; xl migrate-receive [-d -e].

           <b>-e</b>  On  the  new  &lt;host&gt;,  do  not  wait  in  the  background  for  the  death of the domain. See the
               corresponding option of the <u>create</u> subcommand.

           <b>-C</b> <u>config</u>
               Send the specified &lt;config&gt; file instead of the file used on creation of the domain.

           <b>--debug</b>
               Display huge (!) amount of debug information during the migration process.

           <b>-p</b>  Leave the domain on the receive side paused after migration.

           <b>-D</b>  Preserve the <b>domain-id</b> in the domain coniguration that  is  transferred  such  that  it  will  be
               identical  on  the destination host, unless that configuration is overridden using the <b>-C</b> option.
               Note that it is not possible to use this option for a 'localhost' migration.

       <b>remus</b> [<u>OPTIONS</u>] <u>domain-id</u> <u>host</u>
           Enable Remus HA or COLO HA for domain. By default <b>xl</b> relies on ssh as a transport  mechanism  between
           the two hosts.

           <b>NOTES</b>

               Remus  support in xl is still in experimental (proof-of-concept) phase.  Disk replication support
               is limited to DRBD disks.

               COLO support in xl is still in experimental (proof-of-concept) phase. All options are subject  to
               change in the future.

           COLO disk configuration looks like:

             disk = ['...,colo,colo-host=xxx,colo-port=xxx,colo-export=xxx,active-disk=xxx,hidden-disk=xxx...']

           The supported options are:

           <b>colo-host</b>   : Secondary host's ip address.
           <b>colo-port</b>   : Secondary host's port, we will run a nbd server on the secondary host, and the nbd
           server will listen on this port.
           <b>colo-export</b> : Nbd server's disk export name of the secondary host.
           <b>active-disk</b> : Secondary's guest write will be buffered to this disk, and it's used by the secondary.
           <b>hidden-disk</b> : Primary's modified contents will be buffered in this disk, and it's used by the
           secondary.

           COLO network configuration looks like:

             vif = [ '...,forwarddev=xxx,...']

           The supported options are:

           <b>forwarddev</b> : Forward devices for the primary and the secondary, they are directly connected.

           <b>OPTIONS</b>

           <b>-i</b> <u>MS</u>
               Checkpoint domain memory every MS milliseconds (default 200ms).

           <b>-u</b>  Disable memory checkpoint compression.

           <b>-s</b> <u>sshcommand</u>
               Use  &lt;sshcommand&gt;  instead of ssh.  String will be passed to sh.  If empty, run &lt;host&gt; instead of
               ssh &lt;host&gt; xl migrate-receive -r [-e].

           <b>-e</b>  On the new &lt;host&gt;, do not wait  in  the  background  for  the  death  of  the  domain.   See  the
               corresponding option of the <u>create</u> subcommand.

           <b>-N</b> <u>netbufscript</u>
               Use    &lt;netbufscript&gt;    to   setup   network   buffering   instead   of   the   default   script
               (/etc/xen/scripts/remus-netbuf-setup).

           <b>-F</b>  Run Remus in unsafe mode. Use this option with caution as failover may not work as intended.

           <b>-b</b>  Replicate memory checkpoints to /dev/null (blackhole).  Generally useful for debugging.  Requires
               enabling unsafe mode.

           <b>-n</b>  Disable network output buffering. Requires enabling unsafe mode.

           <b>-d</b>  Disable disk replication. Requires enabling unsafe mode.

           <b>-c</b>  Enable  COLO  HA.  This  conflicts  with  <b>-i</b>  and  <b>-b</b>,  and memory checkpoint compression must be
               disabled.

           <b>-p</b>  Use userspace COLO Proxy. This option must be used in conjunction with <b>-c</b>.

       <b>pause</b> <u>domain-id</u>
           Pause a domain.  When in a paused state the domain will still consume allocated  resources  (such  as
           memory), but will not be eligible for scheduling by the Xen hypervisor.

       <b>reboot</b> [<u>OPTIONS</u>] <u>domain-id</u>
           Reboot  a  domain.  This acts just as if the domain had the <b>reboot</b> command run from the console.  The
           command returns as soon as it has executed the reboot action, which may be significantly earlier than
           when the domain actually reboots.

           For HVM domains this requires PV drivers to be installed in your guest OS.  If  PV  drivers  are  not
           present  but  you  have configured the guest OS to behave appropriately you may be able to use the <u>-F</u>
           option to trigger a reset button press.

           The behavior of what happens to a domain when it reboots is set by the  <b>on_reboot</b>  parameter  of  the
           domain configuration file when the domain was created.

           <b>OPTIONS</b>

           <b>-F</b>  If  the  guest  does  not  support PV reboot control then fallback to sending an ACPI power event
               (equivalent to the <u>reset</u> option to <u>trigger</u>).

               You should ensure that the guest is configured to behave as expected in response to this event.

       <b>restore</b> [<u>OPTIONS</u>] [<u>configfile</u>] <u>checkpointfile</u>
           Build a domain from an <b>xl</b> <b>save</b> state file.  See <b>save</b> for more info.

           <b>OPTIONS</b>

           <b>-p</b>  Do not unpause the domain after restoring it.

           <b>-e</b>  Do not wait in the background for the death of the domain on the new host.  See the corresponding
               option of the <u>create</u> subcommand.

           <b>-d</b>  Enable debug messages.

           <b>-V</b>, <b>--vncviewer</b>
               Attach to the domain's VNC server, forking a vncviewer process.

           <b>-A</b>, <b>--vncviewer-autopass</b>
               Pass the VNC password to vncviewer via stdin.

       <b>resume</b> <u>domain-id</u>
           Resume a domain, after having been suspended.

       <b>save</b> [<u>OPTIONS</u>] <u>domain-id</u> <u>checkpointfile</u> [<u>configfile</u>]
           Saves a running domain to a state file so that it can be restored later.  Once saved, the domain will
           no longer be running on the system, unless the -c or -p options are used.  <b>xl</b> <b>restore</b>  restores  from
           this  checkpoint  file.   Passing  a  config  file argument allows the user to manually select the VM
           config file used to create the domain.

           <b>-c</b>  Leave the domain running after creating the snapshot.

           <b>-p</b>  Leave the domain paused after creating the snapshot.

           <b>-D</b>  Preserve the <b>domain-id</b> in the domain coniguration that is embedded in the state file such that it
               will be identical when the domain is restored, unless that configuration is overridden. (See  the
               <b>restore</b> operation above).

       <b>sharing</b> [<u>domain-id</u>]
           Display  the  number  of  shared  pages for a specified domain. If no domain is specified it displays
           information about all domains.

       <b>shutdown</b> [<u>OPTIONS</u>] <u>-a|domain-id</u>
           Gracefully shuts down a domain.  This coordinates with the domain OS to perform graceful shutdown, so
           there is no guarantee that it will succeed, and may take a variable length of time depending on  what
           services must be shut down in the domain.

           For  HVM  domains  this  requires  PV drivers to be installed in your guest OS. If PV drivers are not
           present but you have configured the guest OS to behave appropriately you may be able to  use  the  <u>-F</u>
           option to trigger a power button press.

           The command returns immediately after signaling the domain unless the <b>-w</b> flag is used.

           The  behavior  of what happens to a domain when it reboots is set by the <b>on_shutdown</b> parameter of the
           domain configuration file when the domain was created.

           <b>OPTIONS</b>

           <b>-a</b>, <b>--all</b>
               Shutdown all guest domains.  Often used when doing a complete shutdown of a Xen system.

           <b>-w</b>, <b>--wait</b>
               Wait for the domain to complete shutdown before returning.  If given once, the wait is for domain
               shutdown or domain death.  If given multiple times, the wait is for domain death only.

           <b>-F</b>  If the guest does not support PV shutdown control then fallback to sending an  ACPI  power  event
               (equivalent to the <u>power</u> option to <u>trigger</u>).

               You should ensure that the guest is configured to behave as expected in response to this event.

       <b>suspend</b> <u>domain-id</u>
           Suspend  a  domain.   This  is  a cooperative operation where the domain must respond to the xenstore
           trigger.  When in a suspended state the domain still consumes allocated resources (such  as  memory),
           but is not eligible for scheduling by the Xen hypervisor.  It is in a shutdown state, but not dying.

       <b>sysrq</b> <u>domain-id</u> <u>letter</u>
           Send  a  &lt;Magic  System  Request&gt;  to  the domain, each type of request is represented by a different
           letter.  It can be used to send SysRq requests to Linux guests, see sysrq.txt in  your  Linux  Kernel
           sources for more information.  It requires PV drivers to be installed in your guest OS.

       <b>trigger</b> <u>domain-id</u> <u>nmi|reset|init|power|sleep|s3resume</u> [<u>VCPU</u>]
           Send a trigger to a domain, where the trigger can be: nmi, reset, init, power or sleep.  Optionally a
           specific vcpu number can be passed as an argument.  This command is only available for HVM domains.

       <b>unpause</b> <u>domain-id</u>
           Moves  a  domain  out  of  the  paused  state.   This will allow a previously paused domain to now be
           eligible for scheduling by the Xen hypervisor.

       <b>vcpu-set</b> <u>domain-id</u> <u>vcpu-count</u>
           Enables the <u>vcpu-count</u> virtual CPUs for the domain in question.  Like mem-set, this command can  only
           allocate up to the maximum virtual CPU count configured at boot for the domain.

           If  the  <u>vcpu-count</u> is smaller than the current number of active VCPUs, the highest number VCPUs will
           be hotplug removed.  This may be important for pinning purposes.

           Attempting to set the VCPUs to a number larger than the initially configured VCPU count is an  error.
           Trying to set VCPUs to &lt; 1 will be quietly ignored.

           Some  guests  may  need  to  actually bring the newly added CPU online after <b>vcpu-set</b>, go to <b>SEE</b> <b>ALSO</b>
           section for information.

       <b>vcpu-list</b> [<u>domain-id</u>]
           Lists VCPU information for a specific domain.  If no domain is specified, VCPU  information  for  all
           domains will be provided.

       <b>vcpu-pin</b> [<u>-f|--force</u>] <u>domain-id</u> <u>vcpu</u> <u>cpus</u> <u>hard</u> <u>cpus</u> <u>soft</u>
           Set hard and soft affinity for a <u>vcpu</u> of &lt;domain-id&gt;. Normally VCPUs can float between available CPUs
           whenever Xen deems a different run state is appropriate.

           Hard  affinity  can  be  used  to  restrict  this,  by ensuring certain VCPUs can only run on certain
           physical CPUs. Soft affinity specifies a <u>preferred</u> set of CPUs. Soft affinity needs  special  support
           in the scheduler, which is only provided in credit1.

           The keyword <b>all</b> can be used to apply the hard and soft affinity masks to all the VCPUs in the domain.
           The symbol '-' can be used to leave either hard or soft affinity alone.

           For example:

            xl vcpu-pin 0 3 - 6-9

           will  set  soft  affinity  for  vCPU  3  of  domain 0 to pCPUs 6,7,8 and 9, leaving its hard affinity
           untouched. On the other hand:

            xl vcpu-pin 0 3 3,4 6-9

           will set both hard and soft affinity, the former to pCPUs 3 and 4, the latter to pCPUs 6,7,8, and 9.

           Specifying <u>-f</u> or <u>--force</u> will remove a temporary pinning done by the operating system (normally  this
           should  be  done  by  the  operating  system).   In case a temporary pinning is active for a vcpu the
           affinity of this vcpu can't be changed without this option.

       <b>vm-list</b>
           Prints information about guests. This list excludes information about service  or  auxiliary  domains
           such as dom0 and stubdoms.

           <b>EXAMPLE</b>

           An example format for the list is as follows:

               UUID                                  ID    name
               59e1cf6c-6ab9-4879-90e7-adc8d1c63bf5  2    win
               50bc8f75-81d0-4d53-b2e6-95cb44e2682e  3    linux

       <b>vncviewer</b> [<u>OPTIONS</u>] <u>domain-id</u>
           Attach to the domain's VNC server, forking a vncviewer process.

           <b>OPTIONS</b>

           <u>--autopass</u>
               Pass the VNC password to vncviewer via stdin.

</pre><h4><b>XEN</b> <b>HOST</b> <b>SUBCOMMANDS</b></h4><pre>
       <b>debug-keys</b> <u>keys</u>
           Send  debug  <u>keys</u>  to  Xen.  It is the same as pressing the Xen "conswitch" (Ctrl-A by default) three
           times and then pressing "keys".

       <b>set-parameters</b> <u>params</u>
           Set hypervisor parameters as specified in <u>params</u>.  This  allows  for  some  boot  parameters  of  the
           hypervisor to be modified in the running systems.

       <b>dmesg</b> [<u>OPTIONS</u>]
           Reads the Xen message buffer, similar to dmesg on a Linux system.  The buffer contains informational,
           warning,  and error messages created during Xen's boot process.  If you are having problems with Xen,
           this is one of the first places to look as part of problem determination.

           <b>OPTIONS</b>

           <b>-c</b>, <b>--clear</b>
               Clears Xen's message buffer.

       <b>info</b> [<u>OPTIONS</u>]
           Print information about the Xen host in <u>name</u> <u>:</u> <u>value</u>  format.   When  reporting  a  Xen  bug,  please
           provide       this      information      as      part      of      the      bug      report.      See
           <u>https://wiki.xenproject.org/wiki/Reporting_Bugs_against_Xen_Project</u> on how to report Xen bugs.

           Sample output looks as follows:

            host                   : scarlett
            release                : 3.1.0-rc4+
            version                : #1001 SMP Wed Oct 19 11:09:54 UTC 2011
            machine                : x86_64
            nr_cpus                : 4
            nr_nodes               : 1
            cores_per_socket       : 4
            threads_per_core       : 1
            cpu_mhz                : 2266
            hw_caps                : bfebfbff:28100800:00000000:00003b40:009ce3bd:00000000:00000001:00000000
            virt_caps              : hvm hvm_directio
            total_memory           : 6141
            free_memory            : 4274
            free_cpus              : 0
            outstanding_claims     : 0
            xen_major              : 4
            xen_minor              : 2
            xen_extra              : -unstable
            xen_caps               : xen-3.0-x86_64 xen-3.0-x86_32p hvm-3.0-x86_32 hvm-3.0-x86_32p hvm-3.0-x86_64
            xen_scheduler          : credit
            xen_pagesize           : 4096
            platform_params        : virt_start=0xffff800000000000
            xen_changeset          : Wed Nov 02 17:09:09 2011 +0000 24066:54a5e994a241
            xen_commandline        : com1=115200,8n1 guest_loglvl=all dom0_mem=750M console=com1
            cc_compiler            : gcc version 4.4.5 (Debian 4.4.5-8)
            cc_compile_by          : sstabellini
            cc_compile_domain      : uk.xensource.com
            cc_compile_date        : Tue Nov  8 12:03:05 UTC 2011
            xend_config_format     : 4

           <b>FIELDS</b>

           Not all fields will be explained here, but some of the less obvious ones deserve explanation:

           <b>hw_caps</b>
               A vector showing what hardware capabilities are supported by your processor.  This is  equivalent
               to,  though  more  cryptic, the flags field in <a href="file:/proc/cpuinfo">/proc/cpuinfo</a> on a normal Linux machine: they both
               derive from the feature bits returned by the cpuid command on x86 platforms.

           <b>free_memory</b>
               Available memory (in MB) not allocated to Xen, or any other domains, or claimed for domains.

           <b>outstanding_claims</b>
               When a claim call is done (see <b><a href="../man5/xl.conf.5.html">xl.conf</a></b>(5)) a reservation for a specific amount of  pages  is  set
               and also a global value is incremented. This global value (outstanding_claims) is then reduced as
               the  domain's memory is populated and eventually reaches zero. Most of the time the value will be
               zero, but if you are launching multiple  guests,  and  <b>claim_mode</b>  is  enabled,  this  value  can
               increase/decrease. Note that the value also affects the <b>free_memory</b> - as it will reflect the free
               memory  in  the  hypervisor  minus  the outstanding pages claimed for guests.  See xl <u>info</u> <b>claims</b>
               parameter for detailed listing.

           <b>xen_caps</b>
               The Xen version and architecture.  Architecture values can be one of: x86_32, x86_32p  (i.e.  PAE
               enabled), x86_64, ia64.

           <b>xen_changeset</b>
               The  Xen  mercurial  changeset id.  Very useful for determining exactly what version of code your
               Xen system was built from.

           <b>OPTIONS</b>

           <b>-n</b>, <b>--numa</b>
               List host NUMA topology information

       <b>top</b> Executes the <b><a href="../man1/xentop.1.html">xentop</a>(1)</b> command, which provides real time monitoring of domains.  Xentop has a  curses
           interface, and is reasonably self explanatory.

       <b>uptime</b>
           Prints the current uptime of the domains running.

       <b>claims</b>
           Prints  information  about outstanding claims by the guests. This provides the outstanding claims and
           currently populated memory  count  for  the  guests.   These  values  added  up  reflect  the  global
           outstanding  claim value, which is provided via the <u>info</u> argument, <b>outstanding_claims</b> value.  The <b>Mem</b>
           column has the cumulative value of outstanding claims and the total amount of memory  that  has  been
           right now allocated to the guest.

           <b>EXAMPLE</b>

           An example format for the list is as follows:

            Name                                        ID   Mem VCPUs      State   Time(s)  Claimed
            Domain-0                                     0  2047     4     r-----      19.7     0
            OL5                                          2  2048     1     --p---       0.0   847
            OL6                                          3  1024     4     r-----       5.9     0
            Windows_XP                                   4  2047     1     --p---       0.0  1989

           In which it can be seen that the OL5 guest still has 847MB of claimed memory (out of the total 2048MB
           where 1191MB has been allocated to the guest).

</pre><h4><b>SCHEDULER</b> <b>SUBCOMMANDS</b></h4><pre>
       Xen  ships with a number of domain schedulers, which can be set at boot time with the <b>sched=</b> parameter on
       the Xen command line.  By default <b>credit</b> is used for scheduling.

       <b>sched-credit</b> [<u>OPTIONS</u>]
           Set or get credit (aka credit1) scheduler parameters.  The credit scheduler is  a  proportional  fair
           share CPU scheduler built from the ground up to be work conserving on SMP hosts.

           Each domain (including Domain0) is assigned a weight and a cap.

           <b>OPTIONS</b>

           <b>-d</b> <b>DOMAIN</b>, <b>--domain=DOMAIN</b>
               Specify  domain  for  which  scheduler parameters are to be modified or retrieved.  Mandatory for
               modifying scheduler parameters.

           <b>-w</b> <b>WEIGHT</b>, <b>--weight=WEIGHT</b>
               A domain with a weight of 512 will get twice as much CPU as a domain with a weight of  256  on  a
               contended host. Legal weights range from 1 to 65535 and the default is 256.

           <b>-c</b> <b>CAP</b>, <b>--cap=CAP</b>
               The  cap optionally fixes the maximum amount of CPU a domain will be able to consume, even if the
               host system has idle CPU cycles. The cap is expressed in percentage of one physical CPU: 100 is 1
               physical CPU, 50 is half a CPU, 400 is 4 CPUs, etc. The default, 0, means there is no upper cap.

               NB: Many systems have features that will scale down the computing power of a cpu that is not 100%
               utilized.  This can be in the operating system, but can also sometimes  be  below  the  operating
               system  in  the BIOS.  If you set a cap such that individual cores are running at less than 100%,
               this may have an impact on the performance of your workload over and above the impact of the cap.
               For example, if your processor runs at 2GHz, and you cap a vm at 50%, the power management system
               may also reduce the clock speed to 1GHz; the effect  will  be  that  your  VM  gets  25%  of  the
               available  power  (50%  of  1GHz)  rather  than  50%  (50%  of 2GHz).  If you are not getting the
               performance you expect, look at performance and cpufreq options in your operating system and your
               BIOS.

           <b>-p</b> <b>CPUPOOL</b>, <b>--cpupool=CPUPOOL</b>
               Restrict output to domains in the specified cpupool.

           <b>-s</b>, <b>--schedparam</b>
               Specify to list or set pool-wide scheduler parameters.

           <b>-t</b> <b>TSLICE</b>, <b>--tslice_ms=TSLICE</b>
               Timeslice tells the scheduler how long to allow VMs to run before pre-empting.   The  default  is
               30ms.   Valid  ranges are 1ms to 1000ms.  The length of the timeslice (in ms) must be higher than
               the length of the ratelimit (see below).

           <b>-r</b> <b>RLIMIT</b>, <b>--ratelimit_us=RLIMIT</b>
               Ratelimit attempts to limit the number of schedules per second.  It sets a minimum amount of time
               (in microseconds) a VM must run before we will allow a higher-priority VM to  pre-empt  it.   The
               default  value  is 1000 microseconds (1ms).  Valid range is 100 to 500000 (500ms).  The ratelimit
               length must be lower than the timeslice length.

           <b>-m</b> <b>DELAY</b>, <b>--migration_delay_us=DELAY</b>
               Migration delay specifies for how long a vCPU, after it  stopped  running  should  be  considered
               "cache-hot".  Basically, if less than DELAY us passed since when the vCPU was executing on a CPU,
               it is likely that most of the vCPU's working set is still in the CPU's cache, and  therefore  the
               vCPU is not migrated.

               Default  is  0. Maximum is 100 ms. This can be effective at preventing vCPUs to bounce among CPUs
               too quickly, but, at the same time, the scheduler stops being fully work-conserving.

           <b>COMBINATION</b>

           The following is the effect of combining the above options:

           <b>&lt;nothing&gt;</b>             : List all domain params and sched params from all pools
           <b>-d</b> <b>[domid]</b>            : List domain params for domain [domid]
           <b>-d</b> <b>[domid]</b> <b>[params]</b>   : Set domain params for domain [domid]
           <b>-p</b> <b>[pool]</b>             : list all domains and sched params for [pool]
           <b>-s</b>                    : List sched params for poolid 0
           <b>-s</b> <b>[params]</b>           : Set sched params for poolid 0
           <b>-p</b> <b>[pool]</b> <b>-s</b>          : List sched params for [pool]
           <b>-p</b> <b>[pool]</b> <b>-s</b> <b>[params]</b> : Set sched params for [pool]
           <b>-p</b> <b>[pool]</b> <b>-d</b>...       : Illegal
       <b>sched-credit2</b> [<u>OPTIONS</u>]
           Set or get credit2 scheduler parameters.  The credit2 scheduler is  a  proportional  fair  share  CPU
           scheduler built from the ground up to be work conserving on SMP hosts.

           Each domain (including Domain0) is assigned a weight.

           <b>OPTIONS</b>

           <b>-d</b> <b>DOMAIN</b>, <b>--domain=DOMAIN</b>
               Specify  domain  for  which  scheduler parameters are to be modified or retrieved.  Mandatory for
               modifying scheduler parameters.

           <b>-w</b> <b>WEIGHT</b>, <b>--weight=WEIGHT</b>
               A domain with a weight of 512 will get twice as much CPU as a domain with a weight of  256  on  a
               contended host. Legal weights range from 1 to 65535 and the default is 256.

           <b>-p</b> <b>CPUPOOL</b>, <b>--cpupool=CPUPOOL</b>
               Restrict output to domains in the specified cpupool.

           <b>-s</b>, <b>--schedparam</b>
               Specify to list or set pool-wide scheduler parameters.

           <b>-r</b> <b>RLIMIT</b>, <b>--ratelimit_us=RLIMIT</b>
               Attempts  to  limit  the rate of context switching. It is basically the same as <b>--ratelimit_us</b> in
               <b>sched-credit</b>

       <b>sched-rtds</b> [<u>OPTIONS</u>]
           Set or get rtds (Real Time Deferrable  Server)  scheduler  parameters.   This  rt  scheduler  applies
           Preemptive  Global  Earliest  Deadline  First real-time scheduling algorithm to schedule VCPUs in the
           system.  Each VCPU has a dedicated period, budget and extratime.  While scheduled, a VCPU  burns  its
           budget.   A  VCPU  has  its  budget  replenished  at  the  beginning of each period; Unused budget is
           discarded at the end of each period.  A VCPU with extratime set gets extra time from  the  unreserved
           system resource.

           <b>OPTIONS</b>

           <b>-d</b> <b>DOMAIN</b>, <b>--domain=DOMAIN</b>
               Specify  domain  for  which  scheduler parameters are to be modified or retrieved.  Mandatory for
               modifying scheduler parameters.

           <b>-v</b> <b>VCPUID/all</b>, <b>--vcpuid=VCPUID/all</b>
               Specify vcpu for which scheduler parameters are to be modified or retrieved.

           <b>-p</b> <b>PERIOD</b>, <b>--period=PERIOD</b>
               Period of time, in microseconds, over which to replenish the budget.

           <b>-b</b> <b>BUDGET</b>, <b>--budget=BUDGET</b>
               Amount of time, in microseconds, that the VCPU will be allowed to run every period.

           <b>-e</b> <b>Extratime</b>, <b>--extratime=Extratime</b>
               Binary flag to decide if the VCPU will be allowed to get extra time from  the  unreserved  system
               resource.

           <b>-c</b> <b>CPUPOOL</b>, <b>--cpupool=CPUPOOL</b>
               Restrict output to domains in the specified cpupool.

           <b>EXAMPLE</b>

               1) Use <b>-v</b> <b>all</b> to see the budget and period of all the VCPUs of all the domains:

                   xl sched-rtds -v all
                   Cpupool Pool-0: sched=RTDS
                   Name                        ID VCPU    Period    Budget  Extratime
                   Domain-0                     0    0     10000      4000        yes
                   vm1                          2    0       300       150        yes
                   vm1                          2    1       400       200        yes
                   vm1                          2    2     10000      4000        yes
                   vm1                          2    3      1000       500        yes
                   vm2                          4    0     10000      4000        yes
                   vm2                          4    1     10000      4000        yes

               Without any arguments, it will output the default scheduling parameters for each domain:

                   xl sched-rtds
                   Cpupool Pool-0: sched=RTDS
                   Name                        ID    Period    Budget  Extratime
                   Domain-0                     0     10000      4000        yes
                   vm1                          2     10000      4000        yes
                   vm2                          4     10000      4000        yes

               2)  Use,  for  instance,  <b>-d</b>  <b>vm1,</b> <b>-v</b> <b>all</b> to see the budget and period of all VCPUs of a specific
               domain (<b>vm1</b>):

                   xl sched-rtds -d vm1 -v all
                   Name                        ID VCPU    Period    Budget  Extratime
                   vm1                          2    0       300       150        yes
                   vm1                          2    1       400       200        yes
                   vm1                          2    2     10000      4000        yes
                   vm1                          2    3      1000       500        yes

               To see the parameters of a subset of the VCPUs of a domain, use:

                   xl sched-rtds -d vm1 -v 0 -v 3
                   Name                        ID VCPU    Period    Budget  Extratime
                   vm1                          2    0       300       150        yes
                   vm1                          2    3      1000       500        yes

               If no <b>-v</b> is specified, the default scheduling parameters for the domain are shown:

                   xl sched-rtds -d vm1
                   Name                        ID    Period    Budget  Extratime
                   vm1                          2     10000      4000        yes

               3) Users can set the budget and period of multiple VCPUs of  a  specific  domain  with  only  one
               command, e.g., "xl sched-rtds -d vm1 -v 0 -p 100 -b 50 -e 1 -v 3 -p 300 -b 150 -e 0".

               To change the parameters of all the VCPUs of a domain, use <b>-v</b> <b>all</b>, e.g., "xl sched-rtds -d vm1 -v
               all -p 500 -b 250 -e 1".

</pre><h4><b>CPUPOOLS</b> <b>COMMANDS</b></h4><pre>
       Xen  can  group  the physical cpus of a server in cpu-pools. Each physical CPU is assigned at most to one
       cpu-pool. Domains are  each  restricted  to  a  single  cpu-pool.  Scheduling  does  not  cross  cpu-pool
       boundaries, so each cpu-pool has its own scheduler.  Physical cpus and domains can be moved from one cpu-
       pool to another only by an explicit command.  Cpu-pools can be specified either by name or by id.

       <b>cpupool-create</b> [<u>OPTIONS</u>] [<u>configfile</u>] [<u>variable=value</u> ...]
           Create  a  cpu  pool based an config from a <u>configfile</u> or command-line parameters.  Variable settings
           from the <u>configfile</u> may be altered by specifying new or additional assignments on the command line.

           See the <b><a href="../man5/xlcpupool.cfg.5.html">xlcpupool.cfg</a></b>(5) manpage for more information.

           <b>OPTIONS</b>

           <b>-f=FILE</b>, <b>--defconfig=FILE</b>
               Use the given configuration file.

       <b>cpupool-list</b> [<u>OPTIONS</u>] [<u>cpu-pool</u>]
           List CPU pools on the host.

           <b>OPTIONS</b>

           <b>-c</b>, <b>--cpus</b>
               If this option is specified, <b>xl</b> prints a list of CPUs used by <u>cpu-pool</u>.

       <b>cpupool-destroy</b> <u>cpu-pool</u>
           Deactivates a cpu pool.  This is possible only if no domain is active in the cpu-pool.

       <b>cpupool-rename</b> <u>cpu-pool</u> &lt;newname&gt;
           Renames a cpu-pool to <u>newname</u>.

       <b>cpupool-cpu-add</b> <u>cpu-pool</u> <u>cpus|node:nodes</u>
           Adds one or more CPUs or NUMA nodes to <u>cpu-pool</u>. CPUs and NUMA  nodes  can  be  specified  as  single
           CPU/node IDs or as ranges.

           For example:

            (a) xl cpupool-cpu-add mypool 4
            (b) xl cpupool-cpu-add mypool 1,5,10-16,^13
            (c) xl cpupool-cpu-add mypool node:0,nodes:2-3,^10-12,8

           means  adding  CPU 4 to mypool, in (a); adding CPUs 1,5,10,11,12,14,15 and 16, in (b); and adding all
           the CPUs of NUMA nodes 0, 2 and 3, plus CPU 8, but keeping out CPUs 10,11,12, in (c).

           All the specified CPUs that can be added to the cpupool will be added to it. If some CPU can't (e.g.,
           because they're already part of another cpupool), an error is reported about each one of them.

       <b>cpupool-cpu-remove</b> <u>cpu-pool</u> <u>cpus|node:nodes</u>
           Removes one or more CPUs or NUMA nodes from <u>cpu-pool</u>. CPUs and NUMA nodes can be specified as  single
           CPU/node IDs or as ranges, using the exact same syntax as in <b>cpupool-cpu-add</b> above.

       <b>cpupool-migrate</b> <u>domain-id</u> <u>cpu-pool</u>
           Moves  a  domain  specified  by domain-id or domain-name into a cpu-pool.  Domain-0 can't be moved to
           another cpu-pool.

       <b>cpupool-numa-split</b>
           Splits up the machine into one cpu-pool per numa node.

</pre><h4><b>VIRTUAL</b> <b>DEVICE</b> <b>COMMANDS</b></h4><pre>
       Most virtual devices can be added and removed while guests  are  running,  assuming  that  the  necessary
       support exists in the guest OS.  The effect to the guest OS is much the same as any hotplug event.

   <b>BLOCK</b> <b>DEVICES</b>
       <b>block-attach</b> <u>domain-id</u> <u>disc-spec-component(s)</u> ...
           Create  a new virtual block device and attach it to the specified domain.  A disc specification is in
           the same format used for the <b>disk</b> variable in the domain config file.  See  <b><a href="../man5/xl-disk-configuration.5.html">xl-disk-configuration</a></b>(5).
           This will trigger a hotplug event for the guest.

           Note  that  only PV block devices are supported by block-attach.  Requests to attach emulated devices
           (eg, vdev=hdc) will result in only the PV view being available to the guest.

       <b>block-detach</b> [<u>OPTIONS</u>] <u>domain-id</u> <u>devid</u>
           Detach a domain's virtual block device. <u>devid</u> may be the symbolic name or the numeric device id given
           to the device by domain 0.  You will need to run <b>xl</b> <b>block-list</b> to determine that number.

           Detaching the device requires the cooperation of the domain.  If the  domain  fails  to  release  the
           device (perhaps because the domain is hung or is still using the device), the detach will fail.

           <b>OPTIONS</b>

           <b>--force</b>
               If  this parameter is specified the device will be forcefully detached, which may cause IO errors
               in the domain and possibly a guest crash

       <b>block-list</b> <u>domain-id</u>
           List virtual block devices for a domain.

       <b>cd-insert</b> <u>domain-id</u> <u>virtualdevice</u> <u>target</u>
           Insert a cdrom into a guest domain's existing virtual cd drive. The virtual drive must already  exist
           but  can  be  empty.  How  the  device  should  be  presented to the guest domain is specified by the
           <u>virtualdevice</u> parameter; for example "hdc". Parameter <u>target</u> is the target path in the backend domain
           (usually domain 0)  to  be  exported;  can  be  a  block  device  or  a  file  etc.   See  <b>target</b>  in
           <b><a href="../man5/xl-disk-configuration.5.html">xl-disk-configuration</a></b>(5).

           Only works with HVM domains.

       <b>cd-eject</b> <u>domain-id</u> <u>virtualdevice</u>
           Eject a cdrom from a guest domain's virtual cd drive, specified by <u>virtualdevice</u>. Only works with HVM
           domains.

   <b>NETWORK</b> <b>DEVICES</b>
       <b>network-attach</b> <u>domain-id</u> <u>network-device</u>
           Creates  a  new  network  device  in the domain specified by <u>domain-id</u>.  <u>network-device</u> describes the
           device to attach, using the same format as the <b>vif</b> string in the domain config  file.  See  <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5)
           and <b><a href="../man5/xl-network-configuration.5.html">xl-network-configuration</a></b>(5) for more information.

           Note that only attaching PV network interfaces is supported.

       <b>network-detach</b> <u>domain-id</u> <u>devid|mac</u>
           Removes  the  network  device from the domain specified by <u>domain-id</u>.  <u>devid</u> is the virtual interface
           device number within the domain (i.e. the 3 in vif22.3). Alternatively, the <u>mac</u> address can  be  used
           to select the virtual interface to detach.

       <b>network-list</b> <u>domain-id</u>
           List virtual network interfaces for a domain.

   <b>CHANNEL</b> <b>DEVICES</b>
       <b>channel-list</b> <u>domain-id</u>
           List virtual channel interfaces for a domain.

   <b>VIRTUAL</b> <b>TRUSTED</b> <b>PLATFORM</b> <b>MODULE</b> <b>(vTPM)</b> <b>DEVICES</b>
       <b>vtpm-attach</b> <u>domain-id</u> <u>vtpm-device</u>
           Creates  a  new  vtpm  (virtual Trusted Platform Module) device in the domain specified by <u>domain-id</u>.
           <u>vtpm-device</u> describes the device to attach, using the same format as the <b>vtpm</b> string  in  the  domain
           config file.  See <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) for more information.

       <b>vtpm-detach</b> <u>domain-id</u> <u>devid|uuid</u>
           Removes the vtpm device from the domain specified by <u>domain-id</u>.  <u>devid</u> is the numeric device id given
           to  the  virtual  Trusted Platform Module device. You will need to run <b>xl</b> <b>vtpm-list</b> to determine that
           number. Alternatively, the <u>uuid</u> of the vtpm can be used to select the virtual device to detach.

       <b>vtpm-list</b> <u>domain-id</u>
           List virtual Trusted Platform Modules for a domain.

   <b>VDISPL</b> <b>DEVICES</b>
       <b>vdispl-attach</b> <u>domain-id</u> <u>vdispl-device</u>
           Creates a new vdispl device in the domain specified by <u>domain-id</u>.  <u>vdispl-device</u> describes the device
           to attach, using the same format as the <b>vdispl</b> string in the domain config file.  See  <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5)  for
           more information.

           <b>NOTES</b>

               As  in  <u>vdispl-device</u>  string  semicolon  is used then put quotes or escaping when using from the
               shell.

               <b>EXAMPLE</b>

                   xl vdispl-attach DomU connectors='id0:1920x1080;id1:800x600;id2:640x480'

                   or

                   xl vdispl-attach DomU connectors=id0:1920x1080\;id1:800x600\;id2:640x480

       <b>vdispl-detach</b> <u>domain-id</u> <u>dev-id</u>
           Removes the vdispl device specified by <u>dev-id</u> from the domain specified by <u>domain-id</u>.

       <b>vdispl-list</b> <u>domain-id</u>
           List virtual displays for a domain.

   <b>VSND</b> <b>DEVICES</b>
       <b>vsnd-attach</b> <u>domain-id</u> <u>vsnd-item</u> <u>vsnd-item</u> ...
           Creates a new vsnd device in the domain specified by <u>domain-id</u>.  <u>vsnd-item</u>'s describe the vsnd device
           to attach, using the same format as  the  <b>VSND_ITEM_SPEC</b>  string  in  the  domain  config  file.  See
           <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) for more information.

           <b>EXAMPLE</b>

               xl  vsnd-attach  DomU  'CARD,  short-name=Main, sample-formats=s16_le;s8;u32_be' 'PCM, name=Main'
               'STREAM, id=0, type=p' 'STREAM, id=1, type=c, channels-max=2'

       <b>vsnd-detach</b> <u>domain-id</u> <u>dev-id</u>
           Removes the vsnd device specified by <u>dev-id</u> from the domain specified by <u>domain-id</u>.

       <b>vsnd-list</b> <u>domain-id</u>
           List vsnd devices for a domain.

   <b>KEYBOARD</b> <b>DEVICES</b>
       <b>vkb-attach</b> <u>domain-id</u> <u>vkb-device</u>
           Creates a new keyboard device in the domain specified by <u>domain-id</u>.  <u>vkb-device</u> describes the  device
           to  attach,  using  the  same  format  as  the  <b>VKB_SPEC_STRING</b> string in the domain config file. See
           <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) for more information.

       <b>vkb-detach</b> <u>domain-id</u> <u>devid</u>
           Removes the keyboard device from the domain specified by <u>domain-id</u>.  <u>devid</u> is the  virtual  interface
           device number within the domain

       <b>vkb-list</b> <u>domain-id</u>
           List virtual network interfaces for a domain.

</pre><h4><b>PCI</b> <b>PASS-THROUGH</b></h4><pre>
       <b>pci-assignable-list</b> [<u>-n</u>]
           List  all the <b>BDF</b> of assignable PCI devices. See <b><a href="../man5/xl-pci-configuration.5.html">xl-pci-configuration</a></b>(5) for more information. If the
           -n option is specified then any name supplied when the  device  was  made  assignable  will  also  be
           displayed.

           These are devices in the system which are configured to be available for passthrough and are bound to
           a suitable PCI backend driver in domain 0 rather than a real driver.

       <b>pci-assignable-add</b> [<u>-n</u> <u>NAME</u>] <u>BDF</u>
           Make the device at <b>BDF</b> assignable to guests. See <b><a href="../man5/xl-pci-configuration.5.html">xl-pci-configuration</a></b>(5) for more information. If the
           -n option is supplied then the assignable device entry will the named with the given <b>NAME</b>.

           This  will  bind the device to the pciback driver and assign it to the "quarantine domain".  If it is
           already bound to a driver, it will first be unbound, and the original driver stored so that it can be
           re-bound to the same driver later if desired.  If the device is already bound, it will assign  it  to
           the quarantine domain and return success.

           CAUTION:  This  will  make  the device unusable by Domain 0 until it is returned with pci-assignable-
           remove.  Care should therefore be taken not to do this on a device critical to domain 0's  operation,
           such as storage controllers, network interfaces, or GPUs that are currently being used.

       <b>pci-assignable-remove</b> [<u>-r</u>] <u>BDF</u>|<u>NAME</u>
           Make  a  device  non-assignable to guests. The device may be identified either by its <b>BDF</b> or the <b>NAME</b>
           supplied when the device was made assignable. See <b><a href="../man5/xl-pci-configuration.5.html">xl-pci-configuration</a></b>(5) for more information.

           This will at least unbind the device from pciback, and re-assign it from the "quarantine domain" back
           to domain 0.  If the -r option is specified, it will also  attempt  to  re-bind  the  device  to  its
           original  driver, making it usable by Domain 0 again.  If the device is not bound to pciback, it will
           return success.

           Note that this functionality will work even for devices  which  were  not  made  assignable  by  <b>pci-</b>
           <b>assignable-add</b>.   This  can  be  used  to  allow  dom0  to  access  devices  which were automatically
           quarantined by Xen after domain destruction  as  a  result  of  Xen's  <b>iommu=quarantine</b>  command-line
           default.

           As  always,  this  should  only  be done if you trust the guest, or are confident that the particular
           device you're re-assigning to dom0 will cancel all in-flight DMA on FLR.

       <b>pci-attach</b> <u>domain-id</u> <u>PCI_SPEC_STRING</u>
           Hot-plug a new pass-through pci device to the specified domain. See <b><a href="../man5/xl-pci-configuration.5.html">xl-pci-configuration</a></b>(5) for  more
           information.

       <b>pci-detach</b> [<u>OPTIONS</u>] <u>domain-id</u> <u>PCI_SPEC_STRING</u>
           Hot-unplug  a  pci device that was previously passed through to a domain. See <b><a href="../man5/xl-pci-configuration.5.html">xl-pci-configuration</a></b>(5)
           for more information.

           <b>OPTIONS</b>

           <b>-f</b>  If this parameter is specified, <b>xl</b> is going to forcefully remove the device  even  without  guest
               domain's collaboration.

       <b>pci-list</b> <u>domain-id</u>
           List the <b>BDF</b> of pci devices passed through to a domain.

</pre><h4><b>USB</b> <b>PASS-THROUGH</b></h4><pre>
       <b>usbctrl-attach</b> <u>domain-id</u> <u>usbctrl-device</u>
           Create a new USB controller in the domain specified by <u>domain-id</u>, <u>usbctrl-device</u> describes the device
           to  attach,  using form "KEY=VALUE KEY=VALUE ..." where <b>KEY=VALUE</b> has the same meaning as the <b>usbctrl</b>
           description in the domain config file.  See <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) for more information.

       <b>usbctrl-detach</b> <u>domain-id</u> <u>devid</u>
           Destroy a USB controller from the specified domain.  <b>devid</b> is devid of the USB controller.

       <b>usbdev-attach</b> <u>domain-id</u> <u>usbdev-device</u>
           Hot-plug a new pass-through USB device to the domain specified by <u>domain-id</u>, <u>usbdev-device</u>  describes
           the  device  to  attach, using form "KEY=VALUE KEY=VALUE ..." where <b>KEY=VALUE</b> has the same meaning as
           the <b>usbdev</b> description in the domain config file.  See <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) for more information.

       <b>usbdev-detach</b> <u>domain-id</u> <u>controller=devid</u> <u>port=number</u>
           Hot-unplug a previously assigned USB device from a domain.  <b>controller=devid</b> and <b>port=number</b>  is  USB
           controller:port in the guest domain the USB device is attached to.

       <b>usb-list</b> <u>domain-id</u>
           List pass-through usb devices for a domain.

</pre><h4><b>DEVICE-MODEL</b> <b>CONTROL</b></h4><pre>
       <b>qemu-monitor-command</b> <u>domain-id</u> <u>command</u>
           Issue  a monitor command to the device model of the domain specified by <u>domain-id</u>. <u>command</u> can be any
           valid command qemu understands. This can be e.g. used to add non-standard  devices  or  devices  with
           non-standard parameters to a domain. The output of the command is printed to stdout.

           <b>Warning:</b>  This  qemu  monitor access is provided for convenience when debugging, troubleshooting, and
           experimenting.  Its use is not supported by the Xen Project.

           Specifically, not all information displayed by the qemu  monitor  will  necessarily  be  accurate  or
           complete, because in a Xen system qemu does not have a complete view of the guest.

           Furthermore,  modifying  the guest's setup via the qemu monitor may conflict with the Xen toolstack's
           assumptions.  Resulting problems may include, but are not limited to: guest crashes; toolstack  error
           messages;  inability  to migrate the guest; and security vulnerabilities which are not covered by the
           Xen Project security response policy.

           <b>EXAMPLE</b>

           Obtain information of USB devices connected as such via the device model (only!) to a domain:

            xl qemu-monitor-command vm1 'info usb'
             Device 0.2, Port 5, Speed 480 Mb/s, Product Mass Storage

</pre><h4><b>FLASK</b></h4><pre>
       <b>FLASK</b> is a security framework that defines a  mandatory  access  control  policy  providing  fine-grained
       controls  over  Xen  domains,  allowing  the  policy  writer to define what interactions between domains,
       devices, and the hypervisor are permitted. Some example of what you can do using XSM/FLASK:
        - Prevent two domains from communicating via event channels or grants
        - Control which domains can use device passthrough (and which devices)
        - Restrict or audit operations performed by privileged domains
        - Prevent a privileged domain from arbitrarily mapping pages from other
          domains.

       You  can  find  more  details  on  how  to   use   FLASK   and   an   example   security   policy   here:
       &lt;https://xenbits.xenproject.org/docs/unstable/misc/xsm-flask.txt&gt;

       <b>getenforce</b>
           Determine if the FLASK security module is loaded and enforcing its policy.

       <b>setenforce</b> <u>1|0|Enforcing|Permissive</u>
           Enable  or disable enforcing of the FLASK access controls. The default is permissive, but this can be
           changed to enforcing by specifying "flask=enforcing" or  "flask=late"  on  the  hypervisor's  command
           line.

       <b>loadpolicy</b> <u>policy-file</u>
           Load  FLASK  policy from the given policy file. The initial policy is provided to the hypervisor as a
           multiboot module; this command allows runtime updates to the policy. Loading new security policy will
           reset runtime changes to device labels.

</pre><h4><b>PLATFORM</b> <b>SHARED</b> <b>RESOURCE</b> <b>MONITORING/CONTROL</b></h4><pre>
       Intel Haswell and later server platforms offer shared resource monitoring and control  technologies.  The
       availability of these technologies and the hardware capabilities can be shown with <b>psr-hwinfo</b>.

       See &lt;https://xenbits.xenproject.org/docs/unstable/misc/xl-psr.html&gt; for more information.

       <b>psr-hwinfo</b> [<u>OPTIONS</u>]
           Show Platform Shared Resource (PSR) hardware information.

           <b>OPTIONS</b>

           <b>-m</b>, <b>--cmt</b>
               Show Cache Monitoring Technology (CMT) hardware information.

           <b>-a</b>, <b>--cat</b>
               Show Cache Allocation Technology (CAT) hardware information.

   <b>CACHE</b> <b>MONITORING</b> <b>TECHNOLOGY</b>
       Intel Haswell and later server platforms offer monitoring capability in each logical processor to measure
       specific platform shared resource metric, for example, L3 cache occupancy. In the Xen implementation, the
       monitoring  granularity is domain level. To monitor a specific domain, just attach the domain id with the
       monitoring service. When the domain doesn't need to be monitored any more, detach the domain id from  the
       monitoring service.

       Intel  Broadwell  and  later  server  platforms  also  offer total/local memory bandwidth monitoring. Xen
       supports per-domain  monitoring  for  these  two  additional  monitoring  types.  Both  memory  bandwidth
       monitoring  and L3 cache occupancy monitoring share the same set of underlying monitoring service. Once a
       domain is attached to the monitoring service, monitoring data can be shown for any  of  these  monitoring
       types.

       There is no cache monitoring and memory bandwidth monitoring on L2 cache so far.

       <b>psr-cmt-attach</b> <u>domain-id</u>
           attach: Attach the platform shared resource monitoring service to a domain.

       <b>psr-cmt-detach</b> <u>domain-id</u>
           detach: Detach the platform shared resource monitoring service from a domain.

       <b>psr-cmt-show</b> <u>psr-monitor-type</u> [<u>domain-id</u>]
           Show monitoring data for a certain domain or all domains. Current supported monitor types are:
            - "cache-occupancy": showing the L3 cache occupancy(KB).
            - "total-mem-bandwidth": showing the total memory bandwidth(KB/s).
            - "local-mem-bandwidth": showing the local memory bandwidth(KB/s).

   <b>CACHE</b> <b>ALLOCATION</b> <b>TECHNOLOGY</b>
       Intel  Broadwell  and  later  server  platforms offer capabilities to configure and make use of the Cache
       Allocation Technology (CAT) mechanisms, which enable more cache resources (i.e. L3/L2 cache) to  be  made
       available  for  high  priority  applications.  In  the  Xen  implementation, CAT is used to control cache
       allocation on VM basis. To enforce cache on a specific domain, just set capacity bitmasks (CBM)  for  the
       domain.

       Intel  Broadwell  and  later  server  platforms  also  offer  Code/Data  Prioritization  (CDP)  for cache
       allocations, which support specifying code or data cache for applications. CDP is used on a per VM  basis
       in  the  Xen  implementation. To specify code or data CBM for the domain, CDP feature must be enabled and
       CBM type options need to be specified when setting CBM, and the type options (code and data) are mutually
       exclusive. There is no CDP support on L2 so far.

       <b>psr-cat-set</b> [<u>OPTIONS</u>] <u>domain-id</u> <u>cbm</u>
           Set  cache  capacity  bitmasks(CBM)  for  a  domain.  For  how  to  specify  <u>cbm</u>  please   refer   to
           &lt;https://xenbits.xenproject.org/docs/unstable/misc/xl-psr.html&gt;.

           <b>OPTIONS</b>

           <b>-s</b> <b>SOCKET</b>, <b>--socket=SOCKET</b>
               Specify the socket to process, otherwise all sockets are processed.

           <b>-l</b> <b>LEVEL</b>, <b>--level=LEVEL</b>
               Specify the cache level to process, otherwise the last level cache (L3) is processed.

           <b>-c</b>, <b>--code</b>
               Set code CBM when CDP is enabled.

           <b>-d</b>, <b>--data</b>
               Set data CBM when CDP is enabled.

       <b>psr-cat-show</b> [<u>OPTIONS</u>] [<u>domain-id</u>]
           Show CAT settings for a certain domain or all domains.

           <b>OPTIONS</b>

           <b>-l</b> <b>LEVEL</b>, <b>--level=LEVEL</b>
               Specify the cache level to process, otherwise the last level cache (L3) is processed.

   <b>Memory</b> <b>Bandwidth</b> <b>Allocation</b>
       Intel  Skylake  and  later  server  platforms  offer capabilities to configure and make use of the Memory
       Bandwidth Allocation (MBA) mechanisms, which provides OS/VMMs the ability to slow misbehaving apps/VMs by
       using a credit-based throttling mechanism. In the Xen implementation,  MBA  is  used  to  control  memory
       bandwidth  on  VM basis. To enforce bandwidth on a specific domain, just set throttling value (THRTL) for
       the domain.

       <b>psr-mba-set</b> [<u>OPTIONS</u>] <u>domain-id</u> <u>thrtl</u>
           Set  throttling  value  (THRTL)  for  a  domain.  For  how  to  specify   <u>thrtl</u>   please   refer   to
           &lt;https://xenbits.xenproject.org/docs/unstable/misc/xl-psr.html&gt;.

           <b>OPTIONS</b>

           <b>-s</b> <b>SOCKET</b>, <b>--socket=SOCKET</b>
               Specify the socket to process, otherwise all sockets are processed.

       <b>psr-mba-show</b> [<u>domain-id</u>]
           Show  MBA  settings for a certain domain or all domains. For linear mode, it shows the decimal value.
           For non-linear mode, it shows hexadecimal value.

</pre><h4><b>IGNORED</b> <b>FOR</b> <b>COMPATIBILITY</b> <b>WITH</b> <b>XM</b></h4><pre>
       xl is mostly command-line compatible with the old  xm  utility  used  with  the  old  Python  xend.   For
       compatibility, the following options are ignored:

       <b>xl</b> <b>migrate</b> <b>--live</b>

</pre><h4><b>ENVIRONMENT</b> <b>VARIABLES</b></h4><pre>
       The following environment variables shall affect the execution of xl:

       LIBXL_BOOTLOADER_RESTRICT
           Equivalent to <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) <b>bootloader_restrict</b> option.  Provided for compatibility reasons.  Having this
           variable set is equivalent to enabling the option, even if the value is 0.

           If set takes precedence over <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) and <b><a href="../man5/xl.conf.5.html">xl.conf</a></b>(5) <b>bootloader_restrict</b> options.

       LIBXL_BOOTLOADER_USER
           Equivalent to <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) <b>bootloader_user</b> option.  Provided for compatibility reasons.

           If set takes precedence over <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5) <b>bootloader_user</b> option.

       LIBXL_BOOTLOADER_TIMEOUT
           Timeout  in  seconds  for  bootloader execution when running in restricted mode.  Otherwise the build
           time default in LIBXL_BOOTLOADER_TIMEOUT will be used.

           If defined the value must be an unsigned  integer  between  0  and  INT_MAX,  otherwise  behavior  is
           undefined.  Setting to 0 disables the timeout.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       The following man pages:

       <b><a href="../man5/xl.cfg.5.html">xl.cfg</a></b>(5), <b><a href="../man5/xlcpupool.cfg.5.html">xlcpupool.cfg</a></b>(5), <b><a href="../man1/xentop.1.html">xentop</a></b>(1), <b><a href="../man5/xl-disk-configuration.5.html">xl-disk-configuration</a></b>(5) <b><a href="../man5/xl-network-configuration.5.html">xl-network-configuration</a></b>(5)

       And the following documents on the xenproject.org website:

       &lt;https://xenbits.xenproject.org/docs/unstable/misc/xsm-flask.txt&gt;
       &lt;https://xenbits.xenproject.org/docs/unstable/misc/xl-psr.html&gt;

       For systems that don't automatically bring the CPU online:

       &lt;https://wiki.xenproject.org/wiki/Paravirt_Linux_CPU_Hotplug&gt;

</pre><h4><b>BUGS</b></h4><pre>
       Send                bugs               to               <a href="mailto:xen-devel@lists.xenproject.org">xen-devel@lists.xenproject.org</a>,               see
       https://wiki.xenproject.org/wiki/Reporting_Bugs_against_Xen_Project on how to send bug reports.

4.20.1-pre                                         2025-05-05                                              <u><a href="../man1/xl.1.html">xl</a></u>(1)
</pre>
 </div>
</div></section>
</div>
</body>
</html>