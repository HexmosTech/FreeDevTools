<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>remote_startup - the Grid Engine remote startup mechanism</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/gridengine-common">gridengine-common_8.1.9+dfsg-13.1_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       remote_startup - the Grid Engine remote startup mechanism

</pre><h4><b>DESCRIPTION</b></h4><pre>
       Grid  Engine  supports several commands to facilitate interactive commands or remote startup of a tightly
       integrated parallel job. Each command can be set up  with  <u><a href="../man1/qconf.1.html">qconf</a></u>(1)  (option  <b>-sconf</b>)  to  use  different
       daemons  and  commands  to  start  the  final  session.  Different  startup methods can therefore contain
       different daemons and commands, and are not related to other startup methods in any way, although  it  is
       often desirable to have the same communication method for all startup methods.

       Each method requires a separate instance of the communication daemon to be started by <u><a href="../man8/sge_shepherd.8.html">sge_shepherd</a></u>(8) for
       each  job,  which thus must use a randomly-chosen port, to which the client will try to connect.  This is
       necessary to support tight integration, ensuring that everything for  a  given  job  stays  in  the  same
       process tree and can be properly controlled and accounted by Grid Engine.

</pre><h4><b>QLOGIN</b></h4><pre>
       An  interactive  <b>qlogin</b>  session  invoked by <u><a href="../man1/qlogin.1.html">qlogin</a></u>(1) will show up in <b>qstat</b> with the default name <b>QLOGIN</b>
       unless changed by the <b>-N</b> <u>name</u> option.  The two entries <b>qlogin_daemon</b> and <b>qlogin_command</b>  are  responsible
       for establishing the communication to start such a session.

       The default is the value <b>builtin</b>, which will trigger an SGE internal communication method:

              <b>qlogin_command</b>      builtin
              <b>qlogin_daemon</b>       builtin

       In  cases  where  you  want a different communication method, it can also be set up for the formerly-used
       communication method based on <b>telnet</b>. Despite the fact that <b>telnet</b> is used, there  is  no  need  to  have
       <b>telnetd</b>  running  all  the  time - SGE will start a unique one for each job, even when it's from the same
       user, and telnet can stay disabled as a system service (whether under init  or  inetd).   Only  the  file
       /etc/hosts.equiv needs to contain the name of the machines from where a <u><a href="../man1/qlogin.1.html">qlogin</a></u>(1) should be allowed. This
       is  often  the  head  node of a cluster, or particular submit machines.  Using telnet, the traffic is not
       encrypted, but that may be reasonable on a private subnet  for  the  cluster,  especially  if  SGE's  CSP
       security isn't used to secure the system generally.

       To achieve this:

              <b>qlogin_command</b>      <a href="file:///usr/lib/w3m/cgi-bin/w3mman2html.cgi?telnet">/usr/bin/telnet</a>
              <b>qlogin_daemon</b>       /usr/sbin/in.telnetd

       must  be  defined  in  <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5).   The  defined <b>qlogin_command</b> will then be called with two additional
       parameters: ‘HOST’, and ‘PORT’ in exactly that order, which  refer  to  the  machine  the  <b>qlogin_command</b>
       should address and the port to be used.

       This  can  also be used to set up secure communication using <b>SSH</b> (which can also provide X and credential
       forwarding, as well as compression).  In this case a  small  wrapper  must  be  implemented,  whose  sole
       purpose  is  to  swap  the  two  given  arguments and prepend <b>-p</b> to the port argument.  A suitable one is
       installed as <u>$SGE_ROOT/util/resources/wrappers/qlogin_wrapper</u>:

              <b>qlogin_command</b>      /opt/sge/util/resources/wrappers/qlogin_wrapper
              <b>qlogin_daemon</b>       <a href="file:///usr/lib/w3m/cgi-bin/w3mman2html.cgi?sshd">/usr/sbin/sshd</a> -i

</pre><h4><b>QRLOGIN</b></h4><pre>
       An interactive <b>qrlogin</b> session invoked by <u><a href="../man1/qrsh.1.html">qrsh</a></u>(1) <b>without</b> a command will show  up  in  <b>qstat</b>  having  the
       default  name  <b>QRLOGIN</b>  unless  changed  by  the  <b>-N</b>  <u>name</u>  option.   The  two  entries <b>rlogin_daemon</b> and
       <b>rlogin_command</b> are responsible for establishing the command to start such a session.

       The default is the value <b>builtin</b>, which will trigger an SGE internal communication method:

              <b>rlogin_command</b>      builtin
              <b>rlogin_daemon</b>       builtin

       In cases where you want a different communication method, it can follow the  formerly-used  communication
       method  based on <b>rlogin</b>.  As for telnet, rlogin can stay disabled as a system service (whether under init
       or inetd).  Only the file /etc/hosts.equiv needs to contain the name of the machines from where a <u><a href="../man1/qrsh.1.html">qrsh</a></u>(1)
       should be allowed. This is often the head node of  a  cluster,  or  particular  submit  machines.   Using
       <b>rlogin</b>,  the  traffic  is  not encrypted, but that may be reasonable on a private subnet for the cluster,
       especially if SGE's CSP security isn't used to secure the system generally.

       To achieve this:

              <b>rlogin_command</b>      $SGE_ROOT/utilbin/<u>$ARC</u>/rlogin
              <b>rlogin_daemon</b>       /usr/sbin/in.rlogind

       must be defined in <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5).  The value of <u>$SGE_ROOT</u> must be replaced by the root of the installation,
       and <u>$ARC</u> must be replaced by the particular platform architecture, as use of environment variables is not
       implemented for these entries. When the cluster is homogeneous, it can be set to e.g. ‘lx-amd64’ or  ‘lx-
       x86’.  In  a heterogeneous cluster local configurations need to be defined, where preferably the minority
       of machines will get local configurations.

       The defined <b>rlogin_command</b> will then be called with three additional parameters: ‘-p’,‘PORT’, and  ‘HOST’
       in  exactly  that order, which refer to the machine the <b>rlogin_command</b> should address, and the port to be
       used.

       This can also be used to set up a secure communication using <b>SSH</b>:

              <b>rlogin_command</b>      <a href="file:///usr/lib/w3m/cgi-bin/w3mman2html.cgi?ssh">/usr/bin/ssh</a>
              <b>rlogin_daemon</b>       <a href="file:///usr/lib/w3m/cgi-bin/w3mman2html.cgi?sshd">/usr/sbin/sshd</a> -i

</pre><h4><b>QRSH</b></h4><pre>
       An interactive session for a remote command invoked by <u><a href="../man1/qrsh.1.html">qrsh</a></u>(1) <b>with</b> a command will show up  in  <b>qstat</b>  by
       default  with  name  of  the  command  issued,  unless  changed  by  the <b>-N</b> <u>name</u> option.  The two entries
       <b>rsh_daemon</b> and <b>rsh_command</b> are responsible for establishing the communication to start  such  a  session.
       This  startup  method  will also be used by the master task of a tightly integrated parallel job to start
       slave processes on other granted exechosts.

       The default is the value <b>builtin</b>, which will trigger an SGE internal communication method:

              <b>rsh_command</b>         builtin
              <b>rsh_daemon</b>          builtin

       In cases where you want a different communication method, it can also be set  up  for  the  formerly-used
       communication  method  based  on  <b>rsh</b>.  As for telnet, rsh can stay disabled as a system service (whether
       under init or inetd).  Only the file /etc/hosts.equiv needs to contain the  name  of  the  machines  from
       where  a  <u><a href="../man1/qrsh.1.html">qrsh</a></u>(1)  should  be  allowed.  This  is  often the head node of a cluster, or particular submit
       machines.  Using <b>rsh</b>, the traffic is not encrypted, but that may be reasonable on a  private  subnet  for
       the cluster, especially if SGE's CSP security isn't used to secure the system generally.

       To achieve this:

              <b>rsh_command</b>         $SGE_ROOT/utilbin/<u>$ARC</u>/rsh
              <b>rsh_daemon</b>          $SGE_ROOT/utilbin/<u>$ARC</u>/rshd -l

       must be defined in <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5).  The value of <u>$SGE_ROOT</u> must be replaced by the root of the installation,
       and <u>$ARC</u> must be replaced by the particular platform architecture, as use of environment variables is not
       implemented  for these entries. When the cluster is homogeneous, it can be set to e.g. ‘lx-amd64’ or ‘lx-
       x86’. In a heterogeneous cluster local configurations need to be defined, where preferably  the  minority
       of machines will get local configurations.

       The  defined  <b>rsh_command</b>  will  then  be called with four additional parameters: ‘-n’, ‘-p’, ‘PORT’, and
       ‘HOST’ in exactly that order, which refer to the machine the <b>rsh_command</b> should address and the  port  to
       be used.

       This can also be used to set up a secure communication using <b>SSH</b>:

              <b>rsh_command</b>         <a href="file:///usr/lib/w3m/cgi-bin/w3mman2html.cgi?ssh">/usr/bin/ssh</a>
              <b>rsh_daemon</b>          <a href="file:///usr/lib/w3m/cgi-bin/w3mman2html.cgi?sshd">/usr/sbin/sshd</a> -i
       Again, this is independent of SSH as a system service, which can remain disabled.

</pre><h4><b>LOCAL</b> <b>CONFIGURATIONS</b> <b>OF</b> <b>EXECHOSTS</b></h4><pre>
       It is important to note that the communication method set up for one particular startup method must match
       at  each  end.  This can either be achieved by using only a global configuration, or carefully setting up
       local configurations for the exechosts involved. Whether or not local configurations exist, which must be
       taken care of, can be checked with <b>qconf</b> <b>-sconfl</b>.

       As a general rule, for setting up a communication method between  a  machine  A  (where  the  <b>command</b>  is
       issued) and a machine B (where the <b>daemon</b> is started) it must be guaranteed that the:

              setup communication method for the <b>command</b> on machine A
              (either global configuration from <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5) or local configuration <b>qconf</b> <b>-sconf</b> <b>A</b> of machine A)

       matches

              setup communication method for the <b>daemon</b> for machine B
              (either global configuration from <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5) or local configuration <b>qconf</b> <b>-sconf</b> <b>B</b> of machine B)

       This  way it is also possible to use different communication methods, depending whether a connection from
       A to B is invoked, or from B to A.

</pre><h4><b>RESTRICTIONS</b></h4><pre>
       For all three communication methods, a direct connection between the target and the source machine  where
       the  particular  command was issued must exist. This can also be implemented using TCP/IP forwarding, but
       will usually fail if one  machine  is  behind  NAT  which  will  mangle  the  machines'  addresses.   The
       communication methods won't work with simple firewalling of the exec hosts since the methods use a random
       port.   It  may  be  possible  to  set  up application-specific firewalling, if necessary, or to wrap the
       methods and start an SSH tunnel on the port specified for each communication instance.

       The <b>builtin</b> method does not support forwarding of X graphics from the compute nodes, or GSSAPI tokens  to
       them.  If you need that for any of the remote methods, you will want to set up SSH communication instead.

</pre><h4><b>SSH</b> <b>AUTHENTICATION</b></h4><pre>
       To  allow  the  <b>SSH</b>  setup  explained  above to work, the user must be authenticated without the use of a
       <u>passphrase</u>. While entering a <u>passphrase</u> would still work for interactive commands, it will fail  in  case
       of  a tightly integrated parallel job, where the master process tries to start a slave process on another
       exechost.

       You can set up <u>passphraseless</u> <b>SSH</b> <b>keys</b>, although this is discouraged. A simpler and global working  setup
       is  to use host-based authentication ⟨<a href="http://arc.liv.ac.uk/SGE/howto/hostbased-ssh.html">http://arc.liv.ac.uk/SGE/howto/hostbased-ssh.html</a>⟩ for the machines
       inside the cluster.

</pre><h4><b>SSH</b> <b>TIGHT</b> <b>INTEGRATION</b></h4><pre>
       To have a tight integration of <b>SSH</b> into SGE, the  started  <b>sshd</b>  needs  an  additional  group  ID  to  be
       attached.   With  this  additional group ID, SGE is able to record the resource consumption and computing
       time in a correct way.  Also a <b>qdel</b> of such a job will be able to succeed.

       Such a tight SSH integration can be achieved by two means:

       <b>Use</b> <b>of</b> <b>PAM</b>
              The easiest way on supported platforms  (at  least  GNU/Linux):   a  <u><a href="../man7/pam.7.html">pam</a></u>(7)  module  <u><a href="../man8/pam_sge-qrshsetup.8.html">pam_sge-qrsh-</a></u>
              <u><a href="../man8/pam_sge-qrshsetup.8.html">setup</a></u>(8)  is  available for use with the system ssh; it attaches the necessary additional group ID
              to the started process to provide tight integration.  See also the workshop paper ⟨http://
              gridengine.org/assets/static/ws2007/K5SGE.pdf⟩.

       <b>Recompile</b> <b>Grid</b> <b>Engine</b> <b>with</b> <b>./aimk</b> <b>-tight-ssh</b> <b>...</b>
              The source of Grid Engine contains the necessary additions to compile a modified <u>sshd</u>, which  will
              honor the additional group ID and attach it also to the started process. It's necessary to provide
              the  source  of <u>OpenSSH</u> in the directory <u>3rd_party</u> inside <u>$SGE_ROOT</u> having a plain name ‘openssh’.
              Inside this directory the file <u>sshd.c</u> needs to be patched:

              in main():
                     init_rng();
                     #ifdef SGESSH_INTEGRATION
                     sgessh_readconfig();
                     #endif

              in privsep_postauth():
                     /* Drop privileges */
                     #ifdef SGESSH_INTEGRATION
                     sgessh_do_setusercontext(authctxt-&gt;pw);
                     #else
                     do_setusercontext(authctxt-&gt;pw);
                     #endif

              See the original documentation ⟨<a href="http://gridengine.org/assets/static/ws2007/">http://gridengine.org/assets/static/ws2007/</a>
              SGE-openSSHTightIntegration.RonChen.pdf⟩.

</pre><h4><b>RESTRICTING</b> <b>ACCESS</b></h4><pre>
       With the builtin method in use, there is no need to allow direct access for normal users to compute nodes
       with ssh etc.  However, you may want to allow users to access the nodes for debugging.  If you don't want
       to over-subscribe the nodes, so that qrsh etc. can be used for access, you can use PAM to restrict access
       for a user only to the nodes on which they have a running job, so as to minimize interference with  other
       others.

       There  are two possible ways.  The cleanest uses <u><a href="../man8/pam_sge_authorize.8.html">pam_sge_authorize</a></u>(8).  Otherwise you can use generic PAM
       modules, such as <u><a href="../man8/pam_limits.8.html">pam_limits</a></u>(8) or <u><a href="../man8/pam_access.8.html">pam_access</a></u>(8), with modifications to their  configuration  set  up  and
       taken down in the job prolog and epilog respectively.  See, for instance, a user list message ⟨http://
       gridengine.markmail.org/message/mu3i7haeshlevu6q?q=282211⟩,  and  other examples of similar prolog/epilog
       scripts provided with locking in the pam_authuser contribution in the Torque distribution.

</pre><h4><b>SECURITY</b></h4><pre>
       See the notes above concerning security of the communication channel.

</pre><h4><b>EXAMPLES</b></h4><pre>
       Using SSH with the  PAM  module,  forcing  tty  allocation,  and  preventing  the  delegation  of  GSSAPI
       credentials to the compute nodes:
              rsh_daemon     /opt/sge/util/rshdwrapper
              rsh_command    ssh -tt -o GSSAPIDelegateCredentials=no
              qlogin_daemon  /opt/sge/util/rshdwrapper
              qlogin_command ssh -tt -o GSSAPIDelegateCredentials=no
              rlogin_daemon  /opt/sge/util/rshdwrapper
              rlogin_command ssh -tt -o GSSAPIDelegateCredentials=no

       Old-style method, using telnet and rlogin:
              qlogin_command <a href="file:///usr/lib/w3m/cgi-bin/w3mman2html.cgi?telnet">/usr/bin/telnet</a>
              qlogin_daemon  /usr/sbin/in.telnetd
              rlogin_command /opt/sge/utilbin/lx-x86/rlogin
              rlogin_daemon  /usr/sbin/in.rlogind
              rsh_command    /opt/sge/utilbin/lx-x86/rsh
              rsh_daemon     /opt/sge/utilbin/lx-x86/rshd -l

</pre><h4><b>FILES</b></h4><pre>
       <u>$SGE_ROOT/util/resources/wrappers/qlogin_wrapper</u>
              SSH-based wrapper for qlogin (see above)

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <u><a href="../man1/qconf.1.html">qconf</a></u>(1), <u><a href="../man1/qlogin.1.html">qlogin</a></u>(1), <u><a href="../man1/qrsh.1.html">qrsh</a></u>(1), <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5), <u><a href="../man8/pam_sge_authorize.8.html">pam_sge_authorize</a></u>(8), <u><a href="../man8/pam_sge-qrsh-setup.8.html">pam_sge-qrsh-setup</a></u>(8), Grid Engine-
       specific remote programs ⟨<a href="http://arc.liv.ac.uk/repos/darcs/sge/source/3rdparty/remote/remote.html">http://arc.liv.ac.uk/repos/darcs/sge/source/3rdparty/remote/remote.html</a>⟩.

</pre><h4><b>AUTHOR</b></h4><pre>
       Man page written by Reuti, partly based on Sun material.  Some additions by Dave Love.

</pre><h4><b>COPYRIGHT</b></h4><pre>
       See <u><a href="../man1/sge_intro.1.html">sge_intro</a></u>(1) for a full statement of rights and permissions.

SGE 8.1.3pre                                   2010/11/22 20:58:24                             <u><a href="../man5/remote_startup.5.html">remote_startup</a></u>(5)
</pre>
 </div>
</div></section>
</div>
</body>
</html>