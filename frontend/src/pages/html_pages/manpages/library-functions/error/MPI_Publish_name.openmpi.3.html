<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>C Syntax</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/openmpi-doc">openmpi-doc_5.0.7-1build1_all</a> <br><br><pre>
</pre><h4><b>SYNTAX</b></h4><pre>
   <b>C</b> <b>Syntax</b>
          #include &lt;mpi.h&gt;

          int MPI_Publish_name(const char *service_name, MPI_Info info,
               const char *port_name)

   <b>Fortran</b> <b>Syntax</b>
          USE MPI
          ! or the older form: INCLUDE 'mpif.h'
          MPI_PUBLISH_NAME(SERVICE_NAME, INFO, PORT_NAME, IERROR)
               CHARACTER*(*)   SERVICE_NAME, PORT_NAME
               INTEGER         INFO, IERROR

   <b>Fortran</b> <b>2008</b> <b>Syntax</b>
          USE mpi_f08
          MPI_Publish_name(service_name, info, port_name, ierror)
               TYPE(MPI_Info), INTENT(IN) :: info
               CHARACTER(LEN=*), INTENT(IN) :: service_name, port_name
               INTEGER, OPTIONAL, INTENT(OUT) :: ierror

</pre><h4><b>INPUT</b> <b>PARAMETERS</b></h4><pre>
       • <b>service_name</b>: A service name (string).

       • <b>info</b>: Options to the name service functions (handle).

       • <b>port_name</b>: A port name (string).

</pre><h4><b>OUTPUT</b> <b>PARAMETER</b></h4><pre>
       • <b>ierror</b>: Fortran only: Error status (integer).

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This  routine  publishes the pair (<u>service_name,</u> <u>port_name</u>) so that an application may retrieve <u>port_name</u>
       by calling <u>MPI_Lookup_name</u> with <u>service_name</u> as  an  argument.  It  is  an  error  to  publish  the  same
       <u>service_name</u>  twice, or to use a <u>port_name</u> argument that was not previously opened by the calling process
       via a call to <u>MPI_Open_port</u>.

</pre><h4><b>INFO</b> <b>ARGUMENTS</b></h4><pre>
       The following keys for <u>info</u> are recognized:

          Key                   Type      Description
          ---                   ----      -----------

          ompi_global_scope     bool      If set to true, publish the name in
                                          the global scope.  Publish in the local
                                          scope otherwise.  See the NAME SCOPE
                                          section for more details.

          ompi_unique           bool      If set to true, return an error if the
                                          specified service_name already exists.
                                          Default to overwriting any pre-existing
                                          value.

       <u>bool</u> info keys are actually strings but are evaluated as follows: if the string value is a number, it  is
       converted  to  an integer and cast to a boolean (meaning that zero integers are false and non-zero values
       are true). If the string value is (case-insensitive) “yes” or “true”, the boolean is true. If the  string
       value  is  (case-insensitive)  “no”  or  “false”,  the  boolean  is  false.  All  other string values are
       unrecognized, and therefore false.

       If no info key is provided, the function will first check to see if a global server  has  been  specified
       and is available. If so, then the publish function will default to global scope first, followed by local.
       Otherwise, the data will default to publish with local scope.

</pre><h4><b>NAME</b> <b>SCOPE</b></h4><pre>
       Open  MPI  supports  two name scopes: <u>global</u> and <u>local</u>. Local scope will place the specified service/port
       pair in a data store located on the mpirun of the calling process’ job. Thus, data published  with  local
       scope  will  only  be  accessible  to  processes  in jobs spawned by that mpirun - e.g., processes in the
       calling process’ job, or in jobs spawned via <u>MPI_Comm_spawn</u>.

       Global scope places the specified service/port pair in a data store located on a central server  that  is
       accessible  to all jobs running in the cluster or environment. Thus, data published with global scope can
       be accessed by multiple mpiruns and used for <u>MPI_Comm_connect</u> and <u>MPI_Comm_accept</u> between jobs.

       Note that global scope operations require both the presence of the central server and  that  the  calling
       process  be  able to communicate to that server. <u>MPI_Publish_name</u> will return an error if global scope is
       specified and a global server is either not specified or cannot be found.

       Open MPI provides a server called <u>ompi-server</u> to support global scope operations.  Please  refer  to  its
       manual page for a more detailed description of data store/lookup operations.

       As  an  example of the impact of these scoping rules, consider the case where a job has been started with
       mpirun - call this job “job1”. A process in job1 creates and publishes a service/port pair using a  local
       scope. Open MPI will store this data in the data store within mpirun.

       A  process  in  job1  (perhaps  the  same  as  did the publish, or perhaps some other process in the job)
       subsequently calls <u>MPI_Comm_spawn</u> to start another job (call it “job2”) under this mpirun. Since the  two
       jobs  share  a  common  mpirun,  both  jobs have access to local scope data. Hence, a process in job2 can
       perform an <u>MPI_Lookup_name</u> with a local scope to retrieve the information.

       However, assume another user starts a job using mpirun - call this job “job3”. Because  the  service/port
       data  published by job1 specified local scope, processes in job3 cannot access that data. In contrast, if
       the data had been published using global scope, then any process in job3 could access the data,  provided
       that  mpirun  was  given  knowledge  of how to contact the central server and the process could establish
       communication with it.

</pre><h4><b>ERRORS</b></h4><pre>
       Almost all MPI routines return an error value; C routines as  the  return  result  of  the  function  and
       Fortran routines in the last argument.

       Before  the  error  value  is  returned,  the current MPI error handler associated with the communication
       object (e.g., communicator, window, file) is called.  If no communication object is associated  with  the
       MPI  call,  then  the call is considered attached to MPI_COMM_SELF and will call the associated MPI error
       handler.  When  MPI_COMM_SELF  is  not  initialized   (i.e.,   before   <u>MPI_Init</u>/<u>MPI_Init_thread</u>,   after
       <u>MPI_Finalize</u>,  or  when using the Sessions Model exclusively) the error raises the initial error handler.
       The initial error handler can be changed by calling <u>MPI_Comm_set_errhandler</u> on MPI_COMM_SELF  when  using
       the  World  model,  or the mpi_initial_errhandler CLI argument to mpiexec or info key to <u>MPI_Comm_spawn</u>/‐
       <u>MPI_Comm_spawn_multiple</u>.  If no other appropriate error handler has been set, then the  MPI_ERRORS_RETURN
       error  handler  is  called for MPI I/O functions and the MPI_ERRORS_ABORT error handler is called for all
       other MPI functions.

       Open MPI includes three predefined error handlers that can be used:

       • <b>MPI_ERRORS_ARE_FATAL</b> Causes the program to abort all connected MPI processes.

       • <b>MPI_ERRORS_ABORT</b> An error handler that can be invoked on a communicator, window, file, or session. When
         called on a communicator, it acts as if <u>MPI_Abort</u> was called on  that  communicator.  If  called  on  a
         window  or file, acts as if <u>MPI_Abort</u> was called on a communicator containing the group of processes in
         the corresponding window or file. If called on a session, aborts only the local process.

       • <b>MPI_ERRORS_RETURN</b> Returns an error code to the application.

       MPI applications can also implement their own error handlers by calling:

       • <u>MPI_Comm_create_errhandler</u> then <u>MPI_Comm_set_errhandler</u>

       • <u>MPI_File_create_errhandler</u> then <u>MPI_File_set_errhandler</u>

       • <u>MPI_Session_create_errhandler</u> then <u>MPI_Session_set_errhandler</u> or at <u>MPI_Session_init</u>

       • <u>MPI_Win_create_errhandler</u> then <u>MPI_Win_set_errhandler</u>

       Note that MPI does not guarantee that an MPI program can continue past an error.

       See the <u>MPI</u> <u>man</u> <u>page</u> for a full list of <u>MPI</u> <u>error</u> <u>codes</u>.

       See the Error Handling section of the MPI-3.1 standard for more information.

       <b>SEE</b> <b>ALSO:</b>

          • <u>MPI_Lookup_name</u>

          • <u>MPI_Open_port</u>

</pre><h4><b>COPYRIGHT</b></h4><pre>
       2003-2025, The Open MPI Community

                                                  Jun 07, 2025                               <u><a href="../man3/MPI_PUBLISH_NAME.3.html">MPI_PUBLISH_NAME</a></u>(3)
</pre>
 </div>
</div></section>
</div>
</body>
</html>