<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>libmemkind::static_kind::allocator<T>  -  The  C++  allocator  compatible  with  the C++ standard library</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/plucky/+package/libmemkind-dev">libmemkind-dev_1.14.0-3.1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       libmemkind::static_kind::allocator&lt;T&gt;  -  The  C++  allocator  compatible  with  the C++ standard library
       allocator concepts
       <b>Note:</b> <u>memkind_allocator.h</u> functionality is considered as stable API (STANDARD API).

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>#include</b> <b>&lt;memkind_allocator.h&gt;</b>

       <b>Link</b> <b>with</b> <b>-lmemkind</b>

       <b>libmemkind::static_kind::allocator(libmemkind::kinds</b> <u>kind</u><b>);</b>
       <b>template</b> <b>&lt;typename</b> <b>U&gt;</b> <b>libmemkind::static_kind::allocator&lt;T&gt;::allocator(const</b> <b>libmemkind::static_kind::allocator&lt;U&gt;&amp;)</b> <b>noexcept;</b>
       <b>template</b> <b>&lt;typename</b> <b>U&gt;</b> <b>libmemkind::static_kind::allocator(const</b> <b>allocator&lt;U&gt;&amp;&amp;</b> <u>other</u><b>)</b> <b>noexcept;</b>
       <b>libmemkind::static_kind::allocator&lt;T&gt;::~allocator();</b>
       <b>T</b> <b>*libmemkind::static_kind::allocator&lt;T&gt;::allocate(std::size_t</b> <u>n</u><b>)</b> <b>const;</b>
       <b>void</b> <b>libmemkind::static_kind::allocator&lt;T&gt;::deallocate(T</b> <u>*p</u><b>,</b> <b>std::size_t</b> <u>n</u><b>)</b> <b>const;</b>
       <b>template</b> <b>&lt;class</b> <b>U,</b> <b>class...</b> <b>Args&gt;</b> <b>void</b> <b>libmemkind::static_kind::allocator&lt;T&gt;::construct(U</b> <u>*p</u><b>,</b> <b>Args...</b> <u>args</u><b>)</b> <b>const;</b>
       <b>void</b> <b>libmemkind::static_kind::allocator&lt;T&gt;::destroy(T</b> <u>*p</u><b>)</b> <b>const;</b>

</pre><h4><b>DESCRIPTION</b></h4><pre>
       The <b>libmemkind::static_kind::allocator&lt;T&gt;</b> is intended to be used with STL  containers  to  allocate  from
       static  kinds  memory.  Memory management is based on memkind library. Refer <b><a href="../man3/memkind.3.html">memkind</a></b>(3) man page for more
       details.

       The <b>libmemkind::kinds</b> specifies allocator static kinds of  memory,  representing  type  of  memory  which
       offers different characteristics. The available types of allocator kinds of memory:

       <b>libmemkind::kinds::DEFAULT</b> Default allocation using standard memory and default page size.

       <b>libmemkind::kinds::HIGHEST_CAPACITY</b>  Allocate from a NUMA node(s) that has the highest capacity among all
       nodes in the system.

       <b>libmemkind::kinds::HIGHEST_CAPACITY_PREFERRED</b> Same as <b>libmemkind::kinds::HIGHEST_CAPACITY</b> except that  if
       there  is not enough memory in the NUMA node that has the highest capacity in the local domain to satisfy
       the request, the allocation will fall back on  other  memory  NUMA  nodes.   <b>Note:</b>  For  this  kind,  the
       allocation will not succeed if there are two or more NUMA nodes that have the highest capacity.

       <b>libmemkind::kinds::HIGHEST_CAPACITY_LOCAL</b>  Allocate  from a NUMA node that has the highest capacity among
       all NUMA Nodes from the local domain.  NUMA Nodes have the same local domain for a set of CPUs associated
       with them, e.g. socket or sub-NUMA cluster.  <b>Note:</b> If there are multiple NUMA nodes  in  the  same  local
       domain  that  have  the  highest  capacity  -  allocation  will be done from NUMA node with worse latency
       attribute.  This kind requires locality information described in <b>SYSTEM</b> <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::HIGHEST_CAPACITY_LOCAL_PREFERRED</b>  Same  as   <b>libmemkind::kinds::HIGHEST_CAPACITY_LOCAL</b>
       except  that  if there is not enough memory in the NUMA node that has the highest capacity to satisfy the
       request, the allocation will fall back on other memory NUMA nodes.

       <b>libmemkind::kinds::LOWEST_LATENCY_LOCAL</b> Allocate from a NUMA node that has the lowest latency  among  all
       NUMA  Nodes  from  the  local domain.  NUMA Nodes have the same local domain for a set of CPUs associated
       with them, e.g. socket or sub-NUMA cluster.  <b>Note:</b> If there are multiple NUMA nodes  in  the  same  local
       domain  that  have  the  lowest  latency  -  allocation  will  be done from NUMA node with smaller memory
       capacity.  This kind requires locality and memory performance characteristics  information  described  in
       <b>SYSTEM</b> <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::LOWEST_LATENCY_LOCAL_PREFERRED</b>  Same as <b>libmemkind::kinds::LOWEST_LATENCY_LOCAL</b> except
       that if there is not enough memory in the NUMA node that has the lowest latency to satisfy  the  request,
       the allocation will fall back on other memory NUMA nodes.

       <b>libmemkind::kinds::HIGHEST_BANDWIDTH_LOCAL</b> Allocate from a NUMA node that has the highest bandwidth among
       all NUMA Nodes from the local domain.  NUMA Nodes have the same local domain for a set of CPUs associated
       with  them,  e.g.  socket  or sub-NUMA cluster.  <b>Note:</b> If there are multiple NUMA nodes in the same local
       domain that have the highest bandwidth - allocation will be done  from  NUMA  node  with  smaller  memory
       capacity.   This  kind  requires locality and memory performance characteristics information described in
       <b>SYSTEM</b> <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::HIGHEST_BANDWIDTH_LOCAL_PREFERRED</b> Same  as  <b>libmemkind::kinds::HIGHEST_BANDWIDTH_LOCAL</b>
       except  that if there is not enough memory in the NUMA node that has the highest bandwidth to satisfy the
       request, the allocation will fall back on other memory NUMA nodes.

       <b>libmemkind::kinds::HUGETLB</b> Allocate from standard memory using huge pages. Note: This kind requires  huge
       pages configuration described in <b>SYSTEM</b> <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::INTERLEAVE</b>  Allocate  pages  interleaved  across  all NUMA nodes with transparent huge
       pages disabled.

       <b>libmemkind::kinds::HBW</b> Allocate from the  closest  high  bandwidth  memory  NUMA  node  at  the  time  of
       allocation.  If  there is not enough high bandwidth memory to satisfy the request, errno is set to ENOMEM
       and the allocated pointer is set to <u>NULL</u>.  Note: This kind requires  memory  performance  characteristics
       information described in <b>SYSTEM</b> <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::HBW_ALL</b>  Same as <b>libmemkind::kinds::HBW</b> except decision regarding closest NUMA node is
       postponed until the time of first write.

       <b>libmemkind::kinds::HBW_HUGETLB</b> Same as <b>libmemkind::kinds::HBW</b> except the allocation  is  backed  by  huge
       pages. Note: This kind requires huge pages configuration described in <b>SYSTEM</b> <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::HBW_ALL_HUGETLB</b>        Combination       of       <b>libmemkind::kinds::HBW_ALL</b>       and
       <b>libmemkind::kinds::HBW_HUGETLB</b> properties. Note: This kind requires huge pages configuration described in
       <b>SYSTEM</b> <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::HBW_PREFERRED</b> Same as <b>libmemkind::kinds::HBW</b> except that if there is not  enough  high
       bandwidth memory to satisfy the request, the allocation will fall back on standard memory.

       <b>libmemkind::kinds::HBW_PREFERRED_HUGETLB</b>  Same  as <b>libmemkind::kinds::HBW_PREFERRED</b> except the allocation
       is backed by huge  pages.  Note:  This  kind  requires  huge  pages  configuration  described  in  <b>SYSTEM</b>
       <b>CONFIGURATION</b> section.

       <b>libmemkind::kinds::HBW_INTERLEAVE</b>  Same  as <b>libmemkind::kinds::HBW</b> except that the pages that support the
       allocation are interleaved across all high bandwidth nodes and transparent huge pages are disabled.

       <b>libmemkind::kinds::REGULAR</b> Allocate from regular memory  using  the  default  page  size.  Regular  means
       general purpose memory from the NUMA nodes containing CPUs.

       <b>libmemkind::kinds::DAX_KMEM</b>  Allocate  from  the  closest  persistent  memory  NUMA  node  at the time of
       allocation. If there is not enough memory in the closest persistent  memory  NUMA  node  to  satisfy  the
       request, <u>errno</u> is set to <b>ENOMEM</b> and the allocated pointer is set to <u>NULL</u>.

       <b>libmemkind::kinds::DAX_KMEM_ALL</b>  Allocate  from  the closest persistent memory NUMA node available at the
       time of allocation. If there is not enough memory on any of persistent memory NUMA nodes to  satisfy  the
       request, <u>errno</u> is set to <b>ENOMEM</b> and the allocated pointer is set to <u>NULL</u>.

       <b>libmemkind::kinds::DAX_KMEM_PREFERRED</b>  Same  as  <b>libmemkind::kinds::DAX_KMEM</b>  except that if there is not
       enough memory in the closest persistent memory NUMA node to satisfy the request, the allocation will fall
       back on other memory NUMA nodes.  <b>Note:</b> For this kind, the allocation will not succeed  if  two  or  more
       persistent  memory  NUMA  nodes  are  in  the  same shortest distance to the same CPU on which process is
       eligible to run.  Check on that eligibility is done upon starting the application.

       <b>libmemkind::kinds::DAX_KMEM_INTERLEAVE</b> Same as <b>libmemkind::kinds::DAX_KMEM</b> except  that  the  pages  that
       support the allocation are interleaved across all persistent memory NUMA nodes.

       All  public member types and functions correspond to standard library allocator concepts and definitions.
       The current implementation supports C++11 standard.

       Template arguments:
       <u>T</u> is an object type aliased by value_type.
       <u>U</u> is an object type.

       <b>Note:</b>
       <b>T</b>    <b>*libmemkind::static_kind::allocator&lt;T&gt;::allocate(std::size_t</b>    <u>n</u><b>)</b>    allocates     memory     using
       <b>memkind_malloc</b>().  Throw <u>std::bad_alloc</u> when:
              <u>n</u> = 0
              or there is not enough memory to satisfy the request.

       <b>libmemkind::static_kind::allocator&lt;T&gt;::deallocate(T</b> <u>*p</u><b>,</b> <b>std::size_t</b> <u>n</u><b>)</b> deallocates memory associated with
       pointer returned by <b>allocate</b>() using <b>memkind_free</b>().

</pre><h4><b>SYSTEM</b> <b>CONFIGURATION</b></h4><pre>
       Interfaces for obtaining 2MB (HUGETLB) memory need allocated huge pages in the kernel's huge page pool.

       <b>HUGETLB</b> <b>(huge</b> <b>pages)</b>
              Current  number  of  "persistent"  huge  pages  can  be  read from <u><a href="file:/proc/sys/vm/nr_hugepages">/proc/sys/vm/nr_hugepages</a></u> file.
              Proposed way of setting hugepages is:  <b>sudo</b>  <b>sysctl</b>  <b>vm.nr_hugepages=&lt;number_of_hugepages&gt;</b>.   More
              information can be found here: https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt

       Interfaces  for  obtaining locality information are provided by <u>libhwloc</u> dependency.  Functionality based
       on locality requires that  memkind  library  is  configured  and  built  with  the  support  of  <u>libhwloc</u>
       (./configure --enable-hwloc).

       Interfaces  for obtaining memory performance characteristics information are based on <u>HMAT</u> (Heterogeneous
       Memory    Attribute    Table)     https://uefi.org/sites/default/files/resources/ACPI_6_3_final_Jan30.pdf
       Functionality  based  on  memory  performance  characteristics requires that platform configuration fully
       supports HMAT and memkind library is configured and built  with  the  support  of  <u>libhwloc</u>  (./configure
       --enable-hwloc).

       <b>Note:</b>  For  a  given  target  NUMA  Node, the OS exposes only the performance characteristics of the best
       performing NUMA node.

       <u>libhwloc</u> can be reached on: https://www.open-mpi.org/projects/hwloc

</pre><h4><b>COPYRIGHT</b></h4><pre>
       Copyright (C) 2019 - 2021 Intel Corporation. All rights reserved.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man3/memkind.3.html">memkind</a></b>(3)

Intel Corporation                                  2019-09-24                                <u><a href="../man3/MEMKINDALLOCATOR.3.html">MEMKINDALLOCATOR</a></u>(3)
</pre>
 </div>
</div></section>
</div>
</body>
</html>