<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>C Syntax</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/openmpi-doc">openmpi-doc_5.0.7-1build1_all</a> <br><br><pre>
</pre><h4><b>SYNTAX</b></h4><pre>
   <b>C</b> <b>Syntax</b>
          #include &lt;mpi.h&gt;

          MPI_Put(const void *origin_addr, int origin_count, MPI_Datatype
               origin_datatype, int target_rank, MPI_Aint target_disp,
               int target_count, MPI_Datatype target_datatype, MPI_Win win)

          MPI_Rput(const void *origin_addr, int origin_count, MPI_Datatype
                origin_datatype, int target_rank, MPI_Aint target_disp,
                int target_count, MPI_Datatype target_datatype, MPI_Win win,
                MPI_Request *request)

   <b>Fortran</b> <b>Syntax</b>
          USE MPI
          ! or the older form: INCLUDE 'mpif.h'
          MPI_PUT(ORIGIN_ADDR, ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK,
               TARGET_DISP, TARGET_COUNT, TARGET_DATATYPE, WIN, IERROR)
               &lt;type&gt; ORIGIN_ADDR(*)
               INTEGER(KIND=MPI_ADDRESS_KIND) TARGET_DISP
               INTEGER ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK, TARGET_COUNT,
               TARGET_DATATYPE, WIN, IERROR

          MPI_RPUT(ORIGIN_ADDR, ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK,
                TARGET_DISP, TARGET_COUNT, TARGET_DATATYPE, WIN, REQUEST, IERROR)
                &lt;type&gt; ORIGIN_ADDR(*)
                INTEGER(KIND=MPI_ADDRESS_KIND) TARGET_DISP
                INTEGER ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK, TARGET_COUNT,
                TARGET_DATATYPE, WIN, REQUEST, IERROR

   <b>Fortran</b> <b>2008</b> <b>Syntax</b>
          USE mpi_f08
          MPI_Put(origin_addr, origin_count, origin_datatype, target_rank,
                       target_disp, target_count, target_datatype, win, ierror)
               TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: origin_addr
               INTEGER, INTENT(IN) :: origin_count, target_rank, target_count
               TYPE(MPI_Datatype), INTENT(IN) :: origin_datatype, target_datatype
               INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: target_disp
               TYPE(MPI_Win), INTENT(IN) :: win
               INTEGER, OPTIONAL, INTENT(OUT) :: ierror

          MPI_Rput(origin_addr, origin_count, origin_datatype, target_rank,
               target_disp, target_count, target_datatype, win, request,
                       ierror)
               TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: origin_addr
               INTEGER, INTENT(IN) :: origin_count, target_rank, target_count
               TYPE(MPI_Datatype), INTENT(IN) :: origin_datatype, target_datatype
               INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: target_disp
               TYPE(MPI_Win), INTENT(IN) :: win
               TYPE(MPI_Request), INTENT(OUT) :: request
               INTEGER, OPTIONAL, INTENT(OUT) :: ierror

</pre><h4><b>INPUT</b> <b>PARAMETERS</b></h4><pre>
       • <b>origin_addr</b>: Initial address of origin buffer (choice).

       • <b>origin_count</b>: Number of entries in origin buffer (nonnegative integer).

       • <b>origin_datatype</b>: Data type of each entry in origin buffer (handle).

       • <b>target_rank</b>: Rank of target (nonnegative integer).

       • <b>target_disp</b>: Displacement from start of window to target buffer (nonnegative integer).

       • <b>target_count</b>: Number of entries in target buffer (nonnegative integer).

       • <b>target_datatype</b>: Data type of each entry in target buffer (handle).

       • <b>win</b>: Window object used for communication (handle).

</pre><h4><b>OUTPUT</b> <b>PARAMETER</b></h4><pre>
       • <b>request</b>: MPI_Rput: RMA request

       • <b>ierror</b>: Fortran only: Error status (integer).

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <u>MPI_Put</u>  transfers  <u>origin_count</u> successive entries of the type specified by <u>origin_datatype</u>, starting at
       address <u>origin_addr</u> on the origin node to the target node specified by the <u>win</u>, <u>target_rank</u>

       pair. The data are written in the target buffer at address <u>target_addr</u>  ^  <u>window_base</u>  +  <u>target_disp</u>  x
       <u>disp_unit</u>, where <u>window_base</u> and <u>disp_unit</u> are the base address and window displacement unit specified at
       window initialization, by the target process.

       The target buffer is specified by the arguments <u>target_count</u> and <u>target_datatype</u>.

       The  data  transfer is the same as that which would occur if the origin process executed a send operation
       with arguments <u>origin_addr</u>, <u>origin_count</u>, <u>origin_datatype</u>, <u>target_rank</u>, <u>tag</u>, <u>comm</u>, and the target process
       executed a receive operation with arguments  <u>target_addr</u>,  <u>target_count</u>,  <u>target_datatype</u>,  <u>source</u>,  <u>tag</u>,
       <u>comm</u>,  where  <u>target_addr</u>  is  the  target  buffer  address  computed  as  explained above, and <u>comm</u> is a
       communicator for the group of <u>win</u>.

       The communication must satisfy the same constraints as for a similar message-passing  communication.  The
       <u>target_datatype</u>  may  not  specify  overlapping  entries in the target buffer. The message sent must fit,
       without truncation, in the target buffer. Furthermore, the target buffer must fit in the  target  window.
       In addition, only processes within the same buffer can access the target window.

       The  <u>target_datatype</u>  argument  is  a handle to a datatype object defined at the origin process. However,
       this object is interpreted at the target process: The outcome is as if the target  datatype  object  were
       defined at the target process, by the same sequence of calls used to define it at the origin process. The
       target data type must contain only relative displacements, not absolute addresses. The same holds for get
       and accumulate.

       <u>MPI_Rput</u> is similar to <u>MPI_Put</u>, except that it allocates a communication request object and associates it
       with  the request handle (the argument <u>request</u>). The completion of an <u>MPI_Rput</u> operation (i.e., after the
       corresponding test or wait) indicates that the sender  is  now  free  to  update  the  locations  in  the
       <u>origin_addr</u>  buffer.  It  does  not  indicate  that the data is available at the target window. If remote
       completion is required, <u>MPI_Win_flush</u>, <u>MPI_Win_flush_all</u>, <u>MPI_Win_unlock</u>, or  <u>MPI_Win_unlock_all</u>  can  be
       used.

</pre><h4><b>NOTES</b></h4><pre>
       The <u>target_datatype</u> argument is a handle to a datatype object that is defined at the origin process, even
       though  it  defines  a  data  layout  in  the  target  process  memory. This does not cause problems in a
       homogeneous or heterogeneous environment, as long as only portable data types  are  used  (portable  data
       types are defined in Section 2.4 of the MPI-2 Standard).

       The  performance  of  a  put  transfer can be significantly affected, on some systems, from the choice of
       window location and the shape and location of the origin and target buffer: Transfers to a target  window
       in  memory  allocated  by  <u>MPI_Alloc_mem</u>  may  be  much  faster  on shared memory systems; transfers from
       contiguous buffers will be faster on most, if not  all,  systems;  the  alignment  of  the  communication
       buffers may also impact performance.

</pre><h4><b>ERRORS</b></h4><pre>
       Almost  all  MPI  routines  return  an  error  value; C routines as the return result of the function and
       Fortran routines in the last argument.

       Before the error value is returned, the current MPI  error  handler  associated  with  the  communication
       object  (e.g.,  communicator, window, file) is called.  If no communication object is associated with the
       MPI call, then the call is considered attached to MPI_COMM_SELF and will call the  associated  MPI  error
       handler.   When   MPI_COMM_SELF   is   not  initialized  (i.e.,  before  <u>MPI_Init</u>/<u>MPI_Init_thread</u>,  after
       <u>MPI_Finalize</u>, or when using the Sessions Model exclusively) the error raises the initial  error  handler.
       The  initial  error handler can be changed by calling <u>MPI_Comm_set_errhandler</u> on MPI_COMM_SELF when using
       the World model, or the mpi_initial_errhandler CLI argument to mpiexec or info  key  to  <u>MPI_Comm_spawn</u>/‐
       <u>MPI_Comm_spawn_multiple</u>.   If no other appropriate error handler has been set, then the MPI_ERRORS_RETURN
       error handler is called for MPI I/O functions and the MPI_ERRORS_ABORT error handler is  called  for  all
       other MPI functions.

       Open MPI includes three predefined error handlers that can be used:

       • <b>MPI_ERRORS_ARE_FATAL</b> Causes the program to abort all connected MPI processes.

       • <b>MPI_ERRORS_ABORT</b> An error handler that can be invoked on a communicator, window, file, or session. When
         called  on  a  communicator,  it  acts  as if <u>MPI_Abort</u> was called on that communicator. If called on a
         window or file, acts as if <u>MPI_Abort</u> was called on a communicator containing the group of processes  in
         the corresponding window or file. If called on a session, aborts only the local process.

       • <b>MPI_ERRORS_RETURN</b> Returns an error code to the application.

       MPI applications can also implement their own error handlers by calling:

       • <u>MPI_Comm_create_errhandler</u> then <u>MPI_Comm_set_errhandler</u>

       • <u>MPI_File_create_errhandler</u> then <u>MPI_File_set_errhandler</u>

       • <u>MPI_Session_create_errhandler</u> then <u>MPI_Session_set_errhandler</u> or at <u>MPI_Session_init</u>

       • <u>MPI_Win_create_errhandler</u> then <u>MPI_Win_set_errhandler</u>

       Note that MPI does not guarantee that an MPI program can continue past an error.

       See the <u>MPI</u> <u>man</u> <u>page</u> for a full list of <u>MPI</u> <u>error</u> <u>codes</u>.

       See the Error Handling section of the MPI-3.1 standard for more information.

       <b>SEE</b> <b>ALSO:</b>

          • <u>MPI_Get</u>

          • <u>MPI_Rget</u>

          • <u>MPI_Accumulate</u>

          • <u>MPI_Win_flush</u>

          • <u>MPI_Win_flush_all</u>

          • <u>MPI_Win_unlock</u>

          • <u>MPI_Win_unlock_all</u>

</pre><h4><b>COPYRIGHT</b></h4><pre>
       2003-2025, The Open MPI Community

                                                  Jun 07, 2025                                        <u><a href="../man3/MPI_PUT.3.html">MPI_PUT</a></u>(3)
</pre>
 </div>
</div></section>
</div>
</body>
</html>