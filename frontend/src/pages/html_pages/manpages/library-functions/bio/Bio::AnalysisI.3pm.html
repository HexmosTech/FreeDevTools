<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bio::AnalysisI - An interface to any (local or remote) analysis tool</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/libbio-perl-perl">libbio-perl-perl_1.7.8-1_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       Bio::AnalysisI - An interface to any (local or remote) analysis tool

</pre><h4><b>SYNOPSIS</b></h4><pre>
       This is an interface module - you do not instantiate it.  Use "Bio::Tools::Run::Analysis" module:

         use Bio::Tools::Run::Analysis;
         my $tool = Bio::Tools::Run::Analysis-&gt;new(@args);

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This interface contains all public methods for accessing and controlling local and remote analysis tools.
       It is meant to be used on the client side.

</pre><h4><b>FEEDBACK</b></h4><pre>
   <b>Mailing</b> <b>Lists</b>
       User feedback is an integral part of the evolution of this and other Bioperl modules. Send your comments
       and suggestions preferably to the Bioperl mailing list.  Your participation is much appreciated.

         <a href="mailto:bioperl-l@bioperl.org">bioperl-l@bioperl.org</a>                  - General discussion
         <a href="http://bioperl.org/wiki/Mailing_lists">http://bioperl.org/wiki/Mailing_lists</a>  - About the mailing lists

   <b>Support</b>
       Please direct usage questions or support issues to the mailing list:

       <u><a href="mailto:bioperl-l@bioperl.org">bioperl-l@bioperl.org</a></u>

       rather than to the module maintainer directly. Many experienced and reponsive experts will be able look
       at the problem and quickly address it. Please include a thorough description of the problem with code and
       data examples if at all possible.

   <b>Reporting</b> <b>Bugs</b>
       Report bugs to the Bioperl bug tracking system to help us keep track of the bugs and their resolution.
       Bug reports can be submitted via the web:

         https://github.com/bioperl/bioperl-live/issues

</pre><h4><b>AUTHOR</b></h4><pre>
       Martin Senger (<a href="mailto:martin.senger@gmail.com">martin.senger@gmail.com</a>)

</pre><h4><b>COPYRIGHT</b></h4><pre>
       Copyright (c) 2003, Martin Senger and EMBL-EBI.  All Rights Reserved.

       This module is free software; you can redistribute it and/or modify it under the same terms as Perl
       itself.

</pre><h4><b>DISCLAIMER</b></h4><pre>
       This software is provided "as is" without warranty of any kind.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <a href="http://www.ebi.ac.uk/Tools/webservices/soaplab/guide">http://www.ebi.ac.uk/Tools/webservices/soaplab/guide</a>

</pre><h4><b>APPENDIX</b></h4><pre>
       This is actually the main documentation...

       If you try to call any of these methods directly on this "Bio::AnalysisI" object you will get a <u>not</u>
       <u>implemented</u> error message. You need to call them on a "Bio::Tools::Run::Analysis" object instead.

   <b>analysis_name</b>
        Usage   : $tool-&gt;analysis_name;
        Returns : a name of this analysis
        Args    : none

   <b>analysis_spec</b>
        Usage   : $tool-&gt;analysis_spec;
        Returns : a hash reference describing this analysis
        Args    : none

       The returned hash reference uses the following keys (not all of them always present, perhaps others
       present as well): "name", "type", "version", "supplier", "installation", "description".

       Here is an example output:

         Analysis 'edit.seqret':
               installation =&gt; EMBL-EBI
               description =&gt; Reads and writes (returns) sequences
               supplier =&gt; EMBOSS
               version =&gt; 2.6.0
               type =&gt; edit
               name =&gt; seqret

   <b>describe</b>
        Usage   : $tool-&gt;analysis_spec;
        Returns : an XML detailed description of this analysis
        Args    : none

       The returned XML string contains metadata describing this analysis service. It includes also metadata
       returned (and easier used) by method "analysis_spec", "input_spec" and "result_spec".

       The DTD used for returned metadata is based on the adopted standard (BSA specification for analysis
       engine):

         &lt;!ELEMENT DsLSRAnalysis (analysis)+&gt;

         &lt;!ELEMENT analysis (description?, input*, output*, extension?)&gt;

         &lt;!ATTLIST analysis
             type          CDATA #REQUIRED
             name          CDATA #IMPLIED
             version       CDATA #IMPLIED
             supplier      CDATA #IMPLIED
             installation  CDATA #IMPLIED&gt;

         &lt;!ELEMENT description ANY&gt;
         &lt;!ELEMENT extension ANY&gt;

         &lt;!ELEMENT input (default?, allowed*, extension?)&gt;

         &lt;!ATTLIST input
             type          CDATA #REQUIRED
             name          CDATA #REQUIRED
             mandatory     (true|false) "false"&gt;

         &lt;!ELEMENT default (#PCDATA)&gt;
         &lt;!ELEMENT allowed (#PCDATA)&gt;

         &lt;!ELEMENT output (extension?)&gt;

         &lt;!ATTLIST output
             type          CDATA #REQUIRED
             name          CDATA #REQUIRED&gt;

       But the DTD may be extended by provider-specific metadata. For example, the EBI experimental SOAP-based
       service on top of EMBOSS uses DTD explained at "<a href="http://www.ebi.ac.uk/~senger/applab">http://www.ebi.ac.uk/~senger/applab</a>".

   <b>input_spec</b>
        Usage   : $tool-&gt;input_spec;
        Returns : an array reference with hashes as elements
        Args    : none

       The analysis input data are named, and can be also associated with a default value, with allowed values
       and with few other attributes. The names are important for feeding the service with the input data (the
       inputs are given to methods "create_job", "Bio::AnalysisI|run", and/or "Bio::AnalysisI|wait_for" as
       name/value pairs).

       Here is a (slightly shortened) example of an input specification:

        $input_spec = [
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'sequence_usa'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'sequence_direct_data'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'allowed_values' =&gt; [
                                         'gcg',
                                         'gcg8',
                                         ...
                                         'raw'
                                       ],
                   'type' =&gt; 'String',
                   'name' =&gt; 'sformat'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'sbegin'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'send'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'sprotein'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'snucleotide'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'sreverse'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'slower'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'supper'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'default' =&gt; 'false',
                   'type' =&gt; 'String',
                   'name' =&gt; 'firstonly'
                 },
                 {
                   'mandatory' =&gt; 'false',
                   'default' =&gt; 'fasta',
                   'allowed_values' =&gt; [
                                         'gcg',
                                         'gcg8',
                                         'embl',
                                         ...
                                         'raw'
                                       ],
                   'type' =&gt; 'String',
                   'name' =&gt; 'osformat'
                 }
               ];

   <b>result_spec</b>
        Usage   : $tool-&gt;result_spec;
        Returns : a hash reference with result names as keys
                  and result types as values
        Args    : none

       The analysis results are named and can be retrieved using their names by methods "results" and "result".

       Here is an example of the result specification (again for the service <u>edit.seqret</u>):

         $result_spec = {
                 'outseq' =&gt; 'String',
                 'report' =&gt; 'String',
                 'detailed_status' =&gt; 'String'
               };

   <b>create_job</b>
        Usage   : $tool-&gt;create_job ( {'sequence'=&gt;'tatat'} )
        Returns : Bio::Tools::Run::Analysis::Job
        Args    : data and parameters for this execution
                  (in various formats)

       Create an object representing a single execution of this analysis tool.

       Call this method if you wish to "stage the scene" - to create a job with all input data but without
       actually running it. This method is called automatically from other methods ("Bio::AnalysisI|run" and
       "Bio::AnalysisI|wait_for") so usually you do not need to call it directly.

       The input data and prameters for this execution can be specified in various ways:

       array reference
           The array has scalar elements of the form

              name = [[@]value]

           where  "name"  is  the  name of an input data or input parameter (see method "input_spec" for finding
           what names are recognized by this analysis) and "value"  is  a  value  for  this  data/parameter.  If
           "value"  is  missing  a 1 is assumed (which is convenient for the boolean options). If "value" starts
           with "@" it is treated as a local filename, and its contents is used as the data/parameter value.

       hash reference
           The same as with the array reference but now there is no need to use an equal sign. The hash keys are
           input names and hash values their data. The values can again start with a "@" sign indicating a local
           filename.

       scalar
           In this case, the parameter represents a job ID obtained in  some  previous  invocation  -  such  job
           already exists on the server side, and we are just re-creating it here using the same job ID.

           <u>TBD:</u> <u>here</u> <u>we</u> <u>should</u> <u>allow</u> <u>the</u> <u>same</u> <u>by</u> <u>using</u> <u>a</u> <u>reference</u> <u>to</u> <u>the</u> <u>Bio::Tools::Run::Analysis::Job</u> <u>object.</u>

       undef
           Finally,  if  the  parameter  is  undefined, ask server to create an empty job. The input data may be
           added later using "set_data..."  method(s) - see scripts/papplmaker.PLS for details.

   <b>run</b>
        Usage   : $tool-&gt;run ( ['sequence=@my.seq', 'osformat=embl'] )
        Returns : Bio::Tools::Run::Analysis::Job,
                  representing started job (an execution)
        Args    : the same as for create_job

       Create a job and start it, but do not wait for its completion.

   <b>wait_for</b>
        Usage   : $tool-&gt;wait_for ( { 'sequence' =&gt; '@my,file' } )
        Returns : Bio::Tools::Run::Analysis::Job,
                  representing finished job
        Args    : the same as for create_job

       Create a job, start it and wait for its completion.

       Note that this is a blocking method. It returns only after the executed job finishes, either normally  or
       by an error.

       Usually, after this call, you ask for results of the finished job:

           $analysis-&gt;wait_for (...)-&gt;results;

</pre><h4><b>Module</b> <b>Bio::AnalysisI::JobI</b></h4><pre>
       An interface to the public methods provided by "Bio::Tools::Run::Analysis::Job" objects.

       The  "Bio::Tools::Run::Analysis::Job"  objects  represent a created, running, or finished execution of an
       analysis tool.

       The factory for these objects is module "Bio::Tools::Run::Analysis" where the following methods return an
       "Bio::Tools::Run::Analysis::Job" object:

           create_job   (returning a prepared job)
           run          (returning a running job)
           wait_for     (returning a finished job)

   <b>id</b>
        Usage   : $job-&gt;id;
        Returns : this job ID
        Args    : none

       Each job (an execution) is identifiable by this unique ID which can be used later to re-create  the  same
       job  (in other words: to re-connect to the same job). It is useful in cases when a job takes long time to
       finish and your client program does not want to wait for it within the same session.

   <b>Bio::AnalysisI::JobI::run</b>
        Usage   : $job-&gt;run
        Returns : itself
        Args    : none

       It starts previously created job.  The job already must have all input data filled-in. This differs  from
       the    method    of    the    same   name   of   the   "Bio::Tools::Run::Analysis"   object   where   the
       "Bio::AnalysisI::JobI::run" method creates also a new job allowing to set input data.

   <b>Bio::AnalysisI::JobI::wait_for</b>
        Usage   : $job-&gt;wait_for
        Returns : itself
        Args    : none

       It waits until a previously started execution of this job finishes.

   <b>terminate</b>
        Usage   : $job-&gt;terminate
        Returns : itself
        Args    : none

       Stop the currently running job (represented by this object). This is a definitive stop, there is  no  way
       to resume it later.

   <b>last_event</b>
        Usage   : $job-&gt;last_event
        Returns : an XML string
        Args    : none

       It returns a short XML document showing what happened last with this job. This is the used DTD:

          &lt;!-- place for extensions --&gt;
          &lt;!ENTITY % event_body_template "(state_changed | heartbeat_progress | percent_progress | time_progress | step_progress)"&gt;

          &lt;!ELEMENT analysis_event (message?, (%event_body_template;)?)&gt;

          &lt;!ATTLIST analysis_event
              timestamp  CDATA #IMPLIED&gt;

          &lt;!ELEMENT message (#PCDATA)&gt;

          &lt;!ELEMENT state_changed EMPTY&gt;
          &lt;!ENTITY % analysis_state "created | running | completed | terminated_by_request | terminated_by_error"&gt;
          &lt;!ATTLIST state_changed
              previous_state  (%analysis_state;) "created"
              new_state       (%analysis_state;) "created"&gt;

          &lt;!ELEMENT heartbeat_progress EMPTY&gt;

          &lt;!ELEMENT percent_progress EMPTY&gt;
          &lt;!ATTLIST percent_progress
              percentage CDATA #REQUIRED&gt;

          &lt;!ELEMENT time_progress EMPTY&gt;
          &lt;!ATTLIST time_progress
              remaining CDATA #REQUIRED&gt;

          &lt;!ELEMENT step_progress EMPTY&gt;
          &lt;!ATTLIST step_progress
              total_steps      CDATA #IMPLIED
              steps_completed CDATA #REQUIRED&gt;

       Here  is  an  example  what is returned after a job was created and started, but before it finishes (note
       that the example uses an analysis 'showdb' which does not need any input data):

          use Bio::Tools::Run::Analysis;
          print new Bio::Tools::Run::Analysis (-name =&gt; 'display.showdb')
                    -&gt;run
                    -&gt;last_event;

       It prints:

          &lt;?xml version = "1.0"?&gt;
          &lt;analysis_event&gt;
            &lt;message&gt;Mar 3, 2003 5:14:46 PM (Europe/London)&lt;/message&gt;
            &lt;state_changed previous_state="created" new_state="running"/&gt;
          &lt;/analysis_event&gt;

       The same example but now after it finishes:

          use Bio::Tools::Run::Analysis;
          print new Bio::Tools::Run::Analysis (-name =&gt; 'display.showdb')
                    -&gt;wait_for
                    -&gt;last_event;

          &lt;?xml version = "1.0"?&gt;
          &lt;analysis_event&gt;
            &lt;message&gt;Mar 3, 2003 5:17:14 PM (Europe/London)&lt;/message&gt;
            &lt;state_changed previous_state="running" new_state="completed"/&gt;
          &lt;/analysis_event&gt;

   <b>status</b>
        Usage   : $job-&gt;status
        Returns : string describing the job status
        Args    : none

       It returns one of the following strings (and perhaps more if a server  implementation  extended  possible
       job states):

          CREATED
          RUNNING
          COMPLETED
          TERMINATED_BY_REQUEST
          TERMINATED_BY_ERROR

   <b>created</b>
        Usage   : $job-&gt;created (1)
        Returns : time when this job was created
        Args    : optional

       Without any argument it returns a time of creation of this job in seconds, counting from the beginning of
       the  UNIX  epoch  (1.1.1970).  With a true argument it returns a formatted time, using rules described in
       "Bio::Tools::Run::Analysis::Utils::format_time".

   <b>started</b>
        Usage   : $job-&gt;started (1)
        Returns : time when this job was started
        Args    : optional

       See "created".

   <b>ended</b>
        Usage   : $job-&gt;ended (1)
        Returns : time when this job was terminated
        Args    : optional

       See "created".

   <b>elapsed</b>
        Usage   : $job-&gt;elapsed
        Returns : elapsed time of the execution of the given job
                  (in milliseconds), or 0 of job was not yet started
        Args    : none

       Note that some server implementations cannot count in millisecond - so the returned time may  be  rounded
       to seconds.

   <b>times</b>
        Usage   : $job-&gt;times ('formatted')
        Returns : a hash reference with all time characteristics
        Args    : optional

       It is a convenient method returning a hash reference with the following keys:

          created
          started
          ended
          elapsed

       See "create" for remarks on time formatting.

       An example - both for unformatted and formatted times:

          use Data::Dumper;
          use Bio::Tools::Run::Analysis;
          my $rh = Bio::Tools::Run::Analysis-&gt;new(-name =&gt; 'nucleic_cpg_islands.cpgplot')
                    -&gt;wait_for ( { 'sequence_usa' =&gt; 'embl:hsu52852' } )
                    -&gt;times (1);
          print Data::Dumper-&gt;Dump ( [$rh], ['Times']);
          $rh = Bio::Tools::Run::Analysis-&gt;new(-name =&gt; 'nucleic_cpg_islands.cpgplot')
                    -&gt;wait_for ( { 'sequence_usa' =&gt; 'embl:AL499624' } )
                    -&gt;times;
          print Data::Dumper-&gt;Dump ( [$rh], ['Times']);

          $Times = {
                  'ended'   =&gt; 'Mon Mar  3 17:52:06 2003',
                  'started' =&gt; 'Mon Mar  3 17:52:05 2003',
                  'elapsed' =&gt; '1000',
                  'created' =&gt; 'Mon Mar  3 17:52:05 2003'
                };
          $Times = {
                  'ended'   =&gt; '1046713961',
                  'started' =&gt; '1046713926',
                  'elapsed' =&gt; '35000',
                  'created' =&gt; '1046713926'
                };

   <b>results</b>
        Usage   : $job-&gt;results (...)
        Returns : one or more results created by this job
        Args    : various, see belou

       This  is  a  complex method trying to make sense for all kinds of results. Especially it tries to help to
       put binary results (such as images) into local files. Generally it deals with fhe following facts:

       •   Each analysis tool may produce more results.

       •   Some results may contain binary data not suitable for printing into a terminal window.

       •   Some results may be split into variable number of parts (this is mainly true for  the  image  results
           that can consist of more *.png files).

       Note  also that results have names to distinguish if there are more of them. The names can be obtained by
       method "result_spec".

       Here are the rules how the method works:

           Retrieving NAMED results:
           -------------------------
            results ('name1', ...)   =&gt; return results as they are, no storing into files

            results ( { 'name1' =&gt; 'filename', ... } )  =&gt; store into 'filename', return 'filename'
            results ( 'name1=filename', ...)            =&gt; ditto

            results ( { 'name1' =&gt; '-', ... } )         =&gt; send result to the STDOUT, do not return anything
            results ( 'name1=-', ...)                   =&gt; ditto

            results ( { 'name1' =&gt; '@', ... } )  =&gt; store into file whose name is invented by
                                                    this method, perhaps using RESULT_NAME_TEMPLATE env
            results ( 'name1=@', ...)            =&gt; ditto

            results ( { 'name1' =&gt; '?', ... } )  =&gt; find of what type is this result and then use
                                                    {'name1'=&gt;'@' for binary files, and a regular
                                                    return for non-binary files
            results ( 'name=?', ...)             =&gt; ditto

           Retrieving ALL results:
           -----------------------
            results()     =&gt; return all results as they are, no storing into files

            results ('@') =&gt; return all results, as if each of them given
                             as {'name' =&gt; '@'} (see above)

            results ('?') =&gt; return all results, as if each of them given
                             as {'name' =&gt; '?'} (see above)

           Misc:
           -----
            * any result can be returned as a scalar value, or as an array reference
              (the latter is used for results consisting of more parts, such images);
              this applies regardless whether the returned result is the result itself
              or a filename created for the result

            * look in the documentation of the C&lt;panalysis[.PLS]&gt; script for examples
              (especially how to use various templates for inventing file names)

   <b>result</b>
        Usage   : $job-&gt;result (...)
        Returns : the first result
        Args    : see 'results'

   <b>remove</b>
        Usage   : $job-&gt;remove
        Returns : 1
        Args    : none

       The job object is not actually removed in this time but it is marked  (setting  1  to  "_destroy_on_exit"
       attribute)  as  ready  for deletion when the client program ends (including a request to server to forget
       the job mirror object on the server side).

perl v5.32.1                                       2021-08-15                                <u>Bio::<a href="../man3pm/AnalysisI.3pm.html">AnalysisI</a></u>(3pm)
</pre>
 </div>
</div></section>
</div>
</body>
</html>