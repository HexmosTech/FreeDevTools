<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MPI_Init -  Initialize the MPI execution environment</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/lam-mpidoc">lam-mpidoc_7.1.4-7.2_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       MPI_Init -  Initialize the MPI execution environment

</pre><h4><b>SYNOPSIS</b></h4><pre>
       #include &lt;mpi.h&gt;
       int MPI_Init(int *pargc, char ***pargv)

</pre><h4><b>INPUT</b> <b>PARAMETERS</b></h4><pre>
       <b>pargc</b>  - Pointer to the number of arguments
       <b>pargv</b>  - Pointer to the argument vector

</pre><h4><b>NOTES</b></h4><pre>
       MPI  specifies  no  command-line  arguments  but  does  allow  an MPI implementation to make use of them.
       LAM/MPI neither uses nor adds any values to the <u>argc</u> and <u>argv</u> parameters.  As such, it is legal  to  pass
       <u>NULL</u> for both <u>argc</u> and <u>argv</u> in LAM/MPI.

       Instead,  LAM/MPI relies upon the <u>mpirun</u> command to pass meta-information between nodes in order to start
       MPI programs (of course, the LAM daemons must have previously been launched with  the  <u>lamboot</u>  command).
       As  such,  every rank in <u>MPI_COMM_WORLD</u> will receive the <u>argc</u> and <u>argv</u> that was specified with the <u>mpirun</u>
       command (either via the <u>mpirun</u> command line or an app schema) as soon as <u>main</u> begins.  See the <u>mpirun</u> (1)
       man page for more information.

       If <u>mpirun</u> is <u>not</u> used to start MPI programs, the resulting process will be rank 0 in <u>MPI_COMM_WORLD</u> , and
       <u>MPI_COMM_WORLD</u> will have a size of 1.  This is known as a "singleton" MPI.  It should be noted  that  LAM
       daemons  are  still  used for singleton MPI programs - <u>lamboot</u> must still have been successfully executed
       before running a singleton process.

       LAM/MPI takes care to ensure that the normal Unix process model  of  execution  is  preserved:  no  extra
       threads  or  processes  are  forked  from  the user's process.  Instead, the LAM daemons are used for all
       process management and meta-environment information.  Consequently, LAM/MPI places no restriction on what
       may be invoked before <u>MPI_INIT*</u> or after  <u>MPI_FINALIZE</u>  ;  this  is  <u>not</u>  a  safe  assumption  for  those
       attempting to write portable MPI programs - see "Portability Concerns", below.

       MPI mandates that the same thread must call <u>MPI_INIT</u> (or <u>MPI_INIT_THREAD</u> ) and <u>MPI_FINALIZE</u> .

       Note that the Fortran binding for this routine has only the error return argument ( <u>MPI_INIT(ierror)</u> ).

       Because  the  Fortran  and  C  versions of <u>MPI_INIT</u> are different, there is a restriction on who can call
       <u>MPI_INIT</u> .  The version (Fortran or C) must match the main program.  That is, if the main program  is  in
       C, then the C version of <u>MPI_INIT</u> must be called.  If the main program is in Fortran, the Fortran version
       must be called.

       LAM/MPI  uses  the  value  of argv[0] to identify a process in many of the user-level helper applications
       (mpitask   and   mpimsg,   for   example).    Fortran    programs    are    generally    identified    as
       "LAM_MPI_Fortran_program".   However,  this  name  can  be overridden for Fortran programs by setting the
       environment variable "LAM_MPI_PROCESS_NAME".

       On exit from this routine, all processes will have a copy of the argument list.  This is <u>not</u> <u>required</u>  by
       the MPI standard, and truely portable codes should not rely on it.  This is provided as a service by this
       implementation  (an  MPI  implementation  is  allowed to distribute the command line arguments but is not
       required to).

</pre><h4><b>THREADING</b></h4><pre>
       Applications using <u>MPI_INIT</u> are effectively invoking <u>MPI_INIT_THREAD</u> with a requested thread  support  of
       <u>MPI_THREAD_SINGLE</u>  .  However, this may be overridden with the LAM_MPI_THREAD_LEVEL environment variable.
       If set, this variable replaces the default <u>MPI_THREAD_SINGLE</u> value.  The following values are allowed

       0: Corresponds to <u>MPI_THREAD_SINGLE</u>

       1: Corresponds to <u>MPI_THREAD_FUNNELED</u>

       2: Corresponds to <u>MPI_THREAD_SERIALIZED</u>

       3: Corresponds to <u>MPI_THREAD_MULTIPLE</u>

       See <a href="../man3/MPI_Init_thread.3.html">MPI_Init_thread</a>(3) for more information on thread level support in LAM/MPI.

</pre><h4><b>PREDEFINED</b> <b>ATTRIBUTES</b></h4><pre>
       LAM/MPI defines all required predefined attributes on <u>MPI_COMM_WORLD</u> .  Some values are LAM-specific, and
       require explanation.

       <u>MPI_UNIVERSE_SIZE</u>

       This is an MPI-required attribute.  It is set to an integer whose value indicates how many CPUs  LAM  was
       booted  with.   See  <a href="../man5/bhost.5.html">bhost</a>(5)  and  <a href="../man1/lamboot.1.html">lamboot</a>(1) for more details on how to specify multiple CPUs per node.
       Note that this may be larger than the number of CPUs in <u>MPI_COMM_WORLD</u> .

       <u>LAM_UNIVERSE_NCPUS</u>

       This is a LAM-specific attribute -- it will not be defined in other MPI implementations.  It is  actually
       just a synonym for <u>MPI_UNIVERSE_SIZE</u> -- it contains the number of CPUs in the current LAM universe.  Note
       that this may be larger than the number of CPUs in <u>MPI_COMM_WORLD</u> .

       <u>LAM_UNIVERSE_NNODES</u>

       This  is  a  LAM-specific attribute -- it will not be defined in other MPI implementations.  It indicates
       the total number of nodes in the current LAM universe (which may be different from the  total  number  of
       CPUs).  Node that this may be larger than the number of nodes in <u>MPI_COMM_WORLD</u> .

</pre><h4><b>SIGNALS</b> <b>USED</b></h4><pre>
       The  LAM  implementation  of  MPI  uses, by default, <u>SIGUSR2</u> .  This may be changed when LAM is compiled,
       however, with the <u>--with-signal</u> command line switch to  LAM's  <u>configure</u>  script.   Consult  your  system
       administrator to see if they specified a different signal when LAM was installed.

       LAM/MPI  does  not  catch  any  other signals in user code, by default.  If a process terminates due to a
       signal, the mpirun will be notified of this and will print out an appropriate error message and kill  the
       rest of the user MPI application.

       This  behavior  can be overridden (mainly for historical reasons) with the "-sigs" flag to <u>mpirun</u> .  When
       "-sigs" is used, LAM/MPI will effectively transfer the signal-handling  code  from  mpirun  to  the  user
       program.   Signal  handlers  will  be  installed during <u>MPI_INIT</u> (or <u>MPI_INIT_THREAD</u> ) for the purpose of
       printing error messages before invoking the next signal  handler.   That  is,  LAM  "chains"  its  signal
       handler to be executed before the signal handler that was already set.

       Therefore,  it  is safe for users to set their own signal handlers.  If they wish the LAM signal handlers
       to be executed as well, users should set their handlers before <u>MPI_INIT*</u> is invoked.

       LAM/MPI catches the following signals

       <u>SIGSEGV</u> , <u>SIGBUS</u> , <u>SIGFPE</u> , <u>SIGILL</u>

       All other signals are unused by LAM/MPI, and will be passed to their respective signal handlers.

</pre><h4><b>PORTABILITY</b> <b>CONCERNS</b></h4><pre>
       Portable MPI programs <u>cannot</u> assume the same process model that LAM uses (i.e., essentially the  same  as
       POSIX).   MPI  does  not  mandate  anything  before  <u>MPI_INIT</u>  (or  <u>MPI_INIT_THREAD</u> ), nor anything after
       <u>MPI_FINALIZE</u> executes.  Different MPI implementations make different  assumptions;  some  fork  auxillary
       threads  and/or  processes  to  "help"  with  the  MPI  run-time environment (this may interfere with the
       constructors and destructors of global C++ objects, particularly in the  case  where  using  atexit()  or
       onexit(),  for  example).   As  such, if you are writing a portable MPI program, you cannot make the same
       assumptions that LAM/MPI does.

       In general, it is safest to call <u>MPI_INIT</u> (or <u>MPI_INIT_THREAD</u> ) as soon as possible  after  <u>main</u>  begins,
       and  call  <u>MPI_FINALIZE</u> immediately before the program is supposed to end.  Consult the documentation for
       each MPI implementation for their intialize and finalize behavior.

</pre><h4><b>ERRORS</b></h4><pre>
       If an error occurs in an MPI function, the current MPI error handler is called to handle it.  By default,
       this error handler aborts the MPI job.  The error handler may be changed with  <u>MPI_Errhandler_set</u>  ;  the
       predefined  error  handler  <u>MPI_ERRORS_RETURN</u>  may be used to cause error values to be returned (in C and
       Fortran; this error handler is less useful in with the C++ MPI bindings.  The  predefined  error  handler
       <u>MPI::ERRORS_THROW_EXCEPTIONS</u>  should be used in C++ if the error value needs to be recovered).  Note that
       MPI does <u>not</u> guarantee that an MPI program can continue past an error.

       All MPI routines (except <u>MPI_Wtime</u> and <u>MPI_Wtick</u> ) return an error value; C routines as the value of  the
       function and Fortran routines in the last argument.  The C++ bindings for MPI do not return error values;
       instead,  error  values  are  communicated  by  throwing  exceptions  of  type <u>MPI::Exception</u> (but not by
       default).  Exceptions are only thrown if the error value is not <u>MPI::SUCCESS</u> .

       Note that if the <u>MPI::ERRORS_RETURN</u> handler is set in C++, while MPI functions will return upon an error,
       there will be no way to recover what the actual error value was.
       <b>MPI_SUCCESS</b>
              - No error; MPI routine completed successfully.
       <b>MPI_ERR_OTHER</b>
              - This error class is associated with an error code that indicates that an  attempt  was  made  to
              call <u>MPI_INIT</u> a second time.  <u>MPI_INIT</u> may only be called once in a program.
       <b>MPI_ERR_OTHER</b>
              - Other error; use <u>MPI_Error_string</u> to get more information about this error code.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       MPI_Init_thread, MPI_Finalize, lamboot, mpirun, lamhalt, lamssi

</pre><h4><b>MORE</b> <b>INFORMATION</b></h4><pre>
       For  more  information,  please  see the official MPI Forum web site, which contains the text of both the
       MPI-1 and MPI-2 standards.  These documents contain detailed information about each MPI function (most of
       which is not duplicated in these man pages).

       <u><a href="http://www.mpi-forum.org/">http://www.mpi-forum.org/</a></u>

</pre><h4><b>ACKNOWLEDGEMENTS</b></h4><pre>
       The LAM Team would like the thank the MPICH Team for the handy program to generate man  pages  ("doctext"
       from  <u><a href="ftp://ftp.mcs.anl.gov/pub/sowing/sowing.tar.gz">ftp://ftp.mcs.anl.gov/pub/sowing/sowing.tar.gz</a></u> ), the initial formatting, and some initial text for
       most of the MPI-1 man pages.

</pre><h4><b>LOCATION</b></h4><pre>
       init.c

LAM/MPI 7.1.4                                       6/24/2006                                        <u><a href="../man3/MPI_Init.3.html">MPI_Init</a></u>(3)
</pre>
 </div>
</div></section>
</div>
</body>
</html>