<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>fprof - A Time Profiling Tool using trace to file for minimal runtime performance impact.</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/jammy/+package/erlang-manpages">erlang-manpages_24.2.1+dfsg-1ubuntu0.5_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       fprof - A Time Profiling Tool using trace to file for minimal runtime performance impact.

</pre><h4><b>DESCRIPTION</b></h4><pre>
       This  module  is  used  to profile a program to find out how the execution time is used. Trace to file is
       used to minimize runtime performance impact.

       The <u>fprof</u> module uses tracing to collect profiling data, hence there is no need for  special  compilation
       of  any  module to be profiled. When it starts tracing, <u>fprof</u> will erase all previous tracing in the node
       and set the necessary trace flags on the profiling target processes as well as local call  trace  on  all
       functions  in  all loaded modules and all modules to be loaded. <u>fprof</u> erases all tracing in the node when
       it stops tracing.

       <u>fprof</u> presents both <u>own</u> <u>time</u> i.e how much time a function has used for its own execution, and <u>accumulated</u>
       <u>time</u> i.e including called functions. All presented times are  collected  using  trace  timestamps.  <u>fprof</u>
       tries  to  collect  cpu  time  timestamps, if the host machine OS supports it. Therefore the times may be
       wallclock times and OS scheduling will randomly strike all called functions in a presumably fair way.

       If, however, the profiling time is short, and the host machine OS does not support  high  resolution  cpu
       time measurements, some few OS schedulings may show up as ridiculously long execution times for functions
       doing  practically  nothing.  An  example  of a function more or less just composing a tuple in about 100
       times the normal execution time has been seen, and when the tracing  was  repeated,  the  execution  time
       became normal.

       Profiling is essentially done in 3 steps:

         <u>1</u>:
           Tracing;  to  file,  as  mentioned in the previous paragraph. The trace contains entries for function
           calls, returns to function, process scheduling,  other  process  related  (spawn,  etc)  events,  and
           garbage collection. All trace entries are timestamped.

         <u>2</u>:
           Profiling;  the  trace  file  is read, the execution call stack is simulated, and raw profile data is
           calculated from the simulated call stack and the trace timestamps. The profile data is stored in  the
           <u>fprof</u> server state. During this step the trace data may be dumped in text format to file or console.

         <u>3</u>:
           Analysing;  the  raw  profile  data  is  sorted, filtered and dumped in text format either to file or
           console. The text format intended to be both readable for a human reader, as well  as  parsable  with
           the standard erlang parsing tools.

       Since  <u>fprof</u>  uses  trace  to  file, the runtime performance degradation is minimized, but still far from
       negligible, especially for programs that use the filesystem heavily by themselves. Where  you  place  the
       trace  file is also important, e.g on Solaris <u><a href="file:/tmp">/tmp</a></u> is usually a good choice since it is essentially a RAM
       disk, while any NFS (network) mounted disk is a bad idea.

       <u>fprof</u> can also skip the file step and trace to a tracer process that does the profiling in runtime.

</pre><h4><b>EXPORTS</b></h4><pre>
       <b>start()</b> <b>-&gt;</b> <b>{ok,</b> <b>Pid}</b> <b>|</b> <b>{error,</b> <b>{already_started,</b> <b>Pid}}</b>

              Types:

                 Pid = pid()

              Starts the <u>fprof</u> server.

              Note that it seldom needs to be started explicitly  since  it  is  automatically  started  by  the
              functions that need a running server.

       <b>stop()</b> <b>-&gt;</b> <b>ok</b>

              Same as <u>stop(normal)</u>.

       <b>stop(Reason)</b> <b>-&gt;</b> <b>ok</b>

              Types:

                 Reason = term()

              Stops the <u>fprof</u> server.

              The  supplied <u>Reason</u> becomes the exit reason for the server process. Default Any <u>Reason</u> other than
              <u>kill</u> sends a request to the server and waits for it to clean up, reply  and  exit.  If  <u>Reason</u>  is
              <u>kill</u>, the server is bluntly killed.

              If the <u>fprof</u> server is not running, this function returns immediately with the same return value.

          <b>Note:</b>
              When the <u>fprof</u> server is stopped the collected raw profile data is lost.

       <b>apply(Func,</b> <b>Args)</b> <b>-&gt;</b> <b>term()</b>

              Types:

                 Func = function() | {Module :: module(), Function :: atom()}
                 Args = [term()]

              Same as <u>apply(Func,</u> <u>Args,</u> <u>[])</u>.

       <b>apply(Module,</b> <b>Function,</b> <b>Args)</b> <b>-&gt;</b> <b>term()</b>

              Types:

                 Module = module()
                 Function = atom()
                 Args = [term()]

              Same as <u>apply({Module,</u> <u>Function},</u> <u>Args,</u> <u>[])</u>.

       <b>apply(Func,</b> <b>Args,</b> <b>OptionList)</b> <b>-&gt;</b> <b>term()</b>

              Types:

                 Func = function() | {Module :: module(), Function :: atom()}
                 Args = [term()]
                 OptionList = [Option]
                 Option = apply_option()
                 <b>apply_option()</b> =
                     continue |
                     {procs, PidList :: [pid()]} |
                     start |
                     (TraceStartOption :: trace_option())
                 <b>trace_option()</b> =
                     cpu_time |
                     {cpu_time, boolean()} |
                     file |
                     {file, Filename :: file:filename()} |
                     {procs, PidSpec :: pid_spec()} |
                     {procs, [PidSpec :: pid_spec()]} |
                     start | stop |
                     {tracer, Tracer :: pid() | port()} |
                     verbose |
                     {verbose, boolean()}
                 <b>pid_spec()</b> = pid() | atom()

              Calls <u>erlang:apply(Func,</u> <u>Args)</u> surrounded by <u>trace([start,</u> <u>...])</u> and <u>trace(stop)</u>.

              Some  effort  is  made to keep the trace clean from unnecessary trace messages; tracing is started
              and stopped from a spawned process while the <u>erlang:apply/2</u> call is made in the  current  process,
              only  surrounded  by  <u>receive</u>  and  <u>send</u>  statements towards the trace starting process. The trace
              starting process exits when not needed any more.

              The <u>TraceStartOption</u> is any option allowed for <u>trace/1</u>. The  options  <u>[start,</u>  <u>{procs,</u>  <u>[self()</u>  <u>|</u>
              <u>PidList]}</u>  <u>|</u>  <u>OptList]</u>  are given to <u>trace/1</u>, where <u>OptList</u> is <u>OptionList</u> with <u>continue</u>, <u>start</u> and
              <u>{procs,</u> <b>_</b><u>}</u> options removed.

              The <u>continue</u> option inhibits the call to <u>trace(stop)</u> and leaves  it  up  to  the  caller  to  stop
              tracing at a suitable time.

       <b>apply(Module,</b> <b>Function,</b> <b>Args,</b> <b>OptionList)</b> <b>-&gt;</b> <b>term()</b>

              Types:

                 Module = module()
                 Function = atom()
                 Args = [term()]
                 OptionList = [Option]
                 Option = apply_option()
                 <b>apply_option()</b> =
                     continue |
                     {procs, PidList :: [pid()]} |
                     start |
                     (TraceStartOption :: trace_option())
                 <b>trace_option()</b> =
                     cpu_time |
                     {cpu_time, boolean()} |
                     file |
                     {file, Filename :: file:filename()} |
                     {procs, PidSpec :: pid_spec()} |
                     {procs, [PidSpec :: pid_spec()]} |
                     start | stop |
                     {tracer, Tracer :: pid() | port()} |
                     verbose |
                     {verbose, boolean()}
                 <b>pid_spec()</b> = pid() | atom()

              Same as <u>apply({Module,</u> <u>Function},</u> <u>Args,</u> <u>OptionList)</u>.

              <u>OptionList</u> is an option list allowed for <u>apply/3</u>.

       <b>trace(OptionName</b> <b>::</b> <b>start,</b> <b>Filename)</b> <b>-&gt;</b>
                ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 Filename = file:filename()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>trace([start,</u> <u>{file,</u> <u>Filename}])</u>.

       <b>trace(OptionName</b> <b>::</b> <b>verbose,</b> <b>Filename)</b> <b>-&gt;</b>
                ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 Filename = file:filename()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>trace([start,</u> <u>verbose,</u> <u>{file,</u> <u>Filename}])</u>.

       <b>trace(OptionName,</b> <b>OptionValue)</b> <b>-&gt;</b>
                ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 OptionValue = term()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>trace([{OptionName,</u> <u>OptionValue}])</u>.

       <b>trace(Option</b> <b>::</b> <b>verbose)</b> <b>-&gt;</b>
                ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 ServerPid = pid()
                 Reason = term()

              Same as <u>trace([start,</u> <u>verbose])</u>.

       <b>trace(OptionName)</b> <b>-&gt;</b>
                ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>trace([OptionName])</u>.

       <b>trace(Option</b> <b>::</b> <b>{OptionName,</b> <b>OptionValue})</b> <b>-&gt;</b>
                ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 OptionValue = term()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>trace([{OptionName,</u> <u>OptionValue}])</u>.

       <b>trace(OptionList)</b> <b>-&gt;</b>
                ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionList = [Option]
                 Option = trace_option()
                 ServerPid = pid()
                 Reason = term()
                 <b>trace_option()</b> =
                     cpu_time |
                     {cpu_time, boolean()} |
                     file |
                     {file, Filename :: file:filename()} |
                     {procs, PidSpec :: pid_spec()} |
                     {procs, [PidSpec :: pid_spec()]} |
                     start | stop |
                     {tracer, Tracer :: pid() | port()} |
                     verbose |
                     {verbose, boolean()}
                 <b>pid_spec()</b> = pid() | atom()

              Starts or stops tracing.

              <u>PidSpec</u>  and  <u>Tracer</u> are used in calls to <u>erlang:trace(PidSpec,</u> <u>true,</u> <u>[{tracer,</u> <u>Tracer}</u> <u>|</u> <u>Flags])</u>,
              and <u>Filename</u> is used  to  call  <u>dbg:trace_port(file,</u>  <u>Filename)</u>.  Please  see  <u>erlang:trace/3</u>  and
              <u>dbg:trace_port/2</u>.

              Option description:

                <u>stop</u>:
                  Stops  a running <u>fprof</u> trace and clears all tracing from the node. Either option <u>stop</u> or <u>start</u>
                  must be specified, but not both.

                <u>start</u>:
                  Clears all tracing from the node and starts a new <u>fprof</u> trace. Either  option  <u>start</u>  or  <u>stop</u>
                  must be specified, but not both.

                <u>verbose</u> | <u>{verbose,</u> <u>boolean()}</u>:
                  The  options  <u>verbose</u>  or  <u>{verbose,</u> <u>true}</u> adds some trace flags that <u>fprof</u> does not need, but
                  that may be interesting for general debugging purposes. This option is only allowed  with  the
                  <u>start</u> option.

                <u>cpu_time</u> | <u>{cpu_time,</u> <u>boolean()}</u>:
                  The  options  <u>cpu_time</u>  or  <u>{cpu_time,</u>  <u>true}</u> makes the timestamps in the trace be in CPU time
                  instead of wallclock time which is the default. This option is only  allowed  with  the  <u>start</u>
                  option.

            <b>Warning:</b>
                Getting  correct  values out of cpu_time can be difficult. The best way to get correct values is
                to run using a single scheduler and bind that scheduler to a specific CPU, i.e. <u>erl</u>  <u>+S</u>  <u>1</u>  <u>+sbt</u>
                <u>db</u>.

                <u>{procs,</u> <u>PidSpec}</u> | <u>{procs,</u> <u>[PidSpec]}</u>:
                  Specifies  which  processes  that  shall  be  traced. If this option is not given, the calling
                  process is traced. All processes spawned by the traced processes are also traced. This  option
                  is only allowed with the <u>start</u> option.

                <u>file</u> | <u>{file,</u> <u>Filename}</u>:
                  Specifies the filename of the trace. If the option <u>file</u> is given, or none of these options are
                  given,  the file <u>"fprof.trace"</u> is used. This option is only allowed with the <u>start</u> option, but
                  not with the <u>{tracer,</u> <u>Tracer}</u> option.

                <u>{tracer,</u> <u>Tracer}</u>:
                  Specifies that trace to process or port shall be done instead of trace to file. This option is
                  only allowed with the <u>start</u> option, but not with the <u>{file,</u> <u>Filename}</u> option.

       <b>profile()</b> <b>-&gt;</b> <b>ok</b> <b>|</b> <b>{error,</b> <b>Reason}</b> <b>|</b> <b>{'EXIT',</b> <b>ServerPid,</b> <b>Reason}</b>

              Types:

                 ServerPid = pid()
                 Reason = term()

              Same as <u>profile([])</u>.

       <b>profile(OptionName,</b> <b>OptionValue)</b> <b>-&gt;</b>
                  ok |
                  {ok, Tracer} |
                  {error, Reason} |
                  {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 OptionValue = term()
                 Tracer = ServerPid = pid()
                 Reason = term()

              Same as <u>profile([{OptionName,</u> <u>OptionValue}])</u>.

       <b>profile(OptionName)</b> <b>-&gt;</b>
                  ok |
                  {ok, Tracer} |
                  {error, Reason} |
                  {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 Tracer = ServerPid = pid()
                 Reason = term()

              Same as <u>profile([OptionName])</u>.

       <b>profile(Option</b> <b>::</b> <b>{OptionName,</b> <b>OptionValue})</b> <b>-&gt;</b>
                  ok |
                  {ok, Tracer} |
                  {error, Reason} |
                  {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 OptionValue = term()
                 Tracer = ServerPid = pid()
                 Reason = term()

              Same as <u>profile([{OptionName,</u> <u>OptionValue}])</u>.

       <b>profile(OptionList)</b> <b>-&gt;</b>
                  ok |
                  {ok, Tracer} |
                  {error, Reason} |
                  {'EXIT', ServerPid, Reason}

              Types:

                 OptionList = [Option]
                 Option = profile_option()
                 Tracer = ServerPid = pid()
                 Reason = term()
                 <b>profile_option()</b> =
                     append | dump |
                     {dump, pid() | (Dump :: (Dumpfile :: file:filename() | []))} |
                     file |
                     {file, Filename :: file:filename()} |
                     start | stop

              Compiles a trace into raw profile data held by the <u>fprof</u> server.

              <u>Dumpfile</u> is used to call <u>file:open/2</u>, and <u>Filename</u> is used to call <u>dbg:trace_port(file,</u> <u>Filename)</u>.
              Please see <u>file:open/2</u> and <u>dbg:trace_port/2</u>.

              Option description:

                <u>file</u> | <u>{file,</u> <u>Filename}</u>:
                  Reads the file <u>Filename</u> and creates raw profile data that  is  stored  in  RAM  by  the  <u>fprof</u>
                  server.  If  the  option  <u>file</u>  is  given,  or  none  of  these  options  are  given, the file
                  <u>"fprof.trace"</u> is read. The call will return when the whole trace has been read with the return
                  value <u>ok</u> if successful. This option is not allowed with the <u>start</u> or <u>stop</u> options.

                <u>dump</u> | <u>{dump,</u> <u>Dump}</u>:
                  Specifies the destination for the trace text dump. If this option is not  given,  no  dump  is
                  generated,  if  it  is  <u>dump</u>  the destination will be the caller's group leader, otherwise the
                  destination <u>Dump</u> is either the pid of an I/O device  or  a  filename.  And,  finally,  if  the
                  filename  is  <u>[]</u>  -  <u>"fprof.dump"</u>  is  used  instead. This option is not allowed with the <u>stop</u>
                  option.

                <u>append</u>:
                  Causes the trace text dump to be appended to the destination file. This option is only allowed
                  with the <u>{dump,</u> <u>Dumpfile}</u> option.

                <u>start</u>:
                  Starts a tracer process that profiles trace data in runtime. The call will return  immediately
                  with  the  return  value <u>{ok,</u> <u>Tracer}</u> if successful. This option is not allowed with the <u>stop</u>,
                  <u>file</u> or <u>{file,</u> <u>Filename}</u> options.

                <u>stop</u>:
                  Stops the tracer process that profiles trace data in runtime. The return value will  be  value
                  <u>ok</u> if successful. This option is not allowed with the <u>start</u>, <u>file</u> or <u>{file,</u> <u>Filename}</u> options.

       <b>analyse()</b> <b>-&gt;</b> <b>ok</b> <b>|</b> <b>{error,</b> <b>Reason}</b> <b>|</b> <b>{'EXIT',</b> <b>ServerPid,</b> <b>Reason}</b>

              Types:

                 ServerPid = pid()
                 Reason = term()

              Same as <u>analyse([])</u>.

       <b>analyse(OptionName,</b> <b>OptionValue)</b> <b>-&gt;</b>
                  ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 OptionValue = term()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>analyse([{OptionName,</u> <u>OptionValue}])</u>.

       <b>analyse(OptionName)</b> <b>-&gt;</b>
                  ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>analyse([OptionName])</u>.

       <b>analyse(Option</b> <b>::</b> <b>{OptionName,</b> <b>OptionValue})</b> <b>-&gt;</b>
                  ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionName = atom()
                 OptionValue = term()
                 ServerPid = pid()
                 Reason = term()

              Same as <u>analyse([{OptionName,</u> <u>OptionValue}])</u>.

       <b>analyse(OptionList)</b> <b>-&gt;</b>
                  ok | {error, Reason} | {'EXIT', ServerPid, Reason}

              Types:

                 OptionList = [Option]
                 Option = analyse_option()
                 ServerPid = pid()
                 Reason = term()
                 <b>analyse_option()</b> =
                     append | callers |
                     {callers, boolean()} |
                     {cols, Cols :: integer() &gt;= 0} |
                     dest |
                     {dest, Dest :: pid() | (Destfile :: file:filename())} |
                     details |
                     {details, boolean()} |
                     no_callers | no_details |
                     {sort, SortSpec :: acc | own} |
                     totals |
                     {totals, boolean()}

              Analyses  raw  profile  data  in  the  <u>fprof</u>  server. If called while there is no raw profile data
              available, <u>{error,</u> <u>no_profile}</u> is returned.

              <u>Destfile</u> is used to call <u>file:open/2</u>.

              Option description:

                <u>dest</u> | <u>{dest,</u> <u>Dest}</u>:
                  Specifies the destination for the analysis. If this option is not given or  it  is  <u>dest</u>,  the
                  destination  will  be  the caller's group leader, otherwise the destination <u>Dest</u> is either the
                  <u>pid()</u> of an I/O device or a filename. And, finally, if the filename is <u>[]</u>  -  <u>"fprof.analysis"</u>
                  is used instead.

                <u>append</u>:
                  Causes  the  analysis to be appended to the destination file. This option is only allowed with
                  the <u>{dest,</u> <u>Destfile}</u> option.

                <u>{cols,</u> <u>Cols}</u>:
                  Specifies the number of columns in the analysis text. If this option is not given  the  number
                  of columns is set to 80.

                <u>callers</u> | <u>{callers,</u> <u>true}</u>:
                  Prints callers and called information in the analysis. This is the default.

                <u>{callers,</u> <u>false}</u> | <u>no_callers</u>:
                  Suppresses the printing of callers and called information in the analysis.

                <u>{sort,</u> <u>SortSpec}</u>:
                  Specifies  if the analysis should be sorted according to the ACC column, which is the default,
                  or the OWN column. See Analysis Format below.

                <u>totals</u> | <u>{totals,</u> <u>true}</u>:
                  Includes a section containing call statistics for all calls  regardless  of  process,  in  the
                  analysis.

                <u>{totals,</u> <u>false}</u>:
                  Supresses the totals section in the analysis, which is the default.

                <u>details</u> | <u>{details,</u> <u>true}</u>:
                  Prints call statistics for each process in the analysis. This is the default.

                <u>{details,</u> <u>false}</u> | <u>no_details</u>:
                  Suppresses the call statistics for each process from the analysis.

</pre><h4><b>ANALYSIS</b> <b>FORMAT</b></h4><pre>
       This section describes the output format of the analyse command. See analyse/0.

       The  format  is parsable with the standard Erlang parsing tools <u>erl_scan</u> and <u>erl_parse</u>, <u>file:consult/1</u> or
       <u>io:read/2</u>. The parse format is not explained here - it should be easy for the interested to try  it  out.
       Note that some flags to <u>analyse/1</u> will affect the format.

       The  following example was run on OTP/R8 on Solaris 8, all OTP internals in this example are very version
       dependent.

       As an example, we will use the following  function,  that  you  may  recognise  as  a  slightly  modified
       benchmark function from the manpage <a href="../man3erl/file.3erl.html">file</a>(3erl):

       -module(foo).
       -export([create_file_slow/2]).

       create_file_slow(Name, N) when is_integer(N), N &gt;= 0 -&gt;
           {ok, FD} =
               file:open(Name, [raw, write, delayed_write, binary]),
           if N &gt; 256 -&gt;
                   ok = file:write(FD,
                                   lists:map(fun (X) -&gt; &lt;&lt;X:32/unsigned&gt;&gt; end,
                                   lists:seq(0, 255))),
                   ok = create_file_slow(FD, 256, N);
              true -&gt;
                   ok = create_file_slow(FD, 0, N)
           end,
           ok = file:close(FD).

       create_file_slow(FD, M, M) -&gt;
           ok;
       create_file_slow(FD, M, N) -&gt;
           ok = file:write(FD, &lt;&lt;M:32/unsigned&gt;&gt;),
           create_file_slow(FD, M+1, N).

       Let us have a look at the printout after running:

       1&gt; fprof:apply(foo, create_file_slow, [junk, 1024]).
       2&gt; fprof:profile().
       3&gt; fprof:analyse().

       The printout starts with:

       %% Analysis results:
       {  analysis_options,
        [{callers, true},
         {sort, acc},
         {totals, false},
         {details, true}]}.

       %                                       CNT       ACC       OWN
       [{ totals,                             9627, 1691.119, 1659.074}].  %%%

       The CNT column shows the total number of function calls that was found in the trace. In the ACC column is
       the  total  time  of  the  trace  from  first  timestamp to last. And in the OWN column is the sum of the
       execution time in functions found in the trace, not including called functions. In this case it  is  very
       close  to  the  ACC  time  since the emulator had practically nothing else to do than to execute our test
       program.

       All time values in the printout are in milliseconds.

       The printout continues:

       %                                       CNT       ACC       OWN
       [{ "&lt;0.28.0&gt;",                         9627,undefined, 1659.074}].   %%

       This is the printout header of one process. The printout contains only this  one  process  since  we  did
       <u>fprof:apply/3</u>  which traces only the current process. Therefore the CNT and OWN columns perfectly matches
       the totals above. The ACC column is undefined since summing the ACC times of all  calls  in  the  process
       makes  no  sense - you would get something like the ACC value from totals above multiplied by the average
       depth of the call stack, or something.

       All paragraphs up to the next process header only concerns function calls within this process.

       Now we come to something more interesting:

       {[{undefined,                             0, 1691.076,    0.030}],
        { {fprof,apply_start_stop,4},            0, 1691.076,    0.030},     %
        [{{foo,create_file_slow,2},              1, 1691.046,    0.103},
         {suspend,                               1,    0.000,    0.000}]}.

       {[{{fprof,apply_start_stop,4},            1, 1691.046,    0.103}],
        { {foo,create_file_slow,2},              1, 1691.046,    0.103},     %
        [{{file,close,1},                        1, 1398.873,    0.019},
         {{foo,create_file_slow,3},              1,  249.678,    0.029},
         {{file,open,2},                         1,   20.778,    0.055},
         {{lists,map,2},                         1,   16.590,    0.043},
         {{lists,seq,2},                         1,    4.708,    0.017},
         {{file,write,2},                        1,    0.316,    0.021}]}.

       The printout consists of one paragraph per called function. The function <u>marked</u> with '%' is the  one  the
       paragraph  concerns - <u>foo:create_file_slow/2</u>. Above the marked function are the <u>calling</u> functions - those
       that has called the marked, and below are those <u>called</u> by the marked function.

       The paragraphs are per default sorted in decreasing order of the ACC column for the marked function.  The
       calling  list  and  called  list  within one paragraph are also per default sorted in decreasing order of
       their ACC column.

       The columns are: CNT - the number of times the function has been called, ACC -  the  time  spent  in  the
       function  including  called  functions,  and  OWN  -  the time spent in the function not including called
       functions.

       The rows for the <u>calling</u> functions contain statistics for the <u>marked</u> function with  the  constraint  that
       only the occasions when a call was made from the <u>row's</u> function to the <u>marked</u> function are accounted for.

       The row for the <u>marked</u> function simply contains the sum of all <u>calling</u> rows.

       The  rows  for  the  <u>called</u> functions contains statistics for the <u>row's</u> function with the constraint that
       only the occasions when a call was made from the <u>marked</u> to the <u>row's</u> function are accounted for.

       So, we see that <u>foo:create_file_slow/2</u> used very little time for its own execution. It spent most of  its
       time  in  <u>file:close/1</u>.  The  function <u>foo:create_file_slow/3</u> that writes 3/4 of the file contents is the
       second biggest time thief.

       We also see that the call to <u>file:write/2</u> that writes 1/4 of the file contents takes very little time  in
       itself. What takes time is to build the data (<u>lists:seq/2</u> and <u>lists:map/2</u>).

       The  function  'undefined'  that  has called <u>fprof:apply_start_stop/4</u> is an unknown function because that
       call  was  not  recorded  in  the  trace.  It  was  only  recorded  that  the  execution  returned   from
       <u>fprof:apply_start_stop/4</u>  to some other function above in the call stack, or that the process exited from
       there.

       Let us continue down the printout to find:

       {[{{foo,create_file_slow,2},              1,  249.678,    0.029},
         {{foo,create_file_slow,3},            768,    0.000,   23.294}],
        { {foo,create_file_slow,3},            769,  249.678,   23.323},     %
        [{{file,write,2},                      768,  220.314,   14.539},
         {suspend,                              57,    6.041,    0.000},
         {{foo,create_file_slow,3},            768,    0.000,   23.294}]}.

       If you compare with the code you will see there also that <u>foo:create_file_slow/3</u>  was  called  only  from
       <u>foo:create_file_slow/2</u>   and  itself,  and  called  only  <u>file:write/2</u>,  note  the  number  of  calls  to
       <u>file:write/2</u>. But here we see that <u>suspend</u> was called a  few  times.  This  is  a  pseudo  function  that
       indicates that the process was suspended while executing in <u>foo:create_file_slow/3</u>, and since there is no
       <u>receive</u> or <u>erlang:yield/0</u> in the code, it must be Erlang scheduling suspensions, or the trace file driver
       compensating for large file write operations (these are regarded as a schedule out followed by a schedule
       in to the same process).

       Let us find the <u>suspend</u> entry:

       {[{{file,write,2},                       53,    6.281,    0.000},
         {{foo,create_file_slow,3},             57,    6.041,    0.000},
         {{prim_file,drv_command,4},            50,    4.582,    0.000},
         {{prim_file,drv_get_response,1},       34,    2.986,    0.000},
         {{lists,map,2},                        10,    2.104,    0.000},
         {{prim_file,write,2},                  17,    1.852,    0.000},
         {{erlang,port_command,2},              15,    1.713,    0.000},
         {{prim_file,drv_command,2},            22,    1.482,    0.000},
         {{prim_file,translate_response,2},     11,    1.441,    0.000},
         {{prim_file,'-drv_command/2-fun-0-',1},  15,    1.340,    0.000},
         {{lists,seq,4},                         3,    0.880,    0.000},
         {{foo,'-create_file_slow/2-fun-0-',1},   5,    0.523,    0.000},
         {{erlang,bump_reductions,1},            4,    0.503,    0.000},
         {{prim_file,open_int_setopts,3},        1,    0.165,    0.000},
         {{prim_file,i32,4},                     1,    0.109,    0.000},
         {{fprof,apply_start_stop,4},            1,    0.000,    0.000}],
        { suspend,                             299,   32.002,    0.000},     %
        [ ]}.

       We  find  no  particulary long suspend times, so no function seems to have waited in a receive statement.
       Actually, <u>prim_file:drv_command/4</u> contains a receive statement, but in this  test  program,  the  message
       lies  in  the  process  receive  buffer when the receive statement is entered. We also see that the total
       suspend time for the test run is small.

       The <u>suspend</u> pseudo function has got an OWN time of zero. This is to prevent the process  total  OWN  time
       from  including  time  in  suspension.  Whether  suspend  time  is  really  ACC  or OWN time is more of a
       philosophical question.

       Now we look at another interesting pseudo function, <u>garbage_collect</u>:

       {[{{prim_file,drv_command,4},            25,    0.873,    0.873},
         {{prim_file,write,2},                  16,    0.692,    0.692},
         {{lists,map,2},                         2,    0.195,    0.195}],
        { garbage_collect,                      43,    1.760,    1.760},     %
        [ ]}.

       Here we see that no function distinguishes itself considerably, which is very normal.

       The <u>garbage_collect</u> pseudo function has not got an OWN time of zero like <u>suspend</u>, instead it is equal  to
       the ACC time.

       Garbage  collect  often occurs while a process is suspended, but <u>fprof</u> hides this fact by pretending that
       the suspended function was first unsuspended and then garbage collected.  Otherwise  the  printout  would
       show  <u>garbage_collect</u> being called from <u>suspend</u> but not which function that might have caused the garbage
       collection.

       Let us now get back to the test code:

       {[{{foo,create_file_slow,3},            768,  220.314,   14.539},
         {{foo,create_file_slow,2},              1,    0.316,    0.021}],
        { {file,write,2},                      769,  220.630,   14.560},     %
        [{{prim_file,write,2},                 769,  199.789,   22.573},
         {suspend,                              53,    6.281,    0.000}]}.

       Not   unexpectedly,   we   see   that   <u>file:write/2</u>   was   called   from   <u>foo:create_file_slow/3</u>   and
       <u>foo:create_file_slow/2</u>.  The number of calls in each case as well as the used time are also just confirms
       the previous results.

       We see that <u>file:write/2</u> only calls <u>prim_file:write/2</u>, but let us refrain from digging into the internals
       of the kernel application.

       But, if we nevertheless <u>do</u> dig down we find the  call  to  the  linked  in  driver  that  does  the  file
       operations towards the host operating system:

       {[{{prim_file,drv_command,4},           772, 1458.356, 1456.643}],
        { {erlang,port_command,2},             772, 1458.356, 1456.643},     %
        [{suspend,                              15,    1.713,    0.000}]}.

       This is 86 % of the total run time, and as we saw before it is the close operation the absolutely biggest
       contributor. We find a comparison ratio a little bit up in the call stack:

       {[{{prim_file,close,1},                   1, 1398.748,    0.024},
         {{prim_file,write,2},                 769,  174.672,   12.810},
         {{prim_file,open_int,4},                1,   19.755,    0.017},
         {{prim_file,open_int_setopts,3},        1,    0.147,    0.016}],
        { {prim_file,drv_command,2},           772, 1593.322,   12.867},     %
        [{{prim_file,drv_command,4},           772, 1578.973,   27.265},
         {suspend,                              22,    1.482,    0.000}]}.

       The  time  for file operations in the linked in driver distributes itself as 1 % for open, 11 % for write
       and 87 % for close. All data is probably buffered in the operating system until the close.

       The   unsleeping   reader   may   notice   that   the   ACC   times   for   <u>prim_file:drv_command/2</u>   and
       <u>prim_file:drv_command/4</u> is not equal between the paragraphs above, even though it is easy to believe that
       <u>prim_file:drv_command/2</u> is just a passthrough function.

       The  missing  time can be found in the paragraph for <u>prim_file:drv_command/4</u> where it is evident that not
       only <u>prim_file:drv_command/2</u> is called but also a fun:

       {[{{prim_file,drv_command,2},           772, 1578.973,   27.265}],
        { {prim_file,drv_command,4},           772, 1578.973,   27.265},     %
        [{{erlang,port_command,2},             772, 1458.356, 1456.643},
         {{prim_file,'-drv_command/2-fun-0-',1}, 772,   87.897,   12.736},
         {suspend,                              50,    4.582,    0.000},
         {garbage_collect,                      25,    0.873,    0.873}]}.

       And some  more  missing  time  can  be  explained  by  the  fact  that  <u>prim_file:open_int/4</u>  both  calls
       <u>prim_file:drv_command/2</u>  directly  as well as through <u>prim_file:open_int_setopts/3</u>, which complicates the
       picture.

       {[{{prim_file,open,2},                    1,   20.309,    0.029},
         {{prim_file,open_int,4},                1,    0.000,    0.057}],
        { {prim_file,open_int,4},                2,   20.309,    0.086},     %
        [{{prim_file,drv_command,2},             1,   19.755,    0.017},
         {{prim_file,open_int_setopts,3},        1,    0.360,    0.032},
         {{prim_file,drv_open,2},                1,    0.071,    0.030},
         {{erlang,list_to_binary,1},             1,    0.020,    0.020},
         {{prim_file,i32,1},                     1,    0.017,    0.017},
         {{prim_file,open_int,4},                1,    0.000,    0.057}]}.
       {[{{prim_file,open_int,4},                1,    0.360,    0.032},
         {{prim_file,open_int_setopts,3},        1,    0.000,    0.016}],
        { {prim_file,open_int_setopts,3},        2,    0.360,    0.048},     %
        [{suspend,                               1,    0.165,    0.000},
         {{prim_file,drv_command,2},             1,    0.147,    0.016},
         {{prim_file,open_int_setopts,3},        1,    0.000,    0.016}]}.

</pre><h4><b>NOTES</b></h4><pre>
       The actual supervision of execution times is in itself a CPU intensive activity. A message is written  on
       the trace file for every function call that is made by the profiled code.

       The  ACC  time  calculation is sometimes difficult to make correct, since it is difficult to define. This
       happens especially when a function occurs in several instances in the call stack, for example by  calling
       itself perhaps through other functions and perhaps even non-tail recursively.

       To  produce  sensible  results,  <u>fprof</u>  tries not to charge any function more than once for ACC time. The
       instance highest up (with longest duration) in the call stack is chosen.

       Sometimes a function may unexpectedly waste a lot (some 10 ms or more depending on host  machine  OS)  of
       OWN (and ACC) time, even functions that do practically nothing at all. The problem may be that the OS has
       chosen to schedule out the Erlang runtime system process for a while, and if the OS does not support high
       resolution  cpu  time measurements <u>fprof</u> will use wallclock time for its calculations, and it will appear
       as functions randomly burn virtual machine time.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <a href="../man3erl/dbg.3erl.html">dbg</a>(3erl), <a href="../man3erl/eprof.3erl.html">eprof</a>(3erl), <a href="../man3erl/erlang.3erl.html">erlang</a>(3erl), <a href="../man3erl/io.3erl.html">io</a>(3erl), Tools User's Guide

Ericsson AB                                        tools 3.5.2                                       <u><a href="../man3erl/fprof.3erl.html">fprof</a></u>(3erl)
</pre>
 </div>
</div></section>
</div>
</body>
</html>