<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pth - GNU Portable Threads</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/jammy/+package/libpth-dev">libpth-dev_2.0.7-22_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       <b>pth</b> - GNU Portable Threads

</pre><h4><b>VERSION</b></h4><pre>
       GNU Pth 2.0.7 (08-Jun-2006)

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>Global</b> <b>Library</b> <b>Management</b>
           pth_init, pth_kill, pth_ctrl, pth_version.

       <b>Thread</b> <b>Attribute</b> <b>Handling</b>
           pth_attr_of, pth_attr_new, pth_attr_init, pth_attr_set, pth_attr_get, pth_attr_destroy.

       <b>Thread</b> <b>Control</b>
           pth_spawn,  pth_once,  pth_self,  pth_suspend,  pth_resume, pth_yield, pth_nap, pth_wait, pth_cancel,
           pth_abort, pth_raise, pth_join, pth_exit.

       <b>Utilities</b>
           pth_fdmode, pth_time, pth_timeout, pth_sfiodisc.

       <b>Cancellation</b> <b>Management</b>
           pth_cancel_point, pth_cancel_state.

       <b>Event</b> <b>Handling</b>
           pth_event, pth_event_typeof, pth_event_extract, pth_event_concat, pth_event_isolate,  pth_event_walk,
           pth_event_status, pth_event_free.

       <b>Key-Based</b> <b>Storage</b>
           pth_key_create, pth_key_delete, pth_key_setdata, pth_key_getdata.

       <b>Message</b> <b>Port</b> <b>Communication</b>
           pth_msgport_create,   pth_msgport_destroy,  pth_msgport_find,  pth_msgport_pending,  pth_msgport_put,
           pth_msgport_get, pth_msgport_reply.

       <b>Thread</b> <b>Cleanups</b>
           pth_cleanup_push, pth_cleanup_pop.

       <b>Process</b> <b>Forking</b>
           pth_atfork_push, pth_atfork_pop, pth_fork.

       <b>Synchronization</b>
           pth_mutex_init,   pth_mutex_acquire,    pth_mutex_release,    pth_rwlock_init,    pth_rwlock_acquire,
           pth_rwlock_release,     pth_cond_init,     pth_cond_await,     pth_cond_notify,     pth_barrier_init,
           pth_barrier_reach.

       <b>User-Space</b> <b>Context</b>
           pth_uctx_create, pth_uctx_make, pth_uctx_switch, pth_uctx_destroy.

       <b>Generalized</b> <b>POSIX</b> <b>Replacement</b> <b>API</b>
           pth_sigwait_ev, pth_accept_ev, pth_connect_ev, pth_select_ev, pth_poll_ev, pth_read_ev, pth_readv_ev,
           pth_write_ev, pth_writev_ev, pth_recv_ev, pth_recvfrom_ev, pth_send_ev, pth_sendto_ev.

       <b>Standard</b> <b>POSIX</b> <b>Replacement</b> <b>API</b>
           pth_nanosleep, pth_usleep, pth_sleep, pth_waitpid, pth_system, pth_sigmask, pth_sigwait,  pth_accept,
           pth_connect,   pth_select,   pth_pselect,   pth_poll,  pth_read,  pth_readv,  pth_write,  pth_writev,
           pth_pread, pth_pwrite, pth_recv, pth_recvfrom, pth_send, pth_sendto.

</pre><h4><b>DESCRIPTION</b></h4><pre>
         ____  _   _
        ⎪  _ \⎪ ⎪_⎪ ⎪__
        ⎪ ⎪_) ⎪ __⎪ '_ \         ``Only those who attempt
        ⎪  __/⎪ ⎪_⎪ ⎪ ⎪ ⎪          the absurd can achieve
        ⎪_⎪    \__⎪_⎪ ⎪_⎪          the impossible.''

       <b>Pth</b> is a very portable POSIX/ANSI-C based  library  for  Unix  platforms  which  provides  non-preemptive
       priority-based  scheduling  for  multiple threads of execution (aka `multithreading') inside event-driven
       applications. All threads run in the same address space of the application process, but each  thread  has
       its own individual program counter, run-time stack, signal mask and "errno" variable.

       The  thread  scheduling itself is done in a cooperative way, i.e., the threads are managed and dispatched
       by a priority- and event-driven non-preemptive scheduler. The intention is  that  this  way  both  better
       portability  and  run-time  performance  is  achieved than with preemptive scheduling. The event facility
       allows threads to wait until various types of internal and external events occur, including  pending  I/O
       on  file  descriptors,  asynchronous  signals,  elapsed  timers, pending I/O on message ports, thread and
       process termination, and even results of customized callback functions.

       <b>Pth</b> also provides an optional emulation API for POSIX.1c threads  (`Pthreads')  which  can  be  used  for
       backward  compatibility  to  existing  multithreaded  applications.  See <b>Pth</b>'s <u><a href="../man3/pthread.3.html">pthread</a></u>(3) manual page for
       details.

       <b>Threading</b> <b>Background</b>

       When programming event-driven applications, usually servers, lots of regular jobs and  one-shot  requests
       have  to  be  processed  in  parallel.   To efficiently simulate this parallel processing on uniprocessor
       machines, we use `multitasking' -- that is, we have the application ask the  operating  system  to  spawn
       multiple  instances  of itself. On Unix, typically the kernel implements multitasking in a preemptive and
       priority-based way through heavy-weight processes spawned with <u><a href="../man2/fork.2.html">fork</a></u>(2).  These processes usually  do  <u>not</u>
       share  a  common  address  space.  Instead they are clearly separated from each other, and are created by
       direct cloning a process address space (although modern kernels use memory segment mapping  and  copy-on-
       write semantics to avoid unnecessary copying of physical memory).

       The  drawbacks  are  obvious:  Sharing data between the processes is complicated, and can usually only be
       done efficiently through shared memory (but which  itself  is  not  very  portable).  Synchronization  is
       complicated  because  of  the preemptive nature of the Unix scheduler (one has to use <u>atomic</u> locks, etc).
       The machine's resources can be exhausted very quickly when the server application has to serve  too  many
       long-running requests (heavy-weight processes cost memory). And when each request spawns a sub-process to
       handle  it,  the  server  performance and responsiveness is horrible (heavy-weight processes cost time to
       spawn). Finally, the server application doesn't scale very well with the load because of  these  resource
       problems.  In  practice,  lots  of tricks are usually used to overcome these problems - ranging from pre-
       forked sub-process pools to semi-serialized processing, etc.

       One of the most elegant ways to solve these resource- and  data-sharing  problems  is  to  have  multiple
       <u>light-weight</u>  threads  of  execution inside a single (heavy-weight) process, i.e., to use <u>multithreading</u>.
       Those <u>threads</u> usually improve responsiveness and  performance  of  the  application,  often  improve  and
       simplify  the  internal  program structure, and most important, require less system resources than heavy-
       weight processes. Threads are neither the optimal run-time facility for all types  of  applications,  nor
       can  all  applications  benefit  from them. But at least event-driven server applications usually benefit
       greatly from using threads.

       <b>The</b> <b>World</b> <b>of</b> <b>Threading</b>

       Even though lots of documents exists which describe and define the world of threading, to understand <b>Pth</b>,
       you need only basic knowledge about threading. The following definitions of thread-related  terms  should
       at least help you understand thread programming enough to allow you to use <b>Pth</b>.

       <b>o</b> <b>process</b> vs. <b>thread</b>
         A  process  on  Unix systems consists of at least the following fundamental ingredients: <u>virtual</u> <u>memory</u>
         <u>table</u>, <u>program</u> <u>code</u>, <u>program</u> <u>counter</u>, <u>heap</u> <u>memory</u>, <u>stack</u> <u>memory</u>, <u>stack</u> <u>pointer</u>,  <u>file</u>  <u>descriptor</u>  <u>set</u>,
         <u>signal</u>  <u>table</u>.  On  every  process  switch,  the  kernel  saves  and restores these ingredients for the
         individual processes. On the other hand, a thread consists of only a  private  program  counter,  stack
         memory,  stack  pointer  and  signal table. All other ingredients, in particular the virtual memory, it
         shares with the other threads of the same process.

       <b>o</b> <b>kernel-space</b> vs. <b>user-space</b> threading
         Threads on a Unix platform traditionally can be implemented either inside kernel-space  or  user-space.
         When  threads  are  implemented  by the kernel, the thread context switches are performed by the kernel
         without the application's knowledge. Similarly, when threads are implemented in user-space, the  thread
         context  switches  are  performed by an application library, without the kernel's knowledge. There also
         are hybrid threading approaches where, typically, a user-space library binds  one  or  more  user-space
         threads  to one or more kernel-space threads (there usually called light-weight processes - or in short
         LWPs).

         User-space threads are usually more portable and can perform faster and cheaper context  switches  (for
         instance  via  <u><a href="../man2/swapcontext.2.html">swapcontext</a></u>(2)  or  <u><a href="../man3/setjmp.3.html">setjmp</a></u>(3)/<u><a href="../man3/longjmp.3.html">longjmp</a></u>(3))  than kernel based threads. On the other hand,
         kernel-space threads can take advantage of multiprocessor machines and  don't  have  any  inherent  I/O
         blocking  problems.  Kernel-space threads are usually scheduled in preemptive way side-by-side with the
         underlying processes. User-space threads on the other hand  use  either  preemptive  or  non-preemptive
         scheduling.

       <b>o</b> <b>preemptive</b> vs. <b>non-preemptive</b> thread scheduling
         In  preemptive  scheduling,  the  scheduler  lets  a  thread  execute until a blocking situation occurs
         (usually a function call which would block) or the assigned timeslice elapses. Then it detracts control
         from the thread without a chance for the thread to object. This is usually realized by interrupting the
         thread through a hardware interrupt signal (for kernel-space threads) or a  software  interrupt  signal
         (for  user-space  threads),  like "SIGALRM" or "SIGVTALRM". In non-preemptive scheduling, once a thread
         received control from the scheduler it keeps it until either  a  blocking  situation  occurs  (again  a
         function  call  which  would block and instead switches back to the scheduler) or the thread explicitly
         yields control back to the scheduler in a cooperative way.

       <b>o</b> <b>concurrency</b> vs. <b>parallelism</b>
         Concurrency exists when at least two threads are <u>in</u> <u>progress</u> at the same time. Parallelism arises  when
         at  least  two  threads  are  <u>executing</u>  simultaneously.  Real  parallelism  can  be  only  achieved on
         multiprocessor machines, of course. But one also usually speaks of parallelism or <u>high</u>  <u>concurrency</u>  in
         the  context  of  preemptive  thread scheduling and of <u>low</u> <u>concurrency</u> in the context of non-preemptive
         thread scheduling.

       <b>o</b> <b>responsiveness</b>
         The responsiveness of a system can be described by the user visible delay until the system responses to
         an external request. When this delay is small enough and the user doesn't recognize a noticeable delay,
         the responsiveness of the system is considered good. When the user recognizes or is even annoyed by the
         delay, the responsiveness of the system is considered bad.

       <b>o</b> <b>reentrant</b>, <b>thread-safe</b> and <b>asynchronous-safe</b> functions
         A reentrant function is one that behaves correctly if it is called simultaneously  by  several  threads
         and then also executes simultaneously.  Functions that access global state, such as memory or files, of
         course,  need  to  be  carefully designed in order to be reentrant. Two traditional approaches to solve
         these problems are caller-supplied states and thread-specific data.

         Thread-safety is the avoidance of <u>data</u> <u>races</u>, i.e., situations in which data is set to  either  correct
         or incorrect value depending upon the (unpredictable) order in which multiple threads access and modify
         the  data.  So  a  function  is  thread-safe  when  it  still  behaves semantically correct when called
         simultaneously by several threads (it is not required that the functions also execute  simultaneously).
         The  traditional  approach  to achieve thread-safety is to wrap a function body with an internal mutual
         exclusion lock (aka `mutex').  As  you  should  recognize,  reentrant  is  a  stronger  attribute  than
         thread-safe,  because  it is harder to achieve and results especially in no run-time contention between
         threads. So, a reentrant function is always thread-safe, but not vice versa.

         Additionally there is a related attribute for functions named asynchronous-safe, which comes into  play
         in  conjunction  with  signal  handlers. This is very related to the problem of reentrant functions. An
         asynchronous-safe function is one that can be called safe and without side-effects from within a signal
         handler context. Usually very few functions are of this type, because an application is very restricted
         in what it can perform from within a signal handler (especially what system functions it is allowed  to
         call).  The  reason  mainly is, because only a few system functions are officially declared by POSIX as
         guaranteed to be asynchronous-safe. Asynchronous-safe functions usually have to be already reentrant.

       <b>User-Space</b> <b>Threads</b>

       User-space threads can be implemented in various way. The two traditional approaches are:

       <b>1.</b> <b>Matrix-based</b> <b>explicit</b> <b>dispatching</b> <b>between</b> <b>small</b> <b>units</b> <b>of</b> <b>execution:</b>

          Here the global procedures of the application are split into small execution units (each  is  required
          to  not  run  for more than a few milliseconds) and those units are implemented by separate functions.
          Then a global matrix is defined which describes the execution (and perhaps even dependency)  order  of
          these  functions.  The  main  server procedure then just dispatches between these units by calling one
          function after each other controlled by this matrix. The threads are created by more  than  one  jump-
          trail  through  this  matrix  and  by  switching between these jump-trails controlled by corresponding
          occurred events.

          This approach gives the best possible performance, because one can fine-tune the threads of  execution
          by  adjusting  the matrix, and the scheduling is done explicitly by the application itself. It is also
          very portable, because the matrix is just an ordinary data structure, and  functions  are  a  standard
          feature of ANSI C.

          The  disadvantage  of  this  approach  is that it is complicated to write large applications with this
          approach, because in those applications one quickly  gets  hundreds(!)  of  execution  units  and  the
          control  flow  inside  such  an  application  is very hard to understand (because it is interrupted by
          function borders and one always  has  to  remember  the  global  dispatching  matrix  to  follow  it).
          Additionally, all threads operate on the same execution stack. Although this saves memory, it is often
          nasty,  because  one  cannot  switch  between threads in the middle of a function. Thus the scheduling
          borders are the function borders.

       <b>2.</b> <b>Context-based</b> <b>implicit</b> <b>scheduling</b> <b>between</b> <b>threads</b> <b>of</b> <b>execution:</b>

          Here the idea is that one programs the application as with forked processes, i.e., one spawns a thread
          of execution and this runs from the begin to the end without an  interrupted  control  flow.  But  the
          control  flow  can  be still interrupted - even in the middle of a function.  Actually in a preemptive
          way, similar to what the kernel does for the heavy-weight processes, i.e., every few milliseconds  the
          user-space  scheduler  switches  between  the  threads  of  execution.  But  the thread itself doesn't
          recognize this and usually (except for synchronization issues) doesn't have to care about this.

          The advantage of this approach is that it's very easy to program, because the control flow and context
          of a thread  directly  follows  a  procedure  without  forced  interrupts  through  function  borders.
          Additionally,  the  programming  is  very  similar  to a traditional and well understood <u><a href="../man2/fork.2.html">fork</a></u>(2) based
          approach.

          The disadvantage is that although the general performance is increased, compared to  using  approaches
          based  on  heavy-weight  processes, it is decreased compared to the matrix-approach above. Because the
          implicit preemptive scheduling does usually a lot more  context  switches  (every  user-space  context
          switch  costs some overhead even when it is a lot cheaper than a kernel-level context switch) than the
          explicit cooperative/non-preemptive scheduling.  Finally, there is  no  really  portable  POSIX/ANSI-C
          based  way  to  implement user-space preemptive threading. Either the platform already has threads, or
          one has to hope that some semi-portable package exists for it. And even those  semi-portable  packages
          usually  have  to  deal  with  assembler  code  and  other nasty internals and are not easy to port to
          forthcoming platforms.

       So, in short: the matrix-dispatching approach is portable and fast, but  nasty  to  program.  The  thread
       scheduling  approach is easy to program, but suffers from synchronization and portability problems caused
       by its preemptive nature.

       <b>The</b> <b>Compromise</b> <b>of</b> <b>Pth</b>

       But why not combine the good aspects of both approaches while avoiding their bad aspects? That's the goal
       of <b>Pth</b>. <b>Pth</b> implements easy-to-program threads of  execution,  but  avoids  the  problems  of  preemptive
       scheduling by using non-preemptive scheduling instead.

       This  sounds  like,  and  is,  a  useful approach. Nevertheless, one has to keep the implications of non-
       preemptive thread scheduling in mind when working with <b>Pth</b>. The following list summarizes a few essential
       points:

       <b>o</b> <b>Pth</b> <b>provides</b> <b>maximum</b> <b>portability,</b> <b>but</b> <b>NOT</b> <b>the</b> <b>fanciest</b> <b>features</b>.

         This is, because it uses a nifty and portable POSIX/ANSI-C approach for thread creation (and  this  way
         doesn't require any platform dependent assembler hacks) and schedules the threads in non-preemptive way
         (which  doesn't  require  unportable  facilities like "SIGVTALRM"). On the other hand, this way not all
         fancy threading features can be implemented.  Nevertheless  the  available  facilities  are  enough  to
         provide a robust and full-featured threading system.

       <b>o</b> <b>Pth</b>  <b>increases</b>  <b>the</b>  <b>responsiveness</b>  <b>and</b>  <b>concurrency</b>  <b>of</b>  <b>an</b>  <b>event-driven</b>  <b>application,</b>  <b>but</b>  <b>NOT</b> <b>the</b>
         <b>concurrency</b> <b>of</b> <b>number-crunching</b> <b>applications</b>.

         The reason is the non-preemptive scheduling. Number-crunching applications usually  require  preemptive
         scheduling to achieve concurrency because of their long CPU bursts. For them, non-preemptive scheduling
         (even  together  with  explicit  yielding)  provides only the old concept of `coroutines'. On the other
         hand, event driven applications benefit greatly from non-preemptive scheduling. They  have  only  short
         CPU  bursts  and  lots  of  events  to wait on, and this way run faster under non-preemptive scheduling
         because no unnecessary context switching occurs, as it is the case for  preemptive  scheduling.  That's
         why <b>Pth</b> is mainly intended for server type applications, although there is no technical restriction.

       <b>o</b> <b>Pth</b> <b>requires</b> <b>thread-safe</b> <b>functions,</b> <b>but</b> <b>NOT</b> <b>reentrant</b> <b>functions</b>.

         This  nice fact exists again because of the nature of non-preemptive scheduling, where a function isn't
         interrupted and this way cannot be reentered before it returned. This is a great  portability  benefit,
         because  thread-safety  can  be achieved more easily than reentrance possibility. Especially this means
         that under <b>Pth</b> more existing third-party libraries can be used without side-effects than it's the  case
         for other threading systems.

       <b>o</b> <b>Pth</b> <b>doesn't</b> <b>require</b> <b>any</b> <b>kernel</b> <b>support,</b> <b>but</b> <b>can</b> <b>NOT</b> <b>benefit</b> <b>from</b> <b>multiprocessor</b> <b>machines</b>.

         This  means  that  <b>Pth</b> runs on almost all Unix kernels, because the kernel does not need to be aware of
         the <b>Pth</b> threads (because they are implemented entirely in user-space). On the  other  hand,  it  cannot
         benefit  from  the  existence  of multiprocessors, because for this, kernel support would be needed. In
         practice, this is no problem, because multiprocessor systems are rare, and portability is  almost  more
         important than highest concurrency.

       <b>The</b> <b>life</b> <b>cycle</b> <b>of</b> <b>a</b> <b>thread</b>

       To  understand  the  <b>Pth</b>  Application  Programming Interface (API), it helps to first understand the life
       cycle of a thread in the <b>Pth</b> threading system. It can be illustrated with the following directed graph:

                    NEW
                     ⎪
                     V
             +---&gt; READY ---+
             ⎪       ^      ⎪
             ⎪       ⎪      V
          WAITING &lt;--+-- RUNNING
                            ⎪
             :              V
          SUSPENDED       DEAD

       When a new thread is created, it is moved into the <b>NEW</b> queue of the scheduler. On  the  next  dispatching
       for  this  thread,  the scheduler picks it up from there and moves it to the <b>READY</b> queue. This is a queue
       containing all threads which want to perform a CPU burst. There they are queued  in  priority  order.  On
       each  dispatching  step,  the scheduler always removes the thread with the highest priority only. It then
       increases the priority of all remaining threads by 1, to prevent them from `starving'.

       The thread which was removed from the <b>READY</b> queue is the new <b>RUNNING</b> thread (there  is  always  just  one
       <b>RUNNING</b>  thread,  of  course). The <b>RUNNING</b> thread is assigned execution control. After this thread yields
       execution (either explicitly by yielding execution or implicitly by calling a function which would block)
       there are three possibilities: Either it has terminated, then it is moved to the <b>DEAD</b> queue,  or  it  has
       events on which it wants to wait, then it is moved into the <b>WAITING</b> queue. Else it is assumed it wants to
       perform more CPU bursts and immediately enters the <b>READY</b> queue again.

       Before  the next thread is taken out of the <b>READY</b> queue, the <b>WAITING</b> queue is checked for pending events.
       If one or more events occurred, the threads that are waiting on them are immediately moved to  the  <b>READY</b>
       queue.

       The  purpose  of  the  <b>NEW</b>  queue has to do with the fact that in <b>Pth</b> a thread never directly switches to
       another thread. A thread always yields execution to the scheduler and the  scheduler  dispatches  to  the
       next  thread.  So  a freshly spawned thread has to be kept somewhere until the scheduler gets a chance to
       pick it up for scheduling. That is what the <b>NEW</b> queue is for.

       The purpose of the <b>DEAD</b> queue is to support thread joining. When a thread is marked to be unjoinable,  it
       is  directly  kicked  out  of the system after it terminated. But when it is joinable, it enters the <b>DEAD</b>
       queue. There it remains until another thread joins it.

       Finally, there is a special separated queue named <b>SUSPENDED</b>, to where threads can be manually moved  from
       the  <b>NEW</b>, <b>READY</b> or <b>WAITING</b> queues by the application. The purpose of this special queue is to temporarily
       absorb suspended threads until they are again resumed by the application. Suspended threads do  not  cost
       scheduling  or  event  handling resources, because they are temporarily completely out of the scheduler's
       scope. If a thread is resumed, it is moved back to the queue from where it originally came and  this  way
       again enters the schedulers scope.

</pre><h4><b>APPLICATION</b> <b>PROGRAMMING</b> <b>INTERFACE</b> <b>(API)</b></h4><pre>
       In  the  following  the  <b>Pth</b>  <u>Application</u>  <u>Programming</u>  <u>Interface</u>  (API) is discussed in detail. With the
       knowledge given above, it should now be easy to understand how to program threads with this API. In  good
       Unix  tradition,  <b>Pth</b>  functions use special return values ("NULL" in pointer context, "FALSE" in boolean
       context and "-1" in integer context) to indicate an error condition and set (or pass through) the "errno"
       system variable to pass more details about the error to the caller.

       <b>Global</b> <b>Library</b> <b>Management</b>

       The following functions act on the library as a whole.  They are used  to  initialize  and  shutdown  the
       scheduler and fetch information from it.

       int <b>pth_init</b>(void);
           This initializes the <b>Pth</b> library. It has to be the first <b>Pth</b> API function call in an application, and
           is  mandatory.  It's  usually  done  at  the  begin  of  the <u>main()</u> function of the application. This
           implicitly spawns the internal scheduler thread and transforms  the  single  execution  unit  of  the
           current process into a thread (the `main' thread). It returns "TRUE" on success and "FALSE" on error.

       int <b>pth_kill</b>(void);
           This kills the <b>Pth</b> library. It should be the last <b>Pth</b> API function call in an application, but is not
           really  required.  It's usually done at the end of the main function of the application. At least, it
           has to be called from within the main thread. It implicitly kills all threads and transforms back the
           calling thread into the single execution unit of the underlying process.  The usual way to  terminate
           a  <b>Pth</b>  application is either a simple `"<a href="../man0/pth_exit.0.html">pth_exit</a>(0);"' in the main thread (which waits for all other
           threads to terminate, kills the threading system and then terminates the process) or a  `"pth_kill();
           <a href="../man0/exit.0.html">exit</a>(0)"'  (which  immediately kills the threading system and terminates the process). The <u>pth_kill()</u>
           return immediately with a return code of "FALSE" if it is not called from  within  the  main  thread.
           Else it kills the threading system and returns "TRUE".

       long <b>pth_ctrl</b>(unsigned long <u>query</u>, ...);
           This  is  a  generalized query/control function for the <b>Pth</b> library.  The argument <u>query</u> is a bitmask
           formed out of one or more "PTH_CTRL_"<u>XXXX</u> queries. Currently the following queries are supported:

           "PTH_CTRL_GETTHREADS"
               This returns the total number of threads currently in existence.  This query actually  is  formed
               out   of   the   combination   of   queries   for  threads  in  a  particular  state,  i.e.,  the
               "PTH_CTRL_GETTHREADS" query is equal to the  OR-combination  of  all  the  following  specialized
               queries:

               "PTH_CTRL_GETTHREADS_NEW"  for  the  number  of  threads  in  the  new queue (threads created via
               <u><a href="../man3/pth_spawn.3.html">pth_spawn</a></u>(3) but still not scheduled once), "PTH_CTRL_GETTHREADS_READY" for the number of threads
               in the ready queue (threads who want to do CPU  bursts),  "PTH_CTRL_GETTHREADS_RUNNING"  for  the
               number of running threads (always just one thread!), "PTH_CTRL_GETTHREADS_WAITING" for the number
               of threads in the waiting queue (threads waiting for events), "PTH_CTRL_GETTHREADS_SUSPENDED" for
               the   number   of   threads   in  the  suspended  queue  (threads  waiting  to  be  resumed)  and
               "PTH_CTRL_GETTHREADS_DEAD" for the number of threads in the new queue (terminated threads waiting
               for a join).

           "PTH_CTRL_GETAVLOAD"
               This requires a second argument of type `"float *"' (pointer to a floating point  variable).   It
               stores  a  floating point value describing the exponential averaged load of the scheduler in this
               variable. The load is a function from the number of threads in the ready queue of the  schedulers
               dispatching  unit.   So  a  load  around  1.0  means there is only one ready thread (the standard
               situation when the application has no high load). A higher load value means there a more  threads
               ready  who want to do CPU bursts. The average load value updates once per second only. The return
               value for this query is always 0.

           "PTH_CTRL_GETPRIO"
               This requires a second argument of type `"pth_t"' which identifies  a  thread.   It  returns  the
               priority (ranging from "PTH_PRIO_MIN" to "PTH_PRIO_MAX") of the given thread.

           "PTH_CTRL_GETNAME"
               This  requires a second argument of type `"pth_t"' which identifies a thread. It returns the name
               of the given thread, i.e., the return value of <u><a href="../man3/pth_ctrl.3.html">pth_ctrl</a></u>(3) should be casted to a `"char *"'.

           "PTH_CTRL_DUMPSTATE"
               This requires a second argument of type `"FILE *"' to which a summary of the internal <b>Pth</b> library
               state is written to. The main information which is currently written out is the current state  of
               the thread pool.

           "PTH_CTRL_FAVOURNEW"
               This  requires  a  second  argument of type `"int"' which specified whether the <b>GNU</b> <b>Pth</b> scheduler
               favours new threads on startup, i.e., whether they are moved  from  the  new  queue  to  the  top
               (argument is "TRUE") or middle (argument is "FALSE") of the ready queue. The default is to favour
               new  threads  to make sure they do not starve already at startup, although this slightly violates
               the strict priority based scheduling.

           The function returns "-1" on error.

       long <b>pth_version</b>(void);
           This function returns a hex-value `0x<u>VRRTLL</u>' which describes the current <b>Pth</b> library  version.  <u>V</u>  is
           the  version,  <u>RR</u> the revisions, <u>LL</u> the level and <u>T</u> the type of the level (alphalevel=0, betalevel=1,
           patchlevel=2, etc). For instance <b>Pth</b> version 1.0b1 is encoded  as  0x100101.   The  reason  for  this
           unusual  mapping  is  that this way the version number is steadily <u>increasing</u>. The same value is also
           available under compile time as "PTH_VERSION".

       <b>Thread</b> <b>Attribute</b> <b>Handling</b>

       Attribute objects are used in <b>Pth</b> for two things: First stand-alone/unbound attribute objects are used to
       store attributes for to be spawned threads.  Bounded attribute objects are used to modify  attributes  of
       already existing threads. The following attribute fields exists in attribute objects:

       "PTH_ATTR_PRIO" (read-write) ["int"]
           Thread Priority between "PTH_PRIO_MIN" and "PTH_PRIO_MAX".  The default is "PTH_PRIO_STD".

       "PTH_ATTR_NAME" (read-write) ["char *"]
           Name of thread (up to 40 characters are stored only), mainly for debugging purposes.

       "PTH_ATTR_DISPATCHES" (read-write) ["int"]
           In  bounded  attribute  objects,  this field is incremented every time the context is switched to the
           associated thread.

       "PTH_ATTR_JOINABLE" (read-write&gt; ["int"]
           The thread detachment type, "TRUE" indicates a joinable thread, "FALSE" indicates a detached  thread.
           When  a  thread  is detached, after termination it is immediately kicked out of the system instead of
           inserted into the dead queue.

       "PTH_ATTR_CANCEL_STATE" (read-write) ["unsigned int"]
           The thread cancellation state, i.e., a combination of "PTH_CANCEL_ENABLE" or "PTH_CANCEL_DISABLE" and
           "PTH_CANCEL_DEFERRED" or "PTH_CANCEL_ASYNCHRONOUS".

       "PTH_ATTR_STACK_SIZE" (read-write) ["unsigned int"]
           The thread stack size in bytes. Use lower values than 64 KB with great care!

       "PTH_ATTR_STACK_ADDR" (read-write) ["char *"]
           A pointer to the lower address of a chunk of <u><a href="../man3/malloc.3.html">malloc</a></u>(3)'ed memory for the stack.

       "PTH_ATTR_TIME_SPAWN" (read-only) ["pth_time_t"]
           The time when the thread was spawned.  This can be queried only when the attribute object is bound to
           a thread.

       "PTH_ATTR_TIME_LAST" (read-only) ["pth_time_t"]
           The time when the thread was last dispatched.  This can be queried only when the attribute object  is
           bound to a thread.

       "PTH_ATTR_TIME_RAN" (read-only) ["pth_time_t"]
           The  total  time the thread was running.  This can be queried only when the attribute object is bound
           to a thread.

       "PTH_ATTR_START_FUNC" (read-only) ["void *(*)(void *)"]
           The thread start function.  This can be queried only when the attribute object is bound to a thread.

       "PTH_ATTR_START_ARG" (read-only) ["void *"]
           The thread start argument.  This can be queried only when the attribute object is bound to a thread.

       "PTH_ATTR_STATE" (read-only) ["pth_state_t"]
           The  scheduling   state   of   the   thread,   i.e.,   either   "PTH_STATE_NEW",   "PTH_STATE_READY",
           "PTH_STATE_WAITING",  or "PTH_STATE_DEAD" This can be queried only when the attribute object is bound
           to a thread.

       "PTH_ATTR_EVENTS" (read-only) ["pth_event_t"]
           The event ring the thread is waiting for.  This can be queried only  when  the  attribute  object  is
           bound to a thread.

       "PTH_ATTR_BOUND" (read-only) ["int"]
           Whether the attribute object is bound ("TRUE") to a thread or not ("FALSE").

       The following API functions can be used to handle the attribute objects:

       pth_attr_t <b>pth_attr_of</b>(pth_t <u>tid</u>);
           This  returns  a new attribute object <u>bound</u> to thread <u>tid</u>.  Any queries on this object directly fetch
           attributes from <u>tid</u>. And attribute modifications directly change <u>tid</u>. Use such attribute  objects  to
           modify existing threads.

       pth_attr_t <b>pth_attr_new</b>(void);
           This  returns  a new <u>unbound</u> attribute object. An implicit <u>pth_attr_init()</u> is done on it. Any queries
           on this object just fetch stored attributes from it.  And attribute  modifications  just  change  the
           stored attributes.  Use such attribute objects to pre-configure attributes for to be spawned threads.

       int <b>pth_attr_init</b>(pth_attr_t <u>attr</u>);
           This  initializes  an attribute object <u>attr</u> to the default values: "PTH_ATTR_PRIO" := "PTH_PRIO_STD",
           "PTH_ATTR_NAME"  :=  `"unknown"',  "PTH_ATTR_DISPATCHES"  :=  0,   "PTH_ATTR_JOINABLE"   :=   "TRUE",
           "PTH_ATTR_CANCELSTATE"    :=    "PTH_CANCEL_DEFAULT",    "PTH_ATTR_STACK_SIZE"    :=    64*1024   and
           "PTH_ATTR_STACK_ADDR" := "NULL". All other "PTH_ATTR_*" attributes are read-only attributes and don't
           receive default values in <u>attr</u>, because they exists only for bounded attribute objects.

       int <b>pth_attr_set</b>(pth_attr_t <u>attr</u>, int <u>field</u>, ...);
           This sets the attribute field <u>field</u> in <u>attr</u> to a value specified as an  additional  argument  on  the
           variable argument list. The following attribute <u>fields</u> and argument pairs can be used:

            PTH_ATTR_PRIO           int
            PTH_ATTR_NAME           char *
            PTH_ATTR_DISPATCHES     int
            PTH_ATTR_JOINABLE       int
            PTH_ATTR_CANCEL_STATE   unsigned int
            PTH_ATTR_STACK_SIZE     unsigned int
            PTH_ATTR_STACK_ADDR     char *

       int <b>pth_attr_get</b>(pth_attr_t <u>attr</u>, int <u>field</u>, ...);
           This  retrieves  the  attribute  field  <u>field</u>  in <u>attr</u> and stores its value in the variable specified
           through a pointer in an additional argument on the variable argument list. The following  <u>fields</u>  and
           argument pairs can be used:

            PTH_ATTR_PRIO           int *
            PTH_ATTR_NAME           char **
            PTH_ATTR_DISPATCHES     int *
            PTH_ATTR_JOINABLE       int *
            PTH_ATTR_CANCEL_STATE   unsigned int *
            PTH_ATTR_STACK_SIZE     unsigned int *
            PTH_ATTR_STACK_ADDR     char **
            PTH_ATTR_TIME_SPAWN     pth_time_t *
            PTH_ATTR_TIME_LAST      pth_time_t *
            PTH_ATTR_TIME_RAN       pth_time_t *
            PTH_ATTR_START_FUNC     void *(**)(void *)
            PTH_ATTR_START_ARG      void **
            PTH_ATTR_STATE          pth_state_t *
            PTH_ATTR_EVENTS         pth_event_t *
            PTH_ATTR_BOUND          int *

       int <b>pth_attr_destroy</b>(pth_attr_t <u>attr</u>);
           This destroys a attribute object <u>attr</u>. After this <u>attr</u> is no longer a valid attribute object.

       <b>Thread</b> <b>Control</b>

       The following functions control the threading itself and make up the main API of the <b>Pth</b> library.

       pth_t <b>pth_spawn</b>(pth_attr_t <u>attr</u>, void *(*<u>entry</u>)(void *), void *<u>arg</u>);
           This  spawns  a  new  thread  with  the  attributes  given in <u>attr</u> (or "PTH_ATTR_DEFAULT" for default
           attributes - which means that thread priority, joinability and cancel state are  inherited  from  the
           current  thread)  with  the starting point at routine <u>entry</u>; the dispatch count is not inherited from
           the current thread if <u>attr</u> is not specified - rather, it is initialized to zero.  This entry  routine
           is  called as `pth_exit(<u>entry</u>(<u>arg</u>))' inside the new thread unit, i.e., <u>entry</u>'s return value is fed to
           an implicit <u><a href="../man3/pth_exit.3.html">pth_exit</a></u>(3). So the thread can also exit by just returning. Nevertheless the  thread  can
           also  exit  explicitly  at  any  time by calling <u><a href="../man3/pth_exit.3.html">pth_exit</a></u>(3). But keep in mind that calling the POSIX
           function <u><a href="../man3/exit.3.html">exit</a></u>(3) still terminates the complete process and not just the current thread.

           There is no <b>Pth</b>-internal limit on the number of threads one can spawn, except the  limit  implied  by
           the  available  virtual  memory. <b>Pth</b> internally keeps track of thread in dynamic data structures. The
           function returns "NULL" on error.

       int <b>pth_once</b>(pth_once_t *<u>ctrlvar</u>, void (*<u>func</u>)(void *), void *<u>arg</u>);
           This is a convenience function which uses a control variable of type  "pth_once_t"  to  make  sure  a
           constructor  function <u>func</u> is called only once as `<u>func</u>(<u>arg</u>)' in the system. In other words: Only the
           first call to <u><a href="../man3/pth_once.3.html">pth_once</a></u>(3) by any thread in the system succeeds. The variable referenced  via  <u>ctrlvar</u>
           should be declared as `"pth_once_t" <u>variable-name</u> = "PTH_ONCE_INIT";' before calling this function.

       pth_t <b>pth_self</b>(void);
           This  just  returns the unique thread handle of the currently running thread.  This handle itself has
           to be treated as an opaque entity by the application.  It's usually used  as  an  argument  to  other
           functions who require an argument of type "pth_t".

       int <b>pth_suspend</b>(pth_t <u>tid</u>);
           This suspends a thread <u>tid</u> until it is manually resumed again via <u><a href="../man3/pth_resume.3.html">pth_resume</a></u>(3). For this, the thread
           is  moved to the <b>SUSPENDED</b> queue and this way is completely out of the scheduler's event handling and
           thread dispatching scope. Suspending the current thread is not allowed.  The function returns  "TRUE"
           on success and "FALSE" on errors.

       int <b>pth_resume</b>(pth_t <u>tid</u>);
           This function resumes a previously suspended thread <u>tid</u>, i.e. <u>tid</u> has to stay on the <b>SUSPENDED</b> queue.
           The  thread  is  moved  to  the <b>NEW</b>, <b>READY</b> or <b>WAITING</b> queue (dependent on what its state was when the
           <u><a href="../man3/pth_suspend.3.html">pth_suspend</a></u>(3) call were made) and this way again enters the event handling  and  thread  dispatching
           scope of the scheduler. The function returns "TRUE" on success and "FALSE" on errors.

       int <b>pth_raise</b>(pth_t <u>tid</u>, int <u>sig</u>)
           This  function  raises  a  signal for delivery to thread <u>tid</u> only.  When one just raises a signal via
           <u><a href="../man3/raise.3.html">raise</a></u>(3) or <u><a href="../man2/kill.2.html">kill</a></u>(2), its delivered to an arbitrary thread which has this signal  not  blocked.   With
           <u><a href="../man3/pth_raise.3.html">pth_raise</a></u>(3)  one  can  send  a  signal to a thread and its guarantees that only this thread gets the
           signal delivered. But keep  in  mind  that  nevertheless  the  signals  <u>action</u>  is  still  configured
           <u>process</u>-wide.   When <u>sig</u> is 0 plain thread checking is performed, i.e., `"pth_raise(tid, 0)"' returns
           "TRUE" when thread <u>tid</u> still exists in the <b>PTH</b> system but doesn't send any signal to it.

       int <b>pth_yield</b>(pth_t <u>tid</u>);
           This explicitly yields back the execution control to the scheduler thread.  Usually the execution  is
           implicitly  transferred back to the scheduler when a thread waits for an event. But when a thread has
           to do larger CPU bursts, it can be reasonable to interrupt it explicitly by doing a few  <u><a href="../man3/pth_yield.3.html">pth_yield</a></u>(3)
           calls to give other threads a chance to execute, too.  This obviously is the cooperating part of <b>Pth</b>.
           A  thread  <u>has</u>  <u>not</u>  to yield execution, of course. But when you want to program a server application
           with good response times the threads should be cooperative, i.e., when they should  split  their  CPU
           bursts into smaller units with this call.

           Usually  one  specifies  <u>tid</u>  as  "NULL" to indicate to the scheduler that it can freely decide which
           thread to dispatch next.  But if one wants to indicate to the  scheduler  that  a  particular  thread
           should  be  favored on the next dispatching step, one can specify this thread explicitly. This allows
           the usage of the  old  concept  of  <u>coroutines</u>  where  a  thread/routine  switches  to  a  particular
           cooperating  thread.  If <u>tid</u> is not "NULL" and points to a <u>new</u> or <u>ready</u> thread, it is guaranteed that
           this thread receives execution control on the next dispatching step. If <u>tid</u> is in a  different  state
           (that is, not in "PTH_STATE_NEW" or "PTH_STATE_READY") an error is reported.

           The  function  usually  returns "TRUE" for success and only "FALSE" (with "errno" set to "EINVAL") if
           <u>tid</u> specified an invalid or still not new or ready thread.

       int <b>pth_nap</b>(pth_time_t <u>naptime</u>);
           This functions suspends the execution of the current thread until <u>naptime</u> is elapsed. <u>naptime</u>  is  of
           type  "pth_time_t"  and  this  way has theoretically a resolution of one microsecond. In practice you
           should neither rely on this nor that the thread is awakened exactly after <u>naptime</u> has  elapsed.  It's
           only guarantees that the thread will sleep at least <u>naptime</u>. But because of the non-preemptive nature
           of  <b>Pth</b>  it  can  last  longer  (when  another thread kept the CPU for a long time). Additionally the
           resolution is dependent of the implementation of timers by the operating  system  and  these  usually
           have  only  a  resolution  of  10  microseconds  or  larger.  But usually this isn't important for an
           application unless it tries to use this facility for real time tasks.

       int <b>pth_wait</b>(pth_event_t <u>ev</u>);
           This is the  link  between  the  scheduler  and  the  event  facility  (see  below  for  the  various
           <u>pth_event_xxx()</u>  functions).  It's  modeled like <u><a href="../man2/select.2.html">select</a></u>(2), i.e., one gives this function one or more
           events (in the event ring specified by <u>ev</u>) on which the current thread wants to wait.  The  scheduler
           awakes  the  thread  when  one ore more of them occurred or failed after tagging them as such. The <u>ev</u>
           argument is a <u>pointer</u> to an event ring which  isn't  changed  except  for  the  tagging.  <u><a href="../man3/pth_wait.3.html">pth_wait</a></u>(3)
           returns  the  number  of occurred or failed events and the application can use <u><a href="../man3/pth_event_status.3.html">pth_event_status</a></u>(3) to
           test which events occurred or failed.

       int <b>pth_cancel</b>(pth_t <u>tid</u>);
           This cancels a thread <u>tid</u>. How the cancellation is done depends on  the  cancellation  state  of  <u>tid</u>
           which  the thread can configure itself. When its state is "PTH_CANCEL_DISABLE" a cancellation request
           is just made pending.  When it is "PTH_CANCEL_ENABLE" it depends on the  cancellation  type  what  is
           performed.  When  its  "PTH_CANCEL_DEFERRED" again the cancellation request is just made pending. But
           when its "PTH_CANCEL_ASYNCHRONOUS" the thread is immediately canceled before  <u><a href="../man3/pth_cancel.3.html">pth_cancel</a></u>(3)  returns.
           The   effect   of  a  thread  cancellation  is  equal  to  implicitly  forcing  the  thread  to  call
           `"pth_exit(PTH_CANCELED)"' at one of his cancellation points.  In <b>Pth</b>  thread  enter  a  cancellation
           point either explicitly via <u><a href="../man3/pth_cancel_point.3.html">pth_cancel_point</a></u>(3) or implicitly by waiting for an event.

       int <b>pth_abort</b>(pth_t <u>tid</u>);
           This  is  the cruel way to cancel a thread <u>tid</u>. When it's already dead and waits to be joined it just
           joins it (via `"pth_join("<u>tid</u>", NULL)"') and this way kicks it out of the system.  Else it forces the
           thread to  be  not  joinable  and  to  allow  asynchronous  cancellation  and  then  cancels  it  via
           `"pth_cancel("<u>tid</u>")"'.

       int <b>pth_join</b>(pth_t <u>tid</u>, void **<u>value</u>);
           This  joins  the  current  thread  with  the thread specified via <u>tid</u>.  It first suspends the current
           thread until the <u>tid</u> thread has terminated. Then it  is  awakened  and  stores  the  value  of  <u>tid</u>'s
           <u><a href="../man3/pth_exit.3.html">pth_exit</a></u>(3)  call  into  *<u>value</u>  (if <u>value</u> and not "NULL") and returns to the caller. A thread can be
           joined only when it has the attribute "PTH_ATTR_JOINABLE" set to "TRUE" (the default). A  thread  can
           only  be  joined once, i.e., after the <u><a href="../man3/pth_join.3.html">pth_join</a></u>(3) call the thread <u>tid</u> is completely removed from the
           system.

       void <b>pth_exit</b>(void *<u>value</u>);
           This terminates the current thread. Whether it's immediately removed from the system or inserted into
           the dead queue of the scheduler depends on its join type which was specified at spawning time. If  it
           has  the attribute "PTH_ATTR_JOINABLE" set to "FALSE", it's immediately removed and <u>value</u> is ignored.
           Else the thread is inserted into the dead queue and <u>value</u> remembered  for  a  subsequent  <u><a href="../man3/pth_join.3.html">pth_join</a></u>(3)
           call by another thread.

       <b>Utilities</b>

       Utility functions.

       int <b>pth_fdmode</b>(int <u>fd</u>, int <u>mode</u>);
           This  switches  the  non-blocking  mode  flag  on  file  descriptor  <u>fd</u>.   The  argument  <u>mode</u> can be
           "PTH_FDMODE_BLOCK" for switching <u>fd</u> into blocking I/O mode, "PTH_FDMODE_NONBLOCK"  for  switching  <u>fd</u>
           into  non-blocking  I/O mode or "PTH_FDMODE_POLL" for just polling the current mode. The current mode
           is returned (either "PTH_FDMODE_BLOCK" or "PTH_FDMODE_NONBLOCK") or "PTH_FDMODE_ERROR" on error. Keep
           in mind that since <b>Pth</b> 1.1 there is no longer a requirement to manually switch a file descriptor into
           non-blocking mode in order to use it. This is automatically done  temporarily  inside  <b>Pth</b>.   Instead
           when  you now switch a file descriptor explicitly into non-blocking mode, <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3) or <u><a href="../man3/pth_write.3.html">pth_write</a></u>(3)
           will never block the current thread.

       pth_time_t <b>pth_time</b>(long <u>sec</u>, long <u>usec</u>);
           This is a constructor for a "pth_time_t" structure which is a convenient function to avoid  temporary
           structure  values. It returns a <u>pth_time_t</u> structure which holds the absolute time value specified by
           <u>sec</u> and <u>usec</u>.

       pth_time_t <b>pth_timeout</b>(long <u>sec</u>, long <u>usec</u>);
           This is a constructor for a "pth_time_t" structure which is a convenient function to avoid  temporary
           structure  values.   It returns a <u>pth_time_t</u> structure which holds the absolute time value calculated
           by adding <u>sec</u> and <u>usec</u> to the current time.

       Sfdisc_t *<b>pth_sfiodisc</b>(void);
           This functions is always available, but only reasonably usable when <b>Pth</b> was built with  <b>Sfio</b>  support
           ("--with-sfio"  option)  and "PTH_EXT_SFIO" is then defined by "pth.h". It is useful for applications
           which want to use the comprehensive <b>Sfio</b> I/O library  with  the  <b>Pth</b>  threading  library.  Then  this
           function  can  be used to get an <b>Sfio</b> discipline structure ("Sfdisc_t") which can be pushed onto <b>Sfio</b>
           streams  ("Sfio_t")  in  order  to  let  this  stream   use   <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3)/<u><a href="../man2/pth_write.2.html">pth_write</a></u>(2)   instead   of
           <u><a href="../man2/read.2.html">read</a></u>(2)/<u><a href="../man2/write.2.html">write</a></u>(2).  The  benefit  is  that this way I/O on the <b>Sfio</b> stream does only block the current
           thread instead of the whole process. The application has to <u><a href="../man3/free.3.html">free</a></u>(3) the "Sfdisc_t" structure when  it
           is no longer needed. The Sfio package can be found at <a href="http://www.research.att.com/sw/tools/sfio/">http://www.research.att.com/sw/tools/sfio/</a>.

       <b>Cancellation</b> <b>Management</b>

       <b>Pth</b> supports POSIX style thread cancellation via <u><a href="../man3/pth_cancel.3.html">pth_cancel</a></u>(3) and the following two related functions:

       void <b>pth_cancel_state</b>(int <u>newstate</u>, int *<u>oldstate</u>);
           This  manages the cancellation state of the current thread.  When <u>oldstate</u> is not "NULL" the function
           stores the old cancellation state under the variable pointed to by <u>oldstate</u>. When <u>newstate</u> is  not  0
           it  sets  the  new  cancellation  state.  <u>oldstate</u>  is  created before <u>newstate</u> is set.  A state is a
           combination   of   "PTH_CANCEL_ENABLE"   or   "PTH_CANCEL_DISABLE"   and   "PTH_CANCEL_DEFERRED"   or
           "PTH_CANCEL_ASYNCHRONOUS".   "PTH_CANCEL_ENABLE⎪PTH_CANCEL_DEFERRED" (or "PTH_CANCEL_DEFAULT") is the
           default  state  where  cancellation   is   possible   but   only   at   cancellation   points.    Use
           "PTH_CANCEL_DISABLE"  to complete disable cancellation for a thread and "PTH_CANCEL_ASYNCHRONOUS" for
           allowing asynchronous cancellations, i.e., cancellations which can happen at any time.

       void <b>pth_cancel_point</b>(void);
           This  explicitly  enter  a   cancellation   point.   When   the   current   cancellation   state   is
           "PTH_CANCEL_DISABLE"  or  no  cancellation  request  is  pending, this has no side-effect and returns
           immediately. Else it calls `"pth_exit(PTH_CANCELED)"'.

       <b>Event</b> <b>Handling</b>

       <b>Pth</b> has a very flexible event facility which  is  linked  into  the  scheduler  through  the  <u><a href="../man3/pth_wait.3.html">pth_wait</a></u>(3)
       function. The following functions provide the handling of event rings.

       pth_event_t <b>pth_event</b>(unsigned long <u>spec</u>, ...);
           This  creates a new event ring consisting of a single initial event.  The type of the generated event
           is specified by <u>spec</u>. The following types are available:

           "PTH_EVENT_FD"
               This is a file descriptor event. One or more of "PTH_UNTIL_FD_READABLE", "PTH_UNTIL_FD_WRITEABLE"
               or "PTH_UNTIL_FD_EXCEPTION" have to be OR-ed into <u>spec</u> to specify on  which  state  of  the  file
               descriptor  you  want  to  wait.   The  file  descriptor  itself has to be given as an additional
               argument.  Example: `"pth_event(PTH_EVENT_FD⎪PTH_UNTIL_FD_READABLE, fd)"'.

           "PTH_EVENT_SELECT"
               This is a multiple file descriptor event modeled directly after the <u><a href="../man2/select.2.html">select</a></u>(2) call  (actually  it
               is  also  used to implement <u><a href="../man3/pth_select.3.html">pth_select</a></u>(3) internally).  It's a convenient way to wait for a large
               set of file descriptors at once and at each file  descriptor  for  a  different  type  of  state.
               Additionally  as  a nice side-effect one receives the number of file descriptors which causes the
               event to be occurred (using BSD semantics, i.e., when a file descriptor occurred in two sets it's
               counted twice). The arguments correspond directly to the <u><a href="../man2/select.2.html">select</a></u>(2) function arguments except that
               there is no timeout argument (because  timeouts  already  can  be  handled  via  "PTH_EVENT_TIME"
               events).

               Example: `"pth_event(PTH_EVENT_SELECT, &amp;rc, nfd, rfds, wfds, efds)"' where "rc" has to be of type
               `"int  *"',  "nfd"  has  to  be  of type `"int"' and "rfds", "wfds" and "efds" have to be of type
               `"fd_set *"' (see <u><a href="../man2/select.2.html">select</a></u>(2)). The number of occurred file descriptors are stored in "rc".

           "PTH_EVENT_SIGS"
               This is a signal set event. The two additional arguments have to be a pointer  to  a  signal  set
               (type  `"sigset_t  *"')  and  a pointer to a signal number variable (type `"int *"').  This event
               waits until one of the signals in the signal set occurred.   As  a  result  the  occurred  signal
               number  is  stored in the second additional argument. Keep in mind that the <b>Pth</b> scheduler doesn't
               block signals automatically.  So when you want to wait for a signal with  this  event  you've  to
               block   it   via   <u><a href="../man2/sigprocmask.2.html">sigprocmask</a></u>(2)   or  it  will  be  delivered  without  your  notice.  Example:
               `"sigemptyset(&amp;set); sigaddset(&amp;set, SIGINT); pth_event(PTH_EVENT_SIG, &amp;set, &amp;sig);"'.

           "PTH_EVENT_TIME"
               This is a time point event. The additional argument has to be of type "pth_time_t"  (usually  on-
               the-fly generated via <u><a href="../man3/pth_time.3.html">pth_time</a></u>(3)). This events waits until the specified time point has elapsed.
               Keep  in  mind  that the value is an absolute time point and not an offset. When you want to wait
               for a specified amount of time, you've to add the current time to the offset (usually  on-the-fly
               achieved via <u><a href="../man3/pth_timeout.3.html">pth_timeout</a></u>(3)).  Example: `"pth_event(PTH_EVENT_TIME, pth_timeout(2,0))"'.

           "PTH_EVENT_MSG"
               This  is  a  message  port event. The additional argument has to be of type "pth_msgport_t". This
               events waits until one or more messages were received on the specified  message  port.   Example:
               `"pth_event(PTH_EVENT_MSG, mp)"'.

           "PTH_EVENT_TID"
               This  is  a  thread  event.  The  additional  argument  has  to  be  of  type  "pth_t".   One  of
               "PTH_UNTIL_TID_NEW", "PTH_UNTIL_TID_READY", "PTH_UNTIL_TID_WAITING" or  "PTH_UNTIL_TID_DEAD"  has
               to  be  OR-ed  into  <u>spec</u>  to  specify  on  which state of the thread you want to wait.  Example:
               `"pth_event(PTH_EVENT_TID⎪PTH_UNTIL_TID_DEAD, tid)"'.

           "PTH_EVENT_FUNC"
               This is a custom callback function event. Three additional arguments have to be  given  with  the
               following  types:  `"int  (*)(void  *)"',  `"void *"' and `"pth_time_t"'. The first is a function
               pointer to a check function and the second argument is a user-supplied  context  value  which  is
               passed  to  this  function.  The  scheduler  calls  this  function on a regular basis (on his own
               scheduler stack, so be very careful!) and the thread is kept sleeping while the function  returns
               "FALSE".  Once  it  returned "TRUE" the thread will be awakened. The check interval is defined by
               the third argument, i.e., the check function is polled  again  not  until  this  amount  of  time
               elapsed. Example: `"pth_event(PTH_EVENT_FUNC, func, arg, pth_time(0,500000))"'.

       unsigned long <b>pth_event_typeof</b>(pth_event_t <u>ev</u>);
           This  returns  the  type  of  event  <u>ev</u>.  It's  a  combination  of  the describing "PTH_EVENT_XX" and
           "PTH_UNTIL_XX" value. This is especially useful to know which arguments have to be  supplied  to  the
           <u><a href="../man3/pth_event_extract.3.html">pth_event_extract</a></u>(3) function.

       int <b>pth_event_extract</b>(pth_event_t <u>ev</u>, ...);
           When  <u><a href="../man3/pth_event.3.html">pth_event</a></u>(3)  is  treated  like  <u><a href="../man3/sprintf.3.html">sprintf</a></u>(3),  then  this function is <u><a href="../man3/sscanf.3.html">sscanf</a></u>(3), i.e., it is the
           inverse operation of <u><a href="../man3/pth_event.3.html">pth_event</a></u>(3). This means that it can be used to extract the  ingredients  of  an
           event.   The  ingredients  are  stored  into  variables  which  are given as pointers on the variable
           argument list.  Which pointers have to be present depends on the event type and has to be  determined
           by the caller before via <u><a href="../man3/pth_event_typeof.3.html">pth_event_typeof</a></u>(3).

           To  make  it  clear,  when  you  constructed <u>ev</u> via `"ev = pth_event(PTH_EVENT_FD, fd);"' you have to
           extract it via `"pth_event_extract(ev, &amp;fd)"', etc. For multiple arguments of an event the  order  of
           the  pointer  arguments  is  the  same  as for <u><a href="../man3/pth_event.3.html">pth_event</a></u>(3). But always keep in mind that you have to
           always supply <u>pointers</u> to <u>variables</u> and these variables have to be of the same type as  the  argument
           of <u><a href="../man3/pth_event.3.html">pth_event</a></u>(3) required.

       pth_event_t <b>pth_event_concat</b>(pth_event_t <u>ev</u>, ...);
           This  concatenates one or more additional event rings to the event ring <u>ev</u> and returns <u>ev</u>. The end of
           the argument list has to be marked with a "NULL" argument. Use this function to  create  real  events
           rings out of the single-event rings created by <u><a href="../man3/pth_event.3.html">pth_event</a></u>(3).

       pth_event_t <b>pth_event_isolate</b>(pth_event_t <u>ev</u>);
           This  isolates  the  event  <u>ev</u>  from possibly appended events in the event ring.  When in <u>ev</u> only one
           event exists, this returns "NULL". When remaining events exists, they form a new event ring which  is
           returned.

       pth_event_t <b>pth_event_walk</b>(pth_event_t <u>ev</u>, int <u>direction</u>);
           This  walks  to  the  next  (when  <u>direction</u>  is  "PTH_WALK_NEXT")  or  previews  (when  <u>direction</u> is
           "PTH_WALK_PREV") event in the event  ring  <u>ev</u>  and  returns  this  new  reached  event.  Additionally
           "PTH_UNTIL_OCCURRED"  can  be OR-ed into <u>direction</u> to walk to the next/previous occurred event in the
           ring <u>ev</u>.

       pth_status_t <b>pth_event_status</b>(pth_event_t <u>ev</u>);
           This returns the status of event <u>ev</u>. This is a fast operation because only a tag  on  <u>ev</u>  is  checked
           which  was either set or still not set by the scheduler. In other words: This doesn't check the event
           itself, it just checks the last knowledge of the scheduler. The possible returned status  codes  are:
           "PTH_STATUS_PENDING"  (event  is still pending), "PTH_STATUS_OCCURRED" (event successfully occurred),
           "PTH_STATUS_FAILED" (event failed).

       int <b>pth_event_free</b>(pth_event_t <u>ev</u>, int <u>mode</u>);
           This deallocates the event <u>ev</u> (when <u>mode</u> is "PTH_FREE_THIS") or all events appended to the event ring
           under <u>ev</u> (when <u>mode</u> is "PTH_FREE_ALL").

       <b>Key-Based</b> <b>Storage</b>

       The following functions provide thread-local storage through unique keys similar  to  the  POSIX  <b>Pthread</b>
       API. Use this for thread specific global data.

       int <b>pth_key_create</b>(pth_key_t *<u>key</u>, void (*<u>func</u>)(void *));
           This  created  a  new  unique  key  and stores it in <u>key</u>.  Additionally <u>func</u> can specify a destructor
           function which is called on the current threads termination with the <u>key</u>.

       int <b>pth_key_delete</b>(pth_key_t <u>key</u>);
           This explicitly destroys a key <u>key</u>.

       int <b>pth_key_setdata</b>(pth_key_t <u>key</u>, const void *<u>value</u>);
           This stores <u>value</u> under <u>key</u>.

       void *<b>pth_key_getdata</b>(pth_key_t <u>key</u>);
           This retrieves the value under <u>key</u>.

       <b>Message</b> <b>Port</b> <b>Communication</b>

       The following functions provide message ports which can be used for efficient and  flexible  inter-thread
       communication.

       pth_msgport_t <b>pth_msgport_create</b>(const char *<u>name</u>);
           This  returns  a  pointer  to a new message port. If name <u>name</u> is not "NULL", the <u>name</u> can be used by
           other threads via <u><a href="../man3/pth_msgport_find.3.html">pth_msgport_find</a></u>(3) to find the message port in case they do not know directly  the
           pointer to the message port.

       void <b>pth_msgport_destroy</b>(pth_msgport_t <u>mp</u>);
           This  destroys  a  message  port  <u>mp</u>.  Before  all pending messages on it are replied to their origin
           message port.

       pth_msgport_t <b>pth_msgport_find</b>(const char *<u>name</u>);
           This finds a message port in the system by <u>name</u> and returns the pointer to it.

       int <b>pth_msgport_pending</b>(pth_msgport_t <u>mp</u>);
           This returns the number of pending messages on message port <u>mp</u>.

       int <b>pth_msgport_put</b>(pth_msgport_t <u>mp</u>, pth_message_t *<u>m</u>);
           This puts (or sends) a message <u>m</u> to message port <u>mp</u>.

       pth_message_t *<b>pth_msgport_get</b>(pth_msgport_t <u>mp</u>);
           This gets (or receives) the top message from message port <u>mp</u>.  Incoming messages are always kept in a
           queue, so there can be more pending messages, of course.

       int <b>pth_msgport_reply</b>(pth_message_t *<u>m</u>);
           This replies a message <u>m</u> to the message port of the sender.

       <b>Thread</b> <b>Cleanups</b>

       Per-thread cleanup functions.

       int <b>pth_cleanup_push</b>(void (*<u>handler</u>)(void *), void *<u>arg</u>);
           This pushes the routine <u>handler</u> onto the stack of cleanup routines for  the  current  thread.   These
           routines are called in LIFO order when the thread terminates.

       int <b>pth_cleanup_pop</b>(int <u>execute</u>);
           This  pops  the  top-most  routine  from  the  stack of cleanup routines for the current thread. When
           <u>execute</u> is "TRUE" the routine is additionally called.

       <b>Process</b> <b>Forking</b>

       The following functions provide some special support for process forking situations inside the  threading
       environment.

       int <b>pth_atfork_push</b>(void (*<u>prepare</u>)(void *), void (*)(void *<u>parent</u>), void (*)(void *<u>child</u>), void *<u>arg</u>);
           This  function declares forking handlers to be called before and after <u><a href="../man3/pth_fork.3.html">pth_fork</a></u>(3), in the context of
           the thread that  called  <u><a href="../man3/pth_fork.3.html">pth_fork</a></u>(3).  The  <u>prepare</u>  handler  is  called  before  <u><a href="../man2/fork.2.html">fork</a></u>(2)  processing
           commences.  The  <u>parent</u> handler is called   after <u><a href="../man2/fork.2.html">fork</a></u>(2) processing completes in the parent process.
           The <u>child</u> handler is called after <u><a href="../man2/fork.2.html">fork</a></u>(2) processing completed in the child process. If  no  handling
           is  desired  at  one or more of these three points, the corresponding handler can be given as "NULL".
           Each handler is called with <u>arg</u> as the argument.

           The order of calls to <u><a href="../man3/pth_atfork_push.3.html">pth_atfork_push</a></u>(3) is significant. The <u>parent</u> and <u>child</u> handlers are called  in
           the order in which they were established by calls to <u><a href="../man3/pth_atfork_push.3.html">pth_atfork_push</a></u>(3), i.e., FIFO. The <u>prepare</u> fork
           handlers are called in the opposite order, i.e., LIFO.

       int <b>pth_atfork_pop</b>(void);
           This  removes the top-most handlers on the forking handler stack which were established with the last
           <u><a href="../man3/pth_atfork_push.3.html">pth_atfork_push</a></u>(3) call. It returns "FALSE" when no more handlers couldn't be removed from the stack.

       pid_t <b>pth_fork</b>(void);
           This is a variant of <u><a href="../man2/fork.2.html">fork</a></u>(2) with the difference that the  current  thread  only  is  forked  into  a
           separate  process, i.e., in the parent process nothing changes while in the child process all threads
           are gone except for the scheduler and the calling thread. When  you  really  want  to  duplicate  all
           threads  in  the current process you should use <u><a href="../man2/fork.2.html">fork</a></u>(2) directly. But this is usually not reasonable.
           Additionally this function takes care of forking handlers as established by <u><a href="../man3/pth_fork_push.3.html">pth_fork_push</a></u>(3).

       <b>Synchronization</b>

       The following functions provide synchronization support via mutual exclusion  locks  (<b>mutex</b>),  read-write
       locks  (<b>rwlock</b>), condition variables (<b>cond</b>) and barriers (<b>barrier</b>). Keep in mind that in a non-preemptive
       threading system like <b>Pth</b> this might sound  unnecessary  at  the  first  look,  because  a  thread  isn't
       interrupted  by  the  system.  Actually  when  you have a critical code section which doesn't contain any
       <u>pth_xxx()</u> functions, you don't need any mutex to protect it, of course.

       But when your critical code section contains any  <u>pth_xxx()</u>  function  the  chance  is  high  that  these
       temporarily switch to the scheduler. And this way other threads can make progress and enter your critical
       code section, too.  This is especially true for critical code sections which implicitly or explicitly use
       the event mechanism.

       int <b>pth_mutex_init</b>(pth_mutex_t *<u>mutex</u>);
           This  dynamically  initializes  a mutex variable of type `"pth_mutex_t"'.  Alternatively one can also
           use static initialization via `"pth_mutex_t mutex = PTH_MUTEX_INIT"'.

       int <b>pth_mutex_acquire</b>(pth_mutex_t *<u>mutex</u>, int <u>try</u>, pth_event_t <u>ev</u>);
           This acquires a mutex <u>mutex</u>.  If the mutex is already locked by another thread, the  current  threads
           execution  is  suspended  until  the  mutex  is unlocked again or additionally the extra events in <u>ev</u>
           occurred (when <u>ev</u> is not "NULL").  Recursive locking is  explicitly  supported,  i.e.,  a  thread  is
           allowed  to  acquire a mutex more than once before its released. But it then also has be released the
           same number of times until the mutex is again lockable by others.  When <u>try</u> is "TRUE"  this  function
           never suspends execution. Instead it returns "FALSE" with "errno" set to "EBUSY".

       int <b>pth_mutex_release</b>(pth_mutex_t *<u>mutex</u>);
           This decrements the recursion locking count on <u>mutex</u> and when it is zero it releases the mutex <u>mutex</u>.

       int <b>pth_rwlock_init</b>(pth_rwlock_t *<u>rwlock</u>);
           This  dynamically initializes a read-write lock variable of type `"pth_rwlock_t"'.  Alternatively one
           can also use static initialization via `"pth_rwlock_t rwlock = PTH_RWLOCK_INIT"'.

       int <b>pth_rwlock_acquire</b>(pth_rwlock_t *<u>rwlock</u>, int <u>op</u>, int <u>try</u>, pth_event_t <u>ev</u>);
           This acquires a read-only (when <u>op</u> is "PTH_RWLOCK_RD") or a read-write (when <u>op</u>  is  "PTH_RWLOCK_RW")
           lock <u>rwlock</u>. When the lock is only locked by other threads in read-only mode, the lock succeeds.  But
           when  one  thread holds a read-write lock, all locking attempts suspend the current thread until this
           lock is released again. Additionally in <u>ev</u> events can be given to let the locking timeout, etc.  When
           <u>try</u>  is "TRUE" this function never suspends execution. Instead it returns "FALSE" with "errno" set to
           "EBUSY".

       int <b>pth_rwlock_release</b>(pth_rwlock_t *<u>rwlock</u>);
           This releases a previously acquired (read-only or read-write) lock.

       int <b>pth_cond_init</b>(pth_cond_t *<u>cond</u>);
           This dynamically initializes a condition variable variable of type `"pth_cond_t"'.  Alternatively one
           can also use static initialization via `"pth_cond_t cond = PTH_COND_INIT"'.

       int <b>pth_cond_await</b>(pth_cond_t *<u>cond</u>, pth_mutex_t *<u>mutex</u>, pth_event_t <u>ev</u>);
           This awaits a condition situation. The caller has to follow the  semantics  of  the  POSIX  condition
           variables:  <u>mutex</u>  has  to  be  acquired before this function is called. The execution of the current
           thread is then suspended either until the events in <u>ev</u> occurred (when <u>ev</u> is not "NULL") or  <u>cond</u>  was
           notified  by  another thread via <u><a href="../man3/pth_cond_notify.3.html">pth_cond_notify</a></u>(3).  While the thread is waiting, <u>mutex</u> is released.
           Before it returns <u>mutex</u> is reacquired.

       int <b>pth_cond_notify</b>(pth_cond_t *<u>cond</u>, int <u>broadcast</u>);
           This notified one or all threads which are waiting on <u>cond</u>.  When <u>broadcast</u> is "TRUE" all thread  are
           notified, else only a single (unspecified) one.

       int <b>pth_barrier_init</b>(pth_barrier_t *<u>barrier</u>, int <u>threshold</u>);
           This  dynamically  initializes  a  barrier variable of type `"pth_barrier_t"'.  Alternatively one can
           also use static initialization via `"pth_barrier_t barrier = PTH_BARRIER_INIT("<u>threadhold</u>")"'.

       int <b>pth_barrier_reach</b>(pth_barrier_t *<u>barrier</u>);
           This function reaches a barrier <u>barrier</u>. If this is the last thread (as  specified  by  <u>threshold</u>  on
           init  of  <u>barrier</u>)  all  threads  are  awakened.  Else the current thread is suspended until the last
           thread reached the barrier and this way awakes all threads. The function returns (beside  "FALSE"  on
           error)  the  value  "TRUE" for any thread which neither reached the barrier as the first nor the last
           thread; "PTH_BARRIER_HEADLIGHT" for the thread which reached the barrier  as  the  first  thread  and
           "PTH_BARRIER_TAILLIGHT" for the thread which reached the barrier as the last thread.

       <b>User-Space</b> <b>Context</b>

       The  following functions provide a stand-alone sub-API for user-space context switching. It internally is
       based on the same underlying machine context switching mechanism the threads in <b>GNU</b>  <b>Pth</b>  are  based  on.
       Hence  these  functions you can use for implementing your own simple user-space threads. The "pth_uctx_t"
       context is somewhat modeled after POSIX <u><a href="../man3/ucontext.3.html">ucontext</a></u>(3).

       The time required to create (via <u><a href="../man3/pth_uctx_make.3.html">pth_uctx_make</a></u>(3)) a  user-space  context  can  range  from  just  a  few
       microseconds  up  to  a  more dramatical time (depending on the machine context switching method which is
       available on the platform). On the other hand, the raw performance in switching the  user-space  contexts
       is  always  very good (nearly independent of the used machine context switching method). For instance, on
       an Intel Pentium-III CPU with 800Mhz running under FreeBSD 4 one usually  achieves  about  260,000  user-
       space context switches (via <u><a href="../man3/pth_uctx_switch.3.html">pth_uctx_switch</a></u>(3)) per second.

       int <b>pth_uctx_create</b>(pth_uctx_t *<u>uctx</u>);
           This  function  creates  a  user-space context and stores it into <u>uctx</u>.  There is still no underlying
           user-space context configured. You still have to do this  with  <u><a href="../man3/pth_uctx_make.3.html">pth_uctx_make</a></u>(3).  On  success,  this
           function returns "TRUE", else "FALSE".

       int <b>pth_uctx_make</b>(pth_uctx_t <u>uctx</u>, char *<u>sk_addr</u>, size_t <u>sk_size</u>, const sigset_t *<u>sigmask</u>, void
       (*<u>start_func</u>)(void *), void *<u>start_arg</u>, pth_uctx_t <u>uctx_after</u>);
           This function makes a new user-space context in <u>uctx</u> which will operate on the run-time stack <u>sk_addr</u>
           (which  is  of  maximum size <u>sk_size</u>), with the signals in <u>sigmask</u> blocked (if <u>sigmask</u> is not "NULL")
           and starting to execute with the call  <u>start_func</u>(<u>start_arg</u>).  If  <u>sk_addr</u>  is  "NULL",  a  stack  is
           dynamically  allocated. The stack size <u>sk_size</u> has to be at least 16384 (16KB). If the start function
           <u>start_func</u> returns and <u>uctx_after</u> is not "NULL",  an  implicit  user-space  context  switch  to  this
           context  is  performed.  Else  (if <u>uctx_after</u> is "NULL") the process is terminated with <u><a href="../man3/exit.3.html">exit</a></u>(3). This
           function is somewhat modeled after POSIX <u><a href="../man3/makecontext.3.html">makecontext</a></u>(3). On success, this  function  returns  "TRUE",
           else "FALSE".

       int <b>pth_uctx_switch</b>(pth_uctx_t <u>uctx_from</u>, pth_uctx_t <u>uctx_to</u>);
           This  function  saves the current user-space context in <u>uctx_from</u> for later restoring by another call
           to <u><a href="../man3/pth_uctx_switch.3.html">pth_uctx_switch</a></u>(3) and restores the new user-space context from <u>uctx_to</u>, which previously  had  to
           be  set  with  either  a  previous  call to <u><a href="../man3/pth_uctx_switch.3.html">pth_uctx_switch</a></u>(3) or initially by <u><a href="../man3/pth_uctx_make.3.html">pth_uctx_make</a></u>(3). This
           function is somewhat modeled after POSIX <u><a href="../man3/swapcontext.3.html">swapcontext</a></u>(3). If <u>uctx_from</u> or <u>uctx_to</u>  are  "NULL"  or  if
           <u>uctx_to</u>  contains  no  valid user-space context, "FALSE" is returned instead of "TRUE". These are the
           only errors possible.

       int <b>pth_uctx_destroy</b>(pth_uctx_t <u>uctx</u>);
           This function destroys the user-space context in <u>uctx</u>. The run-time stack associated with  the  user-
           space  context  is  deallocated  only  if  it  was  not  given  by  the  application  (see <u>sk_addr</u> of
           <u><a href="../man3/pth_uctx_create.3.html">pth_uctx_create</a></u>(3)).  If <u>uctx</u> is "NULL", "FALSE" is returned instead of  "TRUE".  This  is  the  only
           error possible.

       <b>Generalized</b> <b>POSIX</b> <b>Replacement</b> <b>API</b>

       The  following functions are generalized replacements functions for the POSIX API, i.e., they are similar
       to the functions under `<b>Standard</b> <b>POSIX</b> <b>Replacement</b> <b>API</b>' but all have an additional event  argument  which
       can be used for timeouts, etc.

       int <b>pth_sigwait_ev</b>(const sigset_t *<u>set</u>, int *<u>sig</u>, pth_event_t <u>ev</u>);
           This  is  equal  to  <u><a href="../man3/pth_sigwait.3.html">pth_sigwait</a></u>(3)  (see  below),  but  has  an  additional  event argument <u>ev</u>. When
           <u><a href="../man3/pth_sigwait.3.html">pth_sigwait</a></u>(3) suspends the current threads execution it usually only uses the signal event on <u>set</u> to
           awake. With this function any number of extra  events  can  be  used  to  awake  the  current  thread
           (remember that <u>ev</u> actually is an event <u>ring</u>).

       int <b>pth_connect_ev</b>(int <u>s</u>, const struct sockaddr *<u>addr</u>, socklen_t <u>addrlen</u>, pth_event_t <u>ev</u>);
           This  is  equal  to  <u><a href="../man3/pth_connect.3.html">pth_connect</a></u>(3)  (see  below),  but  has  an  additional  event argument <u>ev</u>. When
           <u><a href="../man3/pth_connect.3.html">pth_connect</a></u>(3) suspends the current threads execution it usually only uses the  I/O  event  on  <u>s</u>  to
           awake.  With  this  function  any  number  of  extra  events  can be used to awake the current thread
           (remember that <u>ev</u> actually is an event <u>ring</u>).

       int <b>pth_accept_ev</b>(int <u>s</u>, struct sockaddr *<u>addr</u>, socklen_t *<u>addrlen</u>, pth_event_t <u>ev</u>);
           This is equal  to  <u><a href="../man3/pth_accept.3.html">pth_accept</a></u>(3)  (see  below),  but  has  an  additional  event  argument  <u>ev</u>.  When
           <u><a href="../man3/pth_accept.3.html">pth_accept</a></u>(3)  suspends  the  current  threads  execution  it usually only uses the I/O event on <u>s</u> to
           awake. With this function any number of extra  events  can  be  used  to  awake  the  current  thread
           (remember that <u>ev</u> actually is an event <u>ring</u>).

       int <b>pth_select_ev</b>(int <u>nfd</u>, fd_set *<u>rfds</u>, fd_set *<u>wfds</u>, fd_set *<u>efds</u>, struct timeval *<u>timeout</u>, pth_event_t
       <u>ev</u>);
           This  is  equal  to  <u><a href="../man3/pth_select.3.html">pth_select</a></u>(3)  (see  below),  but  has  an  additional  event  argument <u>ev</u>. When
           <u><a href="../man3/pth_select.3.html">pth_select</a></u>(3) suspends the current threads execution it usually only uses the I/O event on <u>rfds</u>, <u>wfds</u>
           and <u>efds</u> to awake. With this function any number of extra events can be used  to  awake  the  current
           thread (remember that <u>ev</u> actually is an event <u>ring</u>).

       int <b>pth_poll_ev</b>(struct pollfd *<u>fds</u>, unsigned int <u>nfd</u>, int <u>timeout</u>, pth_event_t <u>ev</u>);
           This  is  equal to <u><a href="../man3/pth_poll.3.html">pth_poll</a></u>(3) (see below), but has an additional event argument <u>ev</u>. When <u><a href="../man3/pth_poll.3.html">pth_poll</a></u>(3)
           suspends the current threads execution it usually only uses the I/O event on <u>fds</u> to awake. With  this
           function  any  number  of  extra  events  can  be  used to awake the current thread (remember that <u>ev</u>
           actually is an event <u>ring</u>).

       ssize_t <b>pth_read_ev</b>(int <u>fd</u>, void *<u>buf</u>, size_t <u>nbytes</u>, pth_event_t <u>ev</u>);
           This is equal to <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3) (see below), but has an additional event argument <u>ev</u>.  When  <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3)
           suspends  the  current threads execution it usually only uses the I/O event on <u>fd</u> to awake. With this
           function any number of extra events can be used  to  awake  the  current  thread  (remember  that  <u>ev</u>
           actually is an event <u>ring</u>).

       ssize_t <b>pth_readv_ev</b>(int <u>fd</u>, const struct iovec *<u>iovec</u>, int <u>iovcnt</u>, pth_event_t <u>ev</u>);
           This is equal to <u><a href="../man3/pth_readv.3.html">pth_readv</a></u>(3) (see below), but has an additional event argument <u>ev</u>. When <u><a href="../man3/pth_readv.3.html">pth_readv</a></u>(3)
           suspends  the  current threads execution it usually only uses the I/O event on <u>fd</u> to awake. With this
           function any number of extra events can be used  to  awake  the  current  thread  (remember  that  <u>ev</u>
           actually is an event <u>ring</u>).

       ssize_t <b>pth_write_ev</b>(int <u>fd</u>, const void *<u>buf</u>, size_t <u>nbytes</u>, pth_event_t <u>ev</u>);
           This is equal to <u><a href="../man3/pth_write.3.html">pth_write</a></u>(3) (see below), but has an additional event argument <u>ev</u>. When <u><a href="../man3/pth_write.3.html">pth_write</a></u>(3)
           suspends  the  current threads execution it usually only uses the I/O event on <u>fd</u> to awake. With this
           function any number of extra events can be used  to  awake  the  current  thread  (remember  that  <u>ev</u>
           actually is an event <u>ring</u>).

       ssize_t <b>pth_writev_ev</b>(int <u>fd</u>, const struct iovec *<u>iovec</u>, int <u>iovcnt</u>, pth_event_t <u>ev</u>);
           This  is  equal  to  <u><a href="../man3/pth_writev.3.html">pth_writev</a></u>(3)  (see  below),  but  has  an  additional  event  argument <u>ev</u>. When
           <u><a href="../man3/pth_writev.3.html">pth_writev</a></u>(3) suspends the current threads execution it usually only uses the  I/O  event  on  <u>fd</u>  to
           awake.  With  this  function  any  number  of  extra  events  can be used to awake the current thread
           (remember that <u>ev</u> actually is an event <u>ring</u>).

       ssize_t <b>pth_recv_ev</b>(int <u>fd</u>, void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>, pth_event_t <u>ev</u>);
           This is equal to <u><a href="../man3/pth_recv.3.html">pth_recv</a></u>(3) (see below), but has an additional event argument <u>ev</u>.  When  <u><a href="../man3/pth_recv.3.html">pth_recv</a></u>(3)
           suspends  the  current threads execution it usually only uses the I/O event on <u>fd</u> to awake. With this
           function any number of extra events can be used  to  awake  the  current  thread  (remember  that  <u>ev</u>
           actually is an event <u>ring</u>).

       ssize_t <b>pth_recvfrom_ev</b>(int <u>fd</u>, void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>, struct sockaddr *<u>from</u>, socklen_t
       *<u>fromlen</u>, pth_event_t <u>ev</u>);
           This  is  equal  to  <u><a href="../man3/pth_recvfrom.3.html">pth_recvfrom</a></u>(3)  (see  below),  but  has  an  additional event argument <u>ev</u>. When
           <u><a href="../man3/pth_recvfrom.3.html">pth_recvfrom</a></u>(3) suspends the current threads execution it usually only uses the I/O event  on  <u>fd</u>  to
           awake.  With  this  function  any  number  of  extra  events  can be used to awake the current thread
           (remember that <u>ev</u> actually is an event <u>ring</u>).

       ssize_t <b>pth_send_ev</b>(int <u>fd</u>, const void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>, pth_event_t <u>ev</u>);
           This is equal to <u><a href="../man3/pth_send.3.html">pth_send</a></u>(3) (see below), but has an additional event argument <u>ev</u>.  When  <u><a href="../man3/pth_send.3.html">pth_send</a></u>(3)
           suspends  the  current threads execution it usually only uses the I/O event on <u>fd</u> to awake. With this
           function any number of extra events can be used  to  awake  the  current  thread  (remember  that  <u>ev</u>
           actually is an event <u>ring</u>).

       ssize_t <b>pth_sendto_ev</b>(int <u>fd</u>, const void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>, const struct sockaddr *<u>to</u>,
       socklen_t <u>tolen</u>, pth_event_t <u>ev</u>);
           This  is  equal  to  <u><a href="../man3/pth_sendto.3.html">pth_sendto</a></u>(3)  (see  below),  but  has  an  additional  event  argument <u>ev</u>. When
           <u><a href="../man3/pth_sendto.3.html">pth_sendto</a></u>(3) suspends the current threads execution it usually only uses the  I/O  event  on  <u>fd</u>  to
           awake.  With  this  function  any  number  of  extra  events  can be used to awake the current thread
           (remember that <u>ev</u> actually is an event <u>ring</u>).

       <b>Standard</b> <b>POSIX</b> <b>Replacement</b> <b>API</b>

       The following functions are standard replacements functions for the POSIX API.  The difference is  mainly
       that  they suspend the current thread only instead of the whole process in case the file descriptors will
       block.

       int <b>pth_nanosleep</b>(const struct timespec *<u>rqtp</u>, struct timespec *<u>rmtp</u>);
           This is a variant of the POSIX <u><a href="../man3/nanosleep.3.html">nanosleep</a></u>(3) function. It suspends the current threads execution until
           the amount of time in <u>rqtp</u> elapsed.  The thread is guaranteed to not wake up before  this  time,  but
           because  of the non-preemptive scheduling nature of <b>Pth</b>, it can be awakened later, of course. If <u>rmtp</u>
           is not "NULL", the "timespec" structure it references is updated to contain the unslept  amount  (the
           request  time  minus  the  time  actually  slept  time).  The  difference  between  <u><a href="../man3/nanosleep.3.html">nanosleep</a></u>(3)  and
           <u><a href="../man3/pth_nanosleep.3.html">pth_nanosleep</a></u>(3) is that that <u><a href="../man3/pth_nanosleep.3.html">pth_nanosleep</a></u>(3) suspends only the execution of the current thread  and
           not the whole process.

       int <b>pth_usleep</b>(unsigned int <u>usec</u>);
           This  is  a variant of the 4.3BSD <u><a href="../man3/usleep.3.html">usleep</a></u>(3) function. It suspends the current threads execution until
           <u>usec</u> microseconds (= <u>usec</u>*1/1000000 sec) elapsed.  The thread is guaranteed to  not  wake  up  before
           this  time,  but because of the non-preemptive scheduling nature of <b>Pth</b>, it can be awakened later, of
           course.  The difference between <u><a href="../man3/usleep.3.html">usleep</a></u>(3) and <u><a href="../man3/pth_usleep.3.html">pth_usleep</a></u>(3) is that that <u><a href="../man3/pth_usleep.3.html">pth_usleep</a></u>(3) suspends  only
           the execution of the current thread and not the whole process.

       unsigned int <b>pth_sleep</b>(unsigned int <u>sec</u>);
           This is a variant of the POSIX <u><a href="../man3/sleep.3.html">sleep</a></u>(3) function. It suspends the current threads execution until <u>sec</u>
           seconds  elapsed.   The thread is guaranteed to not wake up before this time, but because of the non-
           preemptive scheduling nature of <b>Pth</b>, it can be awakened later, of  course.   The  difference  between
           <u><a href="../man3/sleep.3.html">sleep</a></u>(3)  and <u><a href="../man3/pth_sleep.3.html">pth_sleep</a></u>(3) is that <u><a href="../man3/pth_sleep.3.html">pth_sleep</a></u>(3) suspends only the execution of the current thread and
           not the whole process.

       pid_t <b>pth_waitpid</b>(pid_t <u>pid</u>, int *<u>status</u>, int <u>options</u>);
           This is a variant of the POSIX <u><a href="../man2/waitpid.2.html">waitpid</a></u>(2) function. It suspends the current threads  execution  until
           <u>status</u>  information  is  available  for  a  terminated  child  process  <u>pid</u>.   The difference between
           <u><a href="../man2/waitpid.2.html">waitpid</a></u>(2) and <u><a href="../man3/pth_waitpid.3.html">pth_waitpid</a></u>(3) is that <u><a href="../man3/pth_waitpid.3.html">pth_waitpid</a></u>(3) suspends  only  the  execution  of  the  current
           thread and not the whole process.  For more details about the arguments and return code semantics see
           <u><a href="../man2/waitpid.2.html">waitpid</a></u>(2).

       int <b>pth_system</b>(const char *<u>cmd</u>);
           This  is  a  variant  of  the POSIX <u><a href="../man3/system.3.html">system</a></u>(3) function. It executes the shell command <u>cmd</u> with Bourne
           Shell ("sh") and suspends the current threads execution until this command terminates. The difference
           between <u><a href="../man3/system.3.html">system</a></u>(3) and <u><a href="../man3/pth_system.3.html">pth_system</a></u>(3) is that <u><a href="../man3/pth_system.3.html">pth_system</a></u>(3) suspends only the execution of the  current
           thread  and not the whole process. For more details about the arguments and return code semantics see
           <u><a href="../man3/system.3.html">system</a></u>(3).

       int <b>pth_sigmask</b>(int <u>how</u>, const sigset_t *<u>set</u>, sigset_t *<u>oset</u>)
           This is the <b>Pth</b> thread-related equivalent of POSIX  <u><a href="../man2/sigprocmask.2.html">sigprocmask</a></u>(2)  respectively  <u><a href="../man3/pthread_sigmask.3.html">pthread_sigmask</a></u>(3).
           The  arguments  <u>how</u>, <u>set</u> and <u>oset</u> directly relate to <u><a href="../man2/sigprocmask.2.html">sigprocmask</a></u>(2), because <b>Pth</b> internally just uses
           <u><a href="../man2/sigprocmask.2.html">sigprocmask</a></u>(2) here. So alternatively you can also directly call <u><a href="../man2/sigprocmask.2.html">sigprocmask</a></u>(2), but for  consistency
           reasons you should use this function <u><a href="../man3/pth_sigmask.3.html">pth_sigmask</a></u>(3).

       int <b>pth_sigwait</b>(const sigset_t *<u>set</u>, int *<u>sig</u>);
           This  is  a  variant  of  the POSIX.1c <u><a href="../man3/sigwait.3.html">sigwait</a></u>(3) function. It suspends the current threads execution
           until a signal in <u>set</u> occurred and stores the signal number in <u>sig</u>. The important point is  that  the
           signal  is  not  delivered to a signal handler. Instead it's caught by the scheduler only in order to
           awake the <u>pth_sigwait()</u> call. The trick and noticeable point  here  is  that  this  way  you  get  an
           asynchronous  aware  application  that  is written completely synchronously. When you think about the
           problem of <u>asynchronous</u> <u>safe</u> functions you should recognize that this is a great benefit.

       int <b>pth_connect</b>(int <u>s</u>, const struct sockaddr *<u>addr</u>, socklen_t <u>addrlen</u>);
           This is a variant of the 4.2BSD <u><a href="../man2/connect.2.html">connect</a></u>(2) function. It establishes a connection on  a  socket  <u>s</u>  to
           target  specified  in <u>addr</u> and <u>addrlen</u>.  The difference between <u><a href="../man2/connect.2.html">connect</a></u>(2) and <u><a href="../man3/pth_connect.3.html">pth_connect</a></u>(3) is that
           <u><a href="../man3/pth_connect.3.html">pth_connect</a></u>(3) suspends only the execution of the current thread and not the whole process.  For more
           details about the arguments and return code semantics see <u><a href="../man2/connect.2.html">connect</a></u>(2).

       int <b>pth_accept</b>(int <u>s</u>, struct sockaddr *<u>addr</u>, socklen_t *<u>addrlen</u>);
           This is a variant of the 4.2BSD <u><a href="../man2/accept.2.html">accept</a></u>(2) function. It accepts a connection on a socket by extracting
           the first connection request on the queue of pending connections, creating a new socket with the same
           properties of <u>s</u> and allocates a new  file  descriptor  for  the  socket  (which  is  returned).   The
           difference  between  <u><a href="../man2/accept.2.html">accept</a></u>(2) and <u><a href="../man3/pth_accept.3.html">pth_accept</a></u>(3) is that <u><a href="../man3/pth_accept.3.html">pth_accept</a></u>(3) suspends only the execution of
           the current thread and not the whole process.  For more details about the arguments and  return  code
           semantics see <u><a href="../man2/accept.2.html">accept</a></u>(2).

       int <b>pth_select</b>(int <u>nfd</u>, fd_set *<u>rfds</u>, fd_set *<u>wfds</u>, fd_set *<u>efds</u>, struct timeval *<u>timeout</u>);
           This  is  a  variant  of  the  4.2BSD  <u><a href="../man2/select.2.html">select</a></u>(2) function.  It examines the I/O descriptor sets whose
           addresses are passed in <u>rfds</u>, <u>wfds</u>, and <u>efds</u> to see if  some  of  their  descriptors  are  ready  for
           reading,  are  ready  for  writing, or have an exceptional condition pending, respectively.  For more
           details about the arguments and return code semantics see <u><a href="../man2/select.2.html">select</a></u>(2).

       int <b>pth_pselect</b>(int <u>nfd</u>, fd_set *<u>rfds</u>, fd_set *<u>wfds</u>, fd_set *<u>efds</u>, const struct timespec *<u>timeout</u>, const
       sigset_t *<u>sigmask</u>);
           This is a variant of the POSIX <u><a href="../man2/pselect.2.html">pselect</a></u>(2) function, which in turn is a  stronger  variant  of  4.2BSD
           <u><a href="../man2/select.2.html">select</a></u>(2).  The  difference  is that the higher-resolution "struct timespec" is passed instead of the
           lower-resolution "struct timeval" and that a signal mask is specified which is temporarily set  while
           waiting  for input. For more details about the arguments and return code semantics see <u><a href="../man2/pselect.2.html">pselect</a></u>(2) and
           <u><a href="../man2/select.2.html">select</a></u>(2).

       int <b>pth_poll</b>(struct pollfd *<u>fds</u>, unsigned int <u>nfd</u>, int <u>timeout</u>);
           This is a variant of the SysV <u><a href="../man2/poll.2.html">poll</a></u>(2) function. It examines the I/O descriptors which are  passed  in
           the  array  <u>fds</u>  to  see  if  some  of  them are ready for reading, are ready for writing, or have an
           exceptional condition pending, respectively. For more details about the  arguments  and  return  code
           semantics see <u><a href="../man2/poll.2.html">poll</a></u>(2).

       ssize_t <b>pth_read</b>(int <u>fd</u>, void *<u>buf</u>, size_t <u>nbytes</u>);
           This  is  a  variant  of  the  POSIX <u><a href="../man2/read.2.html">read</a></u>(2) function. It reads up to <u>nbytes</u> bytes into <u>buf</u> from file
           descriptor <u>fd</u>.  The difference between <u><a href="../man2/read.2.html">read</a></u>(2) and <u><a href="../man2/pth_read.2.html">pth_read</a></u>(2) is that <u><a href="../man2/pth_read.2.html">pth_read</a></u>(2) suspends execution
           of the current thread until the file descriptor is ready for reading.  For  more  details  about  the
           arguments and return code semantics see <u><a href="../man2/read.2.html">read</a></u>(2).

       ssize_t <b>pth_readv</b>(int <u>fd</u>, const struct iovec *<u>iovec</u>, int <u>iovcnt</u>);
           This  is  a  variant  of  the POSIX <u><a href="../man2/readv.2.html">readv</a></u>(2) function. It reads data from file descriptor <u>fd</u> into the
           first <u>iovcnt</u> rows of the <u>iov</u> vector.  The  difference  between  <u><a href="../man2/readv.2.html">readv</a></u>(2)  and  <u><a href="../man2/pth_readv.2.html">pth_readv</a></u>(2)  is  that
           <u><a href="../man2/pth_readv.2.html">pth_readv</a></u>(2) suspends execution of the current thread until the file descriptor is ready for reading.
           For more details about the arguments and return code semantics see <u><a href="../man2/readv.2.html">readv</a></u>(2).

       ssize_t <b>pth_write</b>(int <u>fd</u>, const void *<u>buf</u>, size_t <u>nbytes</u>);
           This  is a variant of the POSIX <u><a href="../man2/write.2.html">write</a></u>(2) function. It writes <u>nbytes</u> bytes from <u>buf</u> to file descriptor
           <u>fd</u>.  The difference between <u><a href="../man2/write.2.html">write</a></u>(2) and <u><a href="../man2/pth_write.2.html">pth_write</a></u>(2) is that <u><a href="../man2/pth_write.2.html">pth_write</a></u>(2) suspends execution of  the
           current  thread until the file descriptor is ready for writing.  For more details about the arguments
           and return code semantics see <u><a href="../man2/write.2.html">write</a></u>(2).

       ssize_t <b>pth_writev</b>(int <u>fd</u>, const struct iovec *<u>iovec</u>, int <u>iovcnt</u>);
           This is a variant of the POSIX <u><a href="../man2/writev.2.html">writev</a></u>(2) function. It writes data to  file  descriptor  <u>fd</u>  from  the
           first  <u>iovcnt</u>  rows  of  the  <u>iov</u> vector.  The difference between <u><a href="../man2/writev.2.html">writev</a></u>(2) and <u><a href="../man2/pth_writev.2.html">pth_writev</a></u>(2) is that
           <u><a href="../man2/pth_writev.2.html">pth_writev</a></u>(2) suspends execution of the current  thread  until  the  file  descriptor  is  ready  for
           reading. For more details about the arguments and return code semantics see <u><a href="../man2/writev.2.html">writev</a></u>(2).

       ssize_t <b>pth_pread</b>(int <u>fd</u>, void *<u>buf</u>, size_t <u>nbytes</u>, off_t <u>offset</u>);
           This  is a variant of the POSIX <u><a href="../man3/pread.3.html">pread</a></u>(3) function.  It performs the same action as a regular <u><a href="../man2/read.2.html">read</a></u>(2),
           except that it reads from a given position in the file without changing the file pointer.  The  first
           three arguments are the same as for <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3) with the addition of a fourth argument <u>offset</u> for the
           desired position inside the file.

       ssize_t <b>pth_pwrite</b>(int <u>fd</u>, const void *<u>buf</u>, size_t <u>nbytes</u>, off_t <u>offset</u>);
           This  is  a  variant  of  the  POSIX  <u><a href="../man3/pwrite.3.html">pwrite</a></u>(3)  function.   It performs the same action as a regular
           <u><a href="../man2/write.2.html">write</a></u>(2), except that it writes to a given position in the file without changing  the  file  pointer.
           The  first  three  arguments  are the same as for <u><a href="../man3/pth_write.3.html">pth_write</a></u>(3) with the addition of a fourth argument
           <u>offset</u> for the desired position inside the file.

       ssize_t <b>pth_recv</b>(int <u>fd</u>, void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>);
           This is a variant of the SUSv2 <u><a href="../man2/recv.2.html">recv</a></u>(2) function and equal to ``pth_recvfrom(fd, buf,  nbytes,  flags,
           NULL, 0)''.

       ssize_t <b>pth_recvfrom</b>(int <u>fd</u>, void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>, struct sockaddr *<u>from</u>, socklen_t
       *<u>fromlen</u>);
           This  is  a variant of the SUSv2 <u><a href="../man2/recvfrom.2.html">recvfrom</a></u>(2) function. It reads up to <u>nbytes</u> bytes into <u>buf</u> from file
           descriptor  <u>fd</u>  while  using  <u>flags</u>  and  <u>from</u>/<u>fromlen</u>.  The  difference  between   <u><a href="../man2/recvfrom.2.html">recvfrom</a></u>(2)   and
           <u><a href="../man2/pth_recvfrom.2.html">pth_recvfrom</a></u>(2)  is  that  <u><a href="../man2/pth_recvfrom.2.html">pth_recvfrom</a></u>(2)  suspends  execution  of the current thread until the file
           descriptor is ready for reading. For more details about the arguments and return code  semantics  see
           <u><a href="../man2/recvfrom.2.html">recvfrom</a></u>(2).

       ssize_t <b>pth_send</b>(int <u>fd</u>, const void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>);
           This  is  a  variant  of the SUSv2 <u><a href="../man2/send.2.html">send</a></u>(2) function and equal to ``pth_sendto(fd, buf, nbytes, flags,
           NULL, 0)''.

       ssize_t <b>pth_sendto</b>(int <u>fd</u>, const void *<u>buf</u>, size_t <u>nbytes</u>, int <u>flags</u>, const struct sockaddr *<u>to</u>,
       socklen_t <u>tolen</u>);
           This is a variant of the SUSv2 <u><a href="../man2/sendto.2.html">sendto</a></u>(2) function. It writes <u>nbytes</u> bytes from <u>buf</u> to file descriptor
           <u>fd</u> while using <u>flags</u> and <u>to</u>/<u>tolen</u>.  The  difference  between  <u><a href="../man2/sendto.2.html">sendto</a></u>(2)  and  <u><a href="../man2/pth_sendto.2.html">pth_sendto</a></u>(2)  is  that
           <u><a href="../man2/pth_sendto.2.html">pth_sendto</a></u>(2)  suspends  execution  of  the  current  thread  until  the file descriptor is ready for
           writing. For more details about the arguments and return code semantics see <u><a href="../man2/sendto.2.html">sendto</a></u>(2).

</pre><h4><b>EXAMPLE</b></h4><pre>
       The following example is a useless server which does nothing more than listening on TCP  port  12345  and
       displaying the current time to the socket when a connection was established. For each incoming connection
       a   thread  is  spawned.  Additionally,  to  see  more  multithreading,  a  useless  ticker  thread  runs
       simultaneously which outputs the current time to "stderr" every 5 seconds. The example contains <u>no</u>  error
       checking and is <u>only</u> intended to show you the look and feel of <b>Pth</b>.

        #include &lt;<a href="file:/usr/include/stdio.h">stdio.h</a>&gt;
        #include &lt;<a href="file:/usr/include/stdlib.h">stdlib.h</a>&gt;
        #include &lt;<a href="file:/usr/include/errno.h">errno.h</a>&gt;
        #include &lt;sys/types.h&gt;
        #include &lt;sys/socket.h&gt;
        #include &lt;<a href="file:/usr/include/netinet/in.h">netinet/in.h</a>&gt;
        #include &lt;<a href="file:/usr/include/arpa/inet.h">arpa/inet.h</a>&gt;
        #include &lt;<a href="file:/usr/include/signal.h">signal.h</a>&gt;
        #include &lt;<a href="file:/usr/include/netdb.h">netdb.h</a>&gt;
        #include &lt;<a href="file:/usr/include/unistd.h">unistd.h</a>&gt;
        #include "pth.h"

        #define PORT 12345

        /* the socket connection handler thread */
        static void *handler(void *_arg)
        {
            int fd = (int)_arg;
            time_t now;
            char *ct;

            now = time(NULL);
            ct = ctime(&amp;now);
            pth_write(fd, ct, strlen(ct));
            close(fd);
            return NULL;
        }

        /* the stderr time ticker thread */
        static void *ticker(void *_arg)
        {
            time_t now;
            char *ct;
            float load;

            for (;;) {
                <a href="../man5/pth_sleep.5.html">pth_sleep</a>(5);
                now = time(NULL);
                ct = ctime(&amp;now);
                ct[strlen(ct)-1] = '\0';
                pth_ctrl(PTH_CTRL_GETAVLOAD, &amp;load);
                printf("ticker: time: %s, average load: %.2f\n", ct, load);
            }
        }

        /* the main thread/procedure */
        int main(int argc, char *argv[])
        {
            pth_attr_t attr;
            struct sockaddr_in sar;
            struct protoent *pe;
            struct sockaddr_in peer_addr;
            int peer_len;
            int sa, sw;
            int port;

            pth_init();
            signal(SIGPIPE, SIG_IGN);

            attr = pth_attr_new();
            pth_attr_set(attr, PTH_ATTR_NAME, "ticker");
            pth_attr_set(attr, PTH_ATTR_STACK_SIZE, 64*1024);
            pth_attr_set(attr, PTH_ATTR_JOINABLE, FALSE);
            pth_spawn(attr, ticker, NULL);

            pe = getprotobyname("tcp");
            sa = socket(AF_INET, SOCK_STREAM, pe-&gt;p_proto);
            sar.sin_family = AF_INET;
            sar.sin_addr.s_addr = INADDR_ANY;
            sar.sin_port = htons(PORT);
            bind(sa, (struct sockaddr *)&amp;sar, sizeof(struct sockaddr_in));
            listen(sa, 10);

            pth_attr_set(attr, PTH_ATTR_NAME, "handler");
            for (;;) {
                peer_len = sizeof(peer_addr);
                sw = pth_accept(sa, (struct sockaddr *)&amp;peer_addr, &amp;peer_len);
                pth_spawn(attr, handler, (void *)sw);
            }
        }

</pre><h4><b>BUILD</b> <b>ENVIRONMENTS</b></h4><pre>
       In  this  section  we  will discuss the canonical ways to establish the build environment for a <b>Pth</b> based
       program. The possibilities supported by <b>Pth</b> range from very simple environments to rather complex ones.

       <b>Manual</b> <b>Build</b> <b>Environment</b> <b>(Novice)</b>

       As a first example, assume we have the above test program staying in the source file "foo.c". Then we can
       create a very simple build environment by just adding the following "Makefile":

        $ vi Makefile
        ⎪ CC      = cc
        ⎪ CFLAGS  = `pth-config --cflags`
        ⎪ LDFLAGS = `pth-config --ldflags`
        ⎪ LIBS    = `pth-config --libs`
        ⎪
        ⎪ all: foo
        ⎪ foo: foo.o
        ⎪     $(CC) $(LDFLAGS) -o foo foo.o $(LIBS)
        ⎪ foo.o: foo.c
        ⎪     $(CC) $(CFLAGS) -c foo.c
        ⎪ clean:
        ⎪     rm -f foo foo.o

       This imports the necessary compiler and linker  flags  on-the-fly  from  the  <b>Pth</b>  installation  via  its
       "pth-config" program. This approach is straight-forward and works fine for small projects.

       <b>Autoconf</b> <b>Build</b> <b>Environment</b> <b>(Advanced)</b>

       The  previous  approach  is  simple  but inflexible. First, to speed up building, it would be nice to not
       expand the compiler and linker flags every time the compiler is started. Second, it would  be  useful  to
       also  be  able  to  build  against  uninstalled  <b>Pth</b>,  that  is, against a <b>Pth</b> source tree which was just
       configured and built, but not installed. Third, it would be also useful to  allow  checking  of  the  <b>Pth</b>
       version  to  make sure it is at least a minimum required version.  And finally, it would be also great to
       make sure <b>Pth</b> works correctly by first performing some sanity compile and run-time checks. All  this  can
       be  done  if we use GNU <b>autoconf</b> and the "AC_CHECK_PTH" macro provided by <b>Pth</b>. For this, we establish the
       following three files:

       First we again need the "Makefile", but this  time  it  contains  <b>autoconf</b>  placeholders  and  additional
       cleanup  targets.  And  we  create  it  under the name "Makefile.in", because it is now an input file for
       <b>autoconf</b>:

        $ vi Makefile.in
        ⎪ CC      = @CC@
        ⎪ CFLAGS  = @CFLAGS@
        ⎪ LDFLAGS = @LDFLAGS@
        ⎪ LIBS    = @LIBS@
        ⎪
        ⎪ all: foo
        ⎪ foo: foo.o
        ⎪     $(CC) $(LDFLAGS) -o foo foo.o $(LIBS)
        ⎪ foo.o: foo.c
        ⎪     $(CC) $(CFLAGS) -c foo.c
        ⎪ clean:
        ⎪     rm -f foo foo.o
        ⎪ distclean:
        ⎪     rm -f foo foo.o
        ⎪     rm -f config.log config.status config.cache
        ⎪     rm -f Makefile

       Because <b>autoconf</b> generates additional files, we added a canonical "distclean" target  which  cleans  this
       up. Secondly, we wrote "configure.ac", a (minimal) <b>autoconf</b> script specification:

        $ vi configure.ac
        ⎪ AC_INIT(Makefile.in)
        ⎪ AC_CHECK_PTH(1.3.0)
        ⎪ AC_OUTPUT(Makefile)

       Then  we  let  <b>autoconf</b>'s  "aclocal"  program  generate  for  us  an  "aclocal.m4"  file containing <b>Pth</b>'s
       "AC_CHECK_PTH" macro. Then we generate the final "configure" script out of this "aclocal.m4" file and the
       "configure.ac" file:

        $ aclocal --acdir=`pth-config --acdir`
        $ autoconf

       After these steps, the working directory should look similar to this:

        $ ls -l
        -rw-r--r--  1 rse  users    176 Nov  3 11:11 Makefile.in
        -rw-r--r--  1 rse  users  15314 Nov  3 11:16 aclocal.m4
        -rwxr-xr-x  1 rse  users  52045 Nov  3 11:16 configure
        -rw-r--r--  1 rse  users     63 Nov  3 11:11 configure.ac
        -rw-r--r--  1 rse  users   4227 Nov  3 11:11 foo.c

       If we now run "configure" we get a correct "Makefile" which  immediately  can  be  used  to  build  "foo"
       (assuming that <b>Pth</b> is already installed somewhere, so that "pth-config" is in $PATH):

        $ ./configure
        creating cache ./config.cache
        checking for gcc... gcc
        checking whether the C compiler (gcc   ) works... yes
        checking whether the C compiler (gcc   ) is a cross-compiler... no
        checking whether we are using GNU C... yes
        checking whether gcc accepts -g... yes
        checking how to run the C preprocessor... gcc -E
        checking for GNU Pth... version 1.3.0, installed under <a href="file:/usr/local">/usr/local</a>
        updating cache ./config.cache
        creating ./config.status
        creating Makefile
        rse@en1:/e/gnu/pth/ac
        $ make
        gcc -g -O2 -I/usr/local/include -c foo.c
        gcc -L/usr/local/lib -o foo foo.o -lpth

       If  <b>Pth</b>  is installed in non-standard locations or "pth-config" is not in $PATH, one just has to drop the
       "configure" script a note about the location by running  "configure"  with  the  option  "--with-pth="<u>dir</u>
       (where <u>dir</u> is the argument which was used with the "--prefix" option when <b>Pth</b> was installed).

       <b>Autoconf</b> <b>Build</b> <b>Environment</b> <b>with</b> <b>Local</b> <b>Copy</b> <b>of</b> <b>Pth</b> <b>(Expert)</b>

       Finally let us assume the "foo" program stays under either a <u>GPL</u> or <u>LGPL</u> distribution license and we want
       to  make  it  a  stand-alone package for easier distribution and installation.  That is, we don't want to
       oblige the end-user to install <b>Pth</b> just to allow our  "foo"  package  to  compile.  For  this,  it  is  a
       convenient  practice  to  include  the  required libraries (here <b>Pth</b>) into the source tree of the package
       (here "foo").  <b>Pth</b> ships with all necessary support to allow us to easily achieve this approach. Say,  we
       want  <b>Pth</b>  in  a  subdirectory  named  "pth/" and this directory should be seamlessly integrated into the
       configuration and build process of "foo".

       First we again start with the "Makefile.in", but this time it is a more advanced version  which  supports
       subdirectory movement:

        $ vi Makefile.in
        ⎪ CC      = @CC@
        ⎪ CFLAGS  = @CFLAGS@
        ⎪ LDFLAGS = @LDFLAGS@
        ⎪ LIBS    = @LIBS@
        ⎪
        ⎪ SUBDIRS = pth
        ⎪
        ⎪ all: subdirs_all foo
        ⎪
        ⎪ subdirs_all:
        ⎪     @$(MAKE) $(MFLAGS) subdirs TARGET=all
        ⎪ subdirs_clean:
        ⎪     @$(MAKE) $(MFLAGS) subdirs TARGET=clean
        ⎪ subdirs_distclean:
        ⎪     @$(MAKE) $(MFLAGS) subdirs TARGET=distclean
        ⎪ subdirs:
        ⎪     @for subdir in $(SUBDIRS); do \
        ⎪         echo "===&gt; $$subdir ($(TARGET))"; \
        ⎪         (cd $$subdir; $(MAKE) $(MFLAGS) $(TARGET) ⎪⎪ exit 1) ⎪⎪ exit 1; \
        ⎪         echo "&lt;=== $$subdir"; \
        ⎪     done
        ⎪
        ⎪ foo: foo.o
        ⎪     $(CC) $(LDFLAGS) -o foo foo.o $(LIBS)
        ⎪ foo.o: foo.c
        ⎪     $(CC) $(CFLAGS) -c foo.c
        ⎪
        ⎪ clean: subdirs_clean
        ⎪     rm -f foo foo.o
        ⎪ distclean: subdirs_distclean
        ⎪     rm -f foo foo.o
        ⎪     rm -f config.log config.status config.cache
        ⎪     rm -f Makefile

       Then we create a slightly different <b>autoconf</b> script "configure.ac":

        $ vi configure.ac
        ⎪ AC_INIT(Makefile.in)
        ⎪ AC_CONFIG_AUX_DIR(pth)
        ⎪ AC_CHECK_PTH(1.3.0, subdir:pth --disable-tests)
        ⎪ AC_CONFIG_SUBDIRS(pth)
        ⎪ AC_OUTPUT(Makefile)

       Here we provided a default value for "foo"'s "--with-pth" option as the second argument to "AC_CHECK_PTH"
       which  indicates  that  <b>Pth</b> can be found in the subdirectory named "pth/". Additionally we specified that
       the "--disable-tests" option of <b>Pth</b> should be passed to the "pth/" subdirectory, because we need only  to
       build  the <b>Pth</b> library itself. And we added a "AC_CONFIG_SUBDIR" call which indicates to <b>autoconf</b> that it
       should configure the "pth/" subdirectory, too. The "AC_CONFIG_AUX_DIR" directive was added just  to  make
       <b>autoconf</b>  happy,  because  it  wants  to find a "install.sh" or "shtool" script if "AC_CONFIG_SUBDIRS" is
       used.

       Now we let <b>autoconf</b>'s "aclocal" program again generate for us an "aclocal.m4" file with the  contents  of
       <b>Pth</b>'s "AC_CHECK_PTH" macro.  Finally we generate the "configure" script out of this "aclocal.m4" file and
       the "configure.ac" file.

        $ aclocal --acdir=`pth-config --acdir`
        $ autoconf

       Now  we  have  to create the "pth/" subdirectory itself. For this, we extract the <b>Pth</b> distribution to the
       "foo" source tree and just rename it to "pth/":

        $ gunzip &lt;pth-X.Y.Z.tar.gz ⎪ tar xvf -
        $ mv pth-X.Y.Z pth

       Optionally to reduce the size of the "pth/" subdirectory, we can strip down the <b>Pth</b> sources to a  minimum
       with the <u>striptease</u> feature:

        $ cd pth
        $ ./configure
        $ make striptease
        $ cd ..

       After this the source tree of "foo" should look similar to this:

        $ ls -l
        -rw-r--r--  1 rse  users    709 Nov  3 11:51 Makefile.in
        -rw-r--r--  1 rse  users  16431 Nov  3 12:20 aclocal.m4
        -rwxr-xr-x  1 rse  users  57403 Nov  3 12:21 configure
        -rw-r--r--  1 rse  users    129 Nov  3 12:21 configure.ac
        -rw-r--r--  1 rse  users   4227 Nov  3 11:11 foo.c
        drwxr-xr-x  2 rse  users   3584 Nov  3 12:36 pth
        $ ls -l pth/
        -rw-rw-r--  1 rse  users   26344 Nov  1 20:12 COPYING
        -rw-rw-r--  1 rse  users    2042 Nov  3 12:36 Makefile.in
        -rw-rw-r--  1 rse  users    3967 Nov  1 19:48 README
        -rw-rw-r--  1 rse  users     340 Nov  3 12:36 README.1st
        -rw-rw-r--  1 rse  users   28719 Oct 31 17:06 config.guess
        -rw-rw-r--  1 rse  users   24274 Aug 18 13:31 config.sub
        -rwxrwxr-x  1 rse  users  155141 Nov  3 12:36 configure
        -rw-rw-r--  1 rse  users  162021 Nov  3 12:36 pth.c
        -rw-rw-r--  1 rse  users   18687 Nov  2 15:19 pth.h.in
        -rw-rw-r--  1 rse  users    5251 Oct 31 12:46 pth_acdef.h.in
        -rw-rw-r--  1 rse  users    2120 Nov  1 11:27 pth_acmac.h.in
        -rw-rw-r--  1 rse  users    2323 Nov  1 11:27 pth_p.h.in
        -rw-rw-r--  1 rse  users     946 Nov  1 11:27 pth_vers.c
        -rw-rw-r--  1 rse  users   26848 Nov  1 11:27 pthread.c
        -rw-rw-r--  1 rse  users   18772 Nov  1 11:27 pthread.h.in
        -rwxrwxr-x  1 rse  users   26188 Nov  3 12:36 shtool

       Now when we configure and build the "foo" package it looks similar to this:

        $ ./configure
        creating cache ./config.cache
        checking for gcc... gcc
        checking whether the C compiler (gcc   ) works... yes
        checking whether the C compiler (gcc   ) is a cross-compiler... no
        checking whether we are using GNU C... yes
        checking whether gcc accepts -g... yes
        checking how to run the C preprocessor... gcc -E
        checking for GNU Pth... version 1.3.0, local under pth
        updating cache ./config.cache
        creating ./config.status
        creating Makefile
        configuring in pth
        running <a href="file:/bin/sh">/bin/sh</a> ./configure  --enable-subdir --enable-batch
        --disable-tests --cache-file=.././config.cache --srcdir=.
        loading cache .././config.cache
        checking for gcc... (cached) gcc
        checking whether the C compiler (gcc   ) works... yes
        checking whether the C compiler (gcc   ) is a cross-compiler... no
        [...]
        $ make
        ===&gt; pth (all)
        ./shtool scpp -o pth_p.h -t pth_p.h.in -Dcpp -Cintern -M '==#==' pth.c
        pth_vers.c
        gcc -c -I. -O2 -pipe pth.c
        gcc -c -I. -O2 -pipe pth_vers.c
        ar rc libpth.a pth.o pth_vers.o
        ranlib libpth.a
        &lt;=== pth
        gcc -g -O2 -Ipth -c foo.c
        gcc -Lpth -o foo foo.o -lpth

       As  you  can  see,  <b>autoconf</b>  now  automatically  configures the local (stripped down) copy of <b>Pth</b> in the
       subdirectory "pth/" and the "Makefile" automatically builds the subdirectory, too.

</pre><h4><b>SYSTEM</b> <b>CALL</b> <b>WRAPPER</b> <b>FACILITY</b></h4><pre>
       <b>Pth</b> per default uses an explicit API, including the system calls. For instance you've to  explicitly  use
       <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3)  when you need a thread-aware <u><a href="../man3/read.3.html">read</a></u>(3) and cannot expect that by just calling <u><a href="../man3/read.3.html">read</a></u>(3) only the
       current thread is blocked. Instead with the standard <u><a href="../man3/read.3.html">read</a></u>(3) call the whole process will be blocked.  But
       because  for  some  applications  (mainly  those  consisting  of  lots  of third-party stuff) this can be
       inconvenient.  Here it's required that a call to <u><a href="../man3/read.3.html">read</a></u>(3) `magically' means <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3). The problem  here
       is  that  such  magic  <b>Pth</b> cannot provide per default because it's not really portable.  Nevertheless <b>Pth</b>
       provides a two step approach to solve this problem:

       <b>Soft</b> <b>System</b> <b>Call</b> <b>Mapping</b>

       This  variant  is  available  on  all  platforms  and  can  <u>always</u>  be  enabled  by  building  <b>Pth</b>   with
       "--enable-syscall-soft". This then triggers some "#define"'s in the "pth.h" header which map for instance
       <u><a href="../man3/read.3.html">read</a></u>(3)  to  <u><a href="../man3/pth_read.3.html">pth_read</a></u>(3),  etc.  Currently  the  following  functions  are mapped: <u><a href="../man2/fork.2.html">fork</a></u>(2), <u><a href="../man3/nanosleep.3.html">nanosleep</a></u>(3),
       <u><a href="../man3/usleep.3.html">usleep</a></u>(3), <u><a href="../man3/sleep.3.html">sleep</a></u>(3),  <u><a href="../man3/sigwait.3.html">sigwait</a></u>(3),  <u><a href="../man2/waitpid.2.html">waitpid</a></u>(2),  <u><a href="../man3/system.3.html">system</a></u>(3),  <u><a href="../man2/select.2.html">select</a></u>(2),  <u><a href="../man2/poll.2.html">poll</a></u>(2),  <u><a href="../man2/connect.2.html">connect</a></u>(2),  <u><a href="../man2/accept.2.html">accept</a></u>(2),
       <u><a href="../man2/read.2.html">read</a></u>(2), <u><a href="../man2/write.2.html">write</a></u>(2), <u><a href="../man2/recv.2.html">recv</a></u>(2), <u><a href="../man2/send.2.html">send</a></u>(2), <u><a href="../man2/recvfrom.2.html">recvfrom</a></u>(2), <u><a href="../man2/sendto.2.html">sendto</a></u>(2).

       The  drawback  of  this  approach  is  just  that  really all source files of the application where these
       function calls occur have to include "pth.h", of course. And this also  means  that  existing  libraries,
       including  the  vendor's  <b>stdio</b>,  usually  will still block the whole process if one of its I/O functions
       block.

       <b>Hard</b> <b>System</b> <b>Call</b> <b>Mapping</b>

       This variant is available only on those platforms where the <u><a href="../man2/syscall.2.html">syscall</a></u>(2) function exists and there  it  can
       be  enabled  by  building  <b>Pth</b>  with  "--enable-syscall-hard".  This  then  builds wrapper functions (for
       instances <u><a href="../man3/read.3.html">read</a></u>(3)) into the <b>Pth</b>  library  which  internally  call  the  real  <b>Pth</b>  replacement  functions
       (<u><a href="../man3/pth_read.3.html">pth_read</a></u>(3)).  Currently the following functions are mapped: <u><a href="../man2/fork.2.html">fork</a></u>(2), <u><a href="../man3/nanosleep.3.html">nanosleep</a></u>(3), <u><a href="../man3/usleep.3.html">usleep</a></u>(3), <u><a href="../man3/sleep.3.html">sleep</a></u>(3),
       <u><a href="../man2/waitpid.2.html">waitpid</a></u>(2), <u><a href="../man3/system.3.html">system</a></u>(3), <u><a href="../man2/select.2.html">select</a></u>(2), <u><a href="../man2/poll.2.html">poll</a></u>(2), <u><a href="../man2/connect.2.html">connect</a></u>(2), <u><a href="../man2/accept.2.html">accept</a></u>(2), <u><a href="../man2/read.2.html">read</a></u>(2), <u><a href="../man2/write.2.html">write</a></u>(2).

       The drawback of this approach is that it depends on <u><a href="../man2/syscall.2.html">syscall</a></u>(2)  interface  and  prototype  conflicts  can
       occur  while  building  the wrapper functions due to different function signatures in the vendor C header
       files.  But the advantage of this mapping variant is that the source files of the application where these
       function calls occur have not to include "pth.h" and that  existing  libraries,  including  the  vendor's
       <b>stdio</b>, magically become thread-aware (and then block only the current thread).

</pre><h4><b>IMPLEMENTATION</b> <b>NOTES</b></h4><pre>
       <b>Pth</b>  is  very  portable because it has only one part which perhaps has to be ported to new platforms (the
       machine context initialization). But it is written in a way which works  on  mostly  all  Unix  platforms
       which  support  <u><a href="../man2/makecontext.2.html">makecontext</a></u>(2)  or at least <u><a href="../man2/sigstack.2.html">sigstack</a></u>(2) or <u><a href="../man2/sigaltstack.2.html">sigaltstack</a></u>(2) [see "pth_mctx.c" for details].
       Any other <b>Pth</b> code is POSIX and ANSI C based only.

       The  context  switching  is  done  via  either  SUSv2  <u><a href="../man2/makecontext.2.html">makecontext</a></u>(2)  or  POSIX  make[sig]<u><a href="../man3/setjmp.3.html">setjmp</a></u>(3)  and
       [sig]<u><a href="../man3/longjmp.3.html">longjmp</a></u>(3).  Here  all  CPU  registers,  the  program  counter  and  the stack pointer are switched.
       Additionally the <b>Pth</b> dispatcher switches also the global Unix  "errno"  variable  [see  "pth_mctx.c"  for
       details]  and  the  signal  mask  (either  implicitly via <u><a href="../man3/sigsetjmp.3.html">sigsetjmp</a></u>(3) or in an emulated way via explicit
       <u><a href="../man2/setprocmask.2.html">setprocmask</a></u>(2) calls).

       The <b>Pth</b> event manager is mainly <u><a href="../man2/select.2.html">select</a></u>(2) and <u><a href="../man2/gettimeofday.2.html">gettimeofday</a></u>(2) based, i.e., the current  time  is  fetched
       via  <u><a href="../man2/gettimeofday.2.html">gettimeofday</a></u>(2) once per context switch for time calculations and all I/O events are implemented via
       a single central <u><a href="../man2/select.2.html">select</a></u>(2) call [see "pth_sched.c" for details].

       The thread control block management is done via virtual  priority  queues  without  any  additional  data
       structure  overhead. For this, the queue linkage attributes are part of the thread control blocks and the
       queues are actually implemented as rings with a selected element as the entry point [see "pth_tcb.h"  and
       "pth_pqueue.c" for details].

       Most  time  critical code sections (especially the dispatcher and event manager) are speeded up by inline
       functions (implemented as ANSI C pre-processor macros). Additionally any  debugging  code  is  <u>completely</u>
       removed  from  the source when not built with "-DPTH_DEBUG" (see Autoconf "--enable-debug" option), i.e.,
       not only stub functions remain [see "pth_debug.c" for details].

</pre><h4><b>RESTRICTIONS</b></h4><pre>
       <b>Pth</b> (intentionally) provides no replacements for non-thread-safe functions (like <u><a href="../man3/strtok.3.html">strtok</a></u>(3) which  uses  a
       static  internal  buffer) or synchronous system functions (like <u><a href="../man3/gethostbyname.3.html">gethostbyname</a></u>(3) which doesn't provide an
       asynchronous mode where it doesn't  block).  When  you  want  to  use  those  functions  in  your  server
       application  together  with  threads,  you've  to either link the application against special third-party
       libraries (or for thread-safe/reentrant functions possibly against an existing "libc_r" of  the  platform
       vendor).  For  an  asynchronous  DNS  resolver  library  use  the GNU <b>adns</b> package from Ian Jackson ( see
       <a href="http://www.gnu.org/software/adns/adns.html">http://www.gnu.org/software/adns/adns.html</a> ).

</pre><h4><b>HISTORY</b></h4><pre>
       The <b>Pth</b> library was designed and implemented between February and July 1999 by <u>Ralf</u> <u>S.</u> <u>Engelschall</u>  after
       evaluating  numerous  (mostly  preemptive)  thread  libraries  and after intensive discussions with <u>Peter</u>
       <u>Simons</u>, <u>Martin</u> <u>Kraemer</u>, <u>Lars</u> <u>Eilebrecht</u> and <u>Ralph</u> <u>Babel</u> related to an experimental  (matrix  based)  non-
       preemptive C++ scheduler class written by <u>Peter</u> <u>Simons</u>.

       <b>Pth</b>  was  then  implemented  in  order  to  combine  the <u>non-preemptive</u> approach of multithreading (which
       provides better portability and performance) with an API similar to the  popular  one  found  in  <b>Pthread</b>
       libraries (which provides easy programming).

       So  the  essential  idea  of  the non-preemptive approach was taken over from <u>Peter</u> <u>Simons</u> scheduler. The
       priority based scheduling algorithm was suggested by <u>Martin</u> <u>Kraemer</u>. Some code inspiration also came from
       an experimental threading library (<b>rsthreads</b>) written by <u>Robert</u> <u>S.</u> <u>Thau</u>  for  an  ancient  internal  test
       version  of  the  Apache webserver.  The concept and API of message ports was borrowed from AmigaOS' <b>Exec</b>
       subsystem. The concept and idea for the flexible event mechanism came from <u>Paul</u> <u>Vixie</u>'s  <b>eventlib</b>  (which
       can be found as a part of <b>BIND</b> v8).

</pre><h4><b>BUG</b> <b>REPORTS</b> <b>AND</b> <b>SUPPORT</b></h4><pre>
       If  you  think  you  have  found  a  bug  in  <b>Pth</b>,  you  should  send a report as complete as possible to
       <u><a href="mailto:bug-pth@gnu.org">bug-pth@gnu.org</a></u>. If you can, please try to fix the problem and include a patch, made with  '"diff  -u3"',
       in  your report. Always, at least, include a reasonable amount of description in your report to allow the
       author to deterministically reproduce the bug.

       For further support you additionally can subscribe to the <u><a href="mailto:pth-users@gnu.org">pth-users@gnu.org</a></u> mailing list  by  sending  an
       Email  to  <u><a href="mailto:pth-users-request@gnu.org">pth-users-request@gnu.org</a></u>  with `"subscribe pth-users"' (or `"subscribe pth-users" <u>address</u>' if
       you want to subscribe from a particular Email <u>address</u>) in the body. Then you can discuss your issues with
       other <b>Pth</b> users by sending messages to <u><a href="mailto:pth-users@gnu.org">pth-users@gnu.org</a></u>. Currently (as of August  2000)  you  can  reach
       about    110    Pth    users    on    this    mailing    list.    Old    postings   you   can   find   at
       <u><a href="http://www.mail-archive.com/pth-users">http://www.mail-archive.com/pth-users</a>@gnu.org/</u>.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b>Related</b> <b>Web</b> <b>Locations</b>

       `comp.programming.threads         Newsgroup          Archive',          <a href="http://www.deja.com/topics_if.xp">http://www.deja.com/topics_if.xp</a>?
       search=topic&amp;group=comp.programming.threads

       `comp.programming.threads            Frequently            Asked           Questions           (F.A.Q.)',
       <a href="http://www.lambdacs.com/newsgroup/FAQ.html">http://www.lambdacs.com/newsgroup/FAQ.html</a>

       `<u>Multithreading</u>     <u>-</u>     <u>Definitions</u>     <u>and</u>     <u>Guidelines</u>',     Numeric      Quest      Inc      1998;
       <a href="http://www.numeric-quest.com/lang/multi-frame.html">http://www.numeric-quest.com/lang/multi-frame.html</a>

       `<u>The</u>    <u>Single</u>    <u>UNIX</u>    <u>Specification,</u>    <u>Version</u>    <u>2</u>    <u>-</u>    <u>Threads</u>',    The    Open   Group   1997;
       <a href="http://www.opengroup.org/onlinepubs">http://www.opengroup.org/onlinepubs</a> /007908799/xsh/threads.html

       SMI Thread Resources, Sun Microsystems Inc; <a href="http://www.sun.com/workshop/threads/">http://www.sun.com/workshop/threads/</a>

       Bibliography        on        threads        and        multithreading,         Torsten         Amundsen;
       <a href="http://liinwww.ira.uka.de/bibliography/Os/threads.html">http://liinwww.ira.uka.de/bibliography/Os/threads.html</a>

       <b>Related</b> <b>Books</b>

       B.   Nichols,   D.   Buttlar,   J.P.  Farrel:  `<u>Pthreads</u>  <u>Programming</u>  <u>-</u>  <u>A</u>  <u>POSIX</u>  <u>Standard</u>  <u>for</u>  <u>Better</u>
       <u>Multiprocessing</u>', O'Reilly 1996; ISBN 1-56592-115-1

       B. Lewis, D. J. Berg: `<u>Multithreaded</u> <u>Programming</u> <u>with</u> <u>Pthreads</u>', Sun Microsystems  Press,  Prentice  Hall
       1998; ISBN 0-13-680729-1

       B.  Lewis,  D. J. Berg: `<u>Threads</u> <u>Primer</u> <u>-</u> <u>A</u> <u>Guide</u> <u>To</u> <u>Multithreaded</u> <u>Programming</u>', Prentice Hall 1996; ISBN
       0-13-443698-9

       S. J. Norton, M. D. Dipasquale: `<u>Thread</u> <u>Time</u> <u>-</u> <u>The</u> <u>Multithreaded</u> <u>Programming</u> <u>Guide</u>', Prentice Hall  1997;
       ISBN 0-13-190067-6

       D. R. Butenhof: `<u>Programming</u> <u>with</u> <u>POSIX</u> <u>Threads</u>', Addison Wesley 1997; ISBN 0-201-63392-2

       <b>Related</b> <b>Manpages</b>

       <u><a href="../man1/pth-config.1.html">pth-config</a></u>(1), <u><a href="../man3/pthread.3.html">pthread</a></u>(3).

       <u><a href="../man2/getcontext.2.html">getcontext</a></u>(2),  <u><a href="../man2/setcontext.2.html">setcontext</a></u>(2), <u><a href="../man2/makecontext.2.html">makecontext</a></u>(2), <u><a href="../man2/swapcontext.2.html">swapcontext</a></u>(2), <u><a href="../man2/sigstack.2.html">sigstack</a></u>(2), <u><a href="../man2/sigaltstack.2.html">sigaltstack</a></u>(2), <u><a href="../man2/sigaction.2.html">sigaction</a></u>(2),
       <u><a href="../man2/sigemptyset.2.html">sigemptyset</a></u>(2), <u><a href="../man2/sigaddset.2.html">sigaddset</a></u>(2),  <u><a href="../man2/sigprocmask.2.html">sigprocmask</a></u>(2),  <u><a href="../man2/sigsuspend.2.html">sigsuspend</a></u>(2),  <u><a href="../man3/sigsetjmp.3.html">sigsetjmp</a></u>(3),  <u><a href="../man3/siglongjmp.3.html">siglongjmp</a></u>(3),  <u><a href="../man3/setjmp.3.html">setjmp</a></u>(3),
       <u><a href="../man3/longjmp.3.html">longjmp</a></u>(3), <u><a href="../man2/select.2.html">select</a></u>(2), <u><a href="../man2/gettimeofday.2.html">gettimeofday</a></u>(2).

</pre><h4><b>AUTHOR</b></h4><pre>
        Ralf S. Engelschall
        <a href="mailto:rse@engelschall.com">rse@engelschall.com</a>
        www.engelschall.com

08-Jun-2006                                       GNU Pth 2.0.7                                           <u><a href="../man3/pth.3.html">pth</a></u>(3)
</pre>
 </div>
</div></section>
</div>
</body>
</html>