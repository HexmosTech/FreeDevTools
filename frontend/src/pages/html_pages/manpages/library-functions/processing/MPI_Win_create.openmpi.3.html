<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>C Syntax</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/openmpi-doc">openmpi-doc_5.0.7-1build1_all</a> <br><br><pre>
</pre><h4><b>SYNTAX</b></h4><pre>
   <b>C</b> <b>Syntax</b>
          #include &lt;mpi.h&gt;

          MPI_Win_create(void *base, MPI_Aint size, int disp_unit,
               MPI_Info info, MPI_Comm comm, MPI_Win *win)

   <b>Fortran</b> <b>Syntax</b>
          USE MPI
          ! or the older form: INCLUDE 'mpif.h'
          MPI_WIN_CREATE(BASE, SIZE, DISP_UNIT, INFO, COMM, WIN, IERROR)
               &lt;type&gt; BASE(*)
               INTEGER(KIND=MPI_ADDRESS_KIND) SIZE
               INTEGER DISP_UNIT, INFO, COMM, WIN, IERROR

   <b>Fortran</b> <b>2008</b> <b>Syntax</b>
          USE mpi_f08
          MPI_Win_create(base, size, disp_unit, info, comm, win, ierror)
               TYPE(*), DIMENSION(..), ASYNCHRONOUS :: base
               INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: size
               INTEGER, INTENT(IN) :: disp_unit
               TYPE(MPI_Info), INTENT(IN) :: info
               TYPE(MPI_Comm), INTENT(IN) :: comm
               TYPE(MPI_Win), INTENT(OUT) :: win
               INTEGER, OPTIONAL, INTENT(OUT) :: ierror

</pre><h4><b>INPUT</b> <b>PARAMETERS</b></h4><pre>
       • <b>base</b>: Initial address of window (choice).

       • <b>size</b>: Size of window in bytes (nonnegative integer).

       • <b>disp_unit</b>: Local unit size for displacements, in bytes (positive integer).

       • <b>info</b>: Info argument (handle).

       • <b>comm</b>: Communicator (handle).

</pre><h4><b>OUTPUT</b> <b>PARAMETERS</b></h4><pre>
       • <b>win</b>: Window object returned by the call (handle).

       • <b>ierror</b>: Fortran only: Error status (integer).

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <u>MPI_Win_create</u> is a one-sided MPI communication collective call executed by all processes in the group of
       <u>comm</u>.  It  returns  a  window  object that can be used by these processes to perform RMA operations. Each
       process specifies a window of existing memory that it exposes to RMA accesses by  the  processes  in  the
       group of <u>comm</u>. The window consists of <u>size</u> bytes, starting at address <u>base</u>. A process may elect to expose
       no memory by specifying <u>size</u> = 0.

       If the <u>base</u> value used by <u>MPI_Win_create</u> was allocated by <u>MPI_Alloc_mem</u>, the size of the window can be no
       larger than the value set by the <u>MPI_Alloc_mem</u> function.

       The displacement unit argument is provided to facilitate address arithmetic in RMA operations: the target
       displacement  argument  of  an  RMA  operation  is scaled by the factor <u>disp_unit</u> specified by the target
       process, at window creation.

       The following info keys are supported:

       <b>no_locks</b>
              If set to <u>true</u>, then the implementation may assume that the local window is  never  locked  (by  a
              call  to  <u>MPI_Win_lock</u> or MPI_Win_lock_all). Setting this value if only active synchronization may
              allow the implementation to enable certain optimizations.

       <b>accumulate_ordering</b>
              By default, accumulate operations from one initiator to one  target  on  the  same  window  memory
              location  are strictly ordered. If the info key accumulate_ordering is set to <u>none</u>, no ordering of
              accumulate operations guaranteed. They  key  can  also  be  a  comma-separated  list  of  required
              orderings   consisting   of   <u>rar</u>,  <u>war</u>,  <u>raw</u>,  and  <u>waw</u>  for  read-after-read,  write-after-read,
              read-after-write, and write-after-write, respectively. Looser ordering constraints are  likely  to
              result in improved performance.

       <b>accumulate_ops</b>
              If set to <u>same_op</u>, the implementation will assume that all concurrent accumulate calls to the same
              target  address will use the same operation. If set to <u>same_op_no_op</u>, then the implementation will
              assume that all concurrent accumulate calls to the same target address will use the same operation
              or MPI_NO_OP. The default is <u>same_op_no_op</u>.

       <b>same_size</b>
              If set to <u>true</u>, then the implementation may assume that the argument  <u>size</u>  is  identical  on  all
              processes, and that all processes have provided this info key with the same value.

       <b>same_disp_unit</b>
              If set to <u>true</u>, then the implementation may assume that the argument <u>disp_unit</u> is identical on all
              processes, and that all processes have provided this info key with the same value.

</pre><h4><b>NOTES</b></h4><pre>
       Common  choices  for  <u>disp_unit</u>  are  1  (no  scaling), and (in C syntax) <u>sizeof(type)</u>, for a window that
       consists of an array of elements of type <u>type</u>. The later choice will allow one to use  array  indices  in
       RMA calls, and have those scaled correctly to byte displacements, even in a heterogeneous environment.

       Use  memory  allocated  by  <u>MPI_Alloc_mem</u>  to guarantee properly aligned window boundaries (such as word,
       double-word, cache line, page frame, and so on).

</pre><h4><b>ERRORS</b></h4><pre>
       Almost all MPI routines return an error value; C routines as  the  return  result  of  the  function  and
       Fortran routines in the last argument.

       Before  the  error  value  is  returned,  the current MPI error handler associated with the communication
       object (e.g., communicator, window, file) is called.  If no communication object is associated  with  the
       MPI  call,  then  the call is considered attached to MPI_COMM_SELF and will call the associated MPI error
       handler.  When  MPI_COMM_SELF  is  not  initialized   (i.e.,   before   <u>MPI_Init</u>/<u>MPI_Init_thread</u>,   after
       <u>MPI_Finalize</u>,  or  when using the Sessions Model exclusively) the error raises the initial error handler.
       The initial error handler can be changed by calling <u>MPI_Comm_set_errhandler</u> on MPI_COMM_SELF  when  using
       the  World  model,  or the mpi_initial_errhandler CLI argument to mpiexec or info key to <u>MPI_Comm_spawn</u>/‐
       <u>MPI_Comm_spawn_multiple</u>.  If no other appropriate error handler has been set, then the  MPI_ERRORS_RETURN
       error  handler  is  called for MPI I/O functions and the MPI_ERRORS_ABORT error handler is called for all
       other MPI functions.

       Open MPI includes three predefined error handlers that can be used:

       • <b>MPI_ERRORS_ARE_FATAL</b> Causes the program to abort all connected MPI processes.

       • <b>MPI_ERRORS_ABORT</b> An error handler that can be invoked on a communicator, window, file, or session. When
         called on a communicator, it acts as if <u>MPI_Abort</u> was called on  that  communicator.  If  called  on  a
         window  or file, acts as if <u>MPI_Abort</u> was called on a communicator containing the group of processes in
         the corresponding window or file. If called on a session, aborts only the local process.

       • <b>MPI_ERRORS_RETURN</b> Returns an error code to the application.

       MPI applications can also implement their own error handlers by calling:

       • <u>MPI_Comm_create_errhandler</u> then <u>MPI_Comm_set_errhandler</u>

       • <u>MPI_File_create_errhandler</u> then <u>MPI_File_set_errhandler</u>

       • <u>MPI_Session_create_errhandler</u> then <u>MPI_Session_set_errhandler</u> or at <u>MPI_Session_init</u>

       • <u>MPI_Win_create_errhandler</u> then <u>MPI_Win_set_errhandler</u>

       Note that MPI does not guarantee that an MPI program can continue past an error.

       See the <u>MPI</u> <u>man</u> <u>page</u> for a full list of <u>MPI</u> <u>error</u> <u>codes</u>.

       See the Error Handling section of the MPI-3.1 standard for more information.

       <b>SEE</b> <b>ALSO:</b>

          • <u>MPI_Alloc_mem</u>

          • <u>MPI_Free_mem</u>

          • <u>MPI_Win_allocate</u>

          • <u>MPI_Win_allocate_shared</u>

</pre><h4><b>COPYRIGHT</b></h4><pre>
       2003-2025, The Open MPI Community

                                                  Jun 07, 2025                                 <u><a href="../man3/MPI_WIN_CREATE.3.html">MPI_WIN_CREATE</a></u>(3)
</pre>
 </div>
</div></section>
</div>
</body>
</html>