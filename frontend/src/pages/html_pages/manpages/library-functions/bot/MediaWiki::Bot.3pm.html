<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaWiki::Bot - a high-level bot framework for interacting with MediaWiki wikis</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/libmediawiki-bot-perl">libmediawiki-bot-perl_5.007000-1_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       MediaWiki::Bot - a high-level bot framework for interacting with MediaWiki wikis

</pre><h4><b>VERSION</b></h4><pre>
       version 5.007000

</pre><h4><b>SYNOPSIS</b></h4><pre>
           use MediaWiki::Bot qw(:constants);

           my $bot = MediaWiki::Bot-&gt;new({
               assert      =&gt; 'bot',
               host        =&gt; 'de.wikimedia.org',
               login_data  =&gt; { username =&gt; "Mike's bot account", password =&gt; "password" },
           });

           my $revid = $bot-&gt;get_last("User:Mike.lifeguard/sandbox", "Mike.lifeguard");
           print "Reverting to $revid\n" if defined($revid);
           $bot-&gt;revert('User:Mike.lifeguard', $revid, 'rvv');

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <b>MediaWiki::Bot</b> is a framework that can be used to write bots which interface with the MediaWiki API
       (&lt;<a href="http://en.wikipedia.org/w/api.php">http://en.wikipedia.org/w/api.php</a>&gt;).

</pre><h4><b>METHODS</b></h4><pre>
   <b>new</b>
           my $bot = MediaWiki::Bot({
               host     =&gt; 'en.wikipedia.org',
               operator =&gt; 'Mike.lifeguard',
           });

       Calling "MediaWiki::Bot-&gt;new()" will create a new MediaWiki::Bot object. The only parameter is a hashref
       with keys:

       •   <u>agent</u>  sets  a custom useragent. It is recommended to use "operator" instead, which is all we need to
           do   the   right   thing   for   you.   If   you   really   want   to    do    it    yourself,    see
           &lt;https://meta.wikimedia.org/wiki/User-agent_policy&gt;   for   guidance  on  what  information  must  be
           included.

       •   <u>assert</u> sets a parameter for the AssertEdit extension (commonly 'bot')

           Refer to &lt;<a href="http://mediawiki.org/wiki/Extension">http://mediawiki.org/wiki/Extension</a>:AssertEdit&gt;.

       •   <u>operator</u> allows the bot to send you a message when it fails an assert. This is also  the  recommended
           way to customize the user agent string, which is required by the Wikimedia Foundation. A warning will
           be emitted if you omit this.

       •   <u>maxlag</u> allows you to set the maxlag parameter (default is the recommended 5s).

           Please refer to the MediaWiki documentation prior to changing this from the default.

       •   <u>protocol</u> allows you to specify 'http' or 'https' (default is 'http')

       •   <u>host</u> sets the domain name of the wiki to connect to

       •   <u>path</u> sets the path to api.php (with no leading or trailing slash)

       •   <u>login_data</u> is a hashref of credentials to pass to "login".

       •   <u>debug</u> - whether to provide debug output.

           1 provides only error messages; 2 provides further detail on internal operations.

       For example:

           my $bot = MediaWiki::Bot-&gt;new({
               assert      =&gt; 'bot',
               protocol    =&gt; 'https',
               host        =&gt; 'en.wikimedia.org',
               agent       =&gt; sprintf(
                   'PerlWikiBot/%s (https://metacpan.org/MediaWiki::Bot; User:Mike.lifeguard)',
                   MediaWiki::Bot-&gt;VERSION
               ),
               login_data  =&gt; { username =&gt; "Mike's bot account", password =&gt; "password" },
           });

       For backward compatibility, you can specify up to three parameters:

           my $bot = MediaWiki::Bot-&gt;new('My custom useragent string', $assert, $operator);

       <b>This</b> <b>form</b> <b>is</b> <b>deprecated</b> will never do auto-login or autoconfiguration, and emits deprecation warnings.

       For further reading:

       •   MediaWiki::Bot wiki &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki&gt;

       •   &lt;Installing "MediaWiki::Bot" &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Install&gt;&gt;

       •   Creating a new bot &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Creating-a-new-bot&gt;

       •   Setting the wiki &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Setting-the-wiki&gt;

       •   Where is api.php &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Where-is-api.php&gt;

   <b>set_wiki</b>
       Set what wiki to use. The parameter is a hashref with keys:

       •   <u>host</u> - the domain name

       •   <u>path</u> - the part of the path before api.php (usually 'w')

       •   <u>protocol</u> is either 'http' or 'https'.

       If  you  don't  set  any  parameter,  it's  previous value is used. If it has never been set, the default
       settings are 'http', 'en.wikipedia.org' and 'w'.

       For example:

           $bot-&gt;set_wiki({
               protocol    =&gt; 'https',
               host        =&gt; 'secure.wikimedia.org',
               path        =&gt; 'wikipedia/meta/w',
           });

       For backward compatibility, you can specify up to two parameters:

           $bot-&gt;set_wiki($host, $path);

       <b>This</b> <b>form</b> <b>is</b> <b>deprecated</b>, and will emit deprecation warnings.

   <b>login</b>
       This method takes a hashref with keys <u>username</u> and <u>password</u> at a minimum.  See "Single  User  Login"  and
       "Basic authentication" for additional options.

       Logs  the  use $username in, optionally using $password. First, an attempt will be made to use cookies to
       log in. If this fails, an attempt will be made to use the password provided to log in,  if  any.  If  the
       login was successful, returns true; false otherwise.

           $bot-&gt;login({
               username =&gt; $username,
               password =&gt; $password,
           }) or die "Login failed";

       Once logged in, attempt to do some simple auto-configuration. At present, this consists of:

       •   Warning if the account doesn't have the bot flag, and isn't a sysop account.

       •   Setting an appropriate default assert.

       You can skip this autoconfiguration by passing "autoconfig =&gt; 0"

       For backward compatibility, you can call this as

           $bot-&gt;login($username, $password);

       <b>This</b>  <b>form</b>  <b>is</b>  <b>deprecated</b>, and will emit deprecation warnings. It will never do autoconfiguration or SUL
       login.

       <u>Single</u> <u>User</u> <u>Login</u>

       On WMF wikis, "do_sul" specifies whether to log in on all projects. The default is false. But  even  when
       false, you still get a CentralAuth cookie for, and are thus logged in on, all languages of a given domain
       ("*.wikipedia.org",  for  example).  When set, a login is done on each WMF domain so you are logged in on
       all ~800 content wikis. Since "*.wikimedia.org" is not possible, we  explicitly  include  meta,  commons,
       incubator, and wikispecies.

       <u>Basic</u> <u>authentication</u>

       If you need to supply basic auth credentials, pass a hashref of data as described by LWP::UserAgent:

           $bot-&gt;login({
               username    =&gt; $username,
               password    =&gt; $password,
               basic_auth  =&gt; {    netloc  =&gt; "private.wiki.com:80",
                                   realm   =&gt; "Authentication Realm",
                                   uname   =&gt; "Basic auth username",
                                   pass    =&gt; "password",
                               }
           }) or die "Couldn't log in";

       <u>Bot</u> <u>passwords</u>

       "MediaWiki::Bot"  doesn't  yet  support the more complicated (but more secure) oAuth login flow for bots.
       Instead, we support a simpler "bot password", which is a generated password  connected  to  a  (possibly-
       reduced) set of on-wiki privileges, and IP ranges from which it can be used.

       To  create one, visit "Special:BotPasswords" on the wiki. Enter a label for the password, then select the
       privileges you want to use with that password.  This set should be as restricted as possible;  most  bots
       only  edit  existing  pages.  Keeping the set of privileges as restricted as possible limits the possible
       damage if the password were ever compromised.

       Submit    the    form,    and    you'll    be    given    a    new    "username"    that    looks    like
       "AccountUsername@bot_password_label",  and  a  generated  bot  password.   To  log  in,  provide those to
       "MediaWiki::Bot" verbatim.

       <b>References:</b>        API:Login        &lt;https://www.mediawiki.org/wiki/API:Login&gt;,        Logging         in
       &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Logging-in&gt;

   <b>logout</b>
           $bot-&gt;logout();

       The logout method logs the bot out of the wiki. This invalidates all login cookies.

       <b>References:</b> API:Logging out &lt;https://www.mediawiki.org/wiki/API:Logout&gt;

   <b>edit</b>
           my $text = $bot-&gt;get_text('My page');
           $text .= "\n\n* More text\n";
           $bot-&gt;edit({
               page    =&gt; 'My page',
               text    =&gt; $text,
               summary =&gt; 'Adding new content',
               section =&gt; 'new',
           });

       This method edits a wiki page, and takes a hashref of data with keys:

       •   <u>page</u> - the page title to edit

       •   <u>text</u> - the page text to write

       •   <u>summary</u> - an edit summary

       •   <u>minor</u> - whether to mark the edit as minor or not (boolean)

       •   <u>bot</u> - whether to mark the edit as a bot edit (boolean)

       •   <u>assertion</u> - usually 'bot', but see &lt;<a href="http://mediawiki.org/wiki/Extension">http://mediawiki.org/wiki/Extension</a>:AssertEdit&gt;.

       •   <u>section</u> - edit a single section (identified by number) instead of the whole page

       An MD5 hash is sent to guard against data corruption while in transit.

       You can also call this as:

           $bot-&gt;edit($page, $text, $summary, $is_minor, $assert, $markasbot);

       <b>This</b> <b>form</b> <b>is</b> <b>deprecated</b>, and will emit deprecation warnings.

       <u>CAPTCHAs</u>

       If  a  CAPTCHA  &lt;https://en.wikipedia.org/wiki/CAPTCHA&gt;  is  encountered,  the call to "edit" will return
       false, with the error code set to "ERR_CAPTCHA" and the details informing you that solving a  CAPTCHA  is
       required for this action. The information you need to actually solve the captcha (for example the URL for
       the  image)  is  given  in "$bot-&gt;{error}-&gt;{captcha}" as a hash reference. You will want to grab the keys
       'url' (a relative URL to the image) and 'id' (the ID of the CAPTCHA). Once you have  solved  the  CAPTCHA
       (presumably  by  interacting  with  a  human), retry the edit, adding "captcha_id" and "captcha_solution"
       parameters:

           my $edit = {page =&gt; 'Main Page', text =&gt; 'got your nose'};
           my $edit_status = $bot-&gt;edit($edit);
           if (not $edit_status) {
               if ($bot-&gt;{error}-&gt;{code} == ERR_CAPTCHA) {
                   my @captcha_uri = split /\Q?/, $bot-&gt;{error}{captcha}{url}, 2;
                   my $image = URI-&gt;new(sprintf '%s://%s%s?%s' =&gt;
                       $bot-&gt;{protocol}, $bot-&gt;{host}, $captcha_uri[0], $captcha_uri[1],
                   );

                   require Term::ReadLine;
                   my $term = Term::ReadLine-&gt;new('Solve the captcha');
                   $term-&gt;<a href="../man0/ornaments.0.html">ornaments</a>(0);
                   my $answer = $term-&gt;readline("Please solve $image and type the answer: ");

                   # Add new CAPTCHA params to the edit we're attempting
                   $edit-&gt;{captcha_id} = $bot-&gt;{error}-&gt;{captcha}-&gt;{id};
                   $edit-&gt;{captcha_solution} = $answer;
                   $status = $bot-&gt;edit($edit);
               }
           }

       <b>References:</b> Editing pages  &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Editing-pages&gt;,  API:Edit
       &lt;https://www.mediawiki.org/wiki/API:Edit&gt;, API:Tokens &lt;https://www.mediawiki.org/wiki/API:Tokens&gt;

   <b>move</b>
           $bot-&gt;move($from_title, $to_title, $reason, $options_hashref);

       This moves a wiki page.

       If  you  wish  to  specify  more  options  (like  whether  to  suppress  creation  of  a  redirect),  use
       $options_hashref, which has keys:

       •   <u>movetalk</u> specifies whether to attempt to the talk page.

       •   <u>noredirect</u> specifies whether to suppress creation of a redirect.

       •   <u>movesubpages</u> specifies whether to move subpages, if applicable.

       •   <u>watch</u> and <u>unwatch</u> add or remove the page and the redirect from your watchlist.

       •   <u>ignorewarnings</u> ignores warnings.

           my @pages = ("Humor", "Rumor");
           foreach my $page (@pages) {
               my $to = $page;
               $to =~ s/or$/our/;
               $bot-&gt;move($page, $to, "silly 'merricans");
           }

       <b>References:</b> API:Move &lt;https://www.mediawiki.org/wiki/API:Move&gt;

   <b>get_history</b>
           my @hist = $bot-&gt;get_history($title);
           my @hist = $bot-&gt;get_history($title, $additional_params);

       Returns an array containing the history of the specified page $title.

       The optional hash ref $additional_params can be used to  tune  the  query  by  API  parameters,  such  as
       'rvlimit'  to  return  only  'rvlimit'  number  of  revisions (default is as many as possible, but may be
       limited per query) or 'rvdir' to set the chronological direction.

       Example:

           my @hist = $bot-&gt;get_history('Main Page', {'rvlimit' =&gt; 10, 'rvdir' =&gt; 'older'})

       The array returned contains  hashrefs  with  keys:  revid,  user,  comment,  minor,  timestamp_date,  and
       timestamp_time.

       For backward compatibility, you can specify up to four parameters:

           my @hist = $bot-&gt;get_history($title, $limit, $revid, $direction);

       <b>References</b>:   Getting   page  history  &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Getting-page-
       history&gt;, API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

   <b>get_history_step_by_step</b>
           my @hist = $bot-&gt;get_history_step_by_step($title);
           my @hist = $bot-&gt;get_history_step_by_step($title, $additional_params);

       Same as <b>get_history()</b>, but does not return the full history at once, but let's you loop through it.

       The optional call-by-reference hash ref $additional_params can be used to  loop  through  a  page's  full
       history by using the 'continue' param returned by the API.

       Example:

           my $ready;
           my $filter_params = {};
           while(!$ready){
               my @hist = $bot-&gt;get_history_step_by_step($page, $filter_params);
               if(@hist == 0 || !defined($filter_params-&gt;{'continue'})){
                   $ready = 1;
               }
               # do something with @hist
           }

       <b>References</b>:   Getting   page  history  &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Getting-page-
       history&gt;, API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

   <b>get_text</b>
       Returns the wikitext of the specified $page_title.  The first parameter $page_title is the only  required
       one.

       The second parameter is a hashref with the following independent optional keys:

       •   "rvstartid"  -  if  defined,  this  function  returns the text of that revision, otherwise the newest
           revision will be used.

       •   "rvsection" - if defined, returns the text of that section. Otherwise the whole  page  text  will  be
           returned.

       •   "pageid"  - this is an output parameter and can be used to fetch the id of a page without the need of
           calling "get_id" additionally. Note that  the  value  of  this  param  is  ignored  and  it  will  be
           overwritten by this function.

       •   "rv..." - any param starting with 'rv' will be forwarded to the api call.

       A blank page will return wikitext of "" (which evaluates to false in Perl, but is defined); a nonexistent
       page  will  return  undef  (which  also  evaluates to false in Perl, but is obviously undefined). You can
       distinguish between blank and nonexistent pages by using defined:

           # simple example
           my $wikitext = $bot-&gt;get_text('Page title');
           print "Wikitext: $wikitext\n" if defined $wikitext;

           # advanced example
           my $options = {'revid'=&gt;123456, 'section_number'=&gt;2};
           $wikitext = $bot-&gt;get_text('Page title', $options);
           die "error, see API error message\n" unless defined $options-&gt;{'pageid'};
           warn "page doesn't exist\n" if $options-&gt;{'pageid'} == MediaWiki::Bot::PAGE_NONEXISTENT;
           print "Wikitext: $wikitext\n" if defined $wikitext;

       <b>References:</b> Fetching page text  &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Fetching-page-text&gt;,
       API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

       For  backward-compatibility  the  params  "revid"  and  "section_number"  may  also  be  given  as scalar
       parameters:

           my $wikitext = $bot-&gt;get_text('Page title', 123456, 2);
           print "Wikitext: $wikitext\n" if defined $wikitext;

   <b>get_id</b>
       Returns the id of the specified $page_title. Returns undef if page does not exist.

           my $pageid = $bot-&gt;get_id("Main Page");
           die "Page doesn't exist\n" if !defined($pageid);

       <b>Revisions:</b> API:Properties#info &lt;https://www.mediawiki.org/wiki/API:Properties#info_.2F_in&gt;

   <b>get_pages</b>
       Returns the text of the specified pages in a hashref. Content of undef means page does  not  exist.  Also
       handles redirects or article names that use namespace aliases.

           my @pages = ('Page 1', 'Page 2', 'Page 3');
           my $thing = $bot-&gt;get_pages(\@pages);
           foreach my $page (keys %$thing) {
               my $text = $thing-&gt;{$page};
               print "$text\n" if defined($text);
           }

       <b>References:</b>  Fetching page text &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Fetching-page-text&gt;,
       API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

   <b>get_image</b>
           $buffer = $bot-&gt;get_image('File:Foo.jpg', { width=&gt;256, height=&gt;256 });

       Download an image from a wiki. This is derived from a similar function in MediaWiki::API. This one allows
       the image to be scaled down by passing a hashref with height &amp; width parameters.

       It returns raw data in the original format. You may simply spew it to a file, or process it directly with
       a library such as Imager.

           use File::Slurp qw(write_file);
           my $img_data = $bot-&gt;get_image('File:Foo.jpg');
           write_file( 'Foo.jpg', {binmode =&gt; ':raw'}, \$img_data );

       Images are scaled proportionally. (height/width) will remain constant, except for rounding errors.

       Height and width parameters describe the <b>maximum</b> dimensions. A 400x200 image  will  never  be  scaled  to
       greater dimensions. You can scale it yourself; having the wiki do it is just lazy &amp; selfish.

       <b>References:</b> API:Properties#imageinfo &lt;https://www.mediawiki.org/wiki/API:Properties#imageinfo_.2F_ii&gt;

   <b>revert</b>
       Reverts  the  specified  $page_title  to $revid, with an edit summary of $summary. A default edit summary
       will be used if $summary is omitted.

           my $revid = $bot-&gt;get_last("User:Mike.lifeguard/sandbox", "Mike.lifeguard");
           print "Reverting to $revid\n" if defined($revid);
           $bot-&gt;revert('User:Mike.lifeguard', $revid, 'rvv');

       <b>References:</b> API:Edit &lt;https://www.mediawiki.org/wiki/API:Edit&gt;

   <b>undo</b>
           $bot-&gt;undo($title, $revid, $summary, $after);

       Reverts the specified $revid, with an edit summary of $summary, using the  undo  function.  To  undo  all
       revisions  from  $revid  up  to but not including this one, set $after to another revid. If not set, just
       undo the one revision ($revid).

       <b>References:</b> API:Edit &lt;https://www.mediawiki.org/wiki/API:Edit&gt;

   <b>get_last</b>
       Returns the revid of the last revision to $page not made by $user. undef is returned  if  no  result  was
       found, as would be the case if the page is deleted.

           my $revid = $bot-&gt;get_last('User:Mike.lifeguard/sandbox', 'Mike.lifeguard');
           if defined($revid) {
               print "Reverting to $revid\n";
               $bot-&gt;revert('User:Mike.lifeguard', $revid, 'rvv');
           }

       <b>References:</b> API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

   <b>update_rc</b>
       <b>This</b> <b>method</b> <b>is</b> <b>deprecated</b>, and will emit deprecation warnings.  Replace calls to "update_rc()" with calls
       to the newer "recentchanges()", which returns all available data, including rcid.

       Returns  an  array  containing  the  $limit  most  recent changes to the wiki's <u>main</u> <u>namespace</u>. The array
       contains hashrefs with keys title, revid, old_revid, and timestamp.

           my @rc = $bot-&gt;<a href="../man5/update_rc.5.html">update_rc</a>(5);
           foreach my $hashref (@rc) {
               my $title = $hash-&gt;{'title'};
               print "$title\n";
           }

       The "Options hashref" is also available:

           # Use a callback for incremental processing:
           my $options = { hook =&gt; \&amp;mysub, };
           $bot-&gt;update_rc($options);
           sub mysub {
               my ($res) = @_;
               foreach my $hashref (@$res) {
                   my $page = $hashref-&gt;{'title'};
                   print "$page\n";
               }
           }

   <b>recentchanges($wiki_hashref,</b> <b>$options_hashref)</b>
       Returns an array of hashrefs containing recentchanges data.

       The first parameter is a hashref with the following keys:

       •   <u>ns</u> - the namespace number, or an arrayref  of  numbers  to  specify  several;  default  is  the  main
           namespace

       •   <u>limit</u> - the number of rows to fetch; default is 50

       •   <u>user</u> - only list changes by this user

       •   <u>show</u> - itself a hashref where the key is a category and the value is a boolean. If true, the category
           will  be included; if false, excluded. The categories are kinds of edits: minor, bot, anon, redirect,
           patrolled. See "rcshow" at &lt;<a href="http://www.mediawiki.org/wiki/API">http://www.mediawiki.org/wiki/API</a>:Recentchanges#Parameters&gt;.

       An "Options hashref" can be used as the second parameter:

           my @rc = $bot-&gt;recentchanges({ ns =&gt; 4, limit =&gt; 100 });
           foreach my $hashref (@rc) {
               print $hashref-&gt;{title} . "\n";
           }

           # Or, use a callback for incremental processing:
           $bot-&gt;recentchanges({ ns =&gt; [0,1], limit =&gt; 500 }, { hook =&gt; \&amp;mysub });
           sub mysub {
               my ($res) = @_;
               foreach my $hashref (@$res) {
                   my $page = $hashref-&gt;{title};
                   print "$page\n";
               }
           }

       The hashref returned might contain the following keys:

       •   <u>ns</u> - the namespace number

       •   <u>revid</u>

       •   <u>old_revid</u>

       •   <u>timestamp</u>

       •   <u>rcid</u> - can be used with "patrol"

       •   <u>pageid</u>

       •   <u>type</u> - one of edit, new, log (there may be others)

       •   <u>title</u>

       For backwards compatibility, the previous method signature is still supported:

           $bot-&gt;recentchanges($ns, $limit, $options_hashref);

       <b>References:</b> API:Recentchanges &lt;https://www.mediawiki.org/wiki/API:Recentchanges&gt;

   <b>what_links_here</b>
       Returns an array containing a list of all pages linking to $page.

       Additional optional parameters are:

       •   One of: all (default), redirects, or nonredirects.

       •   A namespace number to search (pass an arrayref to search in multiple namespaces)

       •   An "Options hashref".

       A typical query:

           my @links = $bot-&gt;what_links_here("Meta:Sandbox",
               undef, 1,
               { hook=&gt;\&amp;mysub }
           );
           sub mysub{
               my ($res) = @_;
               foreach my $hash (@$res) {
                   my $title = $hash-&gt;{'title'};
                   my $is_redir = $hash-&gt;{'redirect'};
                   print "Redirect: $title\n" if $is_redir;
                   print "Page: $title\n" unless $is_redir;
               }
           }

       Transclusions are no longer handled by <b>what_links_here()</b> - use "list_transclusions" instead.

       <b>References:</b> Listing incoming links &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Listing-incoming-
       links&gt;, API:Backlinks &lt;https://www.mediawiki.org/wiki/API:Backlinks&gt;

   <b>list_transclusions</b>
       Returns an array containing a list of all pages transcluding $page.

       Other parameters are:

       •   One of: all (default), redirects, or nonredirects

       •   A namespace number to search (pass an arrayref to search in multiple namespaces).

       •   $options_hashref as described by MediaWiki::API:

           Set max to limit the number of queries performed.

           Set hook to a subroutine reference to use a callback hook for incremental processing.

           Refer to the section on "linksearch" for examples.

       A typical query:

           $bot-&gt;list_transclusions("Template:Tlx", undef, 4, {hook =&gt; \&amp;mysub});
           sub mysub{
               my ($res) = @_;
               foreach my $hash (@$res) {
                   my $title = $hash-&gt;{'title'};
                   my $is_redir = $hash-&gt;{'redirect'};
                   print "Redirect: $title\n" if $is_redir;
                   print "Page: $title\n" unless $is_redir;
               }
           }

       <b>References:</b>    Listing    transclusions     &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Listing-
       transclusions&gt; API:Embeddedin &lt;https://www.mediawiki.org/wiki/API:Embeddedin&gt;

   <b>get_pages_in_category</b>
       Returns  an  array  containing  the  names  of all pages in the specified category (include the Category:
       prefix). Does not recurse into sub-categories.

           my @pages = $bot-&gt;get_pages_in_category('Category:People on stamps of Gabon');
           print "The pages in Category:People on stamps of Gabon are:\n@pages\n";

       The options hashref is as described in "Options hashref".  Use "{ max =&gt; 0 }" to get all results.

       <b>References:</b>  Listing  category   contents   &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Listing-
       category-contents&gt;, API:Categorymembers &lt;https://www.mediawiki.org/wiki/API:Categorymembers&gt;

   <b>get_all_pages_in_category</b>
           my @pages = $bot-&gt;get_all_pages_in_category($category, $options_hashref);

       Returns  an  array  containing  the  names  of <b>all</b> pages in the specified category (include the Category:
       prefix), including sub-categories. The $options_hashref is described fully in "Options hashref".

       <b>References:</b>  Listing  category   contents   &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Listing-
       category-contents&gt;, API:Categorymembers &lt;https://www.mediawiki.org/wiki/API:Categorymembers&gt;

   <b>get_all_categories</b>
       Returns an array containing the names of all categories.

           my @categories = $bot-&gt;get_all_categories();
           print "The categories are:\n@categories\n";

       Use  "{  max  =&gt;  0  }"  to get all results. The default number of categories returned is 10, the maximum
       allowed is 500.

       <b>References:</b> API:Allcategories &lt;https://www.mediawiki.org/wiki/API:Allcategories&gt;

   <b>linksearch</b>
       Runs a linksearch on the specified $link and returns an array containing anonymous hashes with keys 'url'
       for the outbound URL, and 'title' for the page the link is on.

       Additional parameters are:

       •   A namespace number to search (pass an arrayref to search in multiple namespaces).

       •   You can search by $protocol (http is default).

       •   $options_hashref is fully documented in "Options hashref":

           Set <u>max</u> in $options to get more than one query's worth of results:

               my $options = { max =&gt; 10, }; # I only want some results
               my @links = $bot-&gt;linksearch("slashdot.org", 1, undef, $options);
               foreach my $hash (@links) {
                   my $url = $hash-&gt;{'url'};
                   my $page = $hash-&gt;{'title'};
                   print "$page: $url\n";
               }

           Set <u>hook</u> to a subroutine reference to use a callback hook for incremental processing:

               my $options = { hook =&gt; \&amp;mysub, }; # I want to do incremental processing
               $bot-&gt;linksearch("slashdot.org", 1, undef, $options);
               sub mysub {
                   my ($res) = @_;
                   foreach my $hashref (@$res) {
                       my $url  = $hashref-&gt;{'url'};
                       my $page = $hashref-&gt;{'title'};
                       print "$page: $url\n";
                   }
               }

       <b>References:</b> Finding external links &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Finding-external-
       links&gt;, API:Exturlusage &lt;https://www.mediawiki.org/wiki/API:Exturlusage&gt;

   <b>purge_page</b>
       Purges the server cache of the specified $page. Returns true on success; false on failure. Pass an  array
       reference to purge multiple pages.

       If  you really care, a true return value is the number of pages successfully purged. You could check that
       it is the same as the number you wanted to purge - maybe some pages don't exist, or  you  passed  invalid
       titles, or you aren't allowed to purge the cache:

           my @to_purge = ('Main Page', 'A', 'B', 'C', 'Very unlikely to exist');
           my $size = scalar @to_purge;

           print "all-at-once:\n";
           my $success = $bot-&gt;purge_page(\@to_purge);

           if ($success == $size) {
               print "@to_purge: OK ($success/$size)\n";
           }
           else {
               my $missed = @to_purge - $success;
               print "We couldn't purge $missed pages (list was: "
                   . join(', ', @to_purge)
                   . ")\n";
           }

           # OR
           print "\n\none-at-a-time:\n";
           foreach my $page (@to_purge) {
               my $ok = $bot-&gt;purge_page($page);
               print "$page: $ok\n";
           }

       <b>References:</b>  Purging  the  server cache &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/wiki/Purging-the-
       server-cache&gt;, API:Purge &lt;https://www.mediawiki.org/wiki/API:Purge&gt;

   <b>get_namespace_names</b>
           my %namespace_names = $bot-&gt;get_namespace_names();

       Returns a hash linking the namespace id, such as 1, to its named equivalent, such as "Talk".

       <b>References:</b> API:Meta#siteinfo &lt;https://www.mediawiki.org/wiki/API:Meta#siteinfo_.2F_si&gt;

   <b>image_usage</b>
       Gets a list of pages which include a certain $image.  Include  the  "File:"  namespace  prefix  to  avoid
       incurring an extra round-trip (which will also emit a deprecation warnings).

       Additional parameters are:

       •   A namespace number to fetch results from (or an arrayref of multiple namespace numbers)

       •   One of all, redirect, or nonredirects.

       •   $options is a hashref as described in the section for "linksearch".

           my @pages = $bot-&gt;image_usage("File:Albert Einstein Head.jpg");

       Or, make use of the "Options hashref" to do incremental processing:

           $bot-&gt;image_usage("File:Albert Einstein Head.jpg",
               undef, undef,
               { hook=&gt;\&amp;mysub, max=&gt;5 }
           );
           sub mysub {
               my $res = shift;
               foreach my $page (@$res) {
                   my $title = $page-&gt;{'title'};
                   print "$title\n";
               }
           }

       <b>References:</b> API:Imageusage &lt;https://www.mediawiki.org/wiki/API:Imageusage&gt;

   <b>global_image_usage($image,</b> <b>$results,</b> <b>$filterlocal)</b>
       Returns an array of hashrefs of data about pages which use the given image.

           my @data = $bot-&gt;global_image_usage('File:Albert Einstein Head.jpg');

       The keys in each hashref are title, url, and wiki. $results is the maximum number of results that will be
       returned (not the maximum number of requests that will be sent, like "max" in the "Options hashref"); the
       default is to attempt to fetch 500 (set to 0 to get all results). $filterlocal will filter out local uses
       of the image.

       <b>References:</b> Extension:GlobalUsage#API &lt;https://www.mediawiki.org/wiki/Extension:GlobalUsage#API&gt;

   <b>links_to_image</b>
       A backward-compatible call to "image_usage". You can provide only the image title.

       <b>This</b> <b>method</b> <b>is</b> <b>deprecated</b>, and will emit deprecation warnings.

   <b>is_blocked</b>
           my $blocked = $bot-&gt;is_blocked('User:Mike.lifeguard');

       Checks if a user is currently blocked.

       <b>References:</b> API:Blocks &lt;https://www.mediawiki.org/wiki/API:Blocks&gt;

   <b>test_blocked</b>
       Retained for backwards compatibility. Use "is_blocked" for clarity.

       <b>This</b> <b>method</b> <b>is</b> <b>deprecated</b>, and will emit deprecation warnings.

   <b>test_image_exists</b>
       Checks if an image exists at $page.

       •   "FILE_NONEXISTENT" (0) means "Nothing there"

       •   "FILE_LOCAL" (1) means "Yes, an image exists locally"

       •   "FILE_SHARED" (2) means "Yes, an image exists on Commons &lt;<a href="http://commons.wikimedia.org">http://commons.wikimedia.org</a>&gt;"

       •   "FILE_PAGE_TEXT_ONLY" (3) means "No image exists, but there is text on the page"

       If you pass in an arrayref of images, you'll get out an arrayref of results.

           use MediaWiki::Bot::Constants;
           my $exists = $bot-&gt;test_image_exists('File:Albert Einstein Head.jpg');
           if ($exists == FILE_NONEXISTENT) {
               print "Doesn't exist\n";
           }
           elsif ($exists == FILE_LOCAL) {
               print "Exists locally\n";
           }
           elsif ($exists == FILE_SHARED) {
               print "Exists on Commons\n";
           }
           elsif ($exists == FILE_PAGE_TEXT_ONLY) {
               print "Page exists, but no image\n";
           }

       <b>References:</b> API:Properties#imageinfo &lt;https://www.mediawiki.org/wiki/API:Properties#imageinfo_.2F_ii&gt;

   <b>get_pages_in_namespace</b>
           $bot-&gt;get_pages_in_namespace($namespace, $limit, $options_hashref);

       Returns an array containing the names of all pages in the specified namespace.  The $namespace_id must be
       a number, not a namespace name.

       Setting  $page_limit is optional, and specifies how many items to retrieve at once. Setting this to 'max'
       is recommended, and this is the default if omitted.  If $page_limit is over 500, it will be rounded up to
       the next multiple of 500.  If $page_limit is set higher than you are allowed to use, it will silently  be
       reduced. Consider setting key 'max' in the "Options hashref" to retrieve multiple sets of results:

           # Gotta get 'em all!
           my @pages = $bot-&gt;get_pages_in_namespace(6, 'max', { max =&gt; 0 });

       <b>References:</b> API:Allpages &lt;https://www.mediawiki.org/wiki/API:Allpages&gt;

   <b>count_contributions</b>
           my $count = $bot-&gt;count_contributions($user);

       Uses the API to count $user's contributions.

       <b>References:</b> API:Users &lt;https://www.mediawiki.org/wiki/API:Users&gt;

   <b>timed_count_contributions</b>
           ($timed_edits_count, $total_count) = $bot-&gt;timed_count_contributions($user, $days);

       Uses  the  API  to  count  $user's  contributions  in  last  number  of  $days and total number of user's
       contributions (if needed).

       Example: If you want to get user contribs for last 30 and 365 days, and total number of edits  you  would
       write something like this:

           my ($last30days, $total) = $bot-&gt;timed_count_contributions($user, 30);
           my $last365days = $bot-&gt;timed_count_contributions($user, 365);

       You could get total number of edits also by separately calling count_contributions like this:

           my $total = $bot-&gt;count_contributions($user);

       and  use  timed_count_contributions  only  in scalar context, but that would mean one more call to server
       (meaning more server load) of which you are excused as timed_count_contributions returns array  with  two
       parameters.

       <b>References:</b> Extension:UserDailyContribs &lt;https://www.mediawiki.org/wiki/Extension:UserDailyContribs&gt;

   <b>last_active</b>
           my $latest_timestamp = $bot-&gt;last_active($user);

       Returns the last active time of $user in "YYYY-MM-DDTHH:MM:SSZ".

       <b>References:</b> API:Usercontribs &lt;https://www.mediawiki.org/wiki/API:Usercontribs&gt;

   <b>recent_edit_to_page</b>
            my ($timestamp, $user) = $bot-&gt;recent_edit_to_page($title);

       Returns timestamp and username for most recent (top) edit to $page.

       <b>References:</b> API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

   <b>get_users</b>
           my @recent_editors = $bot-&gt;get_users($title, $limit, $revid, $direction);

       Gets the most recent editors to $page, up to $limit, starting from $revision and going in $direction.

       <b>References:</b> API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

   <b>was_blocked</b>
           for ("Mike.lifeguard", "Jimbo Wales") {
               print "$_ was blocked\n" if $bot-&gt;was_blocked($_);
           }

       Returns whether $user has ever been blocked.

       <b>References:</b> API:Logevents &lt;https://www.mediawiki.org/wiki/API:Logevents&gt;

   <b>test_block_hist</b>
       Retained for backwards compatibility. Use "was_blocked" for clarity.

       <b>This</b> <b>method</b> <b>is</b> <b>deprecated</b>, and will emit deprecation warnings.

   <b>expandtemplates</b>
           my $expanded = $bot-&gt;expandtemplates($title, $wikitext);

       Expands templates on $page, using $text if provided, otherwise loading the page text automatically.

       <b>References:</b> API:Parsing wikitext &lt;https://www.mediawiki.org/wiki/API:Parsing_wikitext&gt;

   <b>get_allusers</b>
           my @users = $bot-&gt;get_allusers($limit, $user_group, $options_hashref);

       Returns  an array of all users. Default $limit is 500. Optionally specify a $group (like 'sysop') to list
       that group only. The last optional parameter is an "Options hashref".

       <b>References:</b> API:Allusers &lt;https://www.mediawiki.org/wiki/API:Allusers&gt;

   <b>db_to_domain</b>
       Converts a wiki/database name (enwiki) to the domain name (en.wikipedia.org).

           my @wikis = ("enwiki", "kowiki", "bat-smgwiki", "nonexistent");
           foreach my $wiki (@wikis) {
               my $domain = $bot-&gt;db_to_domain($wiki);
               next if !defined($domain);
               print "$wiki: $domain\n";
           }

       You can pass an arrayref to do bulk lookup:

           my @wikis = ("enwiki", "kowiki", "bat-smgwiki", "nonexistent");
           my $domains = $bot-&gt;db_to_domain(\@wikis);
           foreach my $domain (@$domains) {
               next if !defined($domain);
               print "$domain\n";
           }

       <b>References:</b> Extension:SiteMatrix &lt;https://www.mediawiki.org/wiki/Extension:SiteMatrix&gt;

   <b>domain_to_db</b>
           my $db = $bot-&gt;domain_to_db($domain_name);

       As you might expect, does the opposite of "domain_to_db": Converts  a  domain  name  (meta.wikimedia.org)
       into a database/wiki name (metawiki).

       <b>References:</b> Extension:SiteMatrix &lt;https://www.mediawiki.org/wiki/Extension:SiteMatrix&gt;

   <b>diff</b>
       This  allows  retrieval  of  a diff from the API. The return is a scalar containing the <u>HTML</u> <u>table</u> of the
       diff. Options are passed as a hashref with keys:

       •   <u>title</u> is the title to use. Provide <u>either</u> this or revid.

       •   <u>revid</u> is any revid to diff from. If you also specified title, only title will be honoured.

       •   <u>oldid</u> is an identifier to diff to. This can be a revid, or the special values 'cur', 'prev' or 'next'

       <b>References:</b> API:Properties#revisions &lt;https://www.mediawiki.org/wiki/API:Properties#revisions_.2F_rv&gt;

   <b>prefixindex</b>
       This returns an array of hashrefs containing page titles that start with the given $prefix.  The  hashref
       has keys 'title' and 'redirect' (present if the page is a redirect, not present otherwise).

       Additional parameters are:

       •   One of all, redirects, or nonredirects

       •   A single namespace number (unlike linksearch etc, which can accept an arrayref of numbers).

       •   $options_hashref as described in "Options hashref".

           my @prefix_pages = $bot-&gt;prefixindex("User:Mike.lifeguard");
           # Or, the more efficient equivalent
           my @prefix_pages = $bot-&gt;prefixindex("Mike.lifeguard", 2);
           foreach my $hashref (@pages) {
               my $title = $hashref-&gt;{'title'};
               if $hashref-&gt;{'redirect'} {
                   print "$title is a redirect\n";
               }
               else {
                   print "$title\n is not a redirect\n";
               }
           }

       <b>References:</b> API:Allpages &lt;https://www.mediawiki.org/wiki/API:Allpages&gt;

   <b>search</b>
       This is a simple search for your $search_term in page text. It returns an array of page titles matching.

       Additional optional parameters are:

       •   A namespace number to search in, or an arrayref of numbers (default is the main namespace)

       •   $options_hashref is a hashref as described in "Options hashref":

           my @pages = $bot-&gt;search("Mike.lifeguard", 2);
           print "@pages\n";

       Or, use a callback for incremental processing:

           my @pages = $bot-&gt;search("Mike.lifeguard", 2, { hook =&gt; \&amp;mysub });
           sub mysub {
               my ($res) = @_;
               foreach my $hashref (@$res) {
                   my $page = $hashref-&gt;{'title'};
                   print "$page\n";
               }
           }

       <b>References:</b> API:Search &lt;https://www.mediawiki.org/wiki/API:Search&gt;

   <b>get_log</b>
       This  fetches  log  entries,  and returns results as an array of hashes. The first parameter is a hashref
       with keys:

       •   <u>type</u> is the log type (block, delete...)

       •   <u>user</u> is the user who <u>performed</u> the action. Do not include the User: prefix

       •   <u>target</u> is the target of the action. Where an action was performed to a page, it is  the  page  title.
           Where an action was performed to a user, it is User:$username.

       The second is the familiar "Options hashref".

           my $log = $bot-&gt;get_log({
                   type =&gt; 'block',
                   user =&gt; 'User:Mike.lifeguard',
               });
           foreach my $entry (@$log) {
               my $user = $entry-&gt;{'title'};
               print "$user\n";
           }

           $bot-&gt;get_log({
                   type =&gt; 'block',
                   user =&gt; 'User:Mike.lifeguard',
               },
               { hook =&gt; \&amp;mysub, max =&gt; 10 }
           );
           sub mysub {
               my ($res) = @_;
               foreach my $hashref (@$res) {
                   my $title = $hashref-&gt;{'title'};
                   print "$title\n";
               }
           }

       <b>References:</b> API:Logevents &lt;https://www.mediawiki.org/wiki/API:Logevents&gt;

   <b>is_g_blocked</b>
           my $is_globally_blocked = $bot-&gt;is_g_blocked('127.0.0.1');

       Returns  what  IP/range  block  <u>currently</u>  <u>in</u>  <u>place</u>  affects  the IP/range. The return is a scalar of an
       IP/range if found (evaluates to true in boolean context); undef otherwise  (evaluates  false  in  boolean
       context). Pass in a single IP or CIDR range.

       <b>References:</b> Extension:GlobalBlocking &lt;https://www.mediawiki.org/wiki/Extension:GlobalBlocking/API&gt;

   <b>was_g_blocked</b>
           print "127.0.0.1 was globally blocked\n" if $bot-&gt;was_g_blocked('127.0.0.1');

       Returns  whether  an  IP/range  was ever globally blocked. You should probably call this method only when
       your bot is operating on Meta - this method will warn if not.

       <b>References:</b> API:Logevents &lt;https://www.mediawiki.org/wiki/API:Logevents&gt;

   <b>was_locked</b>
           my $was_locked = $bot-&gt;was_locked('Mike.lifeguard');

       Returns whether a user was ever locked. You should probably call  this  method  only  when  your  bot  is
       operating on Meta - this method will warn if not.

       <b>References:</b> API:Logevents &lt;https://www.mediawiki.org/wiki/API:Logevents&gt;

   <b>get_protection</b>
       Returns  data  on  page  protection as a array of up to two hashrefs. Each hashref has a type, level, and
       expiry. Levels are 'sysop' and 'autoconfirmed'; types are 'move'  and  'edit';  expiry  is  a  timestamp.
       Additionally, the key 'cascade' will exist if cascading protection is used.

           my $page = 'Main Page';
           $bot-&gt;edit({
               page    =&gt; $page,
               text    =&gt; rand(),
               summary =&gt; 'test',
           }) unless $bot-&gt;get_protection($page);

       You can also pass an arrayref of page titles to do bulk queries:

           my @pages = ('Main Page', 'User:Mike.lifeguard', 'Project:Sandbox');
           my $answer = $bot-&gt;get_protection(\@pages);
           foreach my $title (keys %$answer) {
               my $protected = $answer-&gt;{$title};
               print "$title is protected\n" if $protected;
               print "$title is unprotected\n" unless $protected;
           }

       <b>References:</b> API:Properties#info &lt;https://www.mediawiki.org/wiki/API:Properties#info_.2F_in&gt;

   <b>is_protected</b>
       This is a synonym for "get_protection", which should be used in preference.

       <b>This</b> <b>method</b> <b>is</b> <b>deprecated</b>, and will emit deprecation warnings.

   <b>patrol</b>
           $bot-&gt;patrol($rcid);

       Marks  a  page  or revision identified by the $rcid as patrolled. To mark several RCIDs as patrolled, you
       may pass an arrayref of them. Returns false and sets "$bot-&gt;{error}" if the account cannot patrol.

       <b>References:</b> API:Patrol &lt;https://www.mediawiki.org/wiki/API:Patrol&gt;

   <b>email</b>
           $bot-&gt;email($user, $subject, $body);

       This allows you to send emails through the wiki. All 3 of $user (without the User: prefix), $subject  and
       $body  are  required.  If  $user  is an arrayref, this will send the same email (subject and body) to all
       users.

       <b>References:</b> API:Email &lt;https://www.mediawiki.org/wiki/API:Email&gt;

   <b>top_edits</b>
       Returns an array of the page titles where the $user is the latest editor. The  second  parameter  is  the
       familiar $options_hashref.

           my @pages = $bot-&gt;top_edits("Mike.lifeguard", {max =&gt; 5});
           foreach my $page (@pages) {
               $bot-&gt;rollback($page, "Mike.lifeguard");
           }

       Note  that  accessing  the  data with a callback happens <b>before</b> filtering the top edits is done. For that
       reason, you should use "contributions" if you need to  use  a  callback.  If  you  use  a  callback  with
       <b>top_edits()</b>,  you  <b>will</b>  <b>not</b> necessarily get top edits returned. It is only safe to use a callback if you
       <u>check</u> that it is a top edit:

           $bot-&gt;top_edits("Mike.lifeguard", { hook =&gt; \&amp;rv });
           sub rv {
               my $data = shift;
               foreach my $page (@$data) {
                   if (exists($page-&gt;{'top'})) {
                       $bot-&gt;rollback($page-&gt;{'title'}, "Mike.lifeguard");
                   }
               }
           }

       <b>References:</b> API:Usercontribs &lt;https://www.mediawiki.org/wiki/API:Usercontribs&gt;

   <b>contributions</b>
           my @contribs = $bot-&gt;contributions($user, $namespace, $options, $from, $to);

       Returns an array of hashrefs of data for the user's contributions.  $namespace  can  be  an  arrayref  of
       namespace  numbers. $options can be specified as in "linksearch".  $from and $to are optional timestamps.
       ISO      8601      date      and      time      is      recommended:      2001-01-15T14:56:00Z,       see
       &lt;https://www.mediawiki.org/wiki/Timestamp&gt;  for all possible formats.  Note that $from (=ucend) has to be
       before $to (=ucstart), unlike direct API access.

       Specify an arrayref of users to get results for multiple users.

       <b>References:</b> API:Usercontribs &lt;https://www.mediawiki.org/wiki/API:Usercontribs&gt;

   <b>upload</b>
           $bot-&gt;upload({ data =&gt; $file_contents, summary =&gt; 'uploading file' });
           $bot-&gt;upload({ file =&gt; $file_name,     title   =&gt; 'Target filename.png' });

       Upload a file to the wiki. Specify the file by either giving the filename, which will be read in,  or  by
       giving the data directly.

       <b>References:</b> API:Upload &lt;https://www.mediawiki.org/wiki/API:Upload&gt;

   <b>upload_from_url</b>
       Upload  file  directly  from  URL to the wiki. Specify URL, the new filename and summary. Summary and new
       filename are optional.

           $bot-&gt;upload_from_url({
               url =&gt; '<a href="http://some.domain.ext/pic.png">http://some.domain.ext/pic.png</a>',
               title =&gt; 'Target_filename.png',
               summary =&gt; 'uploading new pic',
           });

       If on your target wiki is enabled uploading from URL, meaning  $wgAllowCopyUploads  is  set  to  true  in
       LocalSettings.php and you have appropriate user rights, you can use this function to upload files to your
       wiki directly from remote server.

       <b>References:</b> API:Upload#Uploading_from_URL &lt;https://www.mediawiki.org/wiki/API:Upload#Uploading_from_URL&gt;

   <b>usergroups</b>
       Returns a list of the usergroups a user is in:

           my @usergroups = $bot-&gt;usergroups('Mike.lifeguard');

       <b>References:</b> API:Users &lt;https://www.mediawiki.org/wiki/API:Users&gt;

   <b>get_mw_version</b>
       Returns  a  hash  ref with the MediaWiki version. The hash ref contains the keys <u>major</u>, <u>minor</u>, <u>patch</u>, and
       <u>string</u>.  Returns undef on errors.

           my $mw_version = $bot-&gt;get_mw_version;

           # get version as string
           my $mw_ver_as_string = $mw_version-&gt;{'major'} . '.' . $mw_version-&gt;{'minor'};
           if(defined $mw_version-&gt;{'patch'}){
               $mw_ver_as_string .= '.' . $mw_version-&gt;{'patch'};
           }

           # or simply
           my $mw_ver_as_string = $mw_version-&gt;{'string'};

       <b>References:</b> API:Siteinfo &lt;https://www.mediawiki.org/wiki/API:Siteinfo&gt;

   <b>Options</b> <b>hashref</b>
       This is passed through to the lower-level interface MediaWiki::API, and is fully documented there.

       The hashref can have 3 keys:

       max Specifies the maximum number of queries to retrieve data from the wiki. This is  independent  of  the
           <u>size</u> of each query (how many items each query returns).  Set to 0 to retrieve all the results.

       hook
           Specifies  a coderef to a hook function that can be used to process large lists as they come in. When
           this is used, your subroutine will get the raw data. This is noted in cases where it is known  to  be
           significant. For example, when using a hook with "top_edits()", you need to check whether the edit is
           the top edit yourself - your subroutine gets results as they come in, and before they're filtered.

       skip_encoding
           MediaWiki's API uses UTF-8 and any 8 bit character string parameters are encoded automatically by the
           API  call.  If  your  parameters  are already in UTF-8 this will be detected and the encoding will be
           skipped. If your parameters for some reason contain UTF-8 data but no UTF-8 flag is set (i.e. you did
           not use the "use utf8;" pragma) you should prevent re-encoding by passing an option "skip_encoding =&gt;
           1". For example:

               $category ="Cat\x{e9}gorie:moyen_fran\x{e7}ais"; # latin1 string
               $bot-&gt;get_all_pages_in_category($category); # OK

               $category = "Cat". pack("U", 0xe9)."gorie:moyen_fran".pack("U",0xe7)."ais"; # unicode string
               $bot-&gt;get_all_pages_in_category($category); # OK

               $category ="Cat\x{c3}\x{a9}gorie:moyen_fran\x{c3}\x{a7}ais"; # unicode data without utf-8 flag
               # $bot-&gt;get_all_pages_in_category($category); # NOT OK
               $bot-&gt;get_all_pages_in_category($category, { skip_encoding =&gt; 1 }); # OK

           If you need this, it probably means you're doing something wrong. Feel free to ask for help.

</pre><h4><b>ERROR</b> <b>HANDLING</b></h4><pre>
       All functions will return undef in  any  handled  error  situation.  Further  error  data  is  stored  in
       "$bot-&gt;{error}-&gt;{code}" and "$bot-&gt;{error}-&gt;{details}".

       Error codes are provided as constants in MediaWiki::Bot::Constants, and can also be imported through this
       module:

           use MediaWiki::Bot qw(:constants);

</pre><h4><b>AVAILABILITY</b></h4><pre>
       The project homepage is &lt;https://metacpan.org/module/MediaWiki::Bot&gt;.

       The  latest version of this module is available from the Comprehensive Perl Archive Network (CPAN). Visit
       &lt;<a href="http://www.perl.com/CPAN/">http://www.perl.com/CPAN/</a>&gt;     to     find     a     CPAN      site      near      you,      or      see
       &lt;https://metacpan.org/module/MediaWiki::Bot/&gt;.

</pre><h4><b>SOURCE</b></h4><pre>
       The  development  version  is  on  github  at &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot&gt; and may be
       cloned from &lt;git://github.com/MediaWiki-Bot/MediaWiki-Bot.git&gt;

</pre><h4><b>BUGS</b> <b>AND</b> <b>LIMITATIONS</b></h4><pre>
       You  can  make  new  bug  reports,   and   view   existing   ones,   through   the   web   interface   at
       &lt;https://github.com/MediaWiki-Bot/MediaWiki-Bot/issues&gt;.

</pre><h4><b>AUTHORS</b></h4><pre>
       •   Dan Collins &lt;<a href="mailto:dcollins@cpan.org">dcollins@cpan.org</a>&gt;

       •   Mike.lifeguard &lt;<a href="mailto:lifeguard@cpan.org">lifeguard@cpan.org</a>&gt;

       •   Alex Rowe &lt;<a href="mailto:alex.d.rowe@gmail.com">alex.d.rowe@gmail.com</a>&gt;

       •   Oleg Alexandrov &lt;<a href="mailto:oleg.alexandrov@gmail.com">oleg.alexandrov@gmail.com</a>&gt;

       •   jmax.code &lt;<a href="mailto:jmax.code@gmail.com">jmax.code@gmail.com</a>&gt;

       •   Stefan Petrea &lt;<a href="mailto:stefan.petrea@gmail.com">stefan.petrea@gmail.com</a>&gt;

       •   kc2aei &lt;<a href="mailto:kc2aei@gmail.com">kc2aei@gmail.com</a>&gt;

       •   <a href="mailto:bosborne@alum.mit.edu">bosborne@alum.mit.edu</a>

       •   Brian Obio &lt;<a href="mailto:brianobio@gmail.com">brianobio@gmail.com</a>&gt;

       •   patch and bug report contributors

</pre><h4><b>COPYRIGHT</b> <b>AND</b> <b>LICENSE</b></h4><pre>
       This software is Copyright (c) 2021 by the MediaWiki::Bot team &lt;<a href="mailto:perlwikibot@googlegroups.com">perlwikibot@googlegroups.com</a>&gt;.

       This is free software, licensed under:

         The GNU General Public License, Version 3, June 2007

perl v5.32.1                                       2021-11-12                                <u>MediaWiki::<a href="../man3pm/Bot.3pm.html">Bot</a></u>(3pm)
</pre>
 </div>
</div></section>
</div>
</body>
</html>