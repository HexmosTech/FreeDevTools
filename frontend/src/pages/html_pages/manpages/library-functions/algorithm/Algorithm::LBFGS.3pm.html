<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithm::LBFGS - Perl extension for L-BFGS</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/libalgorithm-lbfgs-perl">libalgorithm-lbfgs-perl_0.16-3build5_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       Algorithm::LBFGS - Perl extension for L-BFGS

</pre><h4><b>SYNOPSIS</b></h4><pre>
         use Algorithm::LBFGS;

         # create an L-BFGS optimizer
         my $o = Algorithm::LBFGS-&gt;new;

         # f(x) = (x1 - 1)^2 + (x2 + 2)^2
         # grad f(x) = (2 * (x1 - 1), 2 * (x2 + 2));
         my $eval_cb = sub {
             my $x = shift;
             my $f = ($x-&gt;[0] - 1) * ($x-&gt;[0] - 1) + ($x-&gt;[1] + 2) * ($x-&gt;[1] + 2);
             my $g = [ 2 * ($x-&gt;[0] - 1), 2 * ($x-&gt;[1] + 2) ];
             return ($f, $g);
         };

         my $x0 = [0.0, 0.0]; # initial point
         my $x = $o-&gt;fmin($eval_cb, $x0); # $x is supposed to be [ 1, -2 ];

</pre><h4><b>DESCRIPTION</b></h4><pre>
       L-BFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) is a quasi-Newton method for unconstrained
       optimization. This method is especially efficient on problems involving a large number of variables.

       Generally, it solves a problem described as following:

         min f(x), x = (x1, x2, ..., xn)

       Jorge Nocedal wrote a Fortran 77 version of this algorithm.

       &lt;<a href="http://www.ece.northwestern.edu/~nocedal/lbfgs.html">http://www.ece.northwestern.edu/~nocedal/lbfgs.html</a>&gt;

       And, Naoaki Okazaki rewrote it in pure C (liblbfgs).

       &lt;<a href="http://www.chokkan.org/software/liblbfgs/index.html">http://www.chokkan.org/software/liblbfgs/index.html</a>&gt;

       This module is a Perl port of Naoaki Okazaki's C version.

   <b>new</b>
       "new" creates a L-BFGS optimizer with given parameters.

         my $o1 = new Algorithm::LBFGS(m =&gt; 5);
         my $o2 = new Algorithm::LBFGS(m =&gt; 3, eps =&gt; 1e-6);
         my $o3 = new Algorithm::LBFGS;

       If no parameter is specified explicitly, their default values are used.

       The parameter can be changed after the creation of the optimizer by "set_param". Also, they can be
       queryed by "get_param".

       Please refer to the "List of Parameters" for details about parameters.

   <b>get_param</b>
       Query the value of a parameter.

          my $o = Algorithm::LBFGS-&gt;new;
          print $o-&gt;get_param('epsilon'); # 1e-5

   <b>set_param</b>
       Change the values of one or several parameters.

          my $o = Algorithm::LBFGS-&gt;new;
          $o-&gt;set_param(epsilon =&gt; 1e-6, m =&gt; 7);

   <b>fmin</b>
       The prototype of "fmin" is like

         x = fmin(evaluation_cb, x0, progress_cb, user_data)

       As the name says, it finds a vector x which minimize the function f(x).

       "evaluation_cb" is a ref to the evaluation callback subroutine, "x0" is the initial point of the
       optimization algorithm, "progress_cb" (optional) is a ref to the progress callback subroutine, and
       "user_data" (optional) is a piece of extra data that client program want to pass to both "evaluation_cb"
       and "progress_cb".

       Client program can use "get_status" to find if any problem occured during the optimization after their
       calling "fmin". When the status is "LBFGS_OK", the returning value "x" (array ref) contains the optimized
       variables, otherwise, there may be some problems occured and the value in the returning "x" is undefined.

       <u>evaluation_cb</u>

       The ref to the evaluation callback subroutine.

       The evaluation callback subroutine is supposed to calculate the function value and gradient vector at a
       specified point "x". It is called automatically by "fmin" when an evaluation is needed.

       The client program need to make sure their evaluation callback subroutine has a prototype like

         (f, g) = evaluation_cb(x, step, user_data)

       "x" (array ref) is the current values of variables, "step" is the current step of the line search
       routine, "user_data" is the extra user data specified when calling "fmin".

       The evaluation callback subroutine is supposed to return both the function value "f" and the gradient
       vector "g" (array ref) at current "x".

       <u>x0</u>

       The initial point of the optimization algorithm.  The final result may depend on your choice of "x0".

       NOTE: The content of "x0" will be modified after calling "fmin".  When the algorithm terminates
       successfully, the content of "x0" will be replaced by the optimized variables, otherwise, the content of
       "x0" is undefined.

       <u>progress_cb</u>

       The ref to the progress callback subroutine.

       The progress callback subroutine is called by "fmin" at the end of each iteration, with information of
       current iteration. It is very useful for a client program to monitor the optimization progress.

       The client program need to make sure their progress callback subroutine has a prototype like

         s = progress_cb(x, g, fx, xnorm, gnorm, step, k, ls, user_data)

       "x" (array ref) is the current values of variables. "g" (array ref) is the current gradient vector. "fx"
       is the current function value. "xnorm" and "gnorm" is the L2 norm of "x" and "g". "step" is the line-
       search step used for this iteration. "k" is the iteration count. "ls" is the number of evaluations in
       this iteration. "user_data" is the extra user data specified when calling "fmin".

       The progress callback subroutine is supposed to return an indicating value "s" for "fmin" to decide
       whether the optimization should continue or stop. "fmin" continues to the next iteration when "s=0",
       otherwise, it terminates with status code "LBFGSERR_CANCELED".

       The client program can also pass string values to "progress_cb", which means it want to use a predefined
       progress callback subroutine. There are two predefined progress callback subroutines, 'verbose' and
       'logging'.  'verbose' just prints out all information of each iteration, while 'logging' logs the same
       information in an array ref provided by "user_data".

         ...

         # print out the iterations
         fmin($eval_cb, $x0, 'verbose');

         # log iterations information in the array ref $log
         my $log = [];

         fmin($eval_cb, $x0, 'logging', $log);

         use Data::Dumper;
         print Dumper $log;

       <u>user_data</u>

       The extra user data. It will be sent to both "evaluation_cb" and "progress_cb".

   <b>get_status</b>
       Get the status of previous call of "fmin".

         ...
         $o-&gt;fmin(...);

         # check the status
         if ($o-&gt;get_status eq 'LBFGS_OK') {
            ...
         }

         # print the status out
         print $o-&gt;get_status;

       The status code is a string, which could be one of those in the "List of Status Codes".

   <b>status_ok</b>
       This is a shortcut of saying "get_status" eq "LBFGS_OK".

         ...

         if ($o-&gt;fmin(...), $o-&gt;status_ok) {
             ...
         }

   <b>List</b> <b>of</b> <b>Parameters</b>
       <u>m</u>

       The number of corrections to approximate the inverse hessian matrix.

       The L-BFGS algorithm stores the computation results of previous "m" iterations to approximate the inverse
       hessian matrix of the current iteration. This parameter controls the size of the limited memories
       (corrections). The default value is 6. Values less than 3 are not recommended. Large values will result
       in excessive computing time.

       <u>epsilon</u>

       Epsilon for convergence test.

       This parameter determines the accuracy with which the solution is to be found. A minimization terminates
       when

         ||grad f(x)|| &lt; epsilon * max(1, ||x||)

       where ||.|| denotes the Euclidean (L2) norm. The default value is 1e-5.

       <u>max_iterations</u>

       The maximum number of iterations.

       The L-BFGS algorithm terminates an optimization process with "LBFGSERR_MAXIMUMITERATION" status code when
       the iteration count exceedes this parameter. Setting this parameter to zero continues an optimization
       process until a convergence or error. The default value is 0.

       <u>max_linesearch</u>

       The maximum number of trials for the line search.

       This parameter controls the number of function and gradients evaluations per iteration for the line
       search routine. The default value is 20.

       <u>min_step</u>

       The minimum step of the line search routine.

       The default value is 1e-20. This value need not be modified unless the exponents are too large for the
       machine being used, or unless the problem is extremely badly scaled (in which case the exponents should
       be increased).

       <u>max_step</u>

       The maximum step of the line search.

       The default value is 1e+20. This value need not be modified unless the exponents are too large for the
       machine being used, or unless the problem is extremely badly scaled (in which case the exponents should
       be increased).

       <u>ftol</u>

       A parameter to control the accuracy of the line search routine.

       The default value is 1e-4. This parameter should be greater than zero and smaller than 0.5.

       <u>gtol</u>

       A parameter to control the accuracy of the line search routine.

       The default value is 0.9. If the function and gradient evaluations are inexpensive with respect to the
       cost of the iteration (which is sometimes the case when solving very large problems) it may be
       advantageous to set this parameter to a small value. A typical small value is 0.1. This parameter shuold
       be greater than the ftol parameter (1e-4) and smaller than 1.0.

       <u>xtol</u>

       The machine precision for floating-point values.

       This parameter must be a positive value set by a client program to estimate the machine precision. The
       line search routine will terminate with the status code ("LBFGSERR_ROUNDING_ERROR") if the relative width
       of the interval of uncertainty is less than this parameter.

       <u>orthantwise_c</u>

       Coeefficient for the L1 norm of variables.

       This parameter should be set to zero for standard minimization problems.  Setting this parameter to a
       positive value minimizes the objective function f(x) combined with the L1 norm |x| of the variables, f(x)
       + c|x|.  This parameter is the coeefficient for the |x|, i.e., c. As the L1 norm |x| is not
       differentiable at zero, the module modify function and gradient evaluations from a client program
       suitably; a client program thus have only to return the function value f(x) and gradients grad f(x) as
       usual. The default value is zero.

   <b>List</b> <b>of</b> <b>Status</b> <b>Codes</b>
       <u>LBFGS_OK</u>

       No error occured.

       <u>LBFGSERR_UNKNOWNERROR</u>

       Unknown error.

       <u>LBFGSERR_LOGICERROR</u>

       Logic error.

       <u>LBFGSERR_OUTOFMEMORY</u>

       Insufficient memory.

       <u>LBFGSERR_CANCELED</u>

       The minimization process has been canceled.

       <u>LBFGSERR_INVALID_N</u>

       Invalid number of variables specified.

       <u>LBFGSERR_INVALID_N_SSE</u>

       Invalid number of variables (for SSE) specified.

       <u>LBFGSERR_INVALID_MINSTEP</u>

       Invalid parameter "max_step" specified.

       <u>LBFGSERR_INVALID_MAXSTEP</u>

       Invalid parameter "max_step" specified.

       <u>LBFGSERR_INVALID_FTOL</u>

       Invalid parameter "ftol" specified.

       <u>LBFGSERR_INVALID_GTOL</u>

       Invalid parameter "gtol" specified.

       <u>LBFGSERR_INVALID_XTOL</u>

       Invalid parameter "xtol" specified.

       <u>LBFGSERR_INVALID_MAXLINESEARCH</u>

       Invalid parameter "max_linesearch" specified.

       <u>LBFGSERR_INVALID_ORTHANTWISE</u>

       Invalid parameter "orthantwise_c" specified.

       <u>LBFGSERR_OUTOFINTERVAL</u>

       The line-search step went out of the interval of uncertainty.

       <u>LBFGSERR_INCORRECT_TMINMAX</u>

       A logic error occurred; alternatively, the interval of uncertainty became too small.

       <u>LBFGSERR_ROUNDING_ERROR</u>

       A rounding error occurred; alternatively, no line-search step satisfies the sufficient decrease and
       curvature conditions.

       <u>LBFGSERR_MINIMUMSTEP</u>

       The line-search step became smaller than "min_step".

       <u>LBFGSERR_MAXIMUMSTEP</u>

       The line-search step became larger than "max_step".

       <u>LBFGSERR_MAXIMUMLINESEARCH</u>

       The line-search routine reaches the maximum number of evaluations.

       <u>LBFGSERR_MAXIMUMITERATION</u>

       The algorithm routine reaches the maximum number of iterations.

       <u>LBFGSERR_WIDTHTOOSMALL</u>

       Relative width of the interval of uncertainty is at most "xtol".

       <u>LBFGSERR_INVALIDPARAMETERS</u>

       A logic error (negative line-search step) occurred.

       <u>LBFGSERR_INCREASEGRADIENT</u>

       The current search direction increases the objective function value.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       PDL, PDL::Opt::NonLinear

</pre><h4><b>AUTHOR</b></h4><pre>
       Laye Suen, &lt;<a href="mailto:laye@cpan.org">laye@cpan.org</a>&gt;

</pre><h4><b>COPYRIGHT</b> <b>AND</b> <b>LICENSE</b></h4><pre>
       Copyright (C) 1990, Jorge Nocedal

       Copyright (C) 2007, Naoaki Okazaki

       Copyright (C) 2008, Laye Suen

       This library is distributed under the term of the MIT license.

       &lt;<a href="http://opensource.org/licenses/mit-license.php">http://opensource.org/licenses/mit-license.php</a>&gt;

</pre><h4><b>REFERENCE</b></h4><pre>
        J. Nocedal. Updating Quasi-Newton Matrices with Limited Storage (1980) , Mathematics of Computation 35,
       pp. 773-782.
        D.C. Liu and J. Nocedal. On the Limited Memory Method for Large Scale Optimization (1989), Mathematical
       Programming B, 45, 3, pp. 503-528.
        Jorge Nocedal's Fortran 77 implementation, &lt;<a href="http://www.ece.northwestern.edu/~nocedal/lbfgs.html">http://www.ece.northwestern.edu/~nocedal/lbfgs.html</a>&gt;
        Naoaki Okazaki's C implementation (liblbfgs), &lt;<a href="http://www.chokkan.org/software/liblbfgs/index.html">http://www.chokkan.org/software/liblbfgs/index.html</a>&gt;

perl v5.40.0                                       2024-10-20                              <u>Algorithm::<a href="../man3pm/LBFGS.3pm.html">LBFGS</a></u>(3pm)
</pre>
 </div>
</div></section>
</div>
</body>
</html>