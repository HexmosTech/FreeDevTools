<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>drbdsetup - Configure the DRBD kernel module</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/drbd-utils">drbd-utils_9.22.0-1.1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       drbdsetup - Configure the DRBD kernel module

</pre><h4><b>SYNOPSIS</b></h4><pre>

       <b>drbdsetup</b> command {argument...} [option...]

</pre><h4><b>DESCRIPTION</b></h4><pre>
       The <b>drbdsetup</b> utility serves to configure the DRBD kernel module and to show its current configuration.
       Users usually interact with the <b>drbdadm</b> utility, which provides a more high-level interface to DRBD than
       <b>drbdsetup</b>. (See <b>drbdadm</b>'s <b>--dry-run</b> option to see how <b>drbdadm</b> uses <b>drbdsetup</b>.)

       Some option arguments have a default scale which applies when a plain number is specified (for example
       Kilo, or 1024 times the numeric value). Such default scales can be overridden by using a suffix (for
       example, M for Mega). The common suffixes K = 2^10 = 1024, M = 1024 K, and G = 1024 M are supported.

</pre><h4><b>COMMANDS</b></h4><pre>
       <b>drbdsetup</b> attach <u>minor</u> <u>lower_dev</u> <u>meta_data_dev</u> <u>meta_data_index</u>,
       <b>drbdsetup</b> disk-options <u>minor</u>
           The <b>attach</b> command attaches a lower-level device to an existing replicated device. The <b>disk-options</b>
           command changes the disk options of an attached lower-level device. In either case, the replicated
           device must have been created with <b>drbdsetup</b> <b>new-minor</b>.

           Both commands refer to the replicated device by its <u>minor</u> number.  <u>lower_dev</u> is the name of the
           lower-level device.  <u>meta_data_dev</u> is the name of the device containing the metadata, and may be the
           same as <u>lower_dev</u>.  <u>meta_data_index</u> is either a numeric metadata index, or the keyword <b>internal</b> for
           internal metadata, or the keyword <b>flexible</b> for variable-size external metadata. Available options:

           <b>--al-extents</b> <u>extents</u>
               DRBD automatically maintains a "hot" or "active" disk area likely to be written to again soon
               based on the recent write activity. The "active" disk area can be written to immediately, while
               "inactive" disk areas must be "activated" first, which requires a meta-data write. We also refer
               to this active disk area as the "activity log".

               The activity log saves meta-data writes, but the whole log must be resynced upon recovery of a
               failed node. The size of the activity log is a major factor of how long a resync will take and
               how fast a replicated disk will become consistent after a crash.

               The activity log consists of a number of 4-Megabyte segments; the <u>al-extents</u> parameter determines
               how many of those segments can be active at the same time. The default value for <u>al-extents</u> is
               1237, with a minimum of 7 and a maximum of 65536.

               Note that the effective maximum may be smaller, depending on how you created the device meta
               data, see also <b><a href="../man8/drbdmeta.8.html">drbdmeta</a></b>(8) The effective maximum is 919 * (available on-disk activity-log
               ring-buffer area/4kB -1), the default 32kB ring-buffer effects a maximum of 6433 (covers more
               than 25 GiB of data) We recommend to keep this well within the amount your backend storage and
               replication link are able to resync inside of about 5 minutes.

           <b>--al-updates</b> <b>{yes</b> <b>|</b> <b>no}</b>
               With this parameter, the activity log can be turned off entirely (see the <b>al-extents</b> parameter).
               This will speed up writes because fewer meta-data writes will be necessary, but the entire device
               needs to be resynchronized opon recovery of a failed primary node. The default value for
               <b>al-updates</b> is <b>yes</b>.

           <b>--disk-barrier</b>,
           <b>--disk-flushes</b>,
           <b>--disk-drain</b>
               DRBD has three methods of handling the ordering of dependent write requests:

               <b>disk-barrier</b>
                   Use disk barriers to make sure that requests are written to disk in the right order. Barriers
                   ensure that all requests submitted before a barrier make it to the disk before any requests
                   submitted after the barrier. This is implemented using 'tagged command queuing' on SCSI
                   devices and 'native command queuing' on SATA devices. Only some devices and device stacks
                   support this method. The device mapper (LVM) only supports barriers in some configurations.

                   Note that on systems which do not support disk barriers, enabling this option can lead to
                   data loss or corruption. Until DRBD 8.4.1, <b>disk-barrier</b> was turned on if the I/O stack below
                   DRBD did support barriers. Kernels since linux-2.6.36 (or 2.6.32 RHEL6) no longer allow to
                   detect if barriers are supported. Since drbd-8.4.2, this option is off by default and needs
                   to be enabled explicitly.

               <b>disk-flushes</b>
                   Use disk flushes between dependent write requests, also referred to as 'force unit access' by
                   drive vendors. This forces all data to disk. This option is enabled by default.

               <b>disk-drain</b>
                   Wait for the request queue to "drain" (that is, wait for the requests to finish) before
                   submitting a dependent write request. This method requires that requests are stable on disk
                   when they finish. Before DRBD 8.0.9, this was the only method implemented. This option is
                   enabled by default. Do not disable in production environments.

               From these three methods, drbd will use the first that is enabled and supported by the backing
               storage device. If all three of these options are turned off, DRBD will submit write requests
               without bothering about dependencies. Depending on the I/O stack, write requests can be
               reordered, and they can be submitted in a different order on different cluster nodes. This can
               result in data loss or corruption. Therefore, turning off all three methods of controlling write
               ordering is strongly discouraged.

               A general guideline for configuring write ordering is to use disk barriers or disk flushes when
               using ordinary disks (or an ordinary disk array) with a volatile write cache. On storage without
               cache or with a battery backed write cache, disk draining can be a reasonable choice.

           <b>--disk-timeout</b>
               If the lower-level device on which a DRBD device stores its data does not finish an I/O request
               within the defined <b>disk-timeout</b>, DRBD treats this as a failure. The lower-level device is
               detached, and the device's disk state advances to Diskless. If DRBD is connected to one or more
               peers, the failed request is passed on to one of them.

               This option is <u>dangerous</u> <u>and</u> <u>may</u> <u>lead</u> <u>to</u> <u>kernel</u> <u>panic!</u>

               "Aborting" requests, or force-detaching the disk, is intended for completely blocked/hung local
               backing devices which do no longer complete requests at all, not even do error completions. In
               this situation, usually a hard-reset and failover is the only way out.

               By "aborting", basically faking a local error-completion, we allow for a more graceful swichover
               by cleanly migrating services. Still the affected node has to be rebooted "soon".

               By completing these requests, we allow the upper layers to re-use the associated data pages.

               If later the local backing device "recovers", and now DMAs some data from disk into the original
               request pages, in the best case it will just put random data into unused pages; but typically it
               will corrupt meanwhile completely unrelated data, causing all sorts of damage.

               Which means delayed successful completion, especially for READ requests, is a reason to panic().
               We assume that a delayed *error* completion is OK, though we still will complain noisily about
               it.

               The default value of <b>disk-timeout</b> is 0, which stands for an infinite timeout. Timeouts are
               specified in units of 0.1 seconds. This option is available since DRBD 8.3.12.

           <b>--md-flushes</b>
               Enable disk flushes and disk barriers on the meta-data device. This option is enabled by default.
               See the <b>disk-flushes</b> parameter.

           <b>--on-io-error</b> <u>handler</u>
               Configure how DRBD reacts to I/O errors on a lower-level device. The following policies are
               defined:

               <b>pass_on</b>
                   Change the disk status to Inconsistent, mark the failed block as inconsistent in the bitmap,
                   and retry the I/O operation on a remote cluster node.

               <b>call-local-io-error</b>
                   Call the <b>local-io-error</b> handler (see the <b>handlers</b> section).

               <b>detach</b>
                   Detach the lower-level device and continue in diskless mode.

           <b>--read-balancing</b> <u>policy</u>
               Distribute read requests among cluster nodes as defined by <u>policy</u>. The supported policies are
               <b>prefer-local</b> (the default), <b>prefer-remote</b>, <b>round-robin</b>, <b>least-pending</b>, <b>when-congested-remote</b>,
               <b>32K-striping</b>, <b>64K-striping</b>, <b>128K-striping</b>, <b>256K-striping</b>, <b>512K-striping</b> and <b>1M-striping</b>.

               This option is available since DRBD 8.4.1.

           <b>resync-after</b> <u>minor</u>
               Define that a device should only resynchronize after the specified other device. By default, no
               order between devices is defined, and all devices will resynchronize in parallel. Depending on
               the configuration of the lower-level devices, and the available network and disk bandwidth, this
               can slow down the overall resync process. This option can be used to form a chain or tree of
               dependencies among devices.

           <b>--size</b> <u>size</u>
               Specify the size of the lower-level device explicitly instead of determining it automatically.
               The device size must be determined once and is remembered for the lifetime of the device. In
               order to determine it automatically, all the lower-level devices on all nodes must be attached,
               and all nodes must be connected. If the size is specified explicitly, this is not necessary. The
               <b>size</b> value is assumed to be in units of sectors (512 bytes) by default.

           <b>--discard-zeroes-if-aligned</b> <b>{yes</b> <b>|</b> <b>no}</b>
               There are several aspects to discard/trim/unmap support on linux block devices. Even if discard
               is supported in general, it may fail silently, or may partially ignore discard requests. Devices
               also announce whether reading from unmapped blocks returns defined data (usually zeroes), or
               undefined data (possibly old data, possibly garbage).

               If on different nodes, DRBD is backed by devices with differing discard characteristics, discards
               may lead to data divergence (old data or garbage left over on one backend, zeroes due to unmapped
               areas on the other backend). Online verify would now potentially report tons of spurious
               differences. While probably harmless for most use cases (fstrim on a file system), DRBD cannot
               have that.

               To play safe, we have to disable discard support, if our local backend (on a Primary) does not
               support "discard_zeroes_data=true". We also have to translate discards to explicit zero-out on
               the receiving side, unless the receiving side (Secondary) supports "discard_zeroes_data=true",
               thereby allocating areas what were supposed to be unmapped.

               There are some devices (notably the LVM/DM thin provisioning) that are capable of discard, but
               announce discard_zeroes_data=false. In the case of DM-thin, discards aligned to the chunk size
               will be unmapped, and reading from unmapped sectors will return zeroes. However, unaligned
               partial head or tail areas of discard requests will be silently ignored.

               If we now add a helper to explicitly zero-out these unaligned partial areas, while passing on the
               discard of the aligned full chunks, we effectively achieve discard_zeroes_data=true on such
               devices.

               Setting <b>discard-zeroes-if-aligned</b> to <b>yes</b> will allow DRBD to use discards, and to announce
               discard_zeroes_data=true, even on backends that announce discard_zeroes_data=false.

               Setting <b>discard-zeroes-if-aligned</b> to <b>no</b> will cause DRBD to always fall-back to zero-out on the
               receiving side, and to not even announce discard capabilities on the Primary, if the respective
               backend announces discard_zeroes_data=false.

               We used to ignore the discard_zeroes_data setting completely. To not break established and
               expected behaviour, and suddenly cause fstrim on thin-provisioned LVs to run out-of-space instead
               of freeing up space, the default value is <b>yes</b>.

               This option is available since 8.4.7.

           <b>--disable-write-same</b> <b>{yes</b> <b>|</b> <b>no}</b>
               Some disks announce WRITE_SAME support to the kernel but fail with an I/O error upon actually
               receiving such a request. This mostly happens when using virtualized disks -- notably, this
               behavior has been observed with VMware's virtual disks.

               When <b>disable-write-same</b> is set to <b>yes</b>, WRITE_SAME detection is manually overriden and support is
               disabled.

               The default value of <b>disable-write-same</b> is <b>no</b>. This option is available since 8.4.7.

           <b>--rs-discard-granularity</b> <u>byte</u>
               When <b>rs-discard-granularity</b> is set to a non zero, positive value then DRBD tries to do a resync
               operation in requests of this size. In case such a block contains only zero bytes on the sync
               source node, the sync target node will issue a discard/trim/unmap command for the area.

               The value is constrained by the discard granularity of the backing block device. In case
               <b>rs-discard-granularity</b> is not a multiplier of the discard granularity of the backing block device
               DRBD rounds it up. The feature only gets active if the backing block device reads back zeroes
               after a discard command.

               The usage of <b>rs-discard-granularity</b> may cause <b>c-max-rate</b> to be exceeded. In particular, the
               resync rate may reach 10x the value of <b>rs-discard-granularity</b> per second.

               The default value of <b>rs-discard-granularity</b> is 0. This option is available since 8.4.7.

       <b>drbdsetup</b> peer-device-options <u>resource</u> <u>peer_node_id</u> <u>volume</u>
           These are options that affect the <u>peer</u>'s device.

           <b>--c-delay-target</b> <u>delay_target</u>,
           <b>--c-fill-target</b> <u>fill_target</u>,
           <b>--c-max-rate</b> <u>max_rate</u>,
           <b>--c-plan-ahead</b> <u>plan_time</u>
               Dynamically control the resync speed. The following modes are available:

               •   Dynamic control with fill target (default). Enabled when <b>c-plan-ahead</b> is non-zero and
                   <b>c-fill-target</b> is non-zero. The goal is to fill the buffers along the data path with a defined
                   amount of data. This mode is recommended when DRBD-proxy is used. Configured with
                   <b>c-plan-ahead</b>, <b>c-fill-target</b> and <b>c-max-rate</b>.

               •   Dynamic control with delay target. Enabled when <b>c-plan-ahead</b> is non-zero (default) and
                   <b>c-fill-target</b> is zero. The goal is to have a defined delay along the path. Configured with
                   <b>c-plan-ahead</b>, <b>c-delay-target</b> and <b>c-max-rate</b>.

               •   Fixed resync rate. Enabled when <b>c-plan-ahead</b> is zero. DRBD will try to perform resync I/O at
                   a fixed rate. Configured with <b>resync-rate</b>.

               The <b>c-plan-ahead</b> parameter defines how fast DRBD adapts to changes in the resync speed. It should
               be set to five times the network round-trip time or more. The default value of <b>c-plan-ahead</b> is
               20, in units of 0.1 seconds.

               The <b>c-fill-target</b> parameter defines the how much resync data DRBD should aim to have in-flight at
               all times. Common values for "normal" data paths range from 4K to 100K. The default value of
               <b>c-fill-target</b> is 100, in units of sectors

               The <b>c-delay-target</b> parameter defines the delay in the resync path that DRBD should aim for. This
               should be set to five times the network round-trip time or more. The default value of
               <b>c-delay-target</b> is 10, in units of 0.1 seconds.

               The <b>c-max-rate</b> parameter limits the maximum bandwidth used by dynamically controlled resyncs.
               Setting this to zero removes the limitation (since DRBD 9.0.28). It should be set to either the
               bandwidth available between the DRBD hosts and the machines hosting DRBD-proxy, or to the
               available disk bandwidth. The default value of <b>c-max-rate</b> is 102400, in units of KiB/s.

               Dynamic resync speed control is available since DRBD 8.3.9.

           <b>--c-min-rate</b> <u>min_rate</u>
               A node which is primary and sync-source has to schedule application I/O requests and resync I/O
               requests. The <b>c-min-rate</b> parameter limits how much bandwidth is available for resync I/O; the
               remaining bandwidth is used for application I/O.

               A <b>c-min-rate</b> value of 0 means that there is no limit on the resync I/O bandwidth. This can slow
               down application I/O significantly. Use a value of 1 (1 KiB/s) for the lowest possible resync
               rate.

               The default value of <b>c-min-rate</b> is 250, in units of KiB/s.

           <b>--resync-rate</b> <u>rate</u>
               Define how much bandwidth DRBD may use for resynchronizing. DRBD allows "normal" application I/O
               even during a resync. If the resync takes up too much bandwidth, application I/O can become very
               slow. This parameter allows to avoid that. Please note this is option only works when the dynamic
               resync controller is disabled.

       <b>drbdsetup</b> check-resize <u>minor</u>
           Remember the current size of the lower-level device of the specified replicated device. Used by
           drbdadm. The size information is stored in file /var/lib/drbd/drbd-minor-<u>minor</u>.lkbd.

       <b>drbdsetup</b> new-peer <u>resource</u> <u>peer_node_id</u>,
       <b>drbdsetup</b> net-options <u>resource</u> <u>peer_node_id</u>
           The <b>new-peer</b> command creates a connection within a <u>resource</u>. The resource must have been created with
           <b>drbdsetup</b> <b>new-resource</b>. The <b>net-options</b> command changes the network options of an existing
           connection. Before a connection can be activated with the <b>connect</b> command, at least one path need to
           added with the <b>new-path</b> command. Available options:

           <b>--after-sb-0pri</b> <u>policy</u>
               Define how to react if a split-brain scenario is detected and none of the two nodes is in primary
               role. (We detect split-brain scenarios when two nodes connect; split-brain decisions are always
               between two nodes.) The defined policies are:

               <b>disconnect</b>
                   No automatic resynchronization; simply disconnect.

               <b>discard-younger-primary</b>,
               <b>discard-older-primary</b>
                   Resynchronize from the node which became primary first (<b>discard-younger-primary</b>) or last
                   (<b>discard-older-primary</b>). If both nodes became primary independently, the
                   <b>discard-least-changes</b> policy is used.

               <b>discard-zero-changes</b>
                   If only one of the nodes wrote data since the split brain situation was detected,
                   resynchronize from this node to the other. If both nodes wrote data, disconnect.

               <b>discard-least-changes</b>
                   Resynchronize from the node with more modified blocks.

               <b>discard-node-</b><u>nodename</u>
                   Always resynchronize to the named node.

           <b>--after-sb-1pri</b> <u>policy</u>
               Define how to react if a split-brain scenario is detected, with one node in primary role and one
               node in secondary role. (We detect split-brain scenarios when two nodes connect, so split-brain
               decisions are always among two nodes.) The defined policies are:

               <b>disconnect</b>
                   No automatic resynchronization, simply disconnect.

               <b>consensus</b>
                   Discard the data on the secondary node if the <b>after-sb-0pri</b> algorithm would also discard the
                   data on the secondary node. Otherwise, disconnect.

               <b>violently-as0p</b>
                   Always take the decision of the <b>after-sb-0pri</b> algorithm, even if it causes an erratic change
                   of the primary's view of the data. This is only useful if a single-node file system (i.e.,
                   not OCFS2 or GFS) with the <b>allow-two-primaries</b> flag is used. This option can cause the
                   primary node to crash, and should not be used.

               <b>discard-secondary</b>
                   Discard the data on the secondary node.

               <b>call-pri-lost-after-sb</b>
                   Always take the decision of the <b>after-sb-0pri</b> algorithm. If the decision is to discard the
                   data on the primary node, call the <b>pri-lost-after-sb</b> handler on the primary node.

           <b>--after-sb-2pri</b> <u>policy</u>
               Define how to react if a split-brain scenario is detected and both nodes are in primary role. (We
               detect split-brain scenarios when two nodes connect, so split-brain decisions are always among
               two nodes.) The defined policies are:

               <b>disconnect</b>
                   No automatic resynchronization, simply disconnect.

               <b>violently-as0p</b>
                   See the <b>violently-as0p</b> policy for <b>after-sb-1pri</b>.

               <b>call-pri-lost-after-sb</b>
                   Call the <b>pri-lost-after-sb</b> helper program on one of the machines unless that machine can
                   demote to secondary. The helper program is expected to reboot the machine, which brings the
                   node into a secondary role. Which machine runs the helper program is determined by the
                   <b>after-sb-0pri</b> strategy.

           <b>--allow-two-primaries</b>
               The most common way to configure DRBD devices is to allow only one node to be primary (and thus
               writable) at a time.

               In some scenarios it is preferable to allow two nodes to be primary at once; a mechanism outside
               of DRBD then must make sure that writes to the shared, replicated device happen in a coordinated
               way. This can be done with a shared-storage cluster file system like OCFS2 and GFS, or with
               virtual machine images and a virtual machine manager that can migrate virtual machines between
               physical machines.

               The <b>allow-two-primaries</b> parameter tells DRBD to allow two nodes to be primary at the same time.
               Never enable this option when using a non-distributed file system; otherwise, data corruption and
               node crashes will result!

           <b>--always-asbp</b>
               Normally the automatic after-split-brain policies are only used if current states of the UUIDs do
               not indicate the presence of a third node.

               With this option you request that the automatic after-split-brain policies are used as long as
               the data sets of the nodes are somehow related. This might cause a full sync, if the UUIDs
               indicate the presence of a third node. (Or double faults led to strange UUID sets.)

           <b>--connect-int</b> <u>time</u>
               As soon as a connection between two nodes is configured with <b>drbdsetup</b> <b>connect</b>, DRBD immediately
               tries to establish the connection. If this fails, DRBD waits for <b>connect-int</b> seconds and then
               repeats. The default value of <b>connect-int</b> is 10 seconds.

           <b>--cram-hmac-alg</b> <u>hash-algorithm</u>
               Configure the hash-based message authentication code (HMAC) or secure hash algorithm to use for
               peer authentication. The kernel supports a number of different algorithms, some of which may be
               loadable as kernel modules. See the shash algorithms listed in /proc/crypto. By default,
               <b>cram-hmac-alg</b> is unset. Peer authentication also requires a <b>shared-secret</b> to be configured.

           <b>--csums-alg</b> <u>hash-algorithm</u>
               Normally, when two nodes resynchronize, the sync target requests a piece of out-of-sync data from
               the sync source, and the sync source sends the data. With many usage patterns, a significant
               number of those blocks will actually be identical.

               When a <b>csums-alg</b> algorithm is specified, when requesting a piece of out-of-sync data, the sync
               target also sends along a hash of the data it currently has. The sync source compares this hash
               with its own version of the data. It sends the sync target the new data if the hashes differ, and
               tells it that the data are the same otherwise. This reduces the network bandwidth required, at
               the cost of higher cpu utilization and possibly increased I/O on the sync target.

               The <b>csums-alg</b> can be set to one of the secure hash algorithms supported by the kernel; see the
               shash algorithms listed in /proc/crypto. By default, <b>csums-alg</b> is unset.

           <b>--csums-after-crash-only</b>
               Enabling this option (and csums-alg, above) makes it possible to use the checksum based resync
               only for the first resync after primary crash, but not for later "network hickups".

               In most cases, block that are marked as need-to-be-resynced are in fact changed, so calculating
               checksums, and both reading and writing the blocks on the resync target is all effective
               overhead.

               The advantage of checksum based resync is mostly after primary crash recovery, where the recovery
               marked larger areas (those covered by the activity log) as need-to-be-resynced, just in case.
               Introduced in 8.4.5.

           <b>--data-integrity-alg</b>  <u>alg</u>
               DRBD normally relies on the data integrity checks built into the TCP/IP protocol, but if a data
               integrity algorithm is configured, it will additionally use this algorithm to make sure that the
               data received over the network match what the sender has sent. If a data integrity error is
               detected, DRBD will close the network connection and reconnect, which will trigger a resync.

               The <b>data-integrity-alg</b> can be set to one of the secure hash algorithms supported by the kernel;
               see the shash algorithms listed in /proc/crypto. By default, this mechanism is turned off.

               Because of the CPU overhead involved, we recommend not to use this option in production
               environments. Also see the notes on data integrity below.

           <b>--fencing</b> <u>fencing_policy</u>
               <b>Fencing</b> is a preventive measure to avoid situations where both nodes are primary and
               disconnected. This is also known as a split-brain situation. DRBD supports the following fencing
               policies:

               <b>dont-care</b>
                   No fencing actions are taken. This is the default policy.

               <b>resource-only</b>
                   If a node becomes a disconnected primary, it tries to fence the peer. This is done by calling
                   the <b>fence-peer</b> handler. The handler is supposed to reach the peer over an alternative
                   communication path and call '<b>drbdadm</b> <b>outdate</b> <b>minor</b>' there.

               <b>resource-and-stonith</b>
                   If a node becomes a disconnected primary, it freezes all its IO operations and calls its
                   fence-peer handler. The fence-peer handler is supposed to reach the peer over an alternative
                   communication path and call '<b>drbdadm</b> <b>outdate</b> <b>minor</b>' there. In case it cannot do that, it
                   should stonith the peer. IO is resumed as soon as the situation is resolved. In case the
                   fence-peer handler fails, I/O can be resumed manually with '<b>drbdadm</b> <b>resume-io</b>'.

           <b>--ko-count</b> <u>number</u>
               If a secondary node fails to complete a write request in <b>ko-count</b> times the <b>timeout</b> parameter, it
               is excluded from the cluster. The primary node then sets the connection to this secondary node to
               Standalone. To disable this feature, you should explicitly set it to 0; defaults may change
               between versions.

           <b>--max-buffers</b> <u>number</u>
               Limits the memory usage per DRBD minor device on the receiving side, or for internal buffers
               during resync or online-verify. Unit is PAGE_SIZE, which is 4 KiB on most systems. The minimum
               possible setting is hard coded to 32 (=128 KiB). These buffers are used to hold data blocks while
               they are written to/read from disk. To avoid possible distributed deadlocks on congestion, this
               setting is used as a throttle threshold rather than a hard limit. Once more than max-buffers
               pages are in use, further allocation from this pool is throttled. You want to increase
               max-buffers if you cannot saturate the IO backend on the receiving side.

           <b>--max-epoch-size</b> <u>number</u>
               Define the maximum number of write requests DRBD may issue before issuing a write barrier. The
               default value is 2048, with a minimum of 1 and a maximum of 20000. Setting this parameter to a
               value below 10 is likely to decrease performance.

           <b>--on-congestion</b> <u>policy</u>,
           <b>--congestion-fill</b> <u>threshold</u>,
           <b>--congestion-extents</b> <u>threshold</u>
               By default, DRBD blocks when the TCP send queue is full. This prevents applications from
               generating further write requests until more buffer space becomes available again.

               When DRBD is used together with DRBD-proxy, it can be better to use the <b>pull-ahead</b> <b>on-congestion</b>
               policy, which can switch DRBD into ahead/behind mode before the send queue is full. DRBD then
               records the differences between itself and the peer in its bitmap, but it no longer replicates
               them to the peer. When enough buffer space becomes available again, the node resynchronizes with
               the peer and switches back to normal replication.

               This has the advantage of not blocking application I/O even when the queues fill up, and the
               disadvantage that peer nodes can fall behind much further. Also, while resynchronizing, peer
               nodes will become inconsistent.

               The available congestion policies are <b>block</b> (the default) and <b>pull-ahead</b>. The <b>congestion-fill</b>
               parameter defines how much data is allowed to be "in flight" in this connection. The default
               value is 0, which disables this mechanism of congestion control, with a maximum of 10 GiBytes.
               The <b>congestion-extents</b> parameter defines how many bitmap extents may be active before switching
               into ahead/behind mode, with the same default and limits as the <b>al-extents</b> parameter. The
               <b>congestion-extents</b> parameter is effective only when set to a value smaller than <b>al-extents</b>.

               Ahead/behind mode is available since DRBD 8.3.10.

           <b>--ping-int</b> <u>interval</u>
               When the TCP/IP connection to a peer is idle for more than <b>ping-int</b> seconds, DRBD will send a
               keep-alive packet to make sure that a failed peer or network connection is detected reasonably
               soon. The default value is 10 seconds, with a minimum of 1 and a maximum of 120 seconds. The unit
               is seconds.

           <b>--ping-timeout</b> <u>timeout</u>
               Define the timeout for replies to keep-alive packets. If the peer does not reply within
               <b>ping-timeout</b>, DRBD will close and try to reestablish the connection. The default value is 0.5
               seconds, with a minimum of 0.1 seconds and a maximum of 30 seconds. The unit is tenths of a
               second.

           <b>--socket-check-timeout</b> <u>timeout</u>
               In setups involving a DRBD-proxy and connections that experience a lot of buffer-bloat it might
               be necessary to set <b>ping-timeout</b> to an unusual high value. By default DRBD uses the same value to
               wait if a newly established TCP-connection is stable. Since the DRBD-proxy is usually located in
               the same data center such a long wait time may hinder DRBD's connect process.

               In such setups <b>socket-check-timeout</b> should be set to at least to the round trip time between DRBD
               and DRBD-proxy. I.e. in most cases to 1.

               The default unit is tenths of a second, the default value is 0 (which causes DRBD to use the
               value of <b>ping-timeout</b> instead). Introduced in 8.4.5.

           <b>--protocol</b> <u>name</u>
               Use the specified protocol on this connection. The supported protocols are:

               <b>A</b>
                   Writes to the DRBD device complete as soon as they have reached the local disk and the TCP/IP
                   send buffer.

               <b>B</b>
                   Writes to the DRBD device complete as soon as they have reached the local disk, and all peers
                   have acknowledged the receipt of the write requests.

               <b>C</b>
                   Writes to the DRBD device complete as soon as they have reached the local and all remote
                   disks.

           <b>--rcvbuf-size</b> <u>size</u>
               Configure the size of the TCP/IP receive buffer. A value of 0 (the default) causes the buffer
               size to adjust dynamically. This parameter usually does not need to be set, but it can be set to
               a value up to 10 MiB. The default unit is bytes.

           <b>--rr-conflict</b> <u>policy</u>
               This option helps to solve the cases when the outcome of the resync decision is incompatible with
               the current role assignment in the cluster. The defined policies are:

               <b>disconnect</b>
                   No automatic resynchronization, simply disconnect.

               <b>retry-connect</b>
                   Disconnect now, and retry to connect immediatly afterwards.

               <b>violently</b>
                   Resync to the primary node is allowed, violating the assumption that data on a block device
                   are stable for one of the nodes.  <u>Do</u> <u>not</u> <u>use</u> <u>this</u> <u>option,</u> <u>it</u> <u>is</u> <u>dangerous.</u>

               <b>call-pri-lost</b>
                   Call the <b>pri-lost</b> handler on one of the machines. The handler is expected to reboot the
                   machine, which puts it into secondary role.

               <b>auto-discard</b>
                   <b>Auto-discard</b> reverses the resync direction, so that DRBD resyncs the current primary to the
                   current secondary.  <b>Auto-discard</b> only applies when protocol A is in use and the resync
                   decision is based on the principle that a crashed primary should be the source of a resync.
                   When a primary node crashes, it might have written some last updates to its disk, which were
                   not received by a protocol A secondary. By promoting the secondary in the meantime the user
                   accepted that those last updates have been lost. By using <b>auto-discard</b> you consent that the
                   last updates (before the crash of the primary) should be rolled back automatically.

           <b>--shared-secret</b> <u>secret</u>
               Configure the shared secret used for peer authentication. The secret is a string of up to 64
               characters. Peer authentication also requires the <b>cram-hmac-alg</b> parameter to be set.

           <b>--sndbuf-size</b> <u>size</u>
               Configure the size of the TCP/IP send buffer. Since DRBD 8.0.13 / 8.2.7, a value of 0 (the
               default) causes the buffer size to adjust dynamically. Values below 32 KiB are harmful to the
               throughput on this connection. Large buffer sizes can be useful especially when protocol A is
               used over high-latency networks; the maximum value supported is 10 MiB.

           <b>--tcp-cork</b>
               By default, DRBD uses the TCP_CORK socket option to prevent the kernel from sending partial
               messages; this results in fewer and bigger packets on the network. Some network stacks can
               perform worse with this optimization. On these, the <b>tcp-cork</b> parameter can be used to turn this
               optimization off.

           <b>--timeout</b> <u>time</u>
               Define the timeout for replies over the network: if a peer node does not send an expected reply
               within the specified <b>timeout</b>, it is considered dead and the TCP/IP connection is closed. The
               timeout value must be lower than <b>connect-int</b> and lower than <b>ping-int</b>. The default is 6 seconds;
               the value is specified in tenths of a second.

           <b>--use-rle</b>
               Each replicated device on a cluster node has a separate bitmap for each of its peer devices. The
               bitmaps are used for tracking the differences between the local and peer device: depending on the
               cluster state, a disk range can be marked as different from the peer in the device's bitmap, in
               the peer device's bitmap, or in both bitmaps. When two cluster nodes connect, they exchange each
               other's bitmaps, and they each compute the union of the local and peer bitmap to determine the
               overall differences.

               Bitmaps of very large devices are also relatively large, but they usually compress very well
               using run-length encoding. This can save time and bandwidth for the bitmap transfers.

               The <b>use-rle</b> parameter determines if run-length encoding should be used. It is on by default since
               DRBD 8.4.0.

           <b>--verify-alg</b> <u>hash-algorithm</u>
               Online verification (<b>drbdadm</b> <b>verify</b>) computes and compares checksums of disk blocks (i.e., hash
               values) in order to detect if they differ. The <b>verify-alg</b> parameter determines which algorithm to
               use for these checksums. It must be set to one of the secure hash algorithms supported by the
               kernel before online verify can be used; see the shash algorithms listed in /proc/crypto.

               We recommend to schedule online verifications regularly during low-load periods, for example once
               a month. Also see the notes on data integrity below.

       <b>drbdsetup</b> new-path <u>resource</u> <u>peer_node_id</u> <u>local-addr</u> <u>remote-addr</u>
           The <b>new-path</b> command creates a path within a <u>connection</u>. The connection must have been created with
           <b>drbdsetup</b> <b>new-peer</b>.  <u>Local_addr</u> and <u>remote_addr</u> refer to the local and remote protocol, network
           address, and port in the format [<u>address-family</u>:]<u>address</u>[:<u>port</u>]. The address families <b>ipv4</b>, <b>ipv6</b>,
           <b>ssocks</b> (Dolphin Interconnect Solutions' "super sockets"), <b>sdp</b> (Infiniband Sockets Direct Protocol),
           and <b>sci</b> are supported (<b>sci</b> is an alias for <b>ssocks</b>). If no address family is specified, <b>ipv4</b> is
           assumed. For all address families except <b>ipv6</b>, the <u>address</u> uses IPv4 address notation (for example,
           1.2.3.4). For <b>ipv6</b>, the address is enclosed in brackets and uses IPv6 address notation (for example,
           [fd01:2345:6789:abcd::1]). The <u>port</u> defaults to 7788.

       <b>drbdsetup</b> connect <u>resource</u> <u>peer_node_id</u>
           The <b>connect</b> command activates a connection. That means that the DRBD driver will bind and listen on
           all local addresses of the connection-'s paths. It will begin to try to establish one or more paths
           of the connection. Available options:

           <b>--tentative</b>
               Only determine if a connection to the peer can be established and if a resync is necessary (and
               in which direction) without actually establishing the connection or starting the resync. Check
               the system log to see what DRBD would do without the <b>--tentative</b> option.

           <b>--discard-my-data</b>
               Discard the local data and resynchronize with the peer that has the most up-to-data data. Use
               this option to manually recover from a split-brain situation.

       <b>drbdsetup</b> del-peer <u>resource</u> <u>peer_node_id</u>
           The <b>del-peer</b> command removes a connection from a <u>resource</u>.

       <b>drbdsetup</b> del-path <u>resource</u> <u>peer_node_id</u> <u>local-addr</u> <u>remote-addr</u>
           The <b>del-path</b> command removes a path from a <u>connection</u>. Please note that it fails if the path is
           necessary to keep a connected connection in tact. In order to remove all paths, disconnect the
           connection first.

       <b>drbdsetup</b> cstate <u>resource</u> <u>peer_node_id</u>
           Show the current state of a connection. The connection is identified by the node-id of the peer; see
           the <b>drbdsetup</b> <b>connect</b> command.

       <b>drbdsetup</b> del-minor <u>minor</u>
           Remove a replicated device. No lower-level device may be attached; see <b>drbdsetup</b> <b>detach</b>.

       <b>drbdsetup</b> del-resource <u>resource</u>
           Remove a resource. All volumes and connections must be removed first (<b>drbdsetup</b> <b>del-minor</b>, <b>drbdsetup</b>
           <b>disconnect</b>). Alternatively, <b>drbdsetup</b> <b>down</b> can be used to remove a resource together with all its
           volumes and connections.

       <b>drbdsetup</b> detach <u>minor</u>
           Detach the lower-level device of a replicated device. Available options:

           <b>--force</b>
               Force the detach and return immediately. This puts the lower-level device into failed state until
               all pending I/O has completed, and then detaches the device. Any I/O not yet submitted to the
               lower-level device (for example, because I/O on the device was suspended) is assumed to have
               failed.

       <b>drbdsetup</b> disconnect <u>resource</u> <u>peer_node_id</u>
           Remove a connection to a peer host. The connection is identified by the node-id of the peer; see the
           <b>drbdsetup</b> <b>connect</b> command.

       <b>drbdsetup</b> down {<u>resource</u> | <u>all</u>}
           Take a resource down by removing all volumes, connections, and the resource itself.

       <b>drbdsetup</b> dstate <u>minor</u>
           Show the current disk state of a lower-level device.

       <b>drbdsetup</b> events2 {<u>resource</u> | <u>all</u>}
           Show the current state of all configured DRBD objects, followed by all changes to the state.

           The output format is meant to be human as well as machine readable. The line starts with a word that
           indicates the kind of event: <b>exists</b> for an existing object; <b>create</b>, <b>destroy</b>, and <b>change</b> if an object
           is created, destroyed, or changed; <b>call</b> or <b>response</b> if an event handler is called or it returns; or
           <b>rename</b> when the name of an object is changed. The second word indicates the object the event applies
           to: <b>resource</b>, <b>device</b>, <b>connection</b>, <b>peer-device</b>, <b>path</b>, <b>helper</b>, or a dash (<b>-</b>) to indicate that the
           current state has been dumped completely.

           The remaining words identify the object and describe the state that the object is in. Some special
           keys are worth mentioning:

           resource <b>may_promote:{yes|no}</b>
               Whether promoting to primary is expected to succeed. When <b>quorum</b> is enabled, this can be used to
               trigger failover. When <b>may_promote:yes</b> is reported on this node, then no writes are possible on
               any other node, which generally means that the application can be started on this node, even when
               it has been running on another.

           resource <b>promotion_score:</b><u>score</u>
               An integer heuristic indicating the relative preference for promoting this resource. A higher
               score is better in terms of having local disks and having access to up-to-date data. The score
               may be positive even when some node is primary. It will be zero when promotion is impossible due
               to quorum or lack of any access to up-to-date data.

           Available options:

           <b>--now</b>
               Terminate after reporting the current state. The default is to continuously listen and report
               state changes.

           <b>--poll</b>
               Read from stdin and update when <b>n</b> is read. Newlines are ignored. Every other input terminates the
               command.

               Without <b>--now</b>, changes are printed as usual. On each <b>n</b> the current state is fetched, but only
               changed objects are printed. This is useful with <b>--statistics</b> or <b>--full</b> because DRBD does not
               otherwise send updates when only the statistics change.

               In combination with <b>--now</b> the full state is printed on each <b>n</b>. No other changes are printed.

           <b>--statistics</b>
               Include statistics in the output.

           <b>--diff</b>
               Write information in form of a diff between old and new state. This helps simple tools to avoid
               (old) state tracking on their own.

           <b>--full</b>
               Write complete state information, especially on change events. This enables <b>--statistics</b> and
               <b>--verbose</b>.

       <b>drbdsetup</b> get-gi <u>resource</u> <u>peer_node_id</u> <u>volume</u>
           Show the data generation identifiers for a device on a particular connection. The device is
           identified by its volume number. The connection is identified by its endpoints; see the <b>drbdsetup</b>
           <b>connect</b> command.

           The output consists of the current UUID, bitmap UUID, and the first two history UUIDS, folowed by a
           set of flags. The current UUID and history UUIDs are device specific; the bitmap UUID and flags are
           peer device specific. This command only shows the first two history UUIDs. Internally, DRBD maintains
           one history UUID for each possible peer device.

       <b>drbdsetup</b> invalidate <u>minor</u>
           Replace the local data of a device with that of a peer. All the local data will be marked
           out-of-sync, and a resync with the specified peer device will be initialted.

           Available options:

           <b>--reset-bitmap=no</b>
               Usually an invalidate operation sets all bits in the bitmap to out-of-sync before beginning the
               resync from the peer. By giving <b>--reset-bitmap=no</b> DRBD will use the bitmap as it is. Usually this
               is used after an online verify operation found differences in the backing devices.

               The <b>--reset-bitmap</b> option is available since DRBD kernel driver 9.0.29 and drbd-utils 9.17.

           <b>--sync-from-peer-node-id</b>
               This option allows the caller to select the node to resync from. if it is not gives, DRBD selects
               a suitable source node itself.

       <b>drbdsetup</b> invalidate-remote <u>resource</u> <u>peer_node_id</u> <u>volume</u>
           Replace a peer device's data of a resource with the local data. The peer device's data will be marked
           out-of-sync, and a resync from the local node to the specified peer will be initiated.

           Available options:

           <b>--reset-bitmap=no</b>
               Usually an invalidate remote operation sets all bits in the bitmap to out-of-sync before
               beginning the resync to the peer. By giving <b>--reset-bitmap=no</b> DRBD will use the bitmap as it is.
               Usually this is used after an online verify operation found differences in the backing devices.

               The <b>--reset-bitmap</b> option is available since DRBD kernel driver 9.0.29 and drbd-utils 9.17.

       <b>drbdsetup</b> new-current-uuid <u>minor</u>
           Generate a new current UUID and rotates all other UUID values. This has three use cases: start the
           initial resync; skip the initial resync; bootstrap a single node cluster.

           Available options:

           <b>--force-resync</b>
               Start an initial resync. A precondition is that the volume is in disk state <b>Inconsistent</b> on all
               nodes. This command updates the disk state on the current node to <b>UpToDate</b> and makes it source of
               the resync operations to the peers.

           <b>--clear-bitmap</b>
               Clears the sync bitmap in addition to generating a new current UUID. This skips the initial
               resync. As a consqeuence this volume's disk state changes to <b>UpToDate</b> on all nodes in this
               resource.

           Both operations require a "Just Created" meta data. Here is the complete sequence step by step how to
           skip the initial resync:

            1. On <u>both</u> nodes, initialize meta data and configure the device.

               <b>drbdadm</b> <b>create-md</b> <b>--force</b> <u>res/volume-number</u>

            2. They need to do the initial handshake, so they know their sizes.

               <b>drbdadm</b> <b>up</b> <u>res</u>

            3. They are now Connected Secondary/Secondary Inconsistent/Inconsistent. Generate a new current-uuid
               and clear the dirty bitmap.

               <b>drbdadm</b> <b>--clear-bitmap</b> <b>new-current-uuid</b> <u>res</u>

            4. They are now Connected Secondary/Secondary UpToDate/UpToDate. Make one side primary and create a
               file system.

               <b>drbdadm</b> <b>primary</b> <u>res</u>

               <b>mkfs</b> <b>-t</b> <u>fs-type</u> <b>$(drbdadm</b> <b>sh-dev</b> <u>res/vol</u><b>)</b>

           One obvious side-effect is that the replica is full of old garbage (unless you made them identical
           using other means), so any online-verify is expected to find any number of out-of-sync blocks.

           <u>You</u> <u>must</u> <u>not</u> <u>use</u> <u>this</u> <u>on</u> <u>pre-existing</u> <u>data!</u>  Even though it may appear to work at first glance, once
           you switch to the other node, your data is toast, as it never got replicated. So <u>do</u> <u>not</u> <u>leave</u> <u>out</u> <u>the</u>
           <u>mkfs</u> (or equivalent).

           <b>Bootstraping</b> <b>a</b> <b>single</b> <b>node</b> <b>cluster</b>
               This can also be used to shorten the initial resync of a cluster where the second node is added
               after the first node is gone into production, by means of disk shipping. This use-case works on
               disconnected devices only, the device may be in primary or secondary role.

               The necessary steps on the current active server are:

                1. <b>drbdsetup</b> <b>new-current-uuid</b> <b>--clear-bitmap</b> <u>minor</u>

                2. Take the copy of the current active server. E.g. by pulling a disk out of the RAID1
                   controller, or by copying with dd. You need to copy the actual data, and the meta data.

                3. <b>drbdsetup</b> <b>new-current-uuid</b> <u>minor</u>

               Now add the disk to the new secondary node, and join it to the cluster. You will get a resync of
               that parts that were changed since the first call to <b>drbdsetup</b> in step 1.

       <b>drbdsetup</b> new-minor <u>resource</u> <u>minor</u> <u>volume</u>
           Create a new replicated device within a resource. The command creates a block device inode for the
           replicated device (by default, /dev/drbd<u>minor</u>). The <u>volume</u> number identifies the device within the
           <u>resource</u>.

       <b>drbdsetup</b> new-resource <u>resource</u> <u>node_id</u>,
       <b>drbdsetup</b> resource-options <u>resource</u>
           The <b>new-resource</b> command creates a new resource. The <b>resource-options</b> command changes the resource
           options of an existing resource. Available options:

           <b>--auto-promote</b> <u>bool-value</u>
               A resource must be promoted to primary role before any of its devices can be mounted or opened
               for writing.

               Before DRBD 9, this could only be done explicitly ("drbdadm primary"). Since DRBD 9, the
               <b>auto-promote</b> parameter allows to automatically promote a resource to primary role when one of its
               devices is mounted or opened for writing. As soon as all devices are unmounted or closed with no
               more remaining users, the role of the resource changes back to secondary.

               Automatic promotion only succeeds if the cluster state allows it (that is, if an explicit <b>drbdadm</b>
               <b>primary</b> command would succeed). Otherwise, mounting or opening the device fails as it already did
               before DRBD 9: the <b><a href="../man2/mount.2.html">mount</a></b>(2) system call fails with errno set to EROFS (Read-only file system);
               the <b><a href="../man2/open.2.html">open</a></b>(2) system call fails with errno set to EMEDIUMTYPE (wrong medium type).

               Irrespective of the <b>auto-promote</b> parameter, if a device is promoted explicitly (<b>drbdadm</b> <b>primary</b>),
               it also needs to be demoted explicitly (<b>drbdadm</b> <b>secondary</b>).

               The <b>auto-promote</b> parameter is available since DRBD 9.0.0, and defaults to <b>yes</b>.

           <b>--cpu-mask</b> <u>cpu-mask</u>
               Set the cpu affinity mask for DRBD kernel threads. The cpu mask is specified as a hexadecimal
               number. The default value is 0, which lets the scheduler decide which kernel threads run on which
               CPUs. CPU numbers in <b>cpu-mask</b> which do not exist in the system are ignored.

           <b>--on-no-data-accessible</b> <u>policy</u>
               Determine how to deal with I/O requests when the requested data is not available locally or
               remotely (for example, when all disks have failed). When quorum is enabled, <b>on-no-data-accessible</b>
               should be set to the same value as <b>on-no-quorum</b>. The defined policies are:

               <b>io-error</b>
                   System calls fail with errno set to EIO.

               <b>suspend-io</b>
                   The resource suspends I/O. I/O can be resumed by (re)attaching the lower-level device, by
                   connecting to a peer which has access to the data, or by forcing DRBD to resume I/O with
                   <b>drbdadm</b> <b>resume-io</b> <u>res</u>. When no data is available, forcing I/O to resume will result in the
                   same behavior as the <b>io-error</b> policy.

               This setting is available since DRBD 8.3.9; the default policy is <b>io-error</b>.

           <b>--peer-ack-window</b> <u>value</u>
               On each node and for each device, DRBD maintains a bitmap of the differences between the local
               and remote data for each peer device. For example, in a three-node setup (nodes A, B, C) each
               with a single device, every node maintains one bitmap for each of its peers.

               When nodes receive write requests, they know how to update the bitmaps for the writing node, but
               not how to update the bitmaps between themselves. In this example, when a write request
               propagates from node A to B and C, nodes B and C know that they have the same data as node A, but
               not whether or not they both have the same data.

               As a remedy, the writing node occasionally sends peer-ack packets to its peers which tell them
               which state they are in relative to each other.

               The <b>peer-ack-window</b> parameter specifies how much data a primary node may send before sending a
               peer-ack packet. A low value causes increased network traffic; a high value causes less network
               traffic but higher memory consumption on secondary nodes and higher resync times between the
               secondary nodes after primary node failures. (Note: peer-ack packets may be sent due to other
               reasons as well, e.g. membership changes or expiry of the <b>peer-ack-delay</b> timer.)

               The default value for <b>peer-ack-window</b> is 2 MiB, the default unit is sectors. This option is
               available since 9.0.0.

           <b>--peer-ack-delay</b> <u>expiry-time</u>
               If after the last finished write request no new write request gets issued for <u>expiry-time</u>, then a
               peer-ack packet is sent. If a new write request is issued before the timer expires, the timer
               gets reset to <u>expiry-time</u>. (Note: peer-ack packets may be sent due to other reasons as well, e.g.
               membership changes or the <b>peer-ack-window</b> option.)

               This parameter may influence resync behavior on remote nodes. Peer nodes need to wait until they
               receive an peer-ack for releasing a lock on an AL-extent. Resync operations between peers may
               need to wait for for these locks.

               The default value for <b>peer-ack-delay</b> is 100 milliseconds, the default unit is milliseconds. This
               option is available since 9.0.0.

           <b>--quorum</b> <u>value</u>
               When activated, a cluster partition requires quorum in order to modify the replicated data set.
               That means a node in the cluster partition can only be promoted to primary if the cluster
               partition has quorum. Every node with a disk directly connected to the node that should be
               promoted counts. If a primary node should execute a write request, but the cluster partition has
               lost quorum, it will freeze IO or reject the write request with an error (depending on the
               <b>on-no-quorum</b> setting). Upon loosing quorum a primary always invokes the <b>quorum-lost</b> handler. The
               handler is intended for notification purposes, its return code is ignored.

               The option's value might be set to <b>off</b>, <b>majority</b>, <b>all</b> or a numeric value. If you set it to a
               numeric value, make sure that the value is greater than half of your number of nodes. Quorum is a
               mechanism to avoid data divergence, it might be used instead of fencing when there are more than
               two repicas. It defaults to <b>off</b>

               If all missing nodes are marked as outdated, a partition always has quorum, no matter how small
               it is. I.e. If you disconnect all secondary nodes gracefully a single primary continues to
               operate. In the moment a single secondary is lost, it has to be assumed that it forms a partition
               with all the missing outdated nodes. In case my partition might be smaller than the other, quorum
               is lost in this moment.

               In case you want to allow permanently diskless nodes to gain quorum it is recommendet to not use
               <b>majority</b> or <b>all</b>. It is recommended to specify an absolute number, since DBRD's heuristic to
               determine the complete number of diskfull nodes in the cluster is unreliable.

               The quorum implementation is available starting with the DRBD kernel driver version 9.0.7.

           <b>--quorum-minimum-redundancy</b> <u>value</u>
               This option sets the minimal required number of nodes with an UpToDate disk to allow the
               partition to gain quorum. This is a different requirement than the plain <b>quorum</b> option expresses.

               The option's value might be set to <b>off</b>, <b>majority</b>, <b>all</b> or a numeric value. If you set it to a
               numeric value, make sure that the value is greater than half of your number of nodes.

               In case you want to allow permanently diskless nodes to gain quorum it is recommendet to not use
               <b>majority</b> or <b>all</b>. It is recommended to specify an absolute number, since DBRD's heuristic to
               determine the complete number of diskfull nodes in the cluster is unreliable.

               This option is available starting with the DRBD kernel driver version 9.0.10.

           <b>--on-no-quorum</b> <b>{io-error</b> <b>|</b> <b>suspend-io}</b>
               By default DRBD freezes IO on a device, that lost quorum. By setting the <b>on-no-quorum</b> to <b>io-error</b>
               it completes all IO operations with an error if quorum is lost.

               Usually, the <b>on-no-data-accessible</b> should be set to the same value as <b>on-no-quorum</b>, as it has
               precedence.

               The <b>on-no-quorum</b> options is available starting with the DRBD kernel driver version 9.0.8.

           <b>--on-suspended-primary-outdated</b> <b>{disconnect</b> <b>|</b> <b>force-secondary}</b>
               This setting is only relevant when <b>on-no-quorum</b> is set to <b>suspend-io</b>. It is relevant in the
               following scenario. A primary node loses quorum hence has all IO requests frozen. This primary
               node then connects to another, quorate partition. It detects that a node in this quorate
               partition was promoted to primary, and started a newer data-generation there. As a result, the
               first primary learns that it has to consider itself outdated.

               When it is set to <b>force-secondary</b> then it will demote to secondary immediately, and fail all
               pending (and new) IO requests with IO errors. It will refuse to allow any process to open the
               DRBD devices until all openers closed the device. This state is visible in <b>status</b> and <b>events2</b>
               under the name <b>force-io-failures</b>.

               The <b>disconnect</b> setting simply causes that node to reject connect attempts and stay isolated.

               The <b>on-suspended-primary-outdated</b> option is available starting with the DRBD kernel driver
               version 9.1.7. It has a default value of <b>disconnect</b>.

       <b>drbdsetup</b> outdate <u>minor</u>
           Mark the data on a lower-level device as outdated. This is used for fencing, and prevents the
           resource the device is part of from becoming primary in the future. See the <b>--fencing</b> disk option.

       <b>drbdsetup</b> pause-sync <u>resource</u> <u>peer_node_id</u> <u>volume</u>
           Stop resynchronizing between a local and a peer device by setting the local pause flag. The resync
           can only resume if the pause flags on both sides of a connection are cleared.

       <b>drbdsetup</b> primary <u>resource</u>
           Change the role of a node in a resource to primary. This allows the replicated devices in this
           resource to be mounted or opened for writing. Available options:

           <b>--overwrite-data-of-peer</b>
               This option is an alias for the <b>--force</b> option.

           <b>--force</b>
               Force the resource to become primary even if some devices are not guaranteed to have up-to-date
               data. This option is used to turn one of the nodes in a newly created cluster into the primary
               node, or when manually recovering from a disaster.

               Note that this can lead to split-brain scenarios. Also, when forcefully turning an inconsistent
               device into an up-to-date device, it is highly recommended to use any integrity checks available
               (such as a filesystem check) to make sure that the device can at least be used without crashing
               the system.

           Note that DRBD usually only allows one node in a cluster to be in primary role at any time; this
           allows DRBD to coordinate access to the devices in a resource across nodes. The <b>--allow-two-primaries</b>
           network option changes this; in that case, a mechanism outside of DRBD needs to coordinate device
           access.

       <b>drbdsetup</b> resize <u>minor</u>
           Reexamine the size of the lower-level devices of a replicated device on all nodes. This command is
           called after the lower-level devices on all nodes have been grown to adjust the size of the
           replicated device. Available options:

           <b>--assume-peer-has-space</b>
               Resize the device even if some of the peer devices are not connected at the moment. DRBD will try
               to resize the peer devices when they next connect. It will refuse to connect to a peer device
               which is too small.

           <b>--assume-clean</b>
               Do not resynchronize the added disk space; instead, assume that it is identical on all nodes.
               This option can be used when the disk space is uninitialized and differences do not matter, or
               when it is known to be identical on all nodes. See the <b>drbdsetup</b> <b>verify</b> command.

           <b>--size</b> <u>val</u>
               This option can be used to online shrink the usable size of a drbd device. It's the users
               responsibility to make sure that a file system on the device is not truncated by that operation.

           <b>--al-stripes</b> <u>val</u> <b>--al-stripes</b> <u>val</u>
               These options may be used to change the layout of the activity log online. In case of internal
               meta data this may invovle shrinking the user visible size at the same time (unsing the <b>--size</b>)
               or increasing the avalable space on the backing devices.

       <b>drbdsetup</b> resume-io <u>minor</u>
           Resume I/O on a replicated device. See the <b>--fencing</b> net option.

       <b>drbdsetup</b> resume-sync <u>resource</u> <u>peer_node_id</u> <u>volume</u>
           Allow resynchronization to resume by clearing the local sync pause flag.

       <b>drbdsetup</b> role <u>resource</u>
           Show the current role of a resource.

       <b>drbdsetup</b> secondary <u>resource</u>
           Change the role of a node in a resource to secondary. This command fails if the replicated device is
           in use.

           <b>--force</b>
               A forced demotion to secondary causes all pending and new IO requests to terminate with IO
               errors.

               Please note that a forced demotion returns immediately. The user should unmount any filesystem
               that might be mounted on the DRBD device. The device can be used again when <b>force-io-failures</b> has
               a value of <b>no</b>. (See <b>drbdsetup</b> <b>status</b> and <b>drbdsetup</b> <b>events2</b>).

       <b>drbdsetup</b> show {<u>resource</u> | <u>all</u>}
           Show the current configuration of a resource, or of all resources. Available options:

           <b>--show-defaults</b>
               Show all configuration parameters, even the ones with default values. Normally, parameters with
               default values are not shown.

       <b>drbdsetup</b> show-gi <u>resource</u> <u>peer_node_id</u> <u>volume</u>
           Show the data generation identifiers for a device on a particular connection. In addition, explain
           the output. The output otherwise is the same as in the <b>drbdsetup</b> <b>get-gi</b> command.

       <b>drbdsetup</b> state
           This is an alias for <b>drbdsetup</b> <b>role</b>. Deprecated.

       <b>drbdsetup</b> status {<u>resource</u> | <u>all</u>}
           Show the status of a resource, or of all resources. The output consists of one paragraph for each
           configured resource. Each paragraph contains one line for each resource, followed by one line for
           each device, and one line for each connection. The device and connection lines are indented. The
           connection lines are followed by one line for each peer device; these lines are indented against the
           connection line.

           Long lines are wrapped around at terminal width, and indented to indicate how the lines belongs
           together. Available options:

           <b>--verbose</b>
               Include more information in the output even when it is likely redundant or irrelevant.

           <b>--statistics</b>
               Include data transfer statistics in the output.

           <b>--color={always</b> <b>|</b> <b>auto</b> <b>|</b> <b>never}</b>
               Colorize the output. With <b>--color=auto</b>, <b>drbdsetup</b> emits color codes only when standard output is
               connected to a terminal.

           For example, the non-verbose output for a resource with only one connection and only one volume could
           look like this:

               drbd0 role:Primary
                 disk:UpToDate
                 host2.example.com role:Secondary
                   disk:UpToDate

           With the <b>--verbose</b> option, the same resource could be reported as:

               drbd0 node-id:1 role:Primary suspended:no
                 volume:0 minor:1 disk:UpToDate blocked:no
                 host2.example.com local:ipv4:192.168.123.4:7788
                     peer:ipv4:192.168.123.2:7788 node-id:0 connection:WFReportParams
                     role:Secondary congested:no
                   volume:0 replication:Connected disk:UpToDate resync-suspended:no

       <b>drbdsetup</b> suspend-io <u>minor</u>
           Suspend I/O on a replicated device. It is not usually necessary to use this command.

       <b>drbdsetup</b> verify <u>resource</u> <u>peer_node_id</u> <u>volume</u>
           Start online verification, change which part of the device will be verified, or stop online
           verification. The command requires the specified peer to be connected.

           Online verification compares each disk block on the local and peer node. Blocks which differ between
           the nodes are marked as out-of-sync, but they are <u>not</u> automatically brought back into sync. To bring
           them into sync, the <b>drbdsetup</b> <b>invalidate</b> or <b>drbdsetup</b> <b>invalidate-remote</b> with the <b>--reset-bitmap=no</b>
           option can be used. Progress can be monitored in the output of <b>drbdsetup</b> <b>status</b> <b>--statistics</b>.
           Available options:

           <b>--start</b> <u>position</u>
               Define where online verification should start. This parameter is ignored if online verification
               is already in progress. If the start parameter is not specified, online verification will
               continue where it was interrupted (if the connection to the peer was lost while verifying), after
               the previous stop sector (if the previous online verification has finished), or at the beginning
               of the device (if the end of the device was reached, or online verify has not run before).

               The position on disk is specified in disk sectors (512 bytes) by default.

           <b>--stop</b> <u>position</u>
               Define where online verification should stop. If online verification is already in progress, the
               stop position of the active online verification process is changed. Use this to stop online
               verification.

               The position on disk is specified in disk sectors (512 bytes) by default.

           Also see the notes on data integrity in the <b><a href="../man5/drbd.conf.5.html">drbd.conf</a></b>(5) manual page.

       <b>drbdsetup</b> wait-connect-volume <u>resource</u> <u>peer_node_id</u> <u>volume</u>,
       <b>drbdsetup</b> wait-connect-connection <u>resource</u> <u>peer_node_id</u>,
       <b>drbdsetup</b> wait-connect-resource <u>resource</u>,
       <b>drbdsetup</b> wait-sync-volume <u>resource</u> <u>peer_node_id</u> <u>volume</u>,
       <b>drbdsetup</b> wait-sync-connection <u>resource</u> <u>peer_node_id</u>,
       <b>drbdsetup</b> wait-sync-resource <u>resource</u>
           The <b>wait-connect-*</b> commands waits until a device on a peer is visible. The <b>wait-sync-*</b> commands waits
           until a device on a peer is up to date. Available options for both commands:

           <b>--degr-wfc-timeout</b> <u>timeout</u>
               Define how long to wait until all peers are connected in case the cluster consisted of a single
               node only when the system went down. This parameter is usually set to a value smaller than
               <b>wfc-timeout</b>. The assumption here is that peers which were unreachable before a reboot are less
               likely to be reachable after the reboot, so waiting is less likely to help.

               The timeout is specified in seconds. The default value is 0, which stands for an infinite
               timeout. Also see the <b>wfc-timeout</b> parameter.

           <b>--outdated-wfc-timeout</b> <u>timeout</u>
               Define how long to wait until all peers are connected if all peers were outdated when the system
               went down. This parameter is usually set to a value smaller than <b>wfc-timeout</b>. The assumption here
               is that an outdated peer cannot have become primary in the meantime, so we don't need to wait for
               it as long as for a node which was alive before.

               The timeout is specified in seconds. The default value is 0, which stands for an infinite
               timeout. Also see the <b>wfc-timeout</b> parameter.

           <b>--wait-after-sb</b>
               This parameter causes DRBD to continue waiting in the init script even when a split-brain
               situation has been detected, and the nodes therefore refuse to connect to each other.

           <b>--wfc-timeout</b> <u>timeout</u>
               Define how long the init script waits until all peers are connected. This can be useful in
               combination with a cluster manager which cannot manage DRBD resources: when the cluster manager
               starts, the DRBD resources will already be up and running. With a more capable cluster manager
               such as Pacemaker, it makes more sense to let the cluster manager control DRBD resources. The
               timeout is specified in seconds. The default value is 0, which stands for an infinite timeout.
               Also see the <b>degr-wfc-timeout</b> parameter.

       <b>drbdsetup</b> forget-peer <u>resource</u> <u>peer_node_id</u>
           The <b>forget-peer</b> command removes all traces of a peer node from the meta-data. It frees a bitmap slot
           in the meta-data and make it avalable for futher bitmap slot allocation in case a so-far never seen
           node connects.

           The connection must be taken down before this command may be used. In case the peer re-connects at a
           later point a bit-map based resync will be turned into a full-sync.

       <b>drbdsetup</b> rename-resource <u>resource</u> <u>new_name</u>
           Change the name of <b>resource</b> to <b>new_name</b> on the local node. Note that, since there is no concept of
           resource names in DRBD's network protocol, it is technically possible to have different names for a
           resource on different nodes. However, it is strongly recommended to issue the same <b>rename-resource</b>
           command on all nodes to have consistent naming across the cluster.

           A <b>rename</b> event will be issued on the <b>events2</b> stream to notify users of the new name.

</pre><h4><b>EXAMPLES</b></h4><pre>
       Please see the <b>DRBD</b> <b>User's</b> <b>Guide</b>[1] for examples.

</pre><h4><b>VERSION</b></h4><pre>
       This document was revised for version 9.0.0 of the DRBD distribution.

</pre><h4><b>AUTHOR</b></h4><pre>
       Written by Philipp Reisner &lt;<a href="mailto:philipp.reisner@linbit.com">philipp.reisner@linbit.com</a>&gt; and Lars Ellenberg &lt;<a href="mailto:lars.ellenberg@linbit.com">lars.ellenberg@linbit.com</a>&gt;.

</pre><h4><b>REPORTING</b> <b>BUGS</b></h4><pre>
       Report bugs to &lt;<a href="mailto:drbd-user@lists.linbit.com">drbd-user@lists.linbit.com</a>&gt;.

</pre><h4><b>COPYRIGHT</b></h4><pre>
       Copyright 2001-2018 LINBIT Information Technologies, Philipp Reisner, Lars Ellenberg. This is free
       software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or
       FITNESS FOR A PARTICULAR PURPOSE.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man5/drbd.conf.5.html">drbd.conf</a></b>(5), <b><a href="../man8/drbd.8.html">drbd</a></b>(8), <b><a href="../man8/drbdadm.8.html">drbdadm</a></b>(8), <b>DRBD</b> <b>User's</b> <b>Guide</b>[1], <b>DRBD</b> <b>Web</b> <b>Site</b>[2]

</pre><h4><b>NOTES</b></h4><pre>
        1. DRBD User's Guide
           <a href="http://www.drbd.org/users-guide/">http://www.drbd.org/users-guide/</a>

        2. DRBD Web Site
           <a href="http://www.drbd.org/">http://www.drbd.org/</a>

DRBD 9.0.x                                       17 January 2018                                    <u><a href="../man8/DRBDSETUP.8.html">DRBDSETUP</a></u>(8)
</pre>
 </div>
</div></section>
</div>
</body>
</html>