<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ceph - ceph administration tool</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/ceph-common">ceph-common_19.2.1-0ubuntu3_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       ceph - ceph administration tool

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>ceph</b> <b>auth</b> [ <u>add</u> | <u>caps</u> | <u>del</u> | <u>export</u> | <u>get</u> | <u>get-key</u> | <u>get-or-create</u> | <u>get-or-create-key</u> | <u>import</u> | <u>list</u> | <u>print-key</u> | <u>print_key</u> ] ...

       <b>ceph</b> <b>compact</b>

       <b>ceph</b> <b>config</b> [ <u>dump</u> | <u>ls</u> | <u>help</u> | <u>get</u> | <u>show</u> | <u>show-with-defaults</u> | <u>set</u> | <u>rm</u> | <u>log</u> | <u>reset</u> | <u>assimilate-conf</u> | <u>generate-minimal-conf</u> ] ...

       <b>ceph</b> <b>config-key</b> [ <u>rm</u> | <u>exists</u> | <u>get</u> | <u>ls</u> | <u>dump</u> | <u>set</u> ] ...

       <b>ceph</b> <b>daemon</b> <u>&lt;name&gt;</u> | <u>&lt;path&gt;</u> <u>&lt;command&gt;</u> ...

       <b>ceph</b> <b>daemonperf</b> <u>&lt;name&gt;</u> | <u>&lt;path&gt;</u> [ <u>interval</u> [ <u>count</u> ] ]

       <b>ceph</b> <b>df</b> <u>{detail}</u>

       <b>ceph</b> <b>fs</b> [ <u>add_data_pool</u> | <u>authorize</u> | <u>dump</u> | <u>feature</u> <u>ls</u> | <u>flag</u> <u>set</u> | <u>get</u> | <u>ls</u> | <u>lsflags</u> | <u>new</u> | <u>rename</u> | <u>reset</u> | <u>required_client_features</u> <u>add</u> | <u>required_client_features</u> <u>rm</u> | <u>rm</u> | <u>rm_data_pool</u> | <u>set</u> | <u>swap</u> ] ...

       <b>ceph</b> <b>fsid</b>

       <b>ceph</b> <b>health</b> <u>{detail}</u>

       <b>ceph</b> <b>injectargs</b> <u>&lt;injectedargs&gt;</u> [ <u>&lt;injectedargs&gt;</u>... ]

       <b>ceph</b> <b>log</b> <u>&lt;logtext&gt;</u> [ <u>&lt;logtext&gt;</u>... ]

       <b>ceph</b> <b>mds</b> [ <u>compat</u> | <u>fail</u> | <u>rm</u> | <u>rmfailed</u> | <u>set_state</u> | <u>stat</u> | <u>repaired</u> ] ...

       <b>ceph</b> <b>mon</b> [ <u>add</u> | <u>dump</u> | <u>enable_stretch_mode</u> | <u>getmap</u> | <u>remove</u> | <u>stat</u> ] ...

       <b>ceph</b> <b>osd</b> [ <u>blocklist</u> | <u>blocked-by</u> | <u>create</u> | <u>new</u> | <u>deep-scrub</u> | <u>df</u> | <u>down</u> | <u>dump</u> | <u>erasure-code-profile</u> | <u>find</u> | <u>getcrushmap</u> | <u>getmap</u> | <u>getmaxosd</u> | <u>in</u> | <u>ls</u> | <u>lspools</u> | <u>map</u> | <u>metadata</u> | <u>ok-to-stop</u> | <u>out</u> | <u>pause</u> | <u>perf</u> | <u>pg-temp</u> | <u>force-create-pg</u> | <u>primary-affinity</u> | <u>primary-temp</u> | <u>repair</u> | <u>reweight</u> | <u>reweight-by-pg</u> | <u>rm</u> | <u>destroy</u> | <u>purge</u> | <u>safe-to-destroy</u> | <u>scrub</u> | <u>set</u> | <u>setcrushmap</u> | <u>setmaxosd</u>  | <u>stat</u> | <u>tree</u> | <u>unpause</u> | <u>unset</u> ] ...

       <b>ceph</b> <b>osd</b> <b>crush</b> [ <u>add</u> | <u>add-bucket</u> | <u>create-or-move</u> | <u>dump</u> | <u>get-tunable</u> | <u>link</u> | <u>move</u> | <u>remove</u> | <u>rename-bucket</u> | <u>reweight</u> | <u>reweight-all</u> | <u>reweight-subtree</u> | <u>rm</u> | <u>rule</u> | <u>set</u> | <u>set-tunable</u> | <u>show-tunables</u> | <u>tunables</u> | <u>unlink</u> ] ...

       <b>ceph</b> <b>osd</b> <b>pool</b> [ <u>create</u> | <u>delete</u> | <u>get</u> | <u>get-quota</u> | <u>ls</u> | <u>mksnap</u> | <u>rename</u> | <u>rmsnap</u> | <u>set</u> | <u>set-quota</u> | <u>stats</u> ] ...

       <b>ceph</b> <b>osd</b> <b>pool</b> <b>application</b> [ <u>disable</u> | <u>enable</u> | <u>get</u> | <u>rm</u> | <u>set</u> ] ...

       <b>ceph</b> <b>osd</b> <b>tier</b> [ <u>add</u> | <u>add-cache</u> | <u>cache-mode</u> | <u>remove</u> | <u>remove-overlay</u> | <u>set-overlay</u> ] ...

       <b>ceph</b> <b>pg</b> [ <u>debug</u> | <u>deep-scrub</u> | <u>dump</u> | <u>dump_json</u> | <u>dump_pools_json</u> | <u>dump_stuck</u> | <u>getmap</u> | <u>ls</u> | <u>ls-by-osd</u> | <u>ls-by-pool</u> | <u>ls-by-primary</u> | <u>map</u> | <u>repair</u> | <u>scrub</u> | <u>stat</u> ] ...

       <b>ceph</b> <b>quorum_status</b>

       <b>ceph</b> <b>report</b> { <u>&lt;tags&gt;</u> [ <u>&lt;tags&gt;...</u> ] }

       <b>ceph</b> <b>status</b>

       <b>ceph</b> <b>sync</b> <b>force</b> {--yes-i-really-mean-it} {--i-know-what-i-am-doing}

       <b>ceph</b> <b>tell</b> <u>&lt;name</u> <u>(type.id)&gt;</u> <u>&lt;command&gt;</u> <u>[options...]</u>

       <b>ceph</b> <b>version</b>

</pre><h4><b>DESCRIPTION</b></h4><pre>
       <b>ceph</b>  is  a  control  utility  which  is used for manual deployment and maintenance of a Ceph cluster. It
       provides a diverse set of commands that allows deployment of monitors, OSDs, placement  groups,  MDS  and
       overall maintenance, administration of the cluster.

</pre><h4><b>COMMANDS</b></h4><pre>
   <b>auth</b>
       Manage authentication keys. It is used for adding, removing, exporting or updating of authentication keys
       for a particular  entity such as a monitor or OSD. It uses some additional subcommands.

       Subcommand  <b>add</b>  adds  authentication  info  for a particular entity from input file, or random key if no
       input is given and/or any caps specified in the command.

       Usage:

          ceph auth add &lt;entity&gt; {&lt;caps&gt; [&lt;caps&gt;...]}

       Subcommand <b>caps</b> updates caps for <b>name</b> from caps specified in the command.

       Usage:

          ceph auth caps &lt;entity&gt; &lt;caps&gt; [&lt;caps&gt;...]

       Subcommand <b>del</b> deletes all caps for <b>name</b>.

       Usage:

          ceph auth del &lt;entity&gt;

       Subcommand <b>export</b> writes keyring for requested entity, or master keyring if none given.

       Usage:

          ceph auth export {&lt;entity&gt;}

       Subcommand <b>get</b> writes keyring file with requested key.

       Usage:

          ceph auth get &lt;entity&gt;

       Subcommand <b>get-key</b> displays requested key.

       Usage:

          ceph auth get-key &lt;entity&gt;

       Subcommand <b>get-or-create</b> adds authentication info for a particular entity from input file, or random  key
       if no input given and/or any caps specified in the command.

       Usage:

          ceph auth get-or-create &lt;entity&gt; {&lt;caps&gt; [&lt;caps&gt;...]}

       Subcommand  <b>get-or-create-key</b>  gets or adds key for <b>name</b> from system/caps pairs specified in the command.
       If key already exists, any given caps must match the existing caps for that key.

       Usage:

          ceph auth get-or-create-key &lt;entity&gt; {&lt;caps&gt; [&lt;caps&gt;...]}

       Subcommand <b>import</b> reads keyring from input file.

       Usage:

          ceph auth import

       Subcommand <b>ls</b> lists authentication state.

       Usage:

          ceph auth ls

       Subcommand <b>print-key</b> displays requested key.

       Usage:

          ceph auth print-key &lt;entity&gt;

       Subcommand <b>print_key</b> displays requested key.

       Usage:

          ceph auth print_key &lt;entity&gt;

   <b>compact</b>
       Causes compaction of monitor's RocksDB storage.

       Usage:

          ceph compact

   <b>config</b>
       Configure the cluster. By default, Ceph daemons and clients retrieve  their  configuration  options  from
       monitor  when  they  start, and are updated if any of the tracked options is changed at run time. It uses
       following additional subcommand.

       Subcommand <b>dump</b> to dump all options for the cluster

       Usage:

          ceph config dump

       Subcommand <b>ls</b> to list all option names for the cluster

       Usage:

          ceph config ls

       Subcommand <b>help</b> to describe the specified configuration option

       Usage:

          ceph config help &lt;option&gt;

       Subcommand <b>get</b> to dump the option(s) for the specified entity.

       Usage:

          ceph config get &lt;who&gt; {&lt;option&gt;}

       Subcommand <b>show</b> to display the running configuration of the specified entity. Please  note,  unlike  <b>get</b>,
       which  only  shows  the  options  managed by monitor, <b>show</b> displays all the configurations being actively
       used.  These options are pulled from several sources, for instance, the compiled-in  default  value,  the
       monitor's  configuration  database,  <b>ceph.conf</b>  file  on  the host. The options can even be overridden at
       runtime. So, there is chance that the configuration options in the output of <b>show</b> could be different from
       those in the output of <b>get</b>.

       Usage:

          ceph config show {&lt;who&gt;}

       Subcommand <b>show-with-defaults</b> to display the running configuration along with the compiled-in defaults of
       the specified entity

       Usage:

          ceph config show {&lt;who&gt;}

       Subcommand <b>set</b> to set an option for one or more specified entities

       Usage:

          ceph config set &lt;who&gt; &lt;option&gt; &lt;value&gt; {--force}

       Subcommand <b>rm</b> to clear an option for one or more entities

       Usage:

          ceph config rm &lt;who&gt; &lt;option&gt;

       Subcommand <b>log</b> to show recent history of config changes. If <u>count</u> option is omitted it defaults to 10.

       Usage:

          ceph config log {&lt;count&gt;}

       Subcommand <b>reset</b> to revert configuration to the specified historical version

       Usage:

          ceph config reset &lt;version&gt;

       Subcommand <b>assimilate-conf</b> to assimilate options from stdin, and return a new, minimal conf file

       Usage:

          ceph config assimilate-conf -i &lt;input-config-path&gt; &gt; &lt;output-config-path&gt;
          ceph config assimilate-conf &lt; &lt;input-config-path&gt;

       Subcommand  <b>generate-minimal-conf</b>  to  generate  a  minimal  <b>ceph.conf</b>  file,  which  can  be  used   for
       bootstrapping a daemon or a client.

       Usage:

          ceph config generate-minimal-conf &gt; &lt;minimal-config-path&gt;

   <b>config-key</b>
       Manage configuration key. Config-key is a general purpose key/value service offered by the monitors. This
       service  is  mainly used by Ceph tools and daemons for persisting various settings. Among which, ceph-mgr
       modules uses it for storing their options. It uses some additional subcommands.

       Subcommand <b>rm</b> deletes configuration key.

       Usage:

          ceph config-key rm &lt;key&gt;

       Subcommand <b>exists</b> checks for configuration keys existence.

       Usage:

          ceph config-key exists &lt;key&gt;

       Subcommand <b>get</b> gets the configuration key.

       Usage:

          ceph config-key get &lt;key&gt;

       Subcommand <b>ls</b> lists configuration keys.

       Usage:

          ceph config-key ls

       Subcommand <b>dump</b> dumps configuration keys and values.

       Usage:

          ceph config-key dump

       Subcommand <b>set</b> puts configuration key and value.

       Usage:

          ceph config-key set &lt;key&gt; {&lt;val&gt;}

   <b>daemon</b>
       Submit admin-socket commands.

       Usage:

          ceph daemon {daemon_name|socket_path} {command} ...

       Example:

          ceph daemon osd.0 help

   <b>daemonperf</b>
       Watch performance counters from a Ceph daemon.

       Usage:

          ceph daemonperf {daemon_name|socket_path} [{interval} [{count}]]

   <b>df</b>
       Show cluster's free space status.

       Usage:

          ceph df {detail}

   <b>features</b>
       Show the releases and features of all connected daemons and clients connected to the cluster, along  with
       the  numbers  of them in each bucket grouped by the corresponding features/releases. Each release of Ceph
       supports a different set of features, expressed by the features bitmask.  New  cluster  features  require
       that  clients  support the feature, or else they are not allowed to connect to these new features. As new
       features or capabilities are enabled after an upgrade, older clients are prevented from connecting.

       Usage:

          ceph features

   <b>fs</b>
       Manage cephfs file systems. It uses some additional subcommands.

       Subcommand <b>add_data_pool</b> adds an new data pool to the FS. Ths pool can be used for  file  layouts  as  an
       alternate location to store the file data.

       Usage:

          ceph fs add_data_pool &lt;fs-name&gt; &lt;pool name/id&gt;

       Subcommand  <b>authorize</b>  creates  a  new  client (if the client doesn't exists on the cluster) that will be
       authorized for the given path in <b>&lt;fs_name&gt;</b>.  Pass <b>/</b> to authorize for the entire FS. <b>&lt;perms&gt;</b> below can  be
       <b>r</b>, <b>rw</b> or <b>rwp</b>.

       Running  it  for  an  existing  client  can grant the client a new capability (capability for a different
       CephFS on the same cluster or for a different path on the same CephFS). Or it can also change  read/write
       permission in the capability that client already holds.

       Usage:

          ceph fs authorize &lt;fs_name&gt; client.&lt;client_id&gt; &lt;path&gt; &lt;perms&gt; [&lt;path&gt; &lt;perms&gt;...]

       Subcommand  <b>dump</b> displays the FSMap at the given epoch (default: current).  This includes all file system
       settings, MDS daemons and the ranks they hold and list of standby MDS daemons.

       Usage:

          ceph fs dump [epoch]

       Subcommand <b>feature</b> <b>ls</b> lists all CephFS features supported by current version of Ceph.

       Usage:

          ceph fs feature ls

       Subcommand <b>flag</b> <b>set</b> sets a global CephFS flag. Right now the only flag is  <b>enable_multiple</b>  which  allows
       multiple CephFSs on a Ceph cluster.

       Usage:

          ceph fs flag set &lt;flag-name&gt; &lt;flag-val&gt; --yes-i-really-mean-it

       Subcommand  <b>get</b> displays the information about FS, including settings and ranks. Information printed here
       in subset of same information from the <b>fs</b> <b>dump</b> command.

       Usage:

          ceph fs get &lt;fs-name&gt;

       Subcommand <b>ls</b> to list file systems

       Usage:

          ceph fs ls

       Subcommand <b>lsflags</b> displays all the flags set on the given FS.

       Usage:

          ceph fs lsflags &lt;fs-name&gt;

       Subcommand <b>new</b> to make a new file system using named pools &lt;metadata&gt; and &lt;data&gt;

       Usage:

          ceph fs new &lt;fs_name&gt; &lt;metadata&gt; &lt;data&gt;

       Subcommand <b>rename</b> assigns a new name to CephFS and also updates application tags on  the  pools  of  this
       CephFS.

       Usage:

          ceph fs rename &lt;fs-name&gt; &lt;new-fs-name&gt; {--yes-i-really-mean-it}

       Subcommand  <b>required_client_features</b>  disables  a  client  that  doesn't  possess  a certain feature from
       connecting. This subcommand has two subcommands, one to  add  a  requirement  and  other  to  remove  the
       requirement.

       Usage:

          ceph fs required_client_features &lt;fs name&gt; add &lt;feature-name&gt;
          ceph fs required_client_features &lt;fs name&gt; rm &lt;feature-name&gt;

       Subcommand <b>reset</b> is used for disaster recovery only: reset to a single-MDS map

       Usage:

          ceph fs reset &lt;fs_name&gt; {--yes-i-really-mean-it}

       Subcommand <b>rm</b> to disable the named file system

       Usage:

          ceph fs rm &lt;fs_name&gt; {--yes-i-really-mean-it}

       Subcommand  <b>rm_data_pool</b>  removes the specified pool from FS's list of data pools. File data on this pool
       will become unavailable. Default data pool cannot be removed.

       Usage:

          ceph fs rm_data_pool &lt;fs-name&gt; &lt;pool name/id&gt;

       Subcommand <b>set</b> sets or updates a FS setting value for given FS name.

       Usage:

          ceph fs set &lt;fs-name&gt; &lt;fs-setting&gt; &lt;value&gt;

       Subcommand <b>swap</b> swaps the names of two Ceph file system and updates application tags on the pool  of  the
       file  systems  accordingly.  Optionally, FSIDs of the filesystems can also be swapped along with names by
       passing <b>--swap-fscids</b>.

       Usage:

          ceph fs swap &lt;fs1-name&gt; &lt;fs1-id&gt; &lt;fs2-name&gt; &lt;fs2-id&gt; [--swap-fscids] {--yes-i-really-meant-it}

   <b>fsid</b>
       Show cluster's FSID/UUID.

       Usage:

          ceph fsid

   <b>health</b>
       Show cluster's health.

       Usage:

          ceph health {detail}

   <b>heap</b>
       Show heap usage info (available only if compiled with tcmalloc)

       Usage:

          ceph tell &lt;name (type.id)&gt; heap dump|start_profiler|stop_profiler|stats

       Subcommand <b>release</b> to make TCMalloc to releases no-longer-used memory back to the kernel at once.

       Usage:

          ceph tell &lt;name (type.id)&gt; heap release

       Subcommand <b>(get|set)_release_rate</b> get  or  set  the  TCMalloc  memory  release  rate.  TCMalloc  releases
       no-longer-used memory back to the kernel gradually. the rate controls how quickly this happens.  Increase
       this  setting  to  make  TCMalloc to return unused memory more frequently. 0 means never return memory to
       system, 1 means wait for 1000 pages after releasing a page to system. It is <b>1.0</b> by default..

       Usage:

          ceph tell &lt;name (type.id)&gt; heap get_release_rate|set_release_rate {&lt;val&gt;}

   <b>injectargs</b>
       Inject configuration arguments into monitor.

       Usage:

          ceph injectargs &lt;injected_args&gt; [&lt;injected_args&gt;...]

   <b>log</b>
       Log supplied text to the monitor log.

       Usage:

          ceph log &lt;logtext&gt; [&lt;logtext&gt;...]

   <b>mds</b>
       Manage metadata server configuration and administration. It uses some additional subcommands.

       Subcommand <b>compat</b> manages compatible features. It uses some additional subcommands.

       Subcommand <b>rm_compat</b> removes compatible feature.

       Usage:

          ceph mds compat rm_compat &lt;int[0-]&gt;

       Subcommand <b>rm_incompat</b> removes incompatible feature.

       Usage:

          ceph mds compat rm_incompat &lt;int[0-]&gt;

       Subcommand <b>show</b> shows mds compatibility settings.

       Usage:

          ceph mds compat show

       Subcommand <b>fail</b> forces mds to status fail.

       Usage:

          ceph mds fail &lt;role|gid&gt;

       Subcommand <b>rm</b> removes inactive mds.

       Usage:

          ceph mds rm &lt;int[0-]&gt; &lt;name&gt; (type.id)&gt;

       Subcommand <b>rmfailed</b> removes failed mds.

       Usage:

          ceph mds rmfailed &lt;int[0-]&gt;

       Subcommand <b>set_state</b> sets mds state of &lt;gid&gt; to &lt;numeric-state&gt;.

       Usage:

          ceph mds set_state &lt;int[0-]&gt; &lt;int[0-20]&gt;

       Subcommand <b>stat</b> shows MDS status.

       Usage:

          ceph mds stat

       Subcommand <b>repaired</b> mark a damaged MDS rank as no longer damaged.

       Usage:

          ceph mds repaired &lt;role&gt;

   <b>mon</b>
       Manage monitor configuration and administration. It uses some additional subcommands.

       Subcommand <b>add</b> adds new monitor named &lt;name&gt; at &lt;addr&gt;.

       Usage:

          ceph mon add &lt;name&gt; &lt;IPaddr[:port]&gt;

       Subcommand <b>dump</b> dumps formatted monmap (optionally from epoch)

       Usage:

          ceph mon dump {&lt;int[0-]&gt;}

       Subcommand <b>getmap</b> gets monmap.

       Usage:

          ceph mon getmap {&lt;int[0-]&gt;}

       Subcommand <b>enable_stretch_mode</b> enables stretch mode, changing the peering rules and failure  handling  on
       all  pools.  For a given PG to successfully peer and be marked active, <b>min_size</b> replicas will now need to
       be active under all (currently two) CRUSH buckets of type &lt;dividing_bucket&gt;.

       &lt;tiebreaker_mon&gt; is the tiebreaker mon to use if a network split happens.

       &lt;dividing_bucket&gt; is the bucket type across which to stretch.  This will typically be <b>datacenter</b> or other
       CRUSH hierarchy bucket type that denotes physically or logically distant subdivisions.

       &lt;new_crush_rule&gt; will be set as CRUSH rule for all pools.

       Usage:

          ceph mon enable_stretch_mode &lt;tiebreaker_mon&gt; &lt;new_crush_rule&gt; &lt;dividing_bucket&gt;

       Subcommand <b>remove</b> removes monitor named &lt;name&gt;.

       Usage:

          ceph mon remove &lt;name&gt;

       Subcommand <b>stat</b> summarizes monitor status.

       Usage:

          ceph mon stat

   <b>mgr</b>
       Ceph manager daemon configuration and management.

       Subcommand <b>dump</b> dumps the latest MgrMap, which describes the active and standby manager daemons.

       Usage:

          ceph mgr dump

       Subcommand <b>fail</b> will mark a manager daemon as failed, removing it from the manager map.   If  it  is  the
       active manager daemon a standby will take its place.

       Usage:

          ceph mgr fail &lt;name&gt;

       Subcommand <b>module</b> <b>ls</b> will list currently enabled manager modules (plugins).

       Usage:

          ceph mgr module ls

       Subcommand  <b>module</b>  <b>enable</b>  will  enable  a manager module.  Available modules are included in MgrMap and
       visible via <b>mgr</b> <b>dump</b>.

       Usage:

          ceph mgr module enable &lt;module&gt;

       Subcommand <b>module</b> <b>disable</b> will disable an active manager module.

       Usage:

          ceph mgr module disable &lt;module&gt;

       Subcommand <b>metadata</b> will report metadata about all manager daemons or, if the name is specified, a single
       manager daemon.

       Usage:

          ceph mgr metadata [name]

       Subcommand <b>versions</b> will report a count of running daemon versions.

       Usage:

          ceph mgr versions

       Subcommand <b>count-metadata</b> will report a count of any daemon metadata field.

       Usage:

          ceph mgr count-metadata &lt;field&gt;

   <b>osd</b>
       Manage OSD configuration and administration. It uses some additional subcommands.

       Subcommand <b>blocklist</b> manage blocklisted clients. It uses some additional subcommands.

       Subcommand <b>add</b> add &lt;addr&gt; to blocklist (optionally until &lt;expire&gt; seconds from now)

       Usage:

          ceph osd blocklist add &lt;EntityAddr&gt; {&lt;float[0.0-]&gt;}

       Subcommand <b>ls</b> show blocklisted clients

       Usage:

          ceph osd blocklist ls

       Subcommand <b>rm</b> remove &lt;addr&gt; from blocklist

       Usage:

          ceph osd blocklist rm &lt;EntityAddr&gt;

       Subcommand <b>blocked-by</b> prints a histogram of which OSDs are blocking their peers

       Usage:

          ceph osd blocked-by

       Subcommand <b>create</b> creates new osd (with optional UUID and ID).

       This command is DEPRECATED as of the Luminous release, and will be removed in a future release.

       Subcommand <b>new</b> should instead be used.

       Usage:

          ceph osd create {&lt;uuid&gt;} {&lt;id&gt;}

       Subcommand <b>new</b> can be used to create a new OSD or to recreate a previously destroyed OSD with a  specific
       <u>id</u>.  The  new OSD will have the specified <u>uuid</u>, and the command expects a JSON file containing the base64
       cephx key for auth entity <u>client.osd.&lt;id&gt;</u>, as well as optional  base64  cepx  key  for  dm-crypt  lockbox
       access and a dm-crypt key. Specifying a dm-crypt requires specifying the accompanying lockbox cephx key.

       Usage:

          ceph osd new {&lt;uuid&gt;} {&lt;id&gt;} -i {&lt;params.json&gt;}

       The  parameters  JSON  file  is optional but if provided, is expected to maintain a form of the following
       format:

          {
              "cephx_secret": "AQBWtwhZdBO5ExAAIDyjK2Bh16ZXylmzgYYEjg==",
              "crush_device_class": "myclass"
          }

       Or:

          {
              "cephx_secret": "AQBWtwhZdBO5ExAAIDyjK2Bh16ZXylmzgYYEjg==",
              "cephx_lockbox_secret": "AQDNCglZuaeVCRAAYr76PzR1Anh7A0jswkODIQ==",
              "dmcrypt_key": "&lt;dm-crypt key&gt;",
              "crush_device_class": "myclass"
          }

       Or:

          {
              "crush_device_class": "myclass"
          }

       The "crush_device_class" property is optional. If specified, it will set the initial CRUSH  device  class
       for the new OSD.

       Subcommand <b>crush</b> is used for CRUSH management. It uses some additional subcommands.

       Subcommand <b>add</b> adds or updates crushmap position and weight for &lt;name&gt; with &lt;weight&gt; and location &lt;args&gt;.

       Usage:

          ceph osd crush add &lt;osdname (id|osd.id)&gt; &lt;float[0.0-]&gt; &lt;args&gt; [&lt;args&gt;...]

       Subcommand <b>add-bucket</b> adds no-parent (probably root) crush bucket &lt;name&gt; of type &lt;type&gt;.

       Usage:

          ceph osd crush add-bucket &lt;name&gt; &lt;type&gt;

       Subcommand  <b>create-or-move</b>  creates  entry  or  moves  existing  entry for &lt;name&gt; &lt;weight&gt; at/to location
       &lt;args&gt;.

       Usage:

          ceph osd crush create-or-move &lt;osdname (id|osd.id)&gt; &lt;float[0.0-]&gt; &lt;args&gt;
          [&lt;args&gt;...]

       Subcommand <b>dump</b> dumps crush map.

       Usage:

          ceph osd crush dump

       Subcommand <b>get-tunable</b> get crush tunable straw_calc_version

       Usage:

          ceph osd crush get-tunable straw_calc_version

       Subcommand <b>link</b> links existing entry for &lt;name&gt; under location &lt;args&gt;.

       Usage:

          ceph osd crush link &lt;name&gt; &lt;args&gt; [&lt;args&gt;...]

       Subcommand <b>move</b> moves existing entry for &lt;name&gt; to location &lt;args&gt;.

       Usage:

          ceph osd crush move &lt;name&gt; &lt;args&gt; [&lt;args&gt;...]

       Subcommand <b>remove</b> removes &lt;name&gt; from crush map (everywhere, or just at &lt;ancestor&gt;).

       Usage:

          ceph osd crush remove &lt;name&gt; {&lt;ancestor&gt;}

       Subcommand <b>rename-bucket</b> renames bucket &lt;srcname&gt; to &lt;dstname&gt;

       Usage:

          ceph osd crush rename-bucket &lt;srcname&gt; &lt;dstname&gt;

       Subcommand <b>reweight</b> change &lt;name&gt;'s weight to &lt;weight&gt; in crush map.

       Usage:

          ceph osd crush reweight &lt;name&gt; &lt;float[0.0-]&gt;

       Subcommand <b>reweight-all</b> recalculate the weights for the tree to ensure they sum correctly

       Usage:

          ceph osd crush reweight-all

       Subcommand <b>reweight-subtree</b> changes all leaf items beneath &lt;name&gt; to &lt;weight&gt; in crush map

       Usage:

          ceph osd crush reweight-subtree &lt;name&gt; &lt;weight&gt;

       Subcommand <b>rm</b> removes &lt;name&gt; from crush map (everywhere, or just at &lt;ancestor&gt;).

       Usage:

          ceph osd crush rm &lt;name&gt; {&lt;ancestor&gt;}

       Subcommand <b>rule</b> is used for creating crush rules. It uses some additional subcommands.

       Subcommand <b>create-erasure</b> creates crush rule  &lt;name&gt;  for  erasure  coded  pool  created  with  &lt;profile&gt;
       (default default).

       Usage:

          ceph osd crush rule create-erasure &lt;name&gt; {&lt;profile&gt;}

       Subcommand <b>create-simple</b> creates crush rule &lt;name&gt; to start from &lt;root&gt;, replicate across buckets of type
       &lt;type&gt;, using a choose mode of &lt;firstn|indep&gt; (default firstn; indep best for erasure pools).

       Usage:

          ceph osd crush rule create-simple &lt;name&gt; &lt;root&gt; &lt;type&gt; {firstn|indep}

       Subcommand <b>dump</b> dumps crush rule &lt;name&gt; (default all).

       Usage:

          ceph osd crush rule dump {&lt;name&gt;}

       Subcommand <b>ls</b> lists crush rules.

       Usage:

          ceph osd crush rule ls

       Subcommand <b>rm</b> removes crush rule &lt;name&gt;.

       Usage:

          ceph osd crush rule rm &lt;name&gt;

       Subcommand <b>set</b> used alone, sets crush map from input file.

       Usage:

          ceph osd crush set

       Subcommand  <b>set</b>  with  osdname/osd.id  update  crushmap  position  and weight for &lt;name&gt; to &lt;weight&gt; with
       location &lt;args&gt;.

       Usage:

          ceph osd crush set &lt;osdname (id|osd.id)&gt; &lt;float[0.0-]&gt; &lt;args&gt; [&lt;args&gt;...]

       Subcommand <b>set-tunable</b> set crush tunable &lt;tunable&gt; to &lt;value&gt;.  The only  tunable  that  can  be  set  is
       straw_calc_version.

       Usage:

          ceph osd crush set-tunable straw_calc_version &lt;value&gt;

       Subcommand <b>show-tunables</b> shows current crush tunables.

       Usage:

          ceph osd crush show-tunables

       Subcommand <b>tree</b> shows the crush buckets and items in a tree view.

       Usage:

          ceph osd crush tree

       Subcommand <b>tunables</b> sets crush tunables values to &lt;profile&gt;.

       Usage:

          ceph osd crush tunables legacy|argonaut|bobtail|firefly|hammer|optimal|default

       Subcommand <b>unlink</b> unlinks &lt;name&gt; from crush map (everywhere, or just at &lt;ancestor&gt;).

       Usage:

          ceph osd crush unlink &lt;name&gt; {&lt;ancestor&gt;}

       Subcommand <b>df</b> shows OSD utilization

       Usage:

          ceph osd df {plain|tree}

       Subcommand <b>deep-scrub</b> initiates deep scrub on specified osd.

       Usage:

          ceph osd deep-scrub &lt;who&gt;

       Subcommand <b>down</b> sets osd(s) &lt;id&gt; [&lt;id&gt;...] down.

       Usage:

          ceph osd down &lt;ids&gt; [&lt;ids&gt;...]

       Subcommand <b>dump</b> prints summary of OSD map.

       Usage:

          ceph osd dump {&lt;int[0-]&gt;}

       Subcommand  <b>erasure-code-profile</b>  is used for managing the erasure code profiles. It uses some additional
       subcommands.

       Subcommand <b>get</b> gets erasure code profile &lt;name&gt;.

       Usage:

          ceph osd erasure-code-profile get &lt;name&gt;

       Subcommand <b>ls</b> lists all erasure code profiles.

       Usage:

          ceph osd erasure-code-profile ls

       Subcommand <b>rm</b> removes erasure code profile &lt;name&gt;.

       Usage:

          ceph osd erasure-code-profile rm &lt;name&gt;

       Subcommand <b>set</b> creates erasure code profile &lt;name&gt; with [&lt;key[=value]&gt; ...]  pairs. Add a --force at  the
       end to override an existing profile (IT IS RISKY).

       Usage:

          ceph osd erasure-code-profile set &lt;name&gt; {&lt;profile&gt; [&lt;profile&gt;...]}

       Subcommand <b>find</b> find osd &lt;id&gt; in the CRUSH map and shows its location.

       Usage:

          ceph osd find &lt;int[0-]&gt;

       Subcommand <b>getcrushmap</b> gets CRUSH map.

       Usage:

          ceph osd getcrushmap {&lt;int[0-]&gt;}

       Subcommand <b>getmap</b> gets OSD map.

       Usage:

          ceph osd getmap {&lt;int[0-]&gt;}

       Subcommand <b>getmaxosd</b> shows largest OSD id.

       Usage:

          ceph osd getmaxosd

       Subcommand <b>in</b> sets osd(s) &lt;id&gt; [&lt;id&gt;...] in.

       Usage:

          ceph osd in &lt;ids&gt; [&lt;ids&gt;...]

       Subcommand <b>lost</b> marks osd as permanently lost. THIS DESTROYS DATA IF NO MORE REPLICAS EXIST, BE CAREFUL.

       Usage:

          ceph osd lost &lt;int[0-]&gt; {--yes-i-really-mean-it}

       Subcommand <b>ls</b> shows all OSD ids.

       Usage:

          ceph osd ls {&lt;int[0-]&gt;}

       Subcommand <b>lspools</b> lists pools.

       Usage:

          ceph osd lspools {&lt;int&gt;}

       Subcommand <b>map</b> finds pg for &lt;object&gt; in &lt;pool&gt;.

       Usage:

          ceph osd map &lt;poolname&gt; &lt;objectname&gt;

       Subcommand <b>metadata</b> fetches metadata for osd &lt;id&gt;.

       Usage:

          ceph osd metadata {int[0-]} (default all)

       Subcommand <b>out</b> sets osd(s) &lt;id&gt; [&lt;id&gt;...] out.

       Usage:

          ceph osd out &lt;ids&gt; [&lt;ids&gt;...]

       Subcommand  <b>ok-to-stop</b>  checks  whether the list of OSD(s) can be stopped without immediately making data
       unavailable.  That is, all data should remain readable and writeable, although  data  redundancy  may  be
       reduced  as some PGs may end up in a degraded (but active) state.  It will return a success code if it is
       okay to stop the OSD(s), or an error code and informative message if it is not or if no conclusion can be
       drawn at the current time.  When <b>--max</b> <b>&lt;num&gt;</b> is provided, up to &lt;num&gt; OSDs IDs will return (including the
       provided OSDs) that can all be stopped simultaneously.  This allows larger sets of stoppable OSDs  to  be
       generated  easily  by providing a single starting OSD and a max.  Additional OSDs are drawn from adjacent
       locations in the CRUSH hierarchy.

       Usage:

          ceph osd ok-to-stop &lt;id&gt; [&lt;ids&gt;...] [--max &lt;num&gt;]

       Subcommand <b>pause</b> pauses osd.

       Usage:

          ceph osd pause

       Subcommand <b>perf</b> prints dump of OSD perf summary stats.

       Usage:

          ceph osd perf

       Subcommand <b>pg-temp</b> set pg_temp mapping pgid:[&lt;id&gt; [&lt;id&gt;...]] (developers only).

       Usage:

          ceph osd pg-temp &lt;pgid&gt; {&lt;id&gt; [&lt;id&gt;...]}

       Subcommand <b>force-create-pg</b> forces creation of pg &lt;pgid&gt;.

       Usage:

          ceph osd force-create-pg &lt;pgid&gt;

       Subcommand <b>pool</b> is used for managing data pools. It uses some additional subcommands.

       Subcommand <b>create</b> creates pool.

       Usage:

          ceph osd pool create &lt;poolname&gt; {&lt;int[0-]&gt;} {&lt;int[0-]&gt;} {replicated|erasure}
          {&lt;erasure_code_profile&gt;} {&lt;rule&gt;} {&lt;int&gt;} {--autoscale-mode=&lt;on,off,warn&gt;}

       Subcommand <b>delete</b> deletes pool.

       Usage:

          ceph osd pool delete &lt;poolname&gt; {&lt;poolname&gt;} {--yes-i-really-really-mean-it}

       Subcommand <b>get</b> gets pool parameter &lt;var&gt;.

       Usage:

          ceph osd pool get &lt;poolname&gt; size|min_size|pg_num|pgp_num|crush_rule|write_fadvise_dontneed

       Only for tiered pools:

          ceph osd pool get &lt;poolname&gt; hit_set_type|hit_set_period|hit_set_count|hit_set_fpp|
          target_max_objects|target_max_bytes|cache_target_dirty_ratio|cache_target_dirty_high_ratio|
          cache_target_full_ratio|cache_min_flush_age|cache_min_evict_age|
          min_read_recency_for_promote|hit_set_grade_decay_rate|hit_set_search_last_n

       Only for erasure coded pools:

          ceph osd pool get &lt;poolname&gt; erasure_code_profile

       Use <b>all</b> to get all pool parameters that apply to the pool's type:

          ceph osd pool get &lt;poolname&gt; all

       Subcommand <b>get-quota</b> obtains object or byte limits for pool.

       Usage:

          ceph osd pool get-quota &lt;poolname&gt;

       Subcommand <b>ls</b> list pools

       Usage:

          ceph osd pool ls {detail}

       Subcommand <b>mksnap</b> makes snapshot &lt;snap&gt; in &lt;pool&gt;.

       Usage:

          ceph osd pool mksnap &lt;poolname&gt; &lt;snap&gt;

       Subcommand <b>rename</b> renames &lt;srcpool&gt; to &lt;destpool&gt;.

       Usage:

          ceph osd pool rename &lt;poolname&gt; &lt;poolname&gt;

       Subcommand <b>rmsnap</b> removes snapshot &lt;snap&gt; from &lt;pool&gt;.

       Usage:

          ceph osd pool rmsnap &lt;poolname&gt; &lt;snap&gt;

       Subcommand <b>set</b> sets pool parameter &lt;var&gt; to &lt;val&gt;.

       Usage:

          ceph osd pool set &lt;poolname&gt; size|min_size|pg_num|
          pgp_num|crush_rule|hashpspool|nodelete|nopgchange|nosizechange|
          hit_set_type|hit_set_period|hit_set_count|hit_set_fpp|debug_fake_ec_pool|
          target_max_bytes|target_max_objects|cache_target_dirty_ratio|
          cache_target_dirty_high_ratio|
          cache_target_full_ratio|cache_min_flush_age|cache_min_evict_age|
          min_read_recency_for_promote|write_fadvise_dontneed|hit_set_grade_decay_rate|
          hit_set_search_last_n
          &lt;val&gt; {--yes-i-really-mean-it}

       Subcommand <b>set-quota</b> sets object or byte limit on pool.

       Usage:

          ceph osd pool set-quota &lt;poolname&gt; max_objects|max_bytes &lt;val&gt;

       Subcommand <b>stats</b> obtain stats from all pools, or from specified pool.

       Usage:

          ceph osd pool stats {&lt;name&gt;}

       Subcommand <b>application</b> is used for adding an annotation to the  given  pool.  By  default,  the  possible
       applications  are  object,  block,  and  file  storage  (corresponding  app-names  are  "rgw", "rbd", and
       "cephfs"). However, there might be other applications as well. Based on the application, there may or may
       not be some processing conducted.

       Subcommand <b>disable</b> disables the given application on the given pool.

       Usage:

          ceph osd pool application disable &lt;pool-name&gt; &lt;app&gt; {--yes-i-really-mean-it}

       Subcommand <b>enable</b> adds an annotation to the given pool for the mentioned application.

       Usage:

          ceph osd pool application enable &lt;pool-name&gt; &lt;app&gt; {--yes-i-really-mean-it}

       Subcommand <b>get</b> displays the value for the given key that is associated with the given application of  the
       given pool. Not passing the optional arguments would display all key-value pairs for all applications for
       all pools.

       Usage:

          ceph osd pool application get {&lt;pool-name&gt;} {&lt;app&gt;} {&lt;key&gt;}

       Subcommand <b>rm</b> removes the key-value pair for the given key in the given application of the given pool.

       Usage:

          ceph osd pool application rm &lt;pool-name&gt; &lt;app&gt; &lt;key&gt;

       Subcommand  <b>set</b>  associates or updates, if it already exists, a key-value pair with the given application
       for the given pool.

       Usage:

          ceph osd pool application set &lt;pool-name&gt; &lt;app&gt; &lt;key&gt; &lt;value&gt;

       Subcommand <b>primary-affinity</b> adjust osd primary-affinity from 0.0 &lt;=&lt;weight&gt; &lt;= 1.0

       Usage:

          ceph osd primary-affinity &lt;osdname (id|osd.id)&gt; &lt;float[0.0-1.0]&gt;

       Subcommand <b>primary-temp</b> sets primary_temp mapping pgid:&lt;id&gt;|-1 (developers only).

       Usage:

          ceph osd primary-temp &lt;pgid&gt; &lt;id&gt;

       Subcommand <b>repair</b> initiates repair on a specified osd.

       Usage:

          ceph osd repair &lt;who&gt;

       Subcommand <b>reweight</b> reweights osd to 0.0 &lt; &lt;weight&gt; &lt; 1.0.

       Usage:

          osd reweight &lt;int[0-]&gt; &lt;float[0.0-1.0]&gt;

       Subcommand  <b>reweight-by-pg</b>  reweight  OSDs  by  PG  distribution  [overload-percentage-for-consideration,
       default 120].

       Usage:

          ceph osd reweight-by-pg {&lt;int[100-]&gt;} {&lt;poolname&gt; [&lt;poolname...]}
          {--no-increasing}

       Subcommand  <b>reweight-by-utilization</b>  reweights OSDs by utilization.  It only reweights outlier OSDs whose
       utilization exceeds the average, eg. the default 120% limits reweight to those OSDs that  are  more  than
       20%   over   the   average.    [overload-threshold,   default   120   [max_weight_change,   default  0.05
       [max_osds_to_adjust, default 4]]]

       Usage:

          ceph osd reweight-by-utilization {&lt;int[100-]&gt; {&lt;float[0.0-]&gt; {&lt;int[0-]&gt;}}}
          {--no-increasing}

       Subcommand <b>rm</b> removes osd(s) &lt;id&gt; [&lt;id&gt;...] from the OSD map.

       Usage:

          ceph osd rm &lt;ids&gt; [&lt;ids&gt;...]

       Subcommand <b>destroy</b> marks OSD <u>id</u> as <u>destroyed</u>, removing its cephx entity's keys and all  of  its  dm-crypt
       and daemon-private config key entries.

       This  command  will  not remove the OSD from crush, nor will it remove the OSD from the OSD map. Instead,
       once the command successfully completes, the OSD will show marked as <u>destroyed</u>.

       In order to mark an OSD as destroyed, the OSD must first be marked as <b>lost</b>.

       Usage:

          ceph osd destroy &lt;id&gt; {--yes-i-really-mean-it}

       Subcommand <b>purge</b> performs a combination of <b>osd</b> <b>destroy</b>, <b>osd</b> <b>rm</b> and <b>osd</b> <b>crush</b> <b>remove</b>.

       Usage:

          ceph osd purge &lt;id&gt; {--yes-i-really-mean-it}

       Subcommand <b>safe-to-destroy</b> checks whether it is safe to remove or destroy an OSD without reducing overall
       data redundancy or durability.  It will return a success code if it is definitely safe, or an error  code
       and informative message if it is not or if no conclusion can be drawn at the current time.

       Usage:

          ceph osd safe-to-destroy &lt;id&gt; [&lt;ids&gt;...]

       Subcommand <b>scrub</b> initiates scrub on specified osd.

       Usage:

          ceph osd scrub &lt;who&gt;

       Subcommand  <b>set</b> sets cluster-wide &lt;flag&gt; by updating OSD map.  The <b>full</b> flag is not honored anymore since
       the Mimic release, and <b>ceph</b> <b>osd</b> <b>set</b> <b>full</b> is not supported in the Octopus release.

       Usage:

          ceph osd set pause|noup|nodown|noout|noin|nobackfill|
          norebalance|norecover|noscrub|nodeep-scrub|notieragent

       Subcommand <b>setcrushmap</b> sets crush map from input file.

       Usage:

          ceph osd setcrushmap

       Subcommand <b>setmaxosd</b> sets new maximum osd value.

       Usage:

          ceph osd setmaxosd &lt;int[0-]&gt;

       Subcommand <b>set-require-min-compat-client</b>  enforces  the  cluster  to  be  backward  compatible  with  the
       specified  client version. This subcommand prevents you from making any changes (e.g., crush tunables, or
       using new features) that would violate the current setting. Please note, This subcommand will fail if any
       connected daemon or client is not compatible with the features offered by the given &lt;version&gt;. To see the
       features and releases of all clients connected to cluster, please see <u>ceph</u> <u>features</u>.

       Usage:

          ceph osd set-require-min-compat-client &lt;version&gt;

       Subcommand <b>stat</b> prints summary of OSD map.

       Usage:

          ceph osd stat

       Subcommand <b>tier</b> is used for managing tiers. It uses some additional subcommands.

       Subcommand <b>add</b> adds the tier &lt;tierpool&gt; (the second one) to base pool &lt;pool&gt; (the first one).

       Usage:

          ceph osd tier add &lt;poolname&gt; &lt;poolname&gt; {--force-nonempty}

       Subcommand <b>add-cache</b> adds a cache &lt;tierpool&gt; (the second one) of size &lt;size&gt; to existing pool &lt;pool&gt; (the
       first one).

       Usage:

          ceph osd tier add-cache &lt;poolname&gt; &lt;poolname&gt; &lt;int[0-]&gt;

       Subcommand <b>cache-mode</b> specifies the caching mode for cache tier &lt;pool&gt;.

       Usage:

          ceph osd tier cache-mode &lt;poolname&gt; writeback|proxy|readproxy|readonly|none

       Subcommand <b>remove</b> removes the tier &lt;tierpool&gt; (the second one) from base pool &lt;pool&gt; (the first one).

       Usage:

          ceph osd tier remove &lt;poolname&gt; &lt;poolname&gt;

       Subcommand <b>remove-overlay</b> removes the overlay pool for base pool &lt;pool&gt;.

       Usage:

          ceph osd tier remove-overlay &lt;poolname&gt;

       Subcommand <b>set-overlay</b> set the overlay pool for base pool &lt;pool&gt; to be &lt;overlaypool&gt;.

       Usage:

          ceph osd tier set-overlay &lt;poolname&gt; &lt;poolname&gt;

       Subcommand <b>tree</b> prints OSD tree.

       Usage:

          ceph osd tree {&lt;int[0-]&gt;}

       Subcommand <b>unpause</b> unpauses osd.

       Usage:

          ceph osd unpause

       Subcommand <b>unset</b> unsets cluster-wide &lt;flag&gt; by updating OSD map.

       Usage:

          ceph osd unset pause|noup|nodown|noout|noin|nobackfill|
          norebalance|norecover|noscrub|nodeep-scrub|notieragent

   <b>pg</b>
       It is used for managing the placement groups in OSDs. It uses some additional subcommands.

       Subcommand <b>debug</b> shows debug info about pgs.

       Usage:

          ceph pg debug unfound_objects_exist|degraded_pgs_exist

       Subcommand <b>deep-scrub</b> starts deep-scrub on &lt;pgid&gt;.

       Usage:

          ceph pg deep-scrub &lt;pgid&gt;

       Subcommand <b>dump</b> shows human-readable versions of pg map (only 'all' valid with plain).

       Usage:

          ceph pg dump {all|summary|sum|delta|pools|osds|pgs|pgs_brief} [{all|summary|sum|delta|pools|osds|pgs|pgs_brief...]}

       Subcommand <b>dump_json</b> shows human-readable version of pg map in json only.

       Usage:

          ceph pg dump_json {all|summary|sum|delta|pools|osds|pgs|pgs_brief} [{all|summary|sum|delta|pools|osds|pgs|pgs_brief...]}

       Subcommand <b>dump_pools_json</b> shows pg pools info in json only.

       Usage:

          ceph pg dump_pools_json

       Subcommand <b>dump_stuck</b> shows information about stuck pgs.

       Usage:

          ceph pg dump_stuck {inactive|unclean|stale|undersized|degraded [inactive|unclean|stale|undersized|degraded...]}
          {&lt;int&gt;}

       Subcommand <b>getmap</b> gets binary pg map to -o/stdout.

       Usage:

          ceph pg getmap

       Subcommand <b>ls</b> lists pg with specific pool, osd, state

       Usage:

          ceph pg ls {&lt;int&gt;} {&lt;pg-state&gt; [&lt;pg-state&gt;...]}

       Subcommand <b>ls-by-osd</b> lists pg on osd [osd]

       Usage:

          ceph pg ls-by-osd &lt;osdname (id|osd.id)&gt; {&lt;int&gt;}
          {&lt;pg-state&gt; [&lt;pg-state&gt;...]}

       Subcommand <b>ls-by-pool</b> lists pg with pool = [poolname]

       Usage:

          ceph pg ls-by-pool &lt;poolstr&gt; {&lt;int&gt;} {&lt;pg-state&gt; [&lt;pg-state&gt;...]}

       Subcommand <b>ls-by-primary</b> lists pg with primary = [osd]

       Usage:

          ceph pg ls-by-primary &lt;osdname (id|osd.id)&gt; {&lt;int&gt;}
          {&lt;pg-state&gt; [&lt;pg-state&gt;...]}

       Subcommand <b>map</b> shows mapping of pg to osds.

       Usage:

          ceph pg map &lt;pgid&gt;

       Subcommand <b>repair</b> starts repair on &lt;pgid&gt;.

       Usage:

          ceph pg repair &lt;pgid&gt;

       Subcommand <b>scrub</b> starts scrub on &lt;pgid&gt;.

       Usage:

          ceph pg scrub &lt;pgid&gt;

       Subcommand <b>stat</b> shows placement group status.

       Usage:

          ceph pg stat

   <b>quorum</b>
       Cause a specific MON to enter or exit quorum.

       Usage:

          ceph tell mon.&lt;id&gt; quorum enter|exit

   <b>quorum_status</b>
       Reports status of monitor quorum.

       Usage:

          ceph quorum_status

   <b>report</b>
       Reports full status of cluster, optional title tag strings.

       Usage:

          ceph report {&lt;tags&gt; [&lt;tags&gt;...]}

   <b>status</b>
       Shows cluster status.

       Usage:

          ceph status

   <b>tell</b>
       Sends a command to a specific daemon.

       Usage:

          ceph tell &lt;name (type.id)&gt; &lt;command&gt; [options...]

       List all available commands.

       Usage:

          ceph tell &lt;name (type.id)&gt; help

   <b>version</b>
       Show mon daemon version

       Usage:

          ceph version

</pre><h4><b>OPTIONS</b></h4><pre>
       <b>-i</b> <b>infile,</b> <b>--in-file=infile</b>
              will specify an input file to be passed along as  a  payload  with  the  command  to  the  monitor
              cluster. This is only used for specific monitor commands.

       <b>-o</b> <b>outfile,</b> <b>--out-file=outfile</b>
              will  write  any payload returned by the monitor cluster with its reply to outfile.  Only specific
              monitor commands (e.g. osd getmap) return a payload.

       <b>--setuser</b> <b>user</b>
              will apply the appropriate user ownership to the file specified by the option '-o'.

       <b>--setgroup</b> <b>group</b>
              will apply the appropriate group ownership to the file specified by the option '-o'.

       <b>-c</b> <b>ceph.conf,</b> <b>--conf=ceph.conf</b>
              Use ceph.conf configuration file instead of the default <b>/etc/ceph/ceph.conf</b> to  determine  monitor
              addresses during startup.

       <b>--id</b> <b>CLIENT_ID,</b> <b>--user</b> <b>CLIENT_ID</b>
              Client id for authentication.

       <b>--name</b> <b>CLIENT_NAME,</b> <b>-n</b> <b>CLIENT_NAME</b>
              Client name for authentication.

       <b>--cluster</b> <b>CLUSTER</b>
              Name of the Ceph cluster.

       <b>--admin-daemon</b> <b>ADMIN_SOCKET,</b> <b>daemon</b> <b>DAEMON_NAME</b>
              Submit admin-socket commands via admin sockets in /var/run/ceph.

       <b>--admin-socket</b> <b>ADMIN_SOCKET_NOPE</b>
              You probably mean --admin-daemon

       <b>-s,</b> <b>--status</b>
              Show cluster status.

       <b>-w,</b> <b>--watch</b>
              Watch live cluster changes on the default 'cluster' channel

       <b>-W,</b> <b>--watch-channel</b>
              Watch live cluster changes on any channel (cluster, audit, cephadm, or * for all)

       <b>--watch-debug</b>
              Watch debug events.

       <b>--watch-info</b>
              Watch info events.

       <b>--watch-sec</b>
              Watch security events.

       <b>--watch-warn</b>
              Watch warning events.

       <b>--watch-error</b>
              Watch error events.

       <b>--version,</b> <b>-v</b>
              Display version.

       <b>--verbose</b>
              Make verbose.

       <b>--concise</b>
              Make less verbose.

       <b>-f</b> <b>{json,json-pretty,xml,xml-pretty,plain,yaml},</b> <b>--format</b>
              Format of output. Note: yaml is only valid for orch commands.

       <b>--connect-timeout</b> <b>CLUSTER_TIMEOUT</b>
              Set a timeout for connecting to the cluster.

       <b>--no-increasing</b>
              <b>--no-increasing</b>   is  off  by  default.  So  increasing  the  osd  weight  is  allowed  using  the
              <b>reweight-by-utilization</b> or <b>test-reweight-by-utilization</b> commands.  If this  option  is  used  with
              these commands, it will help not to increase osd weight even the osd is under utilized.

       <b>--block</b>
              block until completion (scrub and deep-scrub only)

</pre><h4><b>AVAILABILITY</b></h4><pre>
       <b>ceph</b>  is part of Ceph, a massively scalable, open-source, distributed storage system. Please refer to the
       Ceph documentation at <u>https://docs.ceph.com</u> for more information.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <u><a href="../man8/ceph-mon.8.html">ceph-mon</a></u>(8), <u><a href="../man8/ceph-osd.8.html">ceph-osd</a></u>(8), <u><a href="../man8/ceph-mds.8.html">ceph-mds</a></u>(8)

</pre><h4><b>COPYRIGHT</b></h4><pre>
       2010-2014, Inktank Storage, Inc. and contributors. Licensed  under  Creative  Commons  Attribution  Share
       Alike 3.0 (CC-BY-SA-3.0)

dev                                               May 22, 2025                                           <u><a href="../man8/CEPH.8.html">CEPH</a></u>(8)
</pre>
 </div>
</div></section>
</div>
</body>
</html>