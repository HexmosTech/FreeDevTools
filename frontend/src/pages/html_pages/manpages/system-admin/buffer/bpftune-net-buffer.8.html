<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BPFTUNE-NET-BUFFER - Networking buffer bpftune plugin for managing net core buffers</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/bpftune">bpftune_0.0~git20250314.8fd59cc-1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       BPFTUNE-NET-BUFFER - Networking buffer bpftune plugin for managing net core buffers

</pre><h4><b>DESCRIPTION</b></h4><pre>
          A   backlog   queue   is   used   to   buffer  incoming  traffic  and  its  length  is  controlled  by
          net.core.netdev_max_backlog.  On fast connections (10Gb/s or higher) the  default  backlog  length  of
          1024  can be insufficient; here the backlog length is increased if 1/16 of current backlog size in the
          last minute is dropped (drops occur when the backlog limit is reached).  In  addition,  backlog  drops
          can avoid small flows; the tunable net.core.flow_limit_cpu_bitmap can be used to set this on a per-cpu
          basis;  when  we  see  sufficient  drops  on  a  CPU, the appropriate bit is set in the CPU bitmask to
          prioritize small flows for drop avoidance.

          When NAPI polls to handle multiple packets, the number of packets is limited by net.core.netdev_budget
          while the time is limited by net.core.netdev_budget_usecs.  If we hit the limit of number  of  packets
          processed without using the usecs budget the time_squeezed softnet stat is bumped; if we see increases
          in time_squeezed, bump netdev_budget/netdev_budget_usecs.

          However,  we  want  to  limit  such increases if they lead to longer task scheduling wait times, so we
          monitor the ratio of time tasks spend waiting versus running across all  processors,  and  if  we  see
          correlations  between  increases in netdev budget and wait/run ratio increases, netdev budget is tuned
          down.

          Tunables:

          • net.core.netdev_max_backlog: maximum per-cpu backlog queue length; default 1024.

          • net.core.flow_limit_cpu_bitmap: avoid drops for small flows on a per-cpu basis; default 0.

          • net.core.netdev_budget: maximum number of packets processed in a NAPI cycle

          • net.core.netdev_budget_usecs: maximum amount of time in microseconds for a NAPI cycle

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
          <b><a href="../man2/bpf.2.html">bpf</a></b>(2), <b><a href="../man8/bpftune.8.html">bpftune</a></b>(8),

                                                                                           <u><a href="../man8/BPFTUNE-NET-BUFFER.8.html">BPFTUNE-NET-BUFFER</a></u>(8)
</pre>
 </div>
</div></section>
</div>
</body>
</html>