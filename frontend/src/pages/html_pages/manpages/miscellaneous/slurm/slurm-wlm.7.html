<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Slurm - Slurm Workload Manager overview.</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/slurm-client">slurm-client_24.11.5-4_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       Slurm - Slurm Workload Manager overview.

</pre><h4><b>DESCRIPTION</b></h4><pre>
       The  Slurm Workload Manager is an open source, fault-tolerant, and highly scalable cluster management and
       job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for  its
       operation and is relatively self-contained. As a cluster resource manager, Slurm has three key functions.
       First,  it allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some
       duration of time so they can perform work. Second, it provides a framework for starting,  executing,  and
       monitoring  work  (normally  a  parallel  job)  on  the  set  of allocated nodes.  Finally, it arbitrates
       contention for resources by managing a  queue  of  pending  work.   Optional  plugins  can  be  used  for
       accounting,  advanced reservation, gang scheduling (time sharing for parallel jobs), backfill scheduling,
       resource limits by user or bank account, and sophisticated multifactor job prioritization algorithms.

       Slurm has a centralized manager, <b>slurmctld</b>, to monitor resources and work. There may  also  be  a  backup
       manager to assume those responsibilities in the event of failure. Each compute server (node) has a <b>slurmd</b>
       daemon,  which  can be compared to a remote shell: it waits for work, executes that work, returns status,
       and waits for more work. An optional <b>slurmdbd</b> (Slurm DataBase Daemon) can be used for accounting purposes
       and to maintain resource limit information.

       Basic user tools include <b>srun</b> to initiate jobs, <b>scancel</b> to terminate queued or  running  jobs,  <b>sinfo</b>  to
       report  system  status,  and  <b>squeue</b>  to  report the status of jobs. There is also an administrative tool
       <b>scontrol</b> available to monitor and/or modify configuration and state information. APIs are  available  for
       all functions.

       Slurm configuration is maintained in the <b>slurm.conf</b> file.

       Man  pages  are  available  for  all  Slurm commands, daemons, APIs, plus the <b>slurm.conf</b> file.  Extensive
       documentation is also available on the internet at <b>&lt;https://slurm.schedmd.com/&gt;</b>.

</pre><h4><b>COPYING</b></h4><pre>
       Copyright (C) 2005-2007 The Regents of the University of  California.   Produced  at  Lawrence  Livermore
       National Laboratory (cf, DISCLAIMER).
       Copyright (C) 2008-2009 Lawrence Livermore National Security.
       Copyright (C) 2010-2022 SchedMD LLC.

       This    file    is    part    of    Slurm,   a   resource   management   program.    For   details,   see
       &lt;https://slurm.schedmd.com/&gt;.

       Slurm is free software; you can redistribute it and/or modify it under  the  terms  of  the  GNU  General
       Public License as published by the Free Software Foundation; either version 2 of the License, or (at your
       option) any later version.

       Slurm  is  distributed  in  the  hope  that it will be useful, but WITHOUT ANY WARRANTY; without even the
       implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR  PURPOSE.  See  the  GNU  General  Public
       License for more details.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man1/sacct.1.html">sacct</a></b>(1),  <b><a href="../man1/sacctmgr.1.html">sacctmgr</a></b>(1),  <b><a href="../man1/salloc.1.html">salloc</a></b>(1),  <b><a href="../man1/sattach.1.html">sattach</a></b>(1), <b><a href="../man1/sbatch.1.html">sbatch</a></b>(1), <b><a href="../man1/sbcast.1.html">sbcast</a></b>(1), <b><a href="../man1/scancel.1.html">scancel</a></b>(1), <b><a href="../man1/scontrol.1.html">scontrol</a></b>(1), <b><a href="../man1/sinfo.1.html">sinfo</a></b>(1),
       <b><a href="../man1/squeue.1.html">squeue</a></b>(1),   <b><a href="../man1/sreport.1.html">sreport</a></b>(1),   <b><a href="../man1/srun.1.html">srun</a></b>(1),   <b><a href="../man1/sshare.1.html">sshare</a></b>(1),   <b><a href="../man1/sstat.1.html">sstat</a></b>(1),   <b><a href="../man1/strigger.1.html">strigger</a></b>(1),   <b><a href="../man1/sview.1.html">sview</a></b>(1),    <b><a href="../man5/slurm.conf.5.html">slurm.conf</a></b>(5),
       <b><a href="../man5/slurmdbd.conf.5.html">slurmdbd.conf</a></b>(5), <b><a href="../man8/slurmctld.8.html">slurmctld</a></b>(8), <b><a href="../man8/slurmd.8.html">slurmd</a></b>(8), <b><a href="../man8/slurmdbd.8.html">slurmdbd</a></b>(8), <b><a href="../man8/slurmstepd.8.html">slurmstepd</a></b>(8), <b><a href="../man7/spank.7.html">spank</a></b>(7)

June 2018                                         Slurm System                                          <u><a href="../man7/Slurm.7.html">Slurm</a></u>(7)
</pre>
 </div>
</div></section>
</div>
</body>
</html>