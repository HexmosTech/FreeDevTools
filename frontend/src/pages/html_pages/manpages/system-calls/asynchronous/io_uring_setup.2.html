<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>io_uring_setup - setup a context for performing asynchronous I/O</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/liburing-dev">liburing-dev_2.11-1_amd64</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       io_uring_setup - setup a context for performing asynchronous I/O

</pre><h4><b>SYNOPSIS</b></h4><pre>
       <b>#include</b> <b>&lt;liburing.h&gt;</b>

       <b>int</b> <b>io_uring_setup(u32</b> <u>entries</u><b>,</b> <b>struct</b> <b>io_uring_params</b> <b>*</b><u>params</u><b>);</b>

</pre><h4><b>DESCRIPTION</b></h4><pre>
       The <b><a href="../man2/io_uring_setup.2.html">io_uring_setup</a></b>(2) system call sets up a submission queue (SQ) and completion queue (CQ) with at least
       <u>entries</u>  entries, and returns a file descriptor which can be used to perform subsequent operations on the
       io_uring instance. The submission and completion queues are shared  between  userspace  and  the  kernel,
       which eliminates the need to copy data when initiating and completing I/O.

       <u>params</u>  is used by the application to pass options to the kernel, and by the kernel to convey information
       about the ring buffers.

           struct io_uring_params {
               __u32 sq_entries;
               __u32 cq_entries;
               __u32 flags;
               __u32 sq_thread_cpu;
               __u32 sq_thread_idle;
               __u32 features;
               __u32 wq_fd;
               __u32 resv[3];
               struct io_sqring_offsets sq_off;
               struct io_cqring_offsets cq_off;
           };

       The <u>flags</u>, <u>sq_thread_cpu</u>, and <u>sq_thread_idle</u> fields are used to configure the io_uring  instance.   <u>flags</u>
       is a bit mask of 0 or more of the following values ORed together:

       <b>IORING_SETUP_IOPOLL</b>
              Perform  busy-waiting  for  an  I/O  completion,  as  opposed  to  getting  notifications  via  an
              asynchronous IRQ (Interrupt Request). The file system (if  any)  and  block  device  must  support
              polling  in  order for this to work. Busy-waiting provides lower latency, but may consume more CPU
              resources than interrupt driven I/O. Currently, this feature is usable only on a  file  descriptor
              opened  using  the  <b>O_DIRECT</b>  flag.  When  a  read  or write is submitted to a polled context, the
              application must poll for completions on the CQ ring by calling <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2).  It is  illegal
              to mix and match polled and non-polled I/O on an io_uring instance.

              This is only applicable for storage devices for now, and the storage device must be configured for
              polling.  How to do that depends on the device type in question. For NVMe devices, the nvme driver
              must be loaded with the <u>poll_queues</u> parameter set to the desired number  of  polling  queues.  The
              polling  queues will be shared appropriately between the CPUs in the system, if the number is less
              than the number of online CPU threads.

       <b>IORING_SETUP_HYBRID_IOPOLL</b>
              This flag must be used with <b>IORING_SETUP_IOPOLL</b> flag. Hybrid io polling  is  a  feature  based  on
              iopoll,  it  differs  from strict polling in that it will delay a bit before doing completion side
              polling, to avoid wasting too much CPU resources. Like <b>IOPOLL</b> , it requires that  devices  support
              polling.

       <b>IORING_SETUP_SQPOLL</b>
              When  this  flag  is specified, a kernel thread is created to perform submission queue polling. An
              io_uring instance configured in this way enables an application to issue I/O without ever  context
              switching  into  the kernel. By using the submission queue to fill in new submission queue entries
              and watching for completions on the completion queue, the application can  submit  and  reap  I/Os
              without doing a single system call.

              If  the  kernel  thread  is  idle  for  more  than  <u>sq_thread_idle</u>  milliseconds,  it will set the
              <b>IORING_SQ_NEED_WAKEUP</b> bit in the <u>flags</u> field of the <u>struct</u> <u>io_sq_ring</u>.   When  this  happens,  the
              application must call <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) to wake the kernel thread. If I/O is kept busy, the kernel
              thread  will  never  sleep.  An  application  making  use  of  this feature will need to guard the
              <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) call with the following code sequence:

                  /*
                   * Ensure that the wakeup flag is read after the tail pointer
                   * has been written. It's important to use memory load acquire
                   * semantics for the flags read, as otherwise the application
                   * and the kernel might not agree on the consistency of the
                   * wakeup flag.
                   */
                  unsigned flags = atomic_load_relaxed(sq_ring-&gt;flags);
                  if (flags &amp; IORING_SQ_NEED_WAKEUP)
                      io_uring_enter(fd, 0, 0, IORING_ENTER_SQ_WAKEUP);

              where <u>sq_ring</u> is a submission queue ring setup using the <u>struct</u> <u>io_sqring_offsets</u> described below.

       Note that, when using a ring setup with
              <b>IORING_SETUP_SQPOLL</b>, you never directly call the <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) system call.  That  is  usually
              taken  care  of  by liburing's <b><a href="../man3/io_uring_submit.3.html">io_uring_submit</a></b>(3) function. It automatically determines if you are
              using polling mode or not and deals with when your program needs to call <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) without
              you having to bother about it.

       Note that while this may sound immediately appealing
              as an automatic "go faster" flag, evaluations should be done on a case-by-case basis to  check  if
              it makes sense for the application.

       Before version 5.11 of the Linux kernel, to successfully use this feature, the
              application  must register a set of files to be used for IO through <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2) using the
              <b>IORING_REGISTER_FILES</b> opcode. Failure to do so will result in  submitted  IO  being  errored  with
              <b>EBADF</b>.   The  presence  of this feature can be detected by the <b>IORING_FEAT_SQPOLL_NONFIXED</b> feature
              flag.  In version 5.11 and later, it is no longer necessary to register files to use this feature.
              5.11 also allows using this as non-root, if the user has the <b>CAP_SYS_NICE</b> capability. In 5.13 this
              requirement was also relaxed, and no special privileges are needed for SQPOLL  in  newer  kernels.
              Certain stable kernels older than 5.13 may also support unprivileged SQPOLL.

       <b>IORING_SETUP_SQ_AFF</b>
              If  this flag is specified, then the poll thread will be bound to the cpu set in the <u>sq_thread_cpu</u>
              field of the <u>struct</u> <u>io_uring_params</u>.  This flag is only  meaningful  when  <b>IORING_SETUP_SQPOLL</b>  is
              specified.  When  cgroup  setting  <u>cpuset.cpus</u>  changes  (typically in container environment), the
              bounded cpu set may be changed as well.

       <b>IORING_SETUP_CQSIZE</b>
              Create the completion queue with <u>struct</u> <u>io_uring_params.cq_entries</u>  entries.  The  value  must  be
              greater than <u>entries</u>, and may be rounded up to the next power-of-two.

       <b>IORING_SETUP_CLAMP</b>
              If this flag is specified, and if <u>entries</u> exceeds <b>IORING_MAX_ENTRIES</b>, then <u>entries</u> will be clamped
              at  <b>IORING_MAX_ENTRIES</b>.   If  the  flag  <b>IORING_SETUP_CQSIZE</b>  is  set,  and if the value of <u>struct</u>
              <u>io_uring_params.cq_entries</u>  exceeds  <b>IORING_MAX_CQ_ENTRIES</b>,   then   it   will   be   clamped   at
              <b>IORING_MAX_CQ_ENTRIES</b>.

       <b>IORING_SETUP_ATTACH_WQ</b>
              This  flag should be set in conjunction with <u>struct</u> <u>io_uring_params.wq_fd</u> being set to an existing
              io_uring ring file descriptor. When set, the  io_uring  instance  being  created  will  share  the
              asynchronous  worker  thread  backend  of  the  specified  io_uring ring, rather than create a new
              separate thread pool. Additionally the sq polling thread will be shared, if <b>IORING_SETUP_SQPOLL</b> is
              set.

       <b>IORING_SETUP_R_DISABLED</b>
              If this flag is specified, the  io_uring  ring  starts  in  a  disabled  state.   In  this  state,
              restrictions  can  be  registered,  but submissions are not allowed.  See <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2) for
              details on how to enable the ring. Available since 5.10.

       <b>IORING_SETUP_SUBMIT_ALL</b>
              Normally io_uring stops submitting a batch of requests, if one of these  requests  results  in  an
              error.  This  can cause submission of less than what is expected, if a request ends in error while
              being submitted. If the ring is created with this flag, <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) will continue submitting
              requests even if it encounters an error submitting a request. CQEs are still  posted  for  errored
              request  regardless  of whether or not this flag is set at ring creation time, the only difference
              is if the submit sequence is halted or continued when an error is observed. Available since 5.18.

       <b>IORING_SETUP_COOP_TASKRUN</b>
              By default, io_uring will interrupt a task running in userspace when a completion event comes  in.
              This  is  to  ensure  that  completions  run  in  a timely manner. For a lot of use cases, this is
              overkill and can cause reduced performance from both the  inter-processor  interrupt  used  to  do
              this, the kernel/user transition, the needless interruption of the tasks userspace activities, and
              reduced batching if completions come in at a rapid rate. Most applications don't need the forceful
              interruption,  as the events are processed at any kernel/user transition. The exception are setups
              where the application uses multiple threads operating on the  same  ring,  where  the  application
              waiting  on  completions isn't the one that submitted them. For most other use cases, setting this
              flag will improve performance. Available since 5.19.

       <b>IORING_SETUP_TASKRUN_FLAG</b>
              Used in conjunction with <b>IORING_SETUP_COOP_TASKRUN</b>, this provides a flag, <b>IORING_SQ_TASKRUN</b>, which
              is set in the SQ ring <u>flags</u> whenever completions are pending that should  be  processed.  liburing
              will  check  for  this  flag  even when doing <b><a href="../man3/io_uring_peek_cqe.3.html">io_uring_peek_cqe</a></b>(3) and enter the kernel to process
              them, and applications can do the same. This makes <b>IORING_SETUP_TASKRUN_FLAG</b> safe to use even when
              applications rely on a peek style operation on the CQ ring to see if anything might be pending  to
              reap. Available since 5.19.

       <b>IORING_SETUP_SQE128</b>
              If  set,  io_uring  will use 128-byte SQEs rather than the normal 64-byte sized variant. This is a
              requirement for using certain request types, as of 5.19 only the  <b>IORING_OP_URING_CMD</b>  passthrough
              command for NVMe passthrough needs this. Available since 5.19.

       <b>IORING_SETUP_CQE32</b>
              If  set,  io_uring  will  use 32-byte CQEs rather than the normal 16-byte sized variant. This is a
              requirement for using certain request types, as of 5.19 only the  <b>IORING_OP_URING_CMD</b>  passthrough
              command for NVMe passthrough needs this. Available since 5.19.

       <b>IORING_SETUP_SINGLE_ISSUER</b>
              A  hint  to the kernel that only a single task (or thread) will submit requests, which is used for
              internal optimisations. The submission task is either the  task  that  created  the  ring,  or  if
              <b>IORING_SETUP_R_DISABLED</b>  is  specified  then  it  is  the  task  that  enables  the  ring  through
              <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2)<b>.</b>  The kernel enforces  this  rule,  failing  requests  with  <b>-EEXIST</b>  if  the
              restriction  is  violated.   Note  that  when <b>IORING_SETUP_SQPOLL</b> is set it is considered that the
              polling task is doing all submissions on behalf of the userspace and so it  always  complies  with
              the rule disregarding how many userspace tasks do <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2).  Available since 6.0.

       <b>IORING_SETUP_DEFER_TASKRUN</b>
              By  default,  io_uring  will  process all outstanding work at the end of any system call or thread
              interrupt. This can delay the application from making other progress.  Setting this flag will hint
              to  io_uring  that  it  should   defer   work   until   an   <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2)   call   with   the
              <b>IORING_ENTER_GETEVENTS</b> flag set. This allows the application to request work to run just before it
              wants  to  process completions.  This flag requires the <b>IORING_SETUP_SINGLE_ISSUER</b> flag to be set,
              and also enforces that the call to <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) is called from the same thread that submitted
              requests.  Note that if  this  flag  is  set  then  it  is  the  application's  responsibility  to
              periodically  trigger  work (for example via any of the CQE waiting functions) or else completions
              may not be delivered.  Available since 6.1.

       <b>IORING_SETUP_NO_MMAP</b>
              By default, io_uring allocates kernel memory that callers must subsequently <b><a href="../man2/mmap.2.html">mmap</a></b>(2).  If this flag
              is set, io_uring instead uses caller-allocated buffers;  <u>p-&gt;cq_off.user_addr</u>  must  point  to  the
              memory  for  the sq/cq rings, and <u>p-&gt;sq_off.user_addr</u> must point to the memory for the sqes.  Each
              allocation must be contiguous memory.  Typically, callers should allocate  this  memory  by  using
              <b><a href="../man2/mmap.2.html">mmap</a></b>(2)  to  allocate  a  huge  page.   If  this  flag is set, a subsequent attempt to <b><a href="../man2/mmap.2.html">mmap</a></b>(2) the
              io_uring file descriptor will fail.  Available since 6.5.

       <b>IORING_SETUP_REGISTERED_FD_ONLY</b>
              If this flag is set, io_uring will register the ring file descriptor, and  return  the  registered
              descriptor index, without ever allocating an unregistered file descriptor. The caller will need to
              use  <b>IORING_REGISTER_USE_REGISTERED_RING</b>  when calling <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2).  This flag only makes
              sense when used alongside with <b>IORING_SETUP_NO_MMAP</b>, which also needs to be set.  Available  since
              6.5.

       <b>IORING_SETUP_NO_SQARRAY</b>
              If  this  flag is set, entries in the submission queue will be submitted in order, wrapping around
              to the first entry after reaching the end of the queue. In other words,  there  will  be  no  more
              indirection  via  the  array  of submission entries, and the queue will be indexed directly by the
              submission queue tail and the range of indexed represented by it modulo queue size.  Subsequently,
              the  user  should  not  map the array of submission queue entries, and the corresponding offset in
              <u>struct</u> <u>io_sqring_offsets</u> will be set to zero. Available since 6.6.

       If no flags are specified, the io_uring instance is setup for interrupt driven I/O. I/O may be  submitted
       using <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) and can be reaped by polling the completion queue.

       The <u>resv</u> array must be initialized to zero.

       <u>features</u>  is  filled  in  by  the  kernel,  which  specifies various features supported by current kernel
       version.

       <b>IORING_FEAT_SINGLE_MMAP</b>
              If this flag is set, the two SQ and CQ rings can be mapped with a single <b><a href="../man2/mmap.2.html">mmap</a></b>(2)  call.  The  SQEs
              must  still  be  allocated  separately. This brings the necessary <b><a href="../man2/mmap.2.html">mmap</a></b>(2) calls down from three to
              two. Available since kernel 5.4.

       <b>IORING_FEAT_NODROP</b>
              If this flag is set, io_uring supports almost never dropping completion events.  A  dropped  event
              can only occur if the kernel runs out of memory, in which case you have worse problems than a lost
              event. Your application and others will likely get OOM killed anyway. If a completion event occurs
              and the CQ ring is full, the kernel stores the event internally until such a time that the CQ ring
              has  room  for more entries. In earlier kernels, if this overflow condition is entered, attempting
              to submit more IO would fail with the <b>-EBUSY</b> error value, if it can't flush the  overflown  events
              to the CQ ring. If this happens, the application must reap events from the CQ ring and attempt the
              submit again. If the kernel has no free memory to store the event internally it will be visible by
              an  increase  in  the  overflow  value  on  the  cqring.  Available since kernel 5.5. Additionally
              <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) will  return  <b>-EBADR</b>  the  next  time  it  would  otherwise  sleep  waiting  for
              completions (since kernel 5.19).

       <b>IORING_FEAT_SUBMIT_STABLE</b>
              If this flag is set, applications can be certain that any data for async offload has been consumed
              when the kernel has consumed the SQE. Available since kernel 5.5.

       <b>IORING_FEAT_RW_CUR_POS</b>
              If  this  flag  is  set,  applications  can  specify  <u>offset</u>  == <b>-1</b> with <b>IORING_OP_{READV,WRITEV}</b>,
              <b>IORING_OP_{READ,WRITE}_FIXED</b>, and <b>IORING_OP_{READ,WRITE}</b> to  mean  current  file  position,  which
              behaves  like  <b><a href="../man2/preadv2.2.html">preadv2</a></b>(2)  and  <b><a href="../man2/pwritev2.2.html">pwritev2</a></b>(2) with <u>offset</u> == <b>-1</b>.  It'll use (and update) the current
              file position. This obviously comes with the caveat that if the application has multiple reads  or
              writes  in flight, then the end result will not be as expected. This is similar to threads sharing
              a file descriptor and doing IO using the current file position. Available since kernel 5.6.

       <b>IORING_FEAT_CUR_PERSONALITY</b>
              If this flag is set, then io_uring guarantees that both sync and  async  execution  of  a  request
              assumes  the  credentials of the task that called <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) to queue the requests. If this
              flag isn't set, then requests are  issued  with  the  credentials  of  the  task  that  originally
              registered  the  io_uring.  If only one task is using a ring, then this flag doesn't matter as the
              credentials will always be the same. Note that this is  the  default  behavior,  tasks  can  still
              register different personalities through <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2) with <b>IORING_REGISTER_PERSONALITY</b> and
              specify the personality to use in the sqe. Available since kernel 5.6.

       <b>IORING_FEAT_FAST_POLL</b>
              If  this  flag is set, then io_uring supports using an internal poll mechanism to drive data/space
              readiness. This means that requests that cannot read or write data to a file no longer need to  be
              punted  to an async thread for handling, instead they will begin operation when the file is ready.
              This is similar to doing poll + read/write in userspace, but eliminates the need to do so. If this
              flag is set, requests waiting on space/data consume a lot less resources doing so as they are  not
              blocking a thread. Available since kernel 5.7.

       <b>IORING_FEAT_POLL_32BITS</b>
              If  this  flag is set, the <b>IORING_OP_POLL_ADD</b> command accepts the full 32-bit range of epoll based
              flags. Most notably <b>EPOLLEXCLUSIVE</b>  which  allows  exclusive  (waking  single  waiters)  behavior.
              Available since kernel 5.9.

       <b>IORING_FEAT_SQPOLL_NONFIXED</b>
              If  this  flag  is set, the <b>IORING_SETUP_SQPOLL</b> feature no longer requires the use of fixed files.
              Any normal file descriptor can be used for IO commands  without  needing  registration.  Available
              since kernel 5.11.

       <b>IORING_FEAT_EXT_ARG</b>
              If  this  flag  is  set,  then  the  <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) system call supports passing in an extended
              argument instead of just the <u>sigset_t</u> of earlier kernels. This.   extended  argument  is  of  type
              <u>struct</u>  <u>io_uring_getevents_arg</u>  and  allows  the  caller  to pass in both a <u>sigset_t</u> and a timeout
              argument for waiting on events. The struct layout is as follows:

               struct io_uring_getevents_arg {
                  __u64 sigmask;
                  __u32 sigmask_sz;
                  __u32 pad;
                  __u64 ts;
              };

              and a pointer to this struct must be passed in if <b>IORING_ENTER_EXT_ARG</b> is set in the flags for the
              enter system call. Available since kernel 5.11.

       <b>IORING_FEAT_NATIVE_WORKERS</b>
              If this flag is set, io_uring is using native workers for its  async  helpers.   Previous  kernels
              used  kernel  threads  that  assumed  the identity of the original io_uring owning task, but later
              kernels will actively create what looks more like regular process threads instead. Available since
              kernel 5.12.

       <b>IORING_FEAT_RSRC_TAGS</b>
              If this flag is set, then io_uring supports a variety of  features  related  to  fixed  files  and
              buffers.  In  particular,  it  indicates  that registered buffers can be updated in-place, whereas
              before the full set would have to be unregistered first. Available since kernel 5.13.

       <b>IORING_FEAT_CQE_SKIP</b>
              If this flag is set, then io_uring supports setting <b>IOSQE_CQE_SKIP_SUCCESS</b> in the  submitted  SQE,
              indicating  that  no  CQE  should  be  generated for this SQE if it executes normally. If an error
              happens processing the SQE, a CQE with the  appropriate  error  value  will  still  be  generated.
              Available since kernel 5.17.

       <b>IORING_FEAT_LINKED_FILE</b>
              If  this  flag  is  set,  then  io_uring  supports  sane  assignment  of  files for SQEs that have
              dependencies. For example, if a chain of SQEs  are  submitted  with  <b>IOSQE_IO_LINK</b>,  then  kernels
              without  this  flag  will prepare the file for each link upfront.  If a previous link opens a file
              with a known index, eg if direct descriptors are used with open or accept,  then  file  assignment
              needs  to  happen post execution of that SQE. If this flag is set, then the kernel will defer file
              assignment until execution of a given request is started. Available since kernel 5.17.

       <b>IORING_FEAT_REG_REG_RING</b>
              If this flag is set, then io_uring supports calling <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2) using a  registered  ring
              fd, via <b>IORING_REGISTER_USE_REGISTERED_RING</b>.  Available since kernel 6.3.

       <b>IORING_FEAT_MIN_TIMEOUT</b>
              If  this  flag  is  set,  then  io_uring  supports  passing  in  a minimum batch wait timeout. See
              <b><a href="../man3/io_uring_submit_and_wait_min_timeout.3.html">io_uring_submit_and_wait_min_timeout</a></b>(3) for more details.

       <b>IORING_FEAT_RECVSEND_BUNDLE</b>
              If  this  flag  is  set,  then  io_uring  supports  bundled  send  and   recv   operations.    See
              <b><a href="../man3/io_uring_prep_send_bundle.3.html">io_uring_prep_send_bundle</a></b>(3)  for  more  information. Also implies support for provided buffers in
              send operations.

       The rest of the fields in the <u>struct</u> <u>io_uring_params</u> are  filled  in  by  the  kernel,  and  provide  the
       information  necessary  to memory map the submission queue, completion queue, and the array of submission
       queue entries.  <u>sq_entries</u> specifies the number of submission queue entries allocated.  <u>sq_off</u>  describes
       the offsets of various ring buffer fields:

           struct io_sqring_offsets {
               __u32 head;
               __u32 tail;
               __u32 ring_mask;
               __u32 ring_entries;
               __u32 flags;
               __u32 dropped;
               __u32 array;
               __u32 resv1;
               __u64 user_addr;
           };

       Taken  together,  <u>sq_entries</u>  and  <u>sq_off</u>  provide  all  of  the  information necessary for accessing the
       submission queue ring buffer and the submission queue entry array. The submission  queue  can  be  mapped
       with a call like:

           ptr = mmap(0, sq_off.array + sq_entries * sizeof(__u32),
                      PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE,
                      ring_fd, IORING_OFF_SQ_RING);

       where  <u>sq_off</u>  is  the  <u>io_sqring_offsets</u>  structure,  and  <u>ring_fd</u>  is the file descriptor returned from
       <b><a href="../man2/io_uring_setup.2.html">io_uring_setup</a></b>(2).  The addition of <u>sq_off.array</u> to the length of the region accounts for the  fact  that
       the  ring is located at the end of the data structure. As an example, the ring buffer head pointer can be
       accessed by adding <u>sq_off.head</u> to the address returned from <b><a href="../man2/mmap.2.html">mmap</a></b>(2):

           head = ptr + sq_off.head;

       The <u>flags</u> field is used by the kernel to communicate state information to the application. Currently,  it
       is  used  to  inform the application when a call to <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) is necessary. See the documentation
       for the <b>IORING_SETUP_SQPOLL</b> flag above.  The <u>dropped</u> member is incremented for  each  invalid  submission
       queue entry encountered in the ring buffer.

       The head and tail track the ring buffer state. The tail is incremented by the application when submitting
       new  I/O,  and  the  head  is  incremented  by  the  kernel when the I/O has been successfully submitted.
       Determining the index of the head or tail into the ring is accomplished by applying a mask:

           index = tail &amp; ring_mask;

       The array of submission queue entries is mapped with:

           sqentries = mmap(0, sq_entries * sizeof(struct io_uring_sqe),
                            PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE,
                            ring_fd, IORING_OFF_SQES);

       The completion queue is described by <u>cq_entries</u> and <u>cq_off</u> shown here:

           struct io_cqring_offsets {
               __u32 head;
               __u32 tail;
               __u32 ring_mask;
               __u32 ring_entries;
               __u32 overflow;
               __u32 cqes;
               __u32 flags;
               __u32 resv1;
               __u64 user_addr;
           };

       The completion queue is simpler, since the entries are not separated from the queue itself,  and  can  be
       mapped with:

           ptr = mmap(0, cq_off.cqes + cq_entries * sizeof(struct io_uring_cqe),
                      PROT_READ|PROT_WRITE, MAP_SHARED|MAP_POPULATE, ring_fd,
                      IORING_OFF_CQ_RING);

       Closing  the  file  descriptor  returned by <b><a href="../man2/io_uring_setup.2.html">io_uring_setup</a></b>(2) will free all resources associated with the
       io_uring context. Note that this may happen asynchronously within the kernel, so  it  is  not  guaranteed
       that resources are freed immediately.

</pre><h4><b>RETURN</b> <b>VALUE</b></h4><pre>
       <b><a href="../man2/io_uring_setup.2.html">io_uring_setup</a></b>(2)  returns  a  new  file descriptor on success. The application may then provide the file
       descriptor in a subsequent <b><a href="../man2/mmap.2.html">mmap</a></b>(2)  call  to  map  the  submission  and  completion  queues,  or  to  the
       <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2) or <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2) system calls.

       On error, a negative error code is returned. The caller should not rely on <u>errno</u> variable.

</pre><h4><b>ERRORS</b></h4><pre>
       <b>EFAULT</b> <u>params</u> is outside your accessible address space.

       <b>EINVAL</b> The  resv  array  contains  non-zero data, p.flags contains an unsupported flag, <u>entries</u> is out of
              bounds, <b>IORING_SETUP_SQ_AFF</b> was specified, but <b>IORING_SETUP_SQPOLL</b> was not, or <b>IORING_SETUP_CQSIZE</b>
              was specified, but <u>io_uring_params.cq_entries</u> was  invalid.   <b>IORING_SETUP_REGISTERED_FD_ONLY</b>  was
              specified, but <b>IORING_SETUP_NO_MMAP</b> was not.

       <b>EMFILE</b> The per-process limit on the number of open file descriptors has been reached (see the description
              of <b>RLIMIT_NOFILE</b> in <b><a href="../man2/getrlimit.2.html">getrlimit</a></b>(2)).

       <b>ENFILE</b> The system-wide limit on the total number of open files has been reached.

       <b>ENOMEM</b> Insufficient kernel resources are available.

       <b>EPERM</b>  <b>IORING_SETUP_SQPOLL</b> was specified, but the effective user ID of the caller did not have sufficient
              privileges.

       <b>EPERM</b>  <u><a href="file:/proc/sys/kernel/io_uring_disabled">/proc/sys/kernel/io_uring_disabled</a></u>  has the value 2, or it has the value 1 and the calling process
              does not hold the <b>CAP_SYS_ADMIN</b> capability or is not a member of <u><a href="file:/proc/sys/kernel/io_uring_group">/proc/sys/kernel/io_uring_group</a></u>.

       <b>ENXIO</b>  <b>IORING_SETUP_ATTACH_WQ</b> was set, but <u>params.wq_fd</u> did not refer to an io_uring instance  or  refers
              to an instance that is in the process of shutting down.

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <b><a href="../man2/io_uring_register.2.html">io_uring_register</a></b>(2), <b><a href="../man2/io_uring_enter.2.html">io_uring_enter</a></b>(2)

Linux                                              2019-01-29                                  <u><a href="../man2/io_uring_setup.2.html">io_uring_setup</a></u>(2)
</pre>
 </div>
</div></section>
</div>
</body>
</html>