{
  "totalCategories": 3,
  "totalRepositories": 116,
  "processing_started": "2025-10-02T16:05:11.939075",
  "data": {
    "official-servers": {
      "category": "official-servers",
      "categoryDisplay": "Official Servers",
      "description": "",
      "totalRepositories": 39,
      "repositories": {
        "21st-dev--magic-mcp": {
          "owner": "21st-dev",
          "name": "magic-mcp",
          "url": "https://github.com/21st-dev/magic-mcp",
          "imageUrl": "https://github.com/21st-dev.png",
          "description": "Magic MCP is an AI tool that allows developers to create user interface components simply by describing them in everyday language. It works with popular coding environments, making the UI design process faster and more intuitive.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:11.939161",
          "collection_timestamp": "2025-10-02T14:58:55.651677",
          "stars": 3741,
          "forks": 246,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-02-19T13:17:50Z",
          "updated_at": "2025-10-01T20:15:48Z",
          "open_issues": 15,
          "readme_content": "# 21st.dev Magic AI Agent\n\n![MCP Banner](https://21st.dev/magic-agent-og-image.png)\n\nMagic Component Platform (MCP) is a powerful AI-driven tool that helps developers create beautiful, modern UI components instantly through natural language descriptions. It integrates seamlessly with popular IDEs and provides a streamlined workflow for UI development.\n\n## üåü Features\n\n- **AI-Powered UI Generation**: Create UI components by describing them in natural language\n- **Multi-IDE Support**:\n  - [Cursor](https://cursor.com) IDE integration\n  - [Windsurf](https://windsurf.ai) support\n  - [VSCode](https://code.visualstudio.com/) support\n  - [VSCode + Cline](https://cline.bot) integration (Beta)\n- **Modern Component Library**: Access to a vast collection of pre-built, customizable components inspired by [21st.dev](https://21st.dev)\n- **Real-time Preview**: Instantly see your components as you create them\n- **TypeScript Support**: Full TypeScript support for type-safe development\n- **SVGL Integration**: Access to a vast collection of professional brand assets and logos\n- **Component Enhancement**: Improve existing components with advanced features and animations (Coming Soon)\n\n## üéØ How It Works\n\n1. **Tell Agent What You Need**\n\n   - In your AI Agent's chat, just type `/ui` and describe the component you're looking for\n   - Example: `/ui create a modern navigation bar with responsive design`\n\n2. **Let Magic Create It**\n\n   - Your IDE prompts you to use Magic\n   - Magic instantly builds a polished UI component\n   - Components are inspired by 21st.dev's library\n\n3. **Seamless Integration**\n   - Components are automatically added to your project\n   - Start using your new UI components right away\n   - All components are fully customizable\n\n## üöÄ Getting Started\n\n### Prerequisites\n\n- Node.js (Latest LTS version recommended)\n- One of the supported IDEs:\n  - Cursor\n  - Windsurf\n  - VSCode (with Cline extension)\n\n### Installation\n\n1. **Generate API Key**\n\n   - Visit [21st.dev Magic Console](https://21st.dev/magic/console)\n   - Generate a new API key\n\n2. **Choose Installation Method**\n\n#### Method 1: CLI Installation (Recommended)\n\nOne command to install and configure MCP for your IDE:\n\n```bash\nnpx @21st-dev/cli@latest install <client> --api-key <key>\n```\n\nSupported clients: cursor, windsurf, cline, claude\n\n#### Method 2: Manual Configuration\n\nIf you prefer manual setup, add this to your IDE's MCP config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"@21st-dev/magic\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@21st-dev/magic@latest\", \"API_KEY=\\\"your-api-key\\\"\"]\n    }\n  }\n}\n```\n\nConfig file locations:\n\n- Cursor: `~/.cursor/mcp.json`\n- Windsurf: `~/.codeium/windsurf/mcp_config.json`\n- Cline: `~/.cline/mcp_config.json`\n- Claude: `~/.claude/mcp_config.json`\n\n#### Method 3: VS Code Installation\n\nFor one-click installation, click one of the install buttons below:\n\n[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=%4021st-dev%2Fmagic&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%4021st-dev%2Fmagic%40latest%22%5D%2C%22env%22%3A%7B%22API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%2221st.dev+Magic+API+Key%22%2C%22password%22%3Atrue%7D%5D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=%4021st-dev%2Fmagic&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%4021st-dev%2Fmagic%40latest%22%5D%2C%22env%22%3A%7B%22API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%2221st.dev+Magic+API+Key%22%2C%22password%22%3Atrue%7D%5D&quality=insiders)\n\n##### Manual VS Code Setup\n\nFirst, check the install buttons above for one-click installation. For manual setup:\n\nAdd the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`:\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"apiKey\",\n        \"description\": \"21st.dev Magic API Key\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"@21st-dev/magic\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@21st-dev/magic@latest\"],\n        \"env\": {\n          \"API_KEY\": \"${input:apiKey}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"apiKey\",\n      \"description\": \"21st.dev Magic API Key\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"@21st-dev/magic\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@21st-dev/magic@latest\"],\n      \"env\": {\n        \"API_KEY\": \"${input:apiKey}\"\n      }\n    }\n  }\n}\n```\n\n## ‚ùì FAQ\n\n### How does Magic AI Agent handle my codebase?\n\nMagic AI Agent only writes or modifies files related to the components it generates. It follows your project's code style and structure, and integrates seamlessly with your existing codebase without affecting other parts of your application.\n\n### Can I customize the generated components?\n\nYes! All generated components are fully editable and come with well-structured code. You can modify the styling, functionality, and behavior just like any other React component in your codebase.\n\n### What happens if I run out of generations?\n\nIf you exceed your monthly generation limit, you'll be prompted to upgrade your plan. You can upgrade at any time to continue generating components. Your existing components will remain fully functional.\n\n### How soon do new components get added to 21st.dev's library?\n\nAuthors can publish components to 21st.dev at any time, and Magic Agent will have immediate access to them. This means you'll always have access to the latest components and design patterns from the community.\n\n### Is there a limit to component complexity?\n\nMagic AI Agent can handle components of varying complexity, from simple buttons to complex interactive forms. However, for best results, we recommend breaking down very complex UIs into smaller, manageable components.\n\n## üõ†Ô∏è Development\n\n### Project Structure\n\n```\nmcp/\n‚îú‚îÄ‚îÄ app/\n‚îÇ   ‚îî‚îÄ‚îÄ components/     # Core UI components\n‚îú‚îÄ‚îÄ types/             # TypeScript type definitions\n‚îú‚îÄ‚îÄ lib/              # Utility functions\n‚îî‚îÄ‚îÄ public/           # Static assets\n```\n\n### Key Components\n\n- `IdeInstructions`: Setup instructions for different IDEs\n- `ApiKeySection`: API key management interface\n- `WelcomeOnboarding`: Onboarding flow for new users\n\n## ü§ù Contributing\n\nWe welcome contributions! Please join our [Discord community](https://discord.gg/Qx4rFunHfm) and provide feedback to help improve Magic Agent. The source code is available on [GitHub](https://github.com/serafimcloud/21st).\n\n## üë• Community & Support\n\n- [Discord Community](https://discord.gg/Qx4rFunHfm) - Join our active community\n- [Twitter](https://x.com/serafimcloud) - Follow us for updates\n\n## ‚ö†Ô∏è Beta Notice\n\nMagic Agent is currently in beta. All features are free during this period. We appreciate your feedback and patience as we continue to improve the platform.\n\n## üìù License\n\nMIT License\n\n## üôè Acknowledgments\n\n- Thanks to our beta testers and community members\n- Special thanks to the Cursor, Windsurf, and Cline teams for their collaboration\n- Integration with [21st.dev](https://21st.dev) for component inspiration\n- [SVGL](https://svgl.app) for logo and brand asset integration\n\n---\n\nFor more information, join our [Discord community](https://discord.gg/Qx4rFunHfm) or visit [21st.dev/magic](https://21st.dev/magic).\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "apimatic--apimatic-validator-mcp": {
          "owner": "apimatic",
          "name": "apimatic-validator-mcp",
          "url": "https://github.com/apimatic/apimatic-validator-mcp",
          "imageUrl": "https://github.com/apimatic.png",
          "description": "Validates OpenAPI specifications using APIMatic's API to ensure compliance and identify issues early. Supports both JSON and YAML formats and works with OpenAPI versions 2.0 and 3.0.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:12.861050",
          "collection_timestamp": "2025-10-02T14:58:59.366609",
          "stars": 5,
          "forks": 13,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-19T10:35:22Z",
          "updated_at": "2025-08-17T01:32:37Z",
          "open_issues": 2,
          "readme_content": "# APIMatic Validator MCP Server\n\nThis repository provides a Model Context Protocol (MCP) Server for validating OpenAPI specifications using [APIMatic](https://www.apimatic.io/). The server processes OpenAPI files and returns validation summaries by leveraging APIMatic‚Äôs API.\n\n## Features\n\n- Validates OpenAPI 2.0 and 3.0 files\n- Uses APIMatic‚Äôs API for comprehensive validation\n- Supports both JSON and YAML formats\n- Implements Model Context Protocol (MCP) for seamless integration\n\n## Installation\n\nEnsure that **Node.js v18+** is installed.\n\n### Clone the Repository\n```sh\ngit clone https://github.com/apimatic/apimatic-validator-mcp.git\ncd apimatic-validator-mcp\n```\n\n### Install Dependencies\n```sh\nnpm install\n```\n\n### Build the Project\n```sh\nnpm run build\n```\n\n## Configuration\n\nTo use the server, an APIMatic API key is required. Sign up at [APIMatic](https://www.apimatic.io/) and obtain the API key.\n\n\n![image](https://github.com/user-attachments/assets/1e2388dd-1330-4dab-a6e0-c6738a494ab9)\n\n\n### Integration with Claude Desktop\n\nModify the `claude_desktop_config.json` file to integrate the MCP server. If the file does not exist, create one in the following location:\n\n#### Windows\n```sh\ncode $env:AppData\\Claude\\claude_desktop_config.json\n```\n\n#### macOS/Linux\n```sh\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n### Add the MCP Server to the Configuration\n```json\n{\n    \"mcpServers\": {\n        \"APIMatic\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"C:\\\\PATH\\\\TO\\\\PARENT\\\\FOLDER\\\\build\\\\index.js\"\n            ],\n            \"env\": {\n                \"APIMATIC_API_KEY\": \"<Add your APIMatic token here>\"\n            }\n        }\n    }\n}\n```\n\nOnce configured, a hammer icon should appear in Claude Desktop. Open it to verify that the `validate-openapi-using-apimatic` tool is successfully integrated.\n\n## Usage\n\n1. Add an OpenAPI file.\n2. Provide a prompt to validate it.\n3. The validation results will be returned.\n\n[APIMatic MCP Server For OpenAPI Validation.webm](https://github.com/user-attachments/assets/b7d14e20-1c82-4a70-b237-7e5b6bd80993)\n\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/apimatic-validator-mcp",
          "npm_downloads": 197,
          "npm_package_name": "apimatic-validator-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "apify--apify-mcp-server": {
          "owner": "apify",
          "name": "apify-mcp-server",
          "url": "https://github.com/apify/apify-mcp-server",
          "imageUrl": "https://github.com/apify.png",
          "description": "Enable interaction with various Apify Actors to perform specific tasks through an MCP server configuration. It supports HTTP server access via Server-Sent Events (SSE) and local server functionality through standard input/output.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:13.720948",
          "collection_timestamp": "2025-10-02T14:59:07.258333",
          "stars": 429,
          "forks": 51,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-01-02T15:43:09Z",
          "updated_at": "2025-10-02T00:20:27Z",
          "open_issues": 23,
          "readme_content": "<h1 align=\"center\">\n    <a href=\"https://mcp.apify.com\">\n        <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/apify/apify-mcp-server/refs/heads/master/docs/apify_mcp_server_dark_background.png\">\n            <img alt=\"Apify MCP Server\" src=\"https://raw.githubusercontent.com/apify/apify-mcp-server/refs/heads/master/docs/apify_mcp_server_white_background.png\" width=\"500\">\n        </picture>\n    </a>\n    <br>\n    <small><a href=\"https://mcp.apify.com\">mcp.apify.com</a></small>\n</h1>\n\n<p align=center>\n    <a href=\"https://www.npmjs.com/package/@apify/actors-mcp-server\" rel=\"nofollow\"><img src=\"https://img.shields.io/npm/v/@apify/actors-mcp-server.svg\" alt=\"NPM latest version\" data-canonical-src=\"https://img.shields.io/npm/v/@apify/actors-mcp-server.svg\" style=\"max-width: 100%;\"></a>\n    <a href=\"https://www.npmjs.com/package/@apify/actors-mcp-server\" rel=\"nofollow\"><img src=\"https://img.shields.io/npm/dm/@apify/actors-mcp-server.svg\" alt=\"Downloads\" data-canonical-src=\"https://img.shields.io/npm/dm/@apify/actors-mcp-server.svg\" style=\"max-width: 100%;\"></a>\n    <a href=\"https://github.com/apify/actors-mcp-server/actions/workflows/check.yaml\"><img src=\"https://github.com/apify/actors-mcp-server/actions/workflows/check.yaml/badge.svg?branch=master\" alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n    <a href=\"https://apify.com/apify/actors-mcp-server\"><img src=\"https://apify.com/actor-badge?actor=apify/actors-mcp-server\" alt=\"Actor runs\" style=\"max-width: 100%;\"></a>\n</p>\n\nThe Apify Model Context Protocol (MCP) server at [**mcp.apify.com**](https://mcp.apify.com) enables your AI agents to extract data from social media, search engines, maps, e-commerce sites, or any other website using thousands of ready-made scrapers, crawlers, and automation tools available on the [Apify Store](https://apify.com/store).\n\n> **üöÄ Try the hosted Apify MCP Server!**\n>\n> For the easiest setup and most powerful features, including the ability to find and use any Actor from Apify Store, connect your AI assistant to our hosted server:\n>\n> **[`https://mcp.apify.com`](https://mcp.apify.com)**\n>\n> It supports OAuth, so you can connect from clients like Claude.ai or Visual Studio Code with just the URL.\n\n![Apify-MCP-server](https://raw.githubusercontent.com/apify/apify-mcp-server/refs/heads/master/docs/apify-mcp-server.png)\n\n## Table of Contents\n- [üåê Introducing the Apify MCP server](#-introducing-the-apify-mcp-server)\n- [üöÄ Quickstart](#-quickstart)\n- [ü§ñ MCP clients and examples](#-mcp-clients-and-examples)\n- [ü™Ñ Try Apify MCP instantly](#-try-apify-mcp-instantly)\n- [üõ†Ô∏è Tools, resources, and prompts](#-tools-resources-and-prompts)\n- [üêõ Troubleshooting (local MCP server)](#-troubleshooting-local-mcp-server)\n- [‚öôÔ∏è Development](#-development)\n- [ü§ù Contributing](#-contributing)\n- [üìö Learn more](#-learn-more)\n\n# üåê Introducing the Apify MCP server\n\nThe Apify MCP Server allows an AI assistant to use any [Apify Actor](https://apify.com/store) as a tool to perform a specific task.\nFor example, it can:\n- Use [Facebook Posts Scraper](https://apify.com/apify/facebook-posts-scraper) to extract data from Facebook posts from multiple pages/profiles.\n- Use [Google Maps Email Extractor](https://apify.com/lukaskrivka/google-maps-with-contact-details) to extract contact details from Google Maps.\n- Use [Google Search Results Scraper](https://apify.com/apify/google-search-scraper) to scrape Google Search Engine Results Pages (SERPs).\n- Use [Instagram Scraper](https://apify.com/apify/instagram-scraper) to scrape Instagram posts, profiles, places, photos, and comments.\n- Use [RAG Web Browser](https://apify.com/apify/web-scraper) to search the web, scrape the top N URLs, and return their content.\n\n**Video tutorial: Integrate 5,000+ Apify Actors and Agents with Claude**\n\n[![Apify MCP Server Tutorial: Integrate 5,000+ Apify Actors and Agents with Claude](https://img.youtube.com/vi/BKu8H91uCTg/hqdefault.jpg)](https://www.youtube.com/watch?v=BKu8H91uCTg)\n\n# üöÄ Quickstart\n\nYou can use the Apify MCP Server in two ways:\n\n**HTTPS Endpoint (mcp.apify.com)**: Connect from your MCP client via OAuth or by including the `Authorization: Bearer <APIFY_TOKEN>` header in your requests. This is the recommended method for most use cases. Because it supports OAuth, you can connect from clients like [Claude.ai](https://claude.ai) or [Visual Studio Code](https://code.visualstudio.com/) using just the URL: `https://mcp.apify.com`.\n- `https://mcp.apify.com` streamable transport\n\n**Standard Input/Output (stdio)**: Ideal for local integrations and command-line tools like the Claude for Desktop client.\n- Set the MCP client server command to `npx @apify/actors-mcp-server` and the `APIFY_TOKEN` environment variable to your Apify API token.\n- See `npx @apify/actors-mcp-server --help` for more options.\n\nYou can find detailed instructions for setting up the MCP server in the [Apify documentation](https://docs.apify.com/platform/integrations/mcp).\n\n# ü§ñ MCP clients and examples\n\nTo interact with the Apify MCP server, you can use various MCP clients, such as:\n- [Claude Desktop](https://claude.ai/download)\n- [Visual Studio Code](https://code.visualstudio.com/)\n- [Apify Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\n- Other clients at [https://modelcontextprotocol.io/clients](https://modelcontextprotocol.io/clients)\n- More clients at [https://glama.ai/mcp/clients](https://glama.ai/mcp/clients)\n\nWith MCP server integrated, you can ask your AI assistant things like:\n- \"Search the web and summarize recent trends in AI Agents.\"\n- \"Find the top 10 Italian restaurants in San Francisco.\"\n- \"Find and analyze the Instagram profile of The Rock.\"\n- \"Provide a step-by-step guide on using the Model Context Protocol, including source URLs.\"\n- \"What Apify Actors can I use?\"\n\n### Supported clients matrix\n\nThe following table outlines the tested MCP clients and their level of support for key features.\n\n| Client | Dynamic Tool Discovery | Notes |\n| --- | --- | --- |\n| **Claude.ai (web)** | ‚úÖ Full | |\n| **Claude Desktop** | üü° Partial | Tools may need to be reloaded manually in the client. |\n| **VS Code (Genie)** | ‚úÖ Full | |\n| **Apify Tester MCP Client** | ‚úÖ Full | Designed for testing Apify MCP servers. |\n\nApify MCP Server is compatible with any MCP client that adheres to the [Model Context Protocol](https://modelcontextprotocol.org/), but the level of support for dynamic tool discovery and other features may vary between clients. Therefore, the server uses [mcp-client-capabilities](https://github.com/apify/mcp-client-capabilities) to detect client capabilities and adjust its behavior accordingly.\n\n**Smart tool selection based on client capabilities:**\n\nWhen the `actors` tool category is requested, the server intelligently selects the most appropriate Actor-related tools based on the client's capabilities:\n\n- **Clients with dynamic tool support** (e.g., Claude.ai web, VS Code Genie): The server provides the `add-actor` tool instead of `call-actor`. This allows for a better user experience where users can dynamically discover and add new Actors as tools during their conversation.\n\n- **Clients with limited dynamic tool support** (e.g., Claude Desktop): The server provides the standard `call-actor` tool along with other Actor category tools, ensuring compatibility while maintaining functionality.\n\n# ü™Ñ Try Apify MCP instantly\n\nWant to try Apify MCP without any setup?\n\nCheck out [Apify Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\n\nThis interactive, chat-like interface provides an easy way to explore the capabilities of Apify MCP without any local setup.\nJust sign in with your Apify account and start experimenting with web scraping, data extraction, and automation tools!\n\nOr use the MCP bundle file (formerly known as Anthropic Desktop extension file, or DXT) for one-click installation: [Apify MCP server MCPB file](https://github.com/apify/apify-mcp-server/releases/latest/download/apify-mcp-server.mcpb)\n\n# üõ†Ô∏è Tools, resources, and prompts\n\nThe MCP server provides a set of tools for interacting with Apify Actors.\nSince the Apify Store is large and growing rapidly, the MCP server provides a way to dynamically discover and use new Actors.\n\n### Actors\n\nAny [Apify Actor](https://apify.com/store) can be used as a tool.\nBy default, the server is pre-configured with one Actor, `apify/rag-web-browser`, and several helper tools.\nThe MCP server loads an Actor's input schema and creates a corresponding MCP tool.\nThis allows the AI agent to know exactly what arguments to pass to the Actor and what to expect in return.\n\n\nFor example, for the `apify/rag-web-browser` Actor, the input parameters are:\n\n```json\n{\n  \"query\": \"restaurants in San Francisco\",\n  \"maxResults\": 3\n}\n```\nYou don't need to manually specify which Actor to call or its input parameters; the LLM handles this automatically.\nWhen a tool is called, the arguments are automatically passed to the Actor by the LLM.\nYou can refer to the specific Actor's documentation for a list of available arguments.\n\n### Helper tools\n\nOne of the most powerful features of using MCP with Apify is dynamic tool discovery.\nIt gives an AI agent the ability to find new tools (Actors) as needed and incorporate them.\nHere are some special MCP operations and how the Apify MCP Server supports them:\n\n- **Apify Actors**: Search for Actors, view their details, and use them as tools for the AI.\n- **Apify documentation**: Search the Apify documentation and fetch specific documents to provide context to the AI.\n- **Actor runs**: Get lists of your Actor runs, inspect their details, and retrieve logs.\n- **Apify storage**: Access data from your datasets and key-value stores.\n\n### Overview of available tools\n\nHere is an overview list of all the tools provided by the Apify MCP Server.\n\n| Tool name | Category | Description | Enabled by default |\n| :--- | :--- | :--- | :---: |\n| `search-actors` | actors | Search for Actors in the Apify Store. | ‚úÖ |\n| `fetch-actor-details` | actors | Retrieve detailed information about a specific Actor. | ‚úÖ |\n| `call-actor` | actors | Call an Actor and get its run results. | ‚úÖ |\n| [`apify-slash-rag-web-browser`](https://apify.com/apify/rag-web-browser) | Actor (see [tool configuration](#tools-configuration)) | An Actor tool to browse the web. | ‚úÖ |\n| `search-apify-docs` | docs | Search the Apify documentation for relevant pages. | ‚úÖ |\n| `fetch-apify-docs` | docs | Fetch the full content of an Apify documentation page by its URL. | ‚úÖ |\n| `get-actor-run` | runs | Get detailed information about a specific Actor run. |  |\n| `get-actor-run-list` | runs | Get a list of an Actor's runs, filterable by status. |  |\n| `get-actor-log` | runs | Retrieve the logs for a specific Actor run. |  |\n| `get-dataset` | storage | Get metadata about a specific dataset. |  |\n| `get-dataset-items` | storage | Retrieve items from a dataset with support for filtering and pagination. |  |\n| `get-dataset-schema` | storage | Generate a JSON schema from dataset items. |  |\n| `get-key-value-store` | storage | Get metadata about a specific key-value store. |  |\n| `get-key-value-store-keys`| storage | List the keys within a specific key-value store. |  |\n| `get-key-value-store-record`| storage | Get the value associated with a specific key in a key-value store. |  |\n| `get-dataset-list` | storage | List all available datasets for the user. |  |\n| `get-key-value-store-list`| storage | List all available key-value stores for the user. |  |\n| `add-actor` | experimental | Add an Actor as a new tool for the user to call. |  |\n| `get-actor-output`* | - | Retrieve the output from an Actor call which is not included in the output preview of the Actor tool. | ‚úÖ |\n\n> **Note:**\n>\n> When using the `actors` tool category, clients that support dynamic tool discovery (like Claude.ai web and VS Code) automatically receive the `add-actor` tool instead of `call-actor` for enhanced Actor discovery capabilities.\n\n> The `get-actor-output` tool is automatically included with any Actor-related tool, such as `call-actor`, `add-actor`, or any specific Actor tool like `apify-slash-rag-web-browser`. When you call an Actor - either through the `call-actor` tool or directly via an Actor tool (e.g., `apify-slash-rag-web-browser`) - you receive a preview of the output. The preview depends on the Actor's output format and length; for some Actors and runs, it may include the entire output, while for others, only a limited version is returned to avoid overwhelming the LLM. To retrieve the full output of an Actor run, use the `get-actor-output` tool (supports limit, offset, and field filtering) with the `datasetId` provided by the Actor call.\n\n### Tools configuration\n\nThe `tools` configuration parameter is used to specify loaded tools - either categories or specific tools directly, and Apify Actors. For example, `tools=storage,runs` loads two categories; `tools=add-actor` loads just one tool.\n\nWhen no query parameters are provided, the MCP server loads the following `tools` by default:\n\n- `actors`\n- `docs`\n- `apify/rag-web-browser`\n\nIf the tools parameter is specified, only the listed tools or categories will be enabled - no default tools will be included.\n\n> **Easy configuration:**\n>\n> Use the [UI configurator](https://mcp.apify.com/) to configure your server, then copy the configuration to your client.\n\n**Configuring the hosted server:**\n\nThe hosted server can be configured using query parameters in the URL. For example, to load the default tools, use:\n\n```\nhttps://mcp.apify.com?tools=actors,docs,apify/rag-web-browser\n```\n\nFor minimal configuration, if you want to use only a single Actor tool - without any discovery or generic calling tools, the server can be configured as follows:\n\n```\nhttps://mcp.apify.com?tools=apify/my-actor\n```\n\nThis setup exposes only the specified Actor (`apify/my-actor`) as a tool. No other tools will be available.\n\n**Configuring the CLI:**\n\nThe CLI can be configured using command-line flags. For example, to load the same tools as in the hosted server configuration, use:\n\n```bash\nnpx @apify/actors-mcp-server --tools actors,docs,apify/rag-web-browser\n```\n\nThe minimal configuration is similar to the hosted server configuration:\n\n```bash\nnpx @apify/actors-mcp-server --tools apify/my-actor\n```\n\nAs above, this exposes only the specified Actor (`apify/my-actor`) as a tool. No other tools will be available.\n\n> **‚ö†Ô∏è Important recommendation**\n>\n> **The default tools configuration may change in future versions.** When no `tools` parameter is specified, the server currently loads default tools, but this behavior is subject to change.\n>\n> **For production use and stable interfaces, always explicitly specify the `tools` parameter** to ensure your configuration remains consistent across updates.\n\n### Backward compatibility\n\nThe v2 configuration preserves backward compatibility with v1 usage. Notes:\n\n- `actors` param (URL) and `--actors` flag (CLI) are still supported.\n  - Internally they are merged into `tools` selectors.\n  - Examples: `?actors=apify/rag-web-browser` ‚â° `?tools=apify/rag-web-browser`; `--actors apify/rag-web-browser` ‚â° `--tools apify/rag-web-browser`.\n- `enable-adding-actors` (CLI) and `enableAddingActors` (URL) are supported but deprecated.\n  - Prefer `tools=experimental` or including the specific tool `tools=add-actor`.\n  - Behavior remains: when enabled with no `tools` specified, the server exposes only `add-actor`; when categories/tools are selected, `add-actor` is also included.\n- `enableActorAutoLoading` remains as a legacy alias for `enableAddingActors` and is mapped automatically.\n- Defaults remain compatible: when no `tools` are specified, the server loads `actors`, `docs`, and `apify/rag-web-browser`.\n  - If any `tools` are specified, the defaults are not added (same as v1 intent for explicit selection).\n- `call-actor` is now included by default via the `actors` category (additive change). To exclude it, specify an explicit `tools` list without `actors`.\n- `preview` category is deprecated and removed. Use specific tool names instead.\n\nExisting URLs and commands using `?actors=...` or `--actors` continue to work unchanged.\n\n### Prompts\n\nThe server provides a set of predefined example prompts to help you get started interacting with Apify through MCP. For example, there is a `GetLatestNewsOnTopic` prompt that allows you to easily retrieve the latest news on a specific topic using the [RAG Web Browser](https://apify.com/apify/rag-web-browser) Actor.\n\n### Resources\n\nThe server does not yet provide any resources.\n\n### Debugging the NPM package\n\nTo debug the server, use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) tool:\n\n```shell\nexport APIFY_TOKEN=\"your-apify-token\"\nnpx @modelcontextprotocol/inspector npx -y @apify/actors-mcp-server\n```\n\n# ‚öôÔ∏è Development\n\n## Prerequisites\n\n- [Node.js](https://nodejs.org/en) (v18 or higher)\n\nCreate an environment file, `.env`, with the following content:\n```text\nAPIFY_TOKEN=\"your-apify-token\"\n```\n\nBuild the `actor-mcp-server` package:\n\n```bash\nnpm run build\n```\n\n## Start HTTP streamable MCP server\n\nRun using Apify CLI:\n\n```bash\nexport APIFY_TOKEN=\"your-apify-token\"\nexport APIFY_META_ORIGIN=STANDBY\napify run -p\n```\n\nOnce the server is running, you can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) to debug the server exposed at `http://localhost:3001`.\n\n## Start standard input/output (stdio) MCP server\n\nYou can launch the MCP Inspector with this command:\n\n```bash\nexport APIFY_TOKEN=\"your-apify-token\"\nnpx @modelcontextprotocol/inspector node ./dist/stdio.js\n```\n\nUpon launching, the Inspector will display a URL that you can open in your browser to begin debugging.\n\n## üê¶ Canary PR releases\n\nApify MCP is split across two repositories: this one for core MCP logic and the private `apify-mcp-server-internal` for the hosted server.\nChanges must be synchronized between both.\n\nTo create a canary release, add the `beta` tag to your PR branch.\nThis publishes the package to [pkg.pr.new](https://pkg.pr.new/) for staging and testing before merging.\nSee [the workflow file](.github/workflows/pre_release.yaml) for details.\n\n## üêã Docker Hub integration\nThe Apify MCP Server is also available on [Docker Hub](https://hub.docker.com/mcp/server/apify-mcp-server/overview), registered via the [mcp-registry](https://github.com/docker/mcp-registry) repository. The entry in `servers/apify-mcp-server/server.yaml` should be deployed automatically by the Docker Hub MCP registry (deployment frequency is unknown). **Before making major changes to the `stdio` server version, be sure to test it locally to ensure the Docker build passes.** To test, change the `source.branch` to your PR branch and run `task build -- apify-mcp-server`. For more details, see [CONTRIBUTING.md](https://github.com/docker/mcp-registry/blob/main/CONTRIBUTING.md).\n\n# üêõ Troubleshooting (local MCP server)\n\n- Make sure you have `node` installed by running `node -v`.\n- Make sure the `APIFY_TOKEN` environment variable is set.\n- Always use the latest version of the MCP server by using `@apify/actors-mcp-server@latest`.\n\n## üí° Limitations\n\nThe Actor input schema is processed to be compatible with most MCP clients while adhering to [JSON Schema](https://json-schema.org/) standards. The processing includes:\n- **Descriptions** are truncated to 500 characters (as defined in `MAX_DESCRIPTION_LENGTH`).\n- **Enum fields** are truncated to a maximum combined length of 200 characters for all elements (as defined in `ACTOR_ENUM_MAX_LENGTH`).\n- **Required fields** are explicitly marked with a `REQUIRED` prefix in their descriptions for compatibility with frameworks that may not handle the JSON schema properly.\n- **Nested properties** are built for special cases like proxy configuration and request list sources to ensure the correct input structure.\n- **Array item types** are inferred when not explicitly defined in the schema, using a priority order: explicit type in items > prefill type > default value type > editor type.\n- **Enum values and examples** are added to property descriptions to ensure visibility, even if the client doesn't fully support the JSON schema.\n- **Rental Actors** are only available for use with the hosted MCP server at https://mcp.apify.com. When running the server locally via stdio, you can only access Actors that are already added to your local toolset. To dynamically search for and use any Actor from the Apify Store‚Äîincluding rental Actors‚Äîconnect to the hosted endpoint.\n\n# ü§ù Contributing\n\nWe welcome contributions to improve the Apify MCP Server! Here's how you can help:\n\n- **üêõ Report issues**: Find a bug or have a feature request? [Open an issue](https://github.com/apify/apify-mcp-server/issues).\n- **üîß Submit pull requests**: Fork the repo and submit pull requests with enhancements or fixes.\n- **üìö Documentation**: Improvements to docs and examples are always welcome.\n- **üí° Share use cases**: Contribute examples to help other users.\n\nFor major changes, please open an issue first to discuss your proposal and ensure it aligns with the project's goals.\n\n# üìö Learn more\n\n- [Model Context Protocol](https://modelcontextprotocol.org/)\n- [What are AI Agents?](https://blog.apify.com/what-are-ai-agents/)\n- [What is MCP and why does it matter?](https://blog.apify.com/what-is-model-context-protocol/)\n- [How to use MCP with Apify Actors](https://blog.apify.com/how-to-use-mcp/)\n- [Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\n- [Webinar: Building and Monetizing MCP Servers on Apify](https://www.youtube.com/watch?v=w3AH3jIrXXo)\n- [MCP Client development guide](https://github.com/cyanheads/model-context-protocol-resources/blob/main/guides/mcp-client-development-guide.md)\n- [How to build and monetize an AI agent on Apify](https://blog.apify.com/how-to-build-an-ai-agent/)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "axiomhq--mcp-server-axiom": {
          "owner": "axiomhq",
          "name": "mcp-server-axiom",
          "url": "https://github.com/axiomhq/mcp-server-axiom",
          "imageUrl": "https://github.com/axiomhq.png",
          "description": "Queries Axiom datasets using Axiom Processing Language (APL) and lists available datasets.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:14.715032",
          "collection_timestamp": "2025-10-02T14:59:11.367940",
          "stars": 58,
          "forks": 9,
          "license": "MIT License",
          "language": "Go",
          "created_at": "2024-12-05T13:06:26Z",
          "updated_at": "2025-09-24T10:23:15Z",
          "open_issues": 5,
          "readme_content": "\n# [DEPRECATED] mcp-server-axiom\n\n---\n\n### ‚ö†Ô∏è DEPRECATION NOTICE \n\n**This repository is deprecated and no longer maintained.**  \nPlease use the official Axiom MCP Server at [https://mcp.axiom.co](https://mcp.axiom.co) instead.\n\n---\n\n## Overview\nA [Model Context Protocol](https://modelcontextprotocol.io/) server implementation for [Axiom](https://axiom.co) that enables AI agents to query your data using Axiom Processing Language (APL).\n\n## Status\n\nWorks with Claude desktop app. Implements six MCP [tools](https://modelcontextprotocol.io/docs/concepts/tools):\n\n- queryApl: Execute APL queries against Axiom datasets\n- listDatasets: List available Axiom datasets\n- getDatasetSchema: Get dataset schema\n- getSavedQueries: Retrieve saved/starred APL queries\n- getMonitors: List monitoring configurations\n- getMonitorsHistory: Get monitor execution history\n\n**Note:** All tools require an API token for authentication. Use your API token as the `token` parameter.\n\nNo support for MCP [resources](https://modelcontextprotocol.io/docs/concepts/resources) or [prompts](https://modelcontextprotocol.io/docs/concepts/prompts) yet.\n\n## Installation\n\n### Releases\n\nDownload the latest built binary from the [releases page](https://github.com/axiomhq/axiom-mcp/releases).\n\n### Source\n\n```bash\ngo install github.com/axiomhq/axiom-mcp@latest\n```\n\n## Configuration\n\nConfigure using one of these methods:\n\n### Config File Example (config.txt):\n```txt\ntoken xaat-your-api-token\nurl https://api.axiom.co\nquery-rate 1\nquery-burst 1\ndatasets-rate 1\ndatasets-burst 1\nmonitors-rate 1\nmonitors-burst 1\n```\n\n### Command Line Flags:\n```bash\naxiom-mcp \\\n  -token xaat-your-api-token \\\n  -url https://api.axiom.co \\\n  -query-rate 1 \\\n  -query-burst 1 \\\n  -datasets-rate 1 \\\n  -datasets-burst 1 \\\n  -monitors-rate 1 \\\n  -monitors-burst 1\n```\n\n### Environment Variables:\n```bash\nexport AXIOM_TOKEN=xaat-your-api-token\nexport AXIOM_URL=https://api.axiom.co\nexport AXIOM_QUERY_RATE=1\nexport AXIOM_QUERY_BURST=1\nexport AXIOM_DATASETS_RATE=1\nexport AXIOM_DATASETS_BURST=1\nexport AXIOM_MONITORS_RATE=1\nexport AXIOM_MONITORS_BURST=1\n```\n\n## Usage\n\n1. Create a config file:\n```bash\necho \"token xaat-your-api-token\" > config.txt\n```\n\n2. Configure the Claude app to use the MCP server:\n\n```bash\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"axiom\": {\n      \"command\": \"/path/to/your/axiom-mcp-binary\",\n      \"args\" : [\"--config\", \"/path/to/your/config.txt\"],\n      \"env\": { // Alternatively, you can set the environment variables here\n        \"AXIOM_TOKEN\": \"xaat-your-api-token\",\n        \"AXIOM_URL\": \"https://api.axiom.co\"\n      }\n    }\n  }\n}\n```\n\n## License\n\nMIT License - see LICENSE file\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-server-axiom",
          "npm_downloads": 5052,
          "npm_package_name": "mcp-server-axiom",
          "npm_success": true,
          "npm_error": null
        },
        "base--base-mcp": {
          "owner": "base",
          "name": "base-mcp",
          "url": "https://github.com/base/base-mcp",
          "imageUrl": "https://github.com/base.png",
          "description": "Enables interaction with the Base blockchain and Coinbase API for AI applications. Supports wallet management, fund transfers, smart contract deployments, and onchain lending functionality.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:15.554545",
          "collection_timestamp": "2025-10-02T14:59:15.550538",
          "stars": 294,
          "forks": 98,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-06T21:57:34Z",
          "updated_at": "2025-09-19T23:15:17Z",
          "open_issues": 32,
          "readme_content": "# Base MCP Server üîµ\n\n![OpenRouter Integration](public/OpenRouter.gif)\n\n[![npm version](https://img.shields.io/npm/v/base-mcp.svg)](https://www.npmjs.com/package/base-mcp)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA Model Context Protocol (MCP) server that provides onchain tools for AI applications like Claude Desktop and Cursor, allowing them to interact with the Base Network and Coinbase API.\n\n## Overview\n\nThis MCP server extends any MCP client's capabilities by providing tools to do anything on Base:\n\n- Retrieve wallet addresses\n- List wallet balances\n- Transfer funds between wallets\n- Deploy smart contracts\n- Interact with Morpho vaults for onchain lending\n- Call contract functions\n- Onramp funds via [Coinbase](https://www.coinbase.com/developer-platform/products/onramp)\n- Manage ERC20 tokens\n- List and transfer NFTs (ERC721 and ERC1155)\n- Buy [OpenRouter](http://openrouter.ai/) credits with USDC\n- Resolve Farcaster usernames to Ethereum addresses\n\nThe server interacts with Base, powered by Base Developer Tools and [AgentKit](https://github.com/coinbase/agentkit).\n\n## Extending Base MCP with 3P Protocols, Tools, and Data Sources\n\nBase MCP is designed to be extensible, allowing you to add your own third-party protocols, tools, and data sources. This section provides an overview of how to extend the Base MCP server with new capabilities.\n\n### Adding New Tools\n\nIf you want to add a new tool to the Base MCP server, follow these steps:\n\n1. Create a new directory in the `src/tools` directory for your tool\n2. Implement the tool following the existing patterns:\n   - `index.ts`: Define and export your tools. Tools are defined as AgentKit ActionProviders.\n   - `schemas.ts`: Define input schemas for your tools\n   - `types.ts`: Define types required for your tools\n   - `utils.ts`: Utilities for your tools\n3. Add your tool to the list of available tools in `src/main.ts`\n4. Add documentation for your tool in the README.md\n5. Add examples of how to use your tool in examples.md\n6. Write tests for your tool\n\n### Project Structure\n\nThe Base MCP server follows this structure for tools:\n\n```\nsrc/\n‚îú‚îÄ‚îÄ tools/\n‚îÇ   ‚îú‚îÄ‚îÄ [TOOL_NAME]/ <-------------------------- ADD DIR HERE\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.ts (defines and exports tools)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.ts (defines input schema)\n‚îÇ   ‚îî‚îÄ‚îÄ utils/ (shared tool utilities)\n```\n\n### Best Practices for Tool Development\n\nWhen developing new tools for Base MCP:\n\n- Follow the existing code style and patterns\n- Ensure your tool has a clear, focused purpose\n- Provide comprehensive input validation\n- Include detailed error handling\n- Write thorough documentation\n- Add examples demonstrating how to use your tool\n- Include tests for your tool\n\nFor more detailed information on contributing to Base MCP, including adding new tools and protocols, see the [CONTRIBUTING.md](CONTRIBUTING.md) file.\n\n## Prerequisites\n\n- Node.js (v16 or higher)\n- npm or yarn\n- Coinbase API credentials (API Key Name and Private Key)\n- A wallet seed phrase\n- Coinbase Project ID (for onramp functionality)\n- Alchemy API Key (required for NFT functionality)\n- Optional: OpenRouter API Key (for buying OpenRouter credits)\n\n## Installation\n\n### Option 1: Install from npm (Recommended)\n\n```bash\n# Install globally\nnpm install -g base-mcp\n\n# Or install locally in your project\nnpm install base-mcp\n```\n\nOnce the package is installed, you can configure clients with the following command:\n\n```bash\nbase-mcp --init\n```\n\n### Option 2: Install from Source\n\n1. Clone this repository:\n\n   ```bash\n   git clone https://github.com/base/base-mcp.git\n   cd base-mcp\n   ```\n\n2. Install dependencies:\n\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n\n   ```bash\n   npm run build\n   ```\n\n4. Optionally, link it globally:\n   ```bash\n   npm link\n   ```\n\n## Configuration\n\nCreate a `.env` file with your credentials:\n\n```\n# Coinbase API credentials\n# You can obtain these from the Coinbase Developer Portal: https://cdp.coinbase.com/\nCOINBASE_API_KEY_NAME=your_api_key_name\nCOINBASE_API_PRIVATE_KEY=your_private_key\n\n# Wallet seed phrase (12 or 24 words)\n# This is the mnemonic phrase for your wallet\nSEED_PHRASE=your seed phrase here\n\n# Coinbase Project ID (for onramp functionality)\n# You can obtain this from the Coinbase Developer Portal\nCOINBASE_PROJECT_ID=your_project_id\n\n# Alchemy API Key (required for NFT functionality)\n# You can obtain this from https://alchemy.com\nALCHEMY_API_KEY=your_alchemy_api_key\n\n# OpenRouter API Key (optional for buying OpenRouter credits)\n# You can obtain this from https://openrouter.ai/keys\nOPENROUTER_API_KEY=your_openrouter_api_key\n\n# Chain ID (optional for Base Sepolia testnet)\n# Use 84532 for Base Sepolia testnet\n# You do not have to include this if you want to use Base Mainnet\nCHAIN_ID=your_chain_id\n\n# Neynar API Key (required for Farcaster functionality)\n# You can obtain this from https://neynar.com\nNEYNAR_API_KEY=your_neynar_api_key\n```\n\n## Testing\n\nTest the MCP server to verify it's working correctly:\n\n```bash\nnpm test\n```\n\nThis script will verify that your MCP server is working correctly by testing the connection and available tools.\n\n## Examples\n\nSee the [examples.md](examples.md) file for detailed examples of how to interact with the Base MCP tools through Claude.\n\n## Integration with Claude Desktop\n\nTo add this MCP server to Claude Desktop:\n\n1. Create or edit the Claude Desktop configuration file at:\n\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\nYou can easily access this file via the Claude Desktop app by navigating to Claude > Settings > Developer > Edit Config.\n\n2. Add the following configuration:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"base-mcp\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"base-mcp@latest\"],\n         \"env\": {\n           \"COINBASE_API_KEY_NAME\": \"your_api_key_name\",\n           \"COINBASE_API_PRIVATE_KEY\": \"your_private_key\",\n           \"SEED_PHRASE\": \"your seed phrase here\",\n           \"COINBASE_PROJECT_ID\": \"your_project_id\",\n           \"ALCHEMY_API_KEY\": \"your_alchemy_api_key\",\n           \"PINATA_JWT\": \"your_pinata_jwt\",\n           \"OPENROUTER_API_KEY\": \"your_openrouter_api_key\",\n           \"CHAIN_ID\": \"optional_for_base_sepolia_testnet\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n3. Restart Claude Desktop for the changes to take effect.\n\n## Available Tools\n\n### get-address\n\nRetrieves the address for your wallet.\n\nExample query to Claude:\n\n> \"What's my wallet address?\"\n\n### list-balances\n\nLists all balances for your wallet.\n\nExample query to Claude:\n\n> \"Show me my wallet balances.\"\n\n### transfer-funds\n\nTransfers funds from your wallet to another address.\n\nParameters:\n\n- `destination`: The address to which to transfer funds\n- `assetId`: The asset ID to transfer\n- `amount`: The amount of funds to transfer\n\nExample query to Claude:\n\n> \"Transfer 0.01 ETH to 0x1234567890abcdef1234567890abcdef12345678.\"\n\n### deploy-contract\n\nDeploys a smart contract to the blockchain.\n\nParameters:\n\n- `constructorArgs`: The arguments for the contract constructor\n- `contractName`: The name of the contract to deploy\n- `solidityInputJson`: The JSON input for the Solidity compiler containing contract source and settings\n- `solidityVersion`: The version of the solidity compiler\n\nExample query to Claude:\n\n> \"Deploy a simple ERC20 token contract for me.\"\n\n### check-address-reputation\n\nChecks the reputation of an address.\n\nParameters:\n\n- `address`: The Ethereum address to check\n\nExample query to Claude:\n\n> \"What's the reputation of 0x1234567890abcdef1234567890abcdef12345678?\"\n\n### get_morpho_vaults\n\nGets the vaults for a given asset on Morpho.\n\nParameters:\n\n- `assetSymbol`: Asset symbol by which to filter vaults (optional)\n\nExample query to Claude:\n\n> \"Show me the available Morpho vaults for USDC.\"\n\n### call_contract\n\nCalls a contract function on the blockchain.\n\nParameters:\n\n- `contractAddress`: The address of the contract to call\n- `functionName`: The name of the function to call\n- `functionArgs`: The arguments to pass to the function\n- `abi`: The ABI of the contract\n- `value`: The value of ETH to send with the transaction (optional)\n\nExample query to Claude:\n\n> \"Call the balanceOf function on the contract at 0x1234567890abcdef1234567890abcdef12345678.\"\n\n### get_onramp_assets\n\nGets the assets available for onramping in a given country/subdivision.\n\nParameters:\n\n- `country`: ISO 3166-1 two-digit country code string representing the purchasing user's country of residence\n- `subdivision`: ISO 3166-2 two-digit country subdivision code (required for US)\n\nExample query to Claude:\n\n> \"What assets can I onramp in the US, specifically in New York?\"\n\n### onramp\n\nGets a URL for onramping funds via Coinbase.\n\nParameters:\n\n- `amountUsd`: The amount of funds to onramp\n- `assetId`: The asset ID to onramp\n\nExample query to Claude:\n\n> \"I want to onramp $100 worth of ETH.\"\n\n### erc20_balance\n\nGets the balance of an ERC20 token.\n\nParameters:\n\n- `contractAddress`: The address of the ERC20 contract\n\nExample query to Claude:\n\n> \"What's my balance of the token at 0x1234567890abcdef1234567890abcdef12345678?\"\n\n### erc20_transfer\n\nTransfers an ERC20 token to another address.\n\nParameters:\n\n- `contractAddress`: The address of the ERC20 contract\n- `toAddress`: The address of the recipient\n- `amount`: The amount of tokens to transfer\n\nExample query to Claude:\n\n> \"Transfer 10 USDC to 0x1234567890abcdef1234567890abcdef12345678.\"\n\n### list_nfts\n\nLists NFTs owned by a specific address.\n\nParameters:\n\n- `ownerAddress`: The address of the owner whose NFTs to list\n- `limit`: Maximum number of NFTs to return (default: 50)\n\nExample query to Claude:\n\n> \"Show me the NFTs owned by 0x89A93a48C6Ef8085B9d07e46AaA96DFDeC717040.\"\n\n### transfer_nft\n\nTransfers an NFT to another address. Supports both ERC721 and ERC1155 standards.\n\nParameters:\n\n- `contractAddress`: The address of the NFT contract\n- `tokenId`: The token ID of the NFT to transfer\n- `toAddress`: The address of the recipient\n- `amount`: The amount to transfer (only used for ERC1155, default: 1)\n\nExample query to Claude:\n\n> \"Transfer my NFT with contract 0x3F06FcF75f45F1bb61D56D68fA7b3F32763AA15c and token ID 56090175025510453004781233574040052668718235229192064098345825090519343038548 to 0x1234567890abcdef1234567890abcdef12345678.\"\n\n### buy_openrouter_credits\n\nBuys OpenRouter credits with USDC.\n\nParameters:\n\n- `amountUsd`: The amount of credits to buy, in USD\n\nExample query to Claude:\n\n> \"Buy $20 worth of OpenRouter credits.\"\n\n## Security Considerations\n\n- The configuration file contains sensitive information (API keys and seed phrases). Ensure it's properly secured and not shared.\n- Consider using environment variables or a secure credential manager instead of hardcoding sensitive information.\n- Be cautious when transferring funds or deploying contracts, as these operations are irreversible on the blockchain.\n- When using the onramp functionality, ensure you're on a secure connection.\n- Verify all transaction details before confirming, especially when transferring funds or buying credits.\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Check that your Coinbase API credentials are correct\n2. Verify that your seed phrase is valid\n3. Ensure you're on the correct network (Base Mainnet)\n4. Check the Claude Desktop logs for any error messages\n\n## License\n\n[MIT License](LICENSE)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\nFor detailed guidelines on contributing to Base MCP, including:\n\n- Reporting bugs\n- Suggesting enhancements\n- Development setup\n- Coding standards\n- **Adding new tools, protocols, and data sources** (see also the [Extending Base MCP](#extending-base-mcp-with-3p-protocols-tools-and-data-sources) section above)\n- Testing requirements\n- Documentation standards\n\nPlease refer to our comprehensive [CONTRIBUTING.md](CONTRIBUTING.md) guide.\n\nBasic contribution steps:\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nPlease make sure your code follows the existing style and includes appropriate tests.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/base-mcp",
          "npm_downloads": 3264,
          "npm_package_name": "base-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "browserbase--mcp-server-browserbase": {
          "owner": "browserbase",
          "name": "mcp-server-browserbase",
          "url": "https://github.com/browserbase/mcp-server-browserbase",
          "imageUrl": "https://github.com/browserbase.png",
          "description": "Provides cloud browser automation capabilities, enabling interaction with web pages, taking screenshots, and executing JavaScript in a cloud browser environment.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:16.357897",
          "collection_timestamp": "2025-10-02T14:59:23.234113",
          "stars": 2679,
          "forks": 290,
          "license": "Apache License 2.0",
          "language": "TypeScript",
          "created_at": "2024-12-05T19:20:40Z",
          "updated_at": "2025-10-02T00:40:38Z",
          "open_issues": 15,
          "readme_content": "# Browserbase MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@browserbasehq/mcp-browserbase)](https://smithery.ai/server/@browserbasehq/mcp-browserbase)\n\n![cover](assets/cover-mcp.png)\n\n[The Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you're building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.\n\nThis server provides cloud browser automation capabilities using [Browserbase](https://www.browserbase.com/) and [Stagehand](https://github.com/browserbase/stagehand). It enables LLMs to interact with web pages, take screenshots, extract information, and perform automated actions with atomic precision.\n\n## Features\n\n| Feature            | Description                                                 |\n| ------------------ | ----------------------------------------------------------- |\n| Browser Automation | Control and orchestrate cloud browsers via Browserbase      |\n| Data Extraction    | Extract structured data from any webpage                    |\n| Web Interaction    | Navigate, click, and fill forms with ease                   |\n| Screenshots        | Capture full-page and element screenshots                   |\n| Model Flexibility  | Supports multiple models (OpenAI, Claude, Gemini, and more) |\n| Vision Support     | Use annotated screenshots for complex DOMs                  |\n| Session Management | Create, manage, and close browser sessions                  |\n| Multi-Session      | Run multiple browser sessions in parallel                   |\n\n## How to Setup\n\n### Quickstarts:\n\n#### Add to Cursor\n\nCopy and Paste this link in your Browser:\n\n```text\ncursor://anysphere.cursor-deeplink/mcp/install?name=browserbase&config=eyJjb21tYW5kIjoibnB4IEBicm93c2VyYmFzZWhxL21jcCIsImVudiI6eyJCUk9XU0VSQkFTRV9BUElfS0VZIjoiIiwiQlJPV1NFUkJBU0VfUFJPSkVDVF9JRCI6IiIsIkdFTUlOSV9BUElfS0VZIjoiIn19\n```\n\nWe currently support 2 transports for our MCP server, STDIO and SHTTP. We recommend you use SHTTP with our remote hosted url to take advantage of the server at full capacity.\n\n## SHTTP:\n\nTo use the Browserbase MCP Server through our remote hosted URL, add the following to your configuration.\n\nGo to [smithery.ai](https://smithery.ai/server/@browserbasehq/mcp-browserbase) and enter your API keys and configuration to get a remote hosted URL.\nWhen using our remote hosted server, we provide the LLM costs for Gemini, the [best performing model](https://www.stagehand.dev/evals) in [Stagehand](https://www.stagehand.dev).\n\n![Smithery Image](assets/smithery.jpg)\n\nIf your client supports SHTTP:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"url\": \"your-smithery-url.com\"\n    }\n  }\n}\n```\n\nIf your client doesn't support SHTTP:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote\", \"your-smithery-url.com\"]\n    }\n  }\n}\n```\n\n## STDIO:\n\nYou can either use our Server hosted on NPM or run it completely locally by cloning this repo.\n\n> **‚ùóÔ∏è Important:** If you want to use a different model you have to add --modelName to the args and provide that respective key as an arg. More info below.\n\n### To run on NPM (Recommended)\n\nGo into your MCP Config JSON and add the Browserbase Server:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"npx\",\n      \"args\": [\"@browserbasehq/mcp-server-browserbase\"],\n      \"env\": {\n        \"BROWSERBASE_API_KEY\": \"\",\n        \"BROWSERBASE_PROJECT_ID\": \"\",\n        \"GEMINI_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\nThat's it! Reload your MCP client and Claude will be able to use Browserbase.\n\n### To run 100% local:\n\n```bash\n# Clone the Repo\ngit clone https://github.com/browserbase/mcp-server-browserbase.git\ncd mcp-server-browserbase\n\n# Install the dependencies and build the project\nnpm install && npm run build\n```\n\nThen in your MCP Config JSON run the server. To run locally we can use STDIO or self-host SHTTP.\n\n### STDIO:\n\nTo your MCP Config JSON file add the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-server-browserbase/cli.js\"],\n      \"env\": {\n        \"BROWSERBASE_API_KEY\": \"\",\n        \"BROWSERBASE_PROJECT_ID\": \"\",\n        \"GEMINI_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\nThen reload your MCP client and you should be good to go!\n\n## Configuration\n\nThe Browserbase MCP server accepts the following command-line flags:\n\n| Flag                       | Description                                                                 |\n| -------------------------- | --------------------------------------------------------------------------- |\n| `--proxies`                | Enable Browserbase proxies for the session                                  |\n| `--advancedStealth`        | Enable Browserbase Advanced Stealth (Only for Scale Plan Users)             |\n| `--keepAlive`              | Enable Browserbase Keep Alive Session                                       |\n| `--contextId <contextId>`  | Specify a Browserbase Context ID to use                                     |\n| `--persist`                | Whether to persist the Browserbase context (default: true)                  |\n| `--port <port>`            | Port to listen on for HTTP/SHTTP transport                                  |\n| `--host <host>`            | Host to bind server to (default: localhost, use 0.0.0.0 for all interfaces) |\n| `--cookies [json]`         | JSON array of cookies to inject into the browser                            |\n| `--browserWidth <width>`   | Browser viewport width (default: 1024)                                      |\n| `--browserHeight <height>` | Browser viewport height (default: 768)                                      |\n| `--modelName <model>`      | The model to use for Stagehand (default: google/gemini-2.0-flash)           |\n| `--modelApiKey <key>`      | API key for the custom model provider (required when using custom models)   |\n| `--experimental`           | Enable experimental features (default: false)                               |\n\nThese flags can be passed directly to the CLI or configured in your MCP configuration file.\n\n### NOTE:\n\nCurrently, these flags can only be used with the local server (npx @browserbasehq/mcp-server-browserbase).\n\n## Configuration Examples\n\n### Proxies\n\nHere are our docs on [Proxies](https://docs.browserbase.com/features/proxies).\n\nTo use proxies, set the --proxies flag in your MCP Config:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"npx\",\n      \"args\": [\"@browserbasehq/mcp-server-browserbase\", \"--proxies\"],\n      \"env\": {\n        \"BROWSERBASE_API_KEY\": \"\",\n        \"BROWSERBASE_PROJECT_ID\": \"\",\n        \"GEMINI_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\n### Advanced Stealth\n\nHere are our docs on [Advanced Stealth](https://docs.browserbase.com/features/stealth-mode#advanced-stealth-mode).\n\nTo use advanced stealth, set the --advancedStealth flag in your MCP Config:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"npx\",\n      \"args\": [\"@browserbasehq/mcp-server-browserbase\", \"--advancedStealth\"],\n      \"env\": {\n        \"BROWSERBASE_API_KEY\": \"\",\n        \"BROWSERBASE_PROJECT_ID\": \"\",\n        \"GEMINI_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\n### Contexts\n\nHere are our docs on [Contexts](https://docs.browserbase.com/features/contexts)\n\nTo use contexts, set the --contextId flag in your MCP Config:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@browserbasehq/mcp-server-browserbase\",\n        \"--contextId\",\n        \"<YOUR_CONTEXT_ID>\"\n      ],\n      \"env\": {\n        \"BROWSERBASE_API_KEY\": \"\",\n        \"BROWSERBASE_PROJECT_ID\": \"\",\n        \"GEMINI_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\n### Browser Viewport Sizing\n\nThe default viewport sizing for a browser session is 1024 x 768. You can adjust the Browser viewport sizing with browserWidth and browserHeight flags.\n\nHere's how to use it for custom browser sizing. We recommend to stick with 16:9 aspect ratios (ie: 1920 x 1080, 1280 x 720, 1024 x 768)\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@browserbasehq/mcp-server-browserbase\",\n        \"--browserHeight 1080\",\n        \"--browserWidth 1920\"\n      ],\n      \"env\": {\n        \"BROWSERBASE_API_KEY\": \"\",\n        \"BROWSERBASE_PROJECT_ID\": \"\",\n        \"GEMINI_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\n### Model Configuration\n\nStagehand defaults to using Google's Gemini 2.0 Flash model, but you can configure it to use other models like GPT-4o, Claude, or other providers.\n\n**Important**: When using any custom model (non-default), you must provide your own API key for that model provider using the `--modelApiKey` flag.\n\nHere's how to configure different models:\n\n```json\n{\n  \"mcpServers\": {\n    \"browserbase\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@browserbasehq/mcp-server-browserbase\",\n        \"--modelName\",\n        \"anthropic/claude-3-5-sonnet-latest\",\n        \"--modelApiKey\",\n        \"your-anthropic-api-key\"\n      ],\n      \"env\": {\n        \"BROWSERBASE_API_KEY\": \"\",\n        \"BROWSERBASE_PROJECT_ID\": \"\"\n      }\n    }\n  }\n}\n```\n\n_Note: The model must be supported in Stagehand. Check out the docs [here](https://docs.stagehand.dev/examples/custom_llms#supported-llms). When using any custom model, you must provide your own API key for that provider._\n\n### Resources\n\nThe server provides access to screenshot resources:\n\n1. **Screenshots** (`screenshot://<screenshot-name>`)\n   - PNG images of captured screenshots\n\n## Key Features\n\n- **AI-Powered Automation**: Natural language commands for web interactions\n- **Multi-Model Support**: Works with OpenAI, Claude, Gemini, and more\n- **Advanced Session Management**: Single and multi-session support for parallel browser automation\n- **Screenshot Capture**: Full-page and element-specific screenshots\n- **Data Extraction**: Intelligent content extraction from web pages\n- **Proxy Support**: Enterprise-grade proxy capabilities\n- **Stealth Mode**: Advanced anti-detection features\n- **Context Persistence**: Maintain authentication and state across sessions\n- **Parallel Workflows**: Run multiple browser sessions simultaneously for complex automation tasks\n\nFor more information about the Model Context Protocol, visit:\n\n- [MCP Documentation](https://modelcontextprotocol.io/docs)\n- [MCP Specification](https://spec.modelcontextprotocol.io/)\n\nFor the official MCP Docs:\n\n- [Browserbase MCP](https://docs.browserbase.com/integrations/mcp/introduction)\n\n## License\n\nLicensed under the Apache 2.0 License.\n\nCopyright 2025 Browserbase, Inc.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "chargebee--agentkit": {
          "owner": "chargebee",
          "name": "agentkit",
          "url": "https://github.com/chargebee/agentkit",
          "imageUrl": "https://github.com/chargebee.png",
          "description": "Integrate Chargebee's API services and documentation directly into coding environments to enhance development efficiency. Provide context-aware code snippets and access to Chargebee's knowledge base for streamlined integration processes.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:17.217440",
          "collection_timestamp": "2025-10-02T14:59:27.146031",
          "stars": 13,
          "forks": 7,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-11T05:25:01Z",
          "updated_at": "2025-09-13T14:48:08Z",
          "open_issues": 3,
          "readme_content": "<p align=\"center\">\n  <img src=\"https://github.com/chargebee/agentkit/blob/main/media/cb-logo.png?raw=true\" alt=\"Chargebee Icon\" width=\"100\" height=\"100\">\n</p>\n\n# Chargebee AgentKit\n\nSeamlessly add Chargebee to your AI Agents using AgentKit for smarter billing and subscription workflows.\n\nAgentKit is a toolkit that enhances AI applications like Claude, Cursor and other agentic AI applications with Chargebee capabilities. It enables users across different roles to integrate their solutions with Chargebee and manage simplifying billing and subscription management using AI.\n\n### Packages\n\n- **[MCP Server](modelcontextprotocol/README.md):** The Chargebee MCP Server provides a powerful set of tools to enhance developer productivity. It integrates with AI-powered code editors like Cursor, Windsurf, and Cline, as well as general-purpose tools such as Claude Desktop.\n\n## Contribution\n\nTo contribute to this project, please see the [contribution guide](CONTRIBUTING.md).\n\n## License\n\n[MIT](LICENSE)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/agentkit",
          "npm_downloads": 131,
          "npm_package_name": "agentkit",
          "npm_success": true,
          "npm_error": null
        },
        "chroma-core--chroma-mcp": {
          "owner": "chroma-core",
          "name": "chroma-mcp",
          "url": "https://github.com/chroma-core/chroma-mcp",
          "imageUrl": "https://github.com/chroma-core.png",
          "description": "Integrates vector database capabilities for managing collections, performing semantic searches, and retrieving data with advanced filtering. Enhances AI models with powerful data retrieval features to improve context and performance.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:18.108324",
          "collection_timestamp": "2025-10-02T14:59:34.366567",
          "stars": 374,
          "forks": 68,
          "license": "Apache License 2.0",
          "language": "Python",
          "created_at": "2025-02-11T00:23:22Z",
          "updated_at": "2025-10-01T14:17:21Z",
          "open_issues": 13,
          "readme_content": "<p align=\"center\">\n  <a href=\"https://trychroma.com\"><img src=\"https://user-images.githubusercontent.com/891664/227103090-6624bf7d-9524-4e05-9d2c-c28d5d451481.png\" alt=\"Chroma logo\"></a>\n</p>\n\n<p align=\"center\">\n    <b>Chroma - the open-source embedding database</b>. <br />\n    The fastest way to build Python or JavaScript LLM apps with memory!\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/MMeYNTmh3x\" target=\"_blank\">\n      <img src=\"https://img.shields.io/discord/1073293645303795742?cacheSeconds=3600\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/chroma-core/chroma/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=license&message=Apache 2.0&color=white\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.trychroma.com/\" target=\"_blank\">\n      Docs\n  </a> |\n  <a href=\"https://www.trychroma.com/\" target=\"_blank\">\n      Homepage\n  </a>\n</p>\n\n# Chroma MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@chroma-core/chroma-mcp)](https://smithery.ai/server/@chroma-core/chroma-mcp)\n\n[The Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol designed for effortless integration between LLM applications and external data sources or tools, offering a standardized framework to seamlessly provide LLMs with the context they require.\n\nThis server provides data retrieval capabilities powered by Chroma, enabling AI models to create collections over generated data and user inputs, and retrieve that data using vector search, full text search, metadata filtering, and more.\n\nThis is a MCP server for self-hosting your access to Chroma. If you are looking for [Package Search](https://www.trychroma.com/package-search) you can find the repository for that [here](https://github.com/chroma-core/package-search).\n\n## Features\n\n- **Flexible Client Types**\n  - Ephemeral (in-memory) for testing and development\n  - Persistent for file-based storage\n  - HTTP client for self-hosted Chroma instances\n  - Cloud client for Chroma Cloud integration (automatically connects to api.trychroma.com)\n\n- **Collection Management**\n  - Create, modify, and delete collections\n  - List all collections with pagination support\n  - Get collection information and statistics\n  - Configure HNSW parameters for optimized vector search\n  - Select embedding functions when creating collections\n\n- **Document Operations**\n  - Add documents with optional metadata and custom IDs\n  - Query documents using semantic search\n  - Advanced filtering using metadata and document content\n  - Retrieve documents by IDs or filters\n  - Full text search capabilities\n\n### Supported Tools\n\n- `chroma_list_collections` - List all collections with pagination support\n- `chroma_create_collection` - Create a new collection with optional HNSW configuration\n- `chroma_peek_collection` - View a sample of documents in a collection\n- `chroma_get_collection_info` - Get detailed information about a collection\n- `chroma_get_collection_count` - Get the number of documents in a collection\n- `chroma_modify_collection` - Update a collection's name or metadata\n- `chroma_delete_collection` - Delete a collection\n- `chroma_add_documents` - Add documents with optional metadata and custom IDs\n- `chroma_query_documents` - Query documents using semantic search with advanced filtering\n- `chroma_get_documents` - Retrieve documents by IDs or filters with pagination\n- `chroma_update_documents` - Update existing documents' content, metadata, or embeddings\n- `chroma_delete_documents` - Delete specific documents from a collection\n\n### Embedding Functions\nChroma MCP supports several embedding functions: `default`, `cohere`, `openai`, `jina`, `voyageai`, and `roboflow`.\n\nThe embedding functions utilize Chroma's collection configuration, which persists the selected embedding function of a collection for retrieval. Once a collection is created using the collection configuration, on retrieval for future queries and inserts, the same embedding function will be used, without needing to specify the embedding function again. Embedding function persistance was added in v1.0.0 of Chroma, so if you created a collection using version <=0.6.3, this feature is not supported.\n\nWhen accessing embedding functions that utilize external APIs, please be sure to add the environment variable for the API key with the correct format, found in [Embedding Function Environment Variables](#embedding-function-environment-variables)\n\n## Usage with Claude Desktop\n\n1. To add an ephemeral client, add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"chroma-mcp\"\n    ]\n}\n```\n\n2. To add a persistent client, add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"chroma-mcp\",\n        \"--client-type\",\n        \"persistent\",\n        \"--data-dir\",\n        \"/full/path/to/your/data/directory\"\n    ]\n}\n```\n\nThis will create a persistent client that will use the data directory specified.\n\n3. To connect to Chroma Cloud, add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"chroma-mcp\",\n        \"--client-type\",\n        \"cloud\",\n        \"--tenant\",\n        \"your-tenant-id\",\n        \"--database\",\n        \"your-database-name\",\n        \"--api-key\",\n        \"your-api-key\"\n    ]\n}\n```\n\nThis will create a cloud client that automatically connects to api.trychroma.com using SSL.\n\n**Note:** Adding API keys in arguments is fine on local devices, but for safety, you can also specify a custom path for your environment configuration file using the `--dotenv-path` argument within the `args` list, for example: `\"args\": [\"chroma-mcp\", \"--dotenv-path\", \"/custom/path/.env\"]`.\n\n4. To connect to a [self-hosted Chroma instance on your own cloud provider](https://docs.trychroma.com/\nproduction/deployment), add the following to your `claude_desktop_config.json` file:\n\n```json\n\"chroma\": {\n    \"command\": \"uvx\",\n    \"args\": [\n      \"chroma-mcp\", \n      \"--client-type\", \n      \"http\", \n      \"--host\", \n      \"your-host\", \n      \"--port\", \n      \"your-port\", \n      \"--custom-auth-credentials\",\n      \"your-custom-auth-credentials\",\n      \"--ssl\",\n      \"true\"\n    ]\n}\n```\n\nThis will create an HTTP client that connects to your self-hosted Chroma instance.\n\n### Demos\n\nFind reference usages, such as shared knowledge bases & adding memory to context windows in the [Chroma MCP Docs](https://docs.trychroma.com/integrations/frameworks/anthropic-mcp#using-chroma-with-claude)\n\n### Using Environment Variables\n\nYou can also use environment variables to configure the client. The server will automatically load variables from a `.env` file located at the path specified by `--dotenv-path` (defaults to `.chroma_env` in the working directory) or from system environment variables. Command-line arguments take precedence over environment variables.\n\n```bash\n# Common variables\nexport CHROMA_CLIENT_TYPE=\"http\"  # or \"cloud\", \"persistent\", \"ephemeral\"\n\n# For persistent client\nexport CHROMA_DATA_DIR=\"/full/path/to/your/data/directory\"\n\n# For cloud client (Chroma Cloud)\nexport CHROMA_TENANT=\"your-tenant-id\"\nexport CHROMA_DATABASE=\"your-database-name\"\nexport CHROMA_API_KEY=\"your-api-key\"\n\n# For HTTP client (self-hosted)\nexport CHROMA_HOST=\"your-host\"\nexport CHROMA_PORT=\"your-port\"\nexport CHROMA_CUSTOM_AUTH_CREDENTIALS=\"your-custom-auth-credentials\"\nexport CHROMA_SSL=\"true\"\n\n# Optional: Specify path to .env file (defaults to .chroma_env)\nexport CHROMA_DOTENV_PATH=\"/path/to/your/.env\" \n```\n\n#### Embedding Function Environment Variables\nWhen using external embedding functions that access an API key, follow the naming convention\n`CHROMA_<>_API_KEY=\"<key>\"`.\nSo to set a Cohere API key, set the environment variable `CHROMA_COHERE_API_KEY=\"\"`. We recommend adding this to a .env file somewhere and using the `CHROMA_DOTENV_PATH` environment variable or `--dotenv-path` flag to set that location for safekeeping.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "cloudflare--mcp-server-cloudflare": {
          "owner": "cloudflare",
          "name": "mcp-server-cloudflare",
          "url": "https://github.com/cloudflare/mcp-server-cloudflare",
          "imageUrl": "https://github.com/cloudflare.png",
          "description": "Interact with Cloudflare services including deploying Workers, managing KV Store, handling R2 Storage, executing SQL queries in D1 databases, and retrieving analytics data.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:18.968164",
          "collection_timestamp": "2025-10-02T14:59:39.990814",
          "stars": 2989,
          "forks": 258,
          "license": "Apache License 2.0",
          "language": "TypeScript",
          "created_at": "2024-11-27T22:07:30Z",
          "updated_at": "2025-10-02T03:18:27Z",
          "open_issues": 29,
          "readme_content": "# Cloudflare MCP Server\n\nModel Context Protocol (MCP) is a [new, standardized protocol](https://modelcontextprotocol.io/introduction) for managing context between large language models (LLMs) and external systems. In this repository, you can find several MCP servers allowing you to connect to Cloudflare's service from an MCP client (e.g. Cursor, Claude) and use natural language to accomplish tasks through your Cloudflare account.\n\nThese MCP servers allow your [MCP Client](https://modelcontextprotocol.io/clients) to read configurations from your account, process information, make suggestions based on data, and even make those suggested changes for you. All of these actions can happen across Cloudflare's many services including application development, security and performance.\n\nThe following servers are included in this repository:\n\n| Server Name                                                    | Description                                                                                     | Server URL                                     |\n| -------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | ---------------------------------------------- |\n| [**Documentation server**](/apps/docs-vectorize)               | Get up to date reference information on Cloudflare                                              | `https://docs.mcp.cloudflare.com/sse`          |\n| [**Workers Bindings server**](/apps/workers-bindings)          | Build Workers applications with storage, AI, and compute primitives                             | `https://bindings.mcp.cloudflare.com/sse`      |\n| [**Workers Builds server**](/apps/workers-builds)              | Get insights and manage your Cloudflare Workers Builds                                          | `https://builds.mcp.cloudflare.com/sse`        |\n| [**Observability server**](/apps/workers-observability)        | Debug and get insight into your application's logs and analytics                                | `https://observability.mcp.cloudflare.com/sse` |\n| [**Radar server**](/apps/radar)                                | Get global Internet traffic insights, trends, URL scans, and other utilities                    | `https://radar.mcp.cloudflare.com/sse`         |\n| [**Container server**](/apps/sandbox-container)                | Spin up a sandbox development environment                                                       | `https://containers.mcp.cloudflare.com/sse`    |\n| [**Browser rendering server**](/apps/browser-rendering)        | Fetch web pages, convert them to markdown and take screenshots                                  | `https://browser.mcp.cloudflare.com/sse`       |\n| [**Logpush server**](/apps/logpush)                            | Get quick summaries for Logpush job health                                                      | `https://logs.mcp.cloudflare.com/sse`          |\n| [**AI Gateway server**](/apps/ai-gateway)                      | Search your logs, get details about the prompts and responses                                   | `https://ai-gateway.mcp.cloudflare.com/sse`    |\n| [**AutoRAG server**](/apps/autorag)                            | List and search documents on your AutoRAGs                                                      | `https://autorag.mcp.cloudflare.com/sse`       |\n| [**Audit Logs server**](/apps/auditlogs)                       | Query audit logs and generate reports for review                                                | `https://auditlogs.mcp.cloudflare.com/sse`     |\n| [**DNS Analytics server**](/apps/dns-analytics)                | Optimize DNS performance and debug issues based on current set up                               | `https://dns-analytics.mcp.cloudflare.com/sse` |\n| [**Digital Experience Monitoring server**](/apps/dex-analysis) | Get quick insight on critical applications for your organization                                | `https://dex.mcp.cloudflare.com/sse`           |\n| [**Cloudflare One CASB server**](/apps/cloudflare-one-casb)    | Quickly identify any security misconfigurations for SaaS applications to safeguard users & data | `https://casb.mcp.cloudflare.com/sse`          |\n| [**GraphQL server**](/apps/graphql/)                           | Get analytics data using Cloudflare‚Äôs GraphQL API                                               | `https://graphql.mcp.cloudflare.com/sse`       |\n\n## Access the remote MCP server from any MCP client\n\nIf your MCP client has first class support for remote MCP servers, the client will provide a way to accept the server URL directly within its interface (e.g. [Cloudflare AI Playground](https://playground.ai.cloudflare.com/))\n\nIf your client does not yet support remote MCP servers, you will need to set up its respective configuration file using mcp-remote (https://www.npmjs.com/package/mcp-remote) to specify which servers your client can access.\n\n```json\n{\n\t\"mcpServers\": {\n\t\t\"cloudflare-observability\": {\n\t\t\t\"command\": \"npx\",\n\t\t\t\"args\": [\"mcp-remote\", \"https://observability.mcp.cloudflare.com/sse\"]\n\t\t},\n\t\t\"cloudflare-bindings\": {\n\t\t\t\"command\": \"npx\",\n\t\t\t\"args\": [\"mcp-remote\", \"https://bindings.mcp.cloudflare.com/sse\"]\n\t\t}\n\t}\n}\n```\n\n## Using Cloudflare's MCP servers from the OpenAI Responses API\n\nTo use one of Cloudflare's MCP servers with [OpenAI's responses API](https://openai.com/index/new-tools-and-features-in-the-responses-api/), you will need to provide the Responses API with an API token that has the scopes (permissions) required for that particular MCP server.\n\nFor example, to use the [Browser Rendering MCP server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/browser-rendering) with OpenAI, create an API token in the Cloudflare dashboard [here](https://dash.cloudflare.com/profile/api-tokens), with the following permissions:\n\n<img width=\"937\" alt=\"Screenshot 2025-05-21 at 10 38 02‚ÄØAM\" src=\"https://github.com/user-attachments/assets/872e253f-23ce-43b3-983c-45f9d0f66100\" />\n\n## Need access to more Cloudflare tools?\n\nWe're continuing to add more functionality to this remote MCP server repo. If you'd like to leave feedback, file a bug or provide a feature request, [please open an issue](https://github.com/cloudflare/mcp-server-cloudflare/issues/new/choose) on this repository\n\n## Troubleshooting\n\n\"Claude's response was interrupted ... \"\n\nIf you see this message, Claude likely hit its context-length limit and stopped mid-reply. This happens most often on servers that trigger many chained tool calls such as the observability server.\n\nTo reduce the chance of running in to this issue:\n\n- Try to be specific, keep your queries concise.\n- If a single request calls multiple tools, try to to break it into several smaller tool calls to keep the responses short.\n\n## Paid Features\n\nSome features may require a paid Cloudflare Workers plan. Ensure your Cloudflare account has the necessary subscription level for the features you intend to use.\n\n## Contributing\n\nInterested in contributing, and running this server locally? See [CONTRIBUTING.md](CONTRIBUTING.md) to get started.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/@cloudflare/mcp-server-cloudflare",
          "npm_downloads": 63925,
          "npm_package_name": "@cloudflare/mcp-server-cloudflare",
          "npm_success": true,
          "npm_error": null
        },
        "comet-ml--opik-mcp": {
          "owner": "comet-ml",
          "name": "opik-mcp",
          "url": "https://github.com/comet-ml/opik-mcp",
          "imageUrl": "https://github.com/comet-ml.png",
          "description": "Integrates with IDEs to provide access to Opik features via a standardized protocol. Facilitates the management of prompts, projects, and metrics with a unified interface and various transport options for flexible integration.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:19.878155",
          "collection_timestamp": "2025-10-02T14:59:43.633123",
          "stars": 172,
          "forks": 26,
          "license": "Apache License 2.0",
          "language": "TypeScript",
          "created_at": "2025-03-11T16:31:03Z",
          "updated_at": "2025-10-02T01:32:29Z",
          "open_issues": 29,
          "readme_content": "<h1 align=\"center\" style=\"border-bottom: none\">\n    <div>\n        <a href=\"https://www.comet.com/site/products/opik/?from=llm&utm_source=opik&utm_medium=github&utm_content=header_img&utm_campaign=opik-mcp\">\n            <picture>\n                <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/comet-ml/opik-mcp/refs/heads/main/docs/assets/logo-dark-mode.svg\">\n                <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/comet-ml/opik-mcp/refs/heads/main/docs/assets/logo-light-mode.svg\">\n                <img alt=\"Comet Opik logo\" src=\"docs/assets/logo-light-mode.svg\" width=\"200\" />\n            </picture>\n        </a>\n        <br>\n        Opik MCP Server\n    </div>\n    (Model Context Protocol)<br>\n</h1>\n\n<p align=\"center\">\nA Model Context Protocol (MCP) implementation for the <a href=\"https://github.com/comet-ml/opik/\">Opik platform</a> with support for multiple transport mechanisms, enabling seamless integration with IDEs and providing a unified interface for Opik's capabilities.\n</p>\n\n<div align=\"center\">\n\n[![License](https://img.shields.io/github/license/comet-ml/opik-mcp)](https://github.com/comet-ml/opik-mcp/blob/main/LICENSE)\n[![Node.js Version](https://img.shields.io/badge/node-%3E%3D20.11.0-brightgreen)](https://nodejs.org/)\n[![TypeScript](https://img.shields.io/badge/typescript-%5E5.8.2-blue)](https://www.typescriptlang.org/)\n<img src=\"https://badge.mcpx.dev?status=on\" title=\"MCP Enabled\"/>\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15411156.svg)](https://doi.org/10.5281/zenodo.15411156)\n\n</div>\n\n<p align=\"center\">\n    <a href=\"https://www.comet.com/site/products/opik/?from=llm&utm_source=opik&utm_medium=github&utm_content=website_button&utm_campaign=opik\"><b>Website</b></a> ‚Ä¢\n    <a href=\"https://chat.comet.com\"><b>Slack community</b></a> ‚Ä¢\n    <a href=\"https://x.com/Cometml\"><b>Twitter</b></a> ‚Ä¢\n    <a href=\"https://www.comet.com/docs/opik/?from=llm&utm_source=opik&utm_medium=github&utm_content=docs_button&utm_campaign=opik\"><b>Documentation</b></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://glama.ai/mcp/servers/@comet-ml/opik-mcp\" rel=\"nofollow\" target=\"_blank\">\n      <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@comet-ml/opik-mcp/badge\" alt=\"Opik Server MCP server\" />\n    </a>\n</p>\n\n> **‚ö†Ô∏è Notice:** SSE (Server-Sent Events) transport support is currently experimental and untested. For production use, we recommend using the direct process execution approach shown in the IDE integration examples.\n\n## üöÄ What is Opik MCP Server?\n\nOpik MCP Server is an open-source implementation of the Model Context Protocol for the Opik platform. It provides a unified interface for interacting with Opik's capabilities, supporting multiple transport mechanisms for flexible integration into various environments.\n\n<br>\n\nYou can use Opik MCP Server for:\n* **IDE Integration:**\n  * Seamlessly integrate with Cursor and other compatible IDEs\n  * Provide direct access to Opik's capabilities from your development environment\n\n* **Unified API Access:**\n  * Access all Opik features through a standardized protocol\n  * Leverage multiple transport options (stdio, SSE) for different integration scenarios\n\n* **Platform Management:**\n  * Manage prompts, projects, traces, and metrics through a consistent interface\n  * Organize and monitor your LLM applications efficiently\n\n## Features\n\n- **Prompts Management**: Create, list, update, and delete prompts\n- **Projects/Workspaces Management**: Organize and manage projects\n- **Traces**: Track and analyze trace data\n- **Metrics**: Gather and query metrics data\n\n## Quick Start\n\n### Installation\n\n#### Cursor Integration\n\nTo integrate with Cursor IDE, open to the Cursor settings page and navigate\nto the Features tab. If you scroll down to the MCP section you will see the\nbutton `+ Add new MCP server` that will allow you to add the Opik MCP server.\n\nOnce the `New MCP server` modal is open, select `command` as the server type and\nenter the command: `npx -y opik-mcp --apiKey YOUR_API_KEY`.\n\nAlternatively, you can create a `.cursor/mcp.json` in your project and add:\n\n```json\n{\n  \"mcpServers\": {\n    \"opik\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"opik-mcp\",\n        \"--apiKey\",\n        \"YOUR_API_KEY\"\n      ]\n    }\n  }\n}\n```\n\nNote: If you are using the Open-Source version of Opik, you will need to specify\nthe `apiBaseUrl` parameter as `http://localhost:5173/api`.\n\n#### Windsurf Installation\n\nTo install the MCP server in Windsurf, you will need to open the Windsurf settings\nand navigate to the MCP section. From there, click on `View raw config` and update\nthe configuration object to be:\n\n```json\n{\n    \"mcpServers\": {\n      \"opik\": {\n        \"command\": \"npx\",\n        \"args\": [\n          \"-y\",\n          \"opik-mcp\",\n          \"--apiKey\",\n          \"YOUR_API_KEY\"\n        ]\n      }\n    }\n  }\n```\n\nNote: If you are using the Open-Source version of Opik, you will need to specify\nthe `apiBaseUrl` parameter as `http://localhost:5173/api`.\n\n#### Manual Installation\n```bash\n# Clone the repository\ngit clone https://github.com/comet-ml/opik-mcp.git\ncd opik-mcp\n\n# Install dependencies and build\nnpm install\nnpm run build\n```\n\n**Configuration**\n\nCreate a `.env` file based on the example:\n\n```bash\ncp .env.example .env\n# Edit .env with your specific configuration\n```\n\n**Starting the Server**\n\n```bash\n# Start with stdio transport (default)\nnpm run start:stdio\n\n# Start with SSE transport for network access (experimental)\nnpm run start:sse\n```\n\n## Transport Options\n\n### Standard Input/Output\n\nIdeal for local integration where the client and server run on the same machine.\n\n```bash\nmake start-stdio\n```\n\n### Server-Sent Events (SSE)\n\nEnables remote access and multiple simultaneous clients over HTTP. Note that this transport option is experimental.\n\n```bash\nmake start-sse\n```\n\nFor detailed information about the SSE transport, see [docs/sse-transport.md](docs/sse-transport.md).\n\n## Development\n\n### Testing\n\n```bash\n# Run all tests\nnpm test\n\n# Run specific test suite\nnpm test -- tests/transports/sse-transport.test.ts\n```\n\n### Pre-commit Hooks\n\nThis project uses pre-commit hooks to ensure code quality:\n\n```bash\n# Run pre-commit checks manually\nmake precommit\n```\n\n## Documentation\n\n- [SSE Transport](docs/sse-transport.md) - Details on using the SSE transport\n- [API Reference](docs/api-reference.md) - Complete API documentation\n- [Configuration](docs/configuration.md) - Advanced configuration options\n- [IDE Integration](docs/ide-integration.md) - Integration with Cursor IDE\n\n## Citation\n\nIf you use this project in your research, please cite it as follows:\n\n```\nComet ML, Inc, Koc, V., & Boiko, Y. (2025). Opik MCP Server. Github. https://doi.org/10.5281/zenodo.15411156\n```\n\nOr use the following BibTeX entry:\n\n```bibtex\n@software{CometML_Opik_MCP_Server_2025,\n  author = {{Comet ML, Inc} and Koc, V. and Boiko, Y.},\n  title = {{Opik MCP Server}},\n  year = {2025},\n  publisher = {GitHub},\n  url = {https://doi.org/10.5281/zenodo.15411156},\n  doi = {10.5281/zenodo.15411156}\n}\n```\n\nYou can also find citation information in the `CITATION.cff` file in this repository.\n\n## License\n\nApache 2.0\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/opik-mcp",
          "npm_downloads": 2065,
          "npm_package_name": "opik-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "devhub--devhub-cms-mcp": {
          "owner": "devhub",
          "name": "devhub-cms-mcp",
          "url": "https://github.com/devhub/devhub-cms-mcp",
          "imageUrl": "https://github.com/devhub.png",
          "description": "Manage content within the DevHub CMS system, allowing for the creation, updating, and retrieval of blog posts and media through an intuitive interface. Integrates with Large Language Models to enhance content management tasks without direct API integration.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:20.711258",
          "collection_timestamp": "2025-10-02T14:59:51.003030",
          "stars": 6,
          "forks": 12,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-03-17T15:17:03Z",
          "updated_at": "2025-09-22T12:49:55Z",
          "open_issues": 3,
          "readme_content": "# DevHub CMS MCP\n\n[![smithery badge](https://smithery.ai/badge/@devhub/devhub-cms-mcp)](https://smithery.ai/server/@devhub/devhub-cms-mcp)\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) integration for managing content in the [DevHub CMS system](https://www.devhub.com/).\n\n## Installation\n\nYou will need the [uv](https://github.com/astral-sh/uv) package manager installed on your local system.\n\n### Manual configuration of Claude Desktop\n\nTo use this server with the [Claude Desktop app](https://claude.ai/download), add the following configuration to the \"mcpServers\" section of your `claude_desktop_config.json`:\n\n```\n{\n    \"mcpServers\": {\n        \"devhub_cms_mcp\": {\n            \"command\": \"uvx\",\n            \"args\": [\n                \"devhub-cms-mcp\"\n            ],\n            \"env\": {\n                \"DEVHUB_API_KEY\": \"YOUR_KEY_HERE\",\n                \"DEVHUB_API_SECRET\": \"YOUR_SECRET_HERE\",\n                \"DEVHUB_BASE_URL\": \"https://yourbrand.cloudfrontend.net\"\n            }\n        }\n    }\n}\n```\n\nAfter updating the config, restart Claude Desktop.\n\n### Manual configuration for Cursor\n\nThis MCP can also be used in cursor with a similar configuration from above added to your [Cursor](https://www.cursor.com/) global environment or to individual projects.\n\nExamples [here](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers)\n\n### Installing via Claude Code\n\nClaude Code's command line [supports MCP installs](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutorials#set-up-model-context-protocol-mcp).\n\nYou can add the `devhub-cms-mcp` by updating the environment variables below\n\n```\nclaude mcp add devhub-cms-mcp \\\n    -e DEVHUB_API_KEY=YOUR_KEY_HERE \\\n    -e DEVHUB_API_SECRET=YOUR_SECRET_HERE \\\n    -e DEVHUB_BASE_URL=https://yourbrand.cloudfrontend.net \\\n    -- uvx devhub-cms-mcp\n```\n\n### Installing via Smithery\n\nTo install DevHub CMS MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@devhub/devhub-cms-mcp):\n\n```bash\nnpx -y @smithery/cli install @devhub/devhub-cms-mcp --client claude\n```\n\n## Local development\n\n### Clone the repo (or your fork)\n\n```\ngit clone git@github.com:devhub/devhub-cms-mcp.git\n```\n\n### Manual configuration of Claude Desktop\n\nTo use this server with the Claude Desktop app for local development, add the following configuration to the \"mcpServers\" section of your `claude_desktop_config.json`:\n\n```\n{\n    \"mcpServers\": {\n        \"devhub_cms_mcp\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/YOUR/LOCAL/PATH/devhub-cms-mcp/\",\n                \"run\",\n                \"main.py\"\n            ],\n            \"env\": {\n                \"DEVHUB_API_KEY\": \"YOUR_KEY_HERE\",\n                \"DEVHUB_API_SECRET\": \"YOUR_SECRET_HERE\",\n                \"DEVHUB_BASE_URL\": \"https://yourbrand.cloudfrontend.net\"\n            }\n        }\n    }\n}\n```\n\nAfter updating the config, restart Claude Desktop.\n\n### Configuration for running with `uv` directly\n\nThis MCP requires the following environment variables to be set:\n\n```bash\nexport DEVHUB_API_KEY=\"your_api_key\"\nexport DEVHUB_API_SECRET=\"your_api_secret\"\nexport DEVHUB_BASE_URL=\"https://yourbrand.cloudfrontend.net\"\n```\n\nThen run the MCP\n\n```\nuv run main.py\n```\n\n## Available Tools\n\nThis MCP provides the following tools for interacting with DevHub CMS:\n\n### Business and Location Management\n\n- **get_businesses()**: Gets all businesses within the DevHub account. Returns a list of businesses with their IDs and names.\n- **get_locations(business_id)**: Gets all locations for a specific business. Returns detailed location information including address, coordinates, and URLs.\n- **get_hours_of_operation(location_id, hours_type='primary')**: Gets the hours of operation for a specific DevHub location. Returns a structured list of time ranges for each day of the week.\n- **update_hours(location_id, new_hours, hours_type='primary')**: Updates the hours of operation for a DevHub location.\n- **get_nearest_location(business_id, latitude, longitude)**: Finds the nearest DevHub location based on geographic coordinates.\n- **site_from_url(url)**: Gets the DevHub site ID and details from a URL. Returns site ID, URL, and associated location IDs.\n\n### Content Management\n\n- **get_blog_post(post_id)**: Retrieves a single blog post by ID, including its title, date, and HTML content.\n- **create_blog_post(site_id, title, content)**: Creates a new blog post. The content should be in HTML format and should not include an H1 tag.\n- **update_blog_post(post_id, title=None, content=None)**: Updates an existing blog post's title and/or content.\n\n### Media Management\n\n- **upload_image(base64_image_content, filename)**: Uploads an image to the DevHub media gallery. Supports webp, jpeg, and png formats. The image must be provided as a base64-encoded string.\n\n## Usage with LLMs\n\nThis MCP is designed to be used with Large Language Models that support the Model Context Protocol. It allows LLMs to manage content in DevHub CMS without needing direct API access integrated into the LLM natively.\n\n## Testing\n\nThis package includes a test suite with mocked requests to the DevHub API, allowing you to test the functionality without making actual API calls.\n\n### Running Tests\n\nTo run the tests, first install the package with test dependencies:\n\n```bash\nuv pip install -e \".[test]\"\n```\n\nRun the tests with pytest:\n\n```bash\nuv run pytest\n```\n\nFor more detailed output and test coverage information:\n\n```bash\nuv run pytest -v --cov=devhub_cms_mcp\n```\n\n### Test Structure\n\n- `tests/devhub_cms_mcp/test_mcp_integration.py`: Tests for MCP integration endpoints\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "exa-labs--exa-mcp-server": {
          "owner": "exa-labs",
          "name": "exa-mcp-server",
          "url": "https://github.com/exa-labs/exa-mcp-server",
          "imageUrl": "https://github.com/exa-labs.png",
          "description": "Fast and intelligent web search and crawling that combines embeddings and traditional search methods to provide optimal results for large language models (LLMs). It facilitates real-time web information retrieval in a secure environment.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:21.689120",
          "collection_timestamp": "2025-10-02T14:59:54.748697",
          "stars": 2791,
          "forks": 216,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2024-11-27T23:38:35Z",
          "updated_at": "2025-10-02T09:12:40Z",
          "open_issues": 26,
          "readme_content": "# Exa MCP Server üîç\n[![npm version](https://badge.fury.io/js/exa-mcp-server.svg)](https://www.npmjs.com/package/exa-mcp-server)\n[![smithery badge](https://smithery.ai/badge/exa)](https://smithery.ai/server/exa)\n\n## üÜï `exa-code`: fast, efficient web context for coding agents\n\nVibe coding should never have a bad vibe. `exa-code` is a huge step towards coding agents that never hallucinate.\n\nWhen your coding agent makes a search query, `exa-code` searches over billions\nof Github repos, docs pages, Stackoverflow posts, and more, to find the perfect, token-efficient context that the agent needs to code correctly. It's powered by the Exa search engine.\n\nExamples of queries you can make with `exa-code`:\n* use Exa search in python and make sure content is always livecrawled\n* use correct syntax for vercel ai sdk to call gpt-5 nano asking it how are you\n* how to set up a reproducible Nix Rust development environment\n\n**‚ú® Works with Cursor and Claude Code!** Use the HTTP-based configuration format:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.exa.ai/mcp\",\n      \"headers\": {\n        \"Remove-Me\": \"Disable web_search_exa tool if you're just coding. To 100% call exa-code, say 'use exa-code'.\"\n      }\n    }\n  }\n}\n```\n\nYou may include your exa api key in the url like this:\n```\nhttps://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY\n```\n\nYou may whitelist specific tools in the url with the `enabledTools` parameter which expects a url encoded array strings like this:\n```\nhttps://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY&enabledTools=%5B%22crawling_exa%ss%5D\n```\n\nYou can also use `exa-code` through [Smithery](https://smithery.ai/server/exa) without an Exa API key.\n\n---\n\nA Model Context Protocol (MCP) server that connects AI assistants like Claude to Exa AI's search capabilities, including web search, research tools, and our new code search feature.\n\n## Remote Exa MCP üåê\n\nConnect directly to Exa's hosted MCP server (instead of running it locally).\n\n### Remote Exa MCP URL\n\n```\nhttps://mcp.exa.ai/mcp\n```\n\n### Claude Desktop Configuration for Remote MCP\n\nAdd this to your Claude Desktop configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-remote\",\n        \"https://mcp.exa.ai/mcp\"\n      ]\n    }\n  }\n}\n```\n\n### Cursor and Claude Code Configuration for Remote MCP\n\nFor Cursor and Claude Code, use this HTTP-based configuration format:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.exa.ai/mcp\",\n      \"headers\": {}\n    }\n  }\n}\n```\n\n### NPM Installation\n\n```bash\nnpm install -g exa-mcp-server\n```\n\n### Using Claude Code\n\n```bash\nclaude mcp add exa -e EXA_API_KEY=YOUR_API_KEY -- npx -y exa-mcp-server\n```\n\n### Using Exa MCP through Smithery\n\nTo install the Exa MCP server via [Smithery](https://smithery.ai/server/exa), head over to:\n\n[smithery.ai/server/exa](https://smithery.ai/server/exa)\n\n\n## Configuration ‚öôÔ∏è\n\n### 1. Configure Claude Desktop to recognize the Exa MCP server\n\nYou can find claude_desktop_config.json inside the settings of Claude Desktop app:\n\nOpen the Claude Desktop app and enable Developer Mode from the top-left menu bar. \n\nOnce enabled, open Settings (also from the top-left menu bar) and navigate to the Developer Option, where you'll find the Edit Config button. Clicking it will open the claude_desktop_config.json file, allowing you to make the necessary edits. \n\nOR (if you want to open claude_desktop_config.json from terminal)\n\n#### For macOS:\n\n1. Open your Claude Desktop configuration:\n\n```bash\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n#### For Windows:\n\n1. Open your Claude Desktop configuration:\n\n```powershell\ncode %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n### 2. Add the Exa server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"exa-mcp-server\"],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nReplace `your-api-key-here` with your actual Exa API key from [dashboard.exa.ai/api-keys](https://dashboard.exa.ai/api-keys).\n\n### 3. Available Tools & Tool Selection\n\nThe Exa MCP server includes powerful tools for developers and researchers:\n\n#### üî• **Featured: Code Search Tool**\n- **get_code_context_exa**: üÜï **NEW!** Search and get relevant code snippets, examples, and documentation from open source libraries, GitHub repositories, and programming frameworks. Perfect for finding up-to-date code documentation, implementation examples, API usage patterns, and best practices from real codebases.\n\n#### üåê **Other Available Tools**\n- **web_search_exa**: Performs real-time web searches with optimized results and content extraction.\n- **company_research**: Comprehensive company research tool that crawls company websites to gather detailed information about businesses.\n- **crawling**: Extracts content from specific URLs, useful for reading articles, PDFs, or any web page when you have the exact URL.\n- **linkedin_search**: Search LinkedIn for companies and people using Exa AI. Simply include company names, person names, or specific LinkedIn URLs in your query.\n- **deep_researcher_start**: Start a smart AI researcher for complex questions. The AI will search the web, read many sources, and think deeply about your question to create a detailed research report.\n- **deep_researcher_check**: Check if your research is ready and get the results. Use this after starting a research task to see if it's done and get your comprehensive report.\n\nYou can choose which tools to enable by adding the `--tools` parameter to your Claude Desktop configuration:\n\n#### üíª **Setup for Code Search Only** (Recommended for Developers)\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"exa-mcp-server\",\n        \"--tools=get_code_context_exa,web_search_exa\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n#### Specify which tools to enable:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"exa-mcp-server\",\n        \"--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nFor enabling multiple tools, use a comma-separated list:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"exa-mcp-server\",\n        \"--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nIf you don't specify any tools, all tools enabled by default will be used.\n\n### 4. Restart Claude Desktop\n\nFor the changes to take effect:\n\n1. Completely quit Claude Desktop (not just close the window)\n2. Start Claude Desktop again\n3. Look for the icon to verify the Exa server is connected\n\n## Using via NPX\n\nIf you prefer to run the server directly, you can use npx:\n\n```bash\n# Run with all tools enabled by default\nnpx exa-mcp-server\n\n# Enable specific tools only\nnpx exa-mcp-server --tools=web_search_exa\n\n# Enable multiple tools\nnpx exa-mcp-server --tools=web_search_exa,get_code_context_exa\n\n# List all available tools\nnpx exa-mcp-server --list-tools\n```\n\n---\n\nBuilt with ‚ù§Ô∏è by team Exa\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/exa-mcp-server",
          "npm_downloads": 95247,
          "npm_package_name": "exa-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "elie222--inbox-zero": {
          "owner": "elie222",
          "name": "inbox-zero",
          "url": "https://github.com/elie222/inbox-zero",
          "imageUrl": "https://github.com/elie222.png",
          "description": "Manage emails effectively with an AI assistant that automates various tasks related to inbox organization and communication. Integrates into environments like Cursor and Claude Desktop for enhanced email management.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:22.563355",
          "collection_timestamp": "2025-10-02T14:59:58.217036",
          "stars": 8925,
          "forks": 1029,
          "license": "Other",
          "language": "TypeScript",
          "created_at": "2023-07-12T15:34:57Z",
          "updated_at": "2025-10-02T02:46:22Z",
          "open_issues": 78,
          "readme_content": "[![](apps/web/app/opengraph-image.png)](https://www.getinboxzero.com)\n\n<p align=\"center\">\n  <a href=\"https://www.getinboxzero.com\">\n    <h1 align=\"center\">Inbox Zero - your 24/7 AI email assistant</h1>\n  </a>\n  <p align=\"center\">\n    Organizes your inbox, pre-drafts replies, and tracks follow‚Äëups - so you reach inbox zero faster. Open source alternative to Fyxer, but more customisable and secure.\n    <br />\n    <a href=\"https://www.getinboxzero.com\">Website</a>\n    ¬∑\n    <a href=\"https://www.getinboxzero.com/discord\">Discord</a>\n    ¬∑\n    <a href=\"https://github.com/elie222/inbox-zero/issues\">Issues</a>\n  </p>\n</p>\n\n<div align=\"center\">\n\n![Stars](https://img.shields.io/github/stars/elie222/inbox-zero?labelColor=black&style=for-the-badge&color=2563EB)\n![Forks](https://img.shields.io/github/forks/elie222/inbox-zero?labelColor=black&style=for-the-badge&color=2563EB)\n\n<a href=\"https://trendshift.io/repositories/6400\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/6400\" alt=\"elie222%2Finbox-zero | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n[![Vercel OSS Program](https://vercel.com/oss/program-badge.svg)](https://vercel.com/oss)\n\n</div>\n\n## Mission\n\nTo help you spend less time in your inbox, so you can focus on what matters.\n\n<br />\n\n[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Felie222%2Finbox-zero&env=AUTH_SECRET,GOOGLE_CLIENT_ID,GOOGLE_CLIENT_SECRET,MICROSOFT_CLIENT_ID,MICROSOFT_CLIENT_SECRET,EMAIL_ENCRYPT_SECRET,EMAIL_ENCRYPT_SALT,UPSTASH_REDIS_URL,UPSTASH_REDIS_TOKEN,GOOGLE_PUBSUB_TOPIC_NAME,DATABASE_URL,NEXT_PUBLIC_BASE_URL)\n\n## Features\n\n- **AI Personal Assistant:** Organizes your inbox and pre-drafts replies in your tone and style.\n- **Cursor Rules for email:** Explain in plain English how your AI should handle your inbox.\n- **Reply Zero:** Track emails to reply to and those awaiting responses.\n- **Smart Categories:** Automatically categorize every sender.\n- **Bulk Unsubscriber:** One-click unsubscribe and archive emails you never read.\n- **Cold Email Blocker:** Auto‚Äëblock cold emails.\n- **Email Analytics:** Track your activity and trends over time.\n\nLearn more in our [docs](https://docs.getinboxzero.com).\n\n## Feature Screenshots\n\n| ![AI Assistant](.github/screenshots/email-assistant.png) |        ![Reply Zero](.github/screenshots/reply-zero.png)        |\n| :------------------------------------------------------: | :-------------------------------------------------------------: |\n|                      _AI Assistant_                      |                          _Reply Zero_                           |\n|  ![Gmail Client](.github/screenshots/email-client.png)   | ![Bulk Unsubscriber](.github/screenshots/bulk-unsubscriber.png) |\n|                      _Gmail client_                      |                       _Bulk Unsubscriber_                       |\n\n## Demo Video\n\n[![Inbox Zero demo](/video-thumbnail.png)](http://www.youtube.com/watch?v=hfvKvTHBjG0)\n\n## Built with\n\n- [Next.js](https://nextjs.org/)\n- [Tailwind CSS](https://tailwindcss.com/)\n- [shadcn/ui](https://ui.shadcn.com/)\n- [Prisma](https://www.prisma.io/)\n- [Upstash](https://upstash.com/)\n- [Turborepo](https://turbo.build/)\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=elie222/inbox-zero&type=Date)](https://www.star-history.com/#elie222/inbox-zero&Date)\n\n## Feature Requests\n\nTo request a feature open a [GitHub issue](https://github.com/elie222/inbox-zero/issues), or join our [Discord](https://www.getinboxzero.com/discord).\n\n## Getting Started for Developers\n\nWe offer a hosted version of Inbox Zero at [https://getinboxzero.com](https://getinboxzero.com). To self-host follow the steps below.\n\n### Self-Hosting with Docker on VPS\n\nFor a complete guide on deploying Inbox Zero to a VPS using Docker, see our [Docker Self-Hosting Guide](docs/hosting/docker.md).\n\n### Setup\n\n[Here's a video](https://youtu.be/hVQENQ4WT2Y) on how to set up the project. It covers the same steps mentioned in this document. But goes into greater detail on setting up the external services.\n\n### Requirements\n\n- [Node.js](https://nodejs.org/en/) >= 18.0.0\n- [pnpm](https://pnpm.io/) >= 8.6.12\n- [Docker desktop](https://www.docker.com/products/docker-desktop/) (recommended but optional)\n\nMake sure you have the above installed before starting.\n\nThe external services that are required are (detailed setup instructions below):\n\n- [Google OAuth](https://console.cloud.google.com/apis/credentials)\n- [Google PubSub](https://console.cloud.google.com/cloudpubsub/topic/list)\n\n### Updating .env file: secrets\n\nCreate your own `.env` file from the example supplied:\n\n```bash\ncp apps/web/.env.example apps/web/.env\ncd apps/web\npnpm install\n```\n\nSet the environment variables in the newly created `.env`. You can see a list of required variables in: `apps/web/env.ts`.\n\nThe required environment variables:\n\n- `AUTH_SECRET` -- can be any random string (try using `openssl rand -hex 32` for a quick secure random string)\n- `EMAIL_ENCRYPT_SECRET` -- Secret key for encrypting OAuth tokens (try using `openssl rand -hex 32` for a secure key)\n- `EMAIL_ENCRYPT_SALT` -- Salt for encrypting OAuth tokens (try using `openssl rand -hex 16` for a secure salt)\n\n\n- `NEXT_PUBLIC_BASE_URL` -- The URL where your app is hosted (e.g., `http://localhost:3000` for local development or `https://yourdomain.com` for production).\n- `INTERNAL_API_KEY` -- A secret key for internal API calls (try using `openssl rand -hex 32` for a secure key)\n\n- `UPSTASH_REDIS_URL` -- Redis URL from Upstash. (can be empty if you are using Docker Compose)\n- `UPSTASH_REDIS_TOKEN` -- Redis token from Upstash. (or specify your own random string if you are using Docker Compose)\n\nWhen using Vercel with Fluid Compute turned off, you should set `MAX_DURATION=300` or lower. See Vercel limits for different plans [here](https://vercel.com/docs/functions/configuring-functions/duration#duration-limits).\n\n### Updating .env file with Google OAuth credentials:\n\n- `GOOGLE_CLIENT_ID` -- Google OAuth client ID. More info [here](https://next-auth.js.org/providers/google)\n- `GOOGLE_CLIENT_SECRET` -- Google OAuth client secret. More info [here](https://next-auth.js.org/providers/google)\n\nGo to [Google Cloud](https://console.cloud.google.com/). Create a new project if necessary.\n\nCreate [new credentials](https://console.cloud.google.com/apis/credentials):\n\n1.  If the banner shows up, configure **consent screen** (if not, you can do this later)\n    1. Click the banner, then Click `Get Started`.\n    2. Choose a name for your app, and enter your email.\n    3. In Audience, choose `External`\n    4. Enter your contact information\n    5. Agree to the User Data policy and then click `Create`.\n    6. Return to APIs and Services using the left sidebar.\n2.  Create new [credentials](https://console.cloud.google.com/apis/credentials):\n    1. Click the `+Create Credentials` button. Choose OAuth Client ID.\n    2. In `Application Type`, Choose `Web application`\n    3. Choose a name for your web client\n    4. In Authorized JavaScript origins, add a URI and enter `http://localhost:3000`\n    5. In `Authorized redirect URIs` enter:\n      - `http://localhost:3000/api/auth/callback/google`\n      - `http://localhost:3000/api/google/linking/callback`\n    6. Click `Create`.\n    7. A popup will show up with the new credentials, including the Client ID and secret.\n3.  Update .env file:\n    1. Copy the Client ID to `GOOGLE_CLIENT_ID`\n    2. Copy the Client secret to `GOOGLE_CLIENT_SECRET`\n4.  Update [scopes](https://console.cloud.google.com/auth/scopes)\n\n    1. Go to `Data Access` in the left sidebar (or click link above)\n    2. Click `Add or remove scopes`\n    3. Copy paste the below into the `Manually add scopes` box:\n\n    ```plaintext\n    https://www.googleapis.com/auth/userinfo.profile\n    https://www.googleapis.com/auth/userinfo.email\n    https://www.googleapis.com/auth/gmail.modify\n    https://www.googleapis.com/auth/gmail.settings.basic\n    https://www.googleapis.com/auth/contacts\n    ```\n\n    4. Click `Update`\n    5. Click `Save` in the Data Access page.\n\n5.  Add yourself as a test user\n    1. Go to [Audience](https://console.cloud.google.com/auth/audience)\n    2. In the `Test users` section, click `+Add users`\n    3. Enter your email and press `Save`\n\n### Updating .env file with Microsoft OAuth credentials:\n\n- `MICROSOFT_CLIENT_ID` -- Microsoft OAuth client ID\n- `MICROSOFT_CLIENT_SECRET` -- Microsoft OAuth client secret\n\nGo to [Microsoft Azure Portal](https://portal.azure.com/). Create a new Azure Active Directory app registration:\n\n1. Navigate to Azure Active Directory\n2. Go to \"App registrations\" in the left sidebar or search it in the searchbar\n3. Click \"New registration\"\n\n   1. Choose a name for your application\n   2. Under \"Supported account types\" select \"Accounts in any organizational directory (Any Azure AD directory - Multitenant) and personal Microsoft accounts (e.g. Skype, Xbox)\"\n   3. Set the Redirect URI:\n      - Platform: Web\n      - URL: `http://localhost:3000/api/auth/callback/microsoft`\n   4. Click \"Register\"\n   5. In the \"Manage\" menu click \"Authentication (Preview)\"\n   6. Add the Redirect URI: `http://localhost:3000/api/outlook/linking/callback`\n\n4. Get your credentials:\n\n   1. The \"Application (client) ID\" shown is your `MICROSOFT_CLIENT_ID`\n   2. To get your client secret:\n      - Click \"Certificates & secrets\" in the left sidebar\n      - Click \"New client secret\"\n      - Add a description and choose an expiry\n      - Click \"Add\"\n      - Copy the secret Value (not the ID) - this is your `MICROSOFT_CLIENT_SECRET`\n\n5. Configure API permissions:\n\n   1. In the \"Manage\" menu click \"API permissions\" in the left sidebar\n   2. Click \"Add a permission\"\n   3. Select \"Microsoft Graph\"\n   4. Select \"Delegated permissions\"\n   5. Add the following permissions:\n\n      - openid\n      - profile\n      - email\n      - User.Read\n      - offline_access\n      - Mail.ReadWrite\n      - Mail.Send\n      - Mail.ReadBasic\n      - Mail.Read\n      - Mail.Read.Shared\n      - MailboxSettings.ReadWrite\n      - Contacts.ReadWrite\n\n   6. Click \"Add permissions\"\n   7. Click \"Grant admin consent\" if you're an admin\n\n6. Update your .env file with the credentials:\n   ```plaintext\n   MICROSOFT_CLIENT_ID=your_client_id_here\n   MICROSOFT_CLIENT_SECRET=your_client_secret_here\n   ```\n\n### Updating .env file with LLM parameters\n\nYou need to set an LLM, but you can use a local one too:\n\n- [Anthropic](https://console.anthropic.com/settings/keys)\n- [OpenAI](https://platform.openai.com/api-keys)\n- AWS Bedrock Anthropic\n- Google Gemini\n- Groq Llama 3.3 70B\n- Ollama (local)\n\nFor the LLM, you can use Anthropic, OpenAI, or Anthropic on AWS Bedrock. You\ncan also use Ollama by setting the following enviroment variables:\n\n```sh\nOLLAMA_BASE_URL=http://localhost:11434/api\nNEXT_PUBLIC_OLLAMA_MODEL=phi3\n```\n\nNote: If you need to access Ollama hosted locally and the application is running on Docker setup, you can use `http://host.docker.internal:11434/api` as the base URL. You might also need to set `OLLAMA_HOST` to `0.0.0.0` in the Ollama configuration file.\n\nYou can select the model you wish to use in the app on the `/settings` page of the app.\n\nIf you are using local ollama, you can set it to be default:\n\n```sh\nDEFAULT_LLM_PROVIDER=ollama\n```\n\nIf this is the case you must also set the `ECONOMY_LLM_PROVIDER` environment variable.\n\n### Redis and Postgres\n\nWe use Postgres for the database.\nFor Redis, you can use [Upstash Redis](https://upstash.com/) or set up your own Redis instance.\n\nYou can run Postgres & Redis locally using `docker-compose`\n\n```bash\ndocker-compose up -d # -d will run the services in the background\n```\n\n### Running the app\n\nTo run the migrations:\n\n```bash\npnpm prisma migrate dev\n```\n\nTo run the app locally for development (slower):\n\n```bash\npnpm run dev\n```\n\nOr from the project root:\n\n```bash\nturbo dev\n```\n\nTo build and run the app locally in production mode (faster):\n\n```bash\npnpm run build\npnpm start\n```\n\nOpen [http://localhost:3000](http://localhost:3000) to view the app in your browser.\n\n### Premium\n\nMany features are available only to premium users. To upgrade yourself, make yourself an admin in the `.env`: `ADMINS=hello@gmail.com`\nThen upgrade yourself at: [http://localhost:3000/admin](http://localhost:3000/admin).\n\n### Set up push notifications via Google PubSub to handle emails in real time\n\nFollow instructions [here](https://developers.google.com/gmail/api/guides/push).\n\n1. [Create a topic](https://developers.google.com/gmail/api/guides/push#create_a_topic)\n2. [Create a subscription](https://developers.google.com/gmail/api/guides/push#create_a_subscription)\n3. [Grant publish rights on your topic](https://developers.google.com/gmail/api/guides/push#grant_publish_rights_on_your_topic)\n\nSet env var `GOOGLE_PUBSUB_TOPIC_NAME`.\nWhen creating the subscription select Push and the url should look something like: `https://www.getinboxzero.com/api/google/webhook?token=TOKEN` or `https://abc.ngrok-free.app/api/google/webhook?token=TOKEN` where the domain is your domain. Set `GOOGLE_PUBSUB_VERIFICATION_TOKEN` in your `.env` file to be the value of `TOKEN`.\n\nTo run in development ngrok can be helpful:\n\n```sh\nngrok http 3000\n# or with an ngrok domain to keep your endpoint stable (set `XYZ`):\nngrok http --domain=XYZ.ngrok-free.app 3000\n```\n\nAnd then update the webhook endpoint in the [Google PubSub subscriptions dashboard](https://console.cloud.google.com/cloudpubsub/subscription/list).\n\nTo start watching emails visit: `/api/watch/all`\n\n### Watching for email updates\n\nSet a cron job to run these:\nThe Google watch is necessary. Others are optional.\n\n```json\n  \"crons\": [\n    {\n      \"path\": \"/api/watch/all\",\n      \"schedule\": \"0 1 * * *\"\n    },\n    {\n      \"path\": \"/api/resend/summary/all\",\n      \"schedule\": \"0 16 * * 1\"\n    },\n    {\n      \"path\": \"/api/reply-tracker/disable-unused-auto-draft\",\n      \"schedule\": \"0 3 * * *\"\n    }\n  ]\n```\n\n[Here](https://vercel.com/guides/how-to-setup-cron-jobs-on-vercel#alternative-cron-providers) are some easy ways to run cron jobs. Upstash is a free, easy option. I could never get the Vercel `vercel.json`. Open to PRs if you find a fix for that.\n\n### Docker Build Instructions\n\nWhen building the Docker image, you **must** specify your `NEXT_PUBLIC_BASE_URL` as a build argument. This is because Next.js embeds `NEXT_PUBLIC_*` variables at build time, not runtime.\n\n### Building the Docker image\n\n```bash\n# For production with your custom domain\ndocker build \\\n  --build-arg NEXT_PUBLIC_BASE_URL=\"https://your-domain.com\" \\\n  -t inbox-zero \\\n  -f docker/Dockerfile.prod .\n\n# For local development (default)\ndocker build -t inbox-zero -f docker/Dockerfile.prod .\n```\n\n### Running the container\n\nAfter building, run the container with your runtime secrets:\n\n```bash\ndocker run -p 3000:3000 \\\n  -e DATABASE_URL=\"your-database-url\" \\\n  -e AUTH_SECRET=\"your-auth-secret\" \\\n  -e GOOGLE_CLIENT_ID=\"your-google-client-id\" \\\n  -e GOOGLE_CLIENT_SECRET=\"your-google-client-secret\" \\\n  # ... other runtime environment variables\n  inbox-zero\n```\n\n**Important:** If you need to change `NEXT_PUBLIC_BASE_URL`, you must rebuild the Docker image. It cannot be changed at runtime.\n\nFor more detailed Docker build instructions and security considerations, see [docker/DOCKER_BUILD_GUIDE.md](docker/DOCKER_BUILD_GUIDE.md).\n\n\n### Calendar integrations\n\n*Note:* The calendar integration feature is a work in progress.\n\n#### Google Calendar\n\n1. Visit: https://console.cloud.google.com/apis/library\n2. Search for \"Google Calendar API\"\n3. Click on it and then click \"Enable\"\n4. Visit: [credentials](https://console.cloud.google.com/apis/credentials):\n    1. Click on your project\n    2. In `Authorized redirect URIs` add:\n      - `http://localhost:3000/api/google/calendar/callback`\n\n## Contributing to the project\n\nYou can view open tasks in our [GitHub Issues](https://github.com/elie222/inbox-zero/issues).\nJoin our [Discord](https://www.getinboxzero.com/discord) to discuss tasks and check what's being worked on.\n\n[ARCHITECTURE.md](./ARCHITECTURE.md) explains the architecture of the project (LLM generated).\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/inbox-zero",
          "npm_downloads": 54,
          "npm_package_name": "inbox-zero",
          "npm_success": true,
          "npm_error": null
        },
        "gotohuman--gotohuman-mcp-server": {
          "owner": "gotohuman",
          "name": "gotohuman-mcp-server",
          "url": "https://github.com/gotohuman/gotohuman-mcp-server",
          "imageUrl": "https://github.com/gotohuman.png",
          "description": "Request human reviews for AI-generated content through a webhook-based workflow. Supports seamless integration into AI workflows, allowing for customizable human approval processes.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:23.490542",
          "collection_timestamp": "2025-10-02T15:00:05.377884",
          "stars": 41,
          "forks": 9,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2025-03-21T15:15:37Z",
          "updated_at": "2025-09-21T10:18:54Z",
          "open_issues": 1,
          "readme_content": "# gotoHuman MCP Server\n\ngotoHuman makes it easy to add **human approvals** to AI agents and agentic workflows.  \nA fully-managed async human-in-the-loop workflow with a customizable approval UI.  \nEnjoy built-in auth, webhooks, notifications, team features, and an evolving training dataset.\n\nUse our MCP server to request human approvals from your AI workflows via MCP or add it to your IDE to help with integration.\n\n## Installation\n\n```bash\nnpx @gotohuman/mcp-server\n```\n\n### Use with Cursor / Claude / Windsurf\n\n```json\n{\n  \"mcpServers\": {\n    \"gotoHuman\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@gotohuman/mcp-server\"],\n      \"env\": {\n        \"GOTOHUMAN_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](cursor://anysphere.cursor-deeplink/mcp/install?name=gotoHuman&config=eyJjb21tYW5kIjoibnB4IC15IEBnb3RvaHVtYW4vbWNwLXNlcnZlciIsImVudiI6eyJHT1RPSFVNQU5fQVBJX0tFWSI6InlvdXItYXBpLWtleSJ9fQ==)\n\nGet your API key and set up an approval step at [app.gotohuman.com](https://app.gotohuman.com)\n\n## Demo\n\nThis is Cursor on the left, but this could be a background agent that also reacts to the approval webhook.\n\nhttps://github.com/user-attachments/assets/380a4223-ea77-4e24-90a5-52669b77f56f\n\n## Tools\n\n### `list-forms`\nList all available review forms.\n  - __Returns__ a list of all available forms in your account incl. high-level info about the added fields\n### `get-form-schema`  \nGet the schema to use when requesting a human review for a given form.\n  - __Params__\n    - `formId`: The form ID to fetch the schema for\n  - __Returns__ the schema, considering the incl. fields and their configuration\n### `request-human-review-with-form`  \nRequest a human review. Will appear in your gotoHuman inbox.\n  - __Params__\n    - `formId`: The form ID for the review\n    - `fieldData`: Content (AI-output to review, context,...) and configuration for the form's fields.  \n    The schema for this needs to be fetched with `get-form-schema`\n    - `metadata`: Optional additional data that will be incl. in the webhook response after form submission\n    - `assignToUsers`: Optional list of user emails to assign the review to\n  - __Returns__ a link to the review in gotoHuman\n\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the server\nnpm run build\n\n# For testing: Run the MCP inspector\nnpm run inspector\n```\n\n  #### Run locally in MCP Client (e.g. Cursor / Claude / Windsurf)\n\n  ```json\n  {\n  \"mcpServers\": {\n    \"gotoHuman\": {\n      \"command\": \"node\",\n      \"args\": [\"/<absolute-path>/build/index.js\"],\n      \"env\": {\n        \"GOTOHUMAN_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n> [!NOTE]\n> For Windows, the `args` path needs to be `C:\\\\<absolute-path>\\\\build\\\\index.js`\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "github--github-mcp-server": {
          "owner": "github",
          "name": "github-mcp-server",
          "url": "https://github.com/github/github-mcp-server",
          "imageUrl": "https://github.com/github.png",
          "description": "Interact with GitHub repositories, manage issues, and automate workflows using GitHub's APIs for seamless integration and advanced functionality.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:24.383399",
          "collection_timestamp": "2025-10-02T15:00:10.128260",
          "stars": 23200,
          "forks": 2658,
          "license": "MIT License",
          "language": "Go",
          "created_at": "2025-03-04T16:42:04Z",
          "updated_at": "2025-10-02T08:27:57Z",
          "open_issues": 275,
          "readme_content": "# GitHub MCP Server\n\nThe GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.\n\n### Use Cases\n\n- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.\n- Issue & PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.\n- CI/CD & Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.\n- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.\n- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.\n\nBuilt for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.\n\n---\n\n## Remote GitHub MCP Server\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&quality=insiders)\n\nThe remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don't worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.\n\n### Prerequisites\n\n1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)\n2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)\n\n### Install in VS Code\n\nFor quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you're using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.\n\nAlternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:\n\n<table>\n<tr><th>Using OAuth</th><th>Using a GitHub PAT</th></tr>\n<tr><th align=left colspan=2>VS Code (version 1.101 or greater)</th></tr>\n<tr valign=top>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\"\n    }\n  }\n}\n```\n\n</td>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\",\n      \"headers\": {\n        \"Authorization\": \"Bearer ${input:github_mcp_pat}\"\n      }\n    }\n  },\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"github_mcp_pat\",\n      \"description\": \"GitHub Personal Access Token\",\n      \"password\": true\n    }\n  ]\n}\n```\n\n</td>\n</tr>\n</table>\n\n### Install in other MCP hosts\n- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot\n- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Web, Claude Desktop and Claude Code CLI\n- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE\n- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE\n\n> **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application's documentation for more info.\n\n### Configuration\nSee [Remote Server Documentation](/docs/remote-server.md) on how to pass additional configuration settings to the remote GitHub MCP Server.\n\n---\n\n## Local GitHub MCP Server\n\n[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&quality=insiders)\n\n### Prerequisites\n\n1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.\n2. Once Docker is installed, you will also need to ensure Docker is running. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.\n3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).\nThe MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).\n\n<details><summary><b>Handling PATs Securely</b></summary>\n\n### Environment Variables (Recommended)\nTo keep your GitHub PAT secure and reusable across different MCP hosts:\n\n1. **Store your PAT in environment variables**\n   ```bash\n   export GITHUB_PAT=your_token_here\n   ```\n   Or create a `.env` file:\n   ```env\n   GITHUB_PAT=your_token_here\n   ```\n\n2. **Protect your `.env` file**\n   ```bash\n   # Add to .gitignore to prevent accidental commits\n   echo \".env\" >> .gitignore\n   ```\n\n3. **Reference the token in configurations**\n   ```bash\n   # CLI usage\n   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT\n\n   # In config files (where supported)\n   \"env\": {\n     \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"$GITHUB_PAT\"\n   }\n   ```\n\n> **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.\n\n### Token Security Best Practices\n\n- **Minimum scopes**: Only grant necessary permissions\n  - `repo` - Repository operations\n  - `read:packages` - Docker image access\n  - `read:org` - Organization team access\n- **Separate tokens**: Use different PATs for different projects/environments\n- **Regular rotation**: Update tokens periodically\n- **Never commit**: Keep tokens out of version control\n- **File permissions**: Restrict access to config files containing tokens\n  ```bash\n  chmod 600 ~/.your-app/config.json\n  ```\n\n</details>\n\n## Installation\n\n### Install in GitHub Copilot on VS Code\n\nFor quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.\n\nMore about using MCP server tools in VS Code's [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).\n\nInstall in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)\n\nAdd the following JSON block to your IDE's MCP settings.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"github_token\",\n        \"description\": \"GitHub Personal Access Token\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"github\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"-i\",\n          \"--rm\",\n          \"-e\",\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n          \"ghcr.io/github/github-mcp-server\"\n        ],\n        \"env\": {\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.\n\n<details>\n<summary><b>Example JSON block without the MCP key included</b></summary>\n<br>\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"github_token\",\n      \"description\": \"GitHub Personal Access Token\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"github\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n        \"ghcr.io/github/github-mcp-server\"\n      ],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n### Install in Other MCP Hosts\n\nFor other MCP host applications, please refer to our installation guides:\n\n- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot\n- **[Claude Code & Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop\n- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE\n- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI\n- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE\n\nFor a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.\n\n> **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application's documentation for the correct MCP configuration syntax and setup process.\n\n### Build from source\n\nIf you don't have Docker, you can use `go build` to build the binary in the\n`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:\n\n```JSON\n{\n  \"mcp\": {\n    \"servers\": {\n      \"github\": {\n        \"command\": \"/path/to/github-mcp-server\",\n        \"args\": [\"stdio\"],\n        \"env\": {\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n        }\n      }\n    }\n  }\n}\n```\n\n## Tool Configuration\n\nThe GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.\n\n_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._\n\n### Available Toolsets\n\nThe following sets of tools are available (all are on by default):\n\n<!-- START AUTOMATED TOOLSETS -->\n| Toolset                 | Description                                                   |\n| ----------------------- | ------------------------------------------------------------- |\n| `context`               | **Strongly recommended**: Tools that provide context about the current user and GitHub context you are operating in |\n| `actions` | GitHub Actions workflows and CI/CD operations |\n| `code_security` | Code security related tools, such as GitHub Code Scanning |\n| `dependabot` | Dependabot tools |\n| `discussions` | GitHub Discussions related tools |\n| `experiments` | Experimental features that are not considered stable yet |\n| `gists` | GitHub Gist related tools |\n| `issues` | GitHub Issues related tools |\n| `notifications` | GitHub Notifications related tools |\n| `orgs` | GitHub Organization related tools |\n| `projects` | GitHub Projects related tools |\n| `pull_requests` | GitHub Pull Request related tools |\n| `repos` | GitHub Repository related tools |\n| `secret_protection` | Secret protection related tools, such as GitHub Secret Scanning |\n| `security_advisories` | Security advisories related tools |\n| `users` | GitHub User related tools |\n<!-- END AUTOMATED TOOLSETS -->\n\n## Tools\n\n\n<!-- START AUTOMATED TOOLS -->\n<details>\n\n<summary>Actions</summary>\n\n- **cancel_workflow_run** - Cancel workflow run\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **delete_workflow_run_logs** - Delete workflow logs\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **download_workflow_run_artifact** - Download workflow artifact\n  - `artifact_id`: The unique identifier of the artifact (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_job_logs** - Get job logs\n  - `failed_only`: When true, gets logs for all failed jobs in run_id (boolean, optional)\n  - `job_id`: The unique identifier of the workflow job (required for single job logs) (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `return_content`: Returns actual log content instead of URLs (boolean, optional)\n  - `run_id`: Workflow run ID (required when using failed_only) (number, optional)\n  - `tail_lines`: Number of lines to return from the end of the log (number, optional)\n\n- **get_workflow_run** - Get workflow run\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **get_workflow_run_logs** - Get workflow run logs\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **get_workflow_run_usage** - Get workflow usage\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_jobs** - List workflow jobs\n  - `filter`: Filters jobs by their completed_at timestamp (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_run_artifacts** - List workflow artifacts\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_runs** - List workflow runs\n  - `actor`: Returns someone's workflow runs. Use the login for the user who created the workflow run. (string, optional)\n  - `branch`: Returns workflow runs associated with a branch. Use the name of the branch. (string, optional)\n  - `event`: Returns workflow runs for a specific event type (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `status`: Returns workflow runs with the check run status (string, optional)\n  - `workflow_id`: The workflow ID or workflow file name (string, required)\n\n- **list_workflows** - List workflows\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **rerun_failed_jobs** - Rerun failed jobs\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **rerun_workflow_run** - Rerun workflow run\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **run_workflow** - Run workflow\n  - `inputs`: Inputs the workflow accepts (object, optional)\n  - `owner`: Repository owner (string, required)\n  - `ref`: The git reference for the workflow. The reference can be a branch or tag name. (string, required)\n  - `repo`: Repository name (string, required)\n  - `workflow_id`: The workflow ID (numeric) or workflow file name (e.g., main.yml, ci.yaml) (string, required)\n\n</details>\n\n<details>\n\n<summary>Code Security</summary>\n\n- **get_code_scanning_alert** - Get code scanning alert\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_code_scanning_alerts** - List code scanning alerts\n  - `owner`: The owner of the repository. (string, required)\n  - `ref`: The Git reference for the results you want to list. (string, optional)\n  - `repo`: The name of the repository. (string, required)\n  - `severity`: Filter code scanning alerts by severity (string, optional)\n  - `state`: Filter code scanning alerts by state. Defaults to open (string, optional)\n  - `tool_name`: The name of the tool used for code scanning. (string, optional)\n\n</details>\n\n<details>\n\n<summary>Context</summary>\n\n- **get_me** - Get my user profile\n  - No parameters required\n\n- **get_team_members** - Get team members\n  - `org`: Organization login (owner) that contains the team. (string, required)\n  - `team_slug`: Team slug (string, required)\n\n- **get_teams** - Get teams\n  - `user`: Username to get teams for. If not provided, uses the authenticated user. (string, optional)\n\n</details>\n\n<details>\n\n<summary>Dependabot</summary>\n\n- **get_dependabot_alert** - Get dependabot alert\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_dependabot_alerts** - List dependabot alerts\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `severity`: Filter dependabot alerts by severity (string, optional)\n  - `state`: Filter dependabot alerts by state. Defaults to open (string, optional)\n\n</details>\n\n<details>\n\n<summary>Discussions</summary>\n\n- **get_discussion** - Get discussion\n  - `discussionNumber`: Discussion Number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_discussion_comments** - Get discussion comments\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `discussionNumber`: Discussion Number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_discussion_categories** - List discussion categories\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name. If not provided, discussion categories will be queried at the organisation level. (string, optional)\n\n- **list_discussions** - List discussions\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `category`: Optional filter by discussion category ID. If provided, only discussions with this category are listed. (string, optional)\n  - `direction`: Order direction. (string, optional)\n  - `orderBy`: Order discussions by field. If provided, the 'direction' also needs to be provided. (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name. If not provided, discussions will be queried at the organisation level. (string, optional)\n\n</details>\n\n<details>\n\n<summary>Gists</summary>\n\n- **create_gist** - Create Gist\n  - `content`: Content for simple single-file gist creation (string, required)\n  - `description`: Description of the gist (string, optional)\n  - `filename`: Filename for simple single-file gist creation (string, required)\n  - `public`: Whether the gist is public (boolean, optional)\n\n- **list_gists** - List Gists\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `since`: Only gists updated after this time (ISO 8601 timestamp) (string, optional)\n  - `username`: GitHub username (omit for authenticated user's gists) (string, optional)\n\n- **update_gist** - Update Gist\n  - `content`: Content for the file (string, required)\n  - `description`: Updated description of the gist (string, optional)\n  - `filename`: Filename to update or create (string, required)\n  - `gist_id`: ID of the gist to update (string, required)\n\n</details>\n\n<details>\n\n<summary>Issues</summary>\n\n- **add_issue_comment** - Add comment to issue\n  - `body`: Comment content (string, required)\n  - `issue_number`: Issue number to comment on (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **add_sub_issue** - Add sub-issue\n  - `issue_number`: The number of the parent issue (number, required)\n  - `owner`: Repository owner (string, required)\n  - `replace_parent`: When true, replaces the sub-issue's current parent issue (boolean, optional)\n  - `repo`: Repository name (string, required)\n  - `sub_issue_id`: The ID of the sub-issue to add. ID is not the same as issue number (number, required)\n\n- **assign_copilot_to_issue** - Assign Copilot to issue\n  - `issueNumber`: Issue number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **create_issue** - Open new issue\n  - `assignees`: Usernames to assign to this issue (string[], optional)\n  - `body`: Issue body content (string, optional)\n  - `labels`: Labels to apply to this issue (string[], optional)\n  - `milestone`: Milestone number (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `title`: Issue title (string, required)\n  - `type`: Type of this issue (string, optional)\n\n- **get_issue** - Get issue details\n  - `issue_number`: The number of the issue (number, required)\n  - `owner`: The owner of the repository (string, required)\n  - `repo`: The name of the repository (string, required)\n\n- **get_issue_comments** - Get issue comments\n  - `issue_number`: Issue number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_issue_types** - List available issue types\n  - `owner`: The organization owner of the repository (string, required)\n\n- **list_issues** - List issues\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `direction`: Order direction. If provided, the 'orderBy' also needs to be provided. (string, optional)\n  - `labels`: Filter by labels (string[], optional)\n  - `orderBy`: Order issues by field. If provided, the 'direction' also needs to be provided. (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `since`: Filter by date (ISO 8601 timestamp) (string, optional)\n  - `state`: Filter by state, by default both open and closed issues are returned when not provided (string, optional)\n\n- **list_sub_issues** - List sub-issues\n  - `issue_number`: Issue number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (default: 1) (number, optional)\n  - `per_page`: Number of results per page (max 100, default: 30) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **remove_sub_issue** - Remove sub-issue\n  - `issue_number`: The number of the parent issue (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `sub_issue_id`: The ID of the sub-issue to remove. ID is not the same as issue number (number, required)\n\n- **reprioritize_sub_issue** - Reprioritize sub-issue\n  - `after_id`: The ID of the sub-issue to be prioritized after (either after_id OR before_id should be specified) (number, optional)\n  - `before_id`: The ID of the sub-issue to be prioritized before (either after_id OR before_id should be specified) (number, optional)\n  - `issue_number`: The number of the parent issue (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `sub_issue_id`: The ID of the sub-issue to reprioritize. ID is not the same as issue number (number, required)\n\n- **search_issues** - Search issues\n  - `order`: Sort order (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only issues for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub issues search syntax (string, required)\n  - `repo`: Optional repository name. If provided with owner, only issues for this repository are listed. (string, optional)\n  - `sort`: Sort field by number of matches of categories, defaults to best match (string, optional)\n\n- **update_issue** - Edit issue\n  - `assignees`: New assignees (string[], optional)\n  - `body`: New description (string, optional)\n  - `duplicate_of`: Issue number that this issue is a duplicate of. Only used when state_reason is 'duplicate'. (number, optional)\n  - `issue_number`: Issue number to update (number, required)\n  - `labels`: New labels (string[], optional)\n  - `milestone`: New milestone number (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `state`: New state (string, optional)\n  - `state_reason`: Reason for the state change. Ignored unless state is changed. (string, optional)\n  - `title`: New title (string, optional)\n  - `type`: New issue type (string, optional)\n\n</details>\n\n<details>\n\n<summary>Notifications</summary>\n\n- **dismiss_notification** - Dismiss notification\n  - `state`: The new state of the notification (read/done) (string, optional)\n  - `threadID`: The ID of the notification thread (string, required)\n\n- **get_notification_details** - Get notification details\n  - `notificationID`: The ID of the notification (string, required)\n\n- **list_notifications** - List notifications\n  - `before`: Only show notifications updated before the given time (ISO 8601 format) (string, optional)\n  - `filter`: Filter notifications to, use default unless specified. Read notifications are ones that have already been acknowledged by the user. Participating notifications are those that the user is directly involved in, such as issues or pull requests they have commented on or created. (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only notifications for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Optional repository name. If provided with owner, only notifications for this repository are listed. (string, optional)\n  - `since`: Only show notifications updated after the given time (ISO 8601 format) (string, optional)\n\n- **manage_notification_subscription** - Manage notification subscription\n  - `action`: Action to perform: ignore, watch, or delete the notification subscription. (string, required)\n  - `notificationID`: The ID of the notification thread. (string, required)\n\n- **manage_repository_notification_subscription** - Manage repository notification subscription\n  - `action`: Action to perform: ignore, watch, or delete the repository notification subscription. (string, required)\n  - `owner`: The account owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **mark_all_notifications_read** - Mark all notifications as read\n  - `lastReadAt`: Describes the last point that notifications were checked (optional). Default: Now (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only notifications for this repository are marked as read. (string, optional)\n  - `repo`: Optional repository name. If provided with owner, only notifications for this repository are marked as read. (string, optional)\n\n</details>\n\n<details>\n\n<summary>Organizations</summary>\n\n- **search_orgs** - Search organizations\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Organization search query. Examples: 'microsoft', 'location:california', 'created:>=2025-01-01'. Search is automatically scoped to type:org. (string, required)\n  - `sort`: Sort field by category (string, optional)\n\n</details>\n\n<details>\n\n<summary>Projects</summary>\n\n- **add_project_item** - Add project item\n  - `item_id`: The numeric ID of the issue or pull request to add to the project. (number, required)\n  - `item_type`: The item's type, either issue or pull_request. (string, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **delete_project_item** - Delete project item\n  - `item_id`: The internal project item ID to delete from the project (not the issue or pull request ID). (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **get_project** - Get project\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number (number, required)\n\n- **get_project_field** - Get project field\n  - `field_id`: The field's id. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **get_project_item** - Get project item\n  - `item_id`: The item's ID. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **list_project_fields** - List project fields\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Number of results per page (max 100, default: 30) (number, optional)\n  - `project_number`: The project's number. (number, required)\n\n- **list_project_items** - List project items\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Number of results per page (max 100, default: 30) (number, optional)\n  - `project_number`: The project's number. (number, required)\n  - `query`: Search query to filter items (string, optional)\n\n- **list_projects** - List projects\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Number of results per page (max 100, default: 30) (number, optional)\n  - `query`: Filter projects by a search query (matches title and description) (string, optional)\n\n</details>\n\n<details>\n\n<summary>Pull Requests</summary>\n\n- **add_comment_to_pending_review** - Add review comment to the requester's latest pending pull request review\n  - `body`: The text of the review comment (string, required)\n  - `line`: The line of the blob in the pull request diff that the comment applies to. For multi-line comments, the last line of the range (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `path`: The relative path to the file that necessitates a comment (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n  - `side`: The side of the diff to comment on. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)\n  - `startLine`: For multi-line comments, the first line of the range that the comment applies to (number, optional)\n  - `startSide`: For multi-line comments, the starting side of the diff that the comment applies to. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)\n  - `subjectType`: The level at which the comment is targeted (string, required)\n\n- **create_and_submit_pull_request_review** - Create and submit a pull request review without comments\n  - `body`: Review comment text (string, required)\n  - `commitID`: SHA of commit to review (string, optional)\n  - `event`: Review action to perform (string, required)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **create_pending_pull_request_review** - Create pending pull request review\n  - `commitID`: SHA of commit to review (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **create_pull_request** - Open new pull request\n  - `base`: Branch to merge into (string, required)\n  - `body`: PR description (string, optional)\n  - `draft`: Create as draft PR (boolean, optional)\n  - `head`: Branch containing changes (string, required)\n  - `maintainer_can_modify`: Allow maintainer edits (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `title`: PR title (string, required)\n\n- **delete_pending_pull_request_review** - Delete the requester's latest pending pull request review\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **get_pull_request** - Get pull request details\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **get_pull_request_diff** - Get pull request diff\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **get_pull_request_files** - Get pull request files\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **get_pull_request_review_comments** - Get pull request review comments\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **get_pull_request_reviews** - Get pull request reviews\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **get_pull_request_status** - Get pull request status checks\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **list_pull_requests** - List pull requests\n  - `base`: Filter by base branch (string, optional)\n  - `direction`: Sort direction (string, optional)\n  - `head`: Filter by head user/org and branch (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sort`: Sort by (string, optional)\n  - `state`: Filter by state (string, optional)\n\n- **merge_pull_request** - Merge pull request\n  - `commit_message`: Extra detail for merge commit (string, optional)\n  - `commit_title`: Title for merge commit (string, optional)\n  - `merge_method`: Merge method (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **request_copilot_review** - Request Copilot review\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **search_pull_requests** - Search pull requests\n  - `order`: Sort order (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only pull requests for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub pull request search syntax (string, required)\n  - `repo`: Optional repository name. If provided with owner, only pull requests for this repository are listed. (string, optional)\n  - `sort`: Sort field by number of matches of categories, defaults to best match (string, optional)\n\n- **submit_pending_pull_request_review** - Submit the requester's latest pending pull request review\n  - `body`: The text of the review comment (string, optional)\n  - `event`: The event to perform (string, required)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **update_pull_request** - Edit pull request\n  - `base`: New base branch name (string, optional)\n  - `body`: New description (string, optional)\n  - `draft`: Mark pull request as draft (true) or ready for review (false) (boolean, optional)\n  - `maintainer_can_modify`: Allow maintainer edits (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number to update (number, required)\n  - `repo`: Repository name (string, required)\n  - `reviewers`: GitHub usernames to request reviews from (string[], optional)\n  - `state`: New state (string, optional)\n  - `title`: New title (string, optional)\n\n- **update_pull_request_branch** - Update pull request branch\n  - `expectedHeadSha`: The expected SHA of the pull request's HEAD ref (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n</details>\n\n<details>\n\n<summary>Repositories</summary>\n\n- **create_branch** - Create branch\n  - `branch`: Name for new branch (string, required)\n  - `from_branch`: Source branch (defaults to repo default) (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **create_or_update_file** - Create or update file\n  - `branch`: Branch to create/update the file in (string, required)\n  - `content`: Content of the file (string, required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path where to create/update the file (string, required)\n  - `repo`: Repository name (string, required)\n  - `sha`: Required if updating an existing file. The blob SHA of the file being replaced. (string, optional)\n\n- **create_repository** - Create repository\n  - `autoInit`: Initialize with README (boolean, optional)\n  - `description`: Repository description (string, optional)\n  - `name`: Repository name (string, required)\n  - `organization`: Organization to create the repository in (omit to create in your personal account) (string, optional)\n  - `private`: Whether repo should be private (boolean, optional)\n\n- **delete_file** - Delete file\n  - `branch`: Branch to delete the file from (string, required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path to the file to delete (string, required)\n  - `repo`: Repository name (string, required)\n\n- **fork_repository** - Fork repository\n  - `organization`: Organization to fork to (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_commit** - Get commit details\n  - `include_diff`: Whether to include file diffs and stats in the response. Default is true. (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Commit SHA, branch name, or tag name (string, required)\n\n- **get_file_contents** - Get file or directory contents\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path to file/directory (directories must end with a slash '/') (string, optional)\n  - `ref`: Accepts optional git refs such as `refs/tags/{tag}`, `refs/heads/{branch}` or `refs/pull/{pr_number}/head` (string, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Accepts optional commit SHA. If specified, it will be used instead of ref (string, optional)\n\n- **get_latest_release** - Get latest release\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_release_by_tag** - Get a release by tag name\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `tag`: Tag name (e.g., 'v1.0.0') (string, required)\n\n- **get_tag** - Get tag details\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `tag`: Tag name (string, required)\n\n- **list_branches** - List branches\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_commits** - List commits\n  - `author`: Author username or email address to filter commits by (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Commit SHA, branch or tag name to list commits of. If not provided, uses the default branch of the repository. If a commit SHA is provided, will list commits up to that SHA. (string, optional)\n\n- **list_releases** - List releases\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_starred_repositories** - List starred repositories\n  - `direction`: The direction to sort the results by. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `sort`: How to sort the results. Can be either 'created' (when the repository was starred) or 'updated' (when the repository was last pushed to). (string, optional)\n  - `username`: Username to list starred repositories for. Defaults to the authenticated user. (string, optional)\n\n- **list_tags** - List tags\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **push_files** - Push files to repository\n  - `branch`: Branch to push to (string, required)\n  - `files`: Array of file objects to push, each object with path (string) and content (string) (object[], required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **search_code** - Search code\n  - `order`: Sort order for results (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub's powerful code search syntax. Examples: 'content:Skill language:Java org:github', 'NOT is:archived language:Python OR language:go', 'repo:github/github-mcp-server'. Supports exact matching, language filters, path filters, and more. (string, required)\n  - `sort`: Sort field ('indexed' only) (string, optional)\n\n- **search_repositories** - Search repositories\n  - `minimal_output`: Return minimal repository information (default: true). When false, returns full GitHub API repository objects. (boolean, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Repository search query. Examples: 'machine learning in:name stars:>1000 language:python', 'topic:react', 'user:facebook'. Supports advanced search syntax for precise filtering. (string, required)\n\n- **star_repository** - Star repository\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **unstar_repository** - Unstar repository\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n</details>\n\n<details>\n\n<summary>Secret Protection</summary>\n\n- **get_secret_scanning_alert** - Get secret scanning alert\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_secret_scanning_alerts** - List secret scanning alerts\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `resolution`: Filter by resolution (string, optional)\n  - `secret_type`: A comma-separated list of secret types to return. All default secret patterns are returned. To return generic patterns, pass the token name(s) in the parameter. (string, optional)\n  - `state`: Filter by state (string, optional)\n\n</details>\n\n<details>\n\n<summary>Security Advisories</summary>\n\n- **get_global_security_advisory** - Get a global security advisory\n  - `ghsaId`: GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, required)\n\n- **list_global_security_advisories** - List global security advisories\n  - `affects`: Filter advisories by affected package or version (e.g. \"package1,package2@1.0.0\"). (string, optional)\n  - `cveId`: Filter by CVE ID. (string, optional)\n  - `cwes`: Filter by Common Weakness Enumeration IDs (e.g. [\"79\", \"284\", \"22\"]). (string[], optional)\n  - `ecosystem`: Filter by package ecosystem. (string, optional)\n  - `ghsaId`: Filter by GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, optional)\n  - `isWithdrawn`: Whether to only return withdrawn advisories. (boolean, optional)\n  - `modified`: Filter by publish or update date or date range (ISO 8601 date or range). (string, optional)\n  - `published`: Filter by publish date or date range (ISO 8601 date or range). (string, optional)\n  - `severity`: Filter by severity. (string, optional)\n  - `type`: Advisory type. (string, optional)\n  - `updated`: Filter by update date or date range (ISO 8601 date or range). (string, optional)\n\n- **list_org_repository_security_advisories** - List org repository security advisories\n  - `direction`: Sort direction. (string, optional)\n  - `org`: The organization login. (string, required)\n  - `sort`: Sort field. (string, optional)\n  - `state`: Filter by advisory state. (string, optional)\n\n- **list_repository_security_advisories** - List repository security advisories\n  - `direction`: Sort direction. (string, optional)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `sort`: Sort field. (string, optional)\n  - `state`: Filter by advisory state. (string, optional)\n\n</details>\n\n<details>\n\n<summary>Users</summary>\n\n- **search_users** - Search users\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: User search query. Examples: 'john smith', 'location:seattle', 'followers:>100'. Search is automatically scoped to type:user. (string, required)\n  - `sort`: Sort users by number of followers or repositories, or when the person joined GitHub. (string, optional)\n\n</details>\n<!-- END AUTOMATED TOOLS -->\n\n### Additional Tools in Remote Github MCP Server\n\n<details>\n\n<summary>Copilot coding agent</summary>\n\n-   **create_pull_request_with_copilot** - Perform task with GitHub Copilot coding agent\n    -   `owner`: Repository owner. You can guess the owner, but confirm it with the user before proceeding. (string, required)\n    -   `repo`: Repository name. You can guess the repository name, but confirm it with the user before proceeding. (string, required)\n    -   `problem_statement`: Detailed description of the task to be performed (e.g., 'Implement a feature that does X', 'Fix bug Y', etc.) (string, required)\n    -   `title`: Title for the pull request that will be created (string, required)\n    -   `base_ref`: Git reference (e.g., branch) that the agent will start its work from. If not specified, defaults to the repository's default branch (string, optional)\n\n</details>\n\n<details>\n\n<summary>Copilot Spaces</summary>\n\n-   **get_copilot_space** - Get Copilot Space\n    -   `owner`: The owner of the space. (string, required)\n    -   `name`: The name of the space. (string, required)\n\n-   **list_copilot_spaces** - List Copilot Spaces\n</details>\n\n#### Specifying Toolsets\n\nTo specify toolsets you want available to the LLM, you can pass an allow-list in two ways:\n\n1. **Using Command Line Argument**:\n\n   ```bash\n   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security\n   ```\n\n2. **Using Environment Variable**:\n   ```bash\n   GITHUB_TOOLSETS=\"repos,issues,pull_requests,actions,code_security\" ./github-mcp-server\n   ```\n\nThe environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.\n\n### Using Toolsets With Docker\n\nWhen using Docker, you can pass the toolsets as environment variables:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_TOOLSETS=\"repos,issues,pull_requests,actions,code_security,experiments\" \\\n  ghcr.io/github/github-mcp-server\n```\n\n### The \"all\" Toolset\n\nThe special toolset `all` can be provided to enable all available toolsets regardless of any other configuration:\n\n```bash\n./github-mcp-server --toolsets all\n```\n\nOr using the environment variable:\n\n```bash\nGITHUB_TOOLSETS=\"all\" ./github-mcp-server\n```\n\n## Dynamic Tool Discovery\n\n**Note**: This feature is currently in beta and may not be available in all environments. Please test it out and let us know if you encounter any issues.\n\nInstead of starting with all tools enabled, you can turn on dynamic toolset discovery. Dynamic toolsets allow the MCP host to list and enable toolsets in response to a user prompt. This should help to avoid situations where the model gets confused by the sheer number of tools available.\n\n### Using Dynamic Tool Discovery\n\nWhen using the binary, you can pass the `--dynamic-toolsets` flag.\n\n```bash\n./github-mcp-server --dynamic-toolsets\n```\n\nWhen using Docker, you can pass the toolsets as environment variables:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_DYNAMIC_TOOLSETS=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\n## Read-Only Mode\n\nTo run the server in read-only mode, you can use the `--read-only` flag. This will only offer read-only tools, preventing any modifications to repositories, issues, pull requests, etc.\n\n```bash\n./github-mcp-server --read-only\n```\n\nWhen using Docker, you can pass the read-only mode as an environment variable:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_READ_ONLY=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\n## GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)\n\nThe flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set\nthe hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.\n\n- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.\n- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.\n``` json\n\"github\": {\n    \"command\": \"docker\",\n    \"args\": [\n    \"run\",\n    \"-i\",\n    \"--rm\",\n    \"-e\",\n    \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n    \"-e\",\n    \"GITHUB_HOST\",\n    \"ghcr.io/github/github-mcp-server\"\n    ],\n    \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\",\n        \"GITHUB_HOST\": \"https://<your GHES or ghe.com domain name>\"\n    }\n}\n```\n\n## i18n / Overriding Descriptions\n\nThe descriptions of the tools can be overridden by creating a\n`github-mcp-server-config.json` file in the same directory as the binary.\n\nThe file should contain a JSON object with the tool names as keys and the new\ndescriptions as values. For example:\n\n```json\n{\n  \"TOOL_ADD_ISSUE_COMMENT_DESCRIPTION\": \"an alternative description\",\n  \"TOOL_CREATE_BRANCH_DESCRIPTION\": \"Create a new branch in a GitHub repository\"\n}\n```\n\nYou can create an export of the current translations by running the binary with\nthe `--export-translations` flag.\n\nThis flag will preserve any translations/overrides you have made, while adding\nany new translations that have been added to the binary since the last time you\nexported.\n\n```sh\n./github-mcp-server --export-translations\ncat github-mcp-server-config.json\n```\n\nYou can also use ENV vars to override the descriptions. The environment\nvariable names are the same as the keys in the JSON file, prefixed with\n`GITHUB_MCP_` and all uppercase.\n\nFor example, to override the `TOOL_ADD_ISSUE_COMMENT_DESCRIPTION` tool, you can\nset the following environment variable:\n\n```sh\nexport GITHUB_MCP_TOOL_ADD_ISSUE_COMMENT_DESCRIPTION=\"an alternative description\"\n```\n\n## Library Usage\n\nThe exported Go API of this module should currently be considered unstable, and subject to breaking changes. In the future, we may offer stability; please file an issue if there is a use case where this would be valuable.\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to [MIT](./LICENSE) for the full terms.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/github-mcp-server",
          "npm_downloads": 14761,
          "npm_package_name": "github-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "graphlit--graphlit-mcp-server": {
          "owner": "graphlit",
          "name": "graphlit-mcp-server",
          "url": "https://github.com/graphlit/graphlit-mcp-server",
          "imageUrl": "https://github.com/graphlit.png",
          "description": "Integrate various data sources such as Slack, Gmail, and web feeds into Graphlit projects, enabling efficient retrieval and searching of relevant content via MCP clients.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:25.262502",
          "collection_timestamp": "2025-10-02T15:00:13.865721",
          "stars": 366,
          "forks": 47,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-01T08:02:03Z",
          "updated_at": "2025-10-01T04:21:42Z",
          "open_issues": 3,
          "readme_content": "[![npm version](https://badge.fury.io/js/graphlit-mcp-server.svg)](https://badge.fury.io/js/graphlit-mcp-server)\n[![smithery badge](https://smithery.ai/badge/@graphlit/graphlit-mcp-server)](https://smithery.ai/server/@graphlit/graphlit-mcp-server)\n\n# Model Context Protocol (MCP) Server for Graphlit Platform\n\n## Overview\n\nThe Model Context Protocol (MCP) Server enables integration between MCP clients and the Graphlit service. This document outlines the setup process and provides a basic example of using the client.\n\nIngest anything from Slack, Discord, websites, Google Drive, email, Jira, Linear or GitHub into a Graphlit project - and then search and retrieve relevant knowledge within an MCP client like Cursor, Windsurf, Goose or Cline.\n\nYour Graphlit project acts as a searchable, and RAG-ready knowledge base across all your developer and product management tools.\n\nDocuments (PDF, DOCX, PPTX, etc.) and HTML web pages will be extracted to Markdown upon ingestion. Audio and video files will be transcribed upon ingestion.\n\nWeb crawling and web search are built-in as MCP tools, with no need to integrate other tools like Firecrawl, Exa, etc. separately.\n\nYou can read more about the MCP Server use cases and features on our [blog](https://www.graphlit.com/blog/graphlit-mcp-server).\n\nWatch our latest [YouTube video](https://www.youtube.com/watch?v=Or-QqonvcAs&t=4s) on using the Graphlit MCP Server with the Goose MCP client.\n\nFor any questions on using the MCP Server, please join our [Discord](https://discord.gg/ygFmfjy3Qx) community and post on the #mcp channel.\n\n<a href=\"https://glama.ai/mcp/servers/fscrivteod\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/fscrivteod/badge\" alt=\"graphlit-mcp-server MCP server\" />\n</a>\n\n## Tools\n\n### Retrieval\n\n- Query Contents\n- Query Collections\n- Query Feeds\n- Query Conversations\n- Retrieve Relevant Sources\n- Retrieve Similar Images\n- Visually Describe Image\n\n### RAG\n\n- Prompt LLM Conversation\n\n### Extraction\n\n- Extract Structured JSON from Text\n\n### Publishing\n\n- Publish as Audio (ElevenLabs Audio)\n- Publish as Image (OpenAI Image Generation)\n\n### Ingestion\n\n- Files\n- Web Pages\n- Messages\n- Posts\n- Emails\n- Issues\n- Text\n- Memory (Short-Term)\n\n### Data Connectors\n\n- Microsoft Outlook email\n- Google Mail\n- Notion\n- Reddit\n- Linear\n- Jira\n- GitHub Issues\n- Google Drive\n- OneDrive\n- SharePoint\n- Dropbox\n- Box\n- GitHub\n- Slack\n- Microsoft Teams\n- Discord\n- Twitter/X\n- Podcasts (RSS)\n\n### Web\n\n- Web Crawling\n- Web Search (including Podcast Search)\n- Web Mapping\n- Screenshot Page\n\n### Notifications\n\n- Slack\n- Email\n- Webhook\n- Twitter/X\n\n### Operations\n\n- Configure Project\n- Create Collection\n- Add Contents to Collection\n- Remove Contents from Collection\n- Delete Collection(s)\n- Delete Feed(s)\n- Delete Content(s)\n- Delete Conversation(s)\n- Is Feed Done?\n- Is Content Done?\n\n### Enumerations\n\n- List Slack Channels\n- List Microsoft Teams Teams\n- List Microsoft Teams Channels\n- List SharePoint Libraries\n- List SharePoint Folders\n- List Linear Projects\n- List Notion Databases\n- List Notion Pages\n- List Dropbox Folders\n- List Box Folders\n- List Discord Guilds\n- List Discord Channels\n- List Google Calendars\n- List Microsoft Calendars\n\n## Resources\n\n- Project\n- Contents\n- Feeds\n- Collections (of Content)\n- Workflows\n- Conversations\n- Specifications\n\n## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n- Node.js installed on your system (recommended version 18.x or higher).\n- An active account on the [Graphlit Platform](https://portal.graphlit.dev) with access to the API settings dashboard.\n\n## Configuration\n\nThe Graphlit MCP Server supports environment variables to be set for authentication and configuration:\n\n- `GRAPHLIT_ENVIRONMENT_ID`: Your environment ID.\n- `GRAPHLIT_ORGANIZATION_ID`: Your organization ID.\n- `GRAPHLIT_JWT_SECRET`: Your JWT secret for signing the JWT token.\n\nYou can find these values in the API settings dashboard on the [Graphlit Platform](https://portal.graphlit.dev).\n\n## Installation\n\n### Installing via VS Code\n\nFor quick installation, use one of the one-click install buttons below:\n\n[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=graphlit&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22organization_id%22%2C%22description%22%3A%22Graphlit%20Organization%20ID%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22environment_id%22%2C%22description%22%3A%22Graphlit%20Environment%20ID%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22jwt_secret%22%2C%22description%22%3A%22Graphlit%20JWT%20Secret%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22graphlit-mcp-server%22%5D%2C%22env%22%3A%7B%22GRAPHLIT_ORGANIZATION_ID%22%3A%22%24%7Binput%3Aorganization_id%7D%22%2C%22GRAPHLIT_ENVIRONMENT_ID%22%3A%22%24%7Binput%3Aenvironment_id%7D%22%2C%22GRAPHLIT_JWT_SECRET%22%3A%22%24%7Binput%3Ajwt_secret%7D%22%7D%7D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=graphlit&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22organization_id%22%2C%22description%22%3A%22Graphlit%20Organization%20ID%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22environment_id%22%2C%22description%22%3A%22Graphlit%20Environment%20ID%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22jwt_secret%22%2C%22description%22%3A%22Graphlit%20JWT%20Secret%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22graphlit-mcp-server%22%5D%2C%22env%22%3A%7B%22GRAPHLIT_ORGANIZATION_ID%22%3A%22%24%7Binput%3Aorganization_id%7D%22%2C%22GRAPHLIT_ENVIRONMENT_ID%22%3A%22%24%7Binput%3Aenvironment_id%7D%22%2C%22GRAPHLIT_JWT_SECRET%22%3A%22%24%7Binput%3Ajwt_secret%7D%22%7D%7D&quality=insiders)\n\nFor manual installation, add the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with others.\n\n> Note that the `mcp` key is not needed in the `.vscode/mcp.json` file.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"organization_id\",\n        \"description\": \"Graphlit Organization ID\",\n        \"password\": true\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"environment_id\",\n        \"description\": \"Graphlit Environment ID\",\n        \"password\": true\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"jwt_secret\",\n        \"description\": \"Graphlit JWT Secret\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"graphlit\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"graphlit-mcp-server\"],\n        \"env\": {\n          \"GRAPHLIT_ORGANIZATION_ID\": \"${input:organization_id}\",\n          \"GRAPHLIT_ENVIRONMENT_ID\": \"${input:environment_id}\",\n          \"GRAPHLIT_JWT_SECRET\": \"${input:jwt_secret}\"\n        }\n      }\n    }\n  }\n}\n```\n\n### Installing via Windsurf\n\nTo install graphlit-mcp-server in Windsurf IDE application, Cline should use NPX:\n\n```bash\nnpx -y graphlit-mcp-server\n```\n\nYour mcp_config.json file should be configured similar to:\n\n```\n{\n    \"mcpServers\": {\n        \"graphlit-mcp-server\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"-y\",\n                \"graphlit-mcp-server\"\n            ],\n            \"env\": {\n                \"GRAPHLIT_ORGANIZATION_ID\": \"your-organization-id\",\n                \"GRAPHLIT_ENVIRONMENT_ID\": \"your-environment-id\",\n                \"GRAPHLIT_JWT_SECRET\": \"your-jwt-secret\",\n            }\n        }\n    }\n}\n```\n\n### Installing via Cline\n\nTo install graphlit-mcp-server in Cline IDE application, Cline should use NPX:\n\n```bash\nnpx -y graphlit-mcp-server\n```\n\nYour cline_mcp_settings.json file should be configured similar to:\n\n```\n{\n    \"mcpServers\": {\n        \"graphlit-mcp-server\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"-y\",\n                \"graphlit-mcp-server\"\n            ],\n            \"env\": {\n                \"GRAPHLIT_ORGANIZATION_ID\": \"your-organization-id\",\n                \"GRAPHLIT_ENVIRONMENT_ID\": \"your-environment-id\",\n                \"GRAPHLIT_JWT_SECRET\": \"your-jwt-secret\",\n            }\n        }\n    }\n}\n```\n\n### Installing via Cursor\n\nTo install graphlit-mcp-server in Cursor IDE application, Cursor should use NPX:\n\n```bash\nnpx -y graphlit-mcp-server\n```\n\nYour mcp.json file should be configured similar to:\n\n```\n{\n    \"mcpServers\": {\n        \"graphlit-mcp-server\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"-y\",\n                \"graphlit-mcp-server\"\n            ],\n            \"env\": {\n                \"GRAPHLIT_ORGANIZATION_ID\": \"your-organization-id\",\n                \"GRAPHLIT_ENVIRONMENT_ID\": \"your-environment-id\",\n                \"GRAPHLIT_JWT_SECRET\": \"your-jwt-secret\",\n            }\n        }\n    }\n}\n```\n\n### Installing via Smithery\n\nTo install graphlit-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@graphlit/graphlit-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @graphlit/graphlit-mcp-server --client claude\n```\n\n### Installing manually\n\nTo use the Graphlit MCP Server in any MCP client application, use:\n\n```\n{\n    \"mcpServers\": {\n        \"graphlit-mcp-server\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"-y\",\n                \"graphlit-mcp-server\"\n            ],\n            \"env\": {\n                \"GRAPHLIT_ORGANIZATION_ID\": \"your-organization-id\",\n                \"GRAPHLIT_ENVIRONMENT_ID\": \"your-environment-id\",\n                \"GRAPHLIT_JWT_SECRET\": \"your-jwt-secret\",\n            }\n        }\n    }\n}\n```\n\nOptionally, you can configure the credentials for data connectors, such as Slack, Google Email and Notion.\nOnly GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET are required.\n\n```\n{\n    \"mcpServers\": {\n        \"graphlit-mcp-server\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"-y\",\n                \"graphlit-mcp-server\"\n            ],\n            \"env\": {\n                \"GRAPHLIT_ORGANIZATION_ID\": \"your-organization-id\",\n                \"GRAPHLIT_ENVIRONMENT_ID\": \"your-environment-id\",\n                \"GRAPHLIT_JWT_SECRET\": \"your-jwt-secret\",\n                \"SLACK_BOT_TOKEN\": \"your-slack-bot-token\",\n                \"DISCORD_BOT_TOKEN\": \"your-discord-bot-token\",\n                \"TWITTER_TOKEN\": \"your-twitter-token\",\n                \"GOOGLE_EMAIL_REFRESH_TOKEN\": \"your-google-refresh-token\",\n                \"GOOGLE_EMAIL_CLIENT_ID\": \"your-google-client-id\",\n                \"GOOGLE_EMAIL_CLIENT_SECRET\": \"your-google-client-secret\",\n                \"LINEAR_API_KEY\": \"your-linear-api-key\",\n                \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"your-github-pat\",\n                \"JIRA_EMAIL\": \"your-jira-email\",\n                \"JIRA_TOKEN\": \"your-jira-token\",\n                \"NOTION_API_KEY\": \"your-notion-api-key\"\n            }\n        }\n    }\n}\n```\n\nNOTE: when running 'npx' on Windows, you may need to explicitly call npx via the command prompt.\n\n```\n\"command\": \"C:\\\\Windows\\\\System32\\\\cmd.exe /c npx\"\n```\n\n## Support\n\nPlease refer to the [Graphlit API Documentation](https://docs.graphlit.dev/).\n\nFor support with the Graphlit MCP Server, please submit a [GitHub Issue](https://github.com/graphlit/graphlit-mcp-server/issues).\n\nFor further support with the Graphlit Platform, please join our [Discord](https://discord.gg/ygFmfjy3Qx) community.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/graphlit-mcp-server",
          "npm_downloads": 39881,
          "npm_package_name": "graphlit-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "heroku--heroku-mcp-server": {
          "owner": "heroku",
          "name": "heroku-mcp-server",
          "url": "https://github.com/heroku/heroku-mcp-server",
          "imageUrl": "https://github.com/heroku.png",
          "description": "Facilitates interaction with Heroku Platform resources using natural language, enabling users to manage applications, dynos, and add-ons through LLM-driven tools.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:26.153939",
          "collection_timestamp": "2025-10-02T15:00:21.685537",
          "stars": 69,
          "forks": 19,
          "license": "Apache License 2.0",
          "language": "TypeScript",
          "created_at": "2025-03-26T14:15:28Z",
          "updated_at": "2025-10-01T23:05:03Z",
          "open_issues": 13,
          "readme_content": "# heroku-mcp-server\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/install-mcp?name=heroku&config=eyJjb21tYW5kIjoibnB4IC15IEBoZXJva3UvbWNwLXNlcnZlciIsImVudiI6eyJIRVJPS1VfQVBJX0tFWSI6IjxZT1VSX0hFUk9LVV9BVVRIX1RPS0VOPiJ9fQ%3D%3D)\n[![smithery badge](https://smithery.ai/badge/@heroku/heroku-mcp-server)](https://smithery.ai/server/@heroku/heroku-mcp-server)\n\n> The Heroku Platform MCP Server works on Common Runtime, Cedar Private and Shield Spaces, and Fir Private Spaces.\n\n## Prerequisites\n\n- **Heroku CLI** must be installed globally on your system, version **10.8.1 or higher**.\n  - [Install or upgrade the Heroku CLI](https://devcenter.heroku.com/articles/heroku-cli)\n\n## Deploy on Heroku\n\n[![Deploy](https://www.herokucdn.com/deploy/button.svg)](https://www.heroku.com/deploy?template=https://github.com/heroku/heroku-mcp-server)\n\n## Overview\n\nThe Heroku Platform MCP Server is a specialized Model Context Protocol (MCP) implementation designed to facilitate\nseamless interaction between large language models (LLMs) and the Heroku Platform. This server provides a robust set of\ntools and capabilities that enable LLMs to read, manage, and operate Heroku Platform resources.\n\nKey Features:\n\n- Direct interaction with Heroku Platform resources through LLM-driven tools\n- Secure and authenticated access to Heroku Platform APIs, leveraging the Heroku CLI\n- Natural language interface for Heroku Platform interactions\n\nNote: The Heroku Platform MCP Server is currently in early development. As we continue to enhance and refine the\nimplementation, the available functionality and tools may evolve. We welcome feedback and contributions to help shape\nthe future of this project.\n\n> **Note:** The [Heroku Platform MCP Server](https://devcenter.heroku.com/articles/heroku-mcp-server) requires the\n> Heroku CLI to be installed globally (v10.8.1+). Ensure you have the correct version by running `heroku --version`.\n\n## Configure the Heroku Platform MCP Server\n\nYou can configure Claude Desktop, Zed, Cursor, Windsurf, and other clients to work with the Heroku Platform MCP Server.\n\n### Configure the Heroku Platform MCP Server with `heroku mcp:start`\n\nUse `heroku mcp:start` to launch the Heroku Platform MCP Server. We recommend this method as it leverages your existing\nHeroku CLI authentication, so you don't need to set the\n[`HEROKU_API_KEY`](https://devcenter.heroku.com/articles/heroku-mcp-server#authentication) environment variable. The\n`heroku mcp:start` command is available in Heroku CLI version 10.8.1 and later.\n\nThere are several benefits to configuring with `heroku mcp:start`:\n\n- No need to manage or expose your Heroku API key\n- Uses your current Heroku CLI authentication context\n- Works seamlessly with supported clients\n\n#### Example configuration for [Claude Desktop](https://claude.ai/download):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"heroku mcp:start\"\n    }\n  }\n}\n```\n\n#### Example configuration for [Zed](https://github.com/zed-industries/zed):\n\n```json\n{\n  \"context_servers\": {\n    \"heroku\": {\n      \"command\": {\n        \"path\": \"heroku\",\n        \"args\": [\"mcp:start\"]\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [Cursor](https://www.cursor.com/):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"heroku mcp:start\"\n    }\n  }\n}\n```\n\n#### Example configuration for [Windsurf](https://www.windsurf.com/):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"heroku mcp:start\"\n    }\n  }\n}\n```\n\n#### Example configuration for [Cline](https://cline.bot):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"heroku mcp:start\"\n    }\n  }\n}\n```\n\n#### Example configuration for [VSCode](https://code.visualstudio.com/):\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"heroku\": {\n        \"type\": \"stdio\",\n        \"command\": \"heroku\",\n        \"args\": [\"mcp:start\"]\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [Trae](https://trae.ai):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"heroku mcp:start\"\n    }\n  }\n}\n```\n\n> **Note:** When you use `heroku mcp:start`, the server authenticates using your current Heroku CLI session so you don't\n> need to set the `HEROKU_API_KEY` environment variable. We recommend you use `heroku mcp:start`, but if you prefer to\n> use an API key, you can use the alternate configuration below.\n\n### Configure the Heroku Platform MCP Server with `npx -y @heroku/mcp-server`\n\nYou can also launch the Heroku Platform MCP Server using the `npx -y @heroku/mcp-server` command. This method requires\nyou to set the [`HEROKU_API_KEY`](https://devcenter.heroku.com/articles/heroku-mcp-server#authentication) environment\nvariable with your Heroku\n[authorization token](https://devcenter.heroku.com/articles/authentication#retrieving-the-api-token).\n\n#### Generating the `HEROKU_API_KEY`\n\nGenerate a Heroku authorization token with one of these methods:\n\n- Use the Heroku CLI command:\n\n  ```sh\n    heroku authorizations:create\n  ```\n\n- Use an existing token in the CLI\n\n  ```sh\n    heroku auth:token\n  ```\n\n  Copy the token and use it as your `HEROKU_API_KEY` in the following steps.\n\n- In your [Heroku Dashboard](https://dashboard.heroku.com/account/applications):\n  1. Select your avatar, then select **Account Settings**.\n  2. Open the Applications tab.\n  3. Next to **Authorizations**, click **Create authorization**.\n\n#### Example configuration for [Claude Desktop](https://claude.ai/download):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@heroku/mcp-server\"],\n      \"env\": {\n        \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [Zed](https://github.com/zed-industries/zed):\n\n```json\n{\n  \"context_servers\": {\n    \"heroku\": {\n      \"command\": {\n        \"path\": \"npx\",\n        \"args\": [\"-y\", \"@heroku/mcp-server\"],\n        \"env\": {\n          \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\"\n        }\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [Cursor](https://www.cursor.com/):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"npx -y @heroku/mcp-server\",\n      \"env\": {\n        \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [Windsurf](https://www.windsurf.com/):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@heroku/mcp-server\"],\n      \"env\": {\n        \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [Cline](https://cline.bot):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@heroku/mcp-server\"],\n      \"env\": {\n        \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [VSCode](https://code.visualstudio.com/):\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"heroku\": {\n        \"type\": \"stdio\",\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@heroku/mcp-server\"],\n        \"env\": {\n          \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\"\n        }\n      }\n    }\n  }\n}\n```\n\n#### Example configuration for [Trae](https://trae.ai):\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@heroku/mcp-server\"],\n      \"env\": {\n        \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n> **Note:** When you use `npx -y @heroku/mcp-server`, you must set the `HEROKU_API_KEY` environment variable with your\n> Heroku authorization token.\n\n## Available Tools\n\n### Application Management\n\n- `list_apps` - List all Heroku apps. You can filter apps by personal, collaborator, team, or space.\n- `get_app_info` - Get detailed information about an app, including its configuration, dynos, and add-ons.\n- `create_app` - Create a new app with customizable settings for region, team, and space.\n- `rename_app` - Rename an existing app.\n- `transfer_app` - Transfer ownership of an app to another user or team.\n- `deploy_to_heroku` - Deploy projects to Heroku with an `app.json` configuration, supporting team deployments, private\n  spaces, and environment setups.\n- `deploy_one_off_dyno` - Execute code or commands in a sandboxed environment on a Heroku one-off dyno. Supports file\n  creation, network access, environment variables, and automatic cleanup. Ideal for running scripts, tests, or temporary\n  workloads.\n\n### Process & Dyno Management\n\n- `ps_list` - List all dynos for an app.\n- `ps_scale` - Scale the number of dynos up or down, or resize dynos.\n- `ps_restart` - Restart specific dynos, process types, or all dynos.\n\n### Add-ons\n\n- `list_addons` - List all add-ons for all apps or for a specific app.\n- `get_addon_info` - Get detailed information about a specific add-on.\n- `create_addon` - Provision a new add-on for an app.\n\n### Maintenance & Logs\n\n- `maintenance_on` - Enable maintenance mode for an app.\n- `maintenance_off` - Disable maintenance mode for an app.\n- `get_app_logs` - View application logs.\n\n### Pipeline Management\n\n- `pipelines_create` - Create a new pipeline.\n- `pipelines_promote` - Promote apps to the next stage in a pipeline.\n- `pipelines_list` - List available pipelines.\n- `pipelines_info` - Get detailed pipeline information.\n\n### Team & Space Management\n\n- `list_teams` - List teams you belong to.\n- `list_private_spaces` - List available spaces.\n\n### PostgreSQL Database Management\n\n- `pg_psql` - Execute SQL queries against the Heroku PostgreSQL database.\n- `pg_info` - Display detailed database information.\n- `pg_ps` - View active queries and execution details.\n- `pg_locks` - View database locks and identify blocking transactions.\n- `pg_outliers` - Identify resource-intensive queries.\n- `pg_credentials` - Manage database credentials and access.\n- `pg_kill` - Terminate specific database processes.\n- `pg_maintenance` - Show database maintenance information.\n- `pg_backups` - Manage database backups and schedules.\n- `pg_upgrade` - Upgrade PostgreSQL to a newer version.\n\n## Debugging\n\nYou can use the [MCP inspector](https://modelcontextprotocol.io/docs/tools/inspector) or the\n[VS Code Run and Debug function](https://code.visualstudio.com/docs/debugtest/debugging#_start-a-debugging-session) to\nrun and debug the server.\n\n1. Link the project as a global CLI using `npm link` from the project root.\n2. Build with `npm run build:dev` or watch for file changes and build automatically with `npm run build:watch`.\n\n### Use the MCP Inspector\n\nUse the MCP inspector with no breakpoints in the code:\n\n```\n# Breakpoints are not available\nnpx @modelcontextprotocol/inspector heroku-mcp-server\n```\n\nAlternatively, if you installed the package in a specific directory or are actively developing on the Heroku MCP server:\n\n```\ncd /path/to/servers\nnpx @modelcontextprotocol/inspector dist/index.js\n```\n\n### Use the VS Code Run and Debug Function\n\nUse the VS Code\n[Run and Debug launcher](https://code.visualstudio.com/docs/debugtest/debugging#_start-a-debugging-session) with fully\nfunctional breakpoints in the code:\n\n1. Locate and select the run debug.\n2. Select the configuration labeled \"`MCP Server Launcher`\" in the dropdown.\n3. Select the run/debug button.\n\n### VS Code / Cursor Debugging Setup\n\nTo set up local debugging with breakpoints:\n\n1. Store your Heroku auth token in the VS Code user settings:\n   - Open the Command Palette (Cmd/Ctrl + Shift + P).\n   - Type `Preferences: Open User Settings (JSON)`.\n   - Add the following snippet:\n\n   ```json\n   {\n     \"heroku.mcp.authToken\": \"your-token-here\"\n   }\n   ```\n\n2. Create or update `.vscode/launch.json`:\n\n   ```json\n   {\n     \"version\": \"0.2.0\",\n     \"configurations\": [\n       {\n         \"type\": \"node\",\n         \"request\": \"launch\",\n         \"name\": \"MCP Server Launcher\",\n         \"skipFiles\": [\"<node_internals>/**\"],\n         \"program\": \"${workspaceFolder}/node_modules/@modelcontextprotocol/inspector/bin/cli.js\",\n         \"outFiles\": [\"${workspaceFolder}/**/dist/**/*.js\"],\n         \"env\": {\n           \"HEROKU_API_KEY\": \"${config:heroku.mcp.authToken}\",\n           \"DEBUG\": \"true\"\n         },\n         \"args\": [\"heroku-mcp-server\"],\n         \"sourceMaps\": true,\n         \"console\": \"integratedTerminal\",\n         \"internalConsoleOptions\": \"neverOpen\",\n         \"preLaunchTask\": \"npm: build:watch\"\n       },\n       {\n         \"type\": \"node\",\n         \"request\": \"attach\",\n         \"name\": \"Attach to Debug Hook Process\",\n         \"port\": 9332,\n         \"skipFiles\": [\"<node_internals>/**\"],\n         \"sourceMaps\": true,\n         \"outFiles\": [\"${workspaceFolder}/dist/**/*.js\"]\n       },\n       {\n         \"type\": \"node\",\n         \"request\": \"attach\",\n         \"name\": \"Attach to REPL Process\",\n         \"port\": 9333,\n         \"skipFiles\": [\"<node_internals>/**\"],\n         \"sourceMaps\": true,\n         \"outFiles\": [\"${workspaceFolder}/dist/**/*.js\"]\n       }\n     ],\n     \"compounds\": [\n       {\n         \"name\": \"Attach to MCP Server\",\n         \"configurations\": [\"Attach to Debug Hook Process\", \"Attach to REPL Process\"]\n       }\n     ]\n   }\n   ```\n\n3. Create `.vscode/tasks.json`:\n\n   ```json\n   {\n     \"version\": \"2.0.0\",\n     \"tasks\": [\n       {\n         \"type\": \"npm\",\n         \"script\": \"build:watch\",\n         \"group\": {\n           \"kind\": \"build\",\n           \"isDefault\": true\n         },\n         \"problemMatcher\": [\"$tsc\"]\n       }\n     ]\n   }\n   ```\n\n4. (Optional) Set breakpoints in your TypeScript files.\n\n5. Press F5 or use the **`Run and Debug`** sidebar.\n\nNote: the debugger automatically builds your TypeScript files before launching.\n\n### Installing via Smithery\n\nTo install Heroku Platform MCP Server for Claude Desktop automatically via\n[Smithery](https://smithery.ai/server/@heroku/heroku-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @heroku/heroku-mcp-server --client claude\n```\n\n## Environment Variables\n\nThe Heroku Platform MCP Server supports the following environment variables:\n\n### `HEROKU_API_KEY`\n\nYour Heroku authorization token. Required for authentication with the Heroku Platform.\n\n### `MCP_SERVER_REQUEST_TIMEOUT`\n\nTimeout in milliseconds for command execution. Defaults to 15000 (15 seconds) if not set.\n\nExample configuration with custom timeout:\n\n```json\n{\n  \"mcpServers\": {\n    \"heroku\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@heroku/mcp-server\"],\n      \"env\": {\n        \"HEROKU_API_KEY\": \"<YOUR_HEROKU_AUTH_TOKEN>\",\n        \"MCP_SERVER_REQUEST_TIMEOUT\": \"30000\"\n      }\n    }\n  }\n}\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "hyperbrowserai--mcp": {
          "owner": "hyperbrowserai",
          "name": "mcp",
          "url": "https://github.com/hyperbrowserai/mcp",
          "imageUrl": "https://github.com/hyperbrowserai.png",
          "description": "Scrape and extract structured data from webpages and crawl internet resources. Provides access to general purpose browser agents for tasks involving web interactions.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:27.137572",
          "collection_timestamp": "2025-10-02T15:00:25.714085",
          "stars": 619,
          "forks": 51,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-02-25T19:06:01Z",
          "updated_at": "2025-09-30T07:34:29Z",
          "open_issues": 4,
          "readme_content": "# Hyperbrowser MCP Server\n[![smithery badge](https://smithery.ai/badge/@hyperbrowserai/mcp)](https://smithery.ai/server/@hyperbrowserai/mcp)\n\n![Frame 5](https://github.com/user-attachments/assets/3309a367-e94b-418a-a047-1bf1ad549c0a)\n\nThis is Hyperbrowser's Model Context Protocol (MCP) Server. It provides various tools to scrape, extract structured data, and crawl webpages. It also provides easy access to general purpose browser agents like OpenAI's CUA, Anthropic's Claude Computer Use, and Browser Use.\n\nMore information about the Hyperbrowser can be found [here](https://docs.hyperbrowser.ai/). The hyperbrowser API supports a superset of features present in the mcp server.\n\nMore information about the Model Context Protocol can be found [here](https://modelcontextprotocol.io/introduction).\n\n## Table of Contents\n\n- [Installation](#installation)\n- [Usage](#usage)\n- [Tools](#tools)\n- [Configuration](#configuration)\n- [License](#license)\n\n## Installation\n\n### Manual Installation\nTo install the server, run:\n\n```bash\nnpx hyperbrowser-mcp <YOUR-HYPERBROWSER-API-KEY>\n```\n\n## Running on Cursor\nAdd to `~/.cursor/mcp.json` like this:\n```json\n{\n  \"mcpServers\": {\n    \"hyperbrowser\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"hyperbrowser-mcp\"],\n      \"env\": {\n        \"HYPERBROWSER_API_KEY\": \"YOUR-API-KEY\"\n      }\n    }\n  }\n}\n```\n\n## Running on Windsurf\nAdd to your `./codeium/windsurf/model_config.json` like this:\n```json\n{\n  \"mcpServers\": {\n    \"hyperbrowser\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"hyperbrowser-mcp\"],\n      \"env\": {\n        \"HYPERBROWSER_API_KEY\": \"YOUR-API-KEY\"\n      }\n    }\n  }\n}\n```\n\n### Development\n\nFor development purposes, you can run the server directly from the source code.\n\n1. Clone the repository:\n\n   ```sh\n   git clone git@github.com:hyperbrowserai/mcp.git hyperbrowser-mcp\n   cd hyperbrowser-mcp\n   ```\n\n2. Install dependencies:\n\n   ```sh\n   npm install # or yarn install\n   npm run build\n   ```\n\n3. Run the server:\n\n   ```sh\n   node dist/server.js\n   ```\n\n## Claude Desktop app\nThis is an example config for the Hyperbrowser MCP server for the Claude Desktop client.\n\n```json\n{\n  \"mcpServers\": {\n    \"hyperbrowser\": {\n      \"command\": \"npx\",\n      \"args\": [\"--yes\", \"hyperbrowser-mcp\"],\n      \"env\": {\n        \"HYPERBROWSER_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\n\n## Tools\n* `scrape_webpage` - Extract formatted (markdown, screenshot etc) content from any webpage \n* `crawl_webpages` - Navigate through multiple linked pages and extract LLM-friendly formatted content\n* `extract_structured_data` - Convert messy HTML into structured JSON\n* `search_with_bing` - Query the web and get results with Bing search\n* `browser_use_agent` - Fast, lightweight browser automation with the Browser Use agent\n* `openai_computer_use_agent` - General-purpose automation using OpenAI‚Äôs CUA model\n* `claude_computer_use_agent` - Complex browser tasks using Claude computer use\n* `create_profile` - Creates a new persistent Hyperbrowser profile.\n* `delete_profile` - Deletes an existing persistent Hyperbrowser profile.\n* `list_profiles` - Lists existing persistent Hyperbrowser profiles.\n\n### Installing via Smithery\n\nTo install Hyperbrowser MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@hyperbrowserai/mcp):\n\n```bash\nnpx -y @smithery/cli install @hyperbrowserai/mcp --client claude\n```\n\n## Resources\n\nThe server provides the documentation about hyperbrowser through the `resources` methods. Any client which can do discovery over resources has access to it.\n\n## License\n\nThis project is licensed under the MIT License.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp",
          "npm_downloads": 17508,
          "npm_package_name": "mcp",
          "npm_success": true,
          "npm_error": null
        },
        "integromat--make-mcp-server": {
          "owner": "integromat",
          "name": "make-mcp-server",
          "url": "https://github.com/integromat/make-mcp-server",
          "imageUrl": "https://github.com/integromat.png",
          "description": "Connects to Make accounts to utilize On-Demand scenarios as callable tools for AI assistants, enabling seamless interaction with automation workflows. Returns output in structured JSON for AI processing.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:28.308672",
          "collection_timestamp": "2025-10-02T15:00:33.193446",
          "stars": 136,
          "forks": 35,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-10T15:21:12Z",
          "updated_at": "2025-09-29T06:26:01Z",
          "open_issues": 5,
          "readme_content": "# Make MCP Server (legacy)\n\n**A modern, cloud-based version of the Make MCP Server is now available. For most use cases, we recommend using [this new version](https://developers.make.com/mcp-server).**\n\nA Model Context Protocol server that enables Make scenarios to be utilized as tools by AI assistants. This integration allows AI systems to trigger and interact with your Make automation workflows.\n\n## How It Works\n\nThe MCP server:\n\n-   Connects to your Make account and identifies all scenarios configured with \"On-Demand\" scheduling\n-   Parses and resolves input parameters for each scenario, providing AI assistants with meaningful parameter descriptions\n-   Allows AI assistants to invoke scenarios with appropriate parameters\n-   Returns scenario output as structured JSON, enabling AI assistants to properly interpret the results\n\n## Benefits\n\n-   Turn your Make scenarios into callable tools for AI assistants\n-   Maintain complex automation logic in Make while exposing functionality to AI systems\n-   Create bidirectional communication between your AI assistants and your existing automation workflows\n\n## Usage with Claude Desktop\n\n### Prerequisites\n\n-   NodeJS\n-   MCP Client (like Claude Desktop App)\n-   Make API Key with `scenarios:read` and `scenarios:run` scopes\n\n### Installation\n\nTo use this server with the Claude Desktop app, add the following configuration to the \"mcpServers\" section of your `claude_desktop_config.json`:\n\n```json\n{\n    \"mcpServers\": {\n        \"make\": {\n            \"command\": \"npx\",\n            \"args\": [\"-y\", \"@makehq/mcp-server\"],\n            \"env\": {\n                \"MAKE_API_KEY\": \"<your-api-key>\",\n                \"MAKE_ZONE\": \"<your-zone>\",\n                \"MAKE_TEAM\": \"<your-team-id>\"\n            }\n        }\n    }\n}\n```\n\n-   `MAKE_API_KEY` - You can generate an API key in your Make profile.\n-   `MAKE_ZONE` - The zone your organization is hosted in (e.g., `eu2.make.com`).\n-   `MAKE_TEAM` - You can find the ID in the URL of the Team page.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "its-dart--dart-mcp-server": {
          "owner": "its-dart",
          "name": "dart-mcp-server",
          "url": "https://github.com/its-dart/dart-mcp-server",
          "imageUrl": "https://github.com/its-dart.png",
          "description": "A server implementation for the Model Context Protocol using Dart, enabling connection between AI models and various tools or data sources. It supports prompt management and resource templates, along with tools for task and document management.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:29.652272",
          "collection_timestamp": "2025-10-02T15:00:36.969282",
          "stars": 119,
          "forks": 27,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-02-22T02:29:56Z",
          "updated_at": "2025-10-01T20:06:57Z",
          "open_issues": 4,
          "readme_content": "<div align=\"center\">\n  <h1>Dart MCP Server</h1>\n  <p>\n    <a href=\"https://npmjs.com/package/dart-mcp-server\"><img src=\"https://img.shields.io/npm/v/dart-mcp-server\" alt=\"NPM\"></a>\n    <a href=\"LICENSE\"><img src=\"https://img.shields.io/github/license/its-dart/dart-mcp-server\" alt=\"License\"></a>\n  </p>\n</div>\n\n[Dart](https://dartai.com?nr=1) is Project Management powered by AI.\n\n> [!WARNING]\n> The Dart local MCP server is deprecated in favor of the simplified and improved hosted Dart MCP server, which you can [configure with these instructions](https://help.dartai.com/en/articles/10733406).\n\n<details>\n<summary>Deprecated information</summary>\n`dart-mcp-server` is the official AI [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol) server for Dart.\n\n- [Features](#features)\n  - [Prompts](#prompts)\n  - [Resource templates](#resource-templates)\n  - [Tools](#tools)\n    - [Task management](#task-management)\n    - [Document management](#document-management)\n- [Setup](#setup)\n  - [Find the MCP settings file for the client](#find-the-mcp-settings-file-for-the-client)\n    - [Claude Desktop](#claude-desktop)\n    - [Claude Code](#claude-code)\n    - [Cursor](#cursor)\n    - [Cline](#cline)\n    - [Windsurf](#windsurf)\n    - [Any other client](#any-other-client)\n  - [Set up the MCP server](#set-up-the-mcp-server)\n  - [Variant: setup with Docker](#variant-setup-with-docker)\n- [Help and Resources](#help-and-resources)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Features\n\n### Prompts\n\nThe following prompts are available\n\n- `create-task` - Create a new task in Dart with title, description, status, priority, and assignee\n- `create-doc` - Create a new document in Dart with title, text content, and folder\n- `summarize-tasks` - Get a summary of tasks with optional filtering by status and assignee\n\nThese prompts make it easy for AI assistants to perform common actions in Dart without needing to understand the underlying API details.\n\n### Resource templates\n\nThe following resources are available\n\n- `dart-config:` - Configuration information about the user's space\n- `dart-task:///{taskId}` - Detailed information about specific tasks\n- `dart-doc:///{docId}` - Detailed information about specific docs\n\n### Tools\n\nThe following tools are available\n\n#### Task management\n\n- `get_config` - Get information about the user's space, including available assignees, dartboards, folders, statuses, tags, priorities, and sizes\n- `list_tasks` - List tasks with optional filtering by assignee, status, dartboard, priority, due date, and more\n- `create_task` - Create a new task with title, description, status, priority, size, dates, dartboard, assignees, tags, and parent task\n- `get_task` - Retrieve an existing task by its ID\n- `update_task` - Update an existing task's properties\n- `delete_task` - Move a task to the trash (recoverable)\n- `add_task_comment` - Add a comment to an existing task\n\n#### Document management\n\n- `list_docs` - List docs with optional filtering by folder, title, text content, and more\n- `create_doc` - Create a new doc with title, text content, and folder\n- `get_doc` - Retrieve an existing doc by its ID\n- `update_doc` - Update an existing doc's properties\n- `delete_doc` - Move a doc to the trash (recoverable)\n\nEach tool supports comprehensive input validation and returns structured JSON responses.\n\n## Setup\n\nThe easiest way to run the MCP server is with `npx`, but a Docker setup is also available.\n\n### Find the MCP settings file for the client\n\n#### Claude Desktop\n\n1. [Install Claude Desktop](https://claude.ai/download) as needed\n2. Open the config file by opening the Claude Desktop app, going into its Settings, opening the 'Developer' tab, and clicking the 'Edit Config' button\n3. Follow the 'Set up the MCP server' steps below\n\n#### Claude Code\n\n1. Install [Claude Code](https://docs.anthropic.com/en/docs/claude-code/getting-started) as needed\n2. Copy your authentication token from [your Dart profile](https://app.dartai.com/?settings=account)\n3. Run the following command, being sure to replace `dsa...` with your actual Dart token\n\n   ```bash\n   claude mcp add dart -e DART_TOKEN=dsa_... -- npx -y dart-mcp-server@latest\n   ```\n\n#### Cursor\n\n1. [Install Cursor](https://www.cursor.com/downloads) as needed\n2. Open the config file by opening Cursor, going into 'Cursor Settings' (not the normal VSCode IDE settings), opening the 'MCP' tab, and clicking the 'Add new global MCP server' button\n3. Follow the 'Set up the MCP server' steps below\n\n#### Cline\n\n1. [Install Cline](https://cline.bot/) in your IDE as needed\n2. Open the config file by opening your IDE, opening the Cline sidebar, clicking the 'MCP Servers' icon button that is second from left at the top, opening the 'Installed' tab, and clicking the 'Configure MCP Servers' button\n3. Follow the 'Set up the MCP server' steps below\n\n#### Windsurf\n\n1. [Install Windsurf](https://windsurf.com/download) as needed\n2. Open the config file by opening Windsurf, going into 'Windsurf Settings' (not the normal VSCode IDE settings), opening the 'Cascade' tab, and clicking the 'View raw config' button in the 'Model Context Protocol (MCP) Servers' section\n3. Follow the 'Set up the MCP server' steps below\n\n#### Any other client\n\n1. Find the MCP settings file, usually something like `[client]_mcp_config.json`\n2. Follow the 'Set up the MCP server' steps below\n\n### Set up the MCP server\n\n1. [Install npx](https://nodejs.org/en/download), which comes bundled with Node, as needed\n2. Copy your authentication token from [your Dart profile](https://app.dartai.com/?settings=account)\n3. Add the following to your MCP setup, being sure to replace `dsa...` with your actual Dart token\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"Dart\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"dart-mcp-server@latest\"],\n         \"env\": {\n           \"DART_TOKEN\": \"dsa_...\"\n         }\n       }\n     }\n   }\n   ```\n\n### Variant: setup with Docker\n\nIf the `npx` setup above does not work well, we also provide a Docker setup. Follow the instructions above to find the MCP settings file\n\n1. [Install Docker](https://www.docker.com/products/docker-desktop/) as needed\n2. Build the Docker container with `docker build -t mcp/dart .`\n3. Copy your authentication token from [your Dart profile](https://app.dartai.com/?settings=account)\n4. Add the following to your MCP setup, being sure to replace `dsa...` with your actual Dart token\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"Dart\": {\n         \"command\": \"bash\",\n         \"args\": [\n           \"-c\",\n           \"docker rm -f dart-mcp >/dev/null 2>&1 || true; docker run -i --rm --name dart-mcp -e DART_TOKEN mcp/dart\"\n         ],\n         \"env\": {\n           \"DART_TOKEN\": \"dsa_...\"\n         }\n       }\n     }\n   }\n   ```\n\n## Help and Resources\n\n- [Homepage](https://dartai.com/?nr=1)\n- [Web App](https://app.dartai.com/)\n- [Help Center](https://help.dartai.com/)\n- [Bugs and Features](https://app.dartai.com/p/r/JFyPnhL9En61)\n- [Library Source](https://github.com/its-dart/dart-mcp-server/)\n- [Chat on Discord](https://discord.gg/RExv8jEkSh)\n- Email us at [support@dartai.com](mailto:support@dartai.com)\n\n## Contributing\n\nContributions are welcome! Please open an issue or submit a pull request.\n\n## License\n\nThis project is licensed under [the MIT License](LICENSE).\n</details>\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/dart-mcp-server",
          "npm_downloads": 15862,
          "npm_package_name": "dart-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "jamsocket--forevervm": {
          "owner": "jamsocket",
          "name": "forevervm",
          "url": "https://github.com/jamsocket/forevervm",
          "imageUrl": "https://github.com/jamsocket.png",
          "description": "Enable agents to execute Python code seamlessly within a REPL environment, allowing for on-the-fly script creation and execution. It enhances automation and coding capabilities directly within workflows.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:31.067975",
          "collection_timestamp": "2025-10-02T15:00:42.247992",
          "stars": 217,
          "forks": 20,
          "license": "MIT License",
          "language": "Rust",
          "created_at": "2025-01-18T14:15:35Z",
          "updated_at": "2025-09-18T11:53:49Z",
          "open_issues": 2,
          "readme_content": "[foreverVM](https://forevervm.com)\n==================================\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/jamsocket/forevervm?style=social)](https://github.com/jamsocket/forevervm)\n[![Chat on Discord](https://img.shields.io/discord/939641163265232947?color=404eed&label=discord)](https://discord.gg/N5sEpsuhh9)\n\n| repo                                                | version                     |\n|-----------------------------------------------------|------------------------------|\n| [cli](https://github.com/jamsocket/forevervm) | [![npm](https://img.shields.io/npm/v/forevervm)](https://www.npmjs.com/package/forevervm) |\n| [sdk](https://github.com/jamsocket/forevervm) | [![npm](https://img.shields.io/npm/v/@forevervm/sdk)](https://www.npmjs.com/package/@forevervm/sdk) |\n\nforeverVM provides an API for running arbitrary, stateful Python code securely.\n\nThe core concepts in foreverVM are **machines** and **instructions**.\n\n**Machines** represent a stateful Python process. You interact with a machine by running **instructions**\n(Python statements and expressions) on it, and receiving the results. A machine processes one instruction\nat a time.\n\nGetting started\n---------------\n\nYou will need an API token (if you need one, reach out to [paul@jamsocket.com](mailto:paul@jamsocket.com)).\n\nThe easiest way to try out foreverVM is using the CLI. First, you will need to log in:\n\n```bash\nnpx forevervm login\n```\n\nOnce logged in, you can open a REPL interface with a new machine:\n\n```bash\nnpx forevervm repl\n```\n\nWhen foreverVM starts your machine, it gives it an ID that you can later use to reconnect to it. You can reconnect to a machine like this:\n\n```bash\nnpx forevervm repl [machine_name]\n```\n\nYou can list your machines (in reverse order of creation) like this:\n\n```bash\nnpx forevervm machine list\n```\n\nYou don't need to terminate machines -- foreverVM will automatically swap them from memory to disk when they are idle, and then\nautomatically swap them back when needed. This is what allows foreverVM to run repls ‚Äúforever‚Äù.\n\nUsing the API\n-------------\n\n```typescript\nimport { ForeverVM } from '@forevervm/sdk'\n\nconst token = process.env.FOREVERVM_TOKEN\nif (!token) {\n  throw new Error('FOREVERVM_TOKEN is not set')\n}\n\n// Initialize foreverVM\nconst fvm = new ForeverVM({ token })\n\n// Connect to a new machine.\nconst repl = fvm.repl()\n\n// Execute some code\nlet execResult = repl.exec('4 + 4')\n\n// Get the result\nconsole.log('result:', await execResult.result)\n\n// We can also print stdout and stderr\nexecResult = repl.exec('for i in range(10):\\n  print(i)')\n\nfor await (const output of execResult.output) {\n  console.log(output.stream, output.data)\n}\n\nprocess.exit(0)\n```\n\nWorking with Tags\n----------------\n\nYou can create machines with tags and filter machines by tags:\n\n```typescript\nimport { ForeverVM } from '@forevervm/sdk'\n\nconst fvm = new ForeverVM({ token: process.env.FOREVERVM_TOKEN })\n\n// Create a machine with tags\nconst machineResponse = await fvm.createMachine({\n  tags: { \n    env: 'production', \n    owner: 'user123',\n    project: 'demo'\n  }\n})\n\n// List machines filtered by tags\nconst productionMachines = await fvm.listMachines({\n  tags: { env: 'production' }\n})\n```\n\nMemory Limits\n----------------\n\nYou can create machines with memory limits by specifying the memory size in megabytes:\n\n```typescript\n// Create a machine with 512MB memory limit\nconst machineResponse = await fvm.createMachine({\n  memory_mb: 512,\n})\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/forevervm",
          "npm_downloads": 2784,
          "npm_package_name": "forevervm",
          "npm_success": true,
          "npm_error": null
        },
        "makenotion--notion-mcp-server": {
          "owner": "makenotion",
          "name": "notion-mcp-server",
          "url": "https://github.com/makenotion/notion-mcp-server",
          "imageUrl": "https://github.com/makenotion.png",
          "description": "Integrate applications with Notion by automating tasks and managing workspace contents through the Notion API. Support for various operations is provided while adhering to the limitations of the Notion API.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:32.922548",
          "collection_timestamp": "2025-10-02T15:00:46.125552",
          "stars": 3259,
          "forks": 310,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-10T18:09:08Z",
          "updated_at": "2025-10-02T09:00:06Z",
          "open_issues": 66,
          "readme_content": "# Notion MCP Server\n\n> [!NOTE] \n> \n> We‚Äôve introduced **Notion MCP**, a remote MCP server with the following improvements:\n> - Easy installation via standard OAuth. No need to fiddle with JSON or API token anymore.\n> - Powerful tools tailored to AI agents. These tools are designed with optimized token consumption in mind.\n> \n> Learn more and try it out [here](https://developers.notion.com/docs/mcp)\n\n\n![notion-mcp-sm](https://github.com/user-attachments/assets/6c07003c-8455-4636-b298-d60ffdf46cd8)\n\nThis project implements an [MCP server](https://spec.modelcontextprotocol.io/) for the [Notion API](https://developers.notion.com/reference/intro). \n\n![mcp-demo](https://github.com/user-attachments/assets/e3ff90a7-7801-48a9-b807-f7dd47f0d3d6)\n\n### Installation\n\n#### 1. Setting up Integration in Notion:\nGo to [https://www.notion.so/profile/integrations](https://www.notion.so/profile/integrations) and create a new **internal** integration or select an existing one.\n\n![Creating a Notion Integration token](docs/images/integrations-creation.png)\n\nWhile we limit the scope of Notion API's exposed (for example, you will not be able to delete databases via MCP), there is a non-zero risk to workspace data by exposing it to LLMs. Security-conscious users may want to further configure the Integration's _Capabilities_. \n\nFor example, you can create a read-only integration token by giving only \"Read content\" access from the \"Configuration\" tab:\n\n![Notion Integration Token Capabilities showing Read content checked](docs/images/integrations-capabilities.png)\n\n#### 2. Connecting content to integration:\nEnsure relevant pages and databases are connected to your integration.\n\nTo do this, visit the **Access** tab in your internal integration settings. Edit access and select the pages you'd like to use.\n![Integration Access tab](docs/images/integration-access.png)\n\n![Edit integration access](docs/images/page-access-edit.png)\n\nAlternatively, you can grant page access individually. You'll need to visit the target page, and click on the 3 dots, and select \"Connect to integration\". \n\n![Adding Integration Token to Notion Connections](docs/images/connections.png)\n\n#### 3. Adding MCP config to your client:\n\n##### Using npm:\n\n**Cursor & Claude:**\n\nAdd the following to your `.cursor/mcp.json` or `claude_desktop_config.json` (MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`)\n\n**Option 1: Using NOTION_TOKEN (recommended)**\n```javascript\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@notionhq/notion-mcp-server\"],\n      \"env\": {\n        \"NOTION_TOKEN\": \"ntn_****\"\n      }\n    }\n  }\n}\n```\n\n**Option 2: Using OPENAPI_MCP_HEADERS (for advanced use cases)**\n```javascript\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@notionhq/notion-mcp-server\"],\n      \"env\": {\n        \"OPENAPI_MCP_HEADERS\": \"{\\\"Authorization\\\": \\\"Bearer ntn_****\\\", \\\"Notion-Version\\\": \\\"2022-06-28\\\" }\"\n      }\n    }\n  }\n}\n```\n\n**Zed**\n\nAdd the following to your `settings.json`\n\n```json\n{\n  \"context_servers\": {\n    \"some-context-server\": {\n      \"command\": {\n        \"path\": \"npx\",\n        \"args\": [\"-y\", \"@notionhq/notion-mcp-server\"],\n        \"env\": {\n          \"OPENAPI_MCP_HEADERS\": \"{\\\"Authorization\\\": \\\"Bearer ntn_****\\\", \\\"Notion-Version\\\": \\\"2022-06-28\\\" }\"\n        }\n      },\n      \"settings\": {}\n    }\n  }\n}\n```\n\n##### Using Docker:\n\nThere are two options for running the MCP server with Docker:\n\n###### Option 1: Using the official Docker Hub image:\n\nAdd the following to your `.cursor/mcp.json` or `claude_desktop_config.json`:\n\n**Using NOTION_TOKEN (recommended):**\n```javascript\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"NOTION_TOKEN\",\n        \"mcp/notion\"\n      ],\n      \"env\": {\n        \"NOTION_TOKEN\": \"ntn_****\"\n      }\n    }\n  }\n}\n```\n\n**Using OPENAPI_MCP_HEADERS (for advanced use cases):**\n```javascript\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"OPENAPI_MCP_HEADERS\",\n        \"mcp/notion\"\n      ],\n      \"env\": {\n        \"OPENAPI_MCP_HEADERS\": \"{\\\"Authorization\\\":\\\"Bearer ntn_****\\\",\\\"Notion-Version\\\":\\\"2022-06-28\\\"}\"\n      }\n    }\n  }\n}\n```\n\nThis approach:\n- Uses the official Docker Hub image\n- Properly handles JSON escaping via environment variables\n- Provides a more reliable configuration method\n\n###### Option 2: Building the Docker image locally:\n\nYou can also build and run the Docker image locally. First, build the Docker image:\n\n```bash\ndocker compose build\n```\n\nThen, add the following to your `.cursor/mcp.json` or `claude_desktop_config.json`:\n\n**Using NOTION_TOKEN (recommended):**\n```javascript\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"NOTION_TOKEN=ntn_****\",\n        \"notion-mcp-server\"\n      ]\n    }\n  }\n}\n```\n\n**Using OPENAPI_MCP_HEADERS (for advanced use cases):**\n```javascript\n{\n  \"mcpServers\": {\n    \"notionApi\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"OPENAPI_MCP_HEADERS={\\\"Authorization\\\": \\\"Bearer ntn_****\\\", \\\"Notion-Version\\\": \\\"2022-06-28\\\"}\",\n        \"notion-mcp-server\"\n      ]\n    }\n  }\n}\n```\n\nDon't forget to replace `ntn_****` with your integration secret. Find it from your integration configuration tab:\n\n![Copying your Integration token from the Configuration tab in the developer portal](https://github.com/user-attachments/assets/67b44536-5333-49fa-809c-59581bf5370a)\n\n\n#### Installing via Smithery\n\n[![smithery badge](https://smithery.ai/badge/@makenotion/notion-mcp-server)](https://smithery.ai/server/@makenotion/notion-mcp-server)\n\nTo install Notion API Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@makenotion/notion-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @makenotion/notion-mcp-server --client claude\n```\n\n### Transport Options\n\nThe Notion MCP Server supports two transport modes:\n\n#### STDIO Transport (Default)\nThe default transport mode uses standard input/output for communication. This is the standard MCP transport used by most clients like Claude Desktop.\n\n```bash\n# Run with default stdio transport\nnpx @notionhq/notion-mcp-server\n\n# Or explicitly specify stdio\nnpx @notionhq/notion-mcp-server --transport stdio\n```\n\n#### Streamable HTTP Transport\nFor web-based applications or clients that prefer HTTP communication, you can use the Streamable HTTP transport:\n\n```bash\n# Run with Streamable HTTP transport on port 3000 (default)\nnpx @notionhq/notion-mcp-server --transport http\n\n# Run on a custom port\nnpx @notionhq/notion-mcp-server --transport http --port 8080\n\n# Run with a custom authentication token\nnpx @notionhq/notion-mcp-server --transport http --auth-token \"your-secret-token\"\n```\n\nWhen using Streamable HTTP transport, the server will be available at `http://0.0.0.0:<port>/mcp`.\n\n##### Authentication\nThe Streamable HTTP transport requires bearer token authentication for security. You have three options:\n\n**Option 1: Auto-generated token (recommended for development)**\n```bash\nnpx @notionhq/notion-mcp-server --transport http\n```\nThe server will generate a secure random token and display it in the console:\n```\nGenerated auth token: a1b2c3d4e5f6789abcdef0123456789abcdef0123456789abcdef0123456789ab\nUse this token in the Authorization header: Bearer a1b2c3d4e5f6789abcdef0123456789abcdef0123456789abcdef0123456789ab\n```\n\n**Option 2: Custom token via command line (recommended for production)**\n```bash\nnpx @notionhq/notion-mcp-server --transport http --auth-token \"your-secret-token\"\n```\n\n**Option 3: Custom token via environment variable (recommended for production)**\n```bash\nAUTH_TOKEN=\"your-secret-token\" npx @notionhq/notion-mcp-server --transport http\n```\n\nThe command line argument `--auth-token` takes precedence over the `AUTH_TOKEN` environment variable if both are provided.\n\n##### Making HTTP Requests\nAll requests to the Streamable HTTP transport must include the bearer token in the Authorization header:\n\n```bash\n# Example request\ncurl -H \"Authorization: Bearer your-token-here\" \\\n     -H \"Content-Type: application/json\" \\\n     -H \"mcp-session-id: your-session-id\" \\\n     -d '{\"jsonrpc\": \"2.0\", \"method\": \"initialize\", \"params\": {}, \"id\": 1}' \\\n     http://localhost:3000/mcp\n```\n\n**Note:** Make sure to set either the `NOTION_TOKEN` environment variable (recommended) or the `OPENAPI_MCP_HEADERS` environment variable with your Notion integration token when using either transport mode.\n\n### Examples\n\n1. Using the following instruction\n```\nComment \"Hello MCP\" on page \"Getting started\"\n```\n\nAI will correctly plan two API calls, `v1/search` and `v1/comments`, to achieve the task\n\n2. Similarly, the following instruction will result in a new page named \"Notion MCP\" added to parent page \"Development\"\n```\nAdd a page titled \"Notion MCP\" to page \"Development\"\n```\n\n3. You may also reference content ID directly\n```\nGet the content of page 1a6b35e6e67f802fa7e1d27686f017f2\n```\n\n### Development\n\nBuild\n\n```\nnpm run build\n```\n\nExecute\n\n```\nnpx -y --prefix /path/to/local/notion-mcp-server @notionhq/notion-mcp-server\n```\n\nPublish\n\n```\nnpm publish --access public\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/notion-mcp-server",
          "npm_downloads": 9753,
          "npm_package_name": "notion-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "firecrawl--firecrawl-mcp-server": {
          "owner": "firecrawl",
          "name": "firecrawl-mcp-server",
          "url": "https://github.com/firecrawl/firecrawl-mcp-server",
          "imageUrl": "https://github.com/firecrawl.png",
          "description": "Integrates with Firecrawl for advanced web scraping capabilities including structured data extraction and batch processing, while supporting both cloud and self-hosted deployments. Provides features like automatic retries, rate limiting, and content analysis powered by LLMs.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:34.185569",
          "collection_timestamp": "2025-10-02T15:00:53.595273",
          "stars": 4642,
          "forks": 489,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2024-12-06T07:50:27Z",
          "updated_at": "2025-10-02T07:44:50Z",
          "open_issues": 57,
          "readme_content": "<div align=\"center\">\n  <a name=\"readme-top\"></a>\n  <img\n    src=\"https://raw.githubusercontent.com/firecrawl/firecrawl-mcp-server/main/img/fire.png\"\n    height=\"140\"\n  >\n</div>\n\n# Firecrawl MCP Server\n\nA Model Context Protocol (MCP) server implementation that integrates with [Firecrawl](https://github.com/firecrawl/firecrawl) for web scraping capabilities.\n\n> Big thanks to [@vrknetha](https://github.com/vrknetha), [@knacklabs](https://www.knacklabs.ai) for the initial implementation!\n\n## Features\n\n- Web scraping, crawling, and discovery\n- Search and content extraction\n- Deep research and batch scraping\n- Automatic retries and rate limiting\n- Cloud and self-hosted support\n- SSE support\n\n> Play around with [our MCP Server on MCP.so's playground](https://mcp.so/playground?server=firecrawl-mcp-server) or on [Klavis AI](https://www.klavis.ai/mcp-servers).\n\n## Installation\n\n### Running with npx\n\n```bash\nenv FIRECRAWL_API_KEY=fc-YOUR_API_KEY npx -y firecrawl-mcp\n```\n\n### Manual Installation\n\n```bash\nnpm install -g firecrawl-mcp\n```\n\n### Running on Cursor\n\nConfiguring Cursor üñ•Ô∏è\nNote: Requires Cursor version 0.45.6+\nFor the most up-to-date configuration instructions, please refer to the official Cursor documentation on configuring MCP servers:\n[Cursor MCP Server Configuration Guide](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers)\n\nTo configure Firecrawl MCP in Cursor **v0.48.6**\n\n1. Open Cursor Settings\n2. Go to Features > MCP Servers\n3. Click \"+ Add new global MCP server\"\n4. Enter the following code:\n   ```json\n   {\n     \"mcpServers\": {\n       \"firecrawl-mcp\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"firecrawl-mcp\"],\n         \"env\": {\n           \"FIRECRAWL_API_KEY\": \"YOUR-API-KEY\"\n         }\n       }\n     }\n   }\n   ```\n\nTo configure Firecrawl MCP in Cursor **v0.45.6**\n\n1. Open Cursor Settings\n2. Go to Features > MCP Servers\n3. Click \"+ Add New MCP Server\"\n4. Enter the following:\n   - Name: \"firecrawl-mcp\" (or your preferred name)\n   - Type: \"command\"\n   - Command: `env FIRECRAWL_API_KEY=your-api-key npx -y firecrawl-mcp`\n\n> If you are using Windows and are running into issues, try `cmd /c \"set FIRECRAWL_API_KEY=your-api-key && npx -y firecrawl-mcp\"`\n\nReplace `your-api-key` with your Firecrawl API key. If you don't have one yet, you can create an account and get it from https://www.firecrawl.dev/app/api-keys\n\nAfter adding, refresh the MCP server list to see the new tools. The Composer Agent will automatically use Firecrawl MCP when appropriate, but you can explicitly request it by describing your web scraping needs. Access the Composer via Command+L (Mac), select \"Agent\" next to the submit button, and enter your query.\n\n### Running on Windsurf\n\nAdd this to your `./codeium/windsurf/model_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-firecrawl\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"firecrawl-mcp\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n### Running with Streamable HTTP Local Mode\n\nTo run the server using Streamable HTTP locally instead of the default stdio transport:\n\n```bash\nenv HTTP_STREAMABLE_SERVER=true FIRECRAWL_API_KEY=fc-YOUR_API_KEY npx -y firecrawl-mcp\n```\n\nUse the url: http://localhost:3000/mcp\n\n### Installing via Smithery (Legacy)\n\nTo install Firecrawl for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@mendableai/mcp-server-firecrawl):\n\n```bash\nnpx -y @smithery/cli install @mendableai/mcp-server-firecrawl --client claude\n```\n\n### Running on VS Code\n\nFor one-click installation, click one of the install buttons below...\n\n[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&quality=insiders)\n\nFor manual installation, add the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"apiKey\",\n        \"description\": \"Firecrawl API Key\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"firecrawl\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"firecrawl-mcp\"],\n        \"env\": {\n          \"FIRECRAWL_API_KEY\": \"${input:apiKey}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with others:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"apiKey\",\n      \"description\": \"Firecrawl API Key\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"firecrawl\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"firecrawl-mcp\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"${input:apiKey}\"\n      }\n    }\n  }\n}\n```\n\n## Configuration\n\n### Environment Variables\n\n#### Required for Cloud API\n\n- `FIRECRAWL_API_KEY`: Your Firecrawl API key\n  - Required when using cloud API (default)\n  - Optional when using self-hosted instance with `FIRECRAWL_API_URL`\n- `FIRECRAWL_API_URL` (Optional): Custom API endpoint for self-hosted instances\n  - Example: `https://firecrawl.your-domain.com`\n  - If not provided, the cloud API will be used (requires API key)\n\n#### Optional Configuration\n\n##### Retry Configuration\n\n- `FIRECRAWL_RETRY_MAX_ATTEMPTS`: Maximum number of retry attempts (default: 3)\n- `FIRECRAWL_RETRY_INITIAL_DELAY`: Initial delay in milliseconds before first retry (default: 1000)\n- `FIRECRAWL_RETRY_MAX_DELAY`: Maximum delay in milliseconds between retries (default: 10000)\n- `FIRECRAWL_RETRY_BACKOFF_FACTOR`: Exponential backoff multiplier (default: 2)\n\n##### Credit Usage Monitoring\n\n- `FIRECRAWL_CREDIT_WARNING_THRESHOLD`: Credit usage warning threshold (default: 1000)\n- `FIRECRAWL_CREDIT_CRITICAL_THRESHOLD`: Credit usage critical threshold (default: 100)\n\n### Configuration Examples\n\nFor cloud API usage with custom retry and credit monitoring:\n\n```bash\n# Required for cloud API\nexport FIRECRAWL_API_KEY=your-api-key\n\n# Optional retry configuration\nexport FIRECRAWL_RETRY_MAX_ATTEMPTS=5        # Increase max retry attempts\nexport FIRECRAWL_RETRY_INITIAL_DELAY=2000    # Start with 2s delay\nexport FIRECRAWL_RETRY_MAX_DELAY=30000       # Maximum 30s delay\nexport FIRECRAWL_RETRY_BACKOFF_FACTOR=3      # More aggressive backoff\n\n# Optional credit monitoring\nexport FIRECRAWL_CREDIT_WARNING_THRESHOLD=2000    # Warning at 2000 credits\nexport FIRECRAWL_CREDIT_CRITICAL_THRESHOLD=500    # Critical at 500 credits\n```\n\nFor self-hosted instance:\n\n```bash\n# Required for self-hosted\nexport FIRECRAWL_API_URL=https://firecrawl.your-domain.com\n\n# Optional authentication for self-hosted\nexport FIRECRAWL_API_KEY=your-api-key  # If your instance requires auth\n\n# Custom retry configuration\nexport FIRECRAWL_RETRY_MAX_ATTEMPTS=10\nexport FIRECRAWL_RETRY_INITIAL_DELAY=500     # Start with faster retries\n```\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-firecrawl\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"firecrawl-mcp\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR_API_KEY_HERE\",\n\n        \"FIRECRAWL_RETRY_MAX_ATTEMPTS\": \"5\",\n        \"FIRECRAWL_RETRY_INITIAL_DELAY\": \"2000\",\n        \"FIRECRAWL_RETRY_MAX_DELAY\": \"30000\",\n        \"FIRECRAWL_RETRY_BACKOFF_FACTOR\": \"3\",\n\n        \"FIRECRAWL_CREDIT_WARNING_THRESHOLD\": \"2000\",\n        \"FIRECRAWL_CREDIT_CRITICAL_THRESHOLD\": \"500\"\n      }\n    }\n  }\n}\n```\n\n### System Configuration\n\nThe server includes several configurable parameters that can be set via environment variables. Here are the default values if not configured:\n\n```typescript\nconst CONFIG = {\n  retry: {\n    maxAttempts: 3, // Number of retry attempts for rate-limited requests\n    initialDelay: 1000, // Initial delay before first retry (in milliseconds)\n    maxDelay: 10000, // Maximum delay between retries (in milliseconds)\n    backoffFactor: 2, // Multiplier for exponential backoff\n  },\n  credit: {\n    warningThreshold: 1000, // Warn when credit usage reaches this level\n    criticalThreshold: 100, // Critical alert when credit usage reaches this level\n  },\n};\n```\n\nThese configurations control:\n\n1. **Retry Behavior**\n\n   - Automatically retries failed requests due to rate limits\n   - Uses exponential backoff to avoid overwhelming the API\n   - Example: With default settings, retries will be attempted at:\n     - 1st retry: 1 second delay\n     - 2nd retry: 2 seconds delay\n     - 3rd retry: 4 seconds delay (capped at maxDelay)\n\n2. **Credit Usage Monitoring**\n   - Tracks API credit consumption for cloud API usage\n   - Provides warnings at specified thresholds\n   - Helps prevent unexpected service interruption\n   - Example: With default settings:\n     - Warning at 1000 credits remaining\n     - Critical alert at 100 credits remaining\n\n### Rate Limiting and Batch Processing\n\nThe server utilizes Firecrawl's built-in rate limiting and batch processing capabilities:\n\n- Automatic rate limit handling with exponential backoff\n- Efficient parallel processing for batch operations\n- Smart request queuing and throttling\n- Automatic retries for transient errors\n\n## How to Choose a Tool\n\nUse this guide to select the right tool for your task:\n\n- **If you know the exact URL(s) you want:**\n  - For one: use **scrape**\n  - For many: use **batch_scrape**\n- **If you need to discover URLs on a site:** use **map**\n- **If you want to search the web for info:** use **search**\n- **If you want to extract structured data:** use **extract**\n- **If you want to analyze a whole site or section:** use **crawl** (with limits!)\n\n### Quick Reference Table\n\n| Tool         | Best for                            | Returns         |\n| ------------ | ----------------------------------- | --------------- |\n| scrape       | Single page content                 | markdown/html   |\n| batch_scrape | Multiple known URLs                 | markdown/html[] |\n| map          | Discovering URLs on a site          | URL[]           |\n| crawl        | Multi-page extraction (with limits) | markdown/html[] |\n| search       | Web search for info                 | results[]       |\n| extract      | Structured data from pages          | JSON            |\n\n## Available Tools\n\n### 1. Scrape Tool (`firecrawl_scrape`)\n\nScrape content from a single URL with advanced options.\n\n**Best for:**\n\n- Single page content extraction, when you know exactly which page contains the information.\n\n**Not recommended for:**\n\n- Extracting content from multiple pages (use batch_scrape for known URLs, or map + batch_scrape to discover URLs first, or crawl for full page content)\n- When you're unsure which page contains the information (use search)\n- When you need structured data (use extract)\n\n**Common mistakes:**\n\n- Using scrape for a list of URLs (use batch_scrape instead).\n\n**Prompt Example:**\n\n> \"Get the content of the page at https://example.com.\"\n\n**Usage Example:**\n\n```json\n{\n  \"name\": \"firecrawl_scrape\",\n  \"arguments\": {\n    \"url\": \"https://example.com\",\n    \"formats\": [\"markdown\"],\n    \"onlyMainContent\": true,\n    \"waitFor\": 1000,\n    \"timeout\": 30000,\n    \"mobile\": false,\n    \"includeTags\": [\"article\", \"main\"],\n    \"excludeTags\": [\"nav\", \"footer\"],\n    \"skipTlsVerification\": false\n  }\n}\n```\n\n**Returns:**\n\n- Markdown, HTML, or other formats as specified.\n\n### 2. Batch Scrape Tool (`firecrawl_batch_scrape`)\n\nScrape multiple URLs efficiently with built-in rate limiting and parallel processing.\n\n**Best for:**\n\n- Retrieving content from multiple pages, when you know exactly which pages to scrape.\n\n**Not recommended for:**\n\n- Discovering URLs (use map first if you don't know the URLs)\n- Scraping a single page (use scrape)\n\n**Common mistakes:**\n\n- Using batch_scrape with too many URLs at once (may hit rate limits or token overflow)\n\n**Prompt Example:**\n\n> \"Get the content of these three blog posts: [url1, url2, url3].\"\n\n**Usage Example:**\n\n```json\n{\n  \"name\": \"firecrawl_batch_scrape\",\n  \"arguments\": {\n    \"urls\": [\"https://example1.com\", \"https://example2.com\"],\n    \"options\": {\n      \"formats\": [\"markdown\"],\n      \"onlyMainContent\": true\n    }\n  }\n}\n```\n\n**Returns:**\n\n- Response includes operation ID for status checking:\n\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Batch operation queued with ID: batch_1. Use firecrawl_check_batch_status to check progress.\"\n    }\n  ],\n  \"isError\": false\n}\n```\n\n### 3. Check Batch Status (`firecrawl_check_batch_status`)\n\nCheck the status of a batch operation.\n\n```json\n{\n  \"name\": \"firecrawl_check_batch_status\",\n  \"arguments\": {\n    \"id\": \"batch_1\"\n  }\n}\n```\n\n### 4. Map Tool (`firecrawl_map`)\n\nMap a website to discover all indexed URLs on the site.\n\n**Best for:**\n\n- Discovering URLs on a website before deciding what to scrape\n- Finding specific sections of a website\n\n**Not recommended for:**\n\n- When you already know which specific URL you need (use scrape or batch_scrape)\n- When you need the content of the pages (use scrape after mapping)\n\n**Common mistakes:**\n\n- Using crawl to discover URLs instead of map\n\n**Prompt Example:**\n\n> \"List all URLs on example.com.\"\n\n**Usage Example:**\n\n```json\n{\n  \"name\": \"firecrawl_map\",\n  \"arguments\": {\n    \"url\": \"https://example.com\"\n  }\n}\n```\n\n**Returns:**\n\n- Array of URLs found on the site\n\n### 5. Search Tool (`firecrawl_search`)\n\nSearch the web and optionally extract content from search results.\n\n**Best for:**\n\n- Finding specific information across multiple websites, when you don't know which website has the information.\n- When you need the most relevant content for a query\n\n**Not recommended for:**\n\n- When you already know which website to scrape (use scrape)\n- When you need comprehensive coverage of a single website (use map or crawl)\n\n**Common mistakes:**\n\n- Using crawl or map for open-ended questions (use search instead)\n\n**Usage Example:**\n\n```json\n{\n  \"name\": \"firecrawl_search\",\n  \"arguments\": {\n    \"query\": \"latest AI research papers 2023\",\n    \"limit\": 5,\n    \"lang\": \"en\",\n    \"country\": \"us\",\n    \"scrapeOptions\": {\n      \"formats\": [\"markdown\"],\n      \"onlyMainContent\": true\n    }\n  }\n}\n```\n\n**Returns:**\n\n- Array of search results (with optional scraped content)\n\n**Prompt Example:**\n\n> \"Find the latest research papers on AI published in 2023.\"\n\n### 6. Crawl Tool (`firecrawl_crawl`)\n\nStarts an asynchronous crawl job on a website and extract content from all pages.\n\n**Best for:**\n\n- Extracting content from multiple related pages, when you need comprehensive coverage.\n\n**Not recommended for:**\n\n- Extracting content from a single page (use scrape)\n- When token limits are a concern (use map + batch_scrape)\n- When you need fast results (crawling can be slow)\n\n**Warning:** Crawl responses can be very large and may exceed token limits. Limit the crawl depth and number of pages, or use map + batch_scrape for better control.\n\n**Common mistakes:**\n\n- Setting limit or maxDepth too high (causes token overflow)\n- Using crawl for a single page (use scrape instead)\n\n**Prompt Example:**\n\n> \"Get all blog posts from the first two levels of example.com/blog.\"\n\n**Usage Example:**\n\n```json\n{\n  \"name\": \"firecrawl_crawl\",\n  \"arguments\": {\n    \"url\": \"https://example.com/blog/*\",\n    \"maxDepth\": 2,\n    \"limit\": 100,\n    \"allowExternalLinks\": false,\n    \"deduplicateSimilarURLs\": true\n  }\n}\n```\n\n**Returns:**\n\n- Response includes operation ID for status checking:\n\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Started crawl for: https://example.com/* with job ID: 550e8400-e29b-41d4-a716-446655440000. Use firecrawl_check_crawl_status to check progress.\"\n    }\n  ],\n  \"isError\": false\n}\n```\n\n### 7. Check Crawl Status (`firecrawl_check_crawl_status`)\n\nCheck the status of a crawl job.\n\n```json\n{\n  \"name\": \"firecrawl_check_crawl_status\",\n  \"arguments\": {\n    \"id\": \"550e8400-e29b-41d4-a716-446655440000\"\n  }\n}\n```\n\n**Returns:**\n\n- Response includes the status of the crawl job:\n\n### 8. Extract Tool (`firecrawl_extract`)\n\nExtract structured information from web pages using LLM capabilities. Supports both cloud AI and self-hosted LLM extraction.\n\n**Best for:**\n\n- Extracting specific structured data like prices, names, details.\n\n**Not recommended for:**\n\n- When you need the full content of a page (use scrape)\n- When you're not looking for specific structured data\n\n**Arguments:**\n\n- `urls`: Array of URLs to extract information from\n- `prompt`: Custom prompt for the LLM extraction\n- `systemPrompt`: System prompt to guide the LLM\n- `schema`: JSON schema for structured data extraction\n- `allowExternalLinks`: Allow extraction from external links\n- `enableWebSearch`: Enable web search for additional context\n- `includeSubdomains`: Include subdomains in extraction\n\nWhen using a self-hosted instance, the extraction will use your configured LLM. For cloud API, it uses Firecrawl's managed LLM service.\n**Prompt Example:**\n\n> \"Extract the product name, price, and description from these product pages.\"\n\n**Usage Example:**\n\n```json\n{\n  \"name\": \"firecrawl_extract\",\n  \"arguments\": {\n    \"urls\": [\"https://example.com/page1\", \"https://example.com/page2\"],\n    \"prompt\": \"Extract product information including name, price, and description\",\n    \"systemPrompt\": \"You are a helpful assistant that extracts product information\",\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"name\": { \"type\": \"string\" },\n        \"price\": { \"type\": \"number\" },\n        \"description\": { \"type\": \"string\" }\n      },\n      \"required\": [\"name\", \"price\"]\n    },\n    \"allowExternalLinks\": false,\n    \"enableWebSearch\": false,\n    \"includeSubdomains\": false\n  }\n}\n```\n\n**Returns:**\n\n- Extracted structured data as defined by your schema\n\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"name\": \"Example Product\",\n        \"price\": 99.99,\n        \"description\": \"This is an example product description\"\n      }\n    }\n  ],\n  \"isError\": false\n}\n```\n\n## Logging System\n\nThe server includes comprehensive logging:\n\n- Operation status and progress\n- Performance metrics\n- Credit usage monitoring\n- Rate limit tracking\n- Error conditions\n\nExample log messages:\n\n```\n[INFO] Firecrawl MCP Server initialized successfully\n[INFO] Starting scrape for URL: https://example.com\n[INFO] Batch operation queued with ID: batch_1\n[WARNING] Credit usage has reached warning threshold\n[ERROR] Rate limit exceeded, retrying in 2s...\n```\n\n## Error Handling\n\nThe server provides robust error handling:\n\n- Automatic retries for transient errors\n- Rate limit handling with backoff\n- Detailed error messages\n- Credit usage warnings\n- Network resilience\n\nExample error response:\n\n```json\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"Error: Rate limit exceeded. Retrying in 2 seconds...\"\n    }\n  ],\n  \"isError\": true\n}\n```\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n\n# Run tests\nnpm test\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create your feature branch\n3. Run tests: `npm test`\n4. Submit a pull request\n\n### Thanks to contributors\n\nThanks to [@vrknetha](https://github.com/vrknetha), [@cawstudios](https://caw.tech) for the initial implementation!\n\nThanks to MCP.so and Klavis AI for hosting and [@gstarwd](https://github.com/gstarwd), [@xiangkaiz](https://github.com/xiangkaiz) and [@zihaolin96](https://github.com/zihaolin96) for integrating our server.\n\n## License\n\nMIT License - see LICENSE file for details\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "metoro-io--metoro-mcp-server": {
          "owner": "metoro-io",
          "name": "metoro-mcp-server",
          "url": "https://github.com/metoro-io/metoro-mcp-server",
          "imageUrl": "https://github.com/metoro-io.png",
          "description": "Interact with Kubernetes clusters through Metoro's APIs via the Claude Desktop App. Facilitates communication between AI models and Kubernetes management operations.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:35.227749",
          "collection_timestamp": "2025-10-02T15:01:00.873616",
          "stars": 43,
          "forks": 11,
          "license": "MIT License",
          "language": "Go",
          "created_at": "2024-12-08T14:11:07Z",
          "updated_at": "2025-09-18T11:48:33Z",
          "open_issues": 3,
          "readme_content": "<div align=\"center\">\n<img src=\"./images/Metoro_square.svg\" height=\"300\" alt=\"Metoro MCP Logo\">\n</div>\n<br/>\n<div align=\"center\">\n\n![GitHub stars](https://img.shields.io/github/stars/metoro-io/metoro-mcp-server?style=social)\n![GitHub forks](https://img.shields.io/github/forks/metoro-io/metoro-mcp-server?style=social)\n![GitHub issues](https://img.shields.io/github/issues/metoro-io/metoro-mcp-server)\n![GitHub pull requests](https://img.shields.io/github/issues-pr/metoro-io/metoro-mcp-server)\n![GitHub license](https://img.shields.io/github/license/metoro-io/metoro-mcp-server)\n![GitHub contributors](https://img.shields.io/github/contributors/metoro-io/metoro-mcp-server)\n![GitHub last commit](https://img.shields.io/github/last-commit/metoro-io/metoro-mcp-server)\n[![GoDoc](https://pkg.go.dev/badge/github.com/metoro-io/metoro-mcp-server.svg)](https://pkg.go.dev/github.com/metoro-io/metoro-mcp-server)\n[![Go Report Card](https://goreportcard.com/badge/github.com/metoro-io/metoro-mcp-server)](https://goreportcard.com/report/github.com/metoro-io/metoro-mcp-server)\n![Tests](https://github.com/metoro-io/metoro-mcp-server/actions/workflows/go-test.yml/badge.svg)\n\n</div>\n\n# metoro-mcp-server\nThis repository contains th Metoro MCP (Model Context Protocol) Server. This MCP Server allows you to interact with your Kubernetes cluster via the Claude Desktop App!\n\n## What is MCP (Model Context Protocol)? \nYou can read more about the Model Context Protocol here: https://modelcontextprotocol.io\n\nBut in a nutshell\n> The Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you‚Äôre building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.\n\n## What is Metoro?\n[Metoro](https://metoro.io/) is an observability platform designed for microservices running in Kubernetes and uses eBPF based instrumentation to generate deep telemetry without code changes.\nThe data that is generated by the eBPF agents is sent to Metoro's backend to be stored and in the Metoro frontend using our apis.\n\nThis MCP server exposes those APIs to an LLM so you can ask your AI questions about your Kubernetes cluster.\n\n## Demo\n\nhttps://github.com/user-attachments/assets/b3f21e9a-45b8-4c17-8d8c-cff560d8694f\n\n## How can I use Metoro MCP Server? \n1. Install the [Claude Desktop App](https://claude.ai/download).\n2. Make sure you have [Golang](https://golang.org/dl/) installed. `brew install go` for mac or `sudo apt-get install golang` for ubuntu.\n3. Clone the repository: `git clone https://github.com/metoro-io/metoro-mcp-server.git`\n4. Navigate to the repository directory: `cd metoro-mcp-server`\n5. Build the server executable: `go build -o metoro-mcp-server`\n\n### If you already have a Metoro Account:\nCopy your auth token from your Metoro account in [Settings](https://us-east.metoro.io/settings) -> Users Settings. \nCreate a file in `~/Library/Application Support/Claude/claude_desktop_config.json` with the following contents:\n```json\n{\n  \"mcpServers\": {\n    \"metoro-mcp-server\": {\n      \"command\": \"<your path to Metoro MCP server go executable>/metoro-mcp-server\",\n      \"args\": [],\n      \"env\": {\n          \"METORO_AUTH_TOKEN\" : \"<your auth token>\",\n          \"METORO_API_URL\": \"https://us-east.metoro.io\"\n       }\n    }\n  }\n}\n```\n\n### If you don't have a Metoro Account:\nNo worries, you can still play around using the [Live Demo Cluster](https://demo.us-east.metoro.io/).\nThe included token is a demo token, publicly available for anyone to use.\n   Create a file in `~/Library/Application Support/Claude/claude_desktop_config.json` with the following contents:\n```json\n{\n  \"mcpServers\": {\n    \"metoro-mcp-server\": {\n      \"command\": \"<your path to Metoro MCP server go executable>/metoro-mcp-server\",\n      \"args\": [],\n      \"env\": {\n          \"METORO_AUTH_TOKEN\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjdXN0b21lcklkIjoiOThlZDU1M2QtYzY4ZC00MDRhLWFhZjItNDM2ODllNWJiMGUzIiwiZW1haWwiOiJ0ZXN0QGNocmlzYmF0dGFyYmVlLmNvbSIsImV4cCI6MTgyMTI0NzIzN30.7G6alDpcZh_OThYj293Jce5rjeOBqAhOlANR_Fl5auw\",\n          \"METORO_API_URL\": \"https://demo.us-east.metoro.io\"\n       }\n    }\n  }\n}\n```\n\n4. Once you are done editing `claude_desktop_config.json` save the file and restart Claude Desktop app.\n5. You should now see the Metoro MCP Server in the dropdown list of MCP Servers in the Claude Desktop App. You are ready to start using Metoro MCP Server with Claude Desktop App!\n\n## Built with\n\nThis server is built on top of our [Golang MCP SDK](https://github.com/metoro-io/mcp-golang).\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "microsoft--playwright-mcp": {
          "owner": "microsoft",
          "name": "playwright-mcp",
          "url": "https://github.com/microsoft/playwright-mcp",
          "imageUrl": "https://github.com/microsoft.png",
          "description": "Automate web interactions on web pages using structured accessibility data for reliable navigation and data extraction without the need for visual models. Enables LLMs to perform actions by leveraging Playwright's accessibility tree.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:36.754235",
          "collection_timestamp": "2025-10-02T15:01:05.539480",
          "stars": 21091,
          "forks": 1654,
          "license": "Apache License 2.0",
          "language": "TypeScript",
          "created_at": "2025-03-21T17:48:36Z",
          "updated_at": "2025-10-02T09:12:41Z",
          "open_issues": 24,
          "readme_content": "## Playwright MCP\n\nA Model Context Protocol (MCP) server that provides browser automation capabilities using [Playwright](https://playwright.dev). This server enables LLMs to interact with web pages through structured accessibility snapshots, bypassing the need for screenshots or visually-tuned models.\n\n### Key Features\n\n- **Fast and lightweight**. Uses Playwright's accessibility tree, not pixel-based input.\n- **LLM-friendly**. No vision models needed, operates purely on structured data.\n- **Deterministic tool application**. Avoids ambiguity common with screenshot-based approaches.\n\n### Requirements\n- Node.js 18 or newer\n- VS Code, Cursor, Windsurf, Claude Desktop, Goose or any other MCP client\n\n<!--\n// Generate using:\nnode utils/generate-links.js\n-->\n\n### Getting started\n\nFirst, install the Playwright MCP server with your client.\n\n**Standard config** works in most of the tools:\n\n```js\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@playwright/mcp@latest\"\n      ]\n    }\n  }\n}\n```\n\n[<img src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Server&color=0098FF\" alt=\"Install in VS Code\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D) [<img alt=\"Install in VS Code Insiders\" src=\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&label=Install%20Server&color=24bfa5\">](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D)\n\n\n<details>\n<summary>Claude Code</summary>\n\nUse the Claude Code CLI to add the Playwright MCP server:\n\n```bash\nclaude mcp add playwright npx @playwright/mcp@latest\n```\n</details>\n\n<details>\n<summary>Claude Desktop</summary>\n\nFollow the MCP install [guide](https://modelcontextprotocol.io/quickstart/user), use the standard config above.\n\n</details>\n\n<details>\n<summary>Codex</summary>\n\nCreate or edit the configuration file `~/.codex/config.toml` and add:\n\n```toml\n[mcp_servers.playwright]\ncommand = \"npx\"\nargs = [\"@playwright/mcp@latest\"]\n```\n\nFor more information, see the [Codex MCP documentation](https://github.com/openai/codex/blob/main/codex-rs/config.md#mcp_servers).\n\n</details>\n\n<details>\n<summary>Cursor</summary>\n\n#### Click the button to install:\n\n[<img src=\"https://cursor.com/deeplink/mcp-install-dark.svg\" alt=\"Install in Cursor\">](https://cursor.com/en/install-mcp?name=Playwright&config=eyJjb21tYW5kIjoibnB4IEBwbGF5d3JpZ2h0L21jcEBsYXRlc3QifQ%3D%3D)\n\n#### Or install manually:\n\nGo to `Cursor Settings` -> `MCP` -> `Add new MCP Server`. Name to your liking, use `command` type with the command `npx @playwright/mcp@latest`. You can also verify config or add command like arguments via clicking `Edit`.\n\n</details>\n\n<details>\n<summary>Gemini CLI</summary>\n\nFollow the MCP install [guide](https://github.com/google-gemini/gemini-cli/blob/main/docs/tools/mcp-server.md#configure-the-mcp-server-in-settingsjson), use the standard config above.\n\n</details>\n\n<details>\n<summary>Goose</summary>\n\n#### Click the button to install:\n\n[![Install in Goose](https://block.github.io/goose/img/extension-install-dark.svg)](https://block.github.io/goose/extension?cmd=npx&arg=%40playwright%2Fmcp%40latest&id=playwright&name=Playwright&description=Interact%20with%20web%20pages%20through%20structured%20accessibility%20snapshots%20using%20Playwright)\n\n#### Or install manually:\n\nGo to `Advanced settings` -> `Extensions` -> `Add custom extension`. Name to your liking, use type `STDIO`, and set the `command` to `npx @playwright/mcp`. Click \"Add Extension\".\n</details>\n\n<details>\n<summary>LM Studio</summary>\n\n#### Click the button to install:\n\n[![Add MCP Server playwright to LM Studio](https://files.lmstudio.ai/deeplink/mcp-install-light.svg)](https://lmstudio.ai/install-mcp?name=playwright&config=eyJjb21tYW5kIjoibnB4IiwiYXJncyI6WyJAcGxheXdyaWdodC9tY3BAbGF0ZXN0Il19)\n\n#### Or install manually:\n\nGo to `Program` in the right sidebar -> `Install` -> `Edit mcp.json`. Use the standard config above.\n</details>\n\n<details>\n<summary>opencode</summary>\n\nFollow the MCP Servers [documentation](https://opencode.ai/docs/mcp-servers/). For example in `~/.config/opencode/opencode.json`:\n\n```json\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"playwright\": {\n      \"type\": \"local\",\n      \"command\": [\n        \"npx\",\n        \"@playwright/mcp@latest\"\n      ],\n      \"enabled\": true\n    }\n  }\n}\n\n```\n</details>\n\n<details>\n<summary>Qodo Gen</summary>\n\nOpen [Qodo Gen](https://docs.qodo.ai/qodo-documentation/qodo-gen) chat panel in VSCode or IntelliJ ‚Üí Connect more tools ‚Üí + Add new MCP ‚Üí Paste the standard config above.\n\nClick <code>Save</code>.\n</details>\n\n<details>\n<summary>VS Code</summary>\n\n#### Click the button to install:\n\n[<img src=\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=Install%20Server&color=0098FF\" alt=\"Install in VS Code\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D) [<img alt=\"Install in VS Code Insiders\" src=\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=flat-square&label=Install%20Server&color=24bfa5\">](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522%2540playwright%252Fmcp%2540latest%2522%255D%257D)\n\n#### Or install manually:\n\nFollow the MCP install [guide](https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server), use the standard config above. You can also install the Playwright MCP server using the VS Code CLI:\n\n```bash\n# For VS Code\ncode --add-mcp '{\"name\":\"playwright\",\"command\":\"npx\",\"args\":[\"@playwright/mcp@latest\"]}'\n```\n\nAfter installation, the Playwright MCP server will be available for use with your GitHub Copilot agent in VS Code.\n</details>\n\n<details>\n<summary>Windsurf</summary>\n\nFollow Windsurf MCP [documentation](https://docs.windsurf.com/windsurf/cascade/mcp). Use the standard config above.\n\n</details>\n\n### Configuration\n\nPlaywright MCP server supports following arguments. They can be provided in the JSON configuration above, as a part of the `\"args\"` list:\n\n<!--- Options generated by update-readme.js -->\n\n```\n> npx @playwright/mcp@latest --help\n  --allowed-hosts <hosts...>            comma-separated list of hosts this\n                                        server is allowed to serve from.\n                                        Defaults to the host the server is bound\n                                        to. Pass '*' to disable the host check.\n  --allowed-origins <origins>           semicolon-separated list of origins to\n                                        allow the browser to request. Default is\n                                        to allow all.\n  --blocked-origins <origins>           semicolon-separated list of origins to\n                                        block the browser from requesting.\n                                        Blocklist is evaluated before allowlist.\n                                        If used without the allowlist, requests\n                                        not matching the blocklist are still\n                                        allowed.\n  --block-service-workers               block service workers\n  --browser <browser>                   browser or chrome channel to use,\n                                        possible values: chrome, firefox,\n                                        webkit, msedge.\n  --caps <caps>                         comma-separated list of additional\n                                        capabilities to enable, possible values:\n                                        vision, pdf.\n  --cdp-endpoint <endpoint>             CDP endpoint to connect to.\n  --cdp-header <headers...>             CDP headers to send with the connect\n                                        request, multiple can be specified.\n  --config <path>                       path to the configuration file.\n  --device <device>                     device to emulate, for example: \"iPhone\n                                        15\"\n  --executable-path <path>              path to the browser executable.\n  --extension                           Connect to a running browser instance\n                                        (Edge/Chrome only). Requires the\n                                        \"Playwright MCP Bridge\" browser\n                                        extension to be installed.\n  --grant-permissions <permissions...>  List of permissions to grant to the\n                                        browser context, for example\n                                        \"geolocation\", \"clipboard-read\",\n                                        \"clipboard-write\".\n  --headless                            run browser in headless mode, headed by\n                                        default\n  --host <host>                         host to bind server to. Default is\n                                        localhost. Use 0.0.0.0 to bind to all\n                                        interfaces.\n  --ignore-https-errors                 ignore https errors\n  --init-script <path...>               path to JavaScript file to add as an\n                                        initialization script. The script will\n                                        be evaluated in every page before any of\n                                        the page's scripts. Can be specified\n                                        multiple times.\n  --isolated                            keep the browser profile in memory, do\n                                        not save it to disk.\n  --image-responses <mode>              whether to send image responses to the\n                                        client. Can be \"allow\" or \"omit\",\n                                        Defaults to \"allow\".\n  --no-sandbox                          disable the sandbox for all process\n                                        types that are normally sandboxed.\n  --output-dir <path>                   path to the directory for output files.\n  --port <port>                         port to listen on for SSE transport.\n  --proxy-bypass <bypass>               comma-separated domains to bypass proxy,\n                                        for example\n                                        \".com,chromium.org,.domain.com\"\n  --proxy-server <proxy>                specify proxy server, for example\n                                        \"http://myproxy:3128\" or\n                                        \"socks5://myproxy:8080\"\n  --save-session                        Whether to save the Playwright MCP\n                                        session into the output directory.\n  --save-trace                          Whether to save the Playwright Trace of\n                                        the session into the output directory.\n  --save-video <size>                   Whether to save the video of the session\n                                        into the output directory. For example\n                                        \"--save-video=800x600\"\n  --secrets <path>                      path to a file containing secrets in the\n                                        dotenv format\n  --shared-browser-context              reuse the same browser context between\n                                        all connected HTTP clients.\n  --storage-state <path>                path to the storage state file for\n                                        isolated sessions.\n  --timeout-action <timeout>            specify action timeout in milliseconds,\n                                        defaults to 5000ms\n  --timeout-navigation <timeout>        specify navigation timeout in\n                                        milliseconds, defaults to 60000ms\n  --user-agent <ua string>              specify user agent string\n  --user-data-dir <path>                path to the user data directory. If not\n                                        specified, a temporary directory will be\n                                        created.\n  --viewport-size <size>                specify browser viewport size in pixels,\n                                        for example \"1280x720\"\n```\n\n<!--- End of options generated section -->\n\n### User profile\n\nYou can run Playwright MCP with persistent profile like a regular browser (default), in isolated contexts for testing sessions, or connect to your existing browser using the browser extension.\n\n**Persistent profile**\n\nAll the logged in information will be stored in the persistent profile, you can delete it between sessions if you'd like to clear the offline state.\nPersistent profile is located at the following locations and you can override it with the `--user-data-dir` argument.\n\n```bash\n# Windows\n%USERPROFILE%\\AppData\\Local\\ms-playwright\\mcp-{channel}-profile\n\n# macOS\n- ~/Library/Caches/ms-playwright/mcp-{channel}-profile\n\n# Linux\n- ~/.cache/ms-playwright/mcp-{channel}-profile\n```\n\n**Isolated**\n\nIn the isolated mode, each session is started in the isolated profile. Every time you ask MCP to close the browser,\nthe session is closed and all the storage state for this session is lost. You can provide initial storage state\nto the browser via the config's `contextOptions` or via the `--storage-state` argument. Learn more about the storage\nstate [here](https://playwright.dev/docs/auth).\n\n```js\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@playwright/mcp@latest\",\n        \"--isolated\",\n        \"--storage-state={path/to/storage.json}\"\n      ]\n    }\n  }\n}\n```\n\n**Browser Extension**\n\nThe Playwright MCP Chrome Extension allows you to connect to existing browser tabs and leverage your logged-in sessions and browser state. See [extension/README.md](extension/README.md) for installation and setup instructions.\n\n### Configuration file\n\nThe Playwright MCP server can be configured using a JSON configuration file. You can specify the configuration file\nusing the `--config` command line option:\n\n```bash\nnpx @playwright/mcp@latest --config path/to/config.json\n```\n\n<details>\n<summary>Configuration file schema</summary>\n\n```typescript\n{\n  // Browser configuration\n  browser?: {\n    // Browser type to use (chromium, firefox, or webkit)\n    browserName?: 'chromium' | 'firefox' | 'webkit';\n\n    // Keep the browser profile in memory, do not save it to disk.\n    isolated?: boolean;\n\n    // Path to user data directory for browser profile persistence\n    userDataDir?: string;\n\n    // Browser launch options (see Playwright docs)\n    // @see https://playwright.dev/docs/api/class-browsertype#browser-type-launch\n    launchOptions?: {\n      channel?: string;        // Browser channel (e.g. 'chrome')\n      headless?: boolean;      // Run in headless mode\n      executablePath?: string; // Path to browser executable\n      // ... other Playwright launch options\n    };\n\n    // Browser context options\n    // @see https://playwright.dev/docs/api/class-browser#browser-new-context\n    contextOptions?: {\n      viewport?: { width: number, height: number };\n      // ... other Playwright context options\n    };\n\n    // CDP endpoint for connecting to existing browser\n    cdpEndpoint?: string;\n\n    // Remote Playwright server endpoint\n    remoteEndpoint?: string;\n  },\n\n  // Server configuration\n  server?: {\n    port?: number;  // Port to listen on\n    host?: string;  // Host to bind to (default: localhost)\n  },\n\n  // List of additional capabilities\n  capabilities?: Array<\n    'tabs' |    // Tab management\n    'install' | // Browser installation\n    'pdf' |     // PDF generation\n    'vision' |  // Coordinate-based interactions\n  >;\n\n  // Directory for output files\n  outputDir?: string;\n\n  // Network configuration\n  network?: {\n    // List of origins to allow the browser to request. Default is to allow all. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.\n    allowedOrigins?: string[];\n\n    // List of origins to block the browser to request. Origins matching both `allowedOrigins` and `blockedOrigins` will be blocked.\n    blockedOrigins?: string[];\n  };\n \n  /**\n   * Whether to send image responses to the client. Can be \"allow\" or \"omit\". \n   * Defaults to \"allow\".\n   */\n  imageResponses?: 'allow' | 'omit';\n}\n```\n</details>\n\n### Standalone MCP server\n\nWhen running headed browser on system w/o display or from worker processes of the IDEs,\nrun the MCP server from environment with the DISPLAY and pass the `--port` flag to enable HTTP transport.\n\n```bash\nnpx @playwright/mcp@latest --port 8931\n```\n\nAnd then in MCP client config, set the `url` to the HTTP endpoint:\n\n```js\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"url\": \"http://localhost:8931/mcp\"\n    }\n  }\n}\n```\n\n<details>\n<summary><b>Docker</b></summary>\n\n**NOTE:** The Docker implementation only supports headless chromium at the moment.\n\n```js\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"--init\", \"--pull=always\", \"mcr.microsoft.com/playwright/mcp\"]\n    }\n  }\n}\n```\n\nOr If you prefer to run the container as a long-lived service instead of letting the MCP client spawn it, use:\n\n```\ndocker run -d -i --rm --init --pull=always \\\n  --entrypoint node \\\n  --name playwright \\\n  -p 8931:8931 \\\n  mcr.microsoft.com/playwright/mcp \\\n  cli.js --headless --browser chromium --no-sandbox --port 8931\n```\n\nThe server will listen on host port **8931** and can be reached by any MCP client.  \n\nYou can build the Docker image yourself.\n\n```\ndocker build -t mcr.microsoft.com/playwright/mcp .\n```\n</details>\n\n<details>\n<summary><b>Programmatic usage</b></summary>\n\n```js\nimport http from 'http';\n\nimport { createConnection } from '@playwright/mcp';\nimport { SSEServerTransport } from '@modelcontextprotocol/sdk/server/sse.js';\n\nhttp.createServer(async (req, res) => {\n  // ...\n\n  // Creates a headless Playwright MCP server with SSE transport\n  const connection = await createConnection({ browser: { launchOptions: { headless: true } } });\n  const transport = new SSEServerTransport('/messages', res);\n  await connection.connect(transport);\n\n  // ...\n});\n```\n</details>\n\n### Tools\n\n<!--- Tools generated by update-readme.js -->\n\n<details>\n<summary><b>Core automation</b></summary>\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_click**\n  - Title: Click\n  - Description: Perform click on a web page\n  - Parameters:\n    - `element` (string): Human-readable element description used to obtain permission to interact with the element\n    - `ref` (string): Exact target element reference from the page snapshot\n    - `doubleClick` (boolean, optional): Whether to perform a double click instead of a single click\n    - `button` (string, optional): Button to click, defaults to left\n    - `modifiers` (array, optional): Modifier keys to press\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_close**\n  - Title: Close browser\n  - Description: Close the page\n  - Parameters: None\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_console_messages**\n  - Title: Get console messages\n  - Description: Returns all console messages\n  - Parameters:\n    - `onlyErrors` (boolean, optional): Only return error messages\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_drag**\n  - Title: Drag mouse\n  - Description: Perform drag and drop between two elements\n  - Parameters:\n    - `startElement` (string): Human-readable source element description used to obtain the permission to interact with the element\n    - `startRef` (string): Exact source element reference from the page snapshot\n    - `endElement` (string): Human-readable target element description used to obtain the permission to interact with the element\n    - `endRef` (string): Exact target element reference from the page snapshot\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_evaluate**\n  - Title: Evaluate JavaScript\n  - Description: Evaluate JavaScript expression on page or element\n  - Parameters:\n    - `function` (string): () => { /* code */ } or (element) => { /* code */ } when element is provided\n    - `element` (string, optional): Human-readable element description used to obtain permission to interact with the element\n    - `ref` (string, optional): Exact target element reference from the page snapshot\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_file_upload**\n  - Title: Upload files\n  - Description: Upload one or multiple files\n  - Parameters:\n    - `paths` (array, optional): The absolute paths to the files to upload. Can be single file or multiple files. If omitted, file chooser is cancelled.\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_fill_form**\n  - Title: Fill form\n  - Description: Fill multiple form fields\n  - Parameters:\n    - `fields` (array): Fields to fill in\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_handle_dialog**\n  - Title: Handle a dialog\n  - Description: Handle a dialog\n  - Parameters:\n    - `accept` (boolean): Whether to accept the dialog.\n    - `promptText` (string, optional): The text of the prompt in case of a prompt dialog.\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_hover**\n  - Title: Hover mouse\n  - Description: Hover over element on page\n  - Parameters:\n    - `element` (string): Human-readable element description used to obtain permission to interact with the element\n    - `ref` (string): Exact target element reference from the page snapshot\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_navigate**\n  - Title: Navigate to a URL\n  - Description: Navigate to a URL\n  - Parameters:\n    - `url` (string): The URL to navigate to\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_navigate_back**\n  - Title: Go back\n  - Description: Go back to the previous page\n  - Parameters: None\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_network_requests**\n  - Title: List network requests\n  - Description: Returns all network requests since loading the page\n  - Parameters: None\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_press_key**\n  - Title: Press a key\n  - Description: Press a key on the keyboard\n  - Parameters:\n    - `key` (string): Name of the key to press or a character to generate, such as `ArrowLeft` or `a`\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_resize**\n  - Title: Resize browser window\n  - Description: Resize the browser window\n  - Parameters:\n    - `width` (number): Width of the browser window\n    - `height` (number): Height of the browser window\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_select_option**\n  - Title: Select option\n  - Description: Select an option in a dropdown\n  - Parameters:\n    - `element` (string): Human-readable element description used to obtain permission to interact with the element\n    - `ref` (string): Exact target element reference from the page snapshot\n    - `values` (array): Array of values to select in the dropdown. This can be a single value or multiple values.\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_snapshot**\n  - Title: Page snapshot\n  - Description: Capture accessibility snapshot of the current page, this is better than screenshot\n  - Parameters: None\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_take_screenshot**\n  - Title: Take a screenshot\n  - Description: Take a screenshot of the current page. You can't perform actions based on the screenshot, use browser_snapshot for actions.\n  - Parameters:\n    - `type` (string, optional): Image format for the screenshot. Default is png.\n    - `filename` (string, optional): File name to save the screenshot to. Defaults to `page-{timestamp}.{png|jpeg}` if not specified.\n    - `element` (string, optional): Human-readable element description used to obtain permission to screenshot the element. If not provided, the screenshot will be taken of viewport. If element is provided, ref must be provided too.\n    - `ref` (string, optional): Exact target element reference from the page snapshot. If not provided, the screenshot will be taken of viewport. If ref is provided, element must be provided too.\n    - `fullPage` (boolean, optional): When true, takes a screenshot of the full scrollable page, instead of the currently visible viewport. Cannot be used with element screenshots.\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_type**\n  - Title: Type text\n  - Description: Type text into editable element\n  - Parameters:\n    - `element` (string): Human-readable element description used to obtain permission to interact with the element\n    - `ref` (string): Exact target element reference from the page snapshot\n    - `text` (string): Text to type into the element\n    - `submit` (boolean, optional): Whether to submit entered text (press Enter after)\n    - `slowly` (boolean, optional): Whether to type one character at a time. Useful for triggering key handlers in the page. By default entire text is filled in at once.\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_wait_for**\n  - Title: Wait for\n  - Description: Wait for text to appear or disappear or a specified time to pass\n  - Parameters:\n    - `time` (number, optional): The time to wait in seconds\n    - `text` (string, optional): The text to wait for\n    - `textGone` (string, optional): The text to wait for to disappear\n  - Read-only: **true**\n\n</details>\n\n<details>\n<summary><b>Tab management</b></summary>\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_tabs**\n  - Title: Manage tabs\n  - Description: List, create, close, or select a browser tab.\n  - Parameters:\n    - `action` (string): Operation to perform\n    - `index` (number, optional): Tab index, used for close/select. If omitted for close, current tab is closed.\n  - Read-only: **false**\n\n</details>\n\n<details>\n<summary><b>Browser installation</b></summary>\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_install**\n  - Title: Install the browser specified in the config\n  - Description: Install the browser specified in the config. Call this if you get an error about the browser not being installed.\n  - Parameters: None\n  - Read-only: **false**\n\n</details>\n\n<details>\n<summary><b>Coordinate-based (opt-in via --caps=vision)</b></summary>\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_mouse_click_xy**\n  - Title: Click\n  - Description: Click left mouse button at a given position\n  - Parameters:\n    - `element` (string): Human-readable element description used to obtain permission to interact with the element\n    - `x` (number): X coordinate\n    - `y` (number): Y coordinate\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_mouse_drag_xy**\n  - Title: Drag mouse\n  - Description: Drag left mouse button to a given position\n  - Parameters:\n    - `element` (string): Human-readable element description used to obtain permission to interact with the element\n    - `startX` (number): Start X coordinate\n    - `startY` (number): Start Y coordinate\n    - `endX` (number): End X coordinate\n    - `endY` (number): End Y coordinate\n  - Read-only: **false**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_mouse_move_xy**\n  - Title: Move mouse\n  - Description: Move mouse to a given position\n  - Parameters:\n    - `element` (string): Human-readable element description used to obtain permission to interact with the element\n    - `x` (number): X coordinate\n    - `y` (number): Y coordinate\n  - Read-only: **true**\n\n</details>\n\n<details>\n<summary><b>PDF generation (opt-in via --caps=pdf)</b></summary>\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_pdf_save**\n  - Title: Save as PDF\n  - Description: Save page as PDF\n  - Parameters:\n    - `filename` (string, optional): File name to save the pdf to. Defaults to `page-{timestamp}.pdf` if not specified.\n  - Read-only: **true**\n\n</details>\n\n<details>\n<summary><b>Verify (opt-in via --caps=verify)</b></summary>\n\n</details>\n\n<details>\n<summary><b>Tracing (opt-in via --caps=tracing)</b></summary>\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_start_tracing**\n  - Title: Start tracing\n  - Description: Start trace recording\n  - Parameters: None\n  - Read-only: **true**\n\n<!-- NOTE: This has been generated via update-readme.js -->\n\n- **browser_stop_tracing**\n  - Title: Stop tracing\n  - Description: Stop trace recording\n  - Parameters: None\n  - Read-only: **true**\n\n</details>\n\n\n<!--- End of tools generated section -->\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/playwright-mcp",
          "npm_downloads": 88372,
          "npm_package_name": "playwright-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "needle-ai--needle-mcp": {
          "owner": "needle-ai",
          "name": "needle-mcp",
          "url": "https://github.com/needle-ai/needle-mcp",
          "imageUrl": "https://github.com/needle-ai.png",
          "description": "Manage documents and perform searches utilizing Needle's capabilities through Claude's Desktop Application.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:38.309163",
          "collection_timestamp": "2025-10-02T15:01:12.950260",
          "stars": 81,
          "forks": 21,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-15T14:25:13Z",
          "updated_at": "2025-09-16T07:46:37Z",
          "open_issues": 2,
          "readme_content": "# Build Agents with Needle MCP Server\n\n[![smithery badge](https://smithery.ai/badge/needle-mcp)](https://smithery.ai/server/needle-mcp)\n\n![Screenshot of Feature - Claude](https://github.com/user-attachments/assets/a7286901-e7be-4efe-afd9-72021dce03d4)\n\nMCP (Model Context Protocol) server to manage documents and perform searches using [Needle](https://needle.app) through Claude's Desktop Application.\n\n<a href=\"https://glama.ai/mcp/servers/5jw1t7hur2\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/5jw1t7hur2/badge\" alt=\"Needle Server MCP server\" />\n</a>\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Features](#features)\n- [Usage](#usage)\n  - [Commands in Claude Desktop](#commands-in-claude-desktop)\n  - [Result in Needle](#result-in-needle)\n- [Installation](#installation)\n- [Video Explanation](#youtube-video-explanation)\n\n---\n\n## Overview\n\nNeedle MCP Server allows you to:\n\n- Organize and store documents for quick retrieval.\n- Perform powerful searches via Claude's large language model.\n- Integrate seamlessly with the Needle ecosystem for advanced document management.\n\nMCP (Model Context Protocol) standardizes the way LLMs connect to external data sources. You can use Needle MCP Server to easily enable semantic search tools in your AI applications, making data buried in PDFs, DOCX, XLSX, and other files instantly accessible by LLMs.\n\n**We recommend using our remote MCP server** for the best experience - no local setup required.\n\n---\n\n## Features\n\n- **Document Management:** Easily add and organize documents on the server.\n- **Search & Retrieval:** Claude-based natural language search for quick answers.\n- **Easy Integration:** Works with [Claude Desktop](#commands-in-claude-desktop) and Needle collections.\n\n---\n\n## Usage\n\n### Commands in Claude Desktop\n\nBelow is an example of how the commands can be used in Claude Desktop to interact with the server:\n\n![Using commands in Claude Desktop](https://github.com/user-attachments/assets/9e0ce522-6675-46d9-9bfb-3162d214625b)\n\n1. **Open Claude Desktop** and connect to the Needle MCP Server.  \n2. **Use simple text commands** to search, retrieve, or modify documents.  \n3. **Review search results** returned by Claude in a user-friendly interface.\n\n### Result in Needle\n\nhttps://github.com/user-attachments/assets/0235e893-af96-4920-8364-1e86f73b3e6c\n\n---\n\n## Youtube Video Explanation\n\nFor a full walkthrough on using the Needle MCP Server with Claude and Claude Desktop, watch this [YouTube explanation video](https://youtu.be/nVrRYp9NZYg).\n\n---\n\n## Installation\n\n### 1. Remote MCP Server (Recommended)\n\n**Claude Desktop Config**\n\nCreate or update your config file:\n- For MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- For Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"needle\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"https://mcp.needle.app/mcp\",\n        \"--header\",\n        \"Authorization:Bearer ${NEEDLE_API_KEY}\"\n      ],\n      \"env\": {\n        \"NEEDLE_API_KEY\": \"<your-needle-api-key>\"\n      }\n    }\n  }\n}\n```\n\n**Cursor Config**\n\nCreate or update `.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"needle\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"https://mcp.needle.app/mcp\",\n        \"--header\",\n        \"Authorization:${NEEDLE_AUTH_HEADER}\"\n      ],\n      \"env\": {\n        \"NEEDLE_AUTH_HEADER\": \"Bearer <your-needle-api-key>\"\n      }\n    }\n  }\n}\n```\n\nGet your API key from [Needle Settings](https://needle.app).\n\nWe provide two endpoints:\n- **Streamable HTTP**: `https://mcp.needle.app/mcp` (recommended)\n- **SSE**: `https://mcp.needle.app/sse`\n\nNote: MCP deprecated SSE endpoints in the latest specification, so newer clients should prefer the Streamable HTTP endpoint.\n\n### 2. Local Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/needle-ai/needle-mcp.git\n```\n\n2. Install UV globally using Homebrew:\n```bash\nbrew install uv\n```\n\n3. Create your config file:\n   - For MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - For Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n**Claude Desktop Config**\n\n```json\n{\n  \"mcpServers\": {\n    \"needle\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/path/to/needle-mcp\", \"run\", \"needle-mcp\"],\n      \"env\": {\n        \"NEEDLE_API_KEY\": \"<your-needle-api-key>\"\n      }\n    }\n  }\n}\n```\n\n**Cursor Config**\n\n```json\n{\n  \"mcpServers\": {\n    \"needle\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/path/to/needle-mcp\", \"run\", \"needle-mcp\"],\n      \"env\": {\n        \"NEEDLE_API_KEY\": \"<your-needle-api-key>\"\n      }\n    }\n  }\n}\n```\n\n4. Replace `/path/to/needle-mcp` with your actual repository path\n5. Add your Needle API key\n6. Restart Claude Desktop\n\n**Installing via Smithery**\n\n```bash\nnpx -y @smithery/cli install needle-mcp --client claude\n```\n\n### 3. Docker Installation\n\n1. Clone and build:\n```bash\ngit clone https://github.com/needle-ai/needle-mcp.git\ncd needle-mcp\ndocker build -t needle-mcp .\n```\n\n2. Add to your Claude Desktop config (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n```json\n{\n  \"mcpServers\": {\n    \"needle\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"--rm\", \"-i\", \"needle-mcp\"],\n      \"env\": {\n        \"NEEDLE_API_KEY\": \"<your-needle-api-key>\"\n      }\n    }\n  }\n}\n```\n\n3. Restart Claude Desktop\n\n## Usage Examples\n\n* \"Create a new collection called 'Technical Docs'\"\n* \"Add this document to the collection, which is https://needle.app\"\n* \"Search the collection for information about AI\"\n* \"List all my collections\"\n\n## Troubleshooting\n\nIf not working:\n- Make sure `uv` is installed globally (if not, uninstall with `pip uninstall uv` and reinstall with `brew install uv`)\n- Or find `uv` path with `which uv` and replace `\"command\": \"uv\"` with the full path\n- Verify your Needle API key is correct\n- Check if the needle-mcp path in config matches your actual repository location\n\n### Reset Claude Desktop Configuration\n\nIf you're seeing old configurations or the integration isn't working:\n\n1. Find all Claude Desktop config files:\n```bash\nfind / -name \"claude_desktop_config.json\" 2>/dev/null\n```\n\n2. Remove all Claude Desktop data:\n- On MacOS: `rm -rf ~/Library/Application\\ Support/Claude/*`\n- On Windows: Delete contents of `%APPDATA%/Claude/`\n\n3. Create a fresh config with only Needle:\n```\nmkdir -p ~/Library/Application\\ Support/Claude\ncat > ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n<< 'EOL'\n{\n  \"mcpServers\": {\n    \"needle\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/needle-mcp\",\n        \"run\",\n        \"needle-mcp\"\n      ],\n      \"env\": {\n        \"NEEDLE_API_KEY\": \"your_needle_api_key\"\n      }\n    }\n  }\n}\nEOL\n```\n\n4. Completely quit Claude Desktop (Command+Q on Mac) and relaunch it\n\n5. If you still see old configurations:\n- Check for additional config files in other locations\n- Try clearing browser cache if using web version\n- Verify the config file is being read from the correct location\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "oceanbase--awesome-oceanbase-mcp": {
          "owner": "oceanbase",
          "name": "awesome-oceanbase-mcp",
          "url": "https://github.com/oceanbase/awesome-oceanbase-mcp",
          "imageUrl": "https://github.com/oceanbase.png",
          "description": "Facilitates secure interaction with OceanBase databases, allowing users to list tables, read data, and execute SQL queries through a controlled interface.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:39.389321",
          "collection_timestamp": "2025-10-02T15:01:20.319930",
          "stars": 78,
          "forks": 27,
          "license": "Apache License 2.0",
          "language": "Python",
          "created_at": "2025-03-19T09:24:59Z",
          "updated_at": "2025-09-30T01:56:27Z",
          "open_issues": 2,
          "readme_content": "<div align=\"center\">\n\n# üåä Awesome OceanBase MCP \n\n**Model Context Protocol (MCP) Server Collection for OceanBase Ecosystem**\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](README_CN.md)\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://python.org)\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue.svg)](https://www.typescriptlang.org/)\n\n</div>\n\n## üìñ Project Overview\n\n**awesome-oceanbase-mcp** is a Model Context Protocol (MCP) server repository specifically designed for the OceanBase ecosystem.\n\nüéØ **Mission**: Enable AI assistants to interact directly with OceanBase databases and ecosystem components through standardized MCP protocols.\n\n‚ú® **Core Values**:\n- ü§ñ **AI-Friendly**: Direct database operations within Claude, ChatGPT and other AI assistants\n- üîí **Secure & Reliable**: Provides safe database access and operation mechanisms\n- üõ†Ô∏è **Complete Ecosystem**: Covers the complete OceanBase product and tool chain\n- üöÄ **Ready to Use**: Simple configuration to get started\n\n## üîç What is MCP?\n\nThe Model Context Protocol (MCP) is an open protocol designed to enable seamless integration between AI applications and external data sources and tools. It provides a standardized way for AI models to access the contextual information and capabilities they need.\n\n## üöÄ Quick Start\n\n### Prerequisites\n\nIf you don't have an OceanBase database instance yet, please:\n- Visit [OceanBase Official Repository](https://github.com/oceanbase/oceanbase) to get the latest version\n- Or use [OceanBase Online Trial](https://www.oceanbase.com/free-trial) for quick setup\n\n## üóÇÔ∏è MCP Server Collection\n\nThis repository provides complete MCP servers for the OceanBase ecosystem:\n\n<table>\n<thead>\n<tr>\n<th width=\"25%\">üîß MCP Server</th>\n<th width=\"60%\">üìù Description</th>\n<th width=\"15%\">üìö Documentation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>OceanBase MCP Server</strong></td>\n<td>Provides secure interaction capabilities with OceanBase databases, supporting SQL queries, data management operations</td>\n<td><a href=\"src/oceanbase_mcp_server/README.md\">üìñ View</a></td>\n</tr>\n<tr>\n<td><strong>OCP MCP Server</strong></td>\n<td>Integrates with OceanBase Cloud Platform, providing cluster management and monitoring capabilities</td>\n<td><a href=\"doc/ocp_mcp_server.md\">üìñ View</a></td>\n</tr>\n<tr>\n<td><strong>OBCloud MCP Server</strong></td>\n<td>Connects to OBCloud services, providing cloud database management functionality</td>\n<td><a href=\"src/obcloud_mcp_server/README.md\">üìñ View</a></td>\n</tr>\n<tr>\n<td><strong>OKCTL MCP Server</strong></td>\n<td>Manages OceanBase resources and deployments in Kubernetes environments</td>\n<td><a href=\"doc/okctl_mcp_server.md\">üìñ View</a></td>\n</tr>\n<tr>\n<td><strong>OBDIAG MCP Server</strong></td>\n<td>Provides OceanBase diagnostic tool integration, supporting performance analysis and troubleshooting</td>\n<td><a href=\"doc/obdiag_mcp_server.md\">üìñ View</a></td>\n</tr>\n<tr>\n<td><strong>obshell MCP Server</strong></td>\n<td>Enables OceanBase cluster creation, deployment and operations management through obshell</td>\n<td><a href=\"doc/obshell_mcp_server.md\">üìñ View</a></td>\n</tr>\n</tbody>\n</table>\n\nüí° **Usage Tips**: Click on the documentation links to view detailed installation and configuration guides.\n\n## üí¨ Community & Support\n\nWe highly value community feedback and contributions!\n\n### üôã‚Äç‚ôÄÔ∏è Getting Help\n\n- üí¨ **Technical Discussion**: Visit [OceanBase Community Forum](https://ask.oceanbase.com) to connect with developers and community partners\n- üìß **Technical Support**: Get official technical support through the community forum\n- üìñ **Documentation Hub**: Check [OceanBase Official Documentation](https://www.oceanbase.com/docs)\n\n### üêõ Issue Reporting\n\nIf you encounter any issues during usage:\n\n1. First check the documentation for the corresponding MCP server\n2. Search [existing Issues](https://github.com/oceanbase/mcp-oceanbase/issues) to confirm if the issue is known\n3. If it's a new issue, please [create a new Issue](https://github.com/oceanbase/mcp-oceanbase/issues/new)\n\n### ü§ù Contributing\n\nWe welcome all forms of contributions:\n\n- üîß **Code Contribution**: Submit Pull Requests\n- üìù **Documentation**: Improve docs and examples\n- üêõ **Bug Reports**: Report bugs and suggest improvements\n- üí° **Feature Requests**: Propose new feature requirements\n\n## üìÑ License\n\nThis project is released under the [Apache License 2.0](LICENSE).\n\n---\n\n<div align=\"center\">\n\n**‚≠ê If this project is helpful to you, please give us a Star!**\n\nMade with ‚ù§Ô∏è by OceanBase Team\n\n</div>\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "oxylabs--oxylabs-mcp": {
          "owner": "oxylabs",
          "name": "oxylabs-mcp",
          "url": "https://github.com/oxylabs/oxylabs-mcp",
          "imageUrl": "https://github.com/oxylabs.png",
          "description": "Fetch and process content from specified URLs using the Oxylabs Web Scraper API, enabling easy access to web data.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:40.417953",
          "collection_timestamp": "2025-10-02T15:01:27.836830",
          "stars": 66,
          "forks": 16,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-01-17T13:47:05Z",
          "updated_at": "2025-09-30T02:00:01Z",
          "open_issues": 2,
          "readme_content": "<p align=\"center\">\n  <img src=\"https://storage.googleapis.com/oxylabs-public-assets/oxylabs_mcp.svg\" alt=\"Oxylabs + MCP\">\n</p>\n<h1 align=\"center\" style=\"border-bottom: none;\">\n  Oxylabs MCP Server\n</h1>\n\n<p align=\"center\">\n  <em>The missing link between AI models and the real‚Äëworld web: one API that delivers clean, structured data from any site.</em>\n</p>\n\n<div align=\"center\">\n\n[![smithery badge](https://smithery.ai/badge/@oxylabs/oxylabs-mcp)](https://smithery.ai/server/@oxylabs/oxylabs-mcp)\n[![pypi package](https://img.shields.io/pypi/v/oxylabs-mcp?color=%2334D058&label=pypi%20package)](https://pypi.org/project/oxylabs-mcp/)\n[![](https://dcbadge.vercel.app/api/server/eWsVUJrnG5?style=flat)](https://discord.gg/Pds3gBmKMH)\n[![Licence](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/f6a9c0bc-83a6-4f78-89d9-f2cec4ece98d)\n![Coverage badge](https://raw.githubusercontent.com/oxylabs/oxylabs-mcp/coverage/coverage-badge.svg)\n\n<br/>\n<a href=\"https://glama.ai/mcp/servers/@oxylabs/oxylabs-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@oxylabs/oxylabs-mcp/badge\" alt=\"Oxylabs Server MCP server\" />\n</a>\n\n</div>\n\n---\n\n## üìñ Overview\n\nThe Oxylabs MCP server provides a bridge between AI models and the web. It enables them to scrape any URL, render JavaScript-heavy pages, extract and format content for AI use, bypass anti-scraping measures, and access geo-restricted web data from 195+ countries.\n\n\n## üõ†Ô∏è MCP Tools\n\nOxylabs MCP provides two sets of tools that can be used together or independently:\n\n### Oxylabs Web Scraper API Tools\n1. **universal_scraper**: Uses Oxylabs Web Scraper API for general website scraping;\n2. **google_search_scraper**: Uses Oxylabs Web Scraper API to extract results from Google Search;\n3. **amazon_search_scraper**: Uses Oxylabs Web Scraper API to scrape Amazon search result pages;\n4. **amazon_product_scraper**: Uses Oxylabs Web Scraper API to extract data from individual Amazon product pages.\n\n### Oxylabs AI Studio Tools\n\n5. **ai_scraper**: Scrape content from any URL in JSON or Markdown format with AI-powered data extraction;\n6. **ai_crawler**: Based on a prompt, crawls a website and collects data in Markdown or JSON format across multiple pages;\n7. **ai_browser_agent**: Based on prompt, controls a browser and returns data in Markdown, JSON, HTML, or screenshot formats;\n8. **ai_search**: Search the web for URLs and their contents with AI-powered content extraction.\n\n\n## ‚úÖ Prerequisites\n\nBefore you begin, make sure you have **at least one** of the following:\n\n- **Oxylabs Web Scraper API Account**: Obtain your username and password from [Oxylabs](https://dashboard.oxylabs.io/) (1-week free trial available);\n- **Oxylabs AI Studio API Key**: Obtain your API key from [Oxylabs AI Studio](https://aistudio.oxylabs.io/settings/api-key). (1000 credits free).\n\n## üì¶ Configuration\n\n### Environment variables\n\nOxylabs MCP server supports the following environment variables:\n| Name                       | Description                                   | Default |\n|----------------------------|-----------------------------------------------|---------|\n| `OXYLABS_USERNAME`         | Your Oxylabs Web Scraper API username         |         |\n| `OXYLABS_PASSWORD`         | Your Oxylabs Web Scraper API password         |         |\n| `OXYLABS_AI_STUDIO_API_KEY`| Your Oxylabs AI Studio API key                |         |\n| `LOG_LEVEL`                | Log level for the logs returned to the client | `INFO`  |\n\nBased on provided credentials, the server will automatically expose the corresponding tools:\n- If only `OXYLABS_USERNAME` and `OXYLABS_PASSWORD` are provided, the server will expose the Web Scraper API tools;\n- If only `OXYLABS_AI_STUDIO_API_KEY` is provided, the server will expose the AI Studio tools;\n- If both `OXYLABS_USERNAME` and `OXYLABS_PASSWORD` and `OXYLABS_AI_STUDIO_API_KEY` are provided, the server will expose all tools.\n\n‚ùó‚ùó‚ùó **Important note: if you don't have Web Scraper API or Oxylabs AI studio credentials, delete the corresponding environment variables placeholders.\nLeaving placeholder values will result in exposed tools that do not work.**\n\n\n\n### Configure with uvx\n\n- Install the uvx package manager:\n  ```bash\n  # macOS and Linux\n  curl -LsSf https://astral.sh/uv/install.sh | sh\n  ```\n  OR:\n  ```bash\n  # Windows\n  powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n  ```\n- Use the following config:\n  ```json\n  {\n    \"mcpServers\": {\n      \"oxylabs\": {\n        \"command\": \"uvx\",\n        \"args\": [\"oxylabs-mcp\"],\n        \"env\": {\n          \"OXYLABS_USERNAME\": \"OXYLABS_USERNAME\",\n          \"OXYLABS_PASSWORD\": \"OXYLABS_PASSWORD\",\n          \"OXYLABS_AI_STUDIO_API_KEY\": \"OXYLABS_AI_STUDIO_API_KEY\"\n        }\n      }\n    }\n  }\n  ```\n\n### Configure with uv\n\n- Install the uv package manager:\n  ```bash\n  # macOS and Linux\n  curl -LsSf https://astral.sh/uv/install.sh | sh\n  ```\n  OR:\n  ```bash\n  # Windows\n  powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n  ```\n\n- Use the following config:\n  ```json\n  {\n    \"mcpServers\": {\n      \"oxylabs\": {\n        \"command\": \"uv\",\n        \"args\": [\n          \"--directory\",\n          \"/<Absolute-path-to-folder>/oxylabs-mcp\",\n          \"run\",\n          \"oxylabs-mcp\"\n        ],\n        \"env\": {\n          \"OXYLABS_USERNAME\": \"OXYLABS_USERNAME\",\n          \"OXYLABS_PASSWORD\": \"OXYLABS_PASSWORD\",\n          \"OXYLABS_AI_STUDIO_API_KEY\": \"OXYLABS_AI_STUDIO_API_KEY\"\n        }\n      }\n    }\n  }\n  ```\n\n### Configure with Smithery Oauth2\n\n- Go to https://smithery.ai/server/@oxylabs/oxylabs-mcp;\n- Click _Auto_ to install the Oxylabs MCP configuration for the respective client;\n- OR use the following config:\n```json\n  {\n    \"mcpServers\": {\n      \"oxylabs\": {\n        \"url\": \"https://server.smithery.ai/@oxylabs/oxylabs-mcp/mcp\"\n      }\n    }\n  }\n```\n- Follow the instructions to authenticate Oxylabs MCP with Oauth2 flow\n\n### Configure with Smithery query parameters\n\nIn case your client does not support the Oauth2 authentication, you can pass the Oxylabs authentication parameters directly in url\n```json\n  {\n    \"mcpServers\": {\n      \"oxylabs\": {\n        \"url\": \"https://server.smithery.ai/@oxylabs/oxylabs-mcp/mcp?oxylabsUsername=OXYLABS_USERNAME&oxylabsPassword=OXYLABS_PASSWORD&oxylabsAiStudioApiKey=OXYLABS_AI_STUDIO_API_KEY\"\n      }\n    }\n  }\n```\n\n### Manual Setup with Claude Desktop\n\nNavigate to **Claude ‚Üí Settings ‚Üí Developer ‚Üí Edit Config** and add one of the configurations above to the `claude_desktop_config.json` file.\n\n### Manual Setup with Cursor AI\n\nNavigate to **Cursor ‚Üí Settings ‚Üí Cursor Settings ‚Üí MCP**. Click **Add new global MCP server** and add one of the configurations above.\n\n\n\n## üìù Logging\n\nServer provides additional information about the tool calls in `notification/message` events\n\n```json\n{\n  \"method\": \"notifications/message\",\n  \"params\": {\n    \"level\": \"info\",\n    \"data\": \"Create job with params: {\\\"url\\\": \\\"https://ip.oxylabs.io\\\"}\"\n  }\n}\n```\n\n```json\n{\n  \"method\": \"notifications/message\",\n  \"params\": {\n    \"level\": \"info\",\n    \"data\": \"Job info: job_id=7333113830223918081 job_status=done\"\n  }\n}\n```\n\n```json\n{\n  \"method\": \"notifications/message\",\n  \"params\": {\n    \"level\": \"error\",\n    \"data\": \"Error: request to Oxylabs API failed\"\n  }\n}\n```\n\n---\n\n## üõ°Ô∏è License\n\nDistributed under the MIT License ‚Äì see [LICENSE](LICENSE) for details.\n\n---\n\n## About Oxylabs\n\nEstablished in 2015, Oxylabs is a market-leading web intelligence collection\nplatform, driven by the highest business, ethics, and compliance standards,\nenabling companies worldwide to unlock data-driven insights.\n\n[![image](https://oxylabs.io/images/og-image.png)](https://oxylabs.io/)\n\n<div align=\"center\">\n<sub>\n  Made with ‚òï by <a href=\"https://oxylabs.io\">Oxylabs</a>.  Feel free to give us a ‚≠ê if MCP saved you a weekend.\n</sub>\n</div>\n\n\n## ‚ú® Key Features\n\n<details>\n<summary><strong> Scrape content from any site</strong></summary>\n<br>\n\n- Extract data from any URL, including complex single-page applications\n- Fully render dynamic websites using headless browser support\n- Choose full JavaScript rendering, HTML-only, or none\n- Emulate Mobile and Desktop viewports for realistic rendering\n\n</details>\n\n<details>\n<summary><strong> Automatically get AI-ready data</strong></summary>\n<br>\n\n- Automatically clean and convert HTML to Markdown for improved readability\n- Use automated parsers for popular targets like Google, Amazon, and more\n\n</details>\n\n<details>\n<summary><strong> Bypass blocks & geo-restrictions</strong></summary>\n<br>\n\n- Bypass sophisticated bot protection systems with high success rate\n- Reliably scrape even the most complex websites\n- Get automatically rotating IPs from a proxy pool covering 195+ countries\n\n</details>\n\n<details>\n<summary><strong> Flexible setup & cross-platform support</strong></summary>\n<br>\n\n- Set rendering and parsing options if needed\n- Feed data directly into AI models or analytics tools\n- Works on macOS, Windows, and Linux\n\n</details>\n\n<details>\n<summary><strong> Built-in error handling and request management</strong></summary>\n<br>\n\n- Comprehensive error handling and reporting\n- Smart rate limiting and request management\n\n</details>\n\n---\n\n\n## Why Oxylabs MCP? &nbsp;üï∏Ô∏è ‚ûú üì¶ ‚ûú ü§ñ\n\nImagine telling your LLM *\"Summarise the latest Hacker News discussion about GPT‚Äë5\"* ‚Äì and it simply answers.  \nMCP (Multi‚ÄëClient Proxy) makes that happen by doing the boring parts for you:\n\n| What Oxylabs MCP does                                             | Why it matters to you                    |\n|-------------------------------------------------------------------|------------------------------------------|\n| **Bypasses anti‚Äëbot walls** with the Oxylabs global proxy network | Keeps you unblocked and anonymous        |\n| **Renders JavaScript** in headless Chrome                         | Single‚Äëpage apps, sorted                 |\n| **Cleans HTML ‚Üí JSON**                                            | Drop straight into vector DBs or prompts |\n| **Optional structured parsers** (Google, Amazon, etc.)            | One‚Äëline access to popular targets       |\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "pydantic--logfire-mcp": {
          "owner": "pydantic",
          "name": "logfire-mcp",
          "url": "https://github.com/pydantic/logfire-mcp",
          "imageUrl": "https://github.com/pydantic.png",
          "description": "Analyzes telemetry data and distributed traces using OpenTelemetry. Queries metrics and performs SQL queries for insights into application exceptions and errors in real-time.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:41.895229",
          "collection_timestamp": "2025-10-02T15:01:35.409659",
          "stars": 112,
          "forks": 19,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-06T12:26:11Z",
          "updated_at": "2025-09-28T02:55:14Z",
          "open_issues": 7,
          "readme_content": "<!-- DO NOT MODIFY THIS FILE DIRECTLY, IT IS GENERATED BY THE TESTS! -->\n\n# Pydantic Logfire MCP Server\n\nThis repository contains a Model Context Protocol (MCP) server with tools that can access the OpenTelemetry traces and\nmetrics you've sent to Pydantic Logfire.\n\n<a href=\"https://glama.ai/mcp/servers/@pydantic/logfire-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@pydantic/logfire-mcp/badge\" alt=\"Pydantic Logfire Server MCP server\" />\n</a>\n\nThis MCP server enables LLMs to retrieve your application's telemetry data, analyze distributed\ntraces, and make use of the results of arbitrary SQL queries executed using the Pydantic Logfire APIs.\n\n## Available Tools\n\n* `find_exceptions_in_file` - Get the details about the 10 most recent exceptions on the file.\n  * Arguments:\n    * `filepath` (string) - The path to the file to find exceptions in.\n    * `age` (integer) - Number of minutes to look back, e.g. 30 for last 30 minutes. Maximum allowed value is 7 days.\n\n* `arbitrary_query` - Run an arbitrary query on the Pydantic Logfire database.\n  * Arguments:\n    * `query` (string) - The query to run, as a SQL string.\n    * `age` (integer) - Number of minutes to look back, e.g. 30 for last 30 minutes. Maximum allowed value is 7 days.\n\n* `logfire_link` - Creates a link to help the user to view the trace in the Logfire UI.\n  * Arguments:\n    * `trace_id` (string) - The trace ID to link to.\n\n* `schema_reference` - The database schema for the Logfire DataFusion database.\n\n\n## Setup\n\n### Install `uv`\n\nThe first thing to do is make sure `uv` is installed, as `uv` is used to run the MCP server.\n\nFor installation instructions, see the [`uv` installation docs](https://docs.astral.sh/uv/getting-started/installation/).\n\nIf you already have an older version of `uv` installed, you might need to update it with `uv self update`.\n\n### Obtain a Pydantic Logfire read token\nIn order to make requests to the Pydantic Logfire APIs, the Pydantic Logfire MCP server requires a \"read token\".\n\nYou can create one under the \"Read Tokens\" section of your project settings in Pydantic Logfire:\nhttps://logfire.pydantic.dev/-/redirect/latest-project/settings/read-tokens\n\n> [!IMPORTANT]\n> Pydantic Logfire read tokens are project-specific, so you need to create one for the specific project you want to expose to the Pydantic Logfire MCP server.\n\n### Manually run the server\n\nOnce you have `uv` installed and have a Pydantic Logfire read token, you can manually run the MCP server using `uvx` (which is provided by `uv`).\n\nYou can specify your read token using the `LOGFIRE_READ_TOKEN` environment variable:\n\n```bash\nLOGFIRE_READ_TOKEN=YOUR_READ_TOKEN uvx logfire-mcp@latest\n```\n\nYou can also set `LOGFIRE_READ_TOKEN` in a `.env` file:\n\n```bash\nLOGFIRE_READ_TOKEN=pylf_v1_us_...\n```\n\n**NOTE:** for this to work, the MCP server needs to run with the directory containing the `.env` file in its working directory.\n\nor using the `--read-token` flag:\n\n```bash\nuvx logfire-mcp@latest --read-token=YOUR_READ_TOKEN\n```\n> [!NOTE]\n> If you are using Cursor, Claude Desktop, Cline, or other MCP clients that manage your MCP servers for you, you **_do\n    NOT_** need to manually run the server yourself. The next section will show you how to configure these clients to make\n    use of the Pydantic Logfire MCP server.\n\n### Base URL\n\nIf you are running Logfire in a self hosted environment, you need to specify the base URL.\nThis can be done using the `LOGFIRE_BASE_URL` environment variable:\n\n```bash\nLOGFIRE_BASE_URL=https://logfire.my-company.com uvx logfire-mcp@latest --read-token=YOUR_READ_TOKEN\n```\n\nYou can also use the `--base-url` argument:\n\n```bash\nuvx logfire-mcp@latest --base-url=https://logfire.my-company.com --read-token=YOUR_READ_TOKEN\n```\n\n## Configuration with well-known MCP clients\n\n### Configure for Cursor\n\nCreate a `.cursor/mcp.json` file in your project root:\n\n```json\n{\n  \"mcpServers\": {\n    \"logfire\": {\n      \"command\": \"uvx\",\n      \"args\": [\"logfire-mcp@latest\", \"--read-token=YOUR-TOKEN\"]\n    }\n  }\n}\n```\n\nThe Cursor doesn't accept the `env` field, so you need to use the `--read-token` flag instead.\n\n### Configure for Claude code\n\nRun the following command:\n\n```bash\nclaude mcp add logfire -e LOGFIRE_READ_TOKEN=YOUR_TOKEN -- uvx logfire-mcp@latest\n```\n\n### Configure for Claude Desktop\n\nAdd to your Claude settings:\n\n```json\n{\n  \"command\": [\"uvx\"],\n  \"args\": [\"logfire-mcp@latest\"],\n  \"type\": \"stdio\",\n  \"env\": {\n    \"LOGFIRE_READ_TOKEN\": \"YOUR_TOKEN\"\n  }\n}\n```\n\n### Configure for Cline\n\nAdd to your Cline settings in `cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"logfire\": {\n      \"command\": \"uvx\",\n      \"args\": [\"logfire-mcp@latest\"],\n      \"env\": {\n        \"LOGFIRE_READ_TOKEN\": \"YOUR_TOKEN\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Configure for VS Code\n\nMake sure you [enabled MCP support in VS Code](https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_enable-mcp-support-in-vs-code).\n\nCreate a `.vscode/mcp.json` file in your project's root directory:\n\n```json\n{\n  \"servers\": {\n    \"logfire\": {\n      \"type\": \"stdio\",\n      \"command\": \"uvx\", // or the absolute /path/to/uvx\n      \"args\": [\"logfire-mcp@latest\"],\n      \"env\": {\n        \"LOGFIRE_READ_TOKEN\": \"YOUR_TOKEN\"\n      }\n    }\n  }\n}\n```\n\n### Configure for Zed\n\nCreate a `.zed/settings.json` file in your project's root directory:\n\n```json\n{\n  \"context_servers\": {\n    \"logfire\": {\n      \"source\": \"custom\",\n      \"command\": \"uvx\",\n      \"args\": [\"logfire-mcp@latest\"],\n      \"env\": {\n        \"LOGFIRE_READ_TOKEN\": \"YOUR_TOKEN\"\n      },\n      \"enabled\": true\n    }\n  }\n}\n```\n\n## Example Interactions\n\n1. Get details about exceptions from traces in a specific file:\n```json\n{\n  \"name\": \"find_exceptions_in_file\",\n  \"arguments\": {\n    \"filepath\": \"app/api.py\",\n    \"age\": 1440\n  }\n}\n```\n\nResponse:\n```json\n[\n  {\n    \"created_at\": \"2024-03-20T10:30:00Z\",\n    \"message\": \"Failed to process request\",\n    \"exception_type\": \"ValueError\",\n    \"exception_message\": \"Invalid input format\",\n    \"function_name\": \"process_request\",\n    \"line_number\": \"42\",\n    \"attributes\": {\n      \"service.name\": \"api-service\",\n      \"code.filepath\": \"app/api.py\"\n    },\n    \"trace_id\": \"1234567890abcdef\"\n  }\n]\n```\n\n2. Run a custom query on traces:\n```json\n{\n  \"name\": \"arbitrary_query\",\n  \"arguments\": {\n    \"query\": \"SELECT trace_id, message, created_at, attributes->>'service.name' as service FROM records WHERE severity_text = 'ERROR' ORDER BY created_at DESC LIMIT 10\",\n    \"age\": 1440\n  }\n}\n```\n\n## Examples of Questions for Claude\n\n1. \"What exceptions occurred in traces from the last hour across all services?\"\n2. \"Show me the recent errors in the file 'app/api.py' with their trace context\"\n3. \"How many errors were there in the last 24 hours per service?\"\n4. \"What are the most common exception types in my traces, grouped by service name?\"\n5. \"Get me the OpenTelemetry schema for traces and metrics\"\n6. \"Find all errors from yesterday and show their trace contexts\"\n\n## Getting Started\n\n1. First, obtain a Pydantic Logfire read token from:\n   https://logfire.pydantic.dev/-/redirect/latest-project/settings/read-tokens\n\n2. Run the MCP server:\n   ```bash\n   uvx logfire-mcp@latest --read-token=YOUR_TOKEN\n   ```\n\n3. Configure your preferred client (Cursor, Claude Desktop, or Cline) using the configuration examples above\n\n4. Start using the MCP server to analyze your OpenTelemetry traces and metrics!\n\n## Contributing\n\nWe welcome contributions to help improve the Pydantic Logfire MCP server. Whether you want to add new trace analysis tools, enhance metrics querying functionality, or improve documentation, your input is valuable.\n\nFor examples of other MCP servers and implementation patterns, see the [Model Context Protocol servers repository](https://github.com/modelcontextprotocol/servers).\n\n## License\n\nPydantic Logfire MCP is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "qdrant--mcp-server-qdrant": {
          "owner": "qdrant",
          "name": "mcp-server-qdrant",
          "url": "https://github.com/qdrant/mcp-server-qdrant",
          "imageUrl": "https://github.com/qdrant.png",
          "description": "Stores and retrieves information using the Qdrant vector search engine, enabling semantic search for relevant data. It functions as a memory layer for AI applications accessing external tools and information.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:43.643086",
          "collection_timestamp": "2025-10-02T15:01:43.280695",
          "stars": 964,
          "forks": 152,
          "license": "Apache License 2.0",
          "language": "Python",
          "created_at": "2024-12-02T12:07:39Z",
          "updated_at": "2025-10-02T08:49:13Z",
          "open_issues": 30,
          "readme_content": "# mcp-server-qdrant: A Qdrant MCP server\n\n[![smithery badge](https://smithery.ai/badge/mcp-server-qdrant)](https://smithery.ai/protocol/mcp-server-qdrant)\n\n> The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol that enables\n> seamless integration between LLM applications and external data sources and tools. Whether you're building an\n> AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to\n> connect LLMs with the context they need.\n\nThis repository is an example of how to create a MCP server for [Qdrant](https://qdrant.tech/), a vector search engine.\n\n## Overview\n\nAn official Model Context Protocol server for keeping and retrieving memories in the Qdrant vector search engine.\nIt acts as a semantic memory layer on top of the Qdrant database.\n\n## Components\n\n### Tools\n\n1. `qdrant-store`\n   - Store some information in the Qdrant database\n   - Input:\n     - `information` (string): Information to store\n     - `metadata` (JSON): Optional metadata to store\n     - `collection_name` (string): Name of the collection to store the information in. This field is required if there are no default collection name.\n                                   If there is a default collection name, this field is not enabled.\n   - Returns: Confirmation message\n2. `qdrant-find`\n   - Retrieve relevant information from the Qdrant database\n   - Input:\n     - `query` (string): Query to use for searching\n     - `collection_name` (string): Name of the collection to store the information in. This field is required if there are no default collection name.\n                                   If there is a default collection name, this field is not enabled.\n   - Returns: Information stored in the Qdrant database as separate messages\n\n## Environment Variables\n\nThe configuration of the server is done using environment variables:\n\n| Name                     | Description                                                         | Default Value                                                     |\n|--------------------------|---------------------------------------------------------------------|-------------------------------------------------------------------|\n| `QDRANT_URL`             | URL of the Qdrant server                                            | None                                                              |\n| `QDRANT_API_KEY`         | API key for the Qdrant server                                       | None                                                              |\n| `COLLECTION_NAME`        | Name of the default collection to use.                              | None                                                              |\n| `QDRANT_LOCAL_PATH`      | Path to the local Qdrant database (alternative to `QDRANT_URL`)     | None                                                              |\n| `EMBEDDING_PROVIDER`     | Embedding provider to use (currently only \"fastembed\" is supported) | `fastembed`                                                       |\n| `EMBEDDING_MODEL`        | Name of the embedding model to use                                  | `sentence-transformers/all-MiniLM-L6-v2`                          |\n| `TOOL_STORE_DESCRIPTION` | Custom description for the store tool                               | See default in [`settings.py`](src/mcp_server_qdrant/settings.py) |\n| `TOOL_FIND_DESCRIPTION`  | Custom description for the find tool                                | See default in [`settings.py`](src/mcp_server_qdrant/settings.py) |\n\nNote: You cannot provide both `QDRANT_URL` and `QDRANT_LOCAL_PATH` at the same time.\n\n> [!IMPORTANT]\n> Command-line arguments are not supported anymore! Please use environment variables for all configuration.\n\n### FastMCP Environment Variables\n\nSince `mcp-server-qdrant` is based on FastMCP, it also supports all the FastMCP environment variables. The most\nimportant ones are listed below:\n\n| Environment Variable                  | Description                                               | Default Value |\n|---------------------------------------|-----------------------------------------------------------|---------------|\n| `FASTMCP_DEBUG`                       | Enable debug mode                                         | `false`       |\n| `FASTMCP_LOG_LEVEL`                   | Set logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL) | `INFO`        |\n| `FASTMCP_HOST`                        | Host address to bind the server to                        | `127.0.0.1`   |\n| `FASTMCP_PORT`                        | Port to run the server on                                 | `8000`        |\n| `FASTMCP_WARN_ON_DUPLICATE_RESOURCES` | Show warnings for duplicate resources                     | `true`        |\n| `FASTMCP_WARN_ON_DUPLICATE_TOOLS`     | Show warnings for duplicate tools                         | `true`        |\n| `FASTMCP_WARN_ON_DUPLICATE_PROMPTS`   | Show warnings for duplicate prompts                       | `true`        |\n| `FASTMCP_DEPENDENCIES`                | List of dependencies to install in the server environment | `[]`          |\n\n## Installation\n\n### Using uvx\n\nWhen using [`uvx`](https://docs.astral.sh/uv/guides/tools/#running-tools) no specific installation is needed to directly run *mcp-server-qdrant*.\n\n```shell\nQDRANT_URL=\"http://localhost:6333\" \\\nCOLLECTION_NAME=\"my-collection\" \\\nEMBEDDING_MODEL=\"sentence-transformers/all-MiniLM-L6-v2\" \\\nuvx mcp-server-qdrant\n```\n\n#### Transport Protocols\n\nThe server supports different transport protocols that can be specified using the `--transport` flag:\n\n```shell\nQDRANT_URL=\"http://localhost:6333\" \\\nCOLLECTION_NAME=\"my-collection\" \\\nuvx mcp-server-qdrant --transport sse\n```\n\nSupported transport protocols:\n\n- `stdio` (default): Standard input/output transport, might only be used by local MCP clients\n- `sse`: Server-Sent Events transport, perfect for remote clients\n- `streamable-http`: Streamable HTTP transport, perfect for remote clients, more recent than SSE\n\nThe default transport is `stdio` if not specified.\n\nWhen SSE transport is used, the server will listen on the specified port and wait for incoming connections. The default\nport is 8000, however it can be changed using the `FASTMCP_PORT` environment variable.\n\n```shell\nQDRANT_URL=\"http://localhost:6333\" \\\nCOLLECTION_NAME=\"my-collection\" \\\nFASTMCP_PORT=1234 \\\nuvx mcp-server-qdrant --transport sse\n```\n\n### Using Docker\n\nA Dockerfile is available for building and running the MCP server:\n\n```bash\n# Build the container\ndocker build -t mcp-server-qdrant .\n\n# Run the container\ndocker run -p 8000:8000 \\\n  -e FASTMCP_HOST=\"0.0.0.0\" \\\n  -e QDRANT_URL=\"http://your-qdrant-server:6333\" \\\n  -e QDRANT_API_KEY=\"your-api-key\" \\\n  -e COLLECTION_NAME=\"your-collection\" \\\n  mcp-server-qdrant\n```\n\n> [!TIP]\n> Please note that we set `FASTMCP_HOST=\"0.0.0.0\"` to make the server listen on all network interfaces. This is\n> necessary when running the server in a Docker container.\n\n### Installing via Smithery\n\nTo install Qdrant MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/protocol/mcp-server-qdrant):\n\n```bash\nnpx @smithery/cli install mcp-server-qdrant --client claude\n```\n\n### Manual configuration of Claude Desktop\n\nTo use this server with the Claude Desktop app, add the following configuration to the \"mcpServers\" section of your\n`claude_desktop_config.json`:\n\n```json\n{\n  \"qdrant\": {\n    \"command\": \"uvx\",\n    \"args\": [\"mcp-server-qdrant\"],\n    \"env\": {\n      \"QDRANT_URL\": \"https://xyz-example.eu-central.aws.cloud.qdrant.io:6333\",\n      \"QDRANT_API_KEY\": \"your_api_key\",\n      \"COLLECTION_NAME\": \"your-collection-name\",\n      \"EMBEDDING_MODEL\": \"sentence-transformers/all-MiniLM-L6-v2\"\n    }\n  }\n}\n```\n\nFor local Qdrant mode:\n\n```json\n{\n  \"qdrant\": {\n    \"command\": \"uvx\",\n    \"args\": [\"mcp-server-qdrant\"],\n    \"env\": {\n      \"QDRANT_LOCAL_PATH\": \"/path/to/qdrant/database\",\n      \"COLLECTION_NAME\": \"your-collection-name\",\n      \"EMBEDDING_MODEL\": \"sentence-transformers/all-MiniLM-L6-v2\"\n    }\n  }\n}\n```\n\nThis MCP server will automatically create a collection with the specified name if it doesn't exist.\n\nBy default, the server will use the `sentence-transformers/all-MiniLM-L6-v2` embedding model to encode memories.\nFor the time being, only [FastEmbed](https://qdrant.github.io/fastembed/) models are supported.\n\n## Support for other tools\n\nThis MCP server can be used with any MCP-compatible client. For example, you can use it with\n[Cursor](https://docs.cursor.com/context/model-context-protocol) and [VS Code](https://code.visualstudio.com/docs), which provide built-in support for the Model Context\nProtocol.\n\n### Using with Cursor/Windsurf\n\nYou can configure this MCP server to work as a code search tool for Cursor or Windsurf by customizing the tool\ndescriptions:\n\n```bash\nQDRANT_URL=\"http://localhost:6333\" \\\nCOLLECTION_NAME=\"code-snippets\" \\\nTOOL_STORE_DESCRIPTION=\"Store reusable code snippets for later retrieval. \\\nThe 'information' parameter should contain a natural language description of what the code does, \\\nwhile the actual code should be included in the 'metadata' parameter as a 'code' property. \\\nThe value of 'metadata' is a Python dictionary with strings as keys. \\\nUse this whenever you generate some code snippet.\" \\\nTOOL_FIND_DESCRIPTION=\"Search for relevant code snippets based on natural language descriptions. \\\nThe 'query' parameter should describe what you're looking for, \\\nand the tool will return the most relevant code snippets. \\\nUse this when you need to find existing code snippets for reuse or reference.\" \\\nuvx mcp-server-qdrant --transport sse # Enable SSE transport\n```\n\nIn Cursor/Windsurf, you can then configure the MCP server in your settings by pointing to this running server using\nSSE transport protocol. The description on how to add an MCP server to Cursor can be found in the [Cursor\ndocumentation](https://docs.cursor.com/context/model-context-protocol#adding-an-mcp-server-to-cursor). If you are\nrunning Cursor/Windsurf locally, you can use the following URL:\n\n```\nhttp://localhost:8000/sse\n```\n\n> [!TIP]\n> We suggest SSE transport as a preferred way to connect Cursor/Windsurf to the MCP server, as it can support remote\n> connections. That makes it easy to share the server with your team or use it in a cloud environment.\n\nThis configuration transforms the Qdrant MCP server into a specialized code search tool that can:\n\n1. Store code snippets, documentation, and implementation details\n2. Retrieve relevant code examples based on semantic search\n3. Help developers find specific implementations or usage patterns\n\nYou can populate the database by storing natural language descriptions of code snippets (in the `information` parameter)\nalong with the actual code (in the `metadata.code` property), and then search for them using natural language queries\nthat describe what you're looking for.\n\n> [!NOTE]\n> The tool descriptions provided above are examples and may need to be customized for your specific use case. Consider\n> adjusting the descriptions to better match your team's workflow and the specific types of code snippets you want to\n> store and retrieve.\n\n**If you have successfully installed the `mcp-server-qdrant`, but still can't get it to work with Cursor, please\nconsider creating the [Cursor rules](https://docs.cursor.com/context/rules-for-ai) so the MCP tools are always used when\nthe agent produces a new code snippet.** You can restrict the rules to only work for certain file types, to avoid using\nthe MCP server for the documentation or other types of content.\n\n### Using with Claude Code\n\nYou can enhance Claude Code's capabilities by connecting it to this MCP server, enabling semantic search over your\nexisting codebase.\n\n#### Setting up mcp-server-qdrant\n\n1. Add the MCP server to Claude Code:\n\n    ```shell\n    # Add mcp-server-qdrant configured for code search\n    claude mcp add code-search \\\n    -e QDRANT_URL=\"http://localhost:6333\" \\\n    -e COLLECTION_NAME=\"code-repository\" \\\n    -e EMBEDDING_MODEL=\"sentence-transformers/all-MiniLM-L6-v2\" \\\n    -e TOOL_STORE_DESCRIPTION=\"Store code snippets with descriptions. The 'information' parameter should contain a natural language description of what the code does, while the actual code should be included in the 'metadata' parameter as a 'code' property.\" \\\n    -e TOOL_FIND_DESCRIPTION=\"Search for relevant code snippets using natural language. The 'query' parameter should describe the functionality you're looking for.\" \\\n    -- uvx mcp-server-qdrant\n    ```\n\n2. Verify the server was added:\n\n    ```shell\n    claude mcp list\n    ```\n\n#### Using Semantic Code Search in Claude Code\n\nTool descriptions, specified in `TOOL_STORE_DESCRIPTION` and `TOOL_FIND_DESCRIPTION`, guide Claude Code on how to use\nthe MCP server. The ones provided above are examples and may need to be customized for your specific use case. However,\nClaude Code should be already able to:\n\n1. Use the `qdrant-store` tool to store code snippets with descriptions.\n2. Use the `qdrant-find` tool to search for relevant code snippets using natural language.\n\n### Run MCP server in Development Mode\n\nThe MCP server can be run in development mode using the `mcp dev` command. This will start the server and open the MCP\ninspector in your browser.\n\n```shell\nCOLLECTION_NAME=mcp-dev fastmcp dev src/mcp_server_qdrant/server.py\n```\n\n### Using with VS Code\n\nFor one-click installation, click one of the install buttons below:\n\n[![Install with UVX in VS Code](https://img.shields.io/badge/VS_Code-UVX-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=qdrant&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22mcp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDRANT_URL%22%3A%22%24%7Binput%3AqdrantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24%7Binput%3AqdrantApiKey%7D%22%2C%22COLLECTION_NAME%22%3A%22%24%7Binput%3AcollectionName%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantUrl%22%2C%22description%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantApiKey%22%2C%22description%22%3A%22Qdrant+API+Key%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22collectionName%22%2C%22description%22%3A%22Collection+Name%22%7D%5D) [![Install with UVX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-UVX-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=qdrant&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22mcp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDRANT_URL%22%3A%22%24%7Binput%3AqdrantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24%7Binput%3AqdrantApiKey%7D%22%2C%22COLLECTION_NAME%22%3A%22%24%7Binput%3AcollectionName%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantUrl%22%2C%22description%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantApiKey%22%2C%22description%22%3A%22Qdrant+API+Key%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22collectionName%22%2C%22description%22%3A%22Collection+Name%22%7D%5D&quality=insiders)\n\n[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Docker-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=qdrant&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-p%22%2C%228000%3A8000%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22QDRANT_URL%22%2C%22-e%22%2C%22QDRANT_API_KEY%22%2C%22-e%22%2C%22COLLECTION_NAME%22%2C%22mcp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDRANT_URL%22%3A%22%24%7Binput%3AqdrantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24%7Binput%3AqdrantApiKey%7D%22%2C%22COLLECTION_NAME%22%3A%22%24%7Binput%3AcollectionName%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantUrl%22%2C%22description%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantApiKey%22%2C%22description%22%3A%22Qdrant+API+Key%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22collectionName%22%2C%22description%22%3A%22Collection+Name%22%7D%5D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Docker-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=qdrant&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-p%22%2C%228000%3A8000%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22QDRANT_URL%22%2C%22-e%22%2C%22QDRANT_API_KEY%22%2C%22-e%22%2C%22COLLECTION_NAME%22%2C%22mcp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDRANT_URL%22%3A%22%24%7Binput%3AqdrantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24%7Binput%3AqdrantApiKey%7D%22%2C%22COLLECTION_NAME%22%3A%22%24%7Binput%3AcollectionName%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantUrl%22%2C%22description%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantApiKey%22%2C%22description%22%3A%22Qdrant+API+Key%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22collectionName%22%2C%22description%22%3A%22Collection+Name%22%7D%5D&quality=insiders)\n\n#### Manual Installation\n\nAdd the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"qdrantUrl\",\n        \"description\": \"Qdrant URL\"\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"qdrantApiKey\",\n        \"description\": \"Qdrant API Key\",\n        \"password\": true\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"collectionName\",\n        \"description\": \"Collection Name\"\n      }\n    ],\n    \"servers\": {\n      \"qdrant\": {\n        \"command\": \"uvx\",\n        \"args\": [\"mcp-server-qdrant\"],\n        \"env\": {\n          \"QDRANT_URL\": \"${input:qdrantUrl}\",\n          \"QDRANT_API_KEY\": \"${input:qdrantApiKey}\",\n          \"COLLECTION_NAME\": \"${input:collectionName}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOr if you prefer using Docker, add this configuration instead:\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"qdrantUrl\",\n        \"description\": \"Qdrant URL\"\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"qdrantApiKey\",\n        \"description\": \"Qdrant API Key\",\n        \"password\": true\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"collectionName\",\n        \"description\": \"Collection Name\"\n      }\n    ],\n    \"servers\": {\n      \"qdrant\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"-p\", \"8000:8000\",\n          \"-i\",\n          \"--rm\",\n          \"-e\", \"QDRANT_URL\",\n          \"-e\", \"QDRANT_API_KEY\",\n          \"-e\", \"COLLECTION_NAME\",\n          \"mcp-server-qdrant\"\n        ],\n        \"env\": {\n          \"QDRANT_URL\": \"${input:qdrantUrl}\",\n          \"QDRANT_API_KEY\": \"${input:qdrantApiKey}\",\n          \"COLLECTION_NAME\": \"${input:collectionName}\"\n        }\n      }\n    }\n  }\n}\n```\n\nAlternatively, you can create a `.vscode/mcp.json` file in your workspace with the following content:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"qdrantUrl\",\n      \"description\": \"Qdrant URL\"\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"qdrantApiKey\",\n      \"description\": \"Qdrant API Key\",\n      \"password\": true\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"collectionName\",\n      \"description\": \"Collection Name\"\n    }\n  ],\n  \"servers\": {\n    \"qdrant\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-qdrant\"],\n      \"env\": {\n        \"QDRANT_URL\": \"${input:qdrantUrl}\",\n        \"QDRANT_API_KEY\": \"${input:qdrantApiKey}\",\n        \"COLLECTION_NAME\": \"${input:collectionName}\"\n      }\n    }\n  }\n}\n```\n\nFor workspace configuration with Docker, use this in `.vscode/mcp.json`:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"qdrantUrl\",\n      \"description\": \"Qdrant URL\"\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"qdrantApiKey\",\n      \"description\": \"Qdrant API Key\",\n      \"password\": true\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"collectionName\",\n      \"description\": \"Collection Name\"\n    }\n  ],\n  \"servers\": {\n    \"qdrant\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-p\", \"8000:8000\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"QDRANT_URL\",\n        \"-e\", \"QDRANT_API_KEY\",\n        \"-e\", \"COLLECTION_NAME\",\n        \"mcp-server-qdrant\"\n      ],\n      \"env\": {\n        \"QDRANT_URL\": \"${input:qdrantUrl}\",\n        \"QDRANT_API_KEY\": \"${input:qdrantApiKey}\",\n        \"COLLECTION_NAME\": \"${input:collectionName}\"\n      }\n    }\n  }\n}\n```\n\n## Contributing\n\nIf you have suggestions for how mcp-server-qdrant could be improved, or want to report a bug, open an issue!\nWe'd love all and any contributions.\n\n### Testing `mcp-server-qdrant` locally\n\nThe [MCP inspector](https://github.com/modelcontextprotocol/inspector) is a developer tool for testing and debugging MCP\nservers. It runs both a client UI (default port 5173) and an MCP proxy server (default port 3000). Open the client UI in\nyour browser to use the inspector.\n\n```shell\nQDRANT_URL=\":memory:\" COLLECTION_NAME=\"test\" \\\nfastmcp dev src/mcp_server_qdrant/server.py\n```\n\nOnce started, open your browser to http://localhost:5173 to access the inspector interface.\n\n## License\n\nThis MCP server is licensed under the Apache License 2.0. This means you are free to use, modify, and distribute the\nsoftware, subject to the terms and conditions of the Apache License 2.0. For more details, please see the LICENSE file\nin the project repository.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "salesforcecli--mcp": {
          "owner": "salesforcecli",
          "name": "mcp",
          "url": "https://github.com/salesforcecli/mcp",
          "imageUrl": "https://github.com/salesforcecli.png",
          "description": "Official Salesforce DX MCP server enabling secure, natural language-driven interaction with Salesforce orgs through LLMs. Built with enhanced security using TypeScript libraries, encrypted authentication, and granular access control. Supports comprehensive Salesforce development workflows including metadata operations, data management, and org administration.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:45.433434",
          "collection_timestamp": "2025-10-02T15:01:45.410731",
          "stars": 170,
          "forks": 47,
          "license": "Apache License 2.0",
          "language": "TypeScript",
          "created_at": "2025-04-23T21:13:40Z",
          "updated_at": "2025-10-02T07:51:21Z",
          "open_issues": 20,
          "readme_content": "# mcp\n\nMCP Server for Interacting with Salesforce Orgs\n\n[![NPM](https://img.shields.io/npm/v/@salesforce/mcp.svg?label=@salesforce/mcp)](https://www.npmjs.com/package/@salesforce/mcp) [![License](https://img.shields.io/badge/License-Apache--2.0-blue.svg)](https://opensource.org/license/apache-2-0)\n\n## Feedback\n\nReport bugs and issues [here](https://github.com/forcedotcom/mcp/issues).  \nFor feature requests and other related topics, start a Discussion [here](https://github.com/forcedotcom/mcp/discussions).  \n\n## Documentation\n\nFor complete documentation about the Salesforce DX MCP Server, see [this section](https://developer.salesforce.com/docs/atlas.en-us.sfdx_dev.meta/sfdx_dev/sfdx_dev_mcp.htm) in the _Salesforce DX Developer Guide_. The docs include:\n\n* Comprehensive overview, including details about the security features.\n* Quick start guide.\n* Multiple examples of configuring the server in your MCP client.\n* Sample prompts for invoking the core DX MCP tools.\n\n[Here are the release notes.](https://github.com/forcedotcom/mcp/tree/main/releasenotes)\n\n## Overview of the Salesforce DX MCP Server (Beta)\n\nThe Salesforce DX MCP Server is a specialized Model Context Protocol (MCP) implementation designed to facilitate seamless interaction between large language models (LLMs) and Salesforce orgs. This MCP server provides a robust set of tools and capabilities that enable LLMs to read, manage, and operate Salesforce resources securely.\n\n> [!NOTE]\n> _Salesforce DX MCP Server is a pilot or beta service that is subject to the Beta Services Terms at [Agreements - Salesforce.com](https://www.salesforce.com/company/legal/) or a written Unified Pilot Agreement if executed by Customer, and applicable terms in the [Product Terms Directory](https://ptd.salesforce.com/). Use of this pilot or beta service is at the Customer's sole discretion._\n\n## Configure the DX MCP Server\n\nConfigure the Salesforce DX MCP Server for your MCP client by updating its associated MCP JSON file; each client is slightly different, so check your MCP client documentation for details. \n\nHere's an example for VS Code with Copilot in which you create and update a `.vscode/mcp.json` file in your project:\n\n```\n{\n     \"servers\": {\n       \"Salesforce DX\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"@salesforce/mcp\", \n         \"--orgs\", \"DEFAULT_TARGET_ORG\", \n         \"--toolsets\", \"orgs,metadata,data,users\",\n         \"--tools\", \"run_apex_tests\",\n         \"--allow-non-ga-tools\"]\n       }\n     }\n}\n```\nThe `args` format shown in the preceding example is the same for all MCP clients; it's how you customize the DX MCP Server for your particular environment. Notes:\n\n- The `\"-y\", \"@salesforce/mcp\"` part tells `npx` to automatically install the `@salesforce/mcp` package instead of asking permission. Don't change this. \n- See the *Reference* sections below for the possible flags you can pass the `args` option, and possible values you can pass to the `--orgs`, `--toolsets`, and `--tools` flags. \n- When writing the `args` option, surround both the flag names and their values in double quotes, and separate all flags and values with commas. Some flags are Boolean and don't take a value.\n- The preceding example shows three flags that take a string value (`--orgs`, `--toolsets`, and `--tools`) and one Boolean flag (`--allow-non-ga-tools`).  This configuration starts a DX MCP Server that enables all the MCP tools in the `orgs`, `metadata`, `data`, and `users` toolsets and a specific tool called `run_apex_tests`.  It also enables tools in these configured toolsets that aren't yet generally available. \n\n<details>\n<summary>Reference: Available Flags for the `args` Option</summary>\n\n## Reference: Available Flags for the \"args\" Option\n\nThese are the flags that you can pass to the `args` option. \n\n| Flag Name | Description | Required? |Notes |\n| -----------------| -------| ------- | ----- |\n| `--orgs` | One or more orgs that you've locally authorized. | Yes | You must specify at least one org. <br/> <br/>See [Configure Orgs](README.md#configure-orgs) for the values you can pass to this flag. |\n| `--toolsets` | Sets of tools, based on functionality, that you want to enable. | No | Set to \"all\" to enable every tool in every toolset. <br/> <br/>See [Configure Toolsets](README.md#configure-toolsets) for the values you can pass to this flag.|\n| `--tools` | Individual tool names that you want to enable. | No | You can use this flag in combination with the `--toolsets` flag. For example, you can enable all tools in one toolset, and just one tool in a different toolset. |\n| `--no-telemetry` | Boolean flag to disable telemetry, the automatic collection of data for monitoring and analysis. | No | Telemetry is enabled by default, so specify this flag to disable it.  |\n| `--debug` | Boolean flag that requests that the DX MCP Server print debug logs. | No | Debug mode is disabled by default. <br/> <br/>**NOTE:** Not all MCP clients expose MCP logs, so this flag might not work for all IDEs. |\n| `--allow-non-ga-tools` | Boolean flag to allow the DX MCP Server to use both the generally available (GA) and NON-GA tools that are in the toolsets or tools you specify. | No | By default, the DX MCP server uses only the tools marked GA. |\n| `--dynamic-tools` | (experimental) Boolean flag that enables dynamic tool discovery and loading. When specified, the DX MCP server starts with a minimal set of core tools and loads new tools as needed. | No| This flag is useful for reducing the initial context size and improving LLM performance. Dynamic tool discovery is disabled by default.<br/> <br/>**NOTE:** This feature works in VSCode and Cline but may not work in other environments.|\n\n</details>\n<details>\n\n<summary>Reference: Configure Orgs</summary>\n\n## Configure Orgs\n\nThe Salesforce MCP tools require an org, and so you must include the required `--orgs` flag to specify at least one authorized org when you configure the MCP server. Separate multiple values with commas.\n\nYou must explicitly [authorize the orgs](https://developer.salesforce.com/docs/atlas.en-us.sfdx_dev.meta/sfdx_dev/sfdx_dev_auth_web_flow.htm) on your computer before the MCP server can access them. Use the `org login web` Salesforce CLI command or the VS Code **SFDX: Authorize an Org** command from the command palette.\n\nThese are the available values for the `--orgs` flag:\n\n| --orgs Value | Description |\n| -------- | ---------- |\n| `DEFAULT_TARGET_ORG` | Allow access to your default org. If you've set a local default org in your DX project, the MCP server uses it. If not, the server uses a globally-set default org.|\n| `DEFAULT_TARGET_DEV_HUB` | Allow access to your default Dev Hub org. If you've set a local default Dev Hub org in your DX project, the MCP server uses it. If not, the server uses a globally-set default Dev Hub org.|\n| `ALLOW_ALL_ORGS` | Allow access to all authorized orgs. Use this value with caution.|\n| `<username or alias>` | Allow access to a specific org by specifying its username or alias.|\n\n</details>\n\n<details>\n<summary>Reference: Configure Toolsets and Tools</summary>\n\n## Configure Toolsets\n\nThe Salesforce DX MCP Server supports **toolsets** - a way to selectively enable different groups of MCP tools based on your needs. This allows you to run the MCP server with only the tools you require, which in turn reduces the context.\n\nUse the `--toolsets` flag to specify the toolsets when you configure the Salesforce DX MCP Server. Separate multiple toolsets with commas. \n\nThese are the available toolsets.\n\n| Toolset| Description|\n| ----- | ----- |\n| `all` | Enables all available tools from all toolsets. Use caution, this will load over 60 tools. |\n| `orgs` | [Tools to manage your authorized orgs.](README.md#orgs-toolset)|\n| `data` | [Tools to manage the data in your org, such as listing all accounts.](README.md#data-toolset)|\n| `users` | [Tools to manage org users, such as assigning a permission set.](README.md#users-toolset)|\n| `metadata` | [Tools to deploy and retrieve metadata to and from your org and your DX project.](README.md#metadata-toolset)|\n| `testing` | [Tools to test your code and features](README.md#testing-toolset)|\n| `other` | [Other useful tools, such as tools for static analysis of your code using Salesforce Code Analyzer.](README.md#other-toolset)|\n| `mobile` | [Tools for mobile development and capabilities.](README.md#mobile-toolset)|\n| `mobile-core` | [A subset of mobile tools focused on essential mobile capabilities.](README.md#mobile-core-toolset)|\n| `aura-experts` | [Tools which provides Aura component analysis, blueprinting, and migration expertise.](README.md#aura-experts-toolset)|\n| `lwc-experts`  | [Tools to assist with LWC development, testing, optimization, and best practices.](README.md#lwc-experts-toolset)|\n\n## Configure Tools\n\nThe Salesforce DX MCP Server also supports registering individual **tools**. This can be used in combination with **toolsets** to further fine-tune registered tools.\n\nUse the `--tools` flag to enable specific tools when you configure the Salesforce DX MCP Server. Separate multiple tools with commas. The `--tools` flag is optional.\n\nThe following sections list all the tools that are included in a specific toolset. The tools marked NON-GA are not yet generally available, specify the `--allow-non-ga-tools` flag to use them. \n\n### Core Toolset (always enabled)\n\n- `get_username` - Determines the appropriate username or alias for Salesforce operations, handling both default orgs and Dev Hubs.\n- `resume_tool_operation` - Resumes a long-running operation that wasn't completed by another tool.\n\n### Orgs Toolset\n\n- `list_all_orgs` - Lists all configured Salesforce orgs, with optional connection status checking.\n- `create_org_snapshot` - (NON-GA) Create a scratch org snapshot. \n- `create_scratch_org` - (NON-GA) Create a scratch org. \n- `delete_org` - (NON-GA) Delete a locally-authorized Salesforce scratch org or sandbox.\n- `org_open` - (NON-GA) Open an org in a browser. \n\n**NOTE:** The tools marked NON-GA are not yet generally available, specify the `--allow-non-ga-tools` flag to use them. \n\n### Data Toolset\n\n- `run_soql_query` - Runs a SOQL query against a Salesforce org.\n\n### Users Toolset\n\n- `assign_permission_set` - Assigns a permission set to the user or on behalf of another user.\n\n### Metadata Toolset\n\n- `deploy_metadata` - Deploys metadata from your DX project to an org.\n- `retrieve_metadata` - Retrieves metadata from your org to your DX project.\n\n### Testing Toolset\n\n- `run_agent_test` - Executes agent tests in your org.\n- `run_apex_test` - Executes apex tests in your org.\n\n### Mobile Toolset\n\n- `create_mobile_lwc_app_review` - Provides TypeScript API documentation for Salesforce LWC App Review Service, offering expert guidance for implementing app review features in Lightning Web Components.\n- `create_mobile_lwc_ar_space_capture` - Provides TypeScript API documentation for Salesforce L    WC AR Space Capture, offering expert guidance for implementing AR space capture features in Lightning Web Components.\n- `create_mobile_lwc_barcode_scanner` - Provides TypeScript API documentation for Salesforce LWC Barcode Scanner, offering expert guidance for implementing barcode scanning features in Lightning Web Components.\n- `create_mobile_lwc_biometrics` - Provides TypeScript API documentation for Salesforce LWC Biometrics Service, offering expert guidance for implementing biometric authentication features in Lightning Web Components.\n- `create_mobile_lwc_calendar` - Provides TypeScript API documentation for Salesforce LWC Calendar Service, offering expert guidance for implementing calendar integration features in Lightning Web Components.\n- `create_mobile_lwc_contacts` - Provides TypeScript API documentation for Salesforce LWC Contacts Service, offering expert guidance for implementing contacts management features in Lightning Web Components.\n- `create_mobile_lwc_document_scanner` - Provides TypeScript API documentation for Salesforce LWC Document Scanner, offering expert guidance for implementing document scanning features in Lightning Web Components.\n- `create_mobile_lwc_geofencing` - Provides TypeScript API documentation for Salesforce LWC Geofencing Service, offering expert guidance for implementing geofencing features in Lightning Web Components.\n- `create_mobile_lwc_location` - Provides TypeScript API documentation for Salesforce LWC Location Service, offering expert guidance for implementing location services in Lightning Web Components.\n- `create_mobile_lwc_nfc` - Provides TypeScript API documentation for Salesforce LWC NFC Service, offering expert guidance for implementing NFC features in Lightning Web Components.\n- `create_mobile_lwc_payments` - Provides TypeScript API documentation for Salesforce LWC Payments Service, offering expert guidance for implementing payment processing features in Lightning Web Components.\n- `get_mobile_lwc_offline_analysis` - Analyzes Lightning Web Components for mobile-specific issues and provides detailed recommendations for mobile offline compatibility and performance improvements.\n- `get_mobile_lwc_offline_guidance` - Provides structured review instructions to detect and remediate mobile offline code violations in Lightning Web Components for Salesforce Mobile Apps.\n\n### Mobile-core Toolset\n\n- `create_mobile_lwc_barcode_scanner` - Provides TypeScript API documentation for Salesforce LWC Barcode Scanner, offering expert guidance for implementing barcode scanning features in Lightning Web Components.\n- `create_mobile_lwc_biometrics` - Provides TypeScript API documentation for Salesforce LWC Biometrics Service, offering expert guidance for implementing biometric authentication features in Lightning Web Components.\n- `create_mobile_lwc_location` - Provides TypeScript API documentation for Salesforce LWC Location Service, offering expert guidance for implementing location services in Lightning Web Components.\n- `get_mobile_lwc_offline_analysis` - Analyzes Lightning Web Components for mobile-specific issues and provides detailed recommendations for mobile offline compatibility and performance improvements.\n- `get_mobile_lwc_offline_guidance` - Provides structured review instructions to detect and remediate mobile offline code violations in Lightning Web Components for Salesforce Mobile Apps.\n\n### Aura Experts Toolset\n\n - `create_aura_blueprint_draft` - (GA)\nCreates a comprehensive Product Requirements Document (PRD) blueprint for Aura component migration. Analyzes Aura component files and generates framework-agnostic specifications suitable for LWC migration, including business requirements, technical patterns, and migration guidelines.\n\n - `enhance_aura_blueprint_draft` - (GA)\nEnhances an existing draft PRD with expert analysis and unknown resolution. Takes a draft blueprint and applies specialized Aura expert knowledge to resolve dependencies, add technical insights, and improve the migration specifications for better LWC implementation guidance.\n\n - `transition_prd_to_lwc` - (GA)\nProvides migration bridge guidance for creating LWC components from Aura specifications. Takes the enhanced PRD and generates specific implementation guidance, platform service mappings, and step-by-step instructions for building the equivalent LWC component.\n\n - `orchestrate_aura_migration` - (GA)\nOrchestrates the complete Aura to LWC migration workflow. Provides end-to-end guidance for the entire migration process, from initial analysis through final implementation, including best practices, tooling recommendations, and quality assurance steps.\n\n### Lwc Experts Toolset\n\n#### Component Development\n\n - `create_lwc_component` - (GA) Creates complete LWC components from PRD specifications with proper structure and best practices\n - `create_lwc_jest_tests` - (GA) Generates comprehensive Jest test suites for LWC components with coverage and mocking\n - `review_lwc_jest_tests` - (GA) Reviews and validates Jest test implementations for LWC components\n\n#### Development Guidelines\n\n - `guide_lwc_accessibility` - (GA) Provides accessibility guidelines and testing instructions for LWC components\n - `guide_lwc_best_practices` - (GA) Offers LWC development best practices and coding standards guidance\n - `guide_lwc_development` - (GA) Comprehensive LWC development workflow and implementation guidelines\n - `guide_lwc_rtl_support` - (GA) Right-to-Left internationalization support and RTL development guidance\n - `guide_lwc_slds2_uplift_linter_fixes` - (GA) Analyzes the given LWC code along with the slds-linter output to fix issues using the SLDS2 knowledge\n - `guide_lwc_security` - (GA) Comprehensive security analysis in accordance with Product Security Guidelines and Lightning Web Security Guidelines\n\n#### Workflow Tools\n\n - `orchestrate_lwc_component_creation` - (GA) Step-by-step component creation workflow guidance\n - `orchestrate_lwc_component_optimization` - (GA)  Performance optimization and best practices for LWC components\n - `orchestrate_lwc_component_testing` - (GA) Comprehensive testing workflow and test generation guidance\n - `orchestrate_lwc_slds2_uplift` - (GA) Migration guidance for upgrading to SLDS2 design system\n\n#### LDS (Lightning Design System) Tools\n\n - `explore_lds_uiapi` - (GA) Explores and documents Lightning Design System UI API capabilities\n - `guide_lds_data_consistency` - (GA) Data consistency patterns and best practices for LDS components\n - `guide_lds_development` - (GA) LDS development guidelines and component integration\n - `guide_lds_referential_integrity` - (GA) Referential integrity patterns for LDS data management\n - `orchestrate_lds_data_requirements` - (GA) Step-by-step guidance for analyzing and clarifying LDS data requirements to produce PRD-ready specifications.\n\n#### Migration & Integration Tools\n\n - `verify_aura_migration_completeness` - (GA) Aura to LWC migration completeness checklist and validation\n - `guide_figma_to_lwc_conversion` - (GA) Converts Figma designs to LWC component specifications\n - `run_lwc_accessibility_jest_tests` - (GA) Accessibility testing utilities and Jest integration for LWC components\n\n### Code-Analysis Toolset\n\n- `run_code_analyzer` - (NON-GA) Performs a static analysis of your code using Salesforce Code Analyzer. Includes validating that the code conforms to best practices, checking for security vulnerabilities, and identifying possible performance issues.\n- `describe_code_analyzer_rule` - (NON-GA) Gets the description of a Salesforce Code Analyzer rule, including the engine it belongs to, its severity, and associated tags.\n\n</details>\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp",
          "npm_downloads": 17508,
          "npm_package_name": "mcp",
          "npm_success": true,
          "npm_error": null
        },
        "screenshotone--mcp": {
          "owner": "screenshotone",
          "name": "mcp",
          "url": "https://github.com/screenshotone/mcp",
          "imageUrl": "https://github.com/screenshotone.png",
          "description": "Render website screenshots and obtain them as images to integrate screenshot capabilities into applications. Capture and utilize website visuals effortlessly through a powerful API.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:46.875722",
          "collection_timestamp": "2025-10-02T15:01:47.534163",
          "stars": 31,
          "forks": 14,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-02-17T09:18:20Z",
          "updated_at": "2025-09-17T13:41:30Z",
          "open_issues": 0,
          "readme_content": "# ScreenshotOne MCP Server\n\nAn official implementation of an [MCP (Model Context Protocol)](https://modelcontextprotocol.io/) server for [ScreenshotOne](https://screenshotone.com).\n\n[A few more words about why it was built and some thoughts about the future of MCP](https://screenshotone.com/blog/mcp-server/).\n\n<a href=\"https://glama.ai/mcp/servers/nq85q0596a\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/nq85q0596a/badge\" alt=\"ScreenshotOne Server MCP server\" />\n</a>\n\n## Tools\n\n-   `render-website-screenshot`: Render a screenshot of a website and returns it as an image.\n\n## Usage\n\n### Build it\n\nAlways install dependencies and build it first:\n\n```bash\nnpm install && npm run build\n```\n\n### Get your ScreenshotOne API key\n\nSign up at [ScreenshotOne](https://screenshotone.com) and get your API key.\n\n### With Claude for Desktop\n\nAdd the following to your `~/Library/Application\\ Support/Claude/claude_desktop_config.json`:\n\n```json\n{\n    \"mcpServers\": {\n        \"screenshotone\": {\n            \"command\": \"node\",\n            \"args\": [\"path/to/screenshotone/mcp/build/index.js\"],\n            \"env\": {\n                \"SCREENSHOTONE_API_KEY\": \"<your api key>\"\n            }\n        }\n    }\n}\n```\n\n### Standalone or for other projects\n\n```bash\nSCREENSHOTONE_API_KEY=your_api_key && node build/index.js\n```\n\n## License\n\n`ScreenshotOne MCP Server` is licensed [under the MIT License](LICENSE).\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp",
          "npm_downloads": 17508,
          "npm_package_name": "mcp",
          "npm_success": true,
          "npm_error": null
        },
        "semgrep--mcp": {
          "owner": "semgrep",
          "name": "mcp",
          "url": "https://github.com/semgrep/mcp",
          "imageUrl": "https://github.com/semgrep.png",
          "description": "Scan code for security vulnerabilities and create custom rules with Semgrep. It provides an interface for advanced code analysis and security enhancements.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:48.078563",
          "collection_timestamp": "2025-10-02T15:01:49.918954",
          "stars": 581,
          "forks": 51,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-17T20:08:14Z",
          "updated_at": "2025-10-02T06:30:24Z",
          "open_issues": 30,
          "readme_content": "## **‚ö†Ô∏è The Semgrep MCP server has been moved from a standalone repo to the [main `semgrep` repository!](https://github.com/semgrep/semgrep) ‚ö†Ô∏è**\n**This repository has been deprecated, and further updates to the Semgrep MCP server will be made via the official `semgrep` binary.**\n\n<p align=\"center\">\n  <a href=\"https://semgrep.dev\">\n    <picture>\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"images/semgrep-logo-light.svg\">\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"images/semgrep-logo-dark.svg\">\n      <img src=\"https://raw.githubusercontent.com/semgrep/mcp/main/images/semgrep-logo-light.svg\" height=\"60\" alt=\"Semgrep logo\"/>\n    </picture>\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://semgrep.dev/docs/\">\n      <img src=\"https://img.shields.io/badge/Semgrep-docs-2acfa6?style=flat-square\" alt=\"Documentation\" />\n  </a>\n  <a href=\"https://go.semgrep.dev/slack\">\n    <img src=\"https://img.shields.io/badge/Slack-4.5k%20-4A154B?style=flat-square&logo=slack&logoColor=white\" alt=\"Join Semgrep community Slack\" />\n  </a>\n  <a href=\"https://www.linkedin.com/company/semgrep/\">\n    <img src=\"https://img.shields.io/badge/LinkedIn-follow-0a66c2?style=flat-square\" alt=\"Follow on LinkedIn\" />\n  </a>\n  <a href=\"https://x.com/intent/follow?screen_name=semgrep\">\n    <img src=\"https://img.shields.io/badge/semgrep-000000?style=flat-square&logo=x&logoColor=white?style=flat-square\" alt=\"Follow @semgrep on X\" />\n  </a>\n</p>\n\n# Semgrep MCP Server\n[![Add MCP Server semgrep to LM Studio](https://files.lmstudio.ai/deeplink/mcp-install-light.svg)](https://lmstudio.ai/install-mcp?name=semgrep&config=eyJ1cmwiOiJodHRwczovL21jcC5zZW1ncmVwLmFpL21jcCIsImhlYWRlcnMiOnsiQXV0aG9yaXphdGlvbiI6IkJlYXJlciA8WU9VUl9IRl9UT0tFTj4ifX0%3D)\n[![Install in Cursor](https://img.shields.io/badge/Cursor-uv-0098FF?style=flat-square)](cursor://anysphere.cursor-deeplink/mcp/install?name=semgrep&config=eyJjb21tYW5kIjoidXZ4IiwiYXJncyI6WyJzZW1ncmVwLW1jcCJdfQ==)\n[![Install in VS Code UV](https://img.shields.io/badge/VS_Code-uv-0098FF?style=flat-square&logo=githubcopilot&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=semgrep&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22semgrep-mcp%22%5D%7D)\n[![Install in VS Code Docker](https://img.shields.io/badge/VS_Code-docker-0098FF?style=flat-square&logo=githubcopilot&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=semgrep&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%20%22-i%22%2C%20%22--rm%22%2C%20%22ghcr.io%2Fsemgrep%2Fmcp%22%2C%20%22-t%22%2C%20%22stdio%22%5D%7D)\n[![Install in VS Code semgrep.ai](https://img.shields.io/badge/VS_Code-semgrep.ai-0098FF?style=flat-square&logo=githubcopilot&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=semgrep.ai&config=%7B%22type%22%3A%20%22sse%22%2C%20%22url%22%3A%22https%3A%2F%2Fmcp.semgrep.ai%2Fsse%22%7D)\n[![PyPI](https://img.shields.io/pypi/v/semgrep-mcp?style=flat-square&color=blue&logo=python&logoColor=white)](https://pypi.org/project/semgrep-mcp/)\n[![Docker](https://img.shields.io/badge/docker-ghcr.io%2Fsemgrep%2Fmcp-0098FF?style=flat-square&logo=docker&logoColor=white)](https://ghcr.io/semgrep/mcp)\n[![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-uv-24bfa5?style=flat-square&logo=githubcopilot&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=semgrep&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22semgrep-mcp%22%5D%7D&quality=insiders)\n[![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-docker-24bfa5?style=flat-square&logo=githubcopilot&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=semgrep&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%20%22-i%22%2C%20%22--rm%22%2C%20%22ghcr.io%2Fsemgrep%2Fmcp%22%2C%20%22-t%22%2C%20%22stdio%22%5D%7D&quality=insiders)\n\nA Model Context Protocol (MCP) server for using [Semgrep](https://semgrep.dev) to scan code for security vulnerabilities. Secure your [vibe coding](https://semgrep.dev/blog/2025/giving-appsec-a-seat-at-the-vibe-coding-table/)! üòÖ\n\n[Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is a standardized API for LLMs, Agents, and IDEs like Cursor, VS Code, Windsurf, or anything that supports MCP, to get specialized help, get context, and harness the power of tools. Semgrep is a fast, deterministic static analysis tool that semantically understands many [languages](https://semgrep.dev/docs/supported-languages) and comes with over [5,000 rules](https://semgrep.dev/registry). üõ†Ô∏è\n\n> [!NOTE]\n> This beta project is under active development. We would love your feedback, bug reports, feature requests, and code. Join the `#mcp` [community Slack](https://go.semgrep.dev/slack) channel!\n\n## Contents\n\n- [Semgrep MCP Server](#semgrep-mcp-server)\n  - [Contents](#contents)\n  - [Getting started](#getting-started)\n    - [Cursor](#cursor)\n    - [ChatGPT](#chatgpt)\n    - [Hosted Server](#hosted-server)\n      - [Cursor](#cursor-1)\n  - [Demo](#demo)\n  - [API](#api)\n    - [Tools](#tools)\n      - [Scan Code](#scan-code)\n      - [Understand Code](#understand-code)\n      - [Cloud Platform (login and Semgrep token required)](#cloud-platform-login-and-semgrep-token-required)\n      - [Meta](#meta)\n    - [Prompts](#prompts)\n    - [Resources](#resources)\n  - [Usage](#usage)\n    - [Standard Input/Output (stdio)](#standard-inputoutput-stdio)\n      - [Python](#python)\n      - [Docker](#docker)\n    - [Streamable HTTP](#streamable-http)\n      - [Python](#python-1)\n      - [Docker](#docker-1)\n    - [Server-sent events (SSE)](#server-sent-events-sse)\n      - [Python](#python-2)\n      - [Docker](#docker-2)\n  - [Semgrep AppSec Platform](#semgrep-appsec-platform)\n  - [Integrations](#integrations)\n    - [Cursor IDE](#cursor-ide)\n    - [VS Code / Copilot](#vs-code--copilot)\n      - [Manual Configuration](#manual-configuration)\n      - [Using Docker](#using-docker)\n    - [Windsurf](#windsurf)\n    - [Claude Desktop](#claude-desktop)\n    - [Claude Code](#claude-code)\n    - [OpenAI](#openai)\n      - [Agents SDK](#agents-sdk)\n    - [Custom clients](#custom-clients)\n      - [Example Python SSE client](#example-python-sse-client)\n  - [Contributing, community, and running from source](#contributing-community-and-running-from-source)\n    - [Similar tools üîç](#similar-tools-)\n    - [Community projects üåü](#community-projects-)\n    - [MCP server registries](#mcp-server-registries)\n\n## Getting started\n\nRun the [Python package](https://pypi.org/p/semgrep-mcp) as a CLI command using [`uv`](https://docs.astral.sh/uv/guides/tools/):\n\n```bash\nuvx semgrep-mcp # see --help for more options\n```\n\nOr, run as a [Docker container](https://ghcr.io/semgrep/mcp):\n\n```bash\ndocker run -i --rm ghcr.io/semgrep/mcp -t stdio\n```\n\n### Cursor\n\nExample [`mcp.json`](https://docs.cursor.com/context/model-context-protocol)\n\n```json\n{\n  \"mcpServers\": {\n    \"semgrep\": {\n      \"command\": \"uvx\",\n      \"args\": [\"semgrep-mcp\"],\n      \"env\": {\n        \"SEMGREP_APP_TOKEN\": \"<token>\"\n      }\n    }\n  }\n}\n\n```\n\nAdd an instruction to your [`.cursor/rules`](https://docs.cursor.com/context/rules-for-ai) to use automatically:\n\n```text\nAlways scan code generated using Semgrep for security vulnerabilities\n```\n\n### ChatGPT\n\n1. Go to the **Connector Settings** page ([direct link](https://chatgpt.com/admin/ca#settings/ConnectorSettings?create-connector=true))\n1. **Name** the connection `Semgrep`\n1. Set **MCP Server URL** to `https://mcp.semgrep.ai/sse`\n1. Set **Authentication** to `No authentication`\n1. Check the **I trust this application** checkbox\n1. Click **Create**\n\nSee more details at the [official docs](https://platform.openai.com/docs/mcp).\n\n\n### Hosted Server\n\n> [!WARNING]\n> [mcp.semgrep.ai](https://mcp.semgrep.ai) is an experimental server that may break unexpectedly. It will rapidly gain new functionality.üöÄ\n\n#### Cursor\n\n1. **Cmd + Shift + J** to open Cursor Settings\n1. Select **MCP Tools**\n1. Click **New MCP Server**.\n1.\n\n```json\n{\n  \"mcpServers\": {\n    \"semgrep\": {\n      \"type\": \"streamable-http\",\n      \"url\": \"https://mcp.semgrep.ai/mcp\"\n    }\n  }\n}\n```\n\n## Demo\n\n<a href=\"https://www.loom.com/share/8535d72e4cfc4e1eb1e03ea223a702df\"> <img style=\"max-width:300px;\" src=\"https://cdn.loom.com/sessions/thumbnails/8535d72e4cfc4e1eb1e03ea223a702df-1047fabea7261abb-full-play.gif\"> </a>\n\n## API\n\n### Tools\n\nEnable LLMs to perform actions, make deterministic computations, and interact with external services.\n\n#### Scan Code\n\n- `security_check`: Scan code for security vulnerabilities\n- `semgrep_scan`: Scan code files for security vulnerabilities with a given config string\n- `semgrep_scan_with_custom_rule`: Scan code files using a custom Semgrep rule\n\n#### Understand Code\n\n- `get_abstract_syntax_tree`: Output the Abstract Syntax Tree (AST) of code\n\n#### Cloud Platform (login and Semgrep token required)\n- `semgrep_findings`: Fetch Semgrep findings from the Semgrep AppSec Platform API\n\n#### Meta\n\n- `supported_languages`: Return the list of languages Semgrep supports\n- `semgrep_rule_schema`: Fetches the latest semgrep rule JSON Schema\n\n### Prompts\n\nReusable prompts to standardize common LLM interactions.\n\n- `write_custom_semgrep_rule`: Return a prompt to help write a Semgrep rule\n\n### Resources\n\nExpose data and content to LLMs\n\n- `semgrep://rule/schema`: Specification of the Semgrep rule YAML syntax using JSON schema\n- `semgrep://rule/{rule_id}/yaml`: Full Semgrep rule in YAML format from the Semgrep registry\n\n## Usage\n\nThis Python package is published to PyPI as [semgrep-mcp](https://pypi.org/p/semgrep-mcp) and can be installed and run with [pip](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#install-a-package), [pipx](https://pipx.pypa.io/), [uv](https://docs.astral.sh/uv/), [poetry](https://python-poetry.org/), or any Python package manager.\n\n```text\n$ pipx install semgrep-mcp\n$ semgrep-mcp --help\n\nUsage: semgrep-mcp [OPTIONS]\n\n  Entry point for the MCP server\n\n  Supports both stdio and sse transports. For stdio, it will read from stdin\n  and write to stdout. For sse, it will start an HTTP server on port 8000.\n\nOptions:\n  -v, --version                Show version and exit.\n  -t, --transport [stdio|sse]  Transport protocol to use (stdio or sse)\n  -h, --help                   Show this message and exit.\n```\n\n### Standard Input/Output (stdio)\n\nThe stdio transport enables communication through standard input and output streams. This is particularly useful for local integrations and command-line tools. See the [spec](https://modelcontextprotocol.io/docs/concepts/transports#built-in-transport-types) for more details.\n\n#### Python\n\n```bash\nsemgrep-mcp\n```\n\nBy default, the Python package will run in `stdio` mode. Because it's using the standard input and output streams, it will look like the tool is hanging without any output, but this is expected.\n\n#### Docker\n\nThis server is published to Github's Container Registry ([ghcr.io/semgrep/mcp](http://ghcr.io/semgrep/mcp))\n\n```\ndocker run -i --rm ghcr.io/semgrep/mcp -t stdio\n```\n\nBy default, the Docker container is in `SSE` mode, so you will have to include `-t stdio` after the image name and run with `-i` to run in [interactive](https://docs.docker.com/reference/cli/docker/container/run/#interactive) mode.\n\n### Streamable HTTP\n\nStreamable HTTP enables streaming responses over JSON RPC via HTTP POST requests. See the [spec](https://modelcontextprotocol.io/specification/draft/basic/transports#streamable-http) for more details.\n\nBy default, the server listens on [127.0.0.1:8000/mcp](https://127.0.0.1/mcp) for client connections. To change any of this, set [FASTMCP\\_\\*](https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/server/fastmcp/server.py#L78) environment variables. _The server must be running for clients to connect to it._\n\n#### Python\n\n```bash\nsemgrep-mcp -t streamable-http\n```\n\nBy default, the Python package will run in `stdio` mode, so you will have to include `-t streamable-http`.\n\n#### Docker\n\n```\ndocker run -p 8000:0000 ghcr.io/semgrep/mcp\n```\n\n\n### Server-sent events (SSE)\n\n> [!WARNING]\n> The MCP communiity considers this a legacy transport portcol and is really intended for backwards compatibility. [Streamable HTTP](#streamable-http) is the recommended replacement.\n\nSSE transport enables server-to-client streaming with Server-Send Events for client-to-server and server-to-client communication. See the [spec](https://modelcontextprotocol.io/docs/concepts/transports#server-sent-events-sse) for more details.\n\nBy default, the server listens on [127.0.0.1:8000/sse](https://127.0.0.1/sse) for client connections. To change any of this, set [FASTMCP\\_\\*](https://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/server/fastmcp/server.py#L78) environment variables. _The server must be running for clients to connect to it._\n\n#### Python\n\n```bash\nsemgrep-mcp -t sse\n```\n\nBy default, the Python package will run in `stdio` mode, so you will have to include `-t sse`.\n\n#### Docker\n\n```\ndocker run -p 8000:0000 ghcr.io/semgrep/mcp -t sse\n```\n\n## Semgrep AppSec Platform\n\nOptionally, to connect to Semgrep AppSec Platform:\n\n1. [Login](https://semgrep.dev/login/) or sign up\n1. Generate a token from [Settings](https://semgrep.dev/orgs/-/settings/tokens/api)\n1. Add the token to your environment variables:\n   - CLI (`export SEMGREP_APP_TOKEN=<token>`)\n\n   - Docker (`docker run -e SEMGREP_APP_TOKEN=<token>`)\n\n   - MCP config JSON\n\n```json\n    \"env\": {\n      \"SEMGREP_APP_TOKEN\": \"<token>\"\n    }\n```\n\n> [!TIP]\n> Please [reach out for support](https://semgrep.dev/docs/support) if needed. ‚òéÔ∏è\n\n## Integrations\n\n### Cursor IDE\n\nAdd the following JSON block to your `~/.cursor/mcp.json` global or `.cursor/mcp.json` project-specific configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"semgrep\": {\n      \"command\": \"uvx\",\n      \"args\": [\"semgrep-mcp\"]\n    }\n  }\n}\n```\n\n![cursor MCP settings](/images/cursor.png)\n\nSee [cursor docs](https://docs.cursor.com/context/model-context-protocol) for more info.\n\n### VS Code / Copilot\n\nClick the install buttons at the top of this README for the quickest installation.\n\n#### Manual Configuration\n\nAdd the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"semgrep\": {\n        \"command\": \"uvx\",\n        \"args\": [\"semgrep-mcp\"]\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace:\n\n```json\n{\n  \"servers\": {\n    \"semgrep\": {\n      \"command\": \"uvx\",\n        \"args\": [\"semgrep-mcp\"]\n    }\n  }\n}\n```\n\n#### Using Docker\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"semgrep\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"-i\",\n          \"--rm\",\n          \"ghcr.io/semgrep/mcp\",\n          \"-t\",\n          \"stdio\"\n        ]\n      }\n    }\n  }\n}\n```\n\nSee [VS Code docs](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more info.\n\n### Windsurf\n\nAdd the following JSON block to your `~/.codeium/windsurf/mcp_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"semgrep\": {\n      \"command\": \"uvx\",\n      \"args\": [\"semgrep-mcp\"]\n    }\n  }\n}\n```\n\nSee [Windsurf docs](https://docs.windsurf.com/windsurf/mcp) for more info.\n\n### Claude Desktop\n\nHere is a [short video](https://www.loom.com/share/f4440cbbb5a24149ac17cc7ddcd95cfa) showing Claude Desktop using this server to write a custom rule.\n\nAdd the following JSON block to your `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"semgrep\": {\n      \"command\": \"uvx\",\n      \"args\": [\"semgrep-mcp\"]\n    }\n  }\n}\n```\n\nSee [Anthropic docs](https://docs.anthropic.com/en/docs/agents-and-tools/mcp) for more info.\n\n### Claude Code\n\n```bash\nclaude mcp add semgrep uvx semgrep-mcp\n```\n\nSee [Claude Code docs](https://docs.anthropic.com/en/docs/claude-code/tutorials#set-up-model-context-protocol-mcp) for more info.\n\n### OpenAI\n\nSee the offical docs:\n- https://platform.openai.com/docs/mcp\n- https://platform.openai.com/docs/guides/tools-remote-mcp\n\n#### Agents SDK\n\n```python\nasync with MCPServerStdio(\n    params={\n        \"command\": \"uvx\",\n        \"args\": [\"semgrep-mcp\"],\n    }\n) as server:\n    tools = await server.list_tools()\n```\n\nSee [OpenAI Agents SDK docs](https://openai.github.io/openai-agents-python/mcp/) for more info.\n\n### Custom clients\n\n#### Example Python SSE client\n\nSee a full example in [examples/sse_client.py](examples/sse_client.py)\n\n```python\nfrom mcp.client.session import ClientSession\nfrom mcp.client.sse import sse_client\n\n\nasync def main():\n    async with sse_client(\"http://localhost:8000/sse\") as (read_stream, write_stream):\n        async with ClientSession(read_stream, write_stream) as session:\n            await session.initialize()\n            results = await session.call_tool(\n                \"semgrep_scan\",\n                {\n                    \"code_files\": [\n                        {\n                            \"path\": \"hello_world.py\",\n                            \"content\": \"def hello(): print('Hello, World!')\",\n                        }\n                    ]\n                },\n            )\n            print(results)\n```\n\n> [!TIP]\n> Some client libraries want the `URL`: [http://localhost:8000/sse](http://localhost:8000/sse)\n> and others only want the `HOST`: `localhost:8000`.\n> Try out the `URL` in a web browser to confirm the server is running, and there are no network issues.\n\nSee [official SDK docs](https://modelcontextprotocol.io/clients#adding-mcp-support-to-your-application) for more info.\n\n## Contributing, community, and running from source\n\n> [!NOTE]\n> We love your feedback, bug reports, feature requests, and code. Join the `#mcp` [community Slack](https://go.semgrep.dev/slack) channel!\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for more info and details on how to run from the MCP server from source code.\n\n### Similar tools üîç\n\n- [semgrep-vscode](https://github.com/semgrep/semgrep-vscode) - Official VS Code extension\n- [semgrep-intellij](https://github.com/semgrep/semgrep-intellij) - IntelliJ plugin\n\n### Community projects üåü\n\n- [semgrep-rules](https://github.com/semgrep/semgrep-rules) - The official collection of Semgrep rules\n- [mcp-server-semgrep](https://github.com/Szowesgad/mcp-server-semgrep) - Original inspiration written by [Szowesgad](https://github.com/Szowesgad) and [stefanskiasan](https://github.com/stefanskiasan)\n\n### MCP server registries\n\n- [Glama](https://glama.ai/mcp/servers/@semgrep/mcp)\n\n<a href=\"https://glama.ai/mcp/servers/@semgrep/mcp\">\n <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/4iqti5mgde/badge\" alt=\"Semgrep Server MCP server\" />\n </a>\n\n- [MCP.so](https://mcp.so/server/mcp/semgrep)\n\n______________________________________________________________________\n\nMade with ‚ù§Ô∏è by the [Semgrep Team](https://semgrep.dev/about/)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp",
          "npm_downloads": 17508,
          "npm_package_name": "mcp",
          "npm_success": true,
          "npm_error": null
        },
        "stripe--agent-toolkit": {
          "owner": "stripe",
          "name": "agent-toolkit",
          "url": "https://github.com/stripe/agent-toolkit",
          "imageUrl": "https://github.com/stripe.png",
          "description": "Integrate with Stripe APIs using function calling to manage customers and products, as well as facilitate interactions with various Stripe services.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:49.311027",
          "collection_timestamp": "2025-10-02T15:01:55.944742",
          "stars": 966,
          "forks": 146,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2024-11-11T17:13:41Z",
          "updated_at": "2025-10-02T09:07:59Z",
          "open_issues": 15,
          "readme_content": "# Stripe Agent Toolkit\n\nThe Stripe Agent Toolkit enables popular agent frameworks including Model Context Protocol (MCP), OpenAI's Agent SDK, LangChain, CrewAI, and Vercel's AI SDK to integrate with Stripe APIs through function calling. The\nlibrary is not exhaustive of the entire Stripe API. It includes support for MCP, Python, and TypeScript and is built directly on top of the Stripe [Python][python-sdk] and [Node][node-sdk] SDKs.\n\nIncluded below are basic instructions, but refer to the [MCP](/modelcontextprotocol) [Python](/python), [TypeScript](/typescript) packages for more information.\n\n## Model Context Protocol\n\nStripe hosts a remote MCP server at `https://mcp.stripe.com`. This allows secure MCP client access via OAuth. View the docs [here](https://docs.stripe.com/mcp#remote).\n\nThe Stripe Agent Toolkit also exposes tools in the [Model Context Protocol (MCP)](https://modelcontextprotocol.com/) format.  Or, to run a local Stripe MCP server using npx, use the following command:\n\n```bash\nnpx -y @stripe/mcp --tools=all --api-key=YOUR_STRIPE_SECRET_KEY\n```\n\n## Python\n\n### Installation\n\nYou don't need this source code unless you want to modify the package. If you just\nwant to use the package run:\n\n```sh\npip install stripe-agent-toolkit\n```\n\n#### Requirements\n\n- Python 3.11+\n\n### Usage\n\nThe library needs to be configured with your account's secret key which is\navailable in your [Stripe Dashboard][api-keys].\n\n```python\nfrom stripe_agent_toolkit.openai.toolkit import StripeAgentToolkit\n\nstripe_agent_toolkit = StripeAgentToolkit(\n    secret_key=\"sk_test_...\",\n    configuration={\n        \"actions\": {\n            \"payment_links\": {\n                \"create\": True,\n            },\n        }\n    },\n)\n```\n\nThe toolkit works with OpenAI's Agent SDK, LangChain, and CrewAI and can be passed as a list of tools. For example:\n\n```python\nfrom agents import Agent\n\nstripe_agent = Agent(\n    name=\"Stripe Agent\",\n    instructions=\"You are an expert at integrating with Stripe\",\n    tools=stripe_agent_toolkit.get_tools()\n)\n```\n\nExamples for OpenAI's Agent SDK,LangChain, and CrewAI are included in [/examples](/python/examples).\n\n#### Context\n\nIn some cases you will want to provide values that serve as defaults when making requests. Currently, the `account` context value enables you to make API calls for your [connected accounts](https://docs.stripe.com/connect/authentication).\n\n```python\nstripe_agent_toolkit = StripeAgentToolkit(\n    secret_key=\"sk_test_...\",\n    configuration={\n        \"context\": {\n            \"account\": \"acct_123\"\n        }\n    }\n)\n```\n\n## TypeScript\n\n### Installation\n\nYou don't need this source code unless you want to modify the package. If you just\nwant to use the package run:\n\n```\nnpm install @stripe/agent-toolkit\n```\n\n#### Requirements\n\n- Node 18+\n\n### Usage\n\nThe library needs to be configured with your account's secret key which is available in your [Stripe Dashboard][api-keys]. Additionally, `configuration` enables you to specify the types of actions that can be taken using the toolkit.\n\n```typescript\nimport { StripeAgentToolkit } from \"@stripe/agent-toolkit/langchain\";\n\nconst stripeAgentToolkit = new StripeAgentToolkit({\n  secretKey: process.env.STRIPE_SECRET_KEY!,\n  configuration: {\n    actions: {\n      paymentLinks: {\n        create: true,\n      },\n    },\n  },\n});\n```\n\n#### Tools\n\nThe toolkit works with LangChain and Vercel's AI SDK and can be passed as a list of tools. For example:\n\n```typescript\nimport { AgentExecutor, createStructuredChatAgent } from \"langchain/agents\";\n\nconst tools = stripeAgentToolkit.getTools();\n\nconst agent = await createStructuredChatAgent({\n  llm,\n  tools,\n  prompt,\n});\n\nconst agentExecutor = new AgentExecutor({\n  agent,\n  tools,\n});\n```\n\n#### Context\n\nIn some cases you will want to provide values that serve as defaults when making requests. Currently, the `account` context value enables you to make API calls for your [connected accounts](https://docs.stripe.com/connect/authentication).\n\n```typescript\nconst stripeAgentToolkit = new StripeAgentToolkit({\n  secretKey: process.env.STRIPE_SECRET_KEY!,\n  configuration: {\n    context: {\n      account: \"acct_123\",\n    },\n  },\n});\n```\n\n#### Metered billing\n\nFor Vercel's AI SDK, you can use middleware to submit billing events for usage. All that is required is the customer ID and the input/output meters to bill.\n\n```typescript\nimport { StripeAgentToolkit } from \"@stripe/agent-toolkit/ai-sdk\";\nimport { openai } from \"@ai-sdk/openai\";\nimport {\n  generateText,\n  experimental_wrapLanguageModel as wrapLanguageModel,\n} from \"ai\";\n\nconst stripeAgentToolkit = new StripeAgentToolkit({\n  secretKey: process.env.STRIPE_SECRET_KEY!,\n  configuration: {\n    actions: {\n      paymentLinks: {\n        create: true,\n      },\n    },\n  },\n});\n\nconst model = wrapLanguageModel({\n  model: openai(\"gpt-4o\"),\n  middleware: stripeAgentToolkit.middleware({\n    billing: {\n      customer: \"cus_123\",\n      meters: {\n        input: \"input_tokens\",\n        output: \"output_tokens\",\n      },\n    },\n  }),\n});\n```\n\n\n\n## Supported API methods\n\n- [Cancel a subscription](https://docs.stripe.com/api/subscriptions/cancel)\n- [Create a coupon](https://docs.stripe.com/api/coupons/create)\n- [Create a customer](https://docs.stripe.com/api/customers/create)\n- [Create a payment link](https://docs.stripe.com/api/payment-link/create)\n- [Create a price](https://docs.stripe.com/api/prices/create)\n- [Create a product](https://docs.stripe.com/api/products/create)\n- [Create a refund](https://docs.stripe.com/api/refunds/create)\n- [Create an invoice item](https://docs.stripe.com/api/invoiceitems/create)\n- [Create an invoice](https://docs.stripe.com/api/invoices/create)\n- [Finalize an invoice](https://docs.stripe.com/api/invoices/finalize)\n- [List all coupons](https://docs.stripe.com/api/coupons/list)\n- [List all customers](https://docs.stripe.com/api/customers/list)\n- [List all disputes](https://docs.stripe.com/api/disputes/list)\n- [List all prices](https://docs.stripe.com/api/prices/list)\n- [List all products](https://docs.stripe.com/api/products/list)\n- [List all subscriptions](https://docs.stripe.com/api/subscriptions/list)\n- [Retrieve balance](https://docs.stripe.com/api/balance/balance_retrieve)\n- [Update a dispute](https://docs.stripe.com/api/disputes/update)\n- [Update a subscription](https://docs.stripe.com/api/subscriptions/update)\n\n[python-sdk]: https://github.com/stripe/stripe-python\n[node-sdk]: https://github.com/stripe/stripe-node\n[api-keys]: https://dashboard.stripe.com/account/apikeys\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/@stripe/agent-toolkit",
          "npm_downloads": 562528,
          "npm_package_name": "@stripe/agent-toolkit",
          "npm_success": true,
          "npm_error": null
        },
        "tavily-ai--tavily-mcp": {
          "owner": "tavily-ai",
          "name": "tavily-mcp",
          "url": "https://github.com/tavily-ai/tavily-mcp",
          "imageUrl": "https://github.com/tavily-ai.png",
          "description": "Enables real-time web search and data extraction capabilities by providing seamless integration with various data sources and tools through the Model Context Protocol.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:50.834903",
          "collection_timestamp": "2025-10-02T15:01:59.849315",
          "stars": 793,
          "forks": 135,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2025-01-27T16:56:37Z",
          "updated_at": "2025-10-01T20:17:53Z",
          "open_issues": 9,
          "readme_content": "# ![Tavily Crawl Beta](./assets/Banner_NEW.png)\n\n\n![GitHub Repo stars](https://img.shields.io/github/stars/tavily-ai/tavily-mcp?style=social)\n![npm](https://img.shields.io/npm/dt/tavily-mcp)\n![smithery badge](https://smithery.ai/badge/@tavily-ai/tavily-mcp)\n\n![MCP demo](./assets/demo_new.gif)\n\nThe Tavily MCP server provides:\n- search, extract, map, crawl tools\n- Real-time web search capabilities through the tavily-search tool\n- Intelligent data extraction from web pages via the tavily-extract tool\n- Powerful web mapping tool that creates a structured map of website \n- Web crawler that systematically explores websites \n\n\n### üìö Helpful Resources\n- [Tutorial](https://medium.com/@dustin_36183/building-a-knowledge-graph-assistant-combining-tavily-and-neo4j-mcp-servers-with-claude-db92de075df9) on combining Tavily MCP with Neo4j MCP server\n- [Tutorial](https://medium.com/@dustin_36183/connect-your-coding-assistant-to-the-web-integrating-tavily-mcp-with-cline-in-vs-code-5f923a4983d1) on integrating Tavily MCP with Cline in VS Code\n\n## Remote MCP Server\n\nConnect directly to Tavily's remote MCP server instead of running it locally. This provides a seamless experience without requiring local installation or configuration.\n\nSimply use the remote MCP server URL with your Tavily API key:\n\n``` \nhttps://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key> \n```\n Get your Tavily API key from [tavily.com](https://www.tavily.com/).\n\n\n### Connect to Cursor\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=tavily-remote-mcp&config=eyJjb21tYW5kIjoibnB4IC15IG1jcC1yZW1vdGUgaHR0cHM6Ly9tY3AudGF2aWx5LmNvbS9tY3AvP3RhdmlseUFwaUtleT08eW91ci1hcGkta2V5PiIsImVudiI6e319)\n\nClick the ‚¨ÜÔ∏è Add to Cursor ‚¨ÜÔ∏è button, this will do most of the work for you but you will still need to edit the configuration to add your API-KEY. You can get a Tavily API key [here](https://www.tavily.com/).\n\n\nonce you click the button you should be redirect to Cursor ...\n\n### Step 1\nClick the install button\n\n![](assets/cursor-step1.png)\n\n\n### Step 2\nYou should see the MCP is now installed, if the blue slide is not already turned on, manually turn it on. You also need to edit the configuration to include your own Tavily API key.\n![](assets/cursor-step2.png)\n\n### Step 3\nYou will then be redirected to your `mcp.json` file where you have to add `your-api-key`.\n\n```json\n{\n  \"mcpServers\": {\n    \"tavily-remote-mcp\": {\n      \"command\": \"npx -y mcp-remote https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key>\",\n      \"env\": {}\n    }\n  }\n}\n```\n\n### Connect to Claude Desktop\n\nClaude desktop now supports adding `integrations` which is currently in beta. An integration in this case is the Tavily Remote MCP, below I will explain how to add the MCP as an `integration` in Claude desktop.\n\n### Step 1 \nopen claude desktop, click the button with the two sliders and then navigate to add integrations.\n![](assets/claude-step1.png)\n\n### Step 2\nclick `Add integrations`\n![](assets/claude-step2.png)\n\n### Step 3\nName the integration and insert the Tavily remote MCP url with your API key. You can get a Tavily API key [here](https://www.tavily.com/). Click `Add` to confirm.\n![](assets/claude-step3.png)\n\n### Step 4\nRetrun to the chat screen and you will see the Tavily Remote MCP is now connected to Claude desktop.\n![](assets/claude-step4.png)\n\n### OpenAI \nAllow models to use remote MCP servers to perform tasks.\n- You first need to export your OPENAI_API_KEY\n- You must also add your Tavily API-key to `<your-api-key>`, you can get a Tavily API key [here](https://www.tavily.com/)\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresp = client.responses.create(\n    model=\"gpt-4.1\",\n    tools=[\n        {\n            \"type\": \"mcp\",\n            \"server_label\": \"tavily\",\n            \"server_url\": \"https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key>\",\n            \"require_approval\": \"never\",\n        },\n    ],\n    input=\"Do you have access to the tavily mcp server?\",\n)\n\nprint(resp.output_text)\n```\n\n### Clients that don't support remote MCPs\n\nmcp-remote is a lightweight bridge that lets MCP clients that can only talk to local (stdio) servers securely connect to remote MCP servers over HTTP + SSE with OAuth-based auth, so you can host and update your server in the cloud while existing clients keep working. It serves as an experimental stop-gap until popular MCP clients natively support remote, authorized servers.\n\n```json\n{\n    \"tavily-remote\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-remote\",\n        \"https://mcp.tavily.com/mcp/?tavilyApiKey=<your-api-key>\"\n      ]\n    }\n}\n```\n\n\n\n## Local MCP \n\n### Prerequisites üîß\n\nBefore you begin, ensure you have:\n\n- [Tavily API key](https://app.tavily.com/home)\n  - If you don't have a Tavily API key, you can sign up for a free account [here](https://app.tavily.com/home)\n- [Claude Desktop](https://claude.ai/download) or [Cursor](https://cursor.sh)\n- [Node.js](https://nodejs.org/) (v20 or higher)\n  - You can verify your Node.js installation by running:\n    - `node --version`\n- [Git](https://git-scm.com/downloads) installed (only needed if using Git installation method)\n  - On macOS: `brew install git`\n  - On Linux: \n    - Debian/Ubuntu: `sudo apt install git`\n    - RedHat/CentOS: `sudo yum install git`\n  - On Windows: Download [Git for Windows](https://git-scm.com/download/win)\n\n## Tavily MCP server installation ‚ö°\n\n### Running with NPX \n\n```bash\nnpx -y tavily-mcp@latest \n```\n\n### Installing via Smithery\n\nTo install Tavily MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@tavily-ai/tavily-mcp):\n\n```bash\nnpx -y @smithery/cli install @tavily-ai/tavily-mcp --client claude\n```\n\nAlthough you can launch a server on its own, it's not particularly helpful in isolation. Instead, you should integrate it into an MCP client. Below is an example of how to configure the Claude Desktop app to work with the tavily-mcp server.\n\n\n## Configuring MCP Clients ‚öôÔ∏è\n\nThis repository will explain how to configure [VS Code](https://code.visualstudio.com), [Cursor](https://cursor.sh) and [Claude Desktop](https://claude.ai/desktop) to work with the tavily-mcp server.\n\n### Configuring VS Code üíª\n\nFor one-click installation, click one of the install buttons below:\n\n[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=tavily&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22tavily-mcp%400.1.4%22%5D%2C%22env%22%3A%7B%22TAVILY_API_KEY%22%3A%22%24%7Binput%3Atavily_api_key%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22tavily_api_key%22%2C%22description%22%3A%22Tavily+API+Key%22%2C%22password%22%3Atrue%7D%5D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=tavily&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22tavily-mcp%400.1.4%22%5D%2C%22env%22%3A%7B%22TAVILY_API_KEY%22%3A%22%24%7Binput%3Atavily_api_key%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22tavily_api_key%22%2C%22description%22%3A%22Tavily+API+Key%22%2C%22password%22%3Atrue%7D%5D&quality=insiders)\n\n### Manual Installation\n\nFirst check if there are install buttons at the top of this section that match your needs. If you prefer manual installation, follow these steps:\n\nAdd the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` (or `Cmd + Shift + P` on macOS) and typing `Preferences: Open User Settings (JSON)`.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"tavily_api_key\",\n        \"description\": \"Tavily API Key\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"tavily\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"tavily-mcp@latest\"],\n        \"env\": {\n          \"TAVILY_API_KEY\": \"${input:tavily_api_key}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"tavily_api_key\",\n      \"description\": \"Tavily API Key\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"tavily\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"tavily-mcp@latest\"],\n      \"env\": {\n        \"TAVILY_API_KEY\": \"${input:tavily_api_key}\"\n      }\n    }\n  }\n}\n```\n\n### Configuring Cline ü§ñ\n\nThe easiest way to set up the Tavily MCP server in Cline is through the marketplace with a single click:\n\n1. Open Cline in VS Code\n2. Click on the Cline icon in the sidebar\n3. Navigate to the \"MCP Servers\" tab ( 4 squares )\n4. Search \"Tavily\" and click \"install\"\n5. When prompted, enter your Tavily API key\n\nAlternatively, you can manually set up the Tavily MCP server in Cline:\n\n1. Open the Cline MCP settings file:\n\n   ### For macOS:\n   ```bash\n   # Using Visual Studio Code\n   code ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   \n   # Or using TextEdit\n   open -e ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   ```\n\n   ### For Windows:\n   ```bash\n   code %APPDATA%\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json\n   ```\n\n2. Add the Tavily server configuration to the file:\n\n   Replace `your-api-key-here` with your actual [Tavily API key](https://tavily.com/api-keys).\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"tavily-mcp\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"tavily-mcp@latest\"],\n         \"env\": {\n           \"TAVILY_API_KEY\": \"your-api-key-here\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n3. Save the file and restart Cline if it's already running.\n\n4. When using Cline, you'll now have access to the Tavily MCP tools. You can ask Cline to use the tavily-search and tavily-extract tools directly in your conversations.\n\n\n### Configuring the Claude Desktop app üñ•Ô∏è\n### For macOS:\n\n```bash\n# Create the config file if it doesn't exist\ntouch \"$HOME/Library/Application Support/Claude/claude_desktop_config.json\"\n\n# Opens the config file in TextEdit \nopen -e \"$HOME/Library/Application Support/Claude/claude_desktop_config.json\"\n\n# Alternative method using Visual Studio Code (requires VS Code to be installed)\ncode \"$HOME/Library/Application Support/Claude/claude_desktop_config.json\"\n```\n\n### For Windows:\n```bash\ncode %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n### Add the Tavily server configuration:\n\nReplace `your-api-key-here` with your actual [Tavily API key](https://tavily.com/api-keys).\n\n```json\n{\n  \"mcpServers\": {\n    \"tavily-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"tavily-mcp@latest\"],\n      \"env\": {\n        \"TAVILY_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n### 2. Git Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/tavily-ai/tavily-mcp.git\ncd tavily-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the project:\n```bash\nnpm run build\n```\n### Configuring the Claude Desktop app ‚öôÔ∏è\nFollow the configuration steps outlined in the [Configuring the Claude Desktop app](#configuring-the-claude-desktop-app-Ô∏è) section above, using the below JSON configuration.\n\nReplace `your-api-key-here` with your actual [Tavily API key](https://tavily.com/api-keys) and `/path/to/tavily-mcp` with the actual path where you cloned the repository on your system.\n\n```json\n{\n  \"mcpServers\": {\n    \"tavily\": {\n      \"command\": \"npx\",\n      \"args\": [\"/path/to/tavily-mcp/build/index.js\"],\n      \"env\": {\n        \"TAVILY_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n## Acknowledgments ‚ú®\n\n- [Model Context Protocol](https://modelcontextprotocol.io) for the MCP specification\n- [Anthropic](https://anthropic.com) for Claude Desktop\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/tavily-mcp",
          "npm_downloads": 695749,
          "npm_package_name": "tavily-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "tinybirdco--mcp-tinybird": {
          "owner": "tinybirdco",
          "name": "mcp-tinybird",
          "url": "https://github.com/tinybirdco/mcp-tinybird",
          "imageUrl": "https://github.com/tinybirdco.png",
          "description": "Connect to Tinybird's real-time analytics platform to search and analyze data using the Tinybird Query API and existing API endpoints.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:52.137437",
          "collection_timestamp": "2025-10-02T15:02:07.576063",
          "stars": 73,
          "forks": 16,
          "license": "Apache License 2.0",
          "language": "Python",
          "created_at": "2024-11-27T10:07:15Z",
          "updated_at": "2025-09-21T10:29:31Z",
          "open_issues": 4,
          "readme_content": "# üö® DEPRECATED\n\n**This repository is deprecated and no longer maintained.**\n\n**New implementation:** [Tinybird MCP Server](https://www.tinybird.co/docs/forward/analytics-agents/mcp)\n\n**Please migrate to the official implementation.**\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "translated--lara-mcp": {
          "owner": "translated",
          "name": "lara-mcp",
          "url": "https://github.com/translated/lara-mcp",
          "imageUrl": "https://github.com/translated.png",
          "description": "Provides translation capabilities with automatic language detection and context-aware translations. Supports multiple language pairs and allows for the fine-tuning of translations using custom instructions.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:53.107772",
          "collection_timestamp": "2025-10-02T15:02:11.462679",
          "stars": 73,
          "forks": 12,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-31T05:10:30Z",
          "updated_at": "2025-09-30T10:34:10Z",
          "open_issues": 1,
          "readme_content": "# Lara Translate MCP Server\n\nA Model Context Protocol (MCP) Server for [Lara Translate](https://laratranslate.com/translate) API, enabling powerful translation capabilities with support for language detection, context-aware translations and translation memories.\n\n[![License](https://img.shields.io/github/license/translated/lara-mcp.svg)](https://github.com/translated/lara-mcp/blob/main/LICENSE)\n[![Docker Pulls](https://img.shields.io/docker/pulls/translatednet/lara-mcp.svg)](https://hub.docker.com/r/translatednet/lara-mcp)\n[![npm downloads](https://img.shields.io/npm/dm/@translated/lara-mcp.svg)](https://www.npmjs.com/package/@translated/lara-mcp)\n\n## üìö Table of Contents\n- üìñ [Introduction](#-introduction)\n- üõ† [Available Tools](#-available-tools)\n- üöÄ [Getting Started](#-getting-started)\n  - üìã [HTTP Server](#http-server-)\n  - üîå [STDIO Server](#stdio-server-%EF%B8%8F)\n- üß™ [Verify Installation](#-verify-installation)\n- üíª [Popular Clients that supports MCPs](#-popular-clients-that-supports-mcps)\n- üÜò [Support](#-support)\n\n## üìñ Introduction\n\n<details>\n<summary><strong>What is MCP?</strong></summary>\n\nModel Context Protocol (MCP) is an open standardized communication protocol that enables AI applications to connect with external tools, data sources, and services. Think of MCP like a USB-C port for AI applications - just as USB-C provides a standardized way to connect devices to various peripherals, MCP provides a standardized way to connect AI models to different data sources and tools.\n\nLara Translate MCP Server enables AI applications to access Lara Translate's powerful translation capabilities through this standardized protocol.\n\n> More info about Model Context Protocol on: https://modelcontextprotocol.io/\n</details>\n\n<details>\n<summary><strong>How Lara Translate MCP Works</strong></summary>\n\nLara Translate MCP Server implements the Model Context Protocol to provide seamless translation capabilities to AI applications. The integration follows this flow:\n\n1. **Connection Establishment**: When an MCP-compatible AI application starts, it connects to configured MCP servers, including the Lara Translate MCP Server\n2. **Tool & Resource Discovery**: The AI application discovers available translation tools and resources provided by the Lara Translate MCP Server\n3. **Request Processing**: When translation needs are identified:\n   - The AI application formats a structured request with text to translate, language pairs, and optional context\n   - The MCP server validates the request and transforms it into Lara Translate API calls\n   - The request is securely sent to Lara Translate's API using your credentials\n4. **Translation & Response**: Lara Translate processes the translation using advanced AI models\n5. **Result Integration**: The translation results are returned to the AI application, which can then incorporate them into its response\n\nThis integration architecture allows AI applications to access professional-grade translations without implementing the API directly, while maintaining the security of your API credentials and offering flexibility to adjust translation parameters through natural language instructions.\n</details>\n\n<details>\n<summary><strong>Why to use Lara inside an LLM</strong></summary>\n\nIntegrating Lara with LLMs creates a powerful synergy that significantly enhances translation quality for non-English languages.\n\n#### Why General LLMs Fall Short in Translation\nWhile large language models possess broad linguistic capabilities, they often lack the specialized expertise and up-to-date terminology required for accurate translations in specific domains and languages.\n\n#### Lara‚Äôs Domain-Specific Advantage\nLara overcomes this limitation by leveraging Translation Language Models (T-LMs) trained on billions of professionally translated segments. These models provide domain-specific machine translation that captures cultural nuances and industry terminology that generic LLMs may miss. The result: translations that are contextually accurate and sound natural to native speakers.\n\n#### Designed for Non-English Strength\nLara has a strong focus on non-English languages, addressing the performance gap found in models such as GPT-4. The dominance of English in datasets such as Common Crawl and Wikipedia results in lower quality output in other languages. Lara helps close this gap by providing higher quality understanding, generation, and restructuring in a multilingual context.\n\n#### Faster, Smarter Multilingual Performance\nBy offloading complex translation tasks to specialized T-LMs, Lara reduces computational overhead and minimizes latency‚Äîa common issue for LLMs handling non-English input. Its architecture processes translations in parallel with the LLM, enabling for real-time, high-quality output without compromising speed or efficiency.\n\n#### Cost-Efficient Translation at Scale\nLara also lowers the cost of using models like GPT-4 in non-English workflows. Since tokenization (and pricing) is optimized for English, using Lara allows translation to take place before hitting the LLM, meaning that only the translated English content is processed. This improves cost efficiency and supports competitive scalability for global enterprises.\n</details>\n\n## üõ† Available Tools\n\n### Translation Tools\n\n<details>\n<summary><strong>translate</strong> - Translate text between languages</summary>\n\n**Inputs**:\n- `text` (array): An array of text blocks to translate, each with:\n    - `text` (string): The text content\n    - `translatable` (boolean): Whether this block should be translated\n- `source` (optional string): Source language code (e.g., 'en-EN')\n- `target` (string): Target language code (e.g., 'it-IT')\n- `context` (optional string): Additional context to improve translation quality\n- `instructions` (optional string[]): Instructions to adjust translation behavior\n- `source_hint` (optional string): Guidance for language detection\n\n**Returns**: Translated text blocks maintaining the original structure\n</details>\n\n### Translation Memories Tools\n\n<details>\n\n<summary><strong>list_memories</strong> - List saved translation memories</summary>\n\n**Returns**: Array of memories and their details\n</details>\n\n<details>\n<summary><strong>create_memory</strong> - Create a new translation memory</summary>\n\n**Inputs**:\n- `name` (string): Name of the new memory\n- `external_id` (optional string): ID of the memory to import from MyMemory (e.g., 'ext_my_[MyMemory ID]')\n\n**Returns**: Created memory data\n</details>\n\n<details>\n<summary><strong>update_memory</strong> - Update translation memory name</summary>\n\n**Inputs**:\n- `id` (string): ID of the memory to update\n- `name` (string): The new name for the memory\n\n**Returns**: Updated memory data\n</details>\n\n<details>\n<summary><strong>delete_memory</strong> - Delete a translation memory</summary>\n\n**Inputs**:\n- `id` (string): ID of the memory to delete\n\n**Returns**: Deleted memory data\n</details>\n\n<details>\n<summary><strong>add_translation</strong> - Add a translation unit to memory</summary>\n\n**Inputs**:\n- `id` (string | string[]): ID or IDs of memories where to add the translation unit\n- `source` (string): Source language code\n- `target` (string): Target language code\n- `sentence` (string): The source sentence\n- `translation` (string): The translated sentence\n- `tuid` (optional string): Translation Unit unique identifier\n- `sentence_before` (optional string): Context sentence before\n- `sentence_after` (optional string): Context sentence after\n\n**Returns**: Added translation details\n</details>\n\n<details>\n<summary><strong>delete_translation</strong> - Delete a translation unit from memory</summary>\n\n**Inputs**:\n- `id` (string): ID of the memory\n- `source` (string): Source language code\n- `target` (string): Target language code\n- `sentence` (string): The source sentence\n- `translation` (string): The translated sentence\n- `tuid` (optional string): Translation Unit unique identifier\n- `sentence_before` (optional string): Context sentence before\n- `sentence_after` (optional string): Context sentence after\n\n**Returns**: Removed translation details\n</details>\n\n<details>\n<summary><strong>import_tmx</strong> - Import a TMX file into a memory</summary>\n\n**Inputs**:\n- `id` (string): ID of the memory to update\n- `tmx_content` (string): The content of the tmx file to upload\n- `gzip` (boolean): Indicates if the file is compressed (.gz)\n\n**Returns**: Import details\n</details>\n\n<details>\n<summary><strong>check_import_status</strong> - Checks the status of a TMX file import</summary>\n\n**Inputs**:\n- `id` (string): The ID of the import job\n\n**Returns**: Import details\n</details>\n\n## üöÄ Getting Started\nLara supports both the STDIO and streamable HTTP protocols. For a hassle-free setup, we recommend using the HTTP protocol. If you prefer to use STDIO, it must be installed locally on your machine.\n\nYou'll find setup instructions for both protocols in the sections below.\n\n### HTTP Server üåê\n<details>\n<summary><strong>‚ùå Clients NOT supporting <code>url</code> configuration (e.g., Claude, OpenAI)</strong></summary>\n\nThis installation guide is intended for clients that do NOT support the url-based configuration. This option requires Node.js to be installed on your system.\n\n> If you're unsure how to configure an MCP with your client, please refer to your MCP client's official documentation.\n\n---\n\n1. Open your client's MCP configuration JSON file with a text editor, then copy and paste the following snippet:\n\n```json\n{\n  \"mcpServers\": {\n    \"lara\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"https://mcp.laratranslate.com/v1\",\n        \"--header\",\n        \"x-lara-access-key-id: ${X_LARA_ACCESS_KEY_ID}\",\n        \"--header\",\n        \"x-lara-access-key-secret: ${X_LARA_ACCESS_KEY_SECRET}\"\n      ],\n      \"env\": {\n        \"X_LARA_ACCESS_KEY_ID\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"X_LARA_ACCESS_KEY_SECRET\": \"<YOUR_ACCESS_KEY_SECRET>\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `<YOUR_ACCESS_KEY_ID>` and `<YOUR_ACCESS_KEY_SECRET>` with your Lara Translate API credentials. Refer to the [Official Documentation](https://developers.laratranslate.com/docs/getting-started#step-3---configure-your-credentials) for details.\n\n3. Restart your MCP client.\n\n</details>\n\n<details>\n<summary><strong>‚úÖ Clients supporting <code>url</code> configuration (e.g., Cursor, Continue)</strong></summary>\n\nThis installation guide is intended for clients that support the url-based configuration. These clients can connect to Lara through a remote HTTP endpoint by specifying a simple configuration object.\n\nSome examples of supported clients include Cursor, Continue, OpenDevin, and Aider.\n> If you're unsure how to configure an MCP with your client, please refer to your MCP client's official documentation.\n\n---\n\n1. Open your client's MCP configuration JSON file with a text editor, then copy and paste the following snippet:\n\n```json\n{\n  \"mcpServers\": {\n    \"lara\": {\n      \"url\": \"https://mcp.laratranslate.com/v1\",\n      \"headers\": {\n        \"x-lara-access-key-id\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"x-lara-access-key-secret\": \"<YOUR_ACCESS_KEY_SECRET>\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `<YOUR_ACCESS_KEY_ID>` and `<YOUR_ACCESS_KEY_SECRET>` with your Lara Translate API credentials. Refer to the [Official Documentation](https://developers.laratranslate.com/docs/getting-started#step-3---configure-your-credentials) for details.\n\n3. Restart your MCP client.\n\n</details>\n\n---\n\n### STDIO Server üñ•Ô∏è\n<details>\n<summary><strong>Using NPX</strong></summary>\n\nThis option requires Node.js to be installed on your system.\n\n1. Add the following to your MCP configuration file:\n```json\n{\n  \"mcpServers\": {\n    \"lara-translate\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@translated/lara-mcp@latest\"],\n      \"env\": {\n        \"LARA_ACCESS_KEY_ID\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"LARA_ACCESS_KEY_SECRET\": \"<YOUR_ACCESS_KEY_SECRET>\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `<YOUR_ACCESS_KEY_ID>` and `<YOUR_ACCESS_KEY_SECRET>` with your actual Lara API credentials.\n</details>\n\n<details>\n<summary><strong>Using Docker</strong></summary>\n\nThis option requires Docker to be installed on your system.\n\n1. Add the following to your MCP configuration file:\n```json\n{\n  \"mcpServers\": {\n    \"lara-translate\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"LARA_ACCESS_KEY_ID\",\n        \"-e\",\n        \"LARA_ACCESS_KEY_SECRET\",\n        \"translatednet/lara-mcp:latest\"\n      ],\n      \"env\": {\n        \"LARA_ACCESS_KEY_ID\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"LARA_ACCESS_KEY_SECRET\": \"<YOUR_ACCESS_KEY_SECRET>\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `<YOUR_ACCESS_KEY_ID>` and `<YOUR_ACCESS_KEY_SECRET>` with your actual Lara API credentials.\n</details>\n\n<details>\n<summary><strong>Building from Source</strong></summary>\n\n#### Using Node.js\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/translated/lara-mcp.git\ncd lara-mcp\n```\n\n2. Install dependencies and build:\n```bash\n# Install dependencies\npnpm install\n\n# Build\npnpm run build\n```\n\n3. Add the following to your MCP configuration file:\n```json\n{\n  \"mcpServers\": {\n    \"lara-translate\": {\n      \"command\": \"node\",\n      \"args\": [\"<FULL_PATH_TO_PROJECT_FOLDER>/dist/index.js\"],\n      \"env\": {\n        \"LARA_ACCESS_KEY_ID\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"LARA_ACCESS_KEY_SECRET\": \"<YOUR_ACCESS_KEY_SECRET>\"\n      }\n    }\n  }\n}\n```\n4. Replace:\n   - `<FULL_PATH_TO_PROJECT_FOLDER>` with the absolute path to your project folder\n   - `<YOUR_ACCESS_KEY_ID>` and `<YOUR_ACCESS_KEY_SECRET>` with your actual Lara API credentials.\n\n#### Building a Docker Image\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/translated/lara-mcp.git\ncd lara-mcp\n```\n\n2. Build the Docker image:\n```bash\ndocker build -t lara-mcp .\n```\n\n3. Add the following to your MCP configuration file:\n```json\n{\n  \"mcpServers\": {\n    \"lara-translate\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"LARA_ACCESS_KEY_ID\",\n        \"-e\",\n        \"LARA_ACCESS_KEY_SECRET\",\n        \"lara-mcp\"\n      ],\n      \"env\": {\n        \"LARA_ACCESS_KEY_ID\": \"<YOUR_ACCESS_KEY_ID>\",\n        \"LARA_ACCESS_KEY_SECRET\": \"<YOUR_ACCESS_KEY_SECRET>\"\n      }\n    }\n  }\n}\n```\n\n4. Replace `<YOUR_ACCESS_KEY_ID>` and `<YOUR_ACCESS_KEY_SECRET>` with your actual credentials.\n</details>\n\n## üß™ Verify Installation\n\nAfter restarting your MCP client, you should see Lara Translate MCP in the list of available MCPs.\n> The method for viewing installed MCPs varies by client. Please consult your MCP client's documentation.\n\nTo verify that Lara Translate MCP is working correctly, try translating with a simple prompt:\n```text\nTranslate with Lara \"Hello world\" to Spanish\n```\n\nYour MCP client will begin generating a response. If Lara Translate MCP is properly installed and configured, your client will either request approval for the action or display a notification that Lara Translate is being used.\n\n## üíª Popular Clients that supports MCPs \n\n> For a complete list of MCP clients and their feature support, visit the [official MCP clients page](https://modelcontextprotocol.io/clients).\n\n| Client                                                            | Description                                          |\n|-------------------------------------------------------------------|------------------------------------------------------|\n| [Claude Desktop](https://claude.ai/download)                      | Desktop application for Claude AI                    |\n| [Aixplain](https://aixplain.com/)                                 | Production-ready AI Agents                           |\n| [Cursor](https://www.cursor.com/)                                 | AI-first code editor                                 |\n| [Cline for VS Code](https://github.com/cline/cline)               | VS Code extension for AI assistance                  |\n| [GitHub Copilot MCP](https://github.com/VikashLoomba/copilot-mcp) | VS Code extension for GitHub Copilot MCP integration |\n| [Windsurf](https://windsurf.com/editor)                           | AI-powered code editor and development environment   |\n\n## üÜò Support\n\n- For issues with Lara Translate API: Visit [Lara Translate API and Integrations Support](https://support.laratranslate.com)\n- For issues with this MCP Server: Open an issue on [GitHub](https://github.com/translated/lara-mcp/issues)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/lara-mcp",
          "npm_downloads": 0,
          "npm_package_name": "lara-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "vectorize-io--vectorize-mcp-server": {
          "owner": "vectorize-io",
          "name": "vectorize-mcp-server",
          "url": "https://github.com/vectorize-io/vectorize-mcp-server",
          "imageUrl": "https://github.com/vectorize-io.png",
          "description": "Integrates advanced vector retrieval and text extraction capabilities, enabling document searches and Markdown text extraction from various file types. Supports deep research generation from custom data pipelines.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:54.337953",
          "collection_timestamp": "2025-10-02T15:02:17.303594",
          "stars": 93,
          "forks": 18,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2025-03-10T14:43:02Z",
          "updated_at": "2025-09-20T08:33:07Z",
          "open_issues": 3,
          "readme_content": "# Vectorize MCP Server\n\nA Model Context Protocol (MCP) server implementation that integrates with [Vectorize](https://vectorize.io/) for advanced Vector retrieval and text extraction.\n\n<a href=\"https://glama.ai/mcp/servers/pxwbgk0kzr\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/pxwbgk0kzr/badge\" alt=\"Vectorize MCP server\" />\n</a>\n\n\n## Installation\n\n### Running with npx\n\n```bash\nexport VECTORIZE_ORG_ID=YOUR_ORG_ID\nexport VECTORIZE_TOKEN=YOUR_TOKEN\nexport VECTORIZE_PIPELINE_ID=YOUR_PIPELINE_ID\n\nnpx -y @vectorize-io/vectorize-mcp-server@latest\n```\n\n### VS Code Installation\n\nFor one-click installation, click one of the install buttons below:\n\n[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=vectorize&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40vectorize-io%2Fvectorize-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22VECTORIZE_ORG_ID%22%3A%22%24%7Binput%3Aorg_id%7D%22%2C%22VECTORIZE_TOKEN%22%3A%22%24%7Binput%3Atoken%7D%22%2C%22VECTORIZE_PIPELINE_ID%22%3A%22%24%7Binput%3Apipeline_id%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22org_id%22%2C%22description%22%3A%22Vectorize+Organization+ID%22%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22token%22%2C%22description%22%3A%22Vectorize+Token%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22pipeline_id%22%2C%22description%22%3A%22Vectorize+Pipeline+ID%22%7D%5D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=vectorize&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40vectorize-io%2Fvectorize-mcp-server%40latest%22%5D%2C%22env%22%3A%7B%22VECTORIZE_ORG_ID%22%3A%22%24%7Binput%3Aorg_id%7D%22%2C%22VECTORIZE_TOKEN%22%3A%22%24%7Binput%3Atoken%7D%22%2C%22VECTORIZE_PIPELINE_ID%22%3A%22%24%7Binput%3Apipeline_id%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22org_id%22%2C%22description%22%3A%22Vectorize+Organization+ID%22%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22token%22%2C%22description%22%3A%22Vectorize+Token%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22pipeline_id%22%2C%22description%22%3A%22Vectorize+Pipeline+ID%22%7D%5D&quality=insiders)\n\n### Manual Installation\n\nFor the quickest installation, use the one-click install buttons at the top of this section.\n\nTo install manually, add the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"org_id\",\n        \"description\": \"Vectorize Organization ID\"\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"token\",\n        \"description\": \"Vectorize Token\",\n        \"password\": true\n      },\n      {\n        \"type\": \"promptString\",\n        \"id\": \"pipeline_id\",\n        \"description\": \"Vectorize Pipeline ID\"\n      }\n    ],\n    \"servers\": {\n      \"vectorize\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@vectorize-io/vectorize-mcp-server@latest\"],\n        \"env\": {\n          \"VECTORIZE_ORG_ID\": \"${input:org_id}\",\n          \"VECTORIZE_TOKEN\": \"${input:token}\",\n          \"VECTORIZE_PIPELINE_ID\": \"${input:pipeline_id}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add the following to a file called `.vscode/mcp.json` in your workspace to share the configuration with others:\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"org_id\",\n      \"description\": \"Vectorize Organization ID\"\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"token\",\n      \"description\": \"Vectorize Token\",\n      \"password\": true\n    },\n    {\n      \"type\": \"promptString\",\n      \"id\": \"pipeline_id\",\n      \"description\": \"Vectorize Pipeline ID\"\n    }\n  ],\n  \"servers\": {\n    \"vectorize\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@vectorize-io/vectorize-mcp-server@latest\"],\n      \"env\": {\n        \"VECTORIZE_ORG_ID\": \"${input:org_id}\",\n        \"VECTORIZE_TOKEN\": \"${input:token}\",\n        \"VECTORIZE_PIPELINE_ID\": \"${input:pipeline_id}\"\n      }\n    }\n  }\n}\n```\n\n## Configuration on Claude/Windsurf/Cursor/Cline\n\n```json\n{\n  \"mcpServers\": {\n    \"vectorize\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@vectorize-io/vectorize-mcp-server@latest\"],\n      \"env\": {\n        \"VECTORIZE_ORG_ID\": \"your-org-id\",\n        \"VECTORIZE_TOKEN\": \"your-token\",\n        \"VECTORIZE_PIPELINE_ID\": \"your-pipeline-id\"\n      }\n    }\n  }\n}\n```\n\n## Tools\n\n### Retrieve documents\n\nPerform vector search and retrieve documents (see official [API](https://docs.vectorize.io/api/api-pipelines/api-retrieval)):\n\n```json\n{\n  \"name\": \"retrieve\",\n  \"arguments\": {\n    \"question\": \"Financial health of the company\",\n    \"k\": 5\n  }\n}\n```\n\n### Text extraction and chunking (Any file to Markdown)\n\nExtract text from a document and chunk it into Markdown format (see official [API](https://docs.vectorize.io/api/api-extraction)):\n\n```json\n{\n  \"name\": \"extract\",\n  \"arguments\": {\n    \"base64document\": \"base64-encoded-document\",\n    \"contentType\": \"application/pdf\"\n  }\n}\n```\n\n### Deep Research\n\nGenerate a Private Deep Research from your pipeline (see official [API](https://docs.vectorize.io/api/api-pipelines/api-deep-research)):\n\n```json\n{\n  \"name\": \"deep-research\",\n  \"arguments\": {\n    \"query\": \"Generate a financial status report about the company\",\n    \"webSearch\": true\n  }\n}\n```\n\n## Development\n\n```bash\nnpm install\nnpm run dev\n```\n\n### Release\nChange the package.json version and then:\n```bash\ngit commit -am \"x.y.z\"\ngit tag x.y.z\ngit push origin\ngit push origin --tags\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create your feature branch\n3. Submit a pull request\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/@vectorize-io/vectorize-mcp-server",
          "npm_downloads": 1857,
          "npm_package_name": "@vectorize-io/vectorize-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "yamadashy--repomix": {
          "owner": "yamadashy",
          "name": "repomix",
          "url": "https://github.com/yamadashy/repomix",
          "imageUrl": "https://github.com/yamadashy.png",
          "description": "Transforms codebases into AI-friendly formats to facilitate analysis by AI tools, improving code reviews and enabling refactoring suggestions. Consolidates repository information through a single command for better AI understanding.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:55.716643",
          "collection_timestamp": "2025-10-02T15:02:21.225598",
          "stars": 19472,
          "forks": 873,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2024-07-13T07:11:32Z",
          "updated_at": "2025-10-02T08:28:01Z",
          "open_issues": 118,
          "readme_content": "<div align=\"center\" markdown=\"1\">\n   <sup>Special thanks to:</sup>\n   <br>\n   <br>\n   <a href=\"https://go.warp.dev/repomix\">\n      <img alt=\"Warp sponsorship\" width=\"400\" src=\"https://raw.githubusercontent.com/warpdotdev/brand-assets/main/Github/Sponsor/Warp-Github-LG-01.png\">\n   </a>\n\n### [Warp, built for coding with multiple AI agents](https://go.warp.dev/repomix)\n[Available for MacOS, Linux, & Windows](https://go.warp.dev/repomix)<br>\n\n   <br>\n\n   <a href=\"https://tuple.app/repomix\">\n      <img alt=\"Tuple sponsorship\" width=\"400\" src=\"website/client/src/public/images/sponsors/tuple/github_repo_sponsorship.png\">\n   </a>\n\n### [Tuple, the premier screen sharing app for developers on macOS and Windows.](https://tuple.app/repomix)\n\n</div>\n\n\n<hr />\n\n<div align=\"center\">\n  <a href=\"https://repomix.com\">\n    <img src=\"website/client/src/public/images/repomix-title.png\" alt=\"Repomix\" width=\"500\" height=\"auto\" />\n  </a>\n  <p align=\"center\">\n    <b>Pack your codebase into AI-friendly formats</b>\n  </p>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://repomix.com\"><b>Use Repomix online! üëâ repomix.com</b></a><br>\n</p>\n\n<p align=\"center\">\n  Need discussion? Join us on <a href=\"https://discord.gg/wNYzTwZFku\">Discord</a>!<br>\n  <i>Share your experience and tips</i><br>\n  <i>Stay updated on new features</i><br>\n  <i>Get help with configuration and usage</i><br>\n</p>\n\n<hr />\n\n[![npm](https://img.shields.io/npm/v/repomix.svg?maxAge=1000)](https://www.npmjs.com/package/repomix)\n[![npm](https://img.shields.io/npm/d18m/repomix)](https://www.npmjs.com/package/repomix)\n[![Actions Status](https://github.com/yamadashy/repomix/actions/workflows/ci.yml/badge.svg)](https://github.com/yamadashy/repomix/actions?query=workflow%3A\"ci\")\n[![codecov](https://codecov.io/github/yamadashy/repomix/graph/badge.svg)](https://codecov.io/github/yamadashy/repomix)\n[![Sponsors](https://img.shields.io/github/sponsors/yamadashy?logo=github)](https://github.com/sponsors/yamadashy)\n[![Discord](https://badgen.net/discord/online-members/wNYzTwZFku?icon=discord&label=discord)](https://discord.gg/wNYzTwZFku)\n\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-yamadashy%2Frepomix-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/yamadashy/repomix)\n<!-- DeepWiki badge generated by https://deepwiki.ryoppippi.com/ -->\n\nüì¶ Repomix is a powerful tool that packs your entire repository into a single, AI-friendly file.  \nIt is perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude,\nChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more.\n\nPlease consider sponsoring me.\n\n[![Sponsor](.github/assets/github-like-sponsor-button.svg)](https://github.com/sponsors/yamadashy)\n\n[![Sponsors](https://cdn.jsdelivr.net/gh/yamadashy/sponsor-list/sponsors/sponsors.png)](https://github.com/sponsors/yamadashy)\n\n## üèÜ Open Source Awards Nomination\n\nWe're honored! Repomix has been nominated for the **Powered by AI** category at the [JSNation Open Source Awards 2025](https://osawards.com/javascript/).\n\nThis wouldn't have been possible without all of you using and supporting Repomix. Thank you!\n\n## üéâ New: Repomix Website & Discord Community!\n\n- Try Repomix in your browser at [repomix.com](https://repomix.com/)\n- Join our [Discord Server](https://discord.gg/wNYzTwZFku) for support and discussion\n\n**We look forward to seeing you there!**\n\n## üåü Features\n\n- **AI-Optimized**: Formats your codebase in a way that's easy for AI to understand and process.\n- **Token Counting**: Provides token counts for each file and the entire repository, useful for LLM context limits.\n- **Simple to Use**: You need just one command to pack your entire repository.\n- **Customizable**: Easily configure what to include or exclude.\n- **Git-Aware**: Automatically respects your `.gitignore` files and `.git/info/exclude`.\n- **Security-Focused**: Incorporates [Secretlint](https://github.com/secretlint/secretlint) for robust security checks to detect and prevent inclusion of sensitive information.\n- **Code Compression**: The `--compress` option uses [Tree-sitter](https://github.com/tree-sitter/tree-sitter) to extract key code elements, reducing token count while preserving structure.\n\n## üöÄ Quick Start\n\n### Using the CLI Tool `>_`\n\nYou can try Repomix instantly in your project directory without installation:\n\n```bash\nnpx repomix@latest\n```\n\nOr install globally for repeated use:\n\n```bash\n# Install using npm\nnpm install -g repomix\n\n# Alternatively using yarn\nyarn global add repomix\n\n# Alternatively using bun\nbun add -g repomix\n\n# Alternatively using Homebrew (macOS/Linux)\nbrew install repomix\n\n# Then run in any project directory\nrepomix\n```\n\nThat's it! Repomix will generate a `repomix-output.xml` file in your current directory, containing your entire\nrepository in an AI-friendly format.\n\nYou can then send this file to an AI assistant with a prompt like:\n\n```\nThis file contains all the files in the repository combined into one.\nI want to refactor the code, so please review it first.\n```\n\n![Repomix File Usage 1](website/client/src/public/images/docs/repomix-file-usage-1.png)\n\nWhen you propose specific changes, the AI might be able to generate code accordingly. With features like Claude's\nArtifacts, you could potentially output multiple files, allowing for the generation of multiple interdependent pieces of\ncode.\n\n![Repomix File Usage 2](website/client/src/public/images/docs/repomix-file-usage-2.png)\n\nHappy coding! üöÄ\n\n### Using The Website üåê\n\nWant to try it quickly? Visit the official website at [repomix.com](https://repomix.com). Simply enter your repository\nname, fill in any optional details, and click the **Pack** button to see your generated output.\n\n#### Available Options\n\nThe website offers several convenient features:\n\n- Customizable output format (XML, Markdown, or Plain Text)\n- Instant token count estimation\n- Much more!\n\n### Using The Browser Extension üß©\n\nGet instant access to Repomix directly from any GitHub repository! Our Chrome extension adds a convenient \"Repomix\" button to GitHub repository pages.\n\n![Repomix Browser Extension](website/client/src/public/images/docs/browser-extension.png)\n\n#### Install\n- Chrome Extension: [Repomix - Chrome Web Store](https://chromewebstore.google.com/detail/repomix/fimfamikepjgchehkohedilpdigcpkoa)\n- Firefox Add-on: [Repomix - Firefox Add-ons](https://addons.mozilla.org/firefox/addon/repomix/)\n\n#### Features\n- One-click access to Repomix for any GitHub repository\n- More exciting features coming soon!\n\n### Using The VSCode Extension ‚ö°Ô∏è\n\nA community-maintained VSCode extension called [Repomix Runner](https://marketplace.visualstudio.com/items?itemName=DorianMassoulier.repomix-runner) (created by [massdo](https://github.com/massdo)) lets you run Repomix right inside your editor with just a few clicks. Run it on any folder, manage outputs seamlessly, and control everything through VSCode's intuitive interface. \n\nWant your output as a file or just the content? Need automatic cleanup? This extension has you covered. Plus, it works smoothly with your existing repomix.config.json.\n\nTry it now on the [VSCode Marketplace](https://marketplace.visualstudio.com/items?itemName=DorianMassoulier.repomix-runner)!\nSource code is available on [GitHub](https://github.com/massdo/repomix-runner).\n\n### Alternative Tools üõ†Ô∏è\n\nIf you're using Python, you might want to check out `Gitingest`, which is better suited for Python ecosystem and data\nscience workflows:\nhttps://github.com/cyclotruc/gitingest\n\n## üìä Usage\n\nTo pack your entire repository:\n\n```bash\nrepomix\n```\n\nTo pack a specific directory:\n\n```bash\nrepomix path/to/directory\n```\n\nTo pack specific files or directories\nusing [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax):\n\n```bash\nrepomix --include \"src/**/*.ts,**/*.md\"\n```\n\nTo exclude specific files or directories:\n\n```bash\nrepomix --ignore \"**/*.log,tmp/\"\n```\n\nTo pack a remote repository:\n\n```bash\nrepomix --remote https://github.com/yamadashy/repomix\n\n# You can also use GitHub shorthand:\nrepomix --remote yamadashy/repomix\n\n# You can specify the branch name, tag, or commit hash:\nrepomix --remote https://github.com/yamadashy/repomix --remote-branch main\n\n# Or use a specific commit hash:\nrepomix --remote https://github.com/yamadashy/repomix --remote-branch 935b695\n\n# Another convenient way is specifying the branch's URL\nrepomix --remote https://github.com/yamadashy/repomix/tree/main\n\n# Commit's URL is also supported\nrepomix --remote https://github.com/yamadashy/repomix/commit/836abcd7335137228ad77feb28655d85712680f1\n\n```\n\nTo pack files from a file list (pipe via stdin):\n\n```bash\n# Using find command\nfind src -name \"*.ts\" -type f | repomix --stdin\n\n# Using git to get tracked files\ngit ls-files \"*.ts\" | repomix --stdin\n\n# Using grep to find files containing specific content\ngrep -l \"TODO\" **/*.ts | repomix --stdin\n\n# Using ripgrep to find files with specific content\nrg -l \"TODO|FIXME\" --type ts | repomix --stdin\n\n# Using ripgrep (rg) to find files\nrg --files --type ts | repomix --stdin\n\n# Using sharkdp/fd to find files\nfd -e ts | repomix --stdin\n\n# Using fzf to select from all files\nfzf -m | repomix --stdin\n\n# Interactive file selection with fzf\nfind . -name \"*.ts\" -type f | fzf -m | repomix --stdin\n\n# Using ls with glob patterns\nls src/**/*.ts | repomix --stdin\n\n# From a file containing file paths\ncat file-list.txt | repomix --stdin\n\n# Direct input with echo\necho -e \"src/index.ts\\nsrc/utils.ts\" | repomix --stdin\n```\n\nThe `--stdin` option allows you to pipe a list of file paths to Repomix, giving you ultimate flexibility in selecting which files to pack.\n\nWhen using `--stdin`, the specified files are effectively added to the include patterns. This means that the normal include and ignore behavior still applies - files specified via stdin will still be excluded if they match ignore patterns.\n\n> [!NOTE]\n> When using `--stdin`, file paths can be relative or absolute, and Repomix will automatically handle path resolution and deduplication.\n\nTo include git logs in the output:\n\n```bash\n# Include git logs with default count (50 commits)\nrepomix --include-logs\n\n# Include git logs with specific commit count\nrepomix --include-logs --include-logs-count 10\n\n# Combine with diffs for comprehensive git context\nrepomix --include-logs --include-diffs\n```\n\nThe git logs include commit dates, messages, and file paths for each commit, providing valuable context for AI analysis of code evolution and development patterns.\n\nTo compress the output:\n\n```bash\nrepomix --compress\n\n# You can also use it with remote repositories:\nrepomix --remote yamadashy/repomix --compress\n```\n\nTo initialize a new configuration file (`repomix.config.json`):\n\n```bash\nrepomix --init\n```\n\nOnce you have generated the packed file, you can use it with Generative AI tools like ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more.\n\n### Docker Usage üê≥\n\nYou can also run Repomix using Docker.  \nThis is useful if you want to run Repomix in an isolated environment or prefer using containers.\n\nBasic usage (current directory):\n\n```bash\ndocker run -v .:/app -it --rm ghcr.io/yamadashy/repomix\n```\n\nTo pack a specific directory:\n\n```bash\ndocker run -v .:/app -it --rm ghcr.io/yamadashy/repomix path/to/directory\n```\n\nProcess a remote repository and output to a `output` directory:\n\n```bash\ndocker run -v ./output:/app -it --rm ghcr.io/yamadashy/repomix --remote https://github.com/yamadashy/repomix\n```\n\n### Prompt Examples\n\nOnce you have generated the packed file with Repomix, you can use it with AI tools like ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more.\nHere are some example prompts to get you started:\n\n#### Code Review and Refactoring\n\nFor a comprehensive code review and refactoring suggestions:\n\n```\nThis file contains my entire codebase. Please review the overall structure and suggest any improvements or refactoring opportunities, focusing on maintainability and scalability.\n```\n\n#### Documentation Generation\n\nTo generate project documentation:\n\n```\nBased on the codebase in this file, please generate a detailed README.md that includes an overview of the project, its main features, setup instructions, and usage examples.\n```\n\n#### Test Case Generation\n\nFor generating test cases:\n\n```\nAnalyze the code in this file and suggest a comprehensive set of unit tests for the main functions and classes. Include edge cases and potential error scenarios.\n```\n\n#### Code Quality Assessment\n\nEvaluate code quality and adherence to best practices:\n\n```\nReview the codebase for adherence to coding best practices and industry standards. Identify areas where the code could be improved in terms of readability, maintainability, and efficiency. Suggest specific changes to align the code with best practices.\n```\n\n#### Library Overview\n\nGet a high-level understanding of the library\n\n```\nThis file contains the entire codebase of library. Please provide a comprehensive overview of the library, including its main purpose, key features, and overall architecture.\n```\n\nFeel free to modify these prompts based on your specific needs and the capabilities of the AI tool you're using.\n\n### Community Discussion\n\nCheck out our [community discussion](https://github.com/yamadashy/repomix/discussions/154) where users share:\n\n- Which AI tools they're using with Repomix\n- Effective prompts they've discovered\n- How Repomix has helped them\n- Tips and tricks for getting the most out of AI code analysis\n\nFeel free to join the discussion and share your own experiences! Your insights could help others make better use of\nRepomix.\n\n### Output File Format\n\nRepomix generates a single file with clear separators between different parts of your codebase.  \nTo enhance AI comprehension, the output file begins with an AI-oriented explanation, making it easier for AI models to\nunderstand the context and structure of the packed repository.\n\n#### XML Format (default)\n\nThe XML format structures the content in a hierarchical manner:\n\n```xml\nThis file is a merged representation of the entire codebase, combining all repository files into a single document.\n\n<file_summary>\n  (Metadata and usage AI instructions)\n</file_summary>\n\n<directory_structure>\nsrc/\ncli/\ncliOutput.ts\nindex.ts\n\n(...remaining directories)\n</directory_structure>\n\n<files>\n<file path=\"src/index.js\">\n  // File contents here\n</file>\n\n(...remaining files)\n</files>\n\n<instruction>\n(Custom instructions from `output.instructionFilePath`)\n</instruction>\n```\n\nFor those interested in the potential of XML tags in AI contexts:  \nhttps://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags\n\n> When your prompts involve multiple components like context, instructions, and examples, XML tags can be a\n> game-changer. They help Claude parse your prompts more accurately, leading to higher-quality outputs.\n\nThis means that the XML output from Repomix is not just a different format, but potentially a more effective way to feed\nyour codebase into AI systems for analysis, code review, or other tasks.\n\n#### Markdown Format\n\nTo generate output in Markdown format, use the `--style markdown` option:\n\n```bash\nrepomix --style markdown\n```\n\nThe Markdown format structures the content in a hierarchical manner:\n\n````markdown\nThis file is a merged representation of the entire codebase, combining all repository files into a single document.\n\n# File Summary\n\n(Metadata and usage AI instructions)\n\n# Repository Structure\n\n```\nsrc/\n  cli/\n    cliOutput.ts\n    index.ts\n```\n\n(...remaining directories)\n\n# Repository Files\n\n## File: src/index.js\n\n```\n// File contents here\n```\n\n(...remaining files)\n\n# Instruction\n\n(Custom instructions from `output.instructionFilePath`)\n````\n\nThis format provides a clean, readable structure that is both human-friendly and easily parseable by AI systems.\n\n#### JSON Format\n\nTo generate output in JSON format, use the `--style json` option:\n\n```bash\nrepomix --style json\n```\n\nThe JSON format structures the content as a hierarchical JSON object with camelCase property names:\n\n```json\n{\n  \"fileSummary\": {\n    \"generationHeader\": \"This file is a merged representation of the entire codebase, combined into a single document by Repomix.\",\n    \"purpose\": \"This file contains a packed representation of the entire repository's contents...\",\n    \"fileFormat\": \"The content is organized as follows...\",\n    \"usageGuidelines\": \"- This file should be treated as read-only...\",\n    \"notes\": \"- Some files may have been excluded based on .gitignore rules...\"\n  },\n  \"userProvidedHeader\": \"Custom header text if specified\",\n  \"directoryStructure\": \"src/\\n  cli/\\n    cliOutput.ts\\n    index.ts\\n  config/\\n    configLoader.ts\",\n  \"files\": {\n    \"src/index.js\": \"// File contents here\",\n    \"src/utils.js\": \"// File contents here\"\n  },\n  \"instruction\": \"Custom instructions from instructionFilePath\"\n}\n```\n\nThis format is ideal for:\n- **Programmatic processing**: Easy to parse and manipulate with JSON libraries\n- **API integration**: Direct consumption by web services and applications  \n- **AI tool compatibility**: Structured format for machine learning and AI systems\n- **Data analysis**: Straightforward extraction of specific information using tools like `jq`\n\n##### Working with JSON Output Using `jq`\n\nThe JSON format makes it easy to extract specific information programmatically:\n\n```bash\n# List all file paths\ncat repomix-output.json | jq -r '.files | keys[]'\n\n# Count total number of files\ncat repomix-output.json | jq '.files | keys | length'\n\n# Extract specific file content\ncat repomix-output.json | jq -r '.files[\"README.md\"]'\ncat repomix-output.json | jq -r '.files[\"src/index.js\"]'\n\n# Find files by extension\ncat repomix-output.json | jq -r '.files | keys[] | select(endswith(\".ts\"))'\n\n# Get files containing specific text\ncat repomix-output.json | jq -r '.files | to_entries[] | select(.value | contains(\"function\")) | .key'\n\n# Extract directory structure\ncat repomix-output.json | jq -r '.directoryStructure'\n\n# Get file summary information\ncat repomix-output.json | jq '.fileSummary.purpose'\ncat repomix-output.json | jq -r '.fileSummary.generationHeader'\n\n# Extract user-provided header (if exists)\ncat repomix-output.json | jq -r '.userProvidedHeader // \"No header provided\"'\n\n# Create a file list with sizes\ncat repomix-output.json | jq -r '.files | to_entries[] | \"\\(.key): \\(.value | length) characters\"'\n```\n\n#### Plain Text Format\n\nTo generate output in plain text format, use the `--style plain` option:\n\n```bash\nrepomix --style plain\n```\n\n```text\nThis file is a merged representation of the entire codebase, combining all repository files into a single document.\n\n================================================================\nFile Summary\n================================================================\n(Metadata and usage AI instructions)\n\n================================================================\nDirectory Structure\n================================================================\nsrc/\n  cli/\n    cliOutput.ts\n    index.ts\n  config/\n    configLoader.ts\n\n(...remaining directories)\n\n================================================================\nFiles\n================================================================\n\n================\nFile: src/index.js\n================\n// File contents here\n\n================\nFile: src/utils.js\n================\n// File contents here\n\n(...remaining files)\n\n================================================================\nInstruction\n================================================================\n(Custom instructions from `output.instructionFilePath`)\n```\n\n### Command Line Options\n\n#### Basic Options\n- `-v, --version`: Show version information and exit\n\n#### CLI Input/Output Options\n- `--verbose`: Enable detailed debug logging (shows file processing, token counts, and configuration details)\n- `--quiet`: Suppress all console output except errors (useful for scripting)\n- `--stdout`: Write packed output directly to stdout instead of a file (suppresses all logging)\n- `--stdin`: Read file paths from stdin, one per line (specified files are processed directly)\n- `--copy`: Copy the generated output to system clipboard after processing\n- `--token-count-tree [threshold]`: Show file tree with token counts; optional threshold to show only files with ‚â•N tokens (e.g., --token-count-tree 100)\n- `--top-files-len <number>`: Number of largest files to show in summary (default: 5, e.g., --top-files-len 20)\n\n#### Repomix Output Options\n- `-o, --output <file>`: Output file path (default: repomix-output.xml, use \"-\" for stdout)\n- `--style <style>`: Output format: xml, markdown, json, or plain (default: xml)\n- `--parsable-style`: Escape special characters to ensure valid XML/Markdown (needed when output contains code that breaks formatting)\n- `--compress`: Extract essential code structure (classes, functions, interfaces) using Tree-sitter parsing\n- `--output-show-line-numbers`: Prefix each line with its line number in the output\n- `--no-file-summary`: Omit the file summary section from output\n- `--no-directory-structure`: Omit the directory tree visualization from output\n- `--no-files`: Generate metadata only without file contents (useful for repository analysis)\n- `--remove-comments`: Strip all code comments before packing\n- `--remove-empty-lines`: Remove blank lines from all files\n- `--truncate-base64`: Truncate long base64 data strings to reduce output size\n- `--header-text <text>`: Custom text to include at the beginning of the output\n- `--instruction-file-path <path>`: Path to file containing custom instructions to include in output\n- `--include-empty-directories`: Include folders with no files in directory structure\n- `--no-git-sort-by-changes`: Don't sort files by git change frequency (default: most changed files first)\n- `--include-diffs`: Add git diff section showing working tree and staged changes\n- `--include-logs`: Add git commit history with messages and changed files\n- `--include-logs-count <count>`: Number of recent commits to include with --include-logs (default: 50)\n\n#### File Selection Options\n- `--include <patterns>`: Include only files matching these glob patterns (comma-separated, e.g., \"src/**/*.js,*.md\")\n- `-i, --ignore <patterns>`: Additional patterns to exclude (comma-separated, e.g., \"*.test.js,docs/**\")\n- `--no-gitignore`: Don't use .gitignore rules for filtering files\n- `--no-default-patterns`: Don't apply built-in ignore patterns (node_modules, .git, build dirs, etc.)\n\n#### Remote Repository Options\n- `--remote <url>`: Clone and pack a remote repository (GitHub URL or user/repo format)\n- `--remote-branch <name>`: Specific branch, tag, or commit to use (default: repository's default branch)\n\n#### Configuration Options\n- `-c, --config <path>`: Use custom config file instead of repomix.config.json\n- `--init`: Create a new repomix.config.json file with defaults\n- `--global`: With --init, create config in home directory instead of current directory\n\n#### Security Options\n- `--no-security-check`: Skip scanning for sensitive data like API keys and passwords\n\n#### Token Count Options\n- `--token-count-encoding <encoding>`: Tokenizer model for counting: o200k_base (GPT-4o), cl100k_base (GPT-3.5/4), etc. (default: o200k_base)\n\n#### MCP\n- `--mcp`: Run as Model Context Protocol server for AI tool integration\n\n#### Examples\n\n```bash\n# Basic usage\nrepomix\n\n# Custom output\nrepomix -o output.xml --style xml\n\n# Output to stdout\nrepomix --stdout > custom-output.txt\n\n# Send output to stdout, then pipe into another command (for example, simonw/llm)\nrepomix --stdout | llm \"Please explain what this code does.\"\n\n# Custom output with compression\nrepomix --compress\n\n# Process specific files\nrepomix --include \"src/**/*.ts\" --ignore \"**/*.test.ts\"\n\n# Remote repository with branch\nrepomix --remote https://github.com/user/repo/tree/main\n\n# Remote repository with commit\nrepomix --remote https://github.com/user/repo/commit/836abcd7335137228ad77feb28655d85712680f1\n\n# Remote repository with shorthand\nrepomix --remote user/repo\n```\n\n### Updating Repomix\n\nTo update a globally installed Repomix:\n\n```bash\n# Using npm\nnpm update -g repomix\n\n# Using yarn\nyarn global upgrade repomix\n\n# Using bun\nbun update -g repomix\n```\n\nUsing `npx repomix` is generally more convenient as it always uses the latest version.\n\n### Remote Repository Processing\n\nRepomix supports processing remote Git repositories without the need for manual cloning. This feature allows you to\nquickly analyze any public Git repository with a single command.\n\nTo process a remote repository, use the `--remote` option followed by the repository URL:\n\n```bash\nrepomix --remote https://github.com/yamadashy/repomix\n```\n\nYou can also use GitHub's shorthand format:\n\n```bash\nrepomix --remote yamadashy/repomix\n```\n\nYou can specify the branch name, tag, or commit hash:\n\n```bash\n# Using --remote-branch option\nrepomix --remote https://github.com/yamadashy/repomix --remote-branch main\n\n# Using branch's URL\nrepomix --remote https://github.com/yamadashy/repomix/tree/main\n```\n\nOr use a specific commit hash:\n\n```bash\n# Using --remote-branch option\nrepomix --remote https://github.com/yamadashy/repomix --remote-branch 935b695\n\n# Using commit's URL\nrepomix --remote https://github.com/yamadashy/repomix/commit/836abcd7335137228ad77feb28655d85712680f1\n```\n\n### Code Compression\n\nThe `--compress` option utilizes [Tree-sitter](https://github.com/tree-sitter/tree-sitter) to perform intelligent code extraction, focusing on essential function and class signatures while removing implementation details. This can help reduce token count while retaining important structural information.\n\n```bash\nrepomix --compress\n```\n\nFor example, this code:\n\n```typescript\nimport { ShoppingItem } from './shopping-item';\n\n/**\n * Calculate the total price of shopping items\n */\nconst calculateTotal = (\n  items: ShoppingItem[]\n) => {\n  let total = 0;\n  for (const item of items) {\n    total += item.price * item.quantity;\n  }\n  return total;\n}\n\n// Shopping item interface\ninterface Item {\n  name: string;\n  price: number;\n  quantity: number;\n}\n```\n\nWill be compressed to:\n\n```typescript\nimport { ShoppingItem } from './shopping-item';\n‚ãÆ----\n/**\n * Calculate the total price of shopping items\n */\nconst calculateTotal = (\n  items: ShoppingItem[]\n) => {\n‚ãÆ----\n// Shopping item interface\ninterface Item {\n  name: string;\n  price: number;\n  quantity: number;\n}\n```\n\n> [!NOTE]\n> This is an experimental feature that we'll be actively improving based on user feedback and real-world usage\n\n### Token Count Optimization\n\nUnderstanding your codebase's token distribution is crucial for optimizing AI interactions. Use the `--token-count-tree` option to visualize token usage across your project:\n\n```bash\nrepomix --token-count-tree\n```\n\nThis displays a hierarchical view of your codebase with token counts:\n\n```\nüî¢ Token Count Tree:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îî‚îÄ‚îÄ src/ (70,925 tokens)\n    ‚îú‚îÄ‚îÄ cli/ (12,714 tokens)\n    ‚îÇ   ‚îú‚îÄ‚îÄ actions/ (7,546 tokens)\n    ‚îÇ   ‚îî‚îÄ‚îÄ reporters/ (990 tokens)\n    ‚îî‚îÄ‚îÄ core/ (41,600 tokens)\n        ‚îú‚îÄ‚îÄ file/ (10,098 tokens)\n        ‚îî‚îÄ‚îÄ output/ (5,808 tokens)\n```\n\nYou can also set a minimum token threshold to focus on larger files:\n\n```bash\nrepomix --token-count-tree 1000  # Only show files/directories with 1000+ tokens\n```\n\nThis helps you:\n- **Identify token-heavy files** that might exceed AI context limits\n- **Optimize file selection** using `--include` and `--ignore` patterns  \n- **Plan compression strategies** by targeting the largest contributors\n- **Balance content vs. context** when preparing code for AI analysis\n\n### MCP Server Integration\n\nRepomix supports the [Model Context Protocol (MCP)](https://modelcontextprotocol.io), allowing AI assistants to directly interact with your codebase. When run as an MCP server, Repomix provides tools that enable AI assistants to package local or remote repositories for analysis without requiring manual file preparation.\n\n```bash\nrepomix --mcp\n```\n\n#### Configuring MCP Servers\n\nTo use Repomix as an MCP server with AI assistants like Claude, you need to configure the MCP settings:\n\n**For VS Code:**\n\nYou can install the Repomix MCP server in VS Code using one of these methods:\n\n1. **Using the Install Badge:**\n\n  [![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=repomix&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22repomix%22%2C%22--mcp%22%5D%7D)\n  [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=repomix&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22repomix%22%2C%22--mcp%22%5D%7D&quality=insiders)\n\n2. **Using the Command Line:**\n\n  ```bash\n  code --add-mcp '{\"name\":\"repomix\",\"command\":\"npx\",\"args\":[\"-y\",\"repomix\",\"--mcp\"]}'\n  ```\n\n  For VS Code Insiders:\n  ```bash\n  code-insiders --add-mcp '{\"name\":\"repomix\",\"command\":\"npx\",\"args\":[\"-y\",\"repomix\",\"--mcp\"]}'\n  ```\n\n**For Cline (VS Code extension):**\n\nEdit the `cline_mcp_settings.json` file:\n```json\n{\n  \"mcpServers\": {\n    \"repomix\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"repomix\",\n        \"--mcp\"\n      ]\n    }\n  }\n}\n```\n\n**For Cursor:**\n\nIn Cursor, add a new MCP server from `Cursor Settings` > `MCP` > `+ Add new global MCP server` with a configuration similar to Cline.\n\n**For Claude Desktop:**\n\nEdit the `claude_desktop_config.json` file with similar configuration to Cline's config.\n\n**For Claude Code:**\n\nTo configure Repomix as an MCP server in [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview), use the following command:\n\n```bash\nclaude mcp add repomix -- npx -y repomix --mcp\n```\n\n**Using Docker instead of npx:**\n\nYou can use Docker as an alternative to npx for running Repomix as an MCP server:\n\n```json\n{\n  \"mcpServers\": {\n    \"repomix-docker\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"ghcr.io/yamadashy/repomix\",\n        \"--mcp\"\n      ]\n    }\n  }\n}\n```\n\nOnce configured, your AI assistant can directly use Repomix's capabilities to analyze codebases without manual file preparation, making code analysis workflows more efficient.\n\n#### Available MCP Tools\n\nWhen running as an MCP server, Repomix provides the following tools:\n\n1. **pack_codebase**: Package a local code directory into a consolidated XML file for AI analysis\n  - Parameters:\n    - `directory`: Absolute path to the directory to pack\n    - `compress`: (Optional, default: false) Enable Tree-sitter compression to extract essential code signatures and structure while removing implementation details. Reduces token usage by ~70% while preserving semantic meaning. Generally not needed since grep_repomix_output allows incremental content retrieval. Use only when you specifically need the entire codebase content for large repositories.\n    - `includePatterns`: (Optional) Specify files to include using fast-glob patterns. Multiple patterns can be comma-separated (e.g., \"**/*.{js,ts}\", \"src/**,docs/**\"). Only matching files will be processed.\n    - `ignorePatterns`: (Optional) Specify additional files to exclude using fast-glob patterns. Multiple patterns can be comma-separated (e.g., \"test/**,*.spec.js\", \"node_modules/**,dist/**\"). These patterns supplement .gitignore and built-in exclusions.\n    - `topFilesLength`: (Optional, default: 10) Number of largest files by size to display in the metrics summary for codebase analysis.\n\n2. **attach_packed_output**: Attach an existing Repomix packed output file for AI analysis\n  - Parameters:\n    - `path`: Path to a directory containing repomix-output.xml or direct path to a packed repository XML file\n    - `topFilesLength`: (Optional, default: 10) Number of largest files by size to display in the metrics summary\n  - Features:\n    - Accepts either a directory containing a repomix-output.xml file or a direct path to an XML file\n    - Registers the file with the MCP server and returns the same structure as the pack_codebase tool\n    - Provides secure access to existing packed outputs without requiring re-processing\n    - Useful for working with previously generated packed repositories\n\n3. **pack_remote_repository**: Fetch, clone, and package a GitHub repository into a consolidated XML file for AI analysis\n  - Parameters:\n    - `remote`: GitHub repository URL or user/repo format (e.g., \"yamadashy/repomix\", \"https://github.com/user/repo\", or \"https://github.com/user/repo/tree/branch\")\n    - `compress`: (Optional, default: false) Enable Tree-sitter compression to extract essential code signatures and structure while removing implementation details. Reduces token usage by ~70% while preserving semantic meaning. Generally not needed since grep_repomix_output allows incremental content retrieval. Use only when you specifically need the entire codebase content for large repositories.\n    - `includePatterns`: (Optional) Specify files to include using fast-glob patterns. Multiple patterns can be comma-separated (e.g., \"**/*.{js,ts}\", \"src/**,docs/**\"). Only matching files will be processed.\n    - `ignorePatterns`: (Optional) Specify additional files to exclude using fast-glob patterns. Multiple patterns can be comma-separated (e.g., \"test/**,*.spec.js\", \"node_modules/**,dist/**\"). These patterns supplement .gitignore and built-in exclusions.\n    - `topFilesLength`: (Optional, default: 10) Number of largest files by size to display in the metrics summary for codebase analysis.\n\n4. **read_repomix_output**: Read the contents of a Repomix-generated output file. Supports partial reading with line range specification for large files.\n  - Parameters:\n    - `outputId`: ID of the Repomix output file to read\n    - `startLine`: (Optional) Starting line number (1-based, inclusive). If not specified, reads from beginning.\n    - `endLine`: (Optional) Ending line number (1-based, inclusive). If not specified, reads to end.\n  - Features:\n    - Specifically designed for web-based environments or sandboxed applications\n    - Retrieves the content of previously generated outputs using their ID\n    - Provides secure access to packed codebase without requiring file system access\n    - Supports partial reading for large files\n\n5. **grep_repomix_output**: Search for patterns in a Repomix output file using grep-like functionality with JavaScript RegExp syntax\n  - Parameters:\n    - `outputId`: ID of the Repomix output file to search\n    - `pattern`: Search pattern (JavaScript RegExp regular expression syntax)\n    - `contextLines`: (Optional, default: 0) Number of context lines to show before and after each match. Overridden by beforeLines/afterLines if specified.\n    - `beforeLines`: (Optional) Number of context lines to show before each match (like grep -B). Takes precedence over contextLines.\n    - `afterLines`: (Optional) Number of context lines to show after each match (like grep -A). Takes precedence over contextLines.\n    - `ignoreCase`: (Optional, default: false) Perform case-insensitive matching\n  - Features:\n    - Uses JavaScript RegExp syntax for powerful pattern matching\n    - Supports context lines for better understanding of matches\n    - Allows separate control of before/after context lines\n    - Case-sensitive and case-insensitive search options\n\n6. **file_system_read_file**: Read a file from the local file system using an absolute path. Includes built-in security validation to detect and prevent access to files containing sensitive information.\n  - Parameters:\n    - `path`: Absolute path to the file to read\n  - Security features:\n    - Implements security validation using [Secretlint](https://github.com/secretlint/secretlint)\n    - Prevents access to files containing sensitive information (API keys, passwords, secrets)\n    - Validates absolute paths to prevent directory traversal attacks\n\n7. **file_system_read_directory**: List the contents of a directory using an absolute path. Returns a formatted list showing files and subdirectories with clear indicators.\n  - Parameters:\n    - `path`: Absolute path to the directory to list\n  - Features:\n    - Shows files and directories with clear indicators (`[FILE]` or `[DIR]`)\n    - Provides safe directory traversal with proper error handling\n    - Validates paths and ensures they are absolute\n    - Useful for exploring project structure and understanding codebase organization\n\n## ‚öôÔ∏è Configuration\n\nCreate a `repomix.config.json` file in your project root for custom configurations.\n\n```bash\nrepomix --init\n```\n\nHere's an explanation of the configuration options:\n\n| Option                           | Description                                                                                                                  | Default                |\n|----------------------------------|------------------------------------------------------------------------------------------------------------------------------|------------------------|\n| `input.maxFileSize`              | Maximum file size in bytes to process. Files larger than this will be skipped                                                | `50000000`            |\n| `output.filePath`                | The name of the output file                                                                                                  | `\"repomix-output.xml\"` |\n| `output.style`                   | The style of the output (`xml`, `markdown`, `json`, `plain`)                                                                 | `\"xml\"`                |\n| `output.parsableStyle`           | Whether to escape the output based on the chosen style schema. Note that this can increase token count.                      | `false`                |\n| `output.compress`                | Whether to perform intelligent code extraction to reduce token count                                                         | `false`                |\n| `output.headerText`              | Custom text to include in the file header                                                                                    | `null`                 |\n| `output.instructionFilePath`     | Path to a file containing detailed custom instructions                                                                       | `null`                 |\n| `output.fileSummary`             | Whether to include a summary section at the beginning of the output                                                          | `true`                 |\n| `output.directoryStructure`      | Whether to include the directory structure in the output                                                                     | `true`                 |\n| `output.files`                   | Whether to include file contents in the output                                                                               | `true`                 |\n| `output.removeComments`          | Whether to remove comments from supported file types                                                                         | `false`                |\n| `output.removeEmptyLines`        | Whether to remove empty lines from the output                                                                                | `false`                |\n| `output.showLineNumbers`         | Whether to add line numbers to each line in the output                                                                       | `false`                |\n| `output.truncateBase64`          | Whether to truncate long base64 data strings (e.g., images) to reduce token count                                            | `false`                |\n| `output.copyToClipboard`         | Whether to copy the output to system clipboard in addition to saving the file                                                | `false`                |\n| `output.topFilesLength`          | Number of top files to display in the summary. If set to 0, no summary will be displayed                                     | `5`                    |\n| `output.tokenCountTree`          | Whether to display file tree with token count summaries. Can be boolean or number (minimum token count threshold)           | `false`                |\n| `output.includeEmptyDirectories` | Whether to include empty directories in the repository structure                                                             | `false`                |\n| `output.git.sortByChanges`       | Whether to sort files by git change count (files with more changes appear at the bottom)                                     | `true`                 |\n| `output.git.sortByChangesMaxCommits` | Maximum number of commits to analyze for git changes                                                                     | `100`                  |\n| `output.git.includeDiffs`       | Whether to include git diffs in the output (includes both work tree and staged changes separately)                          | `false`                |\n| `output.git.includeLogs`        | Whether to include git logs in the output (includes commit history with dates, messages, and file paths)                   | `false`                |\n| `output.git.includeLogsCount`   | Number of git log commits to include                                                                                         | `50`                   |\n| `include`                        | Patterns of files to include (using [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax))  | `[]`                   |\n| `ignore.useGitignore`            | Whether to use patterns from the project's `.gitignore` file                                                                 | `true`                 |\n| `ignore.useDefaultPatterns`      | Whether to use default ignore patterns                                                                                       | `true`                 |\n| `ignore.customPatterns`          | Additional patterns to ignore (using [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax)) | `[]`                   |\n| `security.enableSecurityCheck`   | Whether to perform security checks on files                                                                                  | `true`                 |\n| `tokenCount.encoding`            | Token count encoding used by OpenAI's [tiktoken](https://github.com/openai/tiktoken) tokenizer (e.g., `o200k_base` for GPT-4o, `cl100k_base` for GPT-4/3.5). See [tiktoken model.py](https://github.com/openai/tiktoken/blob/main/tiktoken/model.py#L24) for encoding details. | `\"o200k_base\"`         |\n\nThe configuration file supports [JSON5](https://json5.org/) syntax, which allows:\n- Comments (both single-line and multi-line)\n- Trailing commas in objects and arrays\n- Unquoted property names\n- More relaxed string syntax\n\nExample configuration:\n\n```json5\n{\n  \"input\": {\n    \"maxFileSize\": 50000000\n  },\n  \"output\": {\n    \"filePath\": \"repomix-output.xml\",\n    \"style\": \"xml\",\n    \"parsableStyle\": false,\n    \"compress\": false,\n    \"headerText\": \"Custom header information for the packed file.\",\n    \"fileSummary\": true,\n    \"directoryStructure\": true,\n    \"files\": true,\n    \"removeComments\": false,\n    \"removeEmptyLines\": false,\n    \"topFilesLength\": 5,\n    \"tokenCountTree\": false, // or true, or a number like 10 for minimum token threshold\n    \"showLineNumbers\": false,\n    \"truncateBase64\": false,\n    \"copyToClipboard\": false,\n    \"includeEmptyDirectories\": false,\n    \"git\": {\n      \"sortByChanges\": true,\n      \"sortByChangesMaxCommits\": 100,\n      \"includeDiffs\": false,\n      \"includeLogs\": false,\n      \"includeLogsCount\": 50\n    }\n  },\n  \"include\": [\"**/*\"],\n  \"ignore\": {\n    \"useGitignore\": true,\n    \"useDefaultPatterns\": true,\n    // Patterns can also be specified in .repomixignore\n    \"customPatterns\": [\n      \"additional-folder\",\n      \"**/*.log\"\n    ],\n  },\n  \"security\": {\n    \"enableSecurityCheck\": true\n  },\n  \"tokenCount\": {\n    \"encoding\": \"o200k_base\"\n  }\n}\n```\n\n### Global Configuration\n\nTo create a global configuration file:\n\n```bash\nrepomix --init --global\n```\n\nThe global configuration file will be created in:\n\n- Windows: `%LOCALAPPDATA%\\Repomix\\repomix.config.json`\n- macOS/Linux: `$XDG_CONFIG_HOME/repomix/repomix.config.json` or `~/.config/repomix/repomix.config.json`\n\nNote: Local configuration (if present) takes precedence over global configuration.\n\n### Include and Ignore\n\n#### Include Patterns\n\nRepomix now supports specifying files to include\nusing [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax). This allows for more\nflexible and powerful file selection:\n\n- Use `**/*.js` to include all JavaScript files in any directory\n- Use `src/**/*` to include all files within the `src` directory and its subdirectories\n- Combine multiple patterns like `[\"src/**/*.js\", \"**/*.md\"]` to include JavaScript files in `src` and all Markdown\n  files\n\n#### Ignore Patterns\n\nRepomix offers multiple methods to set ignore patterns for excluding specific files or directories during the packing\nprocess:\n\n- **.gitignore**: By default, patterns listed in your project's `.gitignore` files and `.git/info/exclude` are used. This behavior can be controlled with the `ignore.useGitignore` setting or the `--no-gitignore` cli option.\n- **Default patterns**: Repomix includes a default list of commonly excluded files and directories (e.g., node_modules,\n  .git, binary files). This feature can be controlled with the `ignore.useDefaultPatterns` setting or the `--no-default-patterns` cli option. Please\n  see [defaultIgnore.ts](src/config/defaultIgnore.ts) for more details.\n- **.repomixignore**: You can create a `.repomixignore` file in your project root to define Repomix-specific ignore\n  patterns. This file follows the same format as `.gitignore`.\n- **Custom patterns**: Additional ignore patterns can be specified using the `ignore.customPatterns` option in the\n  configuration file. You can overwrite this setting with the `-i, --ignore` command line option.\n\nPriority Order (from highest to lowest):\n\n1. Custom patterns `ignore.customPatterns`\n2. `.repomixignore`\n3. `.gitignore` and `.git/info/exclude` (if `ignore.useGitignore` is true and `--no-gitignore` is not used)\n4. Default patterns (if `ignore.useDefaultPatterns` is true and `--no-default-patterns` is not used)\n\nThis approach allows for flexible file exclusion configuration based on your project's needs. It helps optimize the size\nof the generated pack file by ensuring the exclusion of security-sensitive files and large binary files, while\npreventing the leakage of confidential information.\n\nNote: Binary files are not included in the packed output by default, but their paths are listed in the \"Repository\nStructure\" section of the output file. This provides a complete overview of the repository structure while keeping the\npacked file efficient and text-based.\n\n### Custom Instruction\n\nThe `output.instructionFilePath` option allows you to specify a separate file containing detailed instructions or\ncontext about your project. This allows AI systems to understand the specific context and requirements of your project,\npotentially leading to more relevant and tailored analysis or suggestions.\n\nHere's an example of how you might use this feature:\n\n1. Create a file named `repomix-instruction.md` in your project root:\n\n```markdown\n# Coding Guidelines\n\n- Follow the Airbnb JavaScript Style Guide\n- Suggest splitting files into smaller, focused units when appropriate\n- Add comments for non-obvious logic. Keep all text in English\n- All new features should have corresponding unit tests\n\n# Generate Comprehensive Output\n\n- Include all content without abbreviation, unless specified otherwise\n- Optimize for handling large codebases while maintaining output quality\n```\n\n2. In your `repomix.config.json`, add the `instructionFilePath` option:\n\n```json5\n{\n  \"output\": {\n    \"instructionFilePath\": \"repomix-instruction.md\",\n    // other options...\n  }\n}\n```\n\nWhen Repomix generates the output, it will include the contents of `repomix-instruction.md` in a dedicated section.\n\nNote: The instruction content is appended at the end of the output file. This placement can be particularly effective\nfor AI systems. For those interested in understanding why this might be beneficial, Anthropic provides some insights in\ntheir documentation:  \nhttps://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips\n\n> Put long-form data at the top: Place your long documents and inputs (~20K+ tokens) near the top of your prompt, above\n> your query, instructions, and examples. This can significantly improve Claude's performance across all models.\n> Queries at the end can improve response quality by up to 30% in tests, especially with complex, multi-document inputs.\n\n### Comment Removal\n\nWhen `output.removeComments` is set to `true`, Repomix will attempt to remove comments from supported file types. This\nfeature can help reduce the size of the output file and focus on the essential code content.\n\nSupported languages include:  \nHTML, CSS, JavaScript, TypeScript, Vue, Svelte, Python, PHP, Ruby, C, C#, Java, Go, Rust, Swift, Kotlin, Dart, Shell,\nand YAML.\n\nNote: The comment removal process is conservative to avoid accidentally removing code. In complex cases, some comments\nmight be retained.\n\n## üîç Security Check\n\nRepomix includes a security check feature that uses [Secretlint](https://github.com/secretlint/secretlint) to detect\npotentially sensitive information in your files. This feature helps you identify possible security risks before sharing\nyour packed repository.\n\nThe security check results will be displayed in the CLI output after the packing process is complete. If any suspicious\nfiles are detected, you'll see a list of these files along with a warning message.\n\nExample output:\n\n```\nüîç Security Check:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n2 suspicious file(s) detected:\n1. src/utils/test.txt\n2. tests/utils/secretLintUtils.test.ts\n\nPlease review these files for potentially sensitive information.\n```\n\nBy default, Repomix's security check feature is enabled. You can disable it by setting `security.enableSecurityCheck` to\n`false` in your configuration file:\n\n```json\n{\n  \"security\": {\n    \"enableSecurityCheck\": false\n  }\n}\n```\n\nOr using the `--no-security-check` command line option:\n\n```bash\nrepomix --no-security-check\n```\n\n> [!NOTE]\n> Disabling security checks may expose sensitive information. Use this option with caution and only when necessary, such\n> as when working with test files or documentation that contains example credentials.\n\n## ü§ñ Using Repomix with GitHub Actions\n\nYou can also use Repomix in your GitHub Actions workflows. This is useful for automating the process of packing your codebase for AI analysis.\n\nBasic usage:\n\n```yaml\n- name: Pack repository with Repomix\n  uses: yamadashy/repomix/.github/actions/repomix@main\n  with:\n    output: repomix-output.xml\n    style: xml\n```\n\nUse `--style` to generate output in different formats:\n\n```yaml\n- name: Pack repository with Repomix\n  uses: yamadashy/repomix/.github/actions/repomix@main\n  with:\n    output: repomix-output.md\n    style: markdown\n```\n\n```yaml\n- name: Pack repository with Repomix (JSON format)\n  uses: yamadashy/repomix/.github/actions/repomix@main\n  with:\n    output: repomix-output.json\n    style: json\n```\n\nPack specific directories with compression:\n\n```yaml\n- name: Pack repository with Repomix\n  uses: yamadashy/repomix/.github/actions/repomix@main\n  with:\n    directories: src tests\n    include: \"**/*.ts,**/*.md\"\n    ignore: \"**/*.test.ts\"\n    output: repomix-output.txt\n    compress: true\n```\n\nUpload the output file as an artifact:\n\n```yaml\n- name: Pack repository with Repomix\n  uses: yamadashy/repomix/.github/actions/repomix@main\n  with:\n    directories: src\n    output: repomix-output.txt\n    compress: true\n\n- name: Upload Repomix output\n  uses: actions/upload-artifact@v4\n  with:\n    name: repomix-output\n    path: repomix-output.txt\n```\n\nComplete workflow example:\n\n```yaml\nname: Pack repository with Repomix\n\non:\n  workflow_dispatch:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  pack-repo:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Pack repository with Repomix\n        uses: yamadashy/repomix/.github/actions/repomix@main\n        with:\n          output: repomix-output.xml\n\n      - name: Upload Repomix output\n        uses: actions/upload-artifact@v4\n        with:\n          name: repomix-output.xml\n          path: repomix-output.xml\n          retention-days: 30\n```\n\nSee the complete workflow example [here](https://github.com/yamadashy/repomix/blob/main/.github/workflows/pack-repository.yml).\n\n### Action Inputs\n\n| Name | Description | Default |\n|------|-------------|---------|\n| `directories` | Space-separated list of directories to process (e.g., `src tests docs`) | `.` |\n| `include` | Comma-separated glob patterns to include files (e.g., `**/*.ts,**/*.md`) | `\"\"` |\n| `ignore` | Comma-separated glob patterns to ignore files (e.g., `**/*.test.ts,**/node_modules/**`) | `\"\"` |\n| `output` | Relative path for the packed file (extension determines format: `.txt`, `.md`, `.xml`) | `repomix-output.xml` |\n| `compress` | Enable smart compression to reduce output size by pruning implementation details | `true` |\n| `style` | Output style (`xml`, `markdown`, `json`, `plain`) | `xml` |\n| `additional-args` | Extra raw arguments for the repomix CLI (e.g., `--no-file-summary --no-security-check`) | `\"\"` |\n| `repomix-version` | Version of the npm package to install (supports semver ranges, tags, or specific versions like `0.2.25`) | `latest` |\n\n### Action Outputs\n\n| Name | Description |\n|------|-------------|\n| `output_file` | Path to the generated output file. Can be used in subsequent steps for artifact upload, LLM processing, or other operations. The file contains a formatted representation of your codebase based on the specified options. |\n\n## üìö Using Repomix as a Library\n\nIn addition to using Repomix as a CLI tool, you can also use it as a library in your Node.js applications.\n\n### Installation\n\n```bash\nnpm install repomix\n```\n\n### Basic Usage\n\n```javascript\nimport { runCli, type CliOptions } from 'repomix';\n\n// Process current directory with custom options\nasync function packProject() {\n  const options = {\n    output: 'output.xml',\n    style: 'xml',\n    compress: true,\n    quiet: true\n  } as CliOptions;\n  \n  const result = await runCli(['.'], process.cwd(), options);\n  return result.packResult;\n}\n```\n\n### Process Remote Repository\n\n```javascript\nimport { runCli, type CliOptions } from 'repomix';\n\n// Clone and process a GitHub repo\nasync function processRemoteRepo(repoUrl) {\n  const options = {\n    remote: repoUrl,\n    output: 'output.xml',\n    compress: true\n  } as CliOptions;\n  \n  return await runCli(['.'], process.cwd(), options);\n}\n```\n\n### Using Core Components\n\nIf you need more control, you can use the low-level APIs:\n\n```javascript\nimport { searchFiles, collectFiles, processFiles, TokenCounter } from 'repomix';\n\nasync function analyzeFiles(directory) {\n  // Find and collect files\n  const { filePaths } = await searchFiles(directory, { /* config */ });\n  const rawFiles = await collectFiles(filePaths, directory);\n  const processedFiles = await processFiles(rawFiles, { /* config */ });\n  \n  // Count tokens\n  const tokenCounter = new TokenCounter('o200k_base');\n  \n  // Return analysis results\n  return processedFiles.map(file => ({\n    path: file.path,\n    tokens: tokenCounter.countTokens(file.content)\n  }));\n}\n```\n\nFor more examples, check the source code at [website/server/src/remoteRepo.ts](https://github.com/yamadashy/repomix/blob/main/website/server/src/remoteRepo.ts) which demonstrates how repomix.com uses the library.\n\n## ü§ù Contribution\n\nWe welcome contributions from the community! To get started, please refer to our [Contributing Guide](CONTRIBUTING.md).\n\n### Contributors\n\n<a href=\"https://github.com/yamadashy/repomix/graphs/contributors\">\n  <img alt=\"contributors\" src=\"https://contrib.rocks/image?repo=yamadashy/repomix\"/>\n</a>\n\n## üîí Privacy Policy\n\n### Repomix CLI Tool\n\n- **Data Collection**: The Repomix CLI tool does **not** collect, transmit, or store any user data, telemetry, or repository information.\n- **Network Usage**: Repomix CLI operates fully offline after installation. The only cases where an internet connection is needed are:\n  - Installation via npm/yarn.\n  - Using the `--remote` flag to process remote repositories.\n  - Checking for updates (manually triggered).\n- **Security Considerations**: Since all processing is local, Repomix CLI is safe to use with private and internal repositories.\n\n### Repomix Website ([repomix.com](https://repomix.com/))\n\n- **Data Collection**: The Repomix website uses **Google Analytics** to collect usage data, such as page views and user interactions. This helps us understand how the website is used and improve the user experience.\n- **File Processing**: When uploading ZIP files or folders, your files are temporarily stored on our servers for processing. All uploaded files and processed data are automatically deleted immediately after processing is complete.\n\n### Repomix Browser Extension\n\n- **Data Collection**: The Repomix browser extension does **not** collect, transmit, or store any user data, telemetry, or repository information.\n- **Permissions**: The extension only requires minimal permissions necessary to add the Repomix button to GitHub repository pages. It does not access or modify repository data.\n\n### Liability Disclaimer\n\nRepomix (the CLI tool, website, and browser extension) is provided \"as is\" without any warranties or guarantees.  \nWe do not take responsibility for how the generated output is used, including but not limited to its accuracy, legality, or any potential consequences arising from its use.\n\n## üìú License\n\nThis project is licensed under the [MIT License](LICENSE).\n\n<p align=\"center\">\n  &nbsp;&nbsp;&nbsp;\n  <a href=\"#repo-content-pjax-container\" target=\"_blank\">\n    Back To Top\n  </a>\n</p>\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/repomix",
          "npm_downloads": 622821,
          "npm_package_name": "repomix",
          "npm_success": true,
          "npm_error": null
        }
      }
    },
    "web-search": {
      "category": "web-search",
      "categoryDisplay": "Web Search",
      "description": "",
      "totalRepositories": 66,
      "repositories": {
        "153913232a--webpack-vue": {
          "owner": "153913232a",
          "name": "webpack-vue",
          "url": "https://github.com/153913232a/webpack-vue",
          "imageUrl": "https://github.com/153913232a.png",
          "description": "This server is a Vue.js application designed to mimic the CNode community, allowing users to create and explore posts in a dedicated test area. It's equipped with a modern development setup using webpack, making it easy to run and modify.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:57.252115",
          "collection_timestamp": "2025-10-02T15:02:25.091528",
          "stars": 2,
          "forks": 1,
          "license": "No License",
          "language": "Vue",
          "created_at": "2018-12-27T10:31:27Z",
          "updated_at": "2025-05-03T12:03:54Z",
          "open_issues": 0,
          "readme_content": "# webpack-vue\nËøôÊòØ‰∏Ä‰∏™Ê®°‰ªøcnodeÁ§æÂå∫ÂÅöÁöÑ‰∏Ä‰∏™appÔºåÂú®Á∫øÈ¢ÑËßàÔºöhttp://47.112.16.176\n‰ΩøÁî®webpack + vueÔºåÂ¶ÇÊûúÊÉ≥Â∞ùËØïÂàõÂª∫Â∏ñÂ≠êËØ∑Âú®ÊµãËØïÂå∫ÂàõÂª∫ÔºÅÔºÅÔºÅ\nÂºÄÂßãÊó∂ÂÖànpm install‰æùËµñ‰∏Ä‰∏ãÁõ∏ÂÖ≥ÂåÖ\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/webpack-vue",
          "npm_downloads": 64,
          "npm_package_name": "webpack-vue",
          "npm_success": true,
          "npm_error": null
        },
        "34892002--bilibili-mcp-js": {
          "owner": "34892002",
          "name": "bilibili-mcp-js",
          "url": "https://github.com/34892002/bilibili-mcp-js",
          "imageUrl": "https://github.com/34892002.png",
          "description": "The Bilibili MCP server allows users to search for videos on Bilibili, a popular Chinese video-sharing platform. It provides a straightforward API for retrieving video details such as titles, authors, view counts, and durations.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:58.581532",
          "collection_timestamp": "2025-10-02T15:02:32.630462",
          "stars": 119,
          "forks": 22,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-24T10:27:50Z",
          "updated_at": "2025-09-17T11:31:19Z",
          "open_issues": 4,
          "readme_content": "# Bilibili MCP\n\n[![English](https://img.shields.io/badge/English-Click-yellow)](README-en.md)\n[![‰∏≠ÊñáÊñáÊ°£](https://img.shields.io/badge/‰∏≠ÊñáÊñáÊ°£-ÁÇπÂáªÊü•Áúã-orange)](README.md)\n[![Êó•Êú¨Ë™û](https://img.shields.io/badge/Êó•Êú¨Ë™û-„ÇØ„É™„ÉÉ„ÇØ-Èùí)](README-ja.md)\n\n## ÁÆÄ‰ªã\nËøôÊòØ‰∏Ä‰∏™Âü∫‰∫é Model Context Protocol (MCP) ÁöÑ BÁ´ôËßÜÈ¢ëÊêúÁ¥¢ÊúçÂä°Âô®„ÄÇËØ•ÊúçÂä°Âô®Êèê‰æõ‰∫ÜÁÆÄÂçïÁöÑ API Êé•Âè£ÔºåÂÖÅËÆ∏Áî®Êà∑ÊêúÁ¥¢ BÁ´ô ÁöÑËßÜÈ¢ëÂÜÖÂÆπ„ÄÇÊèê‰æõLangChainË∞ÉÁî®Á§∫‰æã„ÄÅÊµãËØïËÑöÊú¨„ÄÇ\n\n## È∏£Ë∞¢\n- LangChain Á§∫‰æã‰ª£Á†ÅÂèÇËÄÉËá™ [mcp-langchain-ts-client](https://github.com/isaacwasserman/mcp-langchain-ts-client)\n\n## ÂäüËÉΩÁâπÁÇπ\n- BÁ´ôËßÜÈ¢ëÊêúÁ¥¢\n- ÊîØÊåÅÂàÜÈ°µÊü•ËØ¢\n- ËøîÂõûËßÜÈ¢ë‰ø°ÊÅØÔºàÊ†áÈ¢ò„ÄÅ‰ΩúËÄÖ„ÄÅÊí≠ÊîæÈáè„ÄÅÊó∂ÈïøÁ≠âÔºâ\n- Âü∫‰∫é MCP ÂçèËÆÆÁöÑÊ†áÂáÜÂåñÊé•Âè£\n\n## Á≥ªÁªüË¶ÅÊ±Ç\n- Node.js >= 20.12.0\n\n## npm package\nÊÑüË∞¢[HQHC](https://github.com/HQHC)ÂèëÂ∏ÉÁöÑnpmÂåÖ\n```json\n{\n  \"mcpServers\": {\n    \"bilibili-search\": {\n    \"command\": \"npx\",\n    \"args\": [\"bilibili-mcp\"],\n    \"description\": \"BÁ´ôËßÜÈ¢ëÊêúÁ¥¢ MCP ÊúçÂä°ÔºåÂèØ‰ª•Âú®AIÂ∫îÁî®‰∏≠ÊêúÁ¥¢BÁ´ôËßÜÈ¢ëÂÜÖÂÆπ„ÄÇ\"\n    }\n  }\n}\n```\n\n## Âø´ÈÄüÂºÄÂßã\n> Â¶ÇÊûúË¶ÅËøêË°ålangchain‰æãÂ≠êÔºåËØ∑ÂÖàÈÖçÁΩÆllmÊ®°ÂûãÔºå‰øÆÊîπ.\\example.tsÊñá‰ª∂„ÄÇ\n```javascript\nconst llm = new ChatOpenAI({\n  modelName: \"gpt-4o-mini\",\n  temperature: 0,\n  openAIApiKey: \"your_api_key\", // ÊõøÊç¢Êàê‰Ω†Ê®°ÂûãÁöÑÂØÜÈí•\n  configuration: {\n    baseURL: \"https://www.api.com/v1\", // ÊõøÊç¢Êàê‰Ω†Ê®°ÂûãÁöÑAPIÂú∞ÂùÄ\n  },\n});\n```\n\nbun:\n\n```bash\nbun i\nbun index.ts\n# ÊµãËØïËÑöÊú¨\nbun test.js\n# MCP Inspector\nbun run inspector\n# ËøêË°ålangchain‰æãÂ≠ê\nbun build:bun\nbun example.ts\n```\n\nnpm:\n\n```bash\nnpm i\nnpm run start\n# ÊµãËØïËÑöÊú¨\nnpm run test\n# MCP Inspector\nnpm run inspector\n# ËøêË°ålangchain‰æãÂ≠ê\nnpm run build\nnode dist/example.js\n```\n\n## Êà™Âõæ\n![](./imgs/test-01.png)\n![](./imgs/test-02.png)\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "8enSmith--mcp-open-library": {
          "owner": "8enSmith",
          "name": "mcp-open-library",
          "url": "https://github.com/8enSmith/mcp-open-library",
          "imageUrl": "https://github.com/8enSmith.png",
          "description": "Connect AI assistants to the Open Library to search and retrieve detailed information about books and authors, providing structured JSON responses.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:05:59.679630",
          "collection_timestamp": "2025-10-02T15:02:36.470682",
          "stars": 41,
          "forks": 13,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-04-17T23:31:17Z",
          "updated_at": "2025-09-30T20:19:01Z",
          "open_issues": 0,
          "readme_content": "# MCP Open Library\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/8enSmith/mcp-open-library)](https://archestra.ai/mcp-catalog/8ensmith__mcp-open-library)\n[![smithery badge](https://smithery.ai/badge/@8enSmith/mcp-open-library)](https://smithery.ai/server/@8enSmith/mcp-open-library)\n\nA Model Context Protocol (MCP) server for the Open Library API that enables AI assistants to search for book and author information.\n\n<a href=\"https://glama.ai/mcp/servers/@8enSmith/mcp-open-library\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@8enSmith/mcp-open-library/badge\" alt=\"mcp-open-library MCP server\" />\n</a>\n\n## Overview\n\nThis project implements an MCP server that provides tools for AI assistants to interact with the [Open Library](https://openlibrary.org/). It allows searching for book information by title, searching for authors by name, retrieving detailed author information using their Open Library key, and getting URLs for author photos using their Open Library ID (OLID). The server returns structured data for book and author information.\n\n## Features\n\n- **Book Search by Title**: Search for books using their title (`get_book_by_title`).\n- **Author Search by Name**: Search for authors using their name (`get_authors_by_name`).\n- **Get Author Details**: Retrieve detailed information for a specific author using their Open Library key (`get_author_info`).\n- **Get Author Photo**: Get the URL for an author's photo using their Open Library ID (OLID) (`get_author_photo`).\n- **Get Book Cover**: Get the URL for a book's cover image using various identifiers (ISBN, OCLC, LCCN, OLID, ID) (`get_book_cover`).\n- **Get Book by ID**: Retrieve detailed book information using various identifiers (ISBN, LCCN, OCLC, OLID) (`get_book_by_id`).\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Open Library for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@8enSmith/mcp-open-library):\n\n```bash\nnpx -y @smithery/cli install @8enSmith/mcp-open-library --client claude\n```\n\n### Manual Installation\n```bash\n# Clone the repository\ngit clone https://github.com/8enSmith/mcp-open-library.git\ncd mcp-open-library\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### Running the Server\n\nYou can use the MCP Inspector to test the server:\n\n```bash\nnpm run inspector\n```\n\nAccess the MCP Inspector and then test the tool e.g.\n\n![alt text](image.png)\n\n### Using with an MCP Client\n\nThis server implements the Model Context Protocol, which means it can be used by any MCP-compatible AI assistant or client e.g. [Claude Desktop](https://modelcontextprotocol.io/quickstart/user). The server exposes the following tools:\n\n- `get_book_by_title`: Search for book information by title\n- `get_authors_by_name`: Search for author information by name\n- `get_author_info`: Get detailed information for a specific author using their Open Library Author Key\n- `get_author_photo`: Get the URL for an author's photo using their Open Library Author ID (OLID)\n- `get_book_cover`: Get the URL for a book's cover image using a specific identifier (ISBN, OCLC, LCCN, OLID, or ID)\n- `get_book_by_id`: Get detailed book information using a specific identifier (ISBN, LCCN, OCLC, or OLID)\n\n**Example `get_book_by_title` input:**\n```json\n{\n  \"title\": \"The Hobbit\"\n}\n```\n\n**Example `get_book_by_title` output:**\n```json\n[\n  {\n    \"title\": \"The Hobbit\",\n    \"authors\": [\n      \"J. R. R. Tolkien\"\n    ],\n    \"first_publish_year\": 1937,\n    \"open_library_work_key\": \"/works/OL45883W\",\n    \"edition_count\": 120,\n    \"cover_url\": \"https://covers.openlibrary.org/b/id/10581294-M.jpg\"\n  }\n]\n```\n\n**Example `get_authors_by_name` input:**\n```json\n{\n  \"name\": \"J.R.R. Tolkien\"\n}\n```\n\n**Example `get_authors_by_name` output:**\n```json\n[\n  {\n    \"key\": \"OL26320A\",\n    \"name\": \"J. R. R. Tolkien\",\n    \"alternate_names\": [\n      \"John Ronald Reuel Tolkien\"\n    ],\n    \"birth_date\": \"3 January 1892\",\n    \"top_work\": \"The Hobbit\",\n    \"work_count\": 648\n  }\n]\n```\n\n**Example `get_author_info` input:**\n```json\n{\n  \"author_key\": \"OL26320A\"\n}\n```\n\n**Example `get_author_info` output:**\n```json\n{\n  \"name\": \"J. R. R. Tolkien\",\n  \"personal_name\": \"John Ronald Reuel Tolkien\",\n  \"birth_date\": \"3 January 1892\",\n  \"death_date\": \"2 September 1973\",\n  \"bio\": \"John Ronald Reuel Tolkien (1892-1973) was a major scholar of the English language, specializing in Old and Middle English. He served as the Rawlinson and Bosworth Professor of Anglo-Saxon and later the Merton Professor of English Language and Literature at Oxford University.\",\n  \"alternate_names\": [\"John Ronald Reuel Tolkien\"],\n  \"photos\": [6791763],\n  \"key\": \"/authors/OL26320A\",\n  \"remote_ids\": {\n    \"viaf\": \"95218067\",\n    \"wikidata\": \"Q892\"\n  },\n  \"revision\": 43,\n  \"last_modified\": {\n    \"type\": \"/type/datetime\",\n    \"value\": \"2023-02-12T05:50:22.881\"\n  }\n}\n```\n\n**Example `get_author_photo` input:**\n```json\n{\n  \"olid\": \"OL26320A\"\n}\n```\n\n**Example `get_author_photo` output:**\n```text\nhttps://covers.openlibrary.org/a/olid/OL26320A-L.jpg\n```\n\n**Example `get_book_cover` input:**\n```json\n{\n  \"key\": \"ISBN\",\n  \"value\": \"9780547928227\",\n  \"size\": \"L\"\n}\n```\n\n**Example `get_book_cover` output:**\n```text\nhttps://covers.openlibrary.org/b/isbn/9780547928227-L.jpg\n```\n\nThe `get_book_cover` tool accepts the following parameters:\n- `key`: The type of identifier (one of: `ISBN`, `OCLC`, `LCCN`, `OLID`, or `ID`)\n- `value`: The value of the identifier\n- `size`: Optional cover size (`S` for small, `M` for medium, `L` for large, defaults to `L`)\n\n**Example `get_book_by_id` input:**\n```json\n{\n  \"idType\": \"isbn\",\n  \"idValue\": \"9780547928227\"\n}\n```\n\n**Example `get_book_by_id` output:**\n```json\n{\n  \"title\": \"The Hobbit\",\n  \"authors\": [\n    \"J. R. R. Tolkien\"\n  ],\n  \"publishers\": [\n    \"Houghton Mifflin Harcourt\"\n  ],\n  \"publish_date\": \"October 21, 2012\",\n  \"number_of_pages\": 300,\n  \"isbn_13\": [\n    \"9780547928227\"\n  ],\n  \"isbn_10\": [\n    \"054792822X\"\n  ],\n  \"oclc\": [\n    \"794607877\"\n  ],\n  \"olid\": [\n    \"OL25380781M\"\n  ],\n  \"open_library_edition_key\": \"/books/OL25380781M\",\n  \"open_library_work_key\": \"/works/OL45883W\",\n  \"cover_url\": \"https://covers.openlibrary.org/b/id/8231496-M.jpg\",\n  \"info_url\": \"https://openlibrary.org/books/OL25380781M/The_Hobbit\",\n  \"preview_url\": \"https://archive.org/details/hobbit00tolkien\"\n}\n```\n\nThe `get_book_by_id` tool accepts the following parameters:\n- `idType`: The type of identifier (one of: `isbn`, `lccn`, `oclc`, `olid`)\n- `idValue`: The value of the identifier\n\nAn example of this tool being used in Claude Desktop can be see here:\n\n<img width=\"1132\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0865904a-f984-4f7b-a27d-6397ac59d6d2\" />\n\n### Docker\n\nYou can test this MCP server using Docker. To do this first run:\n\n```bash\ndocker build -t mcp-open-library .\ndocker run -p 8080:8080 mcp-open-library\n```\n\nYou can then test the server running within Docker via the inspector e.g.\n\n```bash\nnpm run inspector http://localhost:8080\n```\n\n## Development\n\n### Project Structure\n\n- `src/index.ts` - Main server implementation\n- `src/types.ts` - TypeScript type definitions\n- `src/index.test.ts` - Test suite\n\n### Available Scripts\n\n- `npm run build` - Build the TypeScript code\n- `npm run watch` - Watch for changes and rebuild\n- `npm test` - Run the test suite\n- `npm run format` - Format code with Prettier\n- `npm run inspector` - Run the MCP Inspector against the server\n\n### Running Tests\n\n```bash\nnpm test\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a pull request.\n\n## Acknowledgments\n\n- [Open Library API](https://openlibrary.org/developers/api)\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-open-library",
          "npm_downloads": 9,
          "npm_package_name": "mcp-open-library",
          "npm_success": true,
          "npm_error": null
        },
        "Abhi5h3k--MCP-URL2SNAP": {
          "owner": "Abhi5h3k",
          "name": "MCP-URL2SNAP",
          "url": "https://github.com/Abhi5h3k/MCP-URL2SNAP",
          "imageUrl": "https://github.com/Abhi5h3k.png",
          "description": "Capture screenshots of any specified URL and return the access URL for the captured image, facilitating webpage snapshot sharing and integration into automation workflows.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:00.825778",
          "collection_timestamp": "2025-10-02T15:02:44.020006",
          "stars": 1,
          "forks": 4,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-03-23T10:26:51Z",
          "updated_at": "2025-07-17T11:35:45Z",
          "open_issues": 3,
          "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/abhi5h3k-mcp-url2snap-badge.png)](https://mseep.ai/app/abhi5h3k-mcp-url2snap)\n\n# [MCP URL2SNAP](https://anthropic-mcp.hashnode.dev/model-context-protocol-mcp-a-beginners-guide-to-the-future-of-ai-communication) üöÄü§ñ\n\n[![smithery badge](https://smithery.ai/badge/@Abhi5h3k/MCP-URL2SNAP)](https://smithery.ai/server/@Abhi5h3k/MCP-URL2SNAP)\n\nA lightweight **Model Context Protocol (MCP)** server that enables your LLM to capture screenshots of any specified URL and return only the access URL for the captured image. This tool simplifies the process of generating and sharing webpage snapshots, making it perfect for integrating visual capture capabilities into AI applications like Claude Desktop or automation workflows.\n\n---\n\n# What is Model Context Protocol (MCP)?\nAt its core, MCP is a standardized protocol designed to streamline communication between AI models and external systems. Think of it as a universal language that allows different AI agents, tools, and services to interact seamlessly.\n\n![MCP drawio (1)](https://github.com/user-attachments/assets/567c5853-3e3c-49c5-bec2-07325f000be2)\n\n---\n\n## **Features**  \n- **Email Verification**: Verify email addresses in real-time.  \n- **MCP Integration**: Seamlessly connect with MCP-compatible LLMs.  \n- **Easy Setup**: Built with Python and the MCP SDK for quick deployment.  \n\n---\n\n# MCP follows a client-server architecture:\n\n![client server drawio](https://github.com/user-attachments/assets/1f7141c9-d96f-4a5d-a8ab-944b8daa81f4)\n\n---\n\n# Watch the Demo\nClick the image below to watch a video demo of the MCP Email Verify tool in action:\n\n[![Youtube](https://github.com/user-attachments/assets/c3c05d3d-aac8-4d6b-a8ce-6dd0aec935f2)](https://youtu.be/Xv1YA5pXdqY)\n\n---\n\n## **Requirements**  \n- **Python**: Python 3.11.0 or higher.  \n- **UV**: 0.6.9 or higher.  \n\n---\n## **Setup**  \n\n### Installing via Smithery\n\nTo install MCP-URL2SNAP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Abhi5h3k/MCP-URL2SNAP):\n\n```bash\nnpx -y @smithery/cli install @Abhi5h3k/MCP-URL2SNAP --client claude\n```\n\n### Manual Installation\n**1. Clone the Repository**  \n```\ngit clone https://github.com/Abhi5h3k/MCP-URL2SNAP.git\ncd MCP-URL2SNAP\n```\n**2. Install UV**\n \nIf you don‚Äôt have UV installed, you can install it using the following commands:\n```\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\nVerify the installation:\n```\nuv --version\n```\n\n**3. Set Up the Virtual Environment**\n\nCreate a virtual environment using UV:\n```\nuv venv\n```\nActivate the virtual environment:\nOn Windows:\n```\n.venv\\Scripts\\activate\n```\n**4. Install Dependencies** \nInstall the required dependencies from pyproject.toml using UV:\n```\nuv install\n```\n\n## Running the Server\n1. Set Up Environment Variables\nCreate a .env file in the root directory and add your [AbstractAPI](https://app.abstractapi.com/api/screenshot/tester) key:\n```\nABSTRACT_API_KEY=your_api_key_here\n```\n2. Run the Server\nStart the MCP server:\n```\nuv run server.py\n```\n\n## Usage\n\n1. Register the Server with Claude Desktop\n  Update the claude_desktop_config.json file to include your MCP server:\n  \n  ```\n  {\n      \"mcpServers\": {\n          \"verify_mail\": {\n              \"command\": \"uv\",\n              \"args\": [\n                  \"--directory\",\n                  \"C:\\\\ABSOLUTE\\\\PATH\\\\TO\\\\MCP-Email-Verify\",\n                  \"run\",\n                  \"server.py\"\n              ],\n              \"env\":{\n                \"ABSTRACT_API_KEY\":\"YUR_API_KEY\"\n              }\n          }\n      }\n  }\n  ```\n ![image](https://github.com/user-attachments/assets/62db4fb4-d71a-49b5-97b8-9fbf4d4ab822)\n \n ![image](https://github.com/user-attachments/assets/da77ff7c-82cd-4ef8-94fd-ce9b11cad83f)\n\n\n2. Restart Claude Desktop\n  Restart Claude Desktop to detect the new tool.\n\n3. Verify Emails\n  Use prompts like:\n\n  \"can you show me the screenshot of https://github.com/Abhi5h3k\"\n\n\n## Development\nFormatting and Linting\nThis project uses black and isort for code formatting and import sorting.\n\n1. Install development dependencies:\n   ```\n    uv add black isort --dev\n    ```\n2. Format the code:\n   ```\n   black .\n   ```\n3. Sort imports:\n  ```\n    isort .\n  ```\n\n\n## Set up pre-commit\n```bash\npre-commit install\npre-commit run --all-files\n```\n\n\nArticle: Model Context Protocol (MCP): [A Beginner's Guide to the Future of AI Communication](https://anthropic-mcp.hashnode.dev/model-context-protocol-mcp-a-beginners-guide-to-the-future-of-ai-communication)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "ac3xx--mcp-servers-kagi": {
          "owner": "ac3xx",
          "name": "mcp-servers-kagi",
          "url": "https://github.com/ac3xx/mcp-servers-kagi",
          "imageUrl": "https://github.com/ac3xx.png",
          "description": "Access Kagi's search engine to perform web searches, providing high-quality, ad-free results through its API. The server is currently in private beta and includes functionality for basic search operations.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:01.655961",
          "collection_timestamp": "2025-10-02T15:02:51.777966",
          "stars": 38,
          "forks": 10,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2024-11-27T13:54:32Z",
          "updated_at": "2025-09-18T01:58:26Z",
          "open_issues": 6,
          "readme_content": "# kagi-server MCP Server\n\n[![smithery badge](https://smithery.ai/badge/kagi-server)](https://smithery.ai/protocol/kagi-server)\nMCP server for Kagi API integration\n\nThis is a TypeScript-based MCP server that integrates the Kagi Search API. It demonstrates core MCP concepts by providing:\n\n- Tools for performing web searches and other operations using Kagi's API (currently in private beta)\n\n## Features\n\n### Implemented Tools\n- `kagi_search` - Perform web searches using Kagi\n  - Takes a query string and optional limit as parameters\n  - Returns search results from Kagi's API\n\n### Planned Tools (Not Yet Implemented)\n- `kagi_summarize` - Generate summaries of web pages or text\n- `kagi_fastgpt` - Get quick responses using Kagi's FastGPT\n- `kagi_enrich` - Fetch enriched news results on specific topics\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Environment Setup\n\nCreate a `.env` file in the root directory with your Kagi API key:\n\n```\nKAGI_API_KEY=your_api_key_here\n```\n\nMake sure to add `.env` to your `.gitignore` file to keep your API key secure.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Kagi Server for Claude Desktop automatically via [Smithery](https://smithery.ai/protocol/kagi-server):\n\n```bash\nnpx @smithery/cli install kagi-server --client claude\n```\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"kagi-server\": {\n      \"command\": \"/path/to/kagi-server/build/index.js\",\n      \"env\": {\n        \"KAGI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Usage\n\nOnce the server is running and connected to Claude Desktop, you can use it to perform web searches. For example:\n\n1. Ask Claude: \"Can you search for information about the latest advancements in quantum computing?\"\n2. Claude will use the `kagi_search` tool to fetch results from Kagi's API.\n3. Claude will then summarize or analyze the search results for you.\n\nNote: The planned tools (summarize, fastgpt, enrich) are not yet implemented and cannot be used.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. Some areas for contribution include:\n\n- Implementing the planned tools (summarize, fastgpt, enrich)\n- Improving error handling and input validation\n- Enhancing documentation and usage examples\n\n## License\n\nThis project is licensed under the MIT License.\n\n## Roadmap\n\n- Implement `kagi_summarize` tool for webpage and text summarization\n- Implement `kagi_fastgpt` tool for quick responses\n- Implement `kagi_enrich` tool for fetching enriched news results\n- Improve error handling and add more robust input validation\n- Add more comprehensive usage examples and documentation\n- Publish the package to npm for easy installation and use with Claude Desktop and npx",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "aimiliyaai--alnitak": {
          "owner": "aimiliyaai",
          "name": "alnitak",
          "url": "https://github.com/aimiliyaai/alnitak",
          "imageUrl": "https://github.com/aimiliyaai.png",
          "description": "A dynamic video platform supporting real-time interactions, featuring video playback, live comments, and content management functionalities. It includes video transcoding, real-time messaging, and role-based access control through JWT-based authentication.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:02.715729",
          "collection_timestamp": "2025-10-02T15:02:59.719135",
          "stars": 0,
          "forks": 0,
          "license": "MIT License",
          "language": "Vue",
          "created_at": "2025-02-02T16:00:50Z",
          "updated_at": "2025-07-20T15:21:21Z",
          "open_issues": 0,
          "readme_content": "# AlnitakÂºπÂπïËßÜÈ¢ëÁΩëÁ´ô\n\nAlnitakÊòØ‰∏Ä‰∏™Âü∫‰∫énuxtÂíågoÂºÄÂèëÁöÑÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑÂºπÂπïËßÜÈ¢ëÁΩëÁ´ô„ÄÇ\nÈ°πÁõÆÂÆûÁé∞‰∫ÜËßÜÈ¢ë„ÄÅ‰∏ìÊ†è„ÄÅÂºπÂπï„ÄÅËØÑËÆ∫„ÄÅÁÇπËµû„ÄÅÊî∂ËóèÁ≠âÂäüËÉΩ„ÄÇ [ÊºîÁ§∫ËßÜÈ¢ë](https://www.bilibili.com/video/BV1E6421Z7Zd/)\n\n## È°πÁõÆÊñáÊ°£\n\n`ÂºÄÂèë‰∫§ÊµÅÁæ§: 909847398`\n\n`ÊñáÊ°£Ôºö` https://alnitak.interastral-peace.com/\n\n## ÁâπÊÄß\n* **ÂºπÂπïÊí≠ÊîæÂô®**: Âü∫‰∫éDPlayer‰∫åÊ¨°ÂºÄÂèëÂá∫ÂºπÂπïÊí≠ÊîæÂô®WPlayerÂπ∂‰∏ä‰º†npm„ÄÇ\n* **ËßÜÈ¢ëËΩ¨Á†Å**ÔºöÂÆûÁé∞‰∫ÜËßÜÈ¢ëÁ†ÅÁéáÂíåÂàÜËæ®ÁéáÁöÑË∞ÉÊï¥ÔºåÂπ∂Â∞ÜËßÜÈ¢ëËΩ¨Á†Å‰∏∫HLSÊ†ºÂºèÔºå‰ª•ÊèêÈ´òÊí≠ÊîæÊïàÊûú\n* **ÂÆûÊó∂ÈÄö‰ø°**ÔºöÂü∫‰∫éWebSocketÂÆûÁé∞‰∫ÜÁßÅ‰ø°ÁöÑÂÆûÊó∂Êî∂ÂèëÂäüËÉΩÔºåÂêåÊó∂ÂÆûÁé∞‰∫ÜËßÜÈ¢ëÂú®Á∫ø‰∫∫Êï∞ÁöÑÂÆûÊó∂Êõ¥Êñ∞\n* **Èâ¥ÊùÉ**ÔºöÂü∫‰∫éJWTÂÆûÁé∞ÂèåTokenÊñπÊ°àÔºåÈÄöËøáÂØπaxios‰∫åÊ¨°Â∞ÅË£ÖÂÆûÁé∞TokenËøáÊúüÈáçÂèëËØ∑Ê±ÇÂäüËÉΩ\n* **ÊªëÂùóÊãºÂõæÂ∫ì**Ôºö‰ΩøÁî®GoËØ≠Ë®ÄÂºÄÂèë‰∫ÜÊªëÂùóÊãºÂõæÁîüÊàêÂ∫ìÔºåÂπ∂Â∞ÜÂÖ∂ÂèëÂ∏ÉÂà∞GitHub‰∏ä‰Ωú‰∏∫È°πÁõÆ‰æùËµñ‰ΩøÁî®\n* **ÊùÉÈôêÁÆ°ÁêÜ**ÔºöÂêéÂè∞ÁÆ°ÁêÜÁ≥ªÁªüÂü∫‰∫éJWTÂíåCasbinÂÆûÁé∞‰∫ÜÂü∫‰∫éËßíËâ≤ÁöÑËÆøÈóÆÊéßÂà∂ÔºàRBACÔºâÔºå‰øùÈöú‰∫ÜÁ≥ªÁªüÁöÑÂÆâÂÖ®ÊÄßÂíåÁÅµÊ¥ªÊÄß\n* **ÂØπË±°Â≠òÂÇ®**ÔºöÊîØÊåÅÈòøÈáå‰∫ë„ÄÅËÖæËÆØ‰∫ë„ÄÅMinIO„ÄÅCloudflareÁ≠â‰∫ëÂ≠òÂÇ®ÊúçÂä°ÔºåÂÆûÁé∞‰∫ÜËßÜÈ¢ëÁöÑÊåÅ‰πÖÂåñÂ≠òÂÇ®ÂíåËÆøÈóÆ\n\n## Áõ∏ÂÖ≥È°πÁõÆ\n\n- wplayer-nextÂºπÂπïÊí≠ÊîæÂô®(https://github.com/wangzmgit/wplayer-next)\n- GOÊªëÂùóÊãºÂõæÁîüÊàê(https://github.com/wangzmgit/jigsaw)\n\n## Ë¥°ÁåÆ\n\nÈùûÂ∏∏Ê¨¢ËøéÊÇ®ÂèÇ‰∏éÈ°πÁõÆÁöÑÁª¥Êä§„ÄÇÂ¶ÇÊúâ‰ªª‰ΩïÊÑèËßÅÊàñÂª∫ËÆÆÔºåËØ∑ÈÄöËøáÂàõÂª∫ Issue ÊàñÊèê‰∫§ Pull Request ÁöÑÊñπÂºèÂëäÁü•Êàë‰ª¨„ÄÇ\nÂú®Êèê‰∫§‰πãÂâçÔºåËØ∑Âä°ÂøÖÈòÖËØª[Ë¥°ÁåÆÊåáÂçó](https://alnitak.interastral-peace.com/guide/other/contribution)„ÄÇ\n\n\n## Â£∞Êòé\nÊú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†ÂíåÁ†îÁ©∂‰ΩøÁî®ÔºåËØ∑ÂãøÂ∞ÜÊú¨È°πÁõÆÁöÑ‰ªª‰ΩïÂÜÖÂÆπÁî®‰∫éÂïÜ‰∏öÊàñÈùûÊ≥ïÁõÆÁöÑÔºåÂê¶ÂàôÂêéÊûúËá™Ë¥ü„ÄÇ\n\n## È°πÁõÆÊà™Âõæ\n|                                 WebÁ´Ø                                 |                                WebÁ´Ø                                |\n| :-------------------------------------------------------------------: | :-----------------------------------------------------------------: |\n|   ![WebÁ´ØÁôªÂΩï](https://alnitak.interastral-peace.com/web_login.png)   |  ![WebÁ´ØÈ¶ñÈ°µ](https://alnitak.interastral-peace.com/web_home.png)   |\n|  ![WebÁ´Ø‰∏ä‰º†](https://alnitak.interastral-peace.com/web_upload.png)   |  ![WebÁ´ØËßÜÈ¢ë](https://alnitak.interastral-peace.com/web_video.png)  |\n| ![WebÁ´Ø‰∏™‰∫∫‰∏≠ÂøÉ](https://alnitak.interastral-peace.com/web_space.png) | ![WebÁ´ØÊ∂àÊÅØ](https://alnitak.interastral-peace.com/web_message.png) |\n\n|                                  ÂêéÂè∞ÁÆ°ÁêÜÁ´Ø                                  |                                  ÂêéÂè∞ÁÆ°ÁêÜÁ´Ø                                   |\n| :--------------------------------------------------------------------------: | :---------------------------------------------------------------------------: |\n|  ![ÂêéÂè∞ÁÆ°ÁêÜÁ´ØÁôªÂΩï](https://alnitak.interastral-peace.com/manage_login.png)   | ![ÂêéÂè∞ÁÆ°ÁêÜÁ´ØËßÜÈ¢ëÁÆ°ÁêÜ](https://alnitak.interastral-peace.com/manage_video.png) |\n| ![ÂêéÂè∞ÁÆ°ÁêÜÁ´ØÁî®Êà∑ÁÆ°ÁêÜ](https://alnitak.interastral-peace.com/manage_user.png) |                                                                               |\n\n|                                ÁßªÂä®Á´Ø                                |                                ÁßªÂä®Á´Ø                                 |\n| :------------------------------------------------------------------: | :-------------------------------------------------------------------: |\n| ![ÁßªÂä®Á´ØÈ¶ñÈ°µ](https://alnitak.interastral-peace.com/mobile_home.png) | ![ÁßªÂä®Á´ØËßÜÈ¢ë](https://alnitak.interastral-peace.com/mobile_video.png) |\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "adamwattis--resource-hub-server": {
          "owner": "adamwattis",
          "name": "resource-hub-server",
          "url": "https://github.com/adamwattis/resource-hub-server",
          "imageUrl": "https://github.com/adamwattis.png",
          "description": "Connects to a centralized hub for managing and configuring MCP servers, facilitating access to shared tools and resources across various environments. Simplifies the management of MCP server settings from a single configuration point.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:03.660924",
          "collection_timestamp": "2025-10-02T15:03:06.769338",
          "stars": 3,
          "forks": 2,
          "license": "No License",
          "language": "JavaScript",
          "created_at": "2024-12-27T22:34:30Z",
          "updated_at": "2025-07-28T16:50:22Z",
          "open_issues": 1,
          "readme_content": "# resource-hub-server\n\nAn MCP server that connects to the Resource Hub - a central place to configure and manage your MCP servers.\n\n## Overview\n\nThe resource-hub-server acts as a proxy between your local MCP environment and the Resource Hub. It allows you to:\n\n- Access centrally configured tools and resources\n- Share configurations across different environments\n- Manage MCP server settings in one place\n\n## Usage\n\n### Quick Start with npx\n\nThe easiest way to run the server is using npx:\n\n```bash\nRESOURCE_HUB_TOKEN=your_token npx @adamwattis/resource-hub-server\n```\n\n### Running from Source\n\nIf you want to run from source:\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n2. Build the server:\n```bash\nnpm run build\n```\n\n3. Run with your Resource Hub token:\n```bash\nRESOURCE_HUB_TOKEN=your_token npm start\n```\n\n### Configuration\n\nYou'll need a Resource Hub token to use this server. You can get this from the Resource Hub token page.\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"resource-hub-server\": {\n      \"command\": \"npx @adamwattis/resource-hub-server\"\n    }\n  }\n}\n```\n\n### Environment Variables\n\n- `RESOURCE_HUB_TOKEN` (required): Your Resource Hub authentication token\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector):\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/@adamwattis/resource-hub-server",
          "npm_downloads": 115,
          "npm_package_name": "@adamwattis/resource-hub-server",
          "npm_success": true,
          "npm_error": null
        },
        "adenot--mcp-google-search": {
          "owner": "adenot",
          "name": "mcp-google-search",
          "url": "https://github.com/adenot/mcp-google-search",
          "imageUrl": "https://github.com/adenot.png",
          "description": "Provides web search capabilities using the Google Custom Search API and extracts content from web pages.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:04.570537",
          "collection_timestamp": "2025-10-02T15:03:10.696672",
          "stars": 48,
          "forks": 18,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2025-02-01T02:27:36Z",
          "updated_at": "2025-09-29T12:37:54Z",
          "open_issues": 1,
          "readme_content": "# mcp-google-server A MCP Server for Google Custom Search and Webpage Reading\n[![smithery badge](https://smithery.ai/badge/@adenot/mcp-google-search)](https://smithery.ai/server/@adenot/mcp-google-search)\n\nA Model Context Protocol server that provides web search capabilities using Google Custom Search API and webpage content extraction functionality.\n\n## Setup\n\n### Getting Google API Key and Search Engine ID\n\n1. Create a Google Cloud Project:\n   - Go to [Google Cloud Console](https://console.cloud.google.com/)\n   - Create a new project or select an existing one\n   - Enable billing for your project\n\n2. Enable Custom Search API:\n   - Go to [API Library](https://console.cloud.google.com/apis/library)\n   - Search for \"Custom Search API\"\n   - Click \"Enable\"\n\n3. Get API Key:\n   - Go to [Credentials](https://console.cloud.google.com/apis/credentials)\n   - Click \"Create Credentials\" > \"API Key\"\n   - Copy your API key\n   - (Optional) Restrict the API key to only Custom Search API\n\n4. Create Custom Search Engine:\n   - Go to [Programmable Search Engine](https://programmablesearchengine.google.com/create/new)\n   - Enter the sites you want to search (use www.google.com for general web search)\n   - Click \"Create\"\n   - On the next page, click \"Customize\"\n   - In the settings, enable \"Search the entire web\"\n   - Copy your Search Engine ID (cx)\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Features\n\n### Search Tool\nPerform web searches using Google Custom Search API:\n- Search the entire web or specific sites\n- Control number of results (1-10)\n- Get structured results with title, link, and snippet\n\n### Webpage Reader Tool\nExtract content from any webpage:\n- Fetch and parse webpage content\n- Extract page title and main text\n- Clean content by removing scripts and styles\n- Return structured data with title, text, and URL\n\n## Installation\n\n### Installing via Smithery\n\nTo install Google Custom Search Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@adenot/mcp-google-search):\n\n```bash\nnpx -y @smithery/cli install @adenot/mcp-google-search --client claude\n```\n\nTo use with Claude Desktop, add the server config with your Google API credentials:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"google-search\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@adenot/mcp-google-search\"\n      ],\n      \"env\": {\n        \"GOOGLE_API_KEY\": \"your-api-key-here\",\n        \"GOOGLE_SEARCH_ENGINE_ID\": \"your-search-engine-id-here\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\n### Search Tool\n```json\n{\n  \"name\": \"search\",\n  \"arguments\": {\n    \"query\": \"your search query\",\n    \"num\": 5  // optional, default is 5, max is 10\n  }\n}\n```\n\n### Webpage Reader Tool\n```json\n{\n  \"name\": \"read_webpage\",\n  \"arguments\": {\n    \"url\": \"https://example.com\"\n  }\n}\n```\n\nExample response from webpage reader:\n```json\n{\n  \"title\": \"Example Domain\",\n  \"text\": \"Extracted and cleaned webpage content...\",\n  \"url\": \"https://example.com\"\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-google-search",
          "npm_downloads": 290,
          "npm_package_name": "mcp-google-search",
          "npm_success": true,
          "npm_error": null
        },
        "adhikasp--mcp-reddit": {
          "owner": "adhikasp",
          "name": "mcp-reddit",
          "url": "https://github.com/adhikasp/mcp-reddit",
          "imageUrl": "https://github.com/adhikasp.png",
          "description": "Fetch and analyze content from Reddit, including retrieving hot threads and detailed post content with comments across various post types such as text, link, and gallery.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:05.573591",
          "collection_timestamp": "2025-10-02T15:03:19.638880",
          "stars": 259,
          "forks": 35,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-20T13:21:47Z",
          "updated_at": "2025-10-02T01:29:57Z",
          "open_issues": 5,
          "readme_content": "# MCP Reddit Server\n[![smithery badge](https://smithery.ai/badge/@adhikasp/mcp-reddit)](https://smithery.ai/server/@adhikasp/mcp-reddit)\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server that provides tools for fetching and analyzing Reddit content.\n\n<a href=\"https://glama.ai/mcp/servers/3cg9gdyors\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/3cg9gdyors/badge\" alt=\"mcp-reddit MCP server\" /></a>\n\n## Features\n\n- Fetch hot threads from any subreddit\n- Get detailed post content including comments\n- Support for different post types (text, link, gallery)\n\n## Installation\n\n### Installing via Smithery\n\nTo install Reddit Content for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@adhikasp/mcp-reddit):\n\n```bash\nnpx -y @smithery/cli install @adhikasp/mcp-reddit --client claude\n```\n\n### Manual Installation\n```json\n{\n  \"reddit\": {\n    \"command\": \"uvx\",\n    \"args\": [\"--from\", \"git+https://github.com/adhikasp/mcp-reddit.git\", \"mcp-reddit\"],\n    \"env\": {}\n  }\n}\n```\n\n## Usage\n\nUsing [mcp-client-cli](https://github.com/adhikasp/mcp-client-cli):\n\n```\n$ llm what are latest hot thread in r/victoria3\n\nI'll fetch the latest hot threads from the Victoria 3 subreddit for you.\n\nTool Calls:\n  fetch_hot_threads\n  Args:\n    subreddit: victoria3\n\n\nBased on the hot threads, here are the key highlights from the Victoria 3 subreddit:\n\n1. Dev Diary #126 - Update 1.8 Overview\n   - Major updates planned for the game, including:\n     - Political Movement Rework (Ideological Forces)\n     - Discrimination Rework\n     - Food Availability, Famines, and Harvest Incidents\n     - Additional features like Companies owning buildings and Bulk Nationalization\n\n2. Dev Diary #138 - Pivot of Empire Update\n   - Update 1.8 \"Masala Chai\" has been released\n   - Focuses on India with new Journal Entries, Events, and Immersion Pack\n   - 10 new achievements added\n   - Save games from 1.7.7 are not compatible with 1.8\n\n3. Interesting Community Discussions:\n   - A player shared a detailed experience of retaking Constantinople as Greece, highlighting the complex population dynamics\n   - Humorous posts about game mechanics, such as investment rights and political movements\n   - Various memes and gameplay screenshots showcasing unique game situations\n\nThe most upvoted thread is the Dev Diary #126, which provides an in-depth look at the upcoming game mechanics improvements, particularly the reworks to political movements and discrimination systems.\n\nWould you like me to elaborate on any of these points or provide more details about the Victoria 3 update?\n``` \n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-reddit-server",
          "npm_downloads": 90,
          "npm_package_name": "mcp-reddit-server",
          "npm_success": true,
          "npm_error": null
        },
        "adhikasp--mcp-twikit": {
          "owner": "adhikasp",
          "name": "mcp-twikit",
          "url": "https://github.com/adhikasp/mcp-twikit",
          "imageUrl": "https://github.com/adhikasp.png",
          "description": "Search and analyze Twitter data integration using the Model Context Protocol, facilitating access to various Twitter data for analysis and insights.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:06.499871",
          "collection_timestamp": "2025-10-02T15:03:27.423581",
          "stars": 208,
          "forks": 27,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-15T03:37:27Z",
          "updated_at": "2025-09-29T14:30:57Z",
          "open_issues": 7,
          "readme_content": "# MCP-Twikit\n\n[![smithery badge](https://smithery.ai/badge/mcp-twikit)](https://smithery.ai/server/mcp-twikit)\nA Model Context Protocol (MCP) server for interacting with Twitter.\n\n<a href=\"https://glama.ai/mcp/servers/49i9dd08w8\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/49i9dd08w8/badge\" alt=\"mcp-twikit MCP server\" /></a>\n\n## Installation\n\n### Installing via Smithery\n\nTo install Twikit Twitter Search for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-twikit):\n\n```bash\nnpx -y @smithery/cli install mcp-twikit --client claude\n```\n\n### Manual Installation\n```json\n{\n    \"mcpServer\": {\n        \"command\": \"uvx\",\n        \"args\": [\"--from\", \"git+https://github.com/adhikasp/mcp-twikit\", \"mcp-twikit\"],\n        \"env\": {\n            \"TWITTER_USERNAME\": \"@example\",\n            \"TWITTER_EMAIL\": \"me@example.com\",\n            \"TWITTER_PASSWORD\": \"secret\",\n        }\n    }\n}\n```\n\n## Example usage\n\nUsing [mcp-client-cli](https://github.com/adhikasp/mcp-client-cli)\n\n\n### Comparing sentiments across different twitter accounts\n\n```\n$ llm compare 20 latest tweet directed @IndiHomeCare, @di_cbn, @BiznetHome, @ID_MyRepublic. What are people sentiment to the product? Do 1 search for each account\n\nI'll help you analyze the latest tweets for these internet service providers in Indonesia to understand the public sentiment. I'll use the search_twitter function for each account.\n\nTool Calls:\n  search_twitter\n  Args:\n    query: to:IndiHomeCare\n    count: 20\n    sort_by: Latest\n\nTool Calls:\n  search_twitter\n  Args:\n    query: to:di_cbn\n    count: 20\n    sort_by: Latest\n\nTool Calls:\n  search_twitter\n  Args:\n    query: to:BiznetHome\n    count: 20\n    sort_by: Latest\n\nTool Calls:\n  search_twitter\n  Args:\n    query: to:ID_MyRepublic\n    count: 20\n    sort_by: Latest\n\nSentiment Analysis Summary:\n\n1. IndiHomeCare:\n- Predominantly Negative Sentiment\n- Key Issues:\n  - Unstable internet connection\n  - Slow response times\n  - Intermittent service disruptions\n  - Long waiting times for customer support\n- Specific Complaints:\n  - Network instability\n  - Lagging internet\n  - Unresolved technical issues\n  - Lack of timely communication\n\n2. CBN (di_cbn):\n- Mostly Negative Sentiment\n- Key Issues:\n  - Prolonged internet outages (some reporting 1-2 days of no service)\n  - Slow customer support response\n  - Lack of clear communication about service disruptions\n- Specific Complaints:\n  - LOS (Line of Sight) issues\n  - No timely resolution of technical problems\n  - Delayed email and support responses\n\n3. BiznetHome:\n- Strongly Negative Sentiment\n- Key Issues:\n  - Frequent network interruptions\n  - Slow internet speeds\n  - Poor customer support responsiveness\n- Specific Complaints:\n  - Packet loss\n  - Inconsistent connection\n  - Long download times\n  - Unresolved technical issues\n\n4. MyRepublic (ID_MyRepublic):\n- Extremely Negative Sentiment\n- Key Issues:\n  - Severe and prolonged service disruptions\n  - Complete internet outages\n  - Inability to access online services and games\n  - Extremely poor customer support\n- Specific Complaints:\n  - Multi-day service interruptions\n  - Inability to access websites and online games\n  - Missed technician appointments\n  - Lack of compensation or clear communication\n\nOverall Sentiment Ranking (from Bad to Worst):\n1. IndiHomeCare (Bad)\n2. CBN (Worse)\n3. BiznetHome (Very Bad)\n4. MyRepublic (Extremely Bad)\n\nCommon Themes Across Providers:\n- Poor network stability\n- Slow customer support response\n- Lack of transparent communication\n- Prolonged service interruptions\n- Unresolved technical issues\n\nRecommendation: These Indonesian internet service providers are experiencing significant customer satisfaction issues. Customers are frustrated with unreliable services, poor technical support, and lack of timely problem resolution.\n```\n\n### Getting tweets from your home timeline\n\n```\n$ llm what is happening on my twitter timeline?\n\nI'll help you check your Twitter timeline. I'll retrieve the latest tweets from your timeline:\n\nTool Calls:\n  get_timeline\n  Args:\n\nI'll summarize the key highlights from your Twitter timeline:\n\n1. Professional/Tech Highlights:\n- @ibamarief is preparing to onboard their first intern, noting it's a significant responsibility\n- @papanberjalan shared a critique about web developers not understanding computer performance\n- @pathofexile is running a Twitch Drops promotion for their game\n\n2. Notable Tweets:\n- @elonmusk posted a cryptic \"Hmm\"\n- @realDonaldTrump discussed eliminating Daylight Saving Time\n- @blinkist shared an article about billionaires reading up to 50 books per year\n\n3. Miscellaneous Interesting Tweets:\n- @nealtaparia shared a thread about 11 companies built around a single product\n- @Rixhabh__ posted about creative and iconic ads\n- Several tweets in Indonesian covering various topics from personal stories to social issues\n\nWould you like me to elaborate on any of these tweets or provide more context about any specific post?\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "aditya002p--mcp-server": {
          "owner": "aditya002p",
          "name": "mcp-server",
          "url": "https://github.com/aditya002p/mcp-server",
          "imageUrl": "https://github.com/aditya002p.png",
          "description": "Enables AI models to conduct real-time web searches, including academic paper searches, social media queries, and company research using a search API. Provides structured search results with content snippets and supports caching of recent searches for quick access.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:07.320521",
          "collection_timestamp": "2025-10-02T15:03:32.155967",
          "stars": 0,
          "forks": 0,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-04-27T14:21:46Z",
          "updated_at": "2025-04-27T14:22:52Z",
          "open_issues": 0,
          "readme_content": "# Exa MCP Server üîç\n[![npm version](https://badge.fury.io/js/exa-mcp-server.svg)](https://www.npmjs.com/package/exa-mcp-server)\n[![smithery badge](https://smithery.ai/badge/exa)](https://smithery.ai/server/exa)\n\nA Model Context Protocol (MCP) server lets AI assistants like Claude use the Exa AI Search API for web searches. This setup allows AI models to get real-time web information in a safe and controlled way.\n\nDemo video https://www.loom.com/share/ac676f29664e4c6cb33a2f0a63772038?sid=0e72619f-5bfc-415d-a705-63d326373f60\n\n\n## What is MCP? ü§î\n\nThe Model Context Protocol (MCP) is a system that lets AI apps, like Claude Desktop, connect to external tools and data sources. It gives a clear and safe way for AI assistants to work with local services and APIs while keeping the user in control.\n\n## What does this server do? üöÄ\n\nThe Exa MCP server:\n- Enables AI assistants to perform web searches using Exa's powerful search API\n- Provides structured search results including titles, URLs, and content snippets\n- Caches recent searches as resources for reference\n- Handles rate limiting and error cases gracefully\n- Supports real-time web crawling for fresh content\n\n\n## Prerequisites üìã\n\nBefore you begin, ensure you have:\n\n- [Node.js](https://nodejs.org/) (v18 or higher)\n- [Claude Desktop](https://claude.ai/download) installed\n- An [Exa API key](https://dashboard.exa.ai/api-keys)\n- Git installed\n\nYou can verify your Node.js installation by running:\n```bash\nnode --version  # Should show v18.0.0 or higher\n```\n\n## Installation üõ†Ô∏è\n\n### NPM Installation\n\n```bash\nnpm install -g exa-mcp-server\n```\n\n### Using Smithery\n\nTo install the Exa MCP server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/exa):\n\n```bash\nnpx -y @smithery/cli install exa --client claude\n```\n\n### Manual Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/exa-labs/exa-mcp-server.git\ncd exa-mcp-server\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n4. Create a global link (this makes the server executable from anywhere):\n\n```bash\nnpm link\n```\n\n## Configuration ‚öôÔ∏è\n\n### 1. Configure Claude Desktop to recognize the Exa MCP server\n\nYou can find claude_desktop_config.json inside the settings of Claude Desktop app:\n\nOpen the Claude Desktop app and enable Developer Mode from the top-left menu bar. \n\nOnce enabled, open Settings (also from the top-left menu bar) and navigate to the Developer Option, where you'll find the Edit Config button. Clicking it will open the claude_desktop_config.json file, allowing you to make the necessary edits. \n\nOR (if you want to open claude_desktop_config.json from terminal)\n\n#### For macOS:\n\n1. Open your Claude Desktop configuration:\n\n```bash\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n#### For Windows:\n\n1. Open your Claude Desktop configuration:\n\n```powershell\ncode %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n### 2. Add the Exa server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\"/path/to/exa-mcp-server/build/index.js\"],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nReplace `your-api-key-here` with your actual Exa API key from [dashboard.exa.ai/api-keys](https://dashboard.exa.ai/api-keys).\n\n### 3. Available Tools & Tool Selection\n\nThe Exa MCP server includes the following tools:\n\n- **web_search_exa**: Performs real-time web searches with optimized results and content extraction.\n- **research_paper_search**: Specialized search focused on academic papers and research content.\n- **twitter_search**: Dedicated Twitter/X.com search that finds tweets, profiles, and conversations.\n- **company_research**: Comprehensive company research tool that crawls company websites to gather detailed information about businesses.\n- **crawling**: Extracts content from specific URLs, useful for reading articles, PDFs, or any web page when you have the exact URL.\n- **competitor_finder**: Identifies competitors of a company by searching for businesses offering similar products or services.\n- **linkedin_search**: Search LinkedIn for companies and people using Exa AI. Simply include company names, person names, or specific LinkedIn URLs in your query.\n\nYou can choose which tools to enable by adding the `--tools` parameter to your Claude Desktop configuration:\n\n#### Specify which tools to enable:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"/path/to/exa-mcp-server/build/index.js\",\n        \"--tools=web_search_exa,research_paper_search,twitter_search,company_research,crawling,competitor_finder,linkedin_search\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nFor enabling multiple tools, use a comma-separated list:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"/path/to/exa-mcp-server/build/index.js\",\n        \"--tools=web_search_exa,research_paper_search,twitter_search,company_research,crawling,competitor_finder,linkedin_search\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nIf you don't specify any tools, all tools enabled by default will be used.\n\n### 4. Restart Claude Desktop\n\nFor the changes to take effect:\n\n1. Completely quit Claude Desktop (not just close the window)\n2. Start Claude Desktop again\n3. Look for the üîå icon to verify the Exa server is connected\n\n## Using via NPX\n\nIf you prefer to run the server directly, you can use npx:\n\n```bash\n# Run with all tools enabled by default\nnpx exa-mcp-server\n\n# Enable specific tools only\nnpx exa-mcp-server --tools=web_search_exa\n\n# Enable multiple tools\nnpx exa-mcp-server --tools=web_search_exa,research_paper_search\n\n# List all available tools\nnpx exa-mcp-server --list-tools\n```\n\n## Usage üéØ\n\nOnce configured, you can ask Claude to perform web searches. Here are some example prompts:\n\n```\nCan you search for recent developments in quantum computing?\n```\n\n```\nFind and analyze recent research papers about climate change solutions.\n```\n\n```\nSearch Twitter for posts from @elonmusk about SpaceX.\n```\n\n```\nFind tweets from @samaltman that were published in the last week about AI safety.\n```\n\n```\nResearch the company exa.ai and find information about their pricing and features.\n```\n\n```\nExtract the content from this research paper: https://arxiv.org/pdf/1706.03762\n```\n\n```\nFind competitors for a company that provides web search API services, excluding exa.ai from the results.\n```\n\n```\nFind the LinkedIn profile for Anthropic company.\n```\n\n```\nSearch for data scientists at OpenAI on LinkedIn.\n```\n\nThe server will:\n\n1. Process the search request\n2. Query the Exa API with optimal settings (including live crawling)\n3. Return formatted results to Claude\n4. Cache the search for future reference\n\n\n## Testing with MCP Inspector üîç\n\nYou can test the server directly using the MCP Inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector node ./build/index.js\n```\n\nThis opens an interactive interface where you can explore the server's capabilities, execute search queries, and view cached search results.\n\n## Troubleshooting üîß\n\n### Common Issues\n\n1. **Server Not Found**\n   * Verify the npm link is correctly set up\n   * Check Claude Desktop configuration syntax\n   * Ensure Node.js is properly installed\n\n2. **API Key Issues**\n   * Confirm your EXA_API_KEY is valid\n   * Check the EXA_API_KEY is correctly set in the Claude Desktop config\n   * Verify no spaces or quotes around the API key\n\n3. **Connection Issues**\n   * Restart Claude Desktop completely\n   * Check Claude Desktop logs:\n   \n   ```bash\n   # macOS\n   tail -n 20 -f ~/Library/Logs/Claude/mcp*.log\n   \n   # Windows\n   type \"%APPDATA%\\Claude\\logs\\mcp*.log\"\n   ```\n\n## Acknowledgments üôè\n\n* [Exa AI](https://exa.ai) for their powerful search API\n* [Model Context Protocol](https://modelcontextprotocol.io) for the MCP specification\n* [Anthropic](https://anthropic.com) for Claude Desktop\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-server",
          "npm_downloads": 29652,
          "npm_package_name": "mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "adityak74--mcp-scholarly": {
          "owner": "adityak74",
          "name": "mcp-scholarly",
          "url": "https://github.com/adityak74/mcp-scholarly",
          "imageUrl": "https://github.com/adityak74.png",
          "description": "Search for academic articles in arXiv, providing access to a range of scholarly content and resources.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:08.305515",
          "collection_timestamp": "2025-10-02T15:03:40.555442",
          "stars": 155,
          "forks": 22,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-01-01T05:34:06Z",
          "updated_at": "2025-09-24T23:11:12Z",
          "open_issues": 4,
          "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/adityak74-mcp-scholarly-badge.png)](https://mseep.ai/app/adityak74-mcp-scholarly)\n\n# mcp-scholarly MCP server\n[![smithery badge](https://smithery.ai/badge/mcp-scholarly)](https://smithery.ai/server/mcp-scholarly)\n\nA MCP server to search for accurate academic articles. More scholarly vendors will be added soon.\n\n![demo1.jpeg](examples/demo1.png)\n\n![image](https://github.com/user-attachments/assets/13202184-bc12-4530-b7c1-2ee698f3e1cc)\n\n<a href=\"https://glama.ai/mcp/servers/aq05b2p0ql\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/aq05b2p0ql/badge\" alt=\"Scholarly Server MCP server\" /></a>\n\n![star-history-202551](https://github.com/user-attachments/assets/f22d5796-017c-4c53-b230-101a09a28118)\n\n\n## Components\n\n### Tools\n\nThe server implements one tool:\n- search-arxiv: Search arxiv for articles related to the given keyword.\n  - Takes \"keyword\" as required string arguments\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"mcp-scholarly\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/adityakarnam/PycharmProjects/mcp-scholarly/mcp-scholarly\",\n        \"run\",\n        \"mcp-scholarly\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"mcp-scholarly\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-scholarly\"\n      ]\n    }\n  }\n  ```\n</details>\n\nor if you are using Docker\n\n<details>\n  <summary>Published Docker Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"mcp-scholarly\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"--rm\", \"-i\",\n        \"mcp/scholarly\"\n      ]\n    }\n  }\n  ```\n</details>\n\n### Installing via Smithery\n\nTo install mcp-scholarly for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-scholarly):\n\n```bash\nnpx -y @smithery/cli install mcp-scholarly --client claude\n```\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /Users/adityakarnam/PycharmProjects/mcp-scholarly/mcp-scholarly run mcp-scholarly\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "aeon-seraph--searxng-mcp": {
          "owner": "aeon-seraph",
          "name": "searxng-mcp",
          "url": "https://github.com/aeon-seraph/searxng-mcp",
          "imageUrl": "https://github.com/aeon-seraph.png",
          "description": "Enables language models to perform web searches through the SearXNG search engine by sending search queries and receiving formatted results. Facilitates real-time data retrieval for enhanced model responses.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:09.303433",
          "collection_timestamp": "2025-10-02T15:03:45.742302",
          "stars": 2,
          "forks": 1,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-08T01:27:35Z",
          "updated_at": "2025-09-03T22:50:38Z",
          "open_issues": 1,
          "readme_content": "# SearXNG Model Context Protocol Server\n\nA Model Context Protocol (MCP) server for interfacing language models with SearXNG search engine.\n\n## Description\n\nThis server enables language models to perform web searches through SearXNG using the Model Context Protocol standard. It provides a clean interface for language models to send search queries to SearXNG and receive formatted results.\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/aeon-seraph/searxng-mcp.git\ncd searxng-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Requirements\n\n- Node.js 16+\n- A running SearXNG instance (by default at http://localhost:8888)\n\n## Usage\n\n```bash\n# Run the server\nnode build/index.js\n```\n\nThe server will run on stdio, making it suitable for integration with MCP-compatible language models.\n\n## Configuration\n\nThe server can be configured using environment variables:\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| SEARXNG_PROTOCOL | Protocol to use (http/https) | http |\n| SEARXNG_HOST | SearXNG host | localhost |\n| SEARXNG_PORT | SearXNG port | 8888 |\n| CACHE_TTL | Cache time-to-live in milliseconds | 600000 (10 minutes) |\n| MAX_CACHE_SIZE | Maximum number of cached queries | 100 |\n\nExample:\n```bash\nSEARXNG_HOST=mysearx.example.com SEARXNG_PORT=443 SEARXNG_PROTOCOL=https node build/index.js\n```\n\n## Docker\n\nThe project includes a Dockerfile for easy deployment:\n\n```bash\n# Build the Docker image\ndocker build -t searxng-mcp .\n\n# Run the container\ndocker run -e SEARXNG_HOST=mysearx.example.com -e SEARXNG_PROTOCOL=https searxng-mcp\n```\n\n## Search Parameters\n\nThe search function supports the following parameters:\n\n- `query` (required): The search query string\n- `categories`: Comma-separated list of search categories\n- `pageno`: Search page number (default: 1)\n- `time_range`: Time range for results (\"day\", \"week\", \"month\", \"year\")\n- `raw_json`: Return raw JSON response instead of formatted text (default: false)\n\n## License\n\nMIT ",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/searxng-mcp",
          "npm_downloads": 262,
          "npm_package_name": "searxng-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "afrise--academic-search-mcp-server": {
          "owner": "afrise",
          "name": "academic-search-mcp-server",
          "url": "https://github.com/afrise/academic-search-mcp-server",
          "imageUrl": "https://github.com/afrise.png",
          "description": "Enables searching and retrieving academic paper information from multiple sources, providing access to paper metadata, abstracts, and full-text content when available. It returns structured data responses adhering to the MCP specification.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:10.115608",
          "collection_timestamp": "2025-10-02T15:03:53.601248",
          "stars": 74,
          "forks": 8,
          "license": "GNU Affero General Public License v3.0",
          "language": "Python",
          "created_at": "2025-02-07T19:47:16Z",
          "updated_at": "2025-10-01T06:44:17Z",
          "open_issues": 2,
          "readme_content": "# Academic Paper Search MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@afrise/academic-search-mcp-server)](https://smithery.ai/server/@afrise/academic-search-mcp-server)\n\nA [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol) server that enables searching and retrieving academic paper information from multiple sources.\n\nThe server provides LLMs with:\n- Real-time academic paper search functionality  \n- Access to paper metadata and abstracts\n- Ability to retrieve full-text content when available\n- Structured data responses following the MCP specification\n\nWhile primarily designed for integration with Anthropic's Claude Desktop client, the MCP specification allows for potential compatibility with other AI models and clients that support tool/function calling capabilities (e.g. OpenAI's API).\n\n**Note**: This software is under active development. Features and functionality are subject to change.\n\n<a href=\"https://glama.ai/mcp/servers/kzsu1zzz9j\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/kzsu1zzz9j/badge\" alt=\"Academic Paper Search Server MCP server\" /></a>\n\n## Features\n\nThis server exposes the following tools:\n- `search_papers`: Search for academic papers across multiple sources\n  - Parameters:\n    - `query` (str): Search query text\n    - `limit` (int, optional): Maximum number of results to return (default: 10)\n  - Returns: Formatted string containing paper details\n  \n- `fetch_paper_details`: Retrieve detailed information for a specific paper\n  - Parameters:\n    - `paper_id` (str): Paper identifier (DOI or Semantic Scholar ID)\n    - `source` (str, optional): Data source (\"crossref\" or \"semantic_scholar\", default: \"crossref\")\n  - Returns: Formatted string with comprehensive paper metadata including:\n    - Title, authors, year, DOI\n    - Venue, open access status, PDF URL (Semantic Scholar only)\n    - Abstract and TL;DR summary (when available)\n\n- `search_by_topic`: Search for papers by topic with optional date range filter\n  - Parameters:\n    - `topic` (str): Search query text (limited to 300 characters)\n    - `year_start` (int, optional): Start year for date range \n    - `year_end` (int, optional): End year for date range\n    - `limit` (int, optional): Maximum number of results to return (default: 10)\n  - Returns: Formatted string containing search results including:\n    - Paper titles, authors, and years\n    - Abstracts and TL;DR summaries when available\n    - Venue and open access information\n\n## Setup\n\n\n### Installing via Smithery\n\nTo install Academic Paper Search Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@afrise/academic-search-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @afrise/academic-search-mcp-server --client claude\n```\n\n***note*** this method is largely untested, as their server seems to be having trouble. you can follow the standalone instructions until smithery gets fixed. \n\n### Installing via uv (manual install): \n\n1. Install dependencies:\n```sh\nuv add \"mcp[cli]\" httpx\n```\n\n2. Set up required API keys in your environment or `.env` file:\n```sh\n#  These are not actually implemented\nSEMANTIC_SCHOLAR_API_KEY=your_key_here \nCROSSREF_API_KEY=your_key_here  # Optional but recommended\n```\n\n3. Run the server:\n```sh\nuv run server.py\n```\n\n## Usage with Claude Desktop\n\n1. Add the server to your Claude Desktop configuration (`claude_desktop_config.json`):\n```json\n{\n  \"mcpServers\": {\n    \"academic-search\": {\n      \"command\": \"uv\",\n      \"args\": [\"run \", \"/path/to/server/server.py\"],\n      \"env\": {\n        \"SEMANTIC_SCHOLAR_API_KEY\": \"your_key_here\",\n        \"CROSSREF_API_KEY\": \"your_key_here\"\n      }\n    }\n  }\n}\n```\n\n2. Restart Claude Desktop\n\n\n## Development\n\nThis server is built using:\n- Python MCP SDK\n- FastMCP for simplified server implementation\n- httpx for API requests\n\n## API Sources\n\n- Semantic Scholar API\n- Crossref API\n\n## License\n\nThis project is licensed under the GNU Affero General Public License v3.0 (AGPL-3.0). This license ensures that:\n\n- You can freely use, modify, and distribute this software\n- Any modifications must be open-sourced under the same license\n- Anyone providing network services using this software must make the source code available\n- Commercial use is allowed, but the software and any derivatives must remain free and open source\n\nSee the [LICENSE](LICENSE) file for the full license text.\n\n## Contributing\n\nContributions are welcome! Here's how you can help:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nPlease note:\n- Follow the existing code style and conventions\n- Add tests for any new functionality\n- Update documentation as needed\n- Ensure your changes respect the AGPL-3.0 license terms\n\nBy contributing to this project, you agree that your contributions will be licensed under the AGPL-3.0 license.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AI-Agent-Hub--mcp-marketplace": {
          "owner": "AI-Agent-Hub",
          "name": "mcp-marketplace",
          "url": "https://github.com/AI-Agent-Hub/mcp-marketplace",
          "imageUrl": "https://github.com/AI-Agent-Hub.png",
          "description": "A web-based plugin that enables browsing, selecting, and installing MCP tools from various marketplaces, enhancing AI agents with capabilities such as map location, search, and payment integration. It features an autonomous tool dispatcher to optimize tool selection based on ratings and usage statistics.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:11.025576",
          "collection_timestamp": "2025-10-02T15:04:01.477914",
          "stars": 28,
          "forks": 5,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-05-06T14:51:48Z",
          "updated_at": "2025-09-29T00:49:24Z",
          "open_issues": 0,
          "readme_content": "## Open MCP Marketplace | AI Agent Store Marketplace Index | OneKey MCP Router | AI Agent & MCP Moneytization Revenue Sharing plans | MCP Tool Use Agent from DeepNLP\n\n\n[![MCP Marketplace User Review Rating Badge](https://www.deepnlp.org/api/marketplace/svg?name=ai-agent-marketplace-index/ai-agent-marketplace-index)](https://www.deepnlp.org/store/mcp-server/mcp-server/pub-ai-agent-marketplace-index/ai-agent-marketplace-index) |\n[![AI Agent Marketplace DeepNLP](https://www.deepnlp.org/api/ai_agent_marketplace/svg?name=ai-agent-marketplace-index/ai-agent-marketplace-index)](https://www.deepnlp.org/store/mcp-server/mcp-server/pub-ai-agent-marketplace-index/ai-agent-marketplace-index) |\n[WeChat](https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/docs/mcp_marketplace_wechat_group.png)\n\n\nVisit the website [MCP Tool Use Agent App](https://agent.deepnlp.org/agent/mcp_tool_use) to explore MCP Servers with sota agentic AI Search/Deep Research, Finance Data,Chart Creation, Excel Spreadsheet/Powerpoint usage.\n\n\n**[MCP Open Marketplace and Search Engine](https://www.deepnlp.org/store/ai-agent/mcp-server)**<br>\n<img src=\"https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/docs/mcp_marketplace_intro.png\" alt=\"mcp marketplace\" width=\"300\" style=\"object-fit: contain;\">\n\n**[MCP Tool Use Agent App](https://agent.deepnlp.org/agent/mcp_tool_use)**<br>\n<img src=\"https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/app/mcp_tool_use/docs/demo_plot_chart.jpg\" alt=\"mcp tool use agent\" width=\"300\" style=\"object-fit: contain;\">\n\n\n## Basic\n\nOpen MCP Marketplace is an open source project aims to make MCP Servers integration into your AI Agent Workflow **Easier**.\n\n- **MCP Search Engine and Marketplace**: [MCP Marketplace Index](https://www.deepnlp.org/store/ai-agent/mcp-server) and [MCP Search Engine](https://www.deepnlp.org/search/agent)\n- **MCP OneKey Router** Use Just One Access Key to Authenticate and Use commercial MCPs, AI Agent & MCP Moneytization Revenue Sharing plans: [OneKey MCP Router](https://github.com/AI-Agent-Hub/OneKey-MCP-Router) introduction and proxy [Onekey MCP servers App](https://github.com/AI-Agent-Hub/mcp-marketplace/tree/main/app/onekey_mcp_router).\n- **MCP Server Tool Meta and Config**: You can get well-cleaned up MCP Servers Tools Meta information, Tools and Config Schema, etc. \n- **Web Based MCP Client with Admin Page**: Similar to Claude Desktop, Cursor, and many other clients, Open MCP-Marketplace provides a pured web based MCP client and Admin Page to connect(Start/End) and use MCP tools.\n- **Agent ToolBox**: Explore, Search Various 11k+ MCP Servers from open mcp marketplace. You can also filter by category, such as official, browser use, map, finance, coding, office software usage, etc.\n- **Various AI Agent Apps Support**: You can easily integrate the app into your existing Chatbot, AI Search/Deep Research Engine, Excel Spreadsheet/Powerpoint Creation, Video/Image generation, Coding IDE, etc. \n- **Public API Access**: Visit [API Documentation](http://deepnlp.org/doc/mcp-marketplace) to search related mcp server and tools by keywords, category and more.\n- **MCP Tool Use Agent and Workflow App**: [MCP Tool Use Agent Source Code](https://github.com/AI-Agent-Hub/mcp-marketplace/tree/main/app/mcp_tool_use)\n- **Python/Typescript Package Support**: [Pypi](https://pypi.org/project/mcp-marketplace/), Npm\n\n\n\n## News\n\n- **OneKey MCP Router**: Use OneKey to Access commercial MCPs. Visit [OneKey MCP Router](https://github.com/AI-Agent-Hub/OneKey-MCP-Router) for details.\n- **Upgraded: Office File Agent and Visualization Agent**: Excel spreadsheet data writing and data analysis agent, Powerpoint generation, Charts Creation. [Excel Spreadsheet Agent](https://agent.deepnlp.org/agent/mcp_tool_use?server=haris-musa/excel-mcp-server), [Visualization Agent](https://agent.deepnlp.org/agent/mcp_tool_use?server=antvis/mcp-server-chart)\n- **Live MCP Tool Use Agent is Online**, Visit the [MCP Tool Use Agent App](https://agent.deepnlp.org/agent/mcp_tool_use) to see the workflows\n\n\n## Example MCP Categories Usage\n\n| Domain | Related MCP Server|  Demo |\n| ---- | ---- |  ----  |\n| Office File Agent |  Excel Spreadsheet, Powerpoint, PDF, etc | [Example](https://agent.deepnlp.org/agent/mcp_tool_use/share/ee640008-6bc1-4c3a-832b-2557f985b540) [MCP]() |\n| AI Search/Deep Research | Bing/Google Custom/Perplexity/Tavily/Firecrawl |  [Demo](https://agent.deepnlp.org/agent/mcp_tool_use?server=tavily-ai/tavily-mcp) [MCP]() |\n| Map Trip Planning | GoogleMap, Amap(Gaode), BaiduMap, etc. | [Example](https://agent.deepnlp.org/agent/mcp_tool_use/share/8ab0b25c-b72d-4cae-9c86-a852df8c6541)  [MCP](https://agent.deepnlp.org/agent/mcp_tool_use?server=amap-mcp/amap-mcp-%E9%AB%98%E5%BE%B7%E5%9C%B0%E5%9B%BE-mcp) [Use MCP]() |\n| Browser Usage | Playwright, Puppeteer, etc. |  [Demo](https://agent.deepnlp.org/agent/mcp_tool_use?server=puppeteer/puppeteer) [MCP]()  |\n| Chart,Graph,Image | everart,mcp-server-charts(AntV),canva-mcp |  [Demo](https://agent.deepnlp.org/agent/mcp_tool_use/share/93d94694-e673-49d3-b805-820c4ef842bd) [MCP]() |\n\n\n\n**Example: Route Planning using Google Map MCP**\n```\nq=Find the best route from JFK Airport to Times Square in New York\n```\n![Route Planning](https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/app/mcp_tool_use/docs/route_planning_mcp_v2.jpg)\n\n\n**Example: Office Agent Excel Spreadsheet and Powerpoint Creation Usage**\n```\nq=Write below information to an excel spreadsheet. Derek: male, graduated in years 2019, IT department, Jenifer: female graduated in 2024 Sales and Marketing department, Alan: male, graduated in 2021 in R&D department, Paul: mail, graduated in 2015, Staff in Operations department. Please formalize the data into three columns: name, graduation year and department. Then use spreadsheet formula to calculate the percentage of employees graduated within 3 years.\n```\n\n![Excel Agent](https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/app/mcp_tool_use/docs/office_excel_use_agent.jpg)\n\n[Excel Spreadsheet and Powerpoint Office Agent](https://agent.deepnlp.org/agent/mcp_tool_use/share/36f34bd2-5527-40b7-9365-5f0c33fd5e22)\n\n\n**Exmaple: Chart Plotting**\n\n```\nq=Plot a pie chart showing 25% of employees graduated within 3 years and 75% graduated more than 3 years ago.\n```\n![Chart Plotting](https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/app/mcp_tool_use/docs/demo_plot_chart.jpg)\n\n[Excel Spreadsheet and Powerpoint Office Agent](https://agent.deepnlp.org/agent/mcp_tool_use/share/93d94694-e673-49d3-b805-820c4ef842bd)\n\n\n**Example: AI Search Deep Research**\n\nVisit [MCP Tool Use App](https://github.com/AI-Agent-Hub/mcp-marketplace/tree/main/app/ai_search)\n\n\n**Example: MCP Admin and Playground To Manage Tools and Servers**\n\nVisit [MCP Tool Use App](https://github.com/AI-Agent-Hub/mcp-marketplace/tree/main/app/mcp_tool_use)\n\n![MCP Marketplace Tool Use](https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/app/mcp_tool_use/docs/marketplace_mcp_admin.jpg?raw=true)\n\n\n## KEY Features\n\n1. MCP Server Public Index of Tools Schema and Config file\nDataset Collection of MCP Servers Tool/Function Call Schemas from 5000+ MCP servers, Useful for Tools RAG, Tools Dispatcher research and R&D. You can search route planning or \"map\" keywords from raw schema files. Welcome to add your config to the index. [MCP Tool Schema](./tools/README.md)\n\n2. MCP Marketplace Web Integration, See Web Demo and Video how to integrate the Open MCP Marketplace to Your AI Search Engine or Agent Workflow.\n\n- **Pure Web-based Plugin** : Show the Panel of MCP Tools from available open MCP marketplace, Support Filtering, Search, Installation  <br>\n- **Browse Navigate and Pagination** : User can browser the MCP Tools by category and use pagination to navigate. <br>\n- **Customized MCP servers Selection and Installation** : Users can choose which MCP tools to perform tasks from mcp tools marketplace with similar features, such as Map Location, Search, Fetch, Payment, etc.  <br>\n- **Badge**: Put Badge on your homepage Track MCP Servers User Reviews and Ratings, such as ![MCP Marketplace User Review Rating Badge](https://www.deepnlp.org/api/marketplace/svg?name=ai-agent-marketplace-index/ai-agent-marketplace-index)\n\n\n3. Various API Endpoint Support for Your AI Client Development\n\n- **Various MCP Marketplace API Endpoint**: Get Server Schema, Such as [pulsemcp.com](https://www.pulsemcp.com), [deepnlp.org](https://www.deepnlp.org), [aiagenta2z.com](https://www.aiagenta2z.com),etc. <br>\n- **GET/UPDATE/CREATE** MCP Servers Meta information to get your MCP Server more visibilityy. <br>\n- **Python and Typescript SDK** Search and registry of MCP Servers and Tools <br>\n- **Rich Meta Data** Tools, Servers Description, URL, Category, Github stars, User reviews score, Ratings and more statistics. <br>\n\n\n4. Agent Workflow of MCP Marketplace\n- [**MCP Tools Dispatcher Agent**](#tool_dispatcher): The MCP Tool Dispatcher Agent helps to retrieve relevent tools from thousands of MCP servers and tools from marketplace, and reduce the context token length of function call LLM.\n\n\n## 1. MCP Server Public Index of Tools Schema and <code>mcp.config</code> file\n\nSee [MCP Tool Schema](./tools/README.md) for details. \n\nCollected tools schema from google map mcp\n```\n{\"name\": \"maps_geocode\", \"description\": \"Convert an address into geographic coordinates\", \"input_schema\": {\"type\": \"object\", \"properties\": {\"address\": {\"type\": \"string\", \"description\": \"The address to geocode\"}}, \"required\": [\"address\"]}}\n{\"name\": \"maps_directions\", \"description\": \"Get directions between two points\", \"input_schema\": {\"type\": \"object\", \"properties\": {\"origin\": {\"type\": \"string\", \"description\": \"Starting point address or coordinates\"}, \"destination\": {\"type\": \"string\", \"description\": \"Ending point address or coordinates\"}, \"mode\": {\"type\": \"string\", \"description\": \"Travel mode (driving, walking, bicycling, transit)\", \"enum\": [\"driving\", \"walking\", \"bicycling\", \"transit\"]}}, \"required\": [\"origin\", \"destination\"]}}\n\n```\n\n## 2. MCP Marketplace Web Client Integration\n\n\n\n### MCP Tool Use Agent\n\n\nMCP Marketplace Browse and Pagination of MCP Servers [Demo](https://agent.deepnlp.org/agent/mcp_tool_use)\n\n![Excel Agent](https://raw.githubusercontent.com/AI-Agent-Hub/mcp-marketplace/refs/heads/main/app/mcp_tool_use/docs/office_excel_use_agent.jpg)\n\n\n\n## 3. Various API Endpoint Support for Your AI Client Development\n### Supported MCP Marketplace API Provider\n\n\n| Endpoint | API | Website |\n| --- | ---- | ---- |\n| deepnlp.org | https://www.deepnlp.org/api/mcp_marketplace/v1 | https://www.deepnlp.org/doc/mcp_marketplace |\n| pulsemcp.com | https://api.pulsemcp.com/v0beta/servers | https://www.pulsemcp.com/api |\n\n\n### Python and Typescript SDK\n\nFor official documentation of MCP Marketplace API, please check https://www.deepnlp.org/doc/mcp_marketplace\n, [Python SDK](./python/README.md) and [Typescript SDK (WIP)]()\n\n**Installation**\n\n```\npip install mcp-marketplace\n\n```\n**Usage**\n\n#### Search MCP Server \n\nSearch MCP Server by Meta Information by unique id, query or category\n\n\n```\nimport mcp_marketplace as mcpm\n\n## endpoint: deepnlp\nmcpm.set_endpoint(\"deepnlp\")\nresult = mcpm.search(query=\"map\", page_id=0, count_per_page=20, mode=\"dict\")\nprint (result)\n\nserver_id = \"financial-datasets/mcp-server\"\nresult2 = mcpm.search(query=\"financial datasets\", count_per_page=20, offset=0)\nprint (result2)\n\n## Search By Unique ID:  e.g. github {owner_name}/{repo_name}\nresult_id = mcpm.search(id=\"puppeteer/puppeteer\", mode=\"list\", page_id=0, count_per_page=100, config_name=\"deepnlp\")\n\n# search by batch query\nquery_list = [\"map\", \"navigation\", \"route planning\"]\nparams_list = [{\"query\": query, \"page_id\":0, \"count_per_page\":50} for query in query_list]\nresults = mcpm.search_batch(params_list)\n\n```\n\n**Curl Endpoint**\n\n```\ncurl https://www.deepnlp.org/api/mcp_marketplace/v1/server/google-maps/google-maps\n```\n\n**Result**\n\n```\n{\n  \"total_hits\": 1,\n  \"id\": \"google-maps/google-maps\",\n  \"items\": [{\n    \"content_name\": \"Google Maps\",\n    \"publisher_id\": \"pub-google-maps\",\n    \"website\": \"https://github.com/modelcontextprotocol/servers/tree/main/src/google-maps\",\n    \"review_cnt\": \"2\",\n    \"rating\": \"4.5\",\n    \"description\": \"Google Maps  Location services, directions, and place details\\r\\n\\r\\n# Google Maps MCP Server\\r\\n\\r\\nMCP Server for the Google Maps API.\\r\\n\\r\\n## Tools\\r\\n\\r\\n1. \\\\`maps_geocode\\\\`\\r\\n\\r\\n   - Convert address to coordinates\\r\\n   - Input: \\\\`address\\\\` (string)\\r\\n   - Returns: location, formatted_address, place_id\\r\\n\\r\\n2. \\\\`maps_reverse_geocode\\\\`\\r\\n\\r\\n   - Convert coordinates to address\\r\\n   - Inputs:\\r\\n     - \\\\`latitude\\\\` (numb\",\n    \"ext_info\": {\n      \"tools\": []\n    },\n    \"subfield\": \"MAP\",\n    \"field\": \"MCP SERVER\",\n    \"id\": \"google-maps/google-maps\",\n    \"content_tag_list\": \"official\",\n    \"config\": [],\n    \"thumbnail_picture\": \"https://118.190.154.215/scripts/img/ai_service_content/b7fe82a3ab985ce1a953f7b4ad9c5e01.jpeg\"\n  }]\n}\n```\n\n\n#### List Available Tools \n```\n\nimport mcp_marketplace as mcpm\n\nserver_id = \"google-maps/google-maps\"\nresult = mcpm.list_tools(id=server_id, config_name=\"deepnlp_tool\")\n    \nserver_id = \"puppeteer/puppeteer\"\nresult = mcpm.list_tools(id=server_id, config_name=\"deepnlp_tool\")\n\n```\n\n**Curl Endpoint**\n\n```\ncurl https://www.deepnlp.org/api/mcp_marketplace/v1/tools/google-maps/google-maps\n```\n\n```\n{\"id\":\"/google-maps/google-maps\",\"tools\":[{\"name\":\"maps_geocode\",\"description\":\"Convert an address into geographic coordinates\",\"input_schema\":{\"type\":\"object\",\"properties\":{\"address\":{\"type\":\"string\",\"description\":\"The address to geocode\"}},\"required\":[\"address\"]}},{\"name\":\"maps_reverse_geocode\",\"description\":\"Convert coordinates into an address\",\"input_schema\":{\"type\":\"object\",\"properties\":{\"latitude\":{\"type\":\"number\",\"description\":\"Latitude coordinate\"},\"longitude\":{\"type\":\"number\",\"description\":\"Longitude coordinate\"}},\"required\":[\"latitude\",\"longitude\"]}},{\"name\":\"maps_search_places\",\"description\":\"Search for places using Google Places API\",\"input_schema\":{\"type\":\"object\",\"properties\":{\"query\":{\"type\":\"string\",\"description\":\"Search query\"},\"location\":{\"type\":\"object\",\"properties\":{\"latitude\":{\"type\":\"number\"},\"longitude\":{\"type\":\"number\"}},\"description\":\"Optional center point for the search\"},\"radius\":{\"type\":\"number\",\"description\":\"Search radius in meters (max 50000)\"}},\"required\":[\"query\"]}},{\"name\":\"maps_place_details\",\"description\":\"Get detailed information about a specific place\",\"input_schema\":{\"type\":\"object\",\"properties\":{\"place_id\":{\"type\":\"string\",\"description\":\"The place ID to get details for\"}},\"required\":[\"place_id\"]}},{\"name\":\"maps_distance_matrix\",\"description\":\"Calculate travel distance and time for multiple origins and destinations\",\"input_schema\":{\"type\":\"object\",\"properties\":{\"origins\":{\"type\":\"array\",\"items\":{\"type\":\"string\"},\"description\":\"Array of origin addresses or coordinates\"},\"destinations\":{\"type\":\"array\",\"items\":{\"type\":\"string\"},\"description\":\"Array of destination addresses or coordinates\"},\"mode\":{\"type\":\"string\",\"description\":\"Travel mode (driving, walking, bicycling, transit)\",\"enum\":[\"driving\",\"walking\",\"bicycling\",\"transit\"]}},\"required\":[\"origins\",\"destinations\"]}},{\"name\":\"maps_elevation\",\"description\":\"Get elevation data for locations on the earth\",\"input_schema\":{\"type\":\"object\",\"properties\":{\"locations\":{\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"latitude\":{\"type\":\"number\"},\"longitude\":{\"type\":\"number\"}},\"required\":[\"latitude\",\"longitude\"]},\"description\":\"Array of locations to get elevation for\"}},\"required\":[\"locations\"]}},{\"name\":\"maps_directions\",\"description\":\"Get directions between two points\",\"input_schema\":{\"type\":\"object\",\"properties\":{\"origin\":{\"type\":\"string\",\"description\":\"Starting point address or coordinates\"},\"destination\":{\"type\":\"string\",\"description\":\"Ending point address or coordinates\"},\"mode\":{\"type\":\"string\",\"description\":\"Travel mode (driving, walking, bicycling, transit)\",\"enum\":[\"driving\",\"walking\",\"bicycling\",\"transit\"]}},\"required\":[\"origin\",\"destination\"]}}]}\n\n```\n\n\n#### List MCP Config files\n\n\n**API**\n\n```\nGET /api/mcp_marketplace/v1/server/${owner_id}/${repo_name}\n```\n\n\n## Resources\n\n### Badage\n\nPut Badge on your homepage markdown to track MCP Servers User Reviews and Ratings, such as [![MCP Marketplace User Review Rating Badge](https://www.deepnlp.org/api/marketplace/svg?name=google-maps/google-maps)](https://www.deepnlp.org/store/ai-agent/mcp-server/pub-google-maps/google-maps). \n\n\nchange google-maps/google-maps to your MCP \"owner_name\"/\"repo_name\"\n```\n![MCP Marketplace User Review Rating Badge](https://www.deepnlp.org/api/marketplace/svg?name=${owner_name}/${repo_name})](https://www.deepnlp.org/store/ai-agent/mcp-server/pub-${owner_name}/${repo_name})\n\n## google map\n![MCP Marketplace User Review Rating Badge](https://www.deepnlp.org/api/marketplace/svg?name=google-maps/google-maps)](https://www.deepnlp.org/store/ai-agent/mcp-server/pub-google-maps/google-maps)\n```\n\n\n## 4. Agent Workflow of MCP Marketplace<a id=\"tool_dispatcher\"></a>\n\n\n(WIP) Here is a diagram of how MCP Marketplace is integrated to your Agent Workflow\n\n```mermaid\ngraph TD\n    Start --> Search[Query Plan]\n    Search[Query Plan] --> QueryPlanning[Query Planning Agent]\n    QueryPlanning --> SearchTask1[Search]\n    SearchTask1 --> DocList[DocList]\n    DocList --> Generation\n    \n    Search[Query Plan] --> ToolDispatcher[Tool Dispatcher Agent]\n    ToolDispatcher --> Task1[MCP Server 1]\n    ToolDispatcher --> Task2[MCP Server 2]\n    ToolDispatcher --> Task3[MCP Server 3]\n    Task1 --> Tool1[Tool List 1]\n    Task2 --> Tool2[Tool List 2]\n    Task3 --> Tool3[Tool List 3]\n\n    Tool1 --> LLM[LLM Function Call Agent]\n    Tool2 --> LLM[LLM Function Call Agent]\n    Tool3 --> LLM[LLM Function Call Agent]\n\n    LLM -->  ToolSelection\n\n    ToolSelection --> ToolResult[Tool Execution Result]\n\n    ToolResult --> Generation\n```\n\n\n## Contribution\n\n\n## Resources\n\n\n- [MCP Marketplace DeepNLP](https://www.deepnlp.org/store/ai-agent/mcp-server)\n- [MCP Marketplace PulseMCP](https://www.pulsemcp.com/)\n- [AI Agent Marketplace](https://www.deepnlp.org/store/ai-agent)\n\n\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AI-FE--dify-mcp-server": {
          "owner": "AI-FE",
          "name": "dify-mcp-server",
          "url": "https://github.com/AI-FE/dify-mcp-server",
          "imageUrl": "https://github.com/AI-FE.png",
          "description": "Integrates the Dify AI API to generate Ant Design business component code, supporting both text and image inputs while handling file uploads and providing stream-based responses.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:11.898212",
          "collection_timestamp": "2025-10-02T15:04:05.378520",
          "stars": 41,
          "forks": 12,
          "license": "No License",
          "language": "JavaScript",
          "created_at": "2025-01-18T07:25:03Z",
          "updated_at": "2025-09-09T06:12:55Z",
          "open_issues": 1,
          "readme_content": "# dify-server MCP ÊúçÂä°Âô®\n\n‰∏Ä‰∏™ÈõÜÊàê Dify AI API ÁöÑ Model Context Protocol ÊúçÂä°Âô®\n\nËøôÊòØ‰∏Ä‰∏™Âü∫‰∫é TypeScript ÁöÑ MCP ÊúçÂä°Âô®ÔºåÈÄöËøáÈõÜÊàê Dify AI API Êù•Êèê‰æõ Ant Design ‰∏öÂä°ÁªÑ‰ª∂ÁöÑ‰ª£Á†ÅÁîüÊàêËÉΩÂäõ„ÄÇÂÆÉÂ±ïÁ§∫‰∫Ü‰ª•‰∏ãÊ†∏ÂøÉ MCP Ê¶ÇÂøµÔºö\n\n- ÈõÜÊàê Dify AI API ÂÆûÁé∞ËÅäÂ§©ÂÆåÊàêÂäüËÉΩ\n- ÊîØÊåÅÊñáÊú¨ÂíåÂõæÁâáËæìÂÖ•\n- ÊµÅÂºèÂìçÂ∫îÂ§ÑÁêÜ\n\n## ÂäüËÉΩÁâπÊÄß\n\n### Tools\n\n- `antd-component-codegen-mcp-tool` - ÁîüÊàê Ant Design ‰∏öÂä°ÁªÑ‰ª∂‰ª£Á†Å\n  - ÊîØÊåÅÊñáÊú¨ÂíåÂèØÈÄâÁöÑÂõæÁâáËæìÂÖ•\n  - Â§ÑÁêÜÂõæÁâáÊñá‰ª∂‰∏ä‰º†\n  - ÊîØÊåÅÊù•Ëá™ Dify AI API ÁöÑÊµÅÂºèÂìçÂ∫î\n\n## ÂºÄÂèëÊåáÂçó\n\nÂÆâË£Ö‰æùËµñÔºö\n\n```bash\nnpm install\n```\n\nÂºÄÂèëÊ®°ÂºèÔºàËá™Âä®ÈáçÊñ∞ÊûÑÂª∫ÔºâÔºö\n\n```bash\nnpm run watch\n```\n\nÊûÑÂª∫ÊúçÂä°Âô®Ôºö\n\n```bash\nnpm run build\n```\n\n## ÂÆâË£ÖËØ¥Êòé\n\n### Âú® Continue ‰∏≠ÈõÜÊàê\n\nÂú®`~/.continue/config.json`‰∏≠Ê∑ªÂä†‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n```json\n{\n  \"experimental\": {\n    \"modelContextProtocolServers\": [\n      {\n        \"transport\": {\n          \"type\": \"stdio\",\n          \"command\": \"node\",\n          \"args\": [\"your/path/dify-server/build/index.js\"],\n          \"env\": {\n            \"DIFY_API_KEY\": \"***\"\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n### Âú® Cline ‰∏≠ÈõÜÊàê\n\nÂú®`your/path/cline_mcp_settings.json`‰∏≠Ê∑ªÂä†‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"dify-server\": {\n      \"command\": \"node\",\n      \"args\": [\"your/path/dify-server/build/index.js\"],\n      \"env\": {\n        \"DIFY_API_KEY\": \"***\"\n      }\n    }\n  }\n}\n```\n\n### Ë∞ÉËØï\n\nÁî±‰∫é MCP ÊúçÂä°Âô®ÈÄöËøáÊ†áÂáÜËæìÂÖ•ËæìÂá∫ÔºàstdioÔºâËøõË°åÈÄö‰ø°ÔºåË∞ÉËØïÂèØËÉΩ‰ºöÊØîËæÉÂõ∞Èöæ„ÄÇÊàë‰ª¨Êé®Ëçê‰ΩøÁî® [MCP Inspector](https://github.com/modelcontextprotocol/inspector)ÔºåÂèØÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§ÂêØÂä®Ôºö\n\n```bash\nnpm run inspector\n```\n\nInspector Â∞ÜÊèê‰æõ‰∏Ä‰∏™ÂèØÂú®ÊµèËßàÂô®‰∏≠ËÆøÈóÆÁöÑË∞ÉËØïÂ∑•ÂÖ∑ URL„ÄÇ\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/dify-mcp-server",
          "npm_downloads": 0,
          "npm_package_name": "dify-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "Ai-Quill--scraperis-mcp": {
          "owner": "Ai-Quill",
          "name": "scraperis-mcp",
          "url": "https://github.com/Ai-Quill/scraperis-mcp",
          "imageUrl": "https://github.com/Ai-Quill.png",
          "description": "Scraper.is provides tools for extracting web content and capturing screenshots, enabling access to real-time information from the web. It supports multiple output formats such as markdown, HTML, and JSON for the extracted data.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:12.789371",
          "collection_timestamp": "2025-10-02T15:04:09.578675",
          "stars": 7,
          "forks": 3,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-06T02:01:41Z",
          "updated_at": "2025-09-03T22:50:42Z",
          "open_issues": 3,
          "readme_content": "# Scraper.is MCP\n\n[![npm version](https://img.shields.io/npm/v/scraperis-mcp.svg)](https://www.npmjs.com/package/scraperis-mcp)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA [Model Context Protocol (MCP)](https://github.com/model-context-protocol/spec) integration for [Scraper.is](https://scraper.is) - A powerful web scraping tool for AI assistants.\n\nThis package allows AI assistants to scrape web content through the MCP protocol, enabling them to access up-to-date information from the web.\n\n## Features\n\n- üåê **Web Scraping**: Extract content from any website\n- üì∏ **Screenshots**: Capture visual representations of web pages\n- üìÑ **Multiple Formats**: Get content in markdown, HTML, or JSON\n- üîÑ **Progress Updates**: Real-time progress reporting during scraping operations\n- üîå **MCP Integration**: Seamless integration with MCP-compatible AI assistants\n\n## Installation\n\n```bash\nnpm install -g scraperis-mcp\n```\n\nOr with yarn:\n\n```bash\nyarn global add scraperis-mcp\n```\n\n## Prerequisites\n\nYou need a Scraper.is API key to use this package. \n\n### Getting Your API Key\n\n1. Sign up or log in at [scraper.is](https://scraper.is)\n2. Navigate to the API Keys section in your dashboard: [https://www.scraper.is/dashboard/apikeys](https://www.scraper.is/dashboard/apikeys)\n3. Create a new API key or copy your existing key\n4. Store this key securely as you'll need it to use this package\n\n## Usage\n\n### Environment Setup\n\nCreate a `.env` file with your Scraper.is API key:\n\n```\nSCRAPERIS_API_KEY=your_api_key_here\n```\n\n### Claude Desktop Integration\n\nTo use this package with Claude Desktop:\n\n1. Install the package globally:\n   ```bash\n   npm install -g scraperis-mcp\n   ```\n\n2. Add the following configuration to your `claude_desktop_config.json` file:\n   ```json\n   {\n     \"mcpServers\": {\n       \"scraperis_scraper\": {\n         \"command\": \"scraperis-mcp\",\n         \"args\": [],\n         \"env\": {\n           \"SCRAPERIS_API_KEY\": \"your-api-key-here\",\n           \"DEBUG\": \"*\"\n         }\n       }\n     }\n   }\n   ```\n\n3. Replace `your-api-key-here` with your actual Scraper.is API key.\n\n4. Restart Claude Desktop to apply the changes.\n\n### Running with MCP Inspector\n\nFor development and testing, you can use the MCP Inspector:\n\n```bash\nnpx @modelcontextprotocol/inspector scraperis-mcp\n```\n\n### Integration with AI Assistants\n\nThis package is designed to be used with AI assistants that support the Model Context Protocol (MCP). When properly configured, the AI assistant can use the following tools:\n\n#### Scrape Tool\n\nThe `scrape` tool allows the AI to extract content from websites. It supports various formats:\n\n- `markdown`: Returns the content in markdown format\n- `html`: Returns the content in HTML format\n- `screenshot`: Returns a screenshot of the webpage\n- `json`: Returns structured data in JSON format\n\nExample prompt for the AI:\n\n```\nCan you scrape the latest news from techcrunch.com and summarize it for me?\n```\n\n## API Reference\n\n### Tools\n\n#### scrape\n\nScrapes content from a webpage based on a prompt.\n\n**Parameters:**\n\n- `prompt` (string): The prompt describing what to scrape, including the URL\n- `format` (string): The format to return the content in (`markdown`, `html`, `screenshot`, `json`, `quick`)\n\n**Example:**\n\n```json\n{\n  \"prompt\": \"Get me the top 10 products from producthunt.com\",\n  \"format\": \"markdown\"\n}\n```\n\n## Development\n\n### Setup\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/Ai-Quill/scraperis-mcp.git\n   cd scraperis-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n### Scripts\n\n- `npm run build`: Build the project\n- `npm run watch`: Watch for changes and rebuild\n- `npm run dev`: Run with MCP Inspector for development\n- `npm run test`: Run tests\n- `npm run lint`: Run ESLint\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgements\n\n- [Model Context Protocol](https://github.com/model-context-protocol/spec)\n- [Scraper.is](https://scraper.is) ",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/scraperis-mcp",
          "npm_downloads": 5839,
          "npm_package_name": "scraperis-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "Aias--barnsworthburning-mcp": {
          "owner": "Aias",
          "name": "barnsworthburning-mcp",
          "url": "https://github.com/Aias/barnsworthburning-mcp",
          "imageUrl": "https://github.com/Aias.png",
          "description": "Search through a digital commonplace book filled with bookmarks and snippets on various topics including design, software, art, architecture, craft, writing, and literature.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:13.724741",
          "collection_timestamp": "2025-10-02T15:04:17.473852",
          "stars": 1,
          "forks": 5,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-05T16:14:27Z",
          "updated_at": "2025-08-21T04:19:58Z",
          "open_issues": 2,
          "readme_content": "# Barnsworthburning MCP\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server for searching [barnsworthburning.net](https://barnsworthburning.net).\n\n<a href=\"https://glama.ai/mcp/servers/5aibjjzkkb\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/5aibjjzkkb/badge\" alt=\"Barnsworthburning MCP server\" />\n</a>\n\n[![Smithery Badge](https://smithery.ai/badge/@Aias/barnsworthburning-mcp)](https://smithery.ai/server/@Aias/barnsworthburning-mcp)\n\n## Overview\n\nThis MCP server provides a tool for searching barnsworthburning.net through the API endpoint at `https://barnsworthburning.net/api/search`. It can be used with Claude for Desktop or any other MCP client.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Barnsworthburning for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Aias/barnsworthburning-mcp):\n\n```bash\nnpx -y @smithery/cli install @Aias/barnsworthburning-mcp --client claude\n```\n\n### Manual Installation\n1. Clone this repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Build the server:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\nRefer to the [Model Context Protocol documentation](https://modelcontextprotocol.io/introduction) for information on how to use MCP servers with compatible clients (such as Claude for Desktop or Cursor).\n\n## Available Tools\n\nThis MCP server provides the following tool:\n\n- **search**: Search barnsworthburning.net for the given query\n  - Parameters:\n    - `query`: The search query to look for on barnsworthburning.net\n\n## Example Queries\n\nOnce the server is connected to the client, you can ask questions like:\n\n- \"Search barnsworthburning.net for 'design'\"\n- \"Find articles about typography on barnsworthburning.net\"\n- \"What does barnsworthburning.net have about user experience?\"\n\n## Development\n\nTo modify or extend this MCP server:\n\n1. Edit the source code in the `src` directory\n2. Rebuild the server with `npm run build`\n\n## License\n\nMIT\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "Ajey95--MCP": {
          "owner": "Ajey95",
          "name": "MCP",
          "url": "https://github.com/Ajey95/MCP",
          "imageUrl": "https://github.com/Ajey95.png",
          "description": "An AI-powered travel assistant that helps users plan routes and discover accommodations, adventure spots, and cultural sites in the Amazon Rainforest while providing essential travel precautions and real-time information through location-based services.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:14.674855",
          "collection_timestamp": "2025-10-02T15:04:20.197602",
          "stars": 0,
          "forks": 0,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-05-05T06:39:31Z",
          "updated_at": "2025-05-05T10:28:36Z",
          "open_issues": 1,
          "readme_content": "# üåø Amazon Rainforest Travel Guide (Claude Agent + MCP)\n\nAn AI-powered travel assistant connected to Claude via MCP, designed to help users explore the Amazon Rainforest ‚Äî from planning routes to discovering nearby hotels and adventure spots.\n\n---\n\n## üöÄ Features\n\n- üåç Get directions from any location to Manaus, Brazil\n- üè® Discover nearby hotels using Geoapify\n- ü•æ Find adventure spots like hikes and nature trails\n- üèõÔ∏è Explore food, monuments, and cultural sites\n- ‚ö†Ô∏è Get essential travel precautions\n- ü§ñ Powered by Claude + FastMCP\n\n---\n\n## üõ†Ô∏è Tech Stack\n\n- [Claude](https://claude.ai/) (Anthropic Desktop Client)\n- [FastMCP](https://github.com/codebasics/FastMCP) for Claude tool registration\n- Python + HTTPX + dotenv\n- OpenTripMap, Geoapify, OpenRouteService APIs\n\n---\n\n## üì¶ Installation\n\n1. **Clone the repo**:\n   ```bash\n   git clone https://github.com/Ajey95/MCP.git\n   cd MCP\n 2. **commands**:\n     ```bash\n     # On Windows.\n      powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n       uv init projectname\n       Create a virtual environment (optional but recommended):\n       python -m venv venv\n       source venv/bin/activate   # On Windows: venv\\Scripts\\activate\n     \n       Add your API keys in a .env file:\n       ORS_API_KEY=your_openrouteservice_api_key\n       GEOAPIFY_API_KEY=your_geoapify_api_key\n       OPENTRIPMAP_API_KEY=your_opentripmap_api_key\n 3. **mcp command**:\n     ```bash\n      install mcp \n      install mcp[cli]\n 4. **Final**:\n       ```bash\n       pip install -r requirements.txt\n       To run uv run mcp install file.py\n       #Continue building!\n---\n## üß† Connecting Claude to Your MCP Server\nRun your server:\n  uv run mcp install file.py\nOpen the Claude desktop app\n\nClick on Add Tool\n\nPaste your MCP endpoint (shown in terminal, e.g., http://localhost:3333/.well-known/ai-plugin.json)\n\nClaude will scan and install tools like:\n\n- get_travel_route\n\n- get_nearby_hotels\n\n- get_adventure_spots\n\n- get_monuments_and_food\n\n- get_precautions\n\n- greet_user\n---\nüó£Ô∏è Sample Prompts to Try in Claude\n  - \"What's the distance and travel time from Rio de Janeiro to the Amazon Rainforest?\"\n  \n  - \"Find top hotels near Manaus.\"\n  \n  - \"Suggest some adventure spots near Manaus.\"\n  \n  - \"What cultural sites can I visit in the Amazon?\"\n  \n  - \"Give me precautions before visiting the rainforest.\"\n---\n## ü§ù Contributing\nPull requests welcome. For major changes, please open an issue first.\n\n## üìÑ License\nMIT\n\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp",
          "npm_downloads": 17508,
          "npm_package_name": "mcp",
          "npm_success": true,
          "npm_error": null
        },
        "AkhrHysd--mcp-pokeapi-server": {
          "owner": "AkhrHysd",
          "name": "mcp-pokeapi-server",
          "url": "https://github.com/AkhrHysd/mcp-pokeapi-server",
          "imageUrl": "https://github.com/AkhrHysd.png",
          "description": "Retrieve detailed Pok√©mon information via the Model Context Protocol (MCP) using PokeAPI. It facilitates fetching data by Pok√©mon name or ID through a standardized JSON-RPC interface.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:15.538363",
          "collection_timestamp": "2025-10-02T15:04:28.061931",
          "stars": 0,
          "forks": 0,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-04-21T01:16:57Z",
          "updated_at": "2025-04-21T01:17:44Z",
          "open_issues": 0,
          "readme_content": "# mcp-pokeapi-server\n\nPOKEAPI „Å®ÈÄ£Êê∫„Åó„ÄÅMCPÔºàModel Context ProtocolÔºâ‰ªïÊßò„Åß„Éù„Ç±„É¢„É≥ÊÉÖÂ†±„ÇíÂèñÂæó„Åß„Åç„Çã„Çµ„Éº„Éê„Éº„Åß„Åô„ÄÇ\n\n## Ê¶ÇË¶Å\n\n- MCP „Éó„É≠„Éà„Ç≥„É´ÔºàJSON-RPC 2.0 over stdioÔºâ„Åß„ÄÅLLM „Ç¢„Éó„É™„ÇÑ MCP „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åã„Çâ„Éù„Ç±„É¢„É≥ÊÉÖÂ†±ÂèñÂæó„ÉÑ„Éº„É´„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ\n- POKEAPIÔºàhttps://pokeapi.co/Ôºâ„ÇíÂà©Áî®„ÄÇ\n- „Çπ„Ç≠„Éº„Éû„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„Å´„ÅØ[zod](https://zod.dev/)„Çí‰ΩøÁî®„ÄÇ\n\n## „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó\n\n```sh\nnpm install\n```\n\n## „Éì„É´„Éâ\n\n```sh\nnpx tsc\n```\n\n## ÈñãÁô∫Áî®Ëµ∑ÂãïÔºàts-nodeÔºâ\n\n```sh\nnpx ts-node src/index.ts\n```\n\n## MCP „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åã„Çâ„ÅÆÂà©Áî®‰æã\n\nMCP „ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÇÑ LLM „Ç¢„Éó„É™„Åã„Çâ„ÄÅÊ®ôÊ∫ñÂÖ•Âäõ/Âá∫Âäõ„Åß JSON-RPC „É™„ÇØ„Ç®„Çπ„Éà„ÇíÈÄÅ‰ø°„Åó„Åæ„Åô„ÄÇ\n\n### 1. „ÉÑ„Éº„É´‰∏ÄË¶ßÂèñÂæóÔºàlist_toolsÔºâ\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"list_tools\"\n}\n```\n\n#### „É¨„Çπ„Éù„É≥„Çπ‰æã\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"tools\": [\n      {\n        \"name\": \"getPokemonInfo\",\n        \"description\": \"„Éù„Ç±„É¢„É≥Âêç„Åæ„Åü„ÅØID„Åã„Çâ„ÄÅPOKEAPI„Åß„Éù„Ç±„É¢„É≥ÊÉÖÂ†±„ÇíÂèñÂæó„Åó„Åæ„Åô„ÄÇ\",\n        \"input_schema\": { ... },\n        \"output_schema\": { ... }\n      }\n    ]\n  }\n}\n```\n\n### 2. „Éù„Ç±„É¢„É≥ÊÉÖÂ†±ÂèñÂæóÔºàcall_toolÔºâ\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 2,\n  \"method\": \"call_tool\",\n  \"params\": {\n    \"name\": \"getPokemonInfo\",\n    \"arguments\": {\n      \"nameOrId\": \"pikachu\"\n    }\n  }\n}\n```\n\n#### „É¨„Çπ„Éù„É≥„Çπ‰æã\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 2,\n  \"result\": {\n    \"content\": [\n      {\n        \"type\": \"json\",\n        \"data\": {\n          \"name\": \"pikachu\",\n          \"id\": 25,\n          \"height\": 4,\n          \"weight\": 60,\n          \"types\": [\"electric\"]\n        }\n      }\n    ]\n  }\n}\n```\n\n## „ÉÜ„Çπ„Éà\n\n```sh\nnpm test\n```\n\n---\n\n### ÂèÇËÄÉ\n\n- [MCP ÂÖ¨Âºè„Éâ„Ç≠„É•„É°„É≥„Éà](https://www.anthropic.com/news/model-context-protocol)\n- [POKEAPI ÂÖ¨Âºè](https://pokeapi.co/)\n- [Zenn: MCP ÂÖ•ÈñÄ](https://zenn.dev/kazuwombat/articles/d8789724f10092)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AkekaratP--mcp-server-airbnb": {
          "owner": "AkekaratP",
          "name": "mcp-server-airbnb",
          "url": "https://github.com/AkekaratP/mcp-server-airbnb",
          "imageUrl": "https://github.com/AkekaratP.png",
          "description": "Search Airbnb listings and retrieve detailed information about specific listings using structured JSON data. The server respects Airbnb's robots.txt rules and does not require an API key.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:16.368575",
          "collection_timestamp": "2025-10-02T15:04:36.228983",
          "stars": 0,
          "forks": 0,
          "license": "MIT License",
          "language": null,
          "created_at": "2025-05-06T03:08:36Z",
          "updated_at": "2025-05-06T03:08:36Z",
          "open_issues": 0,
          "readme_content": "# Airbnb MCP Server\n[![smithery badge](https://smithery.ai/badge/@openbnb-org/mcp-server-airbnb)](https://smithery.ai/server/@openbnb-org/mcp-server-airbnb)\n\nMCP Server for searching Airbnb and get listing details.\n\n## Tools\n\n1. `airbnb_search`\n   - Search for Airbnb listings\n   - Required Input: `location` (string)\n   - Optional Inputs:\n     - `placeId` (string)\n     - `checkin` (string, YYYY-MM-DD)\n     - `checkout` (string, YYYY-MM-DD)\n     - `adults` (number)\n     - `children` (number)\n     - `infants` (number)\n     - `pets` (number)\n     - `minPrice` (number)\n     - `maxPrice` (number)\n     - `cursor` (string)\n     - `ignoreRobotsText` (boolean)\n   - Returns: Array of listings with details like name, price, location, etc.\n\n2. `airbnb_listing_details`\n   - Get detailed information about a specific Airbnb listing\n   - Required Input: `id` (string)\n   - Optional Inputs:\n     - `checkin` (string, YYYY-MM-DD)\n     - `checkout` (string, YYYY-MM-DD)\n     - `adults` (number)\n     - `children` (number)\n     - `infants` (number)\n     - `pets` (number)\n     - `ignoreRobotsText` (boolean)\n   - Returns: Detailed listing information including description, host details, amenities, pricing, etc.\n\n## Features\n\n- Respects Airbnb's robots.txt rules\n- Uses cheerio for HTML parsing\n- No API key required\n- Returns structured JSON data\n- Reduces context load by flattening and picking data\n\n## Setup\n\n\n### Installing on Claude Desktop\nBefore starting make sure [Node.js](https://nodejs.org/) is installed on your desktop for `npx` to work.\n1. Go to: Settings > Developer > Edit Config\n\n2. Add the following to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"airbnb\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@openbnb/mcp-server-airbnb\"\n      ]\n    }\n  }\n}\n```\n\nTo ignore robots.txt for all requests, use this version with `--ignore-robots-txt` args\n\n```json\n{\n  \"mcpServers\": {\n    \"airbnb\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@openbnb/mcp-server-airbnb\",\n        \"--ignore-robots-txt\"\n      ]\n    }\n  }\n}\n```\n3. Restart Claude Desktop and plan your next trip that include Airbnbs!\n\n### Other Option: Installing via Smithery\n\nTo install mcp-server-airbnb for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@openbnb-org/mcp-server-airbnb):\n\n```bash\nnpx -y @smithery/cli install @openbnb-org/mcp-server-airbnb --client claude\n```\n\n## Build (for devs)\n\n```bash\nnpm install\nnpm run build\n```\n\n## License\n\nThis MCP server is licensed under the MIT License.\n\n## Disclaimer\n\nAirbnb is a trademark of Airbnb, Inc.\nOpenBnB is not related to Airbnb, Inc. or its subsidiaries\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AkekaratP--flights-mcp-ts": {
          "owner": "AkekaratP",
          "name": "flights-mcp-ts",
          "url": "https://github.com/AkekaratP/flights-mcp-ts",
          "imageUrl": "https://github.com/AkekaratP.png",
          "description": "Provides flight and accommodation search capabilities using the Duffel API, enabling users to search for one-way, round-trip, and multi-city flights and obtain detailed flight offers. Users can also filter results based on preferences like cabin class and passenger count, while accessing guest reviews for stays.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:17.220431",
          "collection_timestamp": "2025-10-02T15:04:44.401806",
          "stars": 0,
          "forks": 0,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-05-06T06:28:35Z",
          "updated_at": "2025-05-06T06:37:09Z",
          "open_issues": 0,
          "readme_content": "# Flight + Stay Search MCP (TypeScript)\n\nA TypeScript implementation of a flight & Stay search MCP server that uses the Duffel API to search for flights. This MCP server provides tools to search for one-way, round-trip, and multi-city flights.\n\n[![smithery badge](https://smithery.ai/badge/@clockworked247/flights-mcp-ts)](https://smithery.ai/server/@clockworked247/flights-mcp-ts)\n\n## Features\n\n- Search for one-way, round-trip, and multi-city flights\n- Get detailed information about specific flight offers\n- Specify cabin class, number of passengers, and connection preferences\n- Filter by departure and arrival time windows\n- Search for travel stays (hotels/accommodations)\n- Get guest reviews for a specific stay/hotel\n\n## Setup\n\n1. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n2. Build the project:\n   ```bash\n   npm run build\n   ```\n\n3. Start the server:\n   ```bash\n   npm start\n   ```\n\n## Environment Variables\n\nCreate a `.env` file with:\n```\nDUFFEL_API_KEY=your_duffel_api_key\n```\n\nYou can start with a test API key (`duffel_test`) to try the functionality.\n\n## Using with Smithery\n\nTo publish this MCP to Smithery:\n```bash\nnpx @smithery/cli publish\n```\n\nTo run the published MCP:\n```bash\nnpx @smithery/cli run @your-username/flights-mcp-ts --config \"{\\\"duffelApiKey\\\":\\\"your_duffel_api_key\\\"}\"\n```\n\n## Available Tools\n\nThis MCP provides the following tools:\n\n1. `search_flights` - Search for one-way, round-trip, or multi-city flights\n2. `get_offer_details` - Get detailed information about a specific flight offer\n3. `search_multi_city` - A specialized tool for multi-city flight searches\n4. `search_stays` - Search for travel stays (hotels/accommodations)\n5. `get_stay_reviews` - Get guest reviews for a specific stay/hotel\n\n## Example Queries\n\n- \"Find flights from SFO to NYC on May 15, 2025\"\n- \"Search for a round-trip flight from LAX to LHR departing June 10 and returning June 20\"\n- \"Find business class flights from Tokyo to Paris for 2 adults\"\n- \"Get details for flight offer [offer_id]\"\n- \"Find hotels in London for 2 guests from 2025-06-10 to 2025-06-12\"\n- \"Get reviews for stay [hotel_id]\"\n\n---\n\n## Stays/Hotel Search and Reviews\n\n### 1. Search for Stays (`search_stays`)\n\n**Parameters:**\n- `location` (string): City, airport code, or area to search for stays\n- `check_in_date` (string): Check-in date (YYYY-MM-DD)\n- `check_out_date` (string): Check-out date (YYYY-MM-DD)\n- `guests` (number): Number of guests\n- `rooms` (number, optional): Number of rooms\n- `radius_km` (number, optional): Search radius in kilometers\n\n**Example Request:**\n```json\n{\n  \"location\": \"London\",\n  \"check_in_date\": \"2025-06-10\",\n  \"check_out_date\": \"2025-06-12\",\n  \"guests\": 2\n}\n```\n\n**Example Response:**\n```json\n{\n  \"offers\": [\n    {\n      \"offer_id\": \"off_123\",\n      \"hotel_id\": \"acc_0000AWr2VsUNIF1Vl91xg0\",\n      \"hotel_name\": \"The Grand Hotel\",\n      \"address\": \"1 Main St, London\",\n      \"price\": { \"amount\": \"350.00\", \"currency\": \"GBP\" },\n      \"room_type\": \"Deluxe Suite\",\n      \"cancellation_policy\": \"Free cancellation until 24h before check-in\"\n    }\n  ]\n}\n```\n\n**Note:** Use the `hotel_id` from the search results as the `stay_id` for reviews.\n\n---\n\n### 2. Get Stay Reviews (`get_stay_reviews`)\n\n**Parameters:**\n- `stay_id` (string): The unique Duffel stay/hotel ID (from the search_stays result)\n- `after` (string, optional): Pagination cursor (after)\n- `before` (string, optional): Pagination cursor (before)\n- `limit` (number, optional): Max reviews to return (1-200)\n\n**Example Request:**\n```json\n{\n  \"stay_id\": \"acc_0000AWr2VsUNIF1Vl91xg0\"\n}\n```\n\n**Example Response:**\n```json\n{\n  \"meta\": { \"limit\": 50, \"after\": \"...\" },\n  \"reviews\": [\n    {\n      \"text\": \"Excellent facilities. Polite staff.\\nAir conditioning could use some maintenance.\\n\",\n      \"score\": 8.4,\n      \"reviewer_name\": \"Bessie Coleman\",\n      \"created_at\": \"2025-01-01\"\n    }\n  ]\n}\n```\n\n## Local Development\n\nFor development with automatic reloading:\n```bash\nnpm run dev\n```\n\n## License\n\nMIT\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "akream--mcppython": {
          "owner": "akream",
          "name": "mcppython",
          "url": "https://github.com/akream/mcppython",
          "imageUrl": "https://github.com/akream.png",
          "description": "Provides real-time and on-demand cat facts via a FastAPI server using Server-Sent Events (SSE) transport, allowing users to subscribe to a stream of cat facts or request a random fact instantly.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:18.117764",
          "collection_timestamp": "2025-10-02T15:06:46.067605",
          "stars": 0,
          "forks": 1,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-04-28T08:11:38Z",
          "updated_at": "2025-04-28T08:17:33Z",
          "open_issues": 2,
          "readme_content": "# Python MCP Cat Facts\n\nA FastAPI server that implements the Model Context Protocol (MCP) using Server-Sent Events (SSE) transport to provide cat facts.\n\n## Features\n\n- Get a single random cat fact\n- Subscribe to a stream of cat facts delivered every 10 seconds\n- SSE (Server-Sent Events) for real-time communication\n- FastAPI framework with automatic OpenAPI documentation\n\n## Requirements\n\n- Python 3.12+\n- Dependencies:\n  - fastapi\n  - mcp[cli]\n  - uvicorn\n  - cmake\n\n## Installation\n\n### Clone the repository\n\n```bash\ngit clone <repository-url>\ncd python-mcp\n```\n\n### Create a virtual environment\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows, use: venv\\Scripts\\activate\n```\n\n### Install dependencies\n\n```bash\npip install -e .\n```\n\n## Starting the Server in SSE Mode\n\nStart the server using the uv run command:\n\n```bash\nuv run start\n```\n\nOnce the server is running, it will be available at:\n- API: http://localhost:8000\n- API Documentation: http://localhost:8000/docs\n\n## VS Code Integration\n\nTo use this MCP server with VS Code, you need to add the following configuration to your `mcp.json` file:\n\n```json\n{\n    \"servers\": {\n        \"mcp-sse\": {\n            \"type\": \"sse\",\n            \"url\": \"http://0.0.0.0:8000/sse\"\n        }\n    }\n}\n```\n\nThis configuration tells VS Code how to connect to your MCP server using SSE transport.\n\n## Using the Cat Facts API\n\n### Get a single cat fact:\n\nConnect to the SSE endpoint and request a single cat fact. The response will always start with \"Hi!\".\n\n\n## API Endpoints\n\n- `GET /`: Homepage\n- `GET /about`: Information about the application\n- `GET /status`: Current server status\n- `GET /sse`: SSE endpoint for MCP communication\n- `GET /docs`: API documentation (Swagger UI)\n- `GET /redoc`: Alternative API documentation (ReDoc)\n\n## License\n\n[MIT](LICENSE)",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "aldrin-labs--metaplex-mcp-server": {
          "owner": "aldrin-labs",
          "name": "metaplex-mcp-server",
          "url": "https://github.com/aldrin-labs/metaplex-mcp-server",
          "imageUrl": "https://github.com/aldrin-labs.png",
          "description": "Access Metaplex documentation, retrieve repository details from the metaplex-foundation, and search code across Metaplex repositories.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:19.151473",
          "collection_timestamp": "2025-10-02T15:06:53.746549",
          "stars": 1,
          "forks": 6,
          "license": "The Unlicense",
          "language": "TypeScript",
          "created_at": "2025-01-04T05:47:11Z",
          "updated_at": "2025-07-28T10:57:41Z",
          "open_issues": 5,
          "readme_content": "# Metaplex MCP Server\n\nA Model Context Protocol (MCP) server for accessing Metaplex documentation and repository information.\n\n## Features\n\n- Search Metaplex documentation\n- Get repository details from metaplex-foundation\n- Search code across Metaplex repositories\n\n## Usage\n\nThe server runs as an MCP server and can be accessed through the MCP protocol.\n\n## Installation\n\n```bash\n# Install and configure Metaplex MCP Server\ncd ~/Documents/Cline/MCP && \\\ngit clone https://github.com/metaplex-foundation/metaplex-mcp-server.git && \\\ncd metaplex-mcp-server && \\\nnpm install && \\\nnpm run build && \\\necho '{\n  \"metaplex\": {\n    \"command\": \"node\",\n    \"args\": [\"'$(pwd)'/build/index.js\"],\n    \"env\": {}\n  }\n}' | jq -s '.[0] * .[1]' ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json - > /tmp/cline_mcp_settings.json && \\\nmv /tmp/cline_mcp_settings.json ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json && \\\nnohup node build/index.js > /dev/null 2>&1 &\n```\n\n## Development\n\n```bash\n# Install dependencies\nnpm install\n\n# Build and run\nnpm run build && node build/index.js\n```\n\n## License\n\nThis project is released under The Unlicense. See [LICENSE](LICENSE) for details.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "Alex-Smith-1234--Map_MCP": {
          "owner": "Alex-Smith-1234",
          "name": "Map_MCP",
          "url": "https://github.com/Alex-Smith-1234/Map_MCP",
          "imageUrl": "https://github.com/Alex-Smith-1234.png",
          "description": "Integrate dynamic data and manipulate context in real-time to enhance user interactions with external resources. Navigate to specified locations using an asynchronous tool function within a Docker environment.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:20.055575",
          "collection_timestamp": "2025-10-02T15:07:01.149483",
          "stars": 0,
          "forks": 0,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-03-20T08:30:37Z",
          "updated_at": "2025-03-20T11:31:43Z",
          "open_issues": 0,
          "readme_content": "# my-python-project\n\n## È°πÁõÆÊèèËø∞\nËøôÊòØ‰∏Ä‰∏™‰ΩøÁî® FastMCP ÁöÑ Python È°πÁõÆÔºåÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂºÇÊ≠•Â∑•ÂÖ∑ÂáΩÊï∞ `navigate_to`ÔºåÁî®‰∫éÂØºËà™Âà∞ÊåáÂÆöÂüéÂ∏Ç„ÄÇ\n\n## ÂÆâË£ÖËØ¥Êòé\n1. Á°Æ‰øùÂ∑≤ÂÆâË£Ö Docker„ÄÇ\n2. ÂÖãÈöÜÊ≠§È°πÁõÆÔºö\n   ```\n   git clone <repository-url>\n   ```\n3. ËøõÂÖ•È°πÁõÆÁõÆÂΩïÔºö\n   ```\n   cd my-python-project\n   ```\n4. ÊûÑÂª∫ Docker ÈïúÂÉèÔºö\n   ```\n   docker build -t my-python-project .\n   ```\n\n## ‰ΩøÁî®Á§∫‰æã\nÂú® Docker ÂÆπÂô®‰∏≠ËøêË°åÂ∫îÁî®Ôºö\n```\ndocker run -it my-python-project\n```\nÁÑ∂ÂêéÂèØ‰ª•Ë∞ÉÁî® `navigate_to` ÂáΩÊï∞Êù•ÂØºËà™Âà∞ÊåáÂÆöÂüéÂ∏Ç„ÄÇ",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "alexandrebagio--swapi-mcp": {
          "owner": "alexandrebagio",
          "name": "swapi-mcp",
          "url": "https://github.com/alexandrebagio/swapi-mcp",
          "imageUrl": "https://github.com/alexandrebagio.png",
          "description": "Integrate with the Star Wars API to fetch and manipulate data about the Star Wars universe, specifically focusing on listing planets and people. Provides structured information such as climate, terrain, and population of planets.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:20.914565",
          "collection_timestamp": "2025-10-02T15:07:08.823461",
          "stars": 3,
          "forks": 0,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-19T00:29:54Z",
          "updated_at": "2025-03-21T02:52:48Z",
          "open_issues": 0,
          "readme_content": "# Smithery SWAPI Integration [![smithery badge](https://smithery.ai/badge/@alexandrebagio/swapi-mcp)](https://smithery.ai/server/@alexandrebagio/swapi-mcp)\n\nEste reposit√≥rio cont√©m um projeto que integra o [Smithery](https://smithery.com) com a API [SWAPI](https://swapi.dev/), permitindo a busca e listagem de planetas do universo Star Wars.\n\n## Vis√£o Geral\n\nO projeto utiliza o SDK do Smithery para criar um servidor que se comunica com a SWAPI. Atualmente, a funcionalidade principal √© listar planetas, mas o projeto pode ser expandido para incluir outras entidades da SWAPI.\n\n## Funcionalidades\n\n- **Listar Planetas**: Permite buscar e listar todos os planetas dispon√≠veis na SWAPI, fornecendo informa√ß√µes como nome, clima, terreno, popula√ß√£o, entre outros detalhes.\n\n- **Listar Pessoas**: Recupera informa√ß√µes sobre personagens do universo Star Wars, incluindo nome, altura, peso, cor dos olhos, cor do cabelo, e muito mais.\n\n- **Listar Naves Estelares**: Fornece detalhes sobre as naves estelares, como nome, modelo, fabricante, capacidade de carga, e outros atributos t√©cnicos.\n\n- **Listar Ve√≠culos**: Permite acessar dados sobre ve√≠culos terrestres e espaciais, incluindo nome, modelo, fabricante, e especifica√ß√µes t√©cnicas.\n\n- **Listar Esp√©cies**: Oferece informa√ß√µes sobre diferentes esp√©cies no universo Star Wars, como nome, classifica√ß√£o, idioma, e caracter√≠sticas f√≠sicas.\n\n- **Listar Filmes**: Recupera dados sobre os filmes de Star Wars, incluindo t√≠tulo, diretor, produtor, data de lan√ßamento, e uma lista de personagens e naves que aparecem no filme.\n\n## Tecnologias Utilizadas\n\n- Node.js\n- Smithery SDK\n- SWAPI\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "Alihkhawaher--everything-search-server": {
          "owner": "Alihkhawaher",
          "name": "everything-search-server",
          "url": "https://github.com/Alihkhawaher/everything-search-server",
          "imageUrl": "https://github.com/Alihkhawaher.png",
          "description": "Integrates with the Everything Search Engine to provide advanced file search capabilities including full text search, case sensitivity, whole word matching, and regex support. Offers sorting options and formats results with human-readable file sizes and formatted dates.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:21.787479",
          "collection_timestamp": "2025-10-02T15:07:15.966603",
          "stars": 7,
          "forks": 6,
          "license": "No License",
          "language": "JavaScript",
          "created_at": "2024-12-20T04:20:34Z",
          "updated_at": "2025-07-31T01:56:09Z",
          "open_issues": 4,
          "readme_content": "# Everything Search MCP Server\n\nAn MCP server that provides integration with Everything Search Engine, allowing powerful file search capabilities through the Model Context Protocol.\n\n## Features\n\n- Full text search across files and directories\n- Advanced search options:\n  - Case sensitive search\n  - Whole word matching\n  - Regular expressions\n  - Path search\n- Sorting options:\n  - By name\n  - By path\n  - By size\n  - By date modified\n- Result formatting:\n  - Human-readable file sizes\n  - Formatted dates\n  - Full file paths\n\n## Prerequisites\n\n- Node.js 16 or higher\n- Everything Search Engine with HTTP Server enabled\n\n### Everything Search Configuration\n\n1. Open Everything Search\n2. Go to Tools > Options > HTTP Server\n3. Enable HTTP Server\n4. Set the HTTP Server port to 8011 (this is the default port used by this MCP server)\n5. Click OK to save changes\n\nNote: If you need to use a different port, you'll need to modify the port in `src/server.ts` where it connects to `http://127.0.0.1:8011/`\n\n## Installation\n\n```bash\nnpm install\nnpm run build\n```\n\n## Usage\n\nThe server provides a single tool through MCP:\n\n```typescript\nuse_mcp_tool:\n- server_name: everything-search\n- tool_name: search\n- arguments:\n  {\n    \"query\": \"search string\",          // Required: Text to search for\n    \"scope\": \"C:\",                     // Optional: Search scope (default: C:)\n    \"caseSensitive\": false,            // Optional: Match case\n    \"wholeWord\": false,                // Optional: Match whole words only\n    \"regex\": false,                    // Optional: Use regular expressions\n    \"path\": false,                     // Optional: Search in paths\n    \"maxResults\": 100,                 // Optional: Max results (1-1000, default: 100)\n    \"sortBy\": \"name\",                  // Optional: Sort by name/path/size/date_modified\n    \"ascending\": true                  // Optional: Sort direction\n  }\n```\n\n## Example Searches\n\n1. Basic file search:\n```json\n{\n  \"query\": \"*.txt\",\n  \"maxResults\": 5\n}\n```\n\n2. Advanced search with filters:\n```json\n{\n  \"query\": \"test\",\n  \"scope\": \"C:\\\\Users\",\n  \"caseSensitive\": true,\n  \"wholeWord\": true,\n  \"maxResults\": 10,\n  \"sortBy\": \"date_modified\",\n  \"ascending\": false\n}\n```\n\n3. Regex search in paths:\n```json\n{\n  \"query\": \".*\\\\.js$\",\n  \"regex\": true,\n  \"path\": true,\n  \"maxResults\": 5\n}\n```\n\n## License\n\nISC\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "alimo7amed93--webhook-tester-mcp": {
          "owner": "alimo7amed93",
          "name": "webhook-tester-mcp",
          "url": "https://github.com/alimo7amed93/webhook-tester-mcp",
          "imageUrl": "https://github.com/alimo7amed93.png",
          "description": "Automate and manage webhook tokens, inspect incoming requests, and perform analytics without the need for custom API integrations. Enhance webhook workflows with modular tools for observability and automated testing.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:22.699233",
          "collection_timestamp": "2025-10-02T15:07:23.307810",
          "stars": 6,
          "forks": 4,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-04-23T16:55:20Z",
          "updated_at": "2025-09-09T19:37:40Z",
          "open_issues": 3,
          "readme_content": "# üöÄ Webhook Tester MCP Server\n\nA powerful and modular FastMCP server for interacting with webhook-test.com, designed to automate and manage Webhook tokens (URLs), inspect incoming requests, and perform analytics ‚Äî all without writing custom API integrations.\n\nBuilt with the FastMCP framework to expose modular tools and resources, this project enables webhook observability and management.\n\n## üõéÔ∏è Webhooks 101\n\nWebhooks let your app send and receive real-time updates between services. When sending, your app can POST data to a URL whenever something important happens ‚Äî like a new user signup or a status change. When receiving, your app listens for incoming POST requests from other services and reacts to the events they send. This setup is way more efficient than constant polling and is perfect for triggering actions, syncing data, or keeping systems in sync.\n\n## üì¶ Features & Use Cases\n\n‚úÖ Create new webhooks\\\n‚úÖ List all available webhooks\\\n‚úÖ Fetch webhook's details\\\n‚úÖ Fetch webhook payloads\\\n‚úÖ Delete webhooks\n\n## ‚öôÔ∏è Setup\n\n1. Clone the repo\n2. Install dependencies `pip install -r requirements.txt`\n3. Configure `.env`\n\n## üîç Testing Using Claude\n\n- Configure Claude Desktop to use the local server by editing your claude_desktop_config.json file:\n\n``` \n{\n    \"mcpServers\": {\n      \"webhook-tester-mcp\": {\n        \"command\": \"fastmcp\",\n        \"args\": [\"run\", \"{{fullPath}}\\\\Webhook-test_mcp\\\\server.py\"]\n      }\n    }\n  } \n```\n\n## üß™ Demo testing the Server\n\n[![Watch the video](https://img.youtube.com/vi/nGRlQtRlDA4/hqdefault.jpg)](https://www.youtube.com/watch?v=nGRlQtRlDA4)\n\n## üìÑ License\nThis project is licensed under the [MIT License](https://mit-license.org/).",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "allenday--solr-mcp": {
          "owner": "allenday",
          "name": "solr-mcp",
          "url": "https://github.com/allenday/solr-mcp",
          "imageUrl": "https://github.com/allenday.png",
          "description": "Access Apache Solr indexes for executing hybrid search queries that combine keyword precision with vector semantic understanding, supporting both document content and vector embeddings in unified collections.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:23.612411",
          "collection_timestamp": "2025-10-02T15:07:30.790804",
          "stars": 15,
          "forks": 8,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-14T10:26:35Z",
          "updated_at": "2025-08-30T15:02:42Z",
          "open_issues": 4,
          "readme_content": "# Solr MCP\n\nA Python package for accessing Apache Solr indexes via Model Context Protocol (MCP). This integration allows AI assistants like Claude to perform powerful search queries against your Solr indexes, combining both keyword and vector search capabilities.\n\n## Features\n\n- **MCP Server**: Implements the Model Context Protocol for integration with AI assistants\n- **Hybrid Search**: Combines keyword search precision with vector search semantic understanding\n- **Vector Embeddings**: Generates embeddings for documents using Ollama with nomic-embed-text\n- **Unified Collections**: Store both document content and vector embeddings in the same collection\n- **Docker Integration**: Easy setup with Docker and docker-compose\n- **Optimized Vector Search**: Efficiently handles combined vector and SQL queries by pushing down SQL filters to the vector search stage, ensuring optimal performance even with large result sets and pagination\n\n## Architecture\n\n### Vector Search Optimization\n\nThe system employs an important optimization for combined vector and SQL queries. When executing a query that includes both vector similarity search and SQL filters:\n\n1. SQL filters (WHERE clauses) are pushed down to the vector search stage\n2. This ensures that vector similarity calculations are only performed on documents that will match the final SQL criteria\n3. Significantly improves performance for queries with:\n   - Selective WHERE clauses\n   - Pagination (LIMIT/OFFSET)\n   - Large result sets\n\nThis optimization reduces computational overhead and network transfer by minimizing the number of vector similarity calculations needed.\n\n## Quick Start\n\n1. Clone this repository\n2. Start SolrCloud with Docker:\n   ```bash\n   docker-compose up -d\n   ```\n3. Install dependencies:\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   pip install poetry\n   poetry install\n   ```\n4. Process and index the sample document:\n   ```bash\n   python scripts/process_markdown.py data/bitcoin-whitepaper.md --output data/processed/bitcoin_sections.json\n   python scripts/create_unified_collection.py unified\n   python scripts/unified_index.py data/processed/bitcoin_sections.json --collection unified\n   ```\n5. Run the MCP server:\n   ```bash\n   poetry run python -m solr_mcp.server\n   ```\n\nFor more detailed setup and usage instructions, see the [QUICKSTART.md](QUICKSTART.md) guide.\n\n## Requirements\n\n- Python 3.10 or higher\n- Docker and Docker Compose\n- SolrCloud 9.x\n- Ollama (for embedding generation)\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "ameeralns--DeepResearchMCP": {
          "owner": "ameeralns",
          "name": "DeepResearchMCP",
          "url": "https://github.com/ameeralns/DeepResearchMCP",
          "imageUrl": "https://github.com/ameeralns.png",
          "description": "Conducts iterative research on various topics through automated web searches and generates comprehensive reports that include executive summaries, analyses, and visualizations while ensuring content management and error resilience.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:24.557891",
          "collection_timestamp": "2025-10-02T15:07:38.542657",
          "stars": 23,
          "forks": 7,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-04T20:30:44Z",
          "updated_at": "2025-09-30T09:17:21Z",
          "open_issues": 3,
          "readme_content": "# DeepResearch MCP\n\n<div align=\"center\">\n  \n![DeepResearch Logo](https://img.shields.io/badge/DeepResearch-MCP-blue?style=for-the-badge)\n[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)\n[![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com/)\n[![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)](https://nodejs.org/)\n\n</div>\n\n## üìö Overview\n\nDeepResearch MCP is a powerful research assistant built on the Model Context Protocol (MCP). It conducts intelligent, iterative research on any topic through web searches, analysis, and comprehensive report generation.\n\n### üåü Key Features\n\n- **Intelligent Topic Exploration** - Automatically identifies knowledge gaps and generates focused search queries\n- **Comprehensive Content Extraction** - Enhanced web scraping with improved content organization\n- **Structured Knowledge Processing** - Preserves important information while managing token usage\n- **Scholarly Report Generation** - Creates detailed, well-structured reports with executive summaries, analyses, and visualizations\n- **Complete Bibliography** - Properly cites all sources with numbered references\n- **Adaptive Content Management** - Automatically manages content to stay within token limits\n- **Error Resilience** - Recovers from errors and generates partial reports when full processing isn't possible\n\n## üõ†Ô∏è Architecture\n\n<div align=\"center\">\n  \n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                    ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ                ‚îÇ\n‚îÇ  MCP Server Layer  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Research Service‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Search Service ‚îÇ\n‚îÇ  (Tools & Prompts) ‚îÇ     ‚îÇ (Session Mgmt)  ‚îÇ     ‚îÇ  (Firecrawl)   ‚îÇ\n‚îÇ                    ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ                ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                                     ‚îÇ\n                                     ‚ñº\n                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                           ‚îÇ                 ‚îÇ\n                           ‚îÇ  OpenAI Service ‚îÇ\n                           ‚îÇ (Analysis/Rpt)  ‚îÇ\n                           ‚îÇ                 ‚îÇ\n                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n</div>\n\n## üíª Installation\n\n### Prerequisites\n\n- Node.js 18 or higher\n- OpenAI API key\n- Firecrawl API key\n\n### Setup Steps\n\n1. **Clone the repository**\n   ```bash\n   git clone <repository-url>\n   cd deep-research-mcp\n   ```\n\n2. **Install dependencies**\n   ```bash\n   npm install\n   ```\n\n3. **Configure environment variables**\n   ```bash\n   cp .env.example .env\n   ```\n   \n   Edit the `.env` file and add your API keys:\n   ```\n   OPENAI_API_KEY=sk-your-openai-api-key\n   FIRECRAWL_API_KEY=your-firecrawl-api-key\n   ```\n\n4. **Build the project**\n   ```bash\n   npm run build\n   ```\n\n## üöÄ Usage\n\n### Running the MCP Server\n\nStart the server on stdio for MCP client connections:\n\n```bash\nnpm start\n```\n\n### Using the Example Client\n\nRun research on a specific topic with a specified depth:\n\n```bash\nnpm run client \"Your research topic\" 3\n```\n\nParameters:\n- First argument: Research topic or query\n- Second argument: Research depth (number of iterations, default: 2)\n- Third argument (optional): \"complete\" to use the complete-research tool (one-step process)\n\nExample:\n```bash\nnpm run client \"the impact of climate change on coral reefs\" 3 complete\n```\n\n### Example Output\n\nThe DeepResearch MCP will produce a comprehensive report that includes:\n\n- **Executive Summary** - Concise overview of the research findings\n- **Introduction** - Context and importance of the research topic\n- **Methodology** - Description of the research approach\n- **Comprehensive Analysis** - Detailed examination of the topic\n- **Comparative Analysis** - Visual comparison of key aspects\n- **Discussion** - Interpretation of findings and implications\n- **Limitations** - Constraints and gaps in the research\n- **Conclusion** - Final insights and recommendations\n- **Bibliography** - Complete list of sources with URLs\n\n## üîß MCP Integration\n\n### Available MCP Resources\n\n| Resource Path | Description |\n|--------------|-------------|\n| `research://state/{sessionId}` | Access the current state of a research session |\n| `research://findings/{sessionId}` | Access the collected findings for a session |\n\n### Available MCP Tools\n\n| Tool Name | Description | Parameters |\n|-----------|-------------|------------|\n| `initialize-research` | Start a new research session | `query`: string, `depth`: number |\n| `execute-research-step` | Execute the next research step | `sessionId`: string |\n| `generate-report` | Create a final report | `sessionId`: string, `timeout`: number (optional) |\n| `complete-research` | Execute the entire research process | `query`: string, `depth`: number, `timeout`: number (optional) |\n\n## üñ•Ô∏è Claude Desktop Integration\n\nDeepResearch MCP can be integrated with Claude Desktop to provide direct research capabilities to Claude.\n\n### Configuration Steps\n\n1. **Copy the sample configuration**\n   ```bash\n   cp claude_desktop_config_sample.json ~/path/to/claude/desktop/config/directory/claude_desktop_config.json\n   ```\n\n2. **Edit the configuration file**\n   \n   Update the path to point to your installation of deep-research-mcp and add your API keys:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"deep-research\": {\n         \"command\": \"node\",\n         \"args\": [\n           \"/absolute/path/to/your/deep-research-mcp/dist/index.js\"\n         ],\n         \"env\": {\n           \"FIRECRAWL_API_KEY\": \"your-firecrawler-api-key\",\n           \"OPENAI_API_KEY\": \"your-openai-api-key\"\n         }\n       }\n     }\n   }\n   ```\n\n3. **Restart Claude Desktop**\n   \n   After saving the configuration, restart Claude Desktop for the changes to take effect.\n\n4. **Using with Claude Desktop**\n   \n   Now you can ask Claude to perform research using commands like:\n   \n   ```\n   Can you research the impact of climate change on coral reefs and provide a detailed report?\n   ```\n\n## üìã Sample Client Code\n\n```typescript\nimport { Client } from \"@modelcontextprotocol/sdk/client/index.js\";\nimport { StdioClientTransport } from \"@modelcontextprotocol/sdk/client/stdio.js\";\n\nasync function main() {\n  // Connect to the server\n  const transport = new StdioClientTransport({\n    command: \"node\",\n    args: [\"dist/index.js\"]\n  });\n\n  const client = new Client({ name: \"deep-research-client\", version: \"1.0.0\" });\n  await client.connect(transport);\n\n  // Initialize research\n  const initResult = await client.callTool({\n    name: \"initialize-research\",\n    arguments: {\n      query: \"The impact of artificial intelligence on healthcare\",\n      depth: 3\n    }\n  });\n  \n  // Parse the response to get sessionId\n  const { sessionId } = JSON.parse(initResult.content[0].text);\n  \n  // Execute steps until complete\n  let currentDepth = 0;\n  while (currentDepth < 3) {\n    const stepResult = await client.callTool({\n      name: \"execute-research-step\",\n      arguments: { sessionId }\n    });\n    \n    const stepInfo = JSON.parse(stepResult.content[0].text);\n    currentDepth = stepInfo.currentDepth;\n    \n    console.log(`Completed step ${stepInfo.currentDepth}/${stepInfo.maxDepth}`);\n  }\n  \n  // Generate final report with timeout\n  const report = await client.callTool({\n    name: \"generate-report\",\n    arguments: { \n      sessionId,\n      timeout: 180000 // 3 minutes timeout\n    }\n  });\n  \n  console.log(\"Final Report:\");\n  console.log(report.content[0].text);\n}\n\nmain().catch(console.error);\n```\n\n## üîç Troubleshooting\n\n### Common Issues\n\n- **Token Limit Exceeded**: For very large research topics, you may encounter OpenAI token limit errors. Try:\n  - Reducing the research depth\n  - Using more specific queries\n  - Breaking complex topics into smaller sub-topics\n\n- **Timeout Errors**: For complex research, the process may time out. Solutions:\n  - Increase the timeout parameters in tool calls\n  - Use the `complete-research` tool with a longer timeout\n  - Process research in smaller chunks\n\n- **API Rate Limits**: If you encounter rate limit errors from OpenAI or Firecrawl:\n  - Implement a delay between research steps\n  - Use an API key with higher rate limits\n  - Retry with exponential backoff\n\n## üìù License\n\nISC\n\n## üôè Acknowledgements\n\n- Built with [Model Context Protocol](https://github.com/mhuggins7278/model-context-protocol)\n- Powered by [OpenAI](https://openai.com/) and [Firecrawl](https://firecrawl.dev/)",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "amotivv--cloudflare-browser-rendering": {
          "owner": "amotivv",
          "name": "cloudflare-browser-rendering",
          "url": "https://github.com/amotivv/cloudflare-browser-rendering",
          "imageUrl": "https://github.com/amotivv.png",
          "description": "Fetch and process web content for LLM context using Cloudflare Browser Rendering, enabling real-time web data extraction and structured content summarization.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:25.415384",
          "collection_timestamp": "2025-10-02T15:07:46.386372",
          "stars": 7,
          "forks": 5,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-02-28T14:54:23Z",
          "updated_at": "2025-06-11T15:15:17Z",
          "open_issues": 2,
          "readme_content": "# Cloudflare Browser Rendering Experiments & MCP Server\n\nThis project demonstrates how to use Cloudflare Browser Rendering to extract web content for LLM context. It includes experiments with the REST API and Workers Binding API, as well as an MCP server implementation that can be used to provide web context to LLMs.\n\n<a href=\"https://glama.ai/mcp/servers/wg9fikq571\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/wg9fikq571/badge\" alt=\"Web Content Server MCP server\" />\n</a>\n\n## Project Structure\n\n```\ncloudflare-browser-rendering/\n‚îú‚îÄ‚îÄ examples/                   # Example implementations and utilities\n‚îÇ   ‚îú‚îÄ‚îÄ basic-worker-example.js # Basic Worker with Browser Rendering\n‚îÇ   ‚îú‚îÄ‚îÄ minimal-worker-example.js # Minimal implementation\n‚îÇ   ‚îú‚îÄ‚îÄ debugging-tools/        # Tools for debugging\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ debug-test.js       # Debug test utility\n‚îÇ   ‚îî‚îÄ‚îÄ testing/                # Testing utilities\n‚îÇ       ‚îî‚îÄ‚îÄ content-test.js     # Content testing utility\n‚îú‚îÄ‚îÄ experiments/                # Educational experiments\n‚îÇ   ‚îú‚îÄ‚îÄ basic-rest-api/         # REST API tests\n‚îÇ   ‚îú‚îÄ‚îÄ puppeteer-binding/      # Workers Binding API tests\n‚îÇ   ‚îî‚îÄ‚îÄ content-extraction/     # Content processing tests\n‚îú‚îÄ‚îÄ src/                        # MCP server source code\n‚îÇ   ‚îú‚îÄ‚îÄ index.ts                # Main entry point\n‚îÇ   ‚îú‚îÄ‚îÄ server.ts               # MCP server implementation\n‚îÇ   ‚îú‚îÄ‚îÄ browser-client.ts       # Browser Rendering client\n‚îÇ   ‚îî‚îÄ‚îÄ content-processor.ts    # Content processing utilities\n‚îú‚îÄ‚îÄ puppeteer-worker.js         # Cloudflare Worker with Browser Rendering binding\n‚îú‚îÄ‚îÄ test-puppeteer.js           # Tests for the main implementation\n‚îú‚îÄ‚îÄ wrangler.toml               # Wrangler configuration for the Worker\n‚îú‚îÄ‚îÄ cline_mcp_settings.json.example # Example MCP settings for Cline\n‚îú‚îÄ‚îÄ .gitignore                  # Git ignore file\n‚îî‚îÄ‚îÄ LICENSE                     # MIT License\n```\n\n## Prerequisites\n\n- Node.js (v16 or later)\n- A Cloudflare account with Browser Rendering enabled\n- TypeScript\n- Wrangler CLI (for deploying the Worker)\n\n## Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/yourusername/cloudflare-browser-rendering.git\ncd cloudflare-browser-rendering\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n## Cloudflare Worker Setup\n\n1. Install the Cloudflare Puppeteer package:\n\n```bash\nnpm install @cloudflare/puppeteer\n```\n\n2. Configure Wrangler:\n\n```toml\n# wrangler.toml\nname = \"browser-rendering-api\"\nmain = \"puppeteer-worker.js\"\ncompatibility_date = \"2023-10-30\"\ncompatibility_flags = [\"nodejs_compat\"]\n\n[browser]\nbinding = \"browser\"\n```\n\n3. Deploy the Worker:\n\n```bash\nnpx wrangler deploy\n```\n\n4. Test the Worker:\n\n```bash\nnode test-puppeteer.js\n```\n\n## Running the Experiments\n\n### Basic REST API Experiment\n\nThis experiment demonstrates how to use the Cloudflare Browser Rendering REST API to fetch and process web content:\n\n```bash\nnpm run experiment:rest\n```\n\n### Puppeteer Binding API Experiment\n\nThis experiment demonstrates how to use the Cloudflare Browser Rendering Workers Binding API with Puppeteer for more advanced browser automation:\n\n```bash\nnpm run experiment:puppeteer\n```\n\n### Content Extraction Experiment\n\nThis experiment demonstrates how to extract and process web content specifically for use as context in LLMs:\n\n```bash\nnpm run experiment:content\n```\n\n## MCP Server\n\nThe MCP server provides tools for fetching and processing web content using Cloudflare Browser Rendering for use as context in LLMs.\n\n### Building the MCP Server\n\n```bash\nnpm run build\n```\n\n### Running the MCP Server\n\n```bash\nnpm start\n```\n\nOr, for development:\n\n```bash\nnpm run dev\n```\n\n### MCP Server Tools\n\nThe MCP server provides the following tools:\n\n1. `fetch_page` - Fetches and processes a web page for LLM context\n2. `search_documentation` - Searches Cloudflare documentation and returns relevant content\n3. `extract_structured_content` - Extracts structured content from a web page using CSS selectors\n4. `summarize_content` - Summarizes web content for more concise LLM context\n\n## Configuration\n\nTo use your Cloudflare Browser Rendering endpoint, set the `BROWSER_RENDERING_API` environment variable:\n\n```bash\nexport BROWSER_RENDERING_API=https://YOUR_WORKER_URL_HERE\n```\n\nReplace `YOUR_WORKER_URL_HERE` with the URL of your deployed Cloudflare Worker. You'll need to replace this placeholder in several files:\n\n1. In test files: `test-puppeteer.js`, `examples/debugging-tools/debug-test.js`, `examples/testing/content-test.js`\n2. In the MCP server configuration: `cline_mcp_settings.json.example`\n3. In the browser client: `src/browser-client.ts` (as a fallback if the environment variable is not set)\n\n## Integrating with Cline\n\nTo integrate the MCP server with Cline, copy the `cline_mcp_settings.json.example` file to the appropriate location:\n\n```bash\ncp cline_mcp_settings.json.example ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n```\n\nOr add the configuration to your existing `cline_mcp_settings.json` file.\n\n## Key Learnings\n\n1. Cloudflare Browser Rendering requires the `@cloudflare/puppeteer` package to interact with the browser binding.\n2. The correct pattern for using the browser binding is:\n   ```javascript\n   import puppeteer from '@cloudflare/puppeteer';\n   \n   // Then in your handler:\n   const browser = await puppeteer.launch(env.browser);\n   const page = await browser.newPage();\n   ```\n3. When deploying a Worker that uses the Browser Rendering binding, you need to enable the `nodejs_compat` compatibility flag.\n4. Always close the browser after use to avoid resource leaks.\n\n## License\n\nMIT",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "amotivv--cloudflare-browser-rendering-mcp": {
          "owner": "amotivv",
          "name": "cloudflare-browser-rendering-mcp",
          "url": "https://github.com/amotivv/cloudflare-browser-rendering-mcp",
          "imageUrl": "https://github.com/amotivv.png",
          "description": "Fetch and process web content for contextual use in LLMs, with capabilities for structured content extraction and documentation search. Capture screenshots of web pages to enhance insights and contextual understanding.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:26.201423",
          "collection_timestamp": "2025-10-02T15:07:53.579200",
          "stars": 10,
          "forks": 5,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-02-28T17:27:02Z",
          "updated_at": "2025-06-16T14:13:15Z",
          "open_issues": 2,
          "readme_content": "# Cloudflare Browser Rendering MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@amotivv/cloudflare-browser-rendering-mcp)](https://smithery.ai/server/@amotivv/cloudflare-browser-rendering-mcp)\n\nThis MCP (Model Context Protocol) server provides tools for fetching and processing web content using Cloudflare Browser Rendering for use as context in LLMs. It's designed to work with both Claude and Cline client environments.\n\n<a href=\"https://glama.ai/mcp/servers/35u5mo3dm5\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/35u5mo3dm5/badge\" alt=\"cloudflare-browser-rendering-mcp MCP server\" />\n</a>\n\n## Features\n\n- **Web Content Fetching**: Fetch and process web pages for LLM context\n- **Documentation Search**: Search Cloudflare documentation and return relevant content\n- **Structured Content Extraction**: Extract structured content from web pages using CSS selectors\n- **Content Summarization**: Summarize web content for more concise LLM context\n- **Screenshot Capture**: Take screenshots of web pages\n\n## Prerequisites\n\n- Node.js v18 or higher\n- A Cloudflare account with Browser Rendering API access\n- A deployed Cloudflare Worker using the provided `puppeteer-worker.js` file\n\n## Installation\n\n### Installing via Smithery\n\nTo install Cloudflare Browser Rendering for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@amotivv/cloudflare-browser-rendering-mcp):\n\n```bash\nnpx -y @smithery/cli install @amotivv/cloudflare-browser-rendering-mcp --client claude\n```\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/yourusername/cloudflare-browser-rendering.git\n   cd cloudflare-browser-rendering\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Cloudflare Worker Setup\n\n1. Deploy the `puppeteer-worker.js` file to Cloudflare Workers using Wrangler:\n   ```bash\n   npx wrangler deploy\n   ```\n\n2. Make sure to configure the following bindings in your Cloudflare Worker:\n   - Browser Rendering binding named `browser`\n   - KV namespace binding named `SCREENSHOTS`\n\n3. Note the URL of your deployed worker (e.g., `https://browser-rendering-api.yourusername.workers.dev`)\n\n## Configuration\n\n### For Claude Desktop\n\n1. Open the Claude Desktop configuration file:\n   ```bash\n   # macOS\n   code ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n   \n   # Windows\n   code %APPDATA%\\Claude\\claude_desktop_config.json\n   ```\n\n2. Add the MCP server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"cloudflare-browser-rendering\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/cloudflare-browser-rendering/dist/index.js\"],\n         \"env\": {\n           \"BROWSER_RENDERING_API\": \"https://your-worker-url.workers.dev\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n3. Restart Claude Desktop\n\n### For Cline\n\n1. Open the Cline MCP settings file:\n   ```bash\n   # macOS\n   code ~/Library/Application\\ Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   \n   # Windows\n   code %APPDATA%\\Code\\User\\globalStorage\\saoudrizwan.claude-dev\\settings\\cline_mcp_settings.json\n   ```\n\n2. Add the MCP server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"cloudflare-browser-rendering\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/cloudflare-browser-rendering/dist/index.js\"],\n         \"env\": {\n           \"BROWSER_RENDERING_API\": \"https://your-worker-url.workers.dev\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n## Usage\n\nOnce configured, the MCP server will be available to both Claude Desktop and Cline. You can use the following tools:\n\n### fetch_page\n\nFetches and processes a web page for LLM context.\n\n**Parameters:**\n- `url` (required): URL to fetch\n- `maxContentLength` (optional): Maximum content length to return\n\n**Example:**\n```\nCan you fetch and summarize the content from https://developers.cloudflare.com/browser-rendering/?\n```\n\n### search_documentation\n\nSearches Cloudflare documentation and returns relevant content.\n\n**Parameters:**\n- `query` (required): Search query\n- `maxResults` (optional): Maximum number of results to return\n\n**Example:**\n```\nSearch the Cloudflare documentation for information about \"browser rendering API\".\n```\n\n### extract_structured_content\n\nExtracts structured content from a web page using CSS selectors.\n\n**Parameters:**\n- `url` (required): URL to extract content from\n- `selectors` (required): CSS selectors to extract content\n\n**Example:**\n```\nExtract the main heading and first paragraph from https://developers.cloudflare.com/browser-rendering/ using the selectors h1 and p.\n```\n\n### summarize_content\n\nSummarizes web content for more concise LLM context.\n\n**Parameters:**\n- `url` (required): URL to summarize\n- `maxLength` (optional): Maximum length of the summary\n\n**Example:**\n```\nSummarize the content from https://developers.cloudflare.com/browser-rendering/ in 300 words or less.\n```\n\n### take_screenshot\n\nTakes a screenshot of a web page.\n\n**Parameters:**\n- `url` (required): URL to take a screenshot of\n- `width` (optional): Width of the viewport in pixels (default: 1280)\n- `height` (optional): Height of the viewport in pixels (default: 800)\n- `fullPage` (optional): Whether to take a screenshot of the full page or just the viewport (default: false)\n\n**Example:**\n```\nTake a screenshot of https://developers.cloudflare.com/browser-rendering/ with a width of 1024 pixels.\n```\n\n## Troubleshooting\n\n### Logging\n\nThe MCP server uses comprehensive logging with the following prefixes:\n\n- `[Setup]`: Initialization and configuration\n- `[API]`: API requests and responses\n- `[Error]`: Error handling and debugging\n\nTo view logs:\n\n- **Claude Desktop**: Check the logs in `~/Library/Logs/Claude/mcp*.log` (macOS) or `%APPDATA%\\Claude\\Logs\\mcp*.log` (Windows)\n- **Cline**: Logs appear in the output console of the VSCode extension\n\n### Common Issues\n\n1. **\"BROWSER_RENDERING_API environment variable is not set\"**\n   - Make sure you've set the correct URL to your Cloudflare Worker in the MCP server configuration\n\n2. **\"Cloudflare worker API is unavailable or not configured\"**\n   - Verify that your Cloudflare Worker is deployed and running\n   - Check that the URL is correct and accessible\n\n3. **\"Browser binding is not available\"**\n   - Ensure that you've configured the Browser Rendering binding in your Cloudflare Worker\n\n4. **\"SCREENSHOTS KV binding is not available\"**\n   - Ensure that you've configured the KV namespace binding in your Cloudflare Worker\n\n## Development\n\n### Project Structure\n\n- `src/index.ts`: Main entry point\n- `src/server.ts`: MCP server implementation\n- `src/browser-client.ts`: Client for interacting with Cloudflare Browser Rendering\n- `src/content-processor.ts`: Processes web content for LLM context\n- `puppeteer-worker.js`: Cloudflare Worker implementation\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Testing\n\nThe project includes a comprehensive test script that verifies all MCP tools are working correctly:\n\n```bash\nnpm test\n```\n\nThis will:\n1. Start the MCP server\n2. Test each tool with sample requests\n3. Verify the responses\n4. Provide a summary of test results\n\nYou can also run individual tests for specific components:\n\n```bash\n# Test the Puppeteer integration\nnpm run test:puppeteer\n```\n\nFor the tests to work properly, make sure you have:\n1. Built the project with `npm run build`\n2. Set the `BROWSER_RENDERING_API` environment variable to your Cloudflare Worker URL\n3. Deployed the Cloudflare Worker with the necessary bindings\n\n## License\n\nMIT",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "amysatterlee--nps_mcp": {
          "owner": "amysatterlee",
          "name": "nps_mcp",
          "url": "https://github.com/amysatterlee/nps_mcp",
          "imageUrl": "https://github.com/amysatterlee.png",
          "description": "Retrieve and explore data related to the National Park Services, including lists of national parks by state and detailed information about specific parks.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:27.008749",
          "collection_timestamp": "2025-10-02T15:08:01.717040",
          "stars": 3,
          "forks": 5,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-02-03T22:20:09Z",
          "updated_at": "2025-06-03T14:11:44Z",
          "open_issues": 4,
          "readme_content": "---\n\n# MCP Server for National Park Services Data\n\nThis MCP Server provides an interface to retrieve National Park Services (NPS) data. It allows users to:\n- Retrieve a list of national parks in a given U.S. state.\n- Fetch detailed information about a specific national park.\n\nIt uses the National Park Service API to obtain the data.\n\n## Requirements\n\n- Node.js (v18+ recommended)\n- npm or yarn\n- A valid NPS API key (available at [https://www.nps.gov/subjects/developer/get-started.htm](https://www.nps.gov/subjects/developer/get-started.htm))\n- Claude Desktop installed (for running MCP servers)\n\n## Setup\n\n1. Clone this repository:\n   ```sh\n   git clone <repository-url>\n   cd <repository-folder>\n   ```\n\n2. Install dependencies:\n   ```sh\n   npm install\n   ```\n\n3. Create a `.env` file in the root directory and add your NPS API key:\n   ```sh\n   API_KEY=your_nps_api_key_here\n   ```\n\n## Running the Server\n\nTo start the MCP server:\n\n```sh\nnpm run build\nnode ./build/server.js\n```\n\nUsing Claude Desktop:\n\n1. Add this MCP Server to the `claude_desktop_config.json`\n\n```\n{\n    \"mcpServers\": {\n        \"nps\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"/<Path to Server>/build/index.js\"\n            ],\n            \"env\": {\n                \"API_KEY\": \"Your NPS API Key\"\n            }\n        }\n    }\n}\n```\n\n2. Start or Restart Claude Desktop\n3. Ensure your MCP server is recognized and running by clicking on the tools icon at the bottom of Claude's chat window.\n4. Use Claude's interface to query National Park Services data.\n\n## API Endpoints\n\n### Fetch List of National Parks by State\n\n**Tool Name:** `park-list`\n\n**Parameters:**\n- `stateCode` (string) ‚Äì Two-letter U.S. state code\n\n**Response Example:**\n```json\n[\n  {\n    \"fullName\": \"Yellowstone National Park\",\n    \"description\": \"First national park in the U.S.\",\n    \"parkCode\": \"yell\"\n  }\n]\n```\n\n### Fetch Details of a National Park\n\n**Tool Name:** `park-details`\n\n**Parameters:**\n- `parkCode` (string) ‚Äì National Park lookup code\n\n**Response Example:**\n```json\n[\n  {\n    \"fullName\": \"Yellowstone National Park\",\n    \"description\": \"First national park in the U.S.\",\n    \"states\": \"WY, MT, ID\"\n  }\n]\n```\n\n## Prompts\n\n### Retrieve Parks in a State\n\n**Prompt Name:** `parks-by-state`\n\n**Parameters:**\n- `stateCode` (string)\n\n**Example:**\n```text\nWhat National Parks are in the state of CA?\n```\n\n### Get Park Details\n\n**Prompt Name:** `details-for-park`\n\n**Parameters:**\n- `park` (string)\n\n**Example:**\n```text\nGive me details about Yellowstone National Park.\n```\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "Anansitrading--poe-proxy-mcp": {
          "owner": "Anansitrading",
          "name": "poe-proxy-mcp",
          "url": "https://github.com/Anansitrading/poe-proxy-mcp",
          "imageUrl": "https://github.com/Anansitrading.png",
          "description": "Proxy for the Poe.com API that enables querying multiple AI models with session management, real-time streaming responses, and file sharing capabilities. Facilitates integration with web clients using SSE transport and offers special support for Claude 3.7 Sonnet's thinking protocol.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:27.913387",
          "collection_timestamp": "2025-10-02T15:08:09.521746",
          "stars": 6,
          "forks": 3,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-04-23T01:32:02Z",
          "updated_at": "2025-09-25T23:18:15Z",
          "open_issues": 0,
          "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/anansitrading-poe-proxy-mcp-badge.png)](https://mseep.ai/app/anansitrading-poe-proxy-mcp)\n\n# Enhanced POE MCP Server for Warp.dev\n\nA production-ready Model Context Protocol (MCP) server that integrates POE (Poe.com API) with Warp.dev terminal, enabling AI-powered terminal assistance with context-aware tooling, automated workflows, and real-time streaming capabilities.\n\n## üöÄ Features\n\n### Core Capabilities\n- **Multi-Model Support**: Access GPT-4o, Claude 3 Opus/Sonnet, Gemini Pro, Perplexity, and O3 models\n- **Warp Terminal Integration**: Deep integration with Warp's context extraction and action execution\n- **OpenAI SDK Compatibility**: Drop-in replacement for OpenAI API with POE backend\n- **Production-Ready**: Rate limiting, health checks, metrics, and graceful shutdown\n\n### Advanced Features\n- **Context-Aware Queries**: Automatically extracts terminal output, selections, CWD, git state\n- **Real-Time Streaming**: Server-Sent Events (SSE) with delta content streaming\n- **Command Execution**: Safe execution of terminal commands with validation\n- **File Operations**: Create and modify files directly from model responses\n- **Session Management**: Maintain conversation context across multiple queries\n- **Rate Limiting**: Exponential backoff with 500 RPM limit and request queuing\n- **Health Monitoring**: Built-in health checks and Prometheus-style metrics\n\n## üìã Prerequisites\n\n- **Operating System**: Linux (tested on Ubuntu, Zorin OS), macOS, or WSL2 on Windows\n- **Python**: Version 3.8 or higher\n- **Warp Terminal**: [Download from warp.dev](https://warp.dev/)\n- **POE API Key**: Get yours from [poe.com/api_key](https://poe.com/api_key)\n\n## üîß Installation\n\n### Step 1: Clone and Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/Anansitrading/enhanced-poe-mcp.git\ncd enhanced-poe-mcp\n\n# Quick installation with script\nchmod +x install.sh\n./install.sh\n\n# Or manual setup\npython3 -m venv venv\nsource venv/bin/activate  # On Linux/macOS\npip install -e .\n```\n\n### Step 2: Configure Environment\n\nCreate a `.env` file with your credentials:\n\n```bash\n# Required\nPOE_API_KEY=your_poe_api_key_here\n\n# Optional (with defaults)\nOPENAI_API_KEY=your_openai_key  # For OpenAI SDK compatibility\nDEBUG_MODE=false\nUSE_CLAUDE_COMPATIBLE=true\nMAX_FILE_SIZE_MB=10\nSESSION_EXPIRY_MINUTES=60\nRATE_LIMIT_RPM=500\nMAX_RETRIES=3\nSTREAM_BUFFER_SIZE=64\nMETRICS_ENABLED=true\nHEALTH_CHECK_INTERVAL=30\n```\n\n### Step 3: Configure in Warp Terminal\n\n#### Option A: Local Installation (Can cause stability issues)\n\n1. **Open Warp MCP Settings**:\n   - Navigate to: **Settings ‚Üí AI ‚Üí Manage MCP servers**\n   - Or press `Ctrl+P` (Linux/Windows) or `Cmd+P` (macOS) and search for \"Open MCP Servers\"\n\n2. **Add the POE MCP Server**:\n   Click the **+ Add** button and paste this configuration:\n\n   ```json\n   {\n     \"enhanced-poe-mcp\": {\n       \"command\": \"python3\",\n       \"args\": [\"/home/david/Projects/Kijko/MVP/MVP_Kijko/enhanced-poe-mcp/poe_server_phase2.py\"],\n       \"env\": {\n         \"POE_API_KEY\": \"your_poe_api_key_here\",\n         \"PYTHONUNBUFFERED\": \"1\",\n         \"DEBUG_MODE\": \"false\",\n         \"RATE_LIMIT_RPM\": \"500\"\n       }\n     }\n   }\n   ```\n\n   **Important**: Replace `/home/david/Projects/Kijko/MVP/MVP_Kijko/enhanced-poe-mcp` with your actual installation path.\n\n3. **Save and Start**:\n   - Click **Save** to add the configuration\n   - Click **Start** next to your server entry\n   - The server status should show as \"Running\"\n\n#### Option B: Remote Hosting (Recommended for Stability)\n\n**Warp supports remote MCP servers!** Host your MCP server remotely to avoid local stability issues.\n\n1. **Deploy to Railway.app** (Best free option):\n   ```bash\n   # Prepare for deployment\n   cd enhanced-poe-mcp\n   echo \"web: python poe_server_phase2.py\" > Procfile\n   git add .\n   git commit -m \"Add Procfile for Railway\"\n   git push origin main\n   ```\n\n2. **Configure Railway**:\n   - Sign up at [railway.app](https://railway.app)\n   - Create new project ‚Üí Deploy from GitHub\n   - Add environment variables in Railway dashboard:\n     - `POE_API_KEY`\n     - `PORT=8000`\n     - Any other config variables\n\n3. **Configure Warp for Remote MCP**:\n   ```json\n   {\n     \"enhanced-poe-mcp\": {\n       \"url\": \"https://your-app.up.railway.app/mcp/stream\"\n     }\n   }\n   ```\n\n**Alternative Hosting Options**:\n- **Render.com**: Good free tier, easy deployment\n- **Google Cloud Run**: Generous free tier, requires Docker\n- **Fly.io**: Global deployment, more complex setup\n- **Vercel**: ‚ùå NOT COMPATIBLE - Cannot handle persistent connections, SSE streaming, or long-running tasks\n\n## üéÆ Usage in Warp Terminal\n\n### Specifying POE Models\n\nPOE is a marketplace with hundreds of LLMs. You must specify which model to use:\n\n```bash\n# Using Claude 3.5 Sonnet\n@poe --model claude-3-5-sonnet \"Explain quantum computing\"\n\n# Using GPT-4o\n@poe --model gpt-4o \"Write a Python function\"\n\n# Using Gemini Pro\n@poe --model google-gemini-pro \"Analyze this data\"\n```\n\n**Popular Model Identifiers**:\n| Model | Bot Identifier |\n|-------|---------------|\n| Claude 3.5 Sonnet | `claude-3-5-sonnet` |\n| Claude 3 Opus | `claude-3-opus-20240229` |\n| GPT-4 Turbo | `gpt-4-turbo` |\n| GPT-4o | `gpt-4o` |\n| Gemini Pro | `google-gemini-pro` |\n| Llama 3 (70B) | `llama-3-70b` |\n| Mistral Large | `mistral-large` |\n| Perplexity | `perplexity-online` |\n| Custom Bots | Use the handle from poe.com/[bot-name] |\n\n### Basic POE Query\n```bash\n# Ask a simple question with specific model\n@poe --model claude-3-5-sonnet What is the fastest way to create a Python virtual environment?\n\n# Expected output:\n# Claude will respond with: \"Use `python -m venv <directory>` to create a virtual environment. \n# Activate it with `source <directory>/bin/activate` on Linux/macOS...\"\n```\n\n### Query with File Attachment\n```bash\n# Review a configuration file with Claude 3.5\n@poe --model claude-3-5-sonnet Review this Dockerfile for security issues [attach:./Dockerfile]\n\n# Expected output:\n# Claude analyzes the file and provides security recommendations:\n# \"Found potential issues: 1) Running as root user, 2) No health check defined...\"\n```\n\n### Context-Aware Query\n```bash\n# Get help with a recent error (POE sees your terminal output)\n@poe --model gpt-4o Why did my git push fail?\n\n# Expected output:\n# GPT-4o analyzes recent terminal output and responds:\n# \"The push failed because the remote has changes not in your local branch. \n# Run `git pull --rebase` first...\"\n```\n\n### Execute Terminal Commands\n```bash\n# Let POE execute safe commands using Gemini\n@poe --model google-gemini-pro Find all Python files modified today and show their sizes\n\n# Expected output:\n# Gemini generates and executes: find . -name \"*.py\" -mtime 0 -ls\n# Shows results directly in terminal\n```\n\n### Stream Long Responses\n```bash\n# Get streaming output for complex tasks with Claude Opus\n@poe --model claude-3-opus-20240229 --stream Generate a complete FastAPI application with authentication\n\n# Expected output:\n# Claude Opus streams the code generation in real-time, showing each part as it's created\n```\n\n### Session Management\n```bash\n# Clear conversation context\n@poe clear session\n\n# Expected output:\n# \"Session cleared. Starting fresh conversation.\"\n```\n\n### List Available Models\n```bash\n# See all available AI models\n@poe list models\n\n# Expected output:\n# Available models:\n# - claude-3-opus: Advanced reasoning and analysis\n# - gpt-4o: Latest GPT-4 variant\n# - gemini-pro: Google's advanced model\n# - perplexity: Web-aware responses\n```\n\n### Health Check\n```bash\n# Check server health\n@poe health check\n\n# Expected output:\n# Server Status: Healthy ‚úì\n# Uptime: 2h 34m\n# Active Sessions: 3\n# Request Rate: 45 RPM\n```\n\n## üõ†Ô∏è Advanced Configuration\n\n### Server Variants\n\nThe project includes multiple server implementations for different use cases:\n\n| Server File | Description | Use Case |\n|------------|-------------|----------|\n| `poe_server.py` | Basic MCP server | Simple POE proxy |\n| `enhanced_poe_server.py` | Enhanced with Warp actions | Terminal automation |\n| `poe_server_v2.py` | SDK-compatible | OpenAI SDK replacement |\n| `poe_server_phase2.py` | Production server | Full features + monitoring |\n\n### Running Different Modes\n\n```bash\n# Basic server\npython poe_server.py\n\n# Enhanced server with Warp integration\npython enhanced_poe_server.py\n\n# Production server (recommended)\npython poe_server_phase2.py\n\n# SSE mode for web clients\npython run_sse_server.py [port]\n```\n\n### Environment Variables Reference\n\n| Variable | Description | Default | Required |\n|----------|-------------|---------|----------|\n| `POE_API_KEY` | Your POE API key | - | ‚úÖ |\n| `OPENAI_API_KEY` | OpenAI API key (for SDK mode) | - | ‚ùå |\n| `DEBUG_MODE` | Enable verbose logging | `false` | ‚ùå |\n| `USE_CLAUDE_COMPATIBLE` | Claude thinking protocol | `true` | ‚ùå |\n| `MAX_FILE_SIZE_MB` | Max file upload size | `10` | ‚ùå |\n| `SESSION_EXPIRY_MINUTES` | Session lifetime | `60` | ‚ùå |\n| `RATE_LIMIT_RPM` | Requests per minute limit | `500` | ‚ùå |\n| `MAX_RETRIES` | Retry attempts for failures | `3` | ‚ùå |\n| `STREAM_BUFFER_SIZE` | SSE buffer size (KB) | `64` | ‚ùå |\n| `METRICS_ENABLED` | Enable metrics collection | `true` | ‚ùå |\n| `HEALTH_CHECK_INTERVAL` | Health check interval (seconds) | `30` | ‚ùå |\n\n## üìä Monitoring & Metrics\n\n### Health Check Endpoint\n```python\n# Check server health programmatically\nimport requests\nhealth = requests.get(\"http://localhost:8000/health\")\nprint(health.json())\n# Output: {\"status\": \"healthy\", \"uptime\": 3600, \"active_sessions\": 5}\n```\n\n### Metrics Endpoint\n```python\n# Get performance metrics\nmetrics = requests.get(\"http://localhost:8000/metrics\")\nprint(metrics.json())\n# Output: {\"total_requests\": 1234, \"error_rate\": 0.02, \"avg_latency_ms\": 250}\n```\n\n## üêõ Troubleshooting\n\n### MCP Server Won't Start in Warp\n\n**Issue**: Server fails to start or shows as \"Error\" in Warp MCP panel\n\n**Solutions**:\n1. Verify Python path: `which python3` and update configuration\n2. Check file permissions: `chmod +x poe_server_phase2.py`\n3. Test manually: `cd /path/to/server && python3 poe_server_phase2.py`\n4. Check logs: Look for errors in terminal output\n\n### Authentication Errors\n\n**Issue**: \"Invalid API key\" or \"Authentication failed\"\n\n**Solutions**:\n1. Verify POE_API_KEY in `.env` file\n2. Ensure key is added to Warp MCP config environment\n3. Test key at [poe.com/api_key](https://poe.com/api_key)\n\n### Rate Limiting Issues\n\n**Issue**: \"Rate limit exceeded\" errors\n\n**Solutions**:\n1. Increase `RATE_LIMIT_RPM` in configuration\n2. Enable request queuing (automatic in Phase 2 server)\n3. Implement exponential backoff in client code\n\n### Context Not Working\n\n**Issue**: POE doesn't see terminal output or context\n\n**Solutions**:\n1. Use `poe_server_phase2.py` (not basic server)\n2. Ensure Warp context permissions are enabled\n3. Update to latest Warp version\n\n### Linux-Specific Issues\n\n**Issue**: Permission denied or module not found\n\n**Solutions**:\n```bash\n# Fix permissions\nchmod -R 755 /path/to/enhanced-poe-mcp\nchown -R $USER:$USER /path/to/enhanced-poe-mcp\n\n# Install missing Python packages\npip install -r requirements.txt\n\n# Use virtual environment\nsource venv/bin/activate\n```\n\n## üöÄ Remote Deployment Guide (Railway)\n\n### Why Host Remotely?\n- Avoids local stability issues\n- Always available, even when your machine is off\n- Centralized configuration management\n- Better for team collaboration\n\n### Step-by-Step Railway Deployment\n\n1. **Prepare Your Project**:\n   ```bash\n   cd enhanced-poe-mcp\n   \n   # Create Procfile for Railway\n   echo 'web: python poe_server_phase2.py' > Procfile\n   \n   # Ensure requirements.txt is complete\n   pip freeze > requirements.txt\n   \n   # Create runtime.txt for Python version\n   echo \"python-3.11.x\" > runtime.txt\n   \n   # Commit changes\n   git add .\n   git commit -m \"Add Railway deployment files\"\n   git push origin main\n   ```\n\n2. **Set Up Railway**:\n   - Sign up at [railway.app](https://railway.app) (free with GitHub)\n   - Click **\"New Project\"** ‚Üí **\"Deploy from GitHub repo\"**\n   - Select your `enhanced-poe-mcp` repository\n   - Railway will auto-detect Python and begin deployment\n\n3. **Configure Environment Variables**:\n   In Railway dashboard, go to **Variables** tab and add:\n   ```\n   POE_API_KEY=your_poe_api_key_here\n   PORT=8000\n   DEBUG_MODE=false\n   RATE_LIMIT_RPM=500\n   PYTHONUNBUFFERED=1\n   ```\n\n4. **Get Your Server URL**:\n   - Go to **Settings** tab in Railway\n   - Under **Domains**, click **\"Generate Domain\"**\n   - Copy your URL (e.g., `https://your-app.up.railway.app`)\n\n5. **Configure Warp with Remote URL**:\n   ```json\n   {\n     \"enhanced-poe-mcp\": {\n       \"url\": \"https://your-app.up.railway.app/mcp/stream\"\n     }\n   }\n   ```\n\n6. **Test the Connection**:\n   ```bash\n   # Test your remote server\n   curl https://your-app.up.railway.app/health\n   \n   # Should return:\n   # {\"status\": \"healthy\", \"version\": \"2.0.0\"}\n   ```\n\n### Monitoring Your Remote Server\n\n- **Logs**: View in Railway dashboard under \"Deployments\"\n- **Metrics**: Check `/metrics` endpoint\n- **Health**: Monitor `/health` endpoint\n- **Usage**: Railway shows resource consumption in dashboard\n\n## üåóÔ∏è Architecture\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Warp Terminal  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   POE MCP Server         ‚îÇ\n‚îÇ                 ‚îÇ  MCP     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  - User Input   ‚îÇ  Proto   ‚îÇ ‚Ä¢ Request Handler        ‚îÇ\n‚îÇ  - Context      ‚îÇ         ‚îÇ ‚Ä¢ Rate Limiter           ‚îÇ\n‚îÇ  - Actions      ‚îÇ         ‚îÇ ‚Ä¢ Session Manager        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ ‚Ä¢ Warp Context Handler   ‚îÇ\n                            ‚îÇ ‚Ä¢ Streaming Engine       ‚îÇ\n                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                                       ‚îÇ\n                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n                            ‚îÇ      POE API             ‚îÇ\n                            ‚îÇ                          ‚îÇ\n                            ‚îÇ ‚Ä¢ Claude, GPT-4o         ‚îÇ\n                            ‚îÇ ‚Ä¢ Gemini, Perplexity     ‚îÇ\n                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## üß™ Testing\n\n```bash\n# Run all tests\npython run_tests.py\n\n# Run with verbose output\npython run_tests.py --verbose\n\n# Test specific components\npython -m pytest tests/test_poe_server.py -v\npython -m pytest tests/test_rate_limiter.py -v\npython -m pytest tests/test_streaming.py -v\n```\n\n## üìö API Documentation\n\n### MCP Tools Reference\n\n| Tool | Description | Parameters |\n|------|-------------|------------|\n| `ask_poe` | Basic POE query | `prompt`, `model`, `session_id` |\n| `ask_with_attachment` | Query with file | `prompt`, `model`, `file_path` |\n| `ask_poe_with_warp_context` | Context-aware query | `prompt`, `model`, `warp_context` |\n| `stream_poe_to_warp` | Streaming response | `prompt`, `model`, `stream=true` |\n| `execute_warp_action` | Run terminal command | `action_type`, `content`, `validate` |\n| `clear_session` | Reset conversation | `session_id` |\n| `list_available_models` | Get model list | - |\n| `health_check` | Server health | - |\n| `get_metrics` | Performance stats | - |\n\n## ü§ù Contributing\n\nWe welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n### Development Setup\n\n```bash\n# Clone and setup development environment\ngit clone https://github.com/Anansitrading/enhanced-poe-mcp.git\ncd enhanced-poe-mcp\npython3 -m venv venv\nsource venv/bin/activate\npip install -e \".[dev]\"\n\n# Run in development mode\nDEBUG_MODE=true python poe_server_phase2.py\n```\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## üôè Acknowledgments\n\n- [Poe.com](https://poe.com) for the API access\n- [Warp.dev](https://warp.dev) for the amazing terminal\n- [FastMCP](https://github.com/jlowin/fastmcp) for the MCP framework\n- The open-source community for continuous support\n\n## üìû Support\n\n- **Issues**: [GitHub Issues](https://github.com/Anansitrading/enhanced-poe-mcp/issues)\n- **Discussions**: [GitHub Discussions](https://github.com/Anansitrading/enhanced-poe-mcp/discussions)\n- **Documentation**: [Wiki](https://github.com/Anansitrading/enhanced-poe-mcp/wiki)\n\n---\n\n**Note**: This project is not affiliated with Poe.com or Warp.dev. It's an independent integration tool.",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AnCode666--nasa-mcp": {
          "owner": "AnCode666",
          "name": "nasa-mcp",
          "url": "https://github.com/AnCode666/nasa-mcp",
          "imageUrl": "https://github.com/AnCode666.png",
          "description": "Retrieve astronomical data, space weather information, and Earth imagery from NASA's APIs. Query various services such as Astronomy Picture of the Day and Near Earth Objects for real-time data retrieval.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:28.762324",
          "collection_timestamp": "2025-10-02T15:08:13.478586",
          "stars": 4,
          "forks": 2,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-04-30T00:08:02Z",
          "updated_at": "2025-08-17T12:59:18Z",
          "open_issues": 0,
          "readme_content": "[![en](https://img.shields.io/badge/lang-en-red.svg)](README.md)\n[![es](https://img.shields.io/badge/lang-es-yellow.svg)](README_es.md)\n\n# NASA-MCP. Integration via MCP with NASA APIs\n\n**NASA is the National Aeronautics and Space Administration of the United States.**\n\n**NASA-MCP** allows you to retrieve astronomical data, space weather information, Earth imagery, and more from NASA's APIs directly from Claude AI and other MCP compatible clients, using the **Model Context Protocol (MCP)**.\n\nNASA-MCP is an MCP server that exposes tools enabling LLMs to query data from various NASA APIs, including APOD (Astronomy Picture of the Day), Asteroids NeoWs, DONKI (Space Weather Database), Earth imagery, EPIC (Earth Polychromatic Imaging Camera), and Exoplanet data.\n\nIt includes secure handling of API keys and proper error management for all API requests.\n\n## Key Features\n\n- Access to **Astronomy Picture of the Day (APOD)** with explanations and imagery\n- Query **Near Earth Objects** data and asteroid information\n- Retrieve **Space Weather** data from DONKI, including solar flares, geomagnetic storms, and more\n- Get **Earth imagery** from Landsat 8 satellite for specific coordinates\n- Access **EPIC** camera images showing the full Earth disk\n- Query the **Exoplanet Archive** database for information about planets outside our solar system\n\n## Installation\n\n### Installing via Smithery\n\nTo install NASA API Integration Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@AnCode666/nasa-mcp):\n\n```bash\nnpx -y @smithery/cli install @AnCode666/nasa-mcp --client claude\n```\n\n### Install with uv\n\n### Prerequisites\n\n- Python 3.10 or higher\n- [uv](https://docs.astral.sh/uv/getting-started/installation/) package manager\n\n### Installing uv\n\nThe first step is to install `uv`, a package manager for Python.  \n**It can be installed from the command line**.\n\nOn macOS and Linux:\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\nOn Windows:  \n\n```bash\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nYou can also install it with pip:  \n\n```bash\npip install uv\n```\n\nFor more information about installing uv, visit the [uv documentation](https://docs.astral.sh/uv/getting-started/installation/).\n\n## Integration with clients like Claude for Desktop\n\nOnce **uv** is installed, you can use the MCP server from any compatible client such as Claude for Desktop, in which case the steps to follow are:\n\n1. Go to **Claude > Settings > Developer > Edit Config > `claude_desktop_config.json`**\n2. Add the following block inside `\"mcpServers\"`:\n\n```json\n\"nasa-mcp\": {\n    \"command\": \"uvx\",\n    \"args\": [\n        \"nasa_mcp\"\n    ],\n    \"env\": {\n        \"NASA_API_KEY\": \"YOUR_NASA_API_KEY\"\n    }\n}\n```\n\n3. Get a free API key from NASA at: <https://api.nasa.gov/>\n4. Replace `YOUR_NASA_API_KEY` with your actual API key (leave the quotes). You can also use \"DEMO_KEY\" for limited testing.\n5. If you already have another MCP server configured, separate each with a comma `,`.\n\nIn general, to integrate it into any other MCP-compatible client such as Cursor, CODEGPT, or Roo Code, simply go to the MCP server configuration of your client and add the same code block.\n\n## Usage Examples\n\nOnce properly configured, you can ask things like:\n\n- \"Show me today's astronomy picture of the day\"\n- \"Find asteroids that will pass near Earth in the next week\"\n- \"Get information about solar flares from January 2023\"\n- \"Show me Earth imagery for coordinates 29.78, -95.33\"\n- \"Find exoplanets in the habitable zone\"\n\n## DISTRIBUTIONS\n\n### Smithery\n\n[![smithery badge](https://smithery.ai/badge/@AnCode666/nasa-mcp)](https://smithery.ai/server/@AnCode666/nasa-mcp)\n\n### MCP Review\n\n[MCP review certified](https://mcpreview.com/mcp-servers/ancode666/nasa-mcp)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/nasa-mcp",
          "npm_downloads": 0,
          "npm_package_name": "nasa-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "andybrandt--mcp-simple-arxiv": {
          "owner": "andybrandt",
          "name": "mcp-simple-arxiv",
          "url": "https://github.com/andybrandt/mcp-simple-arxiv",
          "imageUrl": "https://github.com/andybrandt.png",
          "description": "Provides access to arXiv papers through their API, enabling searches for papers by title and abstract, retrieval of metadata and abstracts, and access to various paper formats including PDF and HTML.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:29.673483",
          "collection_timestamp": "2025-10-02T15:08:21.311497",
          "stars": 156,
          "forks": 20,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-07T07:52:32Z",
          "updated_at": "2025-10-01T14:29:40Z",
          "open_issues": 1,
          "readme_content": "# mcp-simple-arxiv\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/andybrandt/mcp-simple-arxiv)](https://archestra.ai/mcp-catalog/andybrandt__mcp-simple-arxiv)\n[![smithery badge](https://smithery.ai/badge/mcp-simple-arxiv)](https://smithery.ai/server/mcp-simple-arxiv)\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/dc95dba9-149a-4eaa-bf08-36e0cb0f3a5a)\n\nAn MCP server that provides access to arXiv papers through their API.\n\n<a href=\"https://glama.ai/mcp/servers/p38q3nagwb\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/p38q3nagwb/badge\" alt=\"mcp-simple-arxiv MCP server\" /></a>\n\n## Features\n\nThis server allows LLM clients (like Claude Desktop) to:\n- Search for scientific papers on arXiv by title and abstract content\n- Get paper metadata and abstracts\n- Access links to available paper formats (PDF/HTML)\n\nTo use the web version just add this connector to Claude.ai https://mcp.andybrandt.net/arxiv .\nYou can also install & use it locally. \n\n## Installation and Deployment\n\nThis server can be run in two modes: as a local `stdio` server for desktop clients or as a network-accessible web server.\n\n### Installing via Smithery\n\nTo install Simple Arxiv for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-simple-arxiv):\n\n```bash\nnpx -y @smithery/cli install mcp-simple-arxiv --client claude\n```\n\n### Manual Installation\n```bash\npip install mcp-simple-arxiv\n```\n\n## Usage with Claude Desktop\n\nAdd this configuration to your `claude_desktop_config.json`:\n\n(Mac OS)\n\n```json\n{\n  \"mcpServers\": {\n    \"simple-arxiv\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_simple_arxiv\"]\n      }\n  }\n}\n```\n\n(Windows version):\n\n```json\n{\n  \"mcpServers\": {\n    \"simple-arxiv\": {\n      \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\n        \"-m\",\n        \"mcp_simple_arxiv\"\n      ]\n    }\n  }\n}\n```\n\nAfter restarting Claude Desktop, the following capabilities will be available:\n\n### Searching Papers\n\nYou can ask Claude to search for papers using queries like:\n```\nCan you search arXiv for recent papers about large language models?\n```\n\nThe search will return basic information about matching papers including:\n- Paper title\n- Authors\n- arXiv ID\n- Publication date\n\n### Getting Paper Details\n\nOnce you have a paper ID, you can ask for more details:\n```\nCan you show me the details for paper 2103.08220?\n```\n\nThis will return:\n- Full paper title\n- Authors\n- Publication and update dates\n- Journal reference (if available)\n- Paper abstract\n- Links to available formats (PDF/HTML)\n\n\n*For web deployment see [DEPLOYMENT.md](DEPLOYMENT.md)*.\n\n## Development\n\nTo install for development:\n```bash\ngit clone https://github.com/andybrandt/mcp-simple-arxiv\ncd mcp-simple-arxiv\npip install -e .\n```\n\n### arXiv API Guidelines\n\nThis server follows arXiv API usage guidelines:\n- Rate limiting to max 1 request per 3 seconds\n- Single connection at a time\n- Proper error handling and retry logic\n\n## License\n\nMIT\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "andybrandt--mcp-simple-pubmed": {
          "owner": "andybrandt",
          "name": "mcp-simple-pubmed",
          "url": "https://github.com/andybrandt/mcp-simple-pubmed",
          "imageUrl": "https://github.com/andybrandt.png",
          "description": "Access and search PubMed articles through the Entrez API, retrieve article abstracts, and download full-text content for open access articles when available.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:30.571696",
          "collection_timestamp": "2025-10-02T15:08:29.175240",
          "stars": 134,
          "forks": 29,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-11T14:53:03Z",
          "updated_at": "2025-10-01T17:17:49Z",
          "open_issues": 3,
          "readme_content": "[![MseeP Badge](https://mseep.net/pr/andybrandt-mcp-simple-pubmed-badge.jpg)](https://mseep.ai/app/andybrandt-mcp-simple-pubmed)\n\n# MCP Simple PubMed\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/andybrandt/mcp-simple-pubmed)](https://archestra.ai/mcp-catalog/andybrandt__mcp-simple-pubmed)\n[![smithery badge](https://smithery.ai/badge/mcp-simple-pubmed)](https://smithery.ai/server/mcp-simple-pubmed)\n\nAn MCP server that provides access to PubMed articles through the Entrez API.\n\n<a href=\"https://glama.ai/mcp/servers/5wlfb8i6bj\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/5wlfb8i6bj/badge\" alt=\"mcp-simple-pubmed MCP server\" /></a>\n\n## Features\n\n- Search PubMed database using keywords\n- Access article abstracts\n- Download full text when available (for open access articles available directly on PubMed) \n\nPlease note that the tool returns XML-ized version of full text. It is however more useful for AIs than a \"human readable\" text would have been as it gives them additional information about document's structure. At least, this is what Claude 3.5 Sonnet said he prefers. \n\nPlease also note that inability of this tool and possibly other tools to deliver a paper's full text may not be due to the fact that it is not available. When testing this tool I came across a paper that did not have full text on PubMed and when Claude accessed the publication URL (which we did get through DOI) using fetch he did get a \"forbidden‚Äù error. However, I was able to access the very same page using a regular browser. \n\nIn other words if your AI assistant is not able to get the full text of a paper using this tool it is worth trying manually with a regular web browser.\n\nFinally, this tool of course can‚Äôt give you access to paywalled/paid papers. You may be able to read them through your library access or ‚Äì as a last resort ‚Äì through a certain site that strives to make publicly funded research freely available. \n\n## Installation\n\n### Installing via Smithery\n\nTo install Simple PubMed for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-simple-pubmed):\n\n```bash\nnpx -y @smithery/cli install mcp-simple-pubmed --client claude\n```\n\n### Manual Installation\n```bash\npip install mcp-simple-pubmed\n```\n\n## Configuration\n\nThe server requires the following environment variables:\n\n- `PUBMED_EMAIL`: Your email address (required by NCBI)\n- `PUBMED_API_KEY`: Optional API key for higher rate limits \n\nThe standard rate limit is 3 requests / second. No rate limiting was implemented, as it is highly unlikely in the typical usage scenario that your AI would generate more traffic. If you need it, you can [register for an API key](https://www.ncbi.nlm.nih.gov/account/) which will give you 10 requests / second. Read about [this on NCBI pages](https://www.ncbi.nlm.nih.gov/books/NBK25497/#chapter2.Usage_Guidelines_and_Requiremen).\n\n## Usage with Claude Desktop\n\nAdd to your Claude Desktop configuration (`claude_desktop_config.json`):\n\n(Mac OS)\n\n```json\n{\n  \"mcpServers\": {\n    \"simple-pubmed\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_simple_pubmed\"],\n      \"env\": {\n        \"PUBMED_EMAIL\": \"your-email@example.com\",\n        \"PUBMED_API_KEY\": \"your-api-key\" \n      }\n    }\n  }\n}\n```\n\n(Windows)\n\n\n```json\n{\n  \"mcpServers\": {\n    \"simple-pubmed\": {\n      \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n      \"args\": [\n        \"-m\",\n        \"mcp_simple_pubmed\"\n      ],\n      \"env\": {\n        \"PUBMED_EMAIL\": \"your-email@example.com\",\n        \"PUBMED_API_KEY\": \"your-api-key\" \n      }\n    }\n  }\n}\n```\n\n### macOS SSL Certificate Fix\n\nIf you encounter SSL certificate verification errors on macOS (such as `[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain`), you need to install the proper certificate bundle:\n\n```bash\n/Applications/Python\\ 3.13/Install\\ Certificates.command\n```\nReplace `3.13` with your Python version number. This script comes with Python installations from python.org.\n\nYou can also run it from the Finder:\n\n![image](MacOs_certificates_solution.jpg)\n\nIf you perform this change while Claude Desktop is open you will need to quit it and start it again for it to take effect. \n\n## License\n\nMIT License\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "andybrandt--mcp-simple-timeserver": {
          "owner": "andybrandt",
          "name": "mcp-simple-timeserver",
          "url": "https://github.com/andybrandt/mcp-simple-timeserver",
          "imageUrl": "https://github.com/andybrandt.png",
          "description": "Provides local and UTC time information, allowing AI models to access current time and timezone details from the user's machine.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:31.345741",
          "collection_timestamp": "2025-10-02T15:08:37.044022",
          "stars": 24,
          "forks": 15,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-01T16:54:06Z",
          "updated_at": "2025-09-24T15:30:34Z",
          "open_issues": 2,
          "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/andybrandt-mcp-simple-timeserver-badge.png)](https://mseep.ai/app/andybrandt-mcp-simple-timeserver)\n\n# MCP Simple Timeserver\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/andybrandt/mcp-simple-timeserver)](https://archestra.ai/mcp-catalog/andybrandt__mcp-simple-timeserver)\n[![smithery badge](https://smithery.ai/badge/mcp-simple-timeserver)](https://smithery.ai/server/mcp-simple-timeserver)\n\n*One of the strange design decisions Anthropic made was depriving Claude of timestamps for messages sent by the user or current time in general. Poor Claude can't tell what time it is! `mcp-simple-timeserver` is a simple MCP server that fixes that.*\n\nThis server provides two tools:\n - `get_local_time` provides the current local time and timezone information from the user's machine. This way Claude can know what time it is at the user's location. He can also calculate how much time passed since his last interaction with the user should he want to do so. \n - `get_utc` provides current UTC time obtained from an [NTP time server](https://en.wikipedia.org/wiki/Network_Time_Protocol). \n\n## Installation\n\n### Installing via Smithery\n\nTo install Simple Timeserver for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-simple-timeserver):\n\n```bash\nnpx -y @smithery/cli install mcp-simple-timeserver --client claude\n```\n\n### Manual Installation\nFirst install the module using:\n\n```bash\npip install mcp-simple-timeserver\n\n```\n\nThen configure in MCP client - the [Claude desktop app](https://claude.ai/download).\n\nUnder Mac OS this will look like this:\n\n```json\n\"mcpServers\": {\n  \"simple-timeserver\": {\n    \"command\": \"python\",\n    \"args\": [\"-m\", \"mcp_simple_timeserver\"]\n  }\n}\n```\n\nUnder Windows you have to check the path to your Python executable using `where python` in the `cmd` (Windows command line). \n\nTypical configuration would look like this:\n\n```json\n\"mcpServers\": {\n  \"simple-timeserver\": {\n    \"command\": \"C:\\\\Users\\\\YOUR_USERNAME\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\",\n    \"args\": [\"-m\", \"mcp_simple_timeserver\"]\n  }\n}\n```\n\n## Web Server Variant\n\nThis project also includes a network-hostable version that can be deployed as a standalone web server. For instructions on how to run and deploy it, please see the [Web Server Deployment Guide](WEB_DEPLOYMENT.md).\n\nOr you can simply use my server by adding it under https://mcp.andybrandt.net/timeserver to Claude. (*It does not work with ChatGPT since it currently works only with MCP servers that implement `search()` and `fetch()` tools to serve data in response to LLM's querries*).\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "angheljf--nyt": {
          "owner": "angheljf",
          "name": "nyt",
          "url": "https://github.com/angheljf/nyt",
          "imageUrl": "https://github.com/angheljf.png",
          "description": "A TypeScript-based MCP server that searches New York Times articles from the last 30 days using a specified keyword. It integrates with the New York Times API to retrieve article information based on user queries.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:32.231807",
          "collection_timestamp": "2025-10-02T15:08:40.977592",
          "stars": 14,
          "forks": 7,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2024-11-30T02:36:04Z",
          "updated_at": "2025-08-02T03:11:50Z",
          "open_issues": 2,
          "readme_content": "# NYTimes Article Search MCP Server\n\n[![smithery badge](https://smithery.ai/badge/nyt)](https://smithery.ai/server/nyt)\n\nThis is a TypeScript-based MCP server that allows searching for New York Times articles from the last 30 days based on a keyword. It demonstrates core MCP concepts by providing:\n\n- Tools for searching articles\n- Integration with the New York Times API\n\n![NYTimes Article Search](img/example.png)\n\n<a href=\"https://glama.ai/mcp/servers/ylg4ai4vin\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ylg4ai4vin/badge\" alt=\"NYTimes Article Search Server MCP server\" /></a>\n\n## Features\n\n### Tools\n- `search_articles` - Search NYTimes articles from the last 30 days based on a keyword\n  - Takes `keyword` as a required parameter\n  - Returns a list of articles with title, abstract, URL, published date, and author\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Installation\n\n### Installing via Smithery\n\nTo install NYTimes Article Search for Claude Desktop automatically via [Smithery](https://smithery.ai/server/nyt):\n\n```bash\nnpx -y @smithery/cli install nyt --client claude\n```\n\n### Manual Installation\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"nyt\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/your/build/index.js\"],\n      \"env\": {\n        \"NYTIMES_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n## Environment Variables\n\nCreate a `.env` file in the root of your project and add your New York Times API key:\n\n```\nNYTIMES_API_KEY=your_api_key_here\n```\n\n## Running the Server\n\nAfter building the project, you can run the server with:\n\n```bash\nnode build/index.js\n```\n\nThe server will start and listen for MCP requests over stdio.\n\n## License\n\nThis project is licensed under the MIT License.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/nyt",
          "npm_downloads": 407,
          "npm_package_name": "nyt",
          "npm_success": true,
          "npm_error": null
        },
        "anewkim--docusaurus": {
          "owner": "anewkim",
          "name": "docusaurus",
          "url": "https://github.com/anewkim/docusaurus",
          "imageUrl": "https://github.com/anewkim.png",
          "description": "Generate and deploy modern static websites efficiently, with features for live reloading during development and seamless deployment to GitHub Pages or other static hosting services. Provides an extensible framework for website management and content generation.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:33.075059",
          "collection_timestamp": "2025-10-02T15:08:45.170489",
          "stars": 0,
          "forks": 0,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2023-02-23T08:59:00Z",
          "updated_at": "2023-02-23T08:59:06Z",
          "open_issues": 0,
          "readme_content": "# Website\n\nThis website is built using [Docusaurus 2](https://docusaurus.io/), a modern static website generator.\n\n### Installation\n\n```\n$ yarn\n```\n\n### Local Development\n\n```\n$ yarn start\n```\n\nThis command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.\n\n### Build\n\n```\n$ yarn build\n```\n\nThis command generates static content into the `build` directory and can be served using any static contents hosting service.\n\n### Deployment\n\nUsing SSH:\n\n```\n$ USE_SSH=true yarn deploy\n```\n\nNot using SSH:\n\n```\n$ GIT_USER=<Your GitHub username> yarn deploy\n```\n\nIf you are using GitHub pages for hosting, this command is a convenient way to build the website and push to the `gh-pages` branch.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/docusaurus",
          "npm_downloads": 505382,
          "npm_package_name": "docusaurus",
          "npm_success": true,
          "npm_error": null
        },
        "angrysky56--mcp-windows-website-downloader": {
          "owner": "angrysky56",
          "name": "mcp-windows-website-downloader",
          "url": "https://github.com/angrysky56/mcp-windows-website-downloader",
          "imageUrl": "https://github.com/angrysky56.png",
          "description": "Downloads websites and their associated assets while maintaining a navigable structure. Prepares content for retrieval-augmented generation (RAG) indexing, creating organized folders and indexes for each site downloaded.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:34.162136",
          "collection_timestamp": "2025-10-02T15:08:52.903048",
          "stars": 5,
          "forks": 8,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-01-17T04:24:47Z",
          "updated_at": "2025-07-04T10:58:23Z",
          "open_issues": 1,
          "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/angrysky56-mcp-windows-website-downloader-badge.png)](https://mseep.ai/app/angrysky56-mcp-windows-website-downloader)\n\n# MCP Website Downloader\n\nSimple MCP server for downloading documentation websites and preparing them for RAG indexing.\n\n## Features\n\n- Downloads complete documentation sites, well big chunks anyway.\n- Maintains link structure and navigation, not really. lol\n- Downloads and organizes assets (CSS, JS, images), but isn't really AI friendly and it all probably needs some kind of parsing or vectorizing into a db or something.\n- Creates clean index for RAG systems, currently seems to make an index in each folder, not even looked at it.\n- Simple single-purpose MCP interface, yup.\n\n## Installation\n\nFork and download, cd to the repository.\n```bash\nuv venv\n./venv/Scripts/activate\npip install -e .\n```\n\nPut this in your claude_desktop_config.json with your own paths:\n\n```json\n   \"mcp-windows-website-downloader\": {\n     \"command\": \"uv\",\n     \"args\": [\n       \"--directory\",\n       \"F:/GithubRepos/mcp-windows-website-downloader\",\n       \"run\",\n       \"mcp-windows-website-downloader\",\n       \"--library\",\n       \"F:/GithubRepos/mcp-windows-website-downloader/website_library\"\n     ]\n   },\n```\n\n![alt text]({52E8102D-678C-44FE-9B0E-491483808EB6}.png)\n\n## Other Usage you don't need to worry about and may be hallucinatory lol:\n\n1. Start the server:\n```bash\npython -m mcp_windows_website_downloader.server --library docs_library\n```\n\n2. Use through Claude Desktop or other MCP clients:\n```python\nresult = await server.call_tool(\"download\", {\n    \"url\": \"https://docs.example.com\"\n})\n```\n\n## Output Structure\n\n```\ndocs_library/\n  domain_name/\n    index.html\n    about.html\n    docs/\n      getting-started.html\n      ...\n    assets/\n      css/\n      js/\n      images/\n      fonts/\n    rag_index.json\n```\n\n## Development\n\nThe server follows standard MCP architecture:\n\n```\nsrc/\n  mcp_windows_website_downloader/\n    __init__.py\n    server.py    # MCP server implementation\n    core.py      # Core downloader functionality\n    utils.py     # Helper utilities\n```\n\n### Components\n\n- `server.py`: Main MCP server implementation that handles tool registration and requests\n- `core.py`: Core website downloading functionality with proper asset handling\n- `utils.py`: Helper utilities for file handling and URL processing\n\n### Design Principles\n\n1. Single Responsibility\n   - Each module has one clear purpose\n   - Server handles MCP interface\n   - Core handles downloading\n   - Utils handles common operations\n\n2. Clean Structure\n   - Maintains original site structure\n   - Organizes assets by type\n   - Creates clear index for RAG systems\n\n3. Robust Operation\n   - Proper error handling\n   - Reasonable depth limits\n   - Asset download verification\n   - Clean URL/path processing\n\n### RAG Index\n\nThe `rag_index.json` file contains:\n```json\n{\n  \"url\": \"https://docs.example.com\",\n  \"domain\": \"docs.example.com\", \n  \"pages\": 42,\n  \"path\": \"/path/to/site\"\n}\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\n## License\n\nMIT License - See LICENSE file\n\n## Error Handling\n\nThe server handles common issues:\n\n- Invalid URLs\n- Network errors\n- Asset download failures  \n- Malformed HTML\n- Deep recursion\n- File system errors\n\nError responses follow the format:\n```json\n{\n  \"status\": \"error\",\n  \"error\": \"Detailed error message\"\n}\n```\n\nSuccess responses:\n```json\n{\n  \"status\": \"success\",\n  \"path\": \"/path/to/downloaded/site\",\n  \"pages\": 42\n}\n```",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "anpigon--mcp-server-obsidian-omnisearch": {
          "owner": "anpigon",
          "name": "mcp-server-obsidian-omnisearch",
          "url": "https://github.com/anpigon/mcp-server-obsidian-omnisearch",
          "imageUrl": "https://github.com/anpigon.png",
          "description": "Programmatically search through notes stored in an Obsidian vault using a REST API, returning absolute paths to matching notes for easy integration with other services. It enhances the note-taking experience by leveraging advanced search capabilities.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-02T16:06:35.133968",
          "collection_timestamp": "2025-10-02T15:09:00.625814",
          "stars": 19,
          "forks": 4,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-02T12:47:23Z",
          "updated_at": "2025-08-18T11:53:27Z",
          "open_issues": 4,
          "readme_content": "# MCP Server Obsidian Omnisearch\n\n[![smithery badge](https://smithery.ai/badge/@anpigon/mcp-server-obsidian-omnisearch)](https://smithery.ai/server/@anpigon/mcp-server-obsidian-omnisearch)\nA FastMCP-based server that provides Obsidian vault search functionality through a REST API interface.\n\n## Overview\n\nThis project implements a search service that allows you to search through Obsidian vault notes programmatically. It uses FastMCP to expose the search functionality as a tool that can be integrated with other services.\n\n## Features\n\n- Search through Obsidian vault notes\n- REST API integration\n- Returns absolute paths to matching notes\n- Easy integration with FastMCP tools\n\n## Prerequisites\n\n- Python 3.x\n- Obsidian with Omnisearch plugin installed and running\n- FastMCP library\n- Active Obsidian vault\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Server Obsidian Omnisearch for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@anpigon/mcp-server-obsidian-omnisearch):\n\n```bash\nnpx -y @smithery/cli install @anpigon/mcp-server-obsidian-omnisearch --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n```bash\ngit clone https://github.com/anpigon/mcp-server-obsidian-omnisearch.git\ncd mcp-server-obsidian-omnisearch\n```\n\n2. Install dependencies:\n```bash\nuv install\n```\n\n## Configuration\n\nThe Obsidian vault path is now provided as a command line argument when running the server:\n\n```bash\npython server.py /path/to/your/obsidian/vault\n```\n\n## Usage\n\n### Obsidian Omnisearch API\n\nYou need the Obsidian Omnisearch community plugin running: https://publish.obsidian.md/omnisearch/Inject+Omnisearch+results+into+your+search+engine\n\n### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"obsidian-omnisearch\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"<dir_to>/mcp-server-obsidian-omnisearch\",\n        \"run\",\n        \"mcp-server-obsidian-omnisearch\",\n        \"/path/to/your/obsidian/vault\"\n      ]\n    }\n  }\n}\n```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"obsidian-omnisearch\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-server-obsidian-omnisearch\",\n        \"/path/to/your/obsidian/vault\"\n      ]\n    }\n  }\n}\n```\n</details>\n\n## API Reference\n\n### Search Notes\n- Function: `obsidian_notes_search(query: str)`\n- Description: Searches Obsidian notes and returns absolute paths to matching notes\n- Parameters:\n  - `query`: Search query string\n- Returns: List of absolute paths to matching notes\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /path/to/mcp-server-obsidian-omnisearch run mcp-server-obsidian-omnisearch\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\nYou can also watch the server logs with this command:\n\n```bash\ntail -n 20 -f ~/Library/Logs/Claude/mcp-server-mcp-server-obsidian-omnisearch.log\n```\n\n## Dependencies\n\n- FastMCP\n- requests\n- urllib\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AnuragRai017--python-docs-server-MCP-Server": {
          "owner": "AnuragRai017",
          "name": "python-docs-server-MCP-Server",
          "url": "https://github.com/AnuragRai017/python-docs-server-MCP-Server",
          "imageUrl": "https://github.com/AnuragRai017.png",
          "description": "Fetches Python documentation using the Brave Search API, providing relevant links based on search queries for an enhanced coding experience.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:44.862570",
          "collection_timestamp": "2025-10-02T15:09:08.129300",
          "stars": 0,
          "forks": 4,
          "license": "Apache License 2.0",
          "language": "JavaScript",
          "created_at": "2025-01-14T07:14:10Z",
          "updated_at": "2025-05-15T08:11:10Z",
          "open_issues": 2,
          "readme_content": "---\n\n# python-docs-server MCP Server\n\nA Model Context Protocol server\n\nThis is a TypeScript-based MCP server that provides tools to fetch Python documentation using the Brave Search API.\n\n## Features\n\n### Tools\n- `get_python_docs` - Get Python documentation for a given query\n  - Takes a search query as a required parameter\n  - Uses the Brave Search API to fetch relevant documentation links\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"python-docs-server\": {\n      \"command\": \"/path/to/python-docs-server/build/index.js\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Additional Resources\n\n- [Glama AI Server](https://glama.ai/mcp/servers/@AnuragRai017/python-docs-server-MCP-Server)  \n- [Smithery AI Server](https://smithery.ai/server/@AnuragRai017/python-docs-server-MCP-Server)\n\n---\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "apappascs--tavily-search-mcp-server": {
          "owner": "apappascs",
          "name": "tavily-search-mcp-server",
          "url": "https://github.com/apappascs/tavily-search-mcp-server",
          "imageUrl": "https://github.com/apappascs.png",
          "description": "Integrates the Tavily Search API to perform optimized web searches tailored for LLMs, allowing for control over search parameters such as depth, topic, and time range. It extracts relevant content from results, focusing on quality and size.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:45.859076",
          "collection_timestamp": "2025-10-02T15:09:15.638670",
          "stars": 2,
          "forks": 6,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-01-21T12:39:19Z",
          "updated_at": "2025-05-05T04:23:46Z",
          "open_issues": 0,
          "readme_content": "# Tavily Search MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@apappascs/tavily-search-mcp-server)](https://smithery.ai/server/@apappascs/tavily-search-mcp-server)\nAn MCP server implementation that integrates the Tavily Search API, providing optimized search capabilities for LLMs.\n\n<a href=\"https://glama.ai/mcp/servers/0kmdibf9t1\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/0kmdibf9t1/badge\" alt=\"tavily-search-mcp-server MCP server\" /></a>\n\n## Features\n\n-   **Web Search:** Perform web searches optimized for LLMs, with control over search depth, topic, and time range.\n-   **Content Extraction:** Extracts the most relevant content from search results, optimizing for quality and size.\n-   **Optional Features:** Include images, image descriptions, short LLM-generated answers, and raw HTML content.\n-   **Domain Filtering:** Include or exclude specific domains in search results.\n\n## Tools\n\n-   **tavily_search**\n    -   Execute web searches using the Tavily Search API.\n    -   Inputs:\n        -   `query` (string, required): The search query.\n        -   `search_depth` (string, optional): \"basic\" or \"advanced\" (default: \"basic\").\n        -   `topic` (string, optional): \"general\" or \"news\" (default: \"general\").\n        -   `days` (number, optional): Number of days back for news search (default: 3).\n        -   `time_range` (string, optional): Time range filter (\"day\", \"week\", \"month\", \"year\" or \"d\", \"w\", \"m\", \"y\").\n        -   `max_results` (number, optional): Maximum number of results (default: 5).\n        -   `include_images` (boolean, optional): Include related images (default: false).\n        -   `include_image_descriptions` (boolean, optional): Include descriptions for images (default: false).\n        -   `include_answer` (boolean, optional): Include a short LLM-generated answer (default: false).\n        -   `include_raw_content` (boolean, optional): Include raw HTML content (default: false).\n        -   `include_domains` (string[], optional): Domains to include.\n        -   `exclude_domains` (string[], optional): Domains to exclude.\n\n## Setup Guide üöÄ\n\n### 1. Prerequisites\n\n-   [Claude Desktop](https://claude.ai/desktop) installed on your computer.\n-   A Tavily API key:\n    a. Sign up for a [Tavily API account](https://tavily.com/).\n    b. Choose a plan (Free tier available).\n    c. Generate your API key from the Tavily dashboard.\n\n### 2. Installation\n\n1. Clone this repository somewhere on your computer:\n\n    ```bash\n    git clone https://github.com/apappascs/tavily-search-mcp-server.git \n    ```\n\n2. Install dependencies & build the project:\n\n    ```bash\n    cd tavily-search-mcp-server\n    ```\n    ```bash\n    npm install\n    ```\n    ```bash\n    npm run build\n    ```\n\n### 3. Integration with Claude Desktop\n\n1. Open your Claude Desktop configuration file:\n\n    ```\n    # On Mac:\n    ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n\n    # On Windows:\n    %APPDATA%\\Claude\\claude_desktop_config.json\n    ```\n\n2. Add **one** of the following to the `mcpServers` object in your config, depending on whether you want to run the server using `npm` or `docker`:\n\n   **Option A: Using NPM (stdio transport)**\n\n    ```json\n    {\n        \"mcpServers\": {\n            \"tavily-search-server\": {\n                \"command\": \"node\",\n                \"args\": [\n                    \"/Users/<username>/<FULL_PATH...>/tavily-search-mcp-server/dist/index.js\"\n                ],\n                \"env\": {\n                    \"TAVILY_API_KEY\": \"your_api_key_here\"\n                }\n            }\n        }\n    }\n    ```\n\n   **Option B: Using NPM (SSE transport)**\n\n    ```json\n    {\n        \"mcpServers\": {\n            \"tavily-search-server\": {\n                \"command\": \"node\",\n                \"args\": [\n                    \"/Users/<username>/<FULL_PATH...>/tavily-search-mcp-server/dist/sse.js\"\n                ],\n                \"env\": {\n                    \"TAVILY_API_KEY\": \"your_api_key_here\"\n                },\n                \"port\": 3001\n            }\n        }\n    }\n    ```\n\n   **Option C: Using Docker**\n\n    ```json\n    {\n        \"mcpServers\": {\n            \"tavily-search-server\": {\n                \"command\": \"docker\",\n                \"args\": [\n                    \"run\",\n                    \"-i\",\n                    \"--rm\",\n                    \"-e\",\n                    \"TAVILY_API_KEY\",\n                    \"-v\",\n                    \"/Users/<username>/<FULL_PATH...>/tavily-search-mcp-server:/app\",\n                    \"tavily-search-mcp-server\"\n                ],\n                \"env\": {\n                    \"TAVILY_API_KEY\": \"your_api_key_here\"\n                }\n            }\n        }\n    }\n    ```\n\n3. Important Steps:\n\n    -   Replace `/Users/<username>/<FULL_PATH...>/tavily-search-mcp-server` with the actual full path to where you cloned the repository.\n    -   Add your Tavily API key in the `env` section. **It's always better to have secrets like API keys as environment variables.**\n    -   Make sure to use forward slashes (`/`) in the path, even on Windows.\n    -   If you are using docker make sure you build the image first using `docker build -t tavily-search-mcp-server:latest .`\n\n4. Restart Claude Desktop for the changes to take effect.\n\n### Installing via Smithery\n\nTo install Tavily Search for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@apappascs/tavily-search-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @apappascs/tavily-search-mcp-server --client claude\n```\n\n## Environment Setup (for npm)\n\n1. Copy `.env.example` to `.env`:\n\n    ```bash\n    cp .env.example .env\n    ```\n\n2. Update the `.env` file with your actual Tavily API key:\n\n    ```env\n    TAVILY_API_KEY=your_api_key_here\n    ```\n\n   Note: Never commit your actual API key to version control. The `.env` file is ignored by git for security reasons.\n\n## Running with NPM\nStart the server using Node.js:\n```bash\nnode dist/index.js\n```\n\nFor sse transport:\n```bash\nnode dist/sse.js\n```\n\n## Running with Docker\n\n1. Build the Docker image (if you haven't already):\n\n    ```bash\n    docker build -t tavily-search-mcp-server:latest .\n    ```\n\n2. Run the Docker container with:\n\n   **For stdio transport:**\n\n    ```bash\n    docker run -it --rm -e TAVILY_API_KEY=\"your_api_key_here\" tavily-search-mcp-server:latest\n    ```\n\n   **For sse transport:**\n\n    ```bash\n    docker run -it --rm -p 3001:3001 -e TAVILY_API_KEY=\"your_api_key_here\" -e TRANSPORT=\"sse\" tavily-search-mcp-server:latest\n    ```\n   **You can also leverage your shell's environment variables directly, which is a more secure practice:**\n   ```bash\n    docker run -it --rm -p 3001:3001 -e TAVILY_API_KEY=$TAVILY_API_KEY -e TRANSPORT=\"sse\" tavily-search-mcp-server:latest\n    ```\n   **Note:** The second command demonstrates the recommended approach of using `-e TAVILY_API_KEY=$TAVILY_API_KEY` to pass the value of your `TAVILY_API_KEY` environment variable into the Docker container. This keeps your API key out of your command history, and it is generally preferred over hardcoding secrets in commands.\n\n\n3. **Using docker compose**\n\n   Run:\n\n     ```bash\n     docker compose up -d\n     ```\n\n   To stop the server:\n\n    ```bash\n    docker compose down\n    ```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "appleinmusic--baidu-search-mcp": {
          "owner": "appleinmusic",
          "name": "baidu-search-mcp",
          "url": "https://github.com/appleinmusic/baidu-search-mcp",
          "imageUrl": "https://github.com/appleinmusic.png",
          "description": "Enables AI assistants to perform web searches using the Baidu Wenxin API, supporting multiple models and providing search results along with reference sources. Features include deep search options and recency filtering for improved search relevance.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:46.856156",
          "collection_timestamp": "2025-10-02T15:09:36.028736",
          "stars": 7,
          "forks": 0,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2025-03-23T03:59:06Z",
          "updated_at": "2025-09-08T07:51:05Z",
          "open_issues": 1,
          "readme_content": "# Baidu Search MCP Server\n\nËøôÊòØ‰∏Ä‰∏™Áî®‰∫é Model Context Protocol (MCP) ÁöÑÁôæÂ∫¶ÊêúÁ¥¢ÊúçÂä°Âô®ÂÆûÁé∞ÔºåÂÆÉÂÖÅËÆ∏AIÂä©Êâã‰ΩøÁî®ÁôæÂ∫¶ÊñáÂøÉAPIËøõË°åÊô∫ËÉΩÊêúÁ¥¢„ÄÇ\n\n## ÂäüËÉΩÁâπÊÄß\n\n- ÊîØÊåÅ‰ΩøÁî®ÁôæÂ∫¶ÊñáÂøÉAPIËøõË°åÊô∫ËÉΩÊêúÁ¥¢\n- ÊîØÊåÅÂ§öÁßçÊ®°ÂûãÈÄâÊã©Ôºàernie-3.5-8k, ernie-4.0-8k, deepseek-r1, deepseek-v3Ôºâ\n- Êèê‰æõÊêúÁ¥¢ÁªìÊûúÂíåÂèÇËÄÉÊù•Ê∫ê\n- ÊîØÊåÅÊ∑±Â∫¶ÊêúÁ¥¢ÂíåÊó∂ÊïàÊÄßËøáÊª§\n\n## ÂÆâË£Ö\n\n```bash\nnpm install @modelcontextprotocol/sdk axios\n```\n\n## ÈÖçÁΩÆ\n\n1. È¶ñÂÖàÈúÄË¶ÅËé∑ÂèñÁôæÂ∫¶ÊñáÂøÉAPIÂØÜÈí•Ôºö\n   - ËÆøÈóÆ [ÁôæÂ∫¶Êô∫ËÉΩ‰∫ë](https://cloud.baidu.com/)\n   - ÂàõÂª∫Â∫îÁî®Âπ∂Ëé∑ÂèñAPIÂØÜÈí•\n\n2. ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö\n\n```bash\nexport BAIDU_API_KEY=your_api_key_here\n```\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\n### ‰Ωú‰∏∫Áã¨Á´ãÊúçÂä°Âô®ËøêË°å\n\n```bash\nnode build/index.js\n```\n\n### Âú®MCPÈÖçÁΩÆ‰∏≠‰ΩøÁî®\n\nÂú®‰Ω†ÁöÑMCPËÆæÁΩÆÊñá‰ª∂‰∏≠Ê∑ªÂä†‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"baidu-search\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/baidu-search-mcp/build/index.js\"],\n      \"env\": {\n        \"BAIDU_API_KEY\": \"your_api_key_here\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## API\n\n### baidu_search\n\nÊêúÁ¥¢Â∑•ÂÖ∑ÊîØÊåÅ‰ª•‰∏ãÂèÇÊï∞Ôºö\n\n- `query` (ÂøÖÈúÄ): ÊêúÁ¥¢Êü•ËØ¢ÊñáÊú¨\n- `model`: ‰ΩøÁî®ÁöÑÊ®°ÂûãÂêçÁß∞\n  - ÂèØÈÄâÂÄº: \"ernie-3.5-8k\", \"ernie-4.0-8k\", \"deepseek-r1\", \"deepseek-v3\"\n  - ÈªòËÆ§ÂÄº: \"ernie-3.5-8k\"\n- `search_mode`: ÊêúÁ¥¢Ê®°Âºè\n  - ÂèØÈÄâÂÄº: \"auto\", \"required\", \"disabled\"\n  - ÈªòËÆ§ÂÄº: \"auto\"\n- `enable_deep_search`: ÊòØÂê¶ÂºÄÂêØÊ∑±Â∫¶ÊêúÁ¥¢ÔºàÈªòËÆ§ÔºöfalseÔºâ\n- `search_recency_filter`: ÊêúÁ¥¢ÁªìÊûúÁöÑÊó∂ÊïàÊÄßËåÉÂõ¥\n  - ÂèØÈÄâÂÄº: \"week\", \"month\", \"semiyear\", \"year\"\n\n## ÂºÄÂèë\n\n1. ÂÖãÈöÜ‰ªìÂ∫ì\n2. ÂÆâË£Ö‰æùËµñÔºö\n```bash\nnpm install\n```\n3. ÁºñËØëTypeScriptÔºö\n```bash\nnpm run build\n```\n\n## ËÆ∏ÂèØËØÅ\n\nMIT License\n\n## Ë¥°ÁåÆ\n\nÊ¨¢ËøéÊèê‰∫§ Issues Âíå Pull RequestsÔºÅ\n\n## ÂÖçË¥£Â£∞Êòé\n\nÊú¨È°πÁõÆ‰∏çÂØπAPIÂØÜÈí•ÁöÑ‰ΩøÁî®ÊâøÊãÖË¥£‰ªªÔºåËØ∑Á°Æ‰øùÈÅµÂÆàÁôæÂ∫¶ÊñáÂøÉAPIÁöÑ‰ΩøÁî®Êù°Ê¨æÂíåÊîøÁ≠ñ„ÄÇ\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/baidu-search-mcp-server",
          "npm_downloads": 0,
          "npm_package_name": "baidu-search-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "apify--mcp-server-rag-web-browser": {
          "owner": "apify",
          "name": "mcp-server-rag-web-browser",
          "url": "https://github.com/apify/mcp-server-rag-web-browser",
          "imageUrl": "https://github.com/apify.png",
          "description": "Connects AI models to perform web searches and scrape content, returning information in Markdown format. It facilitates interaction between AI agents and web pages, optimizing data retrieval for large language models.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:47.943260",
          "collection_timestamp": "2025-10-02T15:09:41.155950",
          "stars": 186,
          "forks": 23,
          "license": "Apache License 2.0",
          "language": "JavaScript",
          "created_at": "2024-12-06T14:57:51Z",
          "updated_at": "2025-09-29T13:18:32Z",
          "open_issues": 0,
          "readme_content": "# MCP Server for the RAG Web Browser Actor üåê\n\nImplementation of an MCP server for the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser).\nThis Actor serves as a web browser for large language models (LLMs) and RAG pipelines, similar to a web search in ChatGPT.\n\n> **This MCP server is deprecated in favor of [mcp.apify.com](https://mcp.apify.com)**\n>\n> For the same functionality and much more, please use one of these alternatives:\n\n## üöÄ Recommended: use mcp.apify.com\n\nThe easiest way to get the same web browsing capabilities is to use **[mcp.apify.com](https://mcp.apify.com)** with default settings.\n\n**Benefits:**\n- ‚úÖ No local setup required\n- ‚úÖ Always up-to-date\n- ‚úÖ Access to 6,000+ Apify Actors (including RAG Web Browser)\n- ‚úÖ OAuth support for easy connection\n- ‚úÖ Dynamic tool discovery\n\n**Quick Setup:**\n1. Go to https://mcp.apify.com\n2. Authorize the client (Claude, VS Code, etc.)\n3. Copy the generated MCP server configuration (or use OAuth flow if supported)\n4. Start using browsing & other tools immediately\n\n## üåê Alternative: direct RAG Web Browser integration\n\nYou can also call the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) directly via its HTTP/SSE interface.\n\n**Benefits:**\n- ‚úÖ Direct integration without mcp.apify.com\n- ‚úÖ Real-time streaming via Server-Sent Events\n- ‚úÖ Full control over the integration\n- ‚úÖ No additional dependencies\n\n**Docs:** [Actor Documentation](https://apify.com/apify/rag-web-browser#anthropic-model-context-protocol-mcp-server)\n\n---\n\n## üéØ What does this MCP server do?\n\nThis server is specifically designed to provide fast responses to AI agents and LLMs, allowing them to interact with the web and extract information from web pages.\nIt runs locally and communicates with the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) in [**Standby mode**](https://docs.apify.com/platform/actors/running/standby),\nsending search queries and receiving extracted web content in response.\n\n- **Web Search**: Query Google Search, scrape top N URLs, and return cleaned content as Markdown\n- **Single URL Fetching**: Fetch a specific URL and return its content as Markdown\n- **Local MCP Integration**: Standard input/output (stdio) communication with AI clients\n\n## üß± Components\n\n### Tools\n\n- name: `search`\n  description: Query Google Search OR fetch a direct URL and return cleaned page contents.\n  arguments:\n  - `query` (string, required): Search keywords or a full URL. Advanced Google operators supported.\n  - `maxResults` (number, optional, default: 1): Max organic results to fetch (ignored when `query` is a URL).\n  - `scrapingTool` (string, optional, default: `raw-http`): One of `browser-playwright` | `raw-http`.\n    - `raw-http`: Fast (no JS execution) ‚Äì good for static pages.\n    - `browser-playwright`: Handles JS-heavy sites ‚Äì slower, more robust.\n  - `outputFormats` (array of strings, optional, default: [`markdown`]): One or more of `text`, `markdown`, `html`.\n  - `requestTimeoutSecs` (number, optional, default: 40, min 1 max 300): Total server-side AND client wait budget. A local abort is enforced.\n\n\n## üîÑ Migration Guide\n\n### From Local MCP Server to mcp.apify.com\n\n**Before (Deprecated local server):**\n```json\n{\n  \"mcpServers\": {\n    \"rag-web-browser\": {\n      \"command\": \"npx\",\n      \"args\": [\"@apify/mcp-server-rag-web-browser\"],\n      \"env\": {\n        \"APIFY_TOKEN\": \"your-apify-api-token\"\n      }\n    }\n  }\n}\n```\n\n**After (Recommended Apify server):**\n```json\n{\n  \"mcpServers\": {\n    \"apify\": {\n      \"command\": \"npx\",\n      \"args\": [\"@apify/actors-mcp-server\"],\n      \"env\": {\n        \"APIFY_TOKEN\": \"your-apify-api-token\"\n      }\n    }\n  }\n}\n```\nOr use the hosted endpoint: `https://mcp.apify.com` (when your client supports HTTP transport / remote MCP).\n\n### MCP clients\n- Claude Desktop: https://claude.ai/download\n- Visual Studio Code\n- Apify Tester MCP Client: https://apify.com/jiri.spilka/tester-mcp-client\n\n## üõ†Ô∏è Development\n\n### Prerequisites\n- Node.js (v18 or higher)\n- Apify API Token (`APIFY_TOKEN`)\n\nClone & install:\n```bash\ngit clone https://github.com/apify/mcp-server-rag-web-browser.git\ncd mcp-server-rag-web-browser\nnpm install\n```\n\n### Build\n```bash\nnpm install\nnpm run build\n```\n\n### Debugging\n\nSince MCP servers operate over standard input/output (stdio), debugging can be challenging.\nFor the best debugging experience, use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nexport APIFY_TOKEN=your-apify-api-token\nnpx @modelcontextprotocol/inspector node dist/index.js\n```\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\n# üìñ Learn more\n\n- [Model Context Protocol](https://modelcontextprotocol.org/)\n- [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser)\n- [What are AI Agents?](https://blog.apify.com/what-are-ai-agents/)\n- [What is MCP and why does it matter?](https://blog.apify.com/what-is-model-context-protocol/)\n- [How to use MCP with Apify Actors](https://blog.apify.com/how-to-use-mcp/)\n- [Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\n- [Webinar: Building and Monetizing MCP Servers on Apify](https://www.youtube.com/watch?v=w3AH3jIrXXo)\n- [How to build and monetize an AI agent on Apify](https://blog.apify.com/how-to-build-an-ai-agent/)\n- [Build and deploy MCP servers in minutes with a TypeScript template](https://blog.apify.com/build-and-deploy-mcp-servers-typescript/)\n\n*This repository is maintained for archival purposes only. Please use the recommended alternatives above for active development.*\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-server-rag-web-browser",
          "npm_downloads": 160,
          "npm_package_name": "mcp-server-rag-web-browser",
          "npm_success": true,
          "npm_error": null
        },
        "apridachin--kagi-search-mcp": {
          "owner": "apridachin",
          "name": "kagi-search-mcp",
          "url": "https://github.com/apridachin/kagi-search-mcp",
          "imageUrl": "https://github.com/apridachin.png",
          "description": "Search the web using the Kagi API to retrieve answers and enrich the model context with web content and the latest news.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:48.897537",
          "collection_timestamp": "2025-10-02T15:09:48.844828",
          "stars": 2,
          "forks": 2,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2024-12-27T11:40:33Z",
          "updated_at": "2025-06-16T17:44:22Z",
          "open_issues": 0,
          "readme_content": "# Kagi MCP server\n\n[![smithery badge](https://smithery.ai/badge/kagi-mcp)](https://smithery.ai/client/kagi-mcp)\nMCP server that allows to search web using Kagi API\n\n<a href=\"https://glama.ai/mcp/servers/rl6yu8g58l\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/rl6yu8g58l/badge\" alt=\"Kagi Server MCP server\" /></a>\n\n## Components\n\n### Resources\n\nThe server implements calls of [API methods](https://help.kagi.com/kagi/api/overview.html):\n- fastgpt\n- enrich/web\n- enrich/news\n\n### Prompts\n\nThe server provides doesn't provide any prompts:\n\n### Tools\n\nThe server implements several tools:\n- ask_fastgpt to search web and find an answer\n- enrich_web to enrich model context with web content\n- enrich_news to enrich model context with latest news\n\n## Configuration\n\n## Quickstart\n\n### Install\n\n### Installing via Smithery\n\nTo install the Kagi MCP server for Claude Desktop automatically via [Smithery](https://smithery.ai/client/kagi-mcp):\n\n```bash\nnpx -y @smithery/cli install kagi-mcp --client claude\n```\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```\n  \"mcpServers\": {\n    \"kagi-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"path_to_project\",\n        \"run\",\n        \"kagi-mcp\"\n      ],\n      \"env\": {\n        \"KAGI_API_KEY\": \"YOUR API KEY\"\n      }\n    }\n  }\n  ```\n</details>\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory path_to_project run kagi-mcp\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "arben-adm--brave-mcp-search": {
          "owner": "arben-adm",
          "name": "brave-mcp-search",
          "url": "https://github.com/arben-adm/brave-mcp-search",
          "imageUrl": "https://github.com/arben-adm.png",
          "description": "Integrates with Brave Search to perform web and local searches, facilitating information retrieval through AI models.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:49.687658",
          "collection_timestamp": "2025-10-02T15:09:56.510488",
          "stars": 13,
          "forks": 10,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-01-26T20:25:56Z",
          "updated_at": "2025-09-10T10:32:39Z",
          "open_issues": 0,
          "readme_content": "# Brave Search MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@arben-adm/brave-mcp-search)](https://smithery.ai/server/@arben-adm/brave-mcp-search)\n\nThis project implements a Model Context Protocol (MCP) server for Brave Search, allowing integration with AI assistants like Claude.\n\n## Prerequisites\n\n- Python 3.11+\n- [uv](https://github.com/astral-sh/uv) - A fast Python package installer and resolver\n\n## Installation\n\n### Installing via Smithery\n\nTo install Brave Search MCP server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@arben-adm/brave-mcp-search):\n\n```bash\nnpx -y @smithery/cli install @arben-adm/brave-mcp-search --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n   ```\n   git clone https://github.com/your-username/brave-search-mcp.git\n   cd brave-search-mcp\n   ```\n\n2. Create a virtual environment and install dependencies using uv:\n   ```\n   uv venv\n   source .venv/bin/activate  # On Windows, use: .venv\\Scripts\\activate\n   uv pip install -r requirements.txt\n   ```\n\n3. Set up your Brave Search API key:\n   ```\n   export BRAVE_API_KEY=your_api_key_here\n   ```\n   On Windows, use: `set BRAVE_API_KEY=your_api_key_here`\n\n## Usage\n\n1. Configure your MCP settings file (e.g., `claude_desktop_config.json`) to include the Brave Search MCP server:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"brave-search\": {\n         \"command\": \"uv\",\n         \"args\": [\n           \"--directory\",\n           \"path-to\\\\mcp-python\\\\brave-mcp-search\\\\src\",\n           \"run\",\n           \"server.py\"\n         ],\n         \"env\": {\n           \"BRAVE_API_KEY\": \"YOUR_BRAVE_API_KEY_HERE\"\n         }\n       }\n     }\n   }\n   ```\n\n   Replace `YOUR_BRAVE_API_KEY_HERE` with your actual Brave API key.\n\n2. Start the Brave Search MCP server by running your MCP-compatible AI assistant with the updated configuration.\n\n3. The server will now be running and ready to accept requests from MCP clients.\n\n4. You can now use the Brave Search functionality in your MCP-compatible AI assistant (like Claude) by invoking the available tools.\n\n## Available Tools\n\nThe server provides two main tools:\n\n1. `brave_web_search`: Performs a web search using the Brave Search API.\n2. `brave_local_search`: Searches for local businesses and places.\n\nRefer to the tool docstrings in `src/server.py` for detailed usage information.\n\n## Development\n\nTo make changes to the project:\n\n1. Modify the code in the `src` directory as needed.\n2. Update the `requirements.txt` file if you add or remove dependencies:\n   ```\n   uv pip freeze > requirements.txt\n   ```\n3. Restart the server to apply changes.\n\n## Troubleshooting\n\nIf you encounter any issues:\n\n1. Ensure your Brave API key is correctly set.\n2. Check that all dependencies are installed.\n3. Verify that you're using a compatible Python version.\n4. If you make changes to the code, make sure to restart the server.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "arben-adm--tavily-mcp-search": {
          "owner": "arben-adm",
          "name": "tavily-mcp-search",
          "url": "https://github.com/arben-adm/tavily-mcp-search",
          "imageUrl": "https://github.com/arben-adm.png",
          "description": "Provides multi-topic search capabilities across various domains such as business, news, finance, and politics using the Tavily API.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:50.521443",
          "collection_timestamp": "2025-10-02T15:10:03.957658",
          "stars": 1,
          "forks": 3,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-01-07T22:23:45Z",
          "updated_at": "2025-02-03T13:26:31Z",
          "open_issues": 1,
          "readme_content": "# üîç My Tavily Search MCP Agent\n\nI've created a powerful Model Context Protocol (MCP) Server powered by the Tavily API. With this, you can get high-quality, reliable information from business, news, finance, and politics - all through a robust and developer-friendly interface.\n\n[![smithery badge](https://smithery.ai/badge/mcp-tavily-search)](https://smithery.ai/server/mcp-tavily-search)\n[![Tavily Search Agent MCP Server](https://glama.ai/mcp/servers/p0w4whs3l4/badge)](https://glama.ai/mcp/servers/p0w4whs3l4)\n[![CI](https://github.com/your-username/mcp-tavily-search/workflows/CI/badge.svg)](https://github.com/your-username/mcp-tavily-search/actions)\n[![codecov](https://codecov.io/gh/your-username/mcp-tavily-search/branch/main/graph/badge.svg)](https://codecov.io/gh/your-username/mcp-tavily-search)\n\n## üåü Why I Built Tavily Search MCP\n\nIn today's fast-paced digital landscape, I recognized the need for quick access to precise information. I needed a web search tool that works with my sequential thinking MCP server. That's why I developed Tavily Search MCP, which excels with:\n\n‚ö°Ô∏è Lightning-fast async search responses  \nüõ°Ô∏è Built-in fault tolerance with automatic retries  \nüéØ Clean, markdown-formatted results  \nüîç Smart content snippets  \nüõ†Ô∏è Comprehensive error handling  \nüñºÔ∏è Optional image results  \nüì∞ Specialized news search\n\n## üöÄ Quick Start\n\n### Installing via Smithery\n\nTo install Tavily Search for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-tavily-search):\n\n```bash\nnpx -y @smithery/cli install mcp-tavily-search --client claude\n```\n\n### Installing Manually\nHere's how you can get up and running with my project in minutes:\n\n```bash\n# 1. Create environment\nuv venv && .venv\\Scripts\\activate     # Windows\n# OR\nuv venv && source .venv/bin/activate  # Unix/MacOS\n\n# 2. Install dependencies\nuv pip install -e .\n\n# 3. Set up configuration\necho TAVILY_API_KEY=your-key-here > .env\n\n# 4. Start server\ncd mcp_tavily_search && uv run server.py\n```\n\n## üí° Core Features\n\n### ‚ö°Ô∏è Performance & Reliability\n- I've implemented asynchronous request handling\n- Built-in error handling and automatic retries\n- Configurable request timeouts\n- Comprehensive logging system\n\n### üéØ Search Configuration\n- I've made the search depth configurable (basic/advanced)\n- Adjustable result limits (1-20 results)\n- Clean markdown-formatted output\n- Snippet previews with source URLs\n- Optional image results\n- Specialized news search topic\n\n### üõ°Ô∏è Error Handling\n- API authentication validation\n- Rate limit detection\n- Network error recovery\n- Request timeout management\n\n## üõ†Ô∏è Developer Integration\n\n### Prerequisites\n- Python 3.11 or higher\n- UV Package Manager ([Installation Guide](https://github.com/astral-sh/uv))\n- Tavily API key ([Get one here](https://tavily.com))\n\n### Claude Desktop Setup\n\nI've optimized the Claude Desktop experience with this configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"tavily-search\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/mcp-tavily-search/mcp_tavily_search\",\n        \"run\",\n        \"server.py\"\n      ],\n      \"env\": {\n        \"TAVILY_API_KEY\": \"YOUR-API-KEY\"\n      }\n    }\n  }\n}\n```\n\nüìÅ Configuration paths:\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- Unix/MacOS: `~/.config/Claude/claude_desktop_config.json`\n\n## Project Architecture\n\nI've designed a clean, modular structure to make development a breeze:\n\n```\nmcp-tavily-search/\n‚îú‚îÄ‚îÄ mcp_tavily_search/     # Core package\n‚îÇ   ‚îú‚îÄ‚îÄ server.py          # Server implementation\n‚îÇ   ‚îú‚îÄ‚îÄ client.py          # Tavily API client\n‚îÇ   ‚îú‚îÄ‚îÄ test_server.py     # Server tests\n‚îÇ   ‚îú‚îÄ‚îÄ test_client.py     # Client tests\n‚îÇ   ‚îî‚îÄ‚îÄ __init__.py        # Package initialization\n‚îú‚îÄ‚îÄ .env                   # Environment configuration\n‚îú‚îÄ‚îÄ README.md              # Documentation\n‚îî‚îÄ‚îÄ pyproject.toml         # Project configuration\n```\n\n## Key Components\n\n### Server (server.py)\n- I've implemented the MCP protocol\n- Request handling and routing\n- Error recovery and health monitoring\n\n### Client (client.py)\n- Tavily API integration\n- Retry mechanism with exponential backoff\n- Result formatting and processing\n- Error handling and logging\n\n### Tests (test_server.py and test_client.py)\n- Comprehensive unit tests for both server and client\n- Ensures reliability and correctness of the implementation\n\n## Usage Examples\n\nHere are some examples of how to use the enhanced search capabilities I've implemented:\n\n1. Basic search:\n```json\n{\n  \"name\": \"search\",\n  \"arguments\": {\n    \"query\": \"Latest news on artificial intelligence\"\n  }\n}\n```\n\n2. Advanced search with images:\n```json\n{\n  \"name\": \"search\",\n  \"arguments\": {\n    \"query\": \"Elon Musk SpaceX achievements\",\n    \"search_depth\": \"advanced\",\n    \"include_images\": true,\n    \"max_results\": 10\n  }\n}\n```\n\n3. News-specific search:\n```json\n{\n  \"name\": \"search\",\n  \"arguments\": {\n    \"query\": \"Climate change impact on agriculture\",\n    \"topic\": \"news\",\n    \"max_results\": 5\n  }\n}\n```\n\n4. Search with raw content:\n```json\n{\n  \"name\": \"search\",\n  \"arguments\": {\n    \"query\": \"Python programming best practices\",\n    \"include_raw_content\": true,\n    \"max_results\": 3\n  }\n}\n```\n\n## Troubleshooting Guide\n\n### Connection Issues\nIf things don't work as expected, follow these steps I've outlined:\n\n1. Verify your configuration paths\n2. Check the Claude Desktop logs:\n   ```bash\n   # Windows\n   type %APPDATA%\\Claude\\logs\\latest.log\n   # Unix/MacOS\n   cat ~/.config/Claude/logs/latest.log\n   ```\n3. Test the server manually using the quick start commands\n\n### API Troubleshooting\nIf you're experiencing API issues:\n\n1. Validate your API key permissions\n2. Check your network connection\n3. Monitor the API response in the server logs\n\n## Running Tests\n\nTo run the unit tests for this project, follow these steps:\n\n1. Install the development dependencies:\n   ```bash\n   uv pip install -e \".[dev]\"\n   ```\n\n2. Run the tests using pytest:\n   ```bash\n   pytest mcp_tavily_search\n   ```\n\nThis will run all the tests in the `mcp_tavily_search` directory, including both `test_client.py` and `test_server.py`.\n\n## Community and Support\n\n- I encourage you to report issues and contribute on GitHub\n- Share your implementations and improvements\n- Join our discussions and help others\n\n## Security and Best Practices\n\nSecurity is paramount in my implementation. The server includes:\n\n- Secure API key handling through environment variables\n- Automatic request timeout management\n- Comprehensive error tracking and logging\n\n## License\n\nI've licensed this project under MIT. See the LICENSE file for details.\n\n## Acknowledgments\n\nI'd like to give special thanks to:\n- The innovative Tavily API team\n- The MCP protocol community\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "apify--apify-mcp-server": {
          "owner": "apify",
          "name": "apify-mcp-server",
          "url": "https://github.com/apify/apify-mcp-server",
          "imageUrl": "https://github.com/apify.png",
          "description": "Enable interaction with various Apify Actors to perform specific tasks through an MCP server configuration. It supports HTTP server access via Server-Sent Events (SSE) and local server functionality through standard input/output.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:51.324390",
          "collection_timestamp": "2025-10-02T15:10:11.663470",
          "stars": 429,
          "forks": 51,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-01-02T15:43:09Z",
          "updated_at": "2025-10-02T00:20:27Z",
          "open_issues": 23,
          "readme_content": "<h1 align=\"center\">\n    <a href=\"https://mcp.apify.com\">\n        <picture>\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/apify/apify-mcp-server/refs/heads/master/docs/apify_mcp_server_dark_background.png\">\n            <img alt=\"Apify MCP Server\" src=\"https://raw.githubusercontent.com/apify/apify-mcp-server/refs/heads/master/docs/apify_mcp_server_white_background.png\" width=\"500\">\n        </picture>\n    </a>\n    <br>\n    <small><a href=\"https://mcp.apify.com\">mcp.apify.com</a></small>\n</h1>\n\n<p align=center>\n    <a href=\"https://www.npmjs.com/package/@apify/actors-mcp-server\" rel=\"nofollow\"><img src=\"https://img.shields.io/npm/v/@apify/actors-mcp-server.svg\" alt=\"NPM latest version\" data-canonical-src=\"https://img.shields.io/npm/v/@apify/actors-mcp-server.svg\" style=\"max-width: 100%;\"></a>\n    <a href=\"https://www.npmjs.com/package/@apify/actors-mcp-server\" rel=\"nofollow\"><img src=\"https://img.shields.io/npm/dm/@apify/actors-mcp-server.svg\" alt=\"Downloads\" data-canonical-src=\"https://img.shields.io/npm/dm/@apify/actors-mcp-server.svg\" style=\"max-width: 100%;\"></a>\n    <a href=\"https://github.com/apify/actors-mcp-server/actions/workflows/check.yaml\"><img src=\"https://github.com/apify/actors-mcp-server/actions/workflows/check.yaml/badge.svg?branch=master\" alt=\"Build Status\" style=\"max-width: 100%;\"></a>\n    <a href=\"https://apify.com/apify/actors-mcp-server\"><img src=\"https://apify.com/actor-badge?actor=apify/actors-mcp-server\" alt=\"Actor runs\" style=\"max-width: 100%;\"></a>\n</p>\n\nThe Apify Model Context Protocol (MCP) server at [**mcp.apify.com**](https://mcp.apify.com) enables your AI agents to extract data from social media, search engines, maps, e-commerce sites, or any other website using thousands of ready-made scrapers, crawlers, and automation tools available on the [Apify Store](https://apify.com/store).\n\n> **üöÄ Try the hosted Apify MCP Server!**\n>\n> For the easiest setup and most powerful features, including the ability to find and use any Actor from Apify Store, connect your AI assistant to our hosted server:\n>\n> **[`https://mcp.apify.com`](https://mcp.apify.com)**\n>\n> It supports OAuth, so you can connect from clients like Claude.ai or Visual Studio Code with just the URL.\n\n![Apify-MCP-server](https://raw.githubusercontent.com/apify/apify-mcp-server/refs/heads/master/docs/apify-mcp-server.png)\n\n## Table of Contents\n- [üåê Introducing the Apify MCP server](#-introducing-the-apify-mcp-server)\n- [üöÄ Quickstart](#-quickstart)\n- [ü§ñ MCP clients and examples](#-mcp-clients-and-examples)\n- [ü™Ñ Try Apify MCP instantly](#-try-apify-mcp-instantly)\n- [üõ†Ô∏è Tools, resources, and prompts](#-tools-resources-and-prompts)\n- [üêõ Troubleshooting (local MCP server)](#-troubleshooting-local-mcp-server)\n- [‚öôÔ∏è Development](#-development)\n- [ü§ù Contributing](#-contributing)\n- [üìö Learn more](#-learn-more)\n\n# üåê Introducing the Apify MCP server\n\nThe Apify MCP Server allows an AI assistant to use any [Apify Actor](https://apify.com/store) as a tool to perform a specific task.\nFor example, it can:\n- Use [Facebook Posts Scraper](https://apify.com/apify/facebook-posts-scraper) to extract data from Facebook posts from multiple pages/profiles.\n- Use [Google Maps Email Extractor](https://apify.com/lukaskrivka/google-maps-with-contact-details) to extract contact details from Google Maps.\n- Use [Google Search Results Scraper](https://apify.com/apify/google-search-scraper) to scrape Google Search Engine Results Pages (SERPs).\n- Use [Instagram Scraper](https://apify.com/apify/instagram-scraper) to scrape Instagram posts, profiles, places, photos, and comments.\n- Use [RAG Web Browser](https://apify.com/apify/web-scraper) to search the web, scrape the top N URLs, and return their content.\n\n**Video tutorial: Integrate 5,000+ Apify Actors and Agents with Claude**\n\n[![Apify MCP Server Tutorial: Integrate 5,000+ Apify Actors and Agents with Claude](https://img.youtube.com/vi/BKu8H91uCTg/hqdefault.jpg)](https://www.youtube.com/watch?v=BKu8H91uCTg)\n\n# üöÄ Quickstart\n\nYou can use the Apify MCP Server in two ways:\n\n**HTTPS Endpoint (mcp.apify.com)**: Connect from your MCP client via OAuth or by including the `Authorization: Bearer <APIFY_TOKEN>` header in your requests. This is the recommended method for most use cases. Because it supports OAuth, you can connect from clients like [Claude.ai](https://claude.ai) or [Visual Studio Code](https://code.visualstudio.com/) using just the URL: `https://mcp.apify.com`.\n- `https://mcp.apify.com` streamable transport\n\n**Standard Input/Output (stdio)**: Ideal for local integrations and command-line tools like the Claude for Desktop client.\n- Set the MCP client server command to `npx @apify/actors-mcp-server` and the `APIFY_TOKEN` environment variable to your Apify API token.\n- See `npx @apify/actors-mcp-server --help` for more options.\n\nYou can find detailed instructions for setting up the MCP server in the [Apify documentation](https://docs.apify.com/platform/integrations/mcp).\n\n# ü§ñ MCP clients and examples\n\nTo interact with the Apify MCP server, you can use various MCP clients, such as:\n- [Claude Desktop](https://claude.ai/download)\n- [Visual Studio Code](https://code.visualstudio.com/)\n- [Apify Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\n- Other clients at [https://modelcontextprotocol.io/clients](https://modelcontextprotocol.io/clients)\n- More clients at [https://glama.ai/mcp/clients](https://glama.ai/mcp/clients)\n\nWith MCP server integrated, you can ask your AI assistant things like:\n- \"Search the web and summarize recent trends in AI Agents.\"\n- \"Find the top 10 Italian restaurants in San Francisco.\"\n- \"Find and analyze the Instagram profile of The Rock.\"\n- \"Provide a step-by-step guide on using the Model Context Protocol, including source URLs.\"\n- \"What Apify Actors can I use?\"\n\n### Supported clients matrix\n\nThe following table outlines the tested MCP clients and their level of support for key features.\n\n| Client | Dynamic Tool Discovery | Notes |\n| --- | --- | --- |\n| **Claude.ai (web)** | ‚úÖ Full | |\n| **Claude Desktop** | üü° Partial | Tools may need to be reloaded manually in the client. |\n| **VS Code (Genie)** | ‚úÖ Full | |\n| **Apify Tester MCP Client** | ‚úÖ Full | Designed for testing Apify MCP servers. |\n\nApify MCP Server is compatible with any MCP client that adheres to the [Model Context Protocol](https://modelcontextprotocol.org/), but the level of support for dynamic tool discovery and other features may vary between clients. Therefore, the server uses [mcp-client-capabilities](https://github.com/apify/mcp-client-capabilities) to detect client capabilities and adjust its behavior accordingly.\n\n**Smart tool selection based on client capabilities:**\n\nWhen the `actors` tool category is requested, the server intelligently selects the most appropriate Actor-related tools based on the client's capabilities:\n\n- **Clients with dynamic tool support** (e.g., Claude.ai web, VS Code Genie): The server provides the `add-actor` tool instead of `call-actor`. This allows for a better user experience where users can dynamically discover and add new Actors as tools during their conversation.\n\n- **Clients with limited dynamic tool support** (e.g., Claude Desktop): The server provides the standard `call-actor` tool along with other Actor category tools, ensuring compatibility while maintaining functionality.\n\n# ü™Ñ Try Apify MCP instantly\n\nWant to try Apify MCP without any setup?\n\nCheck out [Apify Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\n\nThis interactive, chat-like interface provides an easy way to explore the capabilities of Apify MCP without any local setup.\nJust sign in with your Apify account and start experimenting with web scraping, data extraction, and automation tools!\n\nOr use the MCP bundle file (formerly known as Anthropic Desktop extension file, or DXT) for one-click installation: [Apify MCP server MCPB file](https://github.com/apify/apify-mcp-server/releases/latest/download/apify-mcp-server.mcpb)\n\n# üõ†Ô∏è Tools, resources, and prompts\n\nThe MCP server provides a set of tools for interacting with Apify Actors.\nSince the Apify Store is large and growing rapidly, the MCP server provides a way to dynamically discover and use new Actors.\n\n### Actors\n\nAny [Apify Actor](https://apify.com/store) can be used as a tool.\nBy default, the server is pre-configured with one Actor, `apify/rag-web-browser`, and several helper tools.\nThe MCP server loads an Actor's input schema and creates a corresponding MCP tool.\nThis allows the AI agent to know exactly what arguments to pass to the Actor and what to expect in return.\n\n\nFor example, for the `apify/rag-web-browser` Actor, the input parameters are:\n\n```json\n{\n  \"query\": \"restaurants in San Francisco\",\n  \"maxResults\": 3\n}\n```\nYou don't need to manually specify which Actor to call or its input parameters; the LLM handles this automatically.\nWhen a tool is called, the arguments are automatically passed to the Actor by the LLM.\nYou can refer to the specific Actor's documentation for a list of available arguments.\n\n### Helper tools\n\nOne of the most powerful features of using MCP with Apify is dynamic tool discovery.\nIt gives an AI agent the ability to find new tools (Actors) as needed and incorporate them.\nHere are some special MCP operations and how the Apify MCP Server supports them:\n\n- **Apify Actors**: Search for Actors, view their details, and use them as tools for the AI.\n- **Apify documentation**: Search the Apify documentation and fetch specific documents to provide context to the AI.\n- **Actor runs**: Get lists of your Actor runs, inspect their details, and retrieve logs.\n- **Apify storage**: Access data from your datasets and key-value stores.\n\n### Overview of available tools\n\nHere is an overview list of all the tools provided by the Apify MCP Server.\n\n| Tool name | Category | Description | Enabled by default |\n| :--- | :--- | :--- | :---: |\n| `search-actors` | actors | Search for Actors in the Apify Store. | ‚úÖ |\n| `fetch-actor-details` | actors | Retrieve detailed information about a specific Actor. | ‚úÖ |\n| `call-actor` | actors | Call an Actor and get its run results. | ‚úÖ |\n| [`apify-slash-rag-web-browser`](https://apify.com/apify/rag-web-browser) | Actor (see [tool configuration](#tools-configuration)) | An Actor tool to browse the web. | ‚úÖ |\n| `search-apify-docs` | docs | Search the Apify documentation for relevant pages. | ‚úÖ |\n| `fetch-apify-docs` | docs | Fetch the full content of an Apify documentation page by its URL. | ‚úÖ |\n| `get-actor-run` | runs | Get detailed information about a specific Actor run. |  |\n| `get-actor-run-list` | runs | Get a list of an Actor's runs, filterable by status. |  |\n| `get-actor-log` | runs | Retrieve the logs for a specific Actor run. |  |\n| `get-dataset` | storage | Get metadata about a specific dataset. |  |\n| `get-dataset-items` | storage | Retrieve items from a dataset with support for filtering and pagination. |  |\n| `get-dataset-schema` | storage | Generate a JSON schema from dataset items. |  |\n| `get-key-value-store` | storage | Get metadata about a specific key-value store. |  |\n| `get-key-value-store-keys`| storage | List the keys within a specific key-value store. |  |\n| `get-key-value-store-record`| storage | Get the value associated with a specific key in a key-value store. |  |\n| `get-dataset-list` | storage | List all available datasets for the user. |  |\n| `get-key-value-store-list`| storage | List all available key-value stores for the user. |  |\n| `add-actor` | experimental | Add an Actor as a new tool for the user to call. |  |\n| `get-actor-output`* | - | Retrieve the output from an Actor call which is not included in the output preview of the Actor tool. | ‚úÖ |\n\n> **Note:**\n>\n> When using the `actors` tool category, clients that support dynamic tool discovery (like Claude.ai web and VS Code) automatically receive the `add-actor` tool instead of `call-actor` for enhanced Actor discovery capabilities.\n\n> The `get-actor-output` tool is automatically included with any Actor-related tool, such as `call-actor`, `add-actor`, or any specific Actor tool like `apify-slash-rag-web-browser`. When you call an Actor - either through the `call-actor` tool or directly via an Actor tool (e.g., `apify-slash-rag-web-browser`) - you receive a preview of the output. The preview depends on the Actor's output format and length; for some Actors and runs, it may include the entire output, while for others, only a limited version is returned to avoid overwhelming the LLM. To retrieve the full output of an Actor run, use the `get-actor-output` tool (supports limit, offset, and field filtering) with the `datasetId` provided by the Actor call.\n\n### Tools configuration\n\nThe `tools` configuration parameter is used to specify loaded tools - either categories or specific tools directly, and Apify Actors. For example, `tools=storage,runs` loads two categories; `tools=add-actor` loads just one tool.\n\nWhen no query parameters are provided, the MCP server loads the following `tools` by default:\n\n- `actors`\n- `docs`\n- `apify/rag-web-browser`\n\nIf the tools parameter is specified, only the listed tools or categories will be enabled - no default tools will be included.\n\n> **Easy configuration:**\n>\n> Use the [UI configurator](https://mcp.apify.com/) to configure your server, then copy the configuration to your client.\n\n**Configuring the hosted server:**\n\nThe hosted server can be configured using query parameters in the URL. For example, to load the default tools, use:\n\n```\nhttps://mcp.apify.com?tools=actors,docs,apify/rag-web-browser\n```\n\nFor minimal configuration, if you want to use only a single Actor tool - without any discovery or generic calling tools, the server can be configured as follows:\n\n```\nhttps://mcp.apify.com?tools=apify/my-actor\n```\n\nThis setup exposes only the specified Actor (`apify/my-actor`) as a tool. No other tools will be available.\n\n**Configuring the CLI:**\n\nThe CLI can be configured using command-line flags. For example, to load the same tools as in the hosted server configuration, use:\n\n```bash\nnpx @apify/actors-mcp-server --tools actors,docs,apify/rag-web-browser\n```\n\nThe minimal configuration is similar to the hosted server configuration:\n\n```bash\nnpx @apify/actors-mcp-server --tools apify/my-actor\n```\n\nAs above, this exposes only the specified Actor (`apify/my-actor`) as a tool. No other tools will be available.\n\n> **‚ö†Ô∏è Important recommendation**\n>\n> **The default tools configuration may change in future versions.** When no `tools` parameter is specified, the server currently loads default tools, but this behavior is subject to change.\n>\n> **For production use and stable interfaces, always explicitly specify the `tools` parameter** to ensure your configuration remains consistent across updates.\n\n### Backward compatibility\n\nThe v2 configuration preserves backward compatibility with v1 usage. Notes:\n\n- `actors` param (URL) and `--actors` flag (CLI) are still supported.\n  - Internally they are merged into `tools` selectors.\n  - Examples: `?actors=apify/rag-web-browser` ‚â° `?tools=apify/rag-web-browser`; `--actors apify/rag-web-browser` ‚â° `--tools apify/rag-web-browser`.\n- `enable-adding-actors` (CLI) and `enableAddingActors` (URL) are supported but deprecated.\n  - Prefer `tools=experimental` or including the specific tool `tools=add-actor`.\n  - Behavior remains: when enabled with no `tools` specified, the server exposes only `add-actor`; when categories/tools are selected, `add-actor` is also included.\n- `enableActorAutoLoading` remains as a legacy alias for `enableAddingActors` and is mapped automatically.\n- Defaults remain compatible: when no `tools` are specified, the server loads `actors`, `docs`, and `apify/rag-web-browser`.\n  - If any `tools` are specified, the defaults are not added (same as v1 intent for explicit selection).\n- `call-actor` is now included by default via the `actors` category (additive change). To exclude it, specify an explicit `tools` list without `actors`.\n- `preview` category is deprecated and removed. Use specific tool names instead.\n\nExisting URLs and commands using `?actors=...` or `--actors` continue to work unchanged.\n\n### Prompts\n\nThe server provides a set of predefined example prompts to help you get started interacting with Apify through MCP. For example, there is a `GetLatestNewsOnTopic` prompt that allows you to easily retrieve the latest news on a specific topic using the [RAG Web Browser](https://apify.com/apify/rag-web-browser) Actor.\n\n### Resources\n\nThe server does not yet provide any resources.\n\n### Debugging the NPM package\n\nTo debug the server, use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) tool:\n\n```shell\nexport APIFY_TOKEN=\"your-apify-token\"\nnpx @modelcontextprotocol/inspector npx -y @apify/actors-mcp-server\n```\n\n# ‚öôÔ∏è Development\n\n## Prerequisites\n\n- [Node.js](https://nodejs.org/en) (v18 or higher)\n\nCreate an environment file, `.env`, with the following content:\n```text\nAPIFY_TOKEN=\"your-apify-token\"\n```\n\nBuild the `actor-mcp-server` package:\n\n```bash\nnpm run build\n```\n\n## Start HTTP streamable MCP server\n\nRun using Apify CLI:\n\n```bash\nexport APIFY_TOKEN=\"your-apify-token\"\nexport APIFY_META_ORIGIN=STANDBY\napify run -p\n```\n\nOnce the server is running, you can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) to debug the server exposed at `http://localhost:3001`.\n\n## Start standard input/output (stdio) MCP server\n\nYou can launch the MCP Inspector with this command:\n\n```bash\nexport APIFY_TOKEN=\"your-apify-token\"\nnpx @modelcontextprotocol/inspector node ./dist/stdio.js\n```\n\nUpon launching, the Inspector will display a URL that you can open in your browser to begin debugging.\n\n## üê¶ Canary PR releases\n\nApify MCP is split across two repositories: this one for core MCP logic and the private `apify-mcp-server-internal` for the hosted server.\nChanges must be synchronized between both.\n\nTo create a canary release, add the `beta` tag to your PR branch.\nThis publishes the package to [pkg.pr.new](https://pkg.pr.new/) for staging and testing before merging.\nSee [the workflow file](.github/workflows/pre_release.yaml) for details.\n\n## üêã Docker Hub integration\nThe Apify MCP Server is also available on [Docker Hub](https://hub.docker.com/mcp/server/apify-mcp-server/overview), registered via the [mcp-registry](https://github.com/docker/mcp-registry) repository. The entry in `servers/apify-mcp-server/server.yaml` should be deployed automatically by the Docker Hub MCP registry (deployment frequency is unknown). **Before making major changes to the `stdio` server version, be sure to test it locally to ensure the Docker build passes.** To test, change the `source.branch` to your PR branch and run `task build -- apify-mcp-server`. For more details, see [CONTRIBUTING.md](https://github.com/docker/mcp-registry/blob/main/CONTRIBUTING.md).\n\n# üêõ Troubleshooting (local MCP server)\n\n- Make sure you have `node` installed by running `node -v`.\n- Make sure the `APIFY_TOKEN` environment variable is set.\n- Always use the latest version of the MCP server by using `@apify/actors-mcp-server@latest`.\n\n## üí° Limitations\n\nThe Actor input schema is processed to be compatible with most MCP clients while adhering to [JSON Schema](https://json-schema.org/) standards. The processing includes:\n- **Descriptions** are truncated to 500 characters (as defined in `MAX_DESCRIPTION_LENGTH`).\n- **Enum fields** are truncated to a maximum combined length of 200 characters for all elements (as defined in `ACTOR_ENUM_MAX_LENGTH`).\n- **Required fields** are explicitly marked with a `REQUIRED` prefix in their descriptions for compatibility with frameworks that may not handle the JSON schema properly.\n- **Nested properties** are built for special cases like proxy configuration and request list sources to ensure the correct input structure.\n- **Array item types** are inferred when not explicitly defined in the schema, using a priority order: explicit type in items > prefill type > default value type > editor type.\n- **Enum values and examples** are added to property descriptions to ensure visibility, even if the client doesn't fully support the JSON schema.\n- **Rental Actors** are only available for use with the hosted MCP server at https://mcp.apify.com. When running the server locally via stdio, you can only access Actors that are already added to your local toolset. To dynamically search for and use any Actor from the Apify Store‚Äîincluding rental Actors‚Äîconnect to the hosted endpoint.\n\n# ü§ù Contributing\n\nWe welcome contributions to improve the Apify MCP Server! Here's how you can help:\n\n- **üêõ Report issues**: Find a bug or have a feature request? [Open an issue](https://github.com/apify/apify-mcp-server/issues).\n- **üîß Submit pull requests**: Fork the repo and submit pull requests with enhancements or fixes.\n- **üìö Documentation**: Improvements to docs and examples are always welcome.\n- **üí° Share use cases**: Contribute examples to help other users.\n\nFor major changes, please open an issue first to discuss your proposal and ensure it aligns with the project's goals.\n\n# üìö Learn more\n\n- [Model Context Protocol](https://modelcontextprotocol.org/)\n- [What are AI Agents?](https://blog.apify.com/what-are-ai-agents/)\n- [What is MCP and why does it matter?](https://blog.apify.com/what-is-model-context-protocol/)\n- [How to use MCP with Apify Actors](https://blog.apify.com/how-to-use-mcp/)\n- [Tester MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\n- [Webinar: Building and Monetizing MCP Servers on Apify](https://www.youtube.com/watch?v=w3AH3jIrXXo)\n- [MCP Client development guide](https://github.com/cyanheads/model-context-protocol-resources/blob/main/guides/mcp-client-development-guide.md)\n- [How to build and monetize an AI agent on Apify](https://blog.apify.com/how-to-build-an-ai-agent/)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "arjunkmrm--perplexity-deep-research": {
          "owner": "arjunkmrm",
          "name": "perplexity-deep-research",
          "url": "https://github.com/arjunkmrm/perplexity-deep-research",
          "imageUrl": "https://github.com/arjunkmrm.png",
          "description": "Enables AI assistants to perform web searches utilizing Perplexity's Deep Research with access to the chat completions API and sonar-deep-research model. Offers a tool for executing search queries with an optional recency filter.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:52.292865",
          "collection_timestamp": "2025-10-02T15:10:19.159744",
          "stars": 9,
          "forks": 3,
          "license": "No License",
          "language": "JavaScript",
          "created_at": "2025-02-27T17:10:24Z",
          "updated_at": "2025-09-24T09:02:16Z",
          "open_issues": 3,
          "readme_content": "# Perplexity Deep Research MCP\n[![smithery badge](https://smithery.ai/badge/@arjunkmrm/perplexity-deep-research)](https://smithery.ai/server/@arjunkmrm/perplexity-deep-research)\n\nA Model Context Protocol (MCP) server for Perplexity AI API with web search capabilities. This server allows AI assistants to perform web searches using Perplexity's chat completions API with the sonar-deep-research model.\n\n## Features\n\n- Provides a `deep_research` tool for AI assistants to perform web searches\n- Uses Perplexity's chat completions API with the sonar-deep-research model\n\n## Tool: deep_research\n\nThe server provides a `deep_research` tool with the following input parameters:\n\n- `query` (required): The search query to perform\n- `search_recency_filter` (optional): Filter search results by recency (options: month, week, day, hour)\n\n## Configuration\n\n### Environment Variables\n\n- `PERPLEXITY_API_KEY`: Your Perplexity API key (required)\n\n## Response Format\n\nThe response from the `deep_research` tool includes:\n\n- Content of search results\n- Citations for the information\n\n## Installing via Smithery\n\nTo install perplexity-deep-research for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@arjunkmrm/perplexity-deep-research):\n\n```bash\nnpx -y @smithery/cli install @arjunkmrm/perplexity-deep-research --client claude\n```\n\n## License\n\nMIT \n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "arjunprabhulal--mcp-flight-search": {
          "owner": "arjunprabhulal",
          "name": "mcp-flight-search",
          "url": "https://github.com/arjunprabhulal/mcp-flight-search",
          "imageUrl": "https://github.com/arjunprabhulal.png",
          "description": "Enables flight searches with real-time data integration through SerpAPI for one-way and round-trip flights, featuring rich logging and a modular code structure for maintenance and scalability.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:53.275180",
          "collection_timestamp": "2025-10-02T15:10:26.842874",
          "stars": 31,
          "forks": 17,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-04-02T03:43:19Z",
          "updated_at": "2025-08-26T22:26:43Z",
          "open_issues": 0,
          "readme_content": "# MCP Flight Search\n<a href=\"https://glama.ai/mcp/servers/@arjunprabhulal/mcp-flight-search\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@arjunprabhulal/mcp-flight-search/badge\" />\n</a>\n\nA flight search service built with Model Context Protocol (MCP). This service demonstrates how to implement MCP tools for flight search capabilities.\n\n## What is Model Context Protocol?\n\nThe Model Context Protocol (MCP) is a standard developed by Anthropic that enables AI models to use tools by defining a structured format for tool descriptions, calls, and responses. This project implements MCP tools that can be used by Claude and other MCP-compatible models.\n\n## Installation\n\n```bash\n# Install from PyPI\npip install mcp-flight-search\n\n# Or install from the project directory (development mode)\npip install -e .\n```\n\n## Usage\n\nStart the MCP server:\n\n```bash\n# Using the command-line entry point\nmcp-flight-search --connection_type http\n\n# Or run directly\npython main.py --connection_type http\n```\n\nYou can also specify a custom port:\n```bash\npython main.py --connection_type http --port 5000\n```\n\n## Environment Variables\n\nSet the SerpAPI key as an environment variable:\n```bash\nexport SERP_API_KEY=\"your-api-key-here\"\n```\n\n## Features\n\n- MCP-compliant tools for flight search functionality\n- Integration with SerpAPI Google Flights\n- Support for one-way and round-trip flights\n- Rich logging with structured output\n- Modular, maintainable code structure\n\n## MCP Tools\n\nThis package provides the following Model Context Protocol tools:\n\n- `search_flights_tool`: Search for flights between airports with parameters:\n  - `origin`: Departure airport code (e.g., ATL, JFK)\n  - `destination`: Arrival airport code (e.g., LAX, ORD)\n  - `outbound_date`: Departure date (YYYY-MM-DD)\n  - `return_date`: Optional return date for round trips (YYYY-MM-DD)\n\n- `server_status`: Check if the MCP server is running\n\n## Project Structure\n\n```\nmcp-flight-search/\n‚îú‚îÄ‚îÄ mcp_flight_search/\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Package initialization and exports\n‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Configuration variables (API keys)\n‚îÇ   ‚îú‚îÄ‚îÄ models/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Models package init\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py           # Pydantic models (FlightInfo)\n‚îÇ   ‚îú‚îÄ‚îÄ services/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Services package init\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_service.py    # Main flight search logic\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ serpapi_client.py    # SerpAPI client wrapper\n‚îÇ   ‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Utils package init\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging.py           # Logging configuration\n‚îÇ   ‚îî‚îÄ‚îÄ server.py                # MCP server setup and tool registration\n‚îú‚îÄ‚îÄ main.py                      # Main entry point\n‚îú‚îÄ‚îÄ pyproject.toml               # Python packaging configuration\n‚îú‚îÄ‚îÄ LICENSE                      # MIT License\n‚îî‚îÄ‚îÄ README.md                    # Project documentation\n```\n\n## Author\n\nFor more articles on AI/ML and Generative AI, follow me on Medium: https://medium.com/@arjun-prabhulal\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details. \n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "arjunkmrm--perplexity-search": {
          "owner": "arjunkmrm",
          "name": "perplexity-search",
          "url": "https://github.com/arjunkmrm/perplexity-search",
          "imageUrl": "https://github.com/arjunkmrm.png",
          "description": "A Model Context Protocol server for conducting web searches using Perplexity's Sonar Pro, facilitating retrieval of information based on user-defined queries. It offers a `search` tool that enables AI assistants to filter search results by recency.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:54.280576",
          "collection_timestamp": "2025-10-02T15:10:32.747286",
          "stars": 9,
          "forks": 5,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-02-28T09:44:39Z",
          "updated_at": "2025-09-05T07:58:19Z",
          "open_issues": 0,
          "readme_content": "# Perplexity Search MCP\n\n[![smithery badge](https://smithery.ai/badge/@arjunkmrm/perplexity-search)](https://smithery.ai/server/@arjunkmrm/perplexity-search)\n\nA simple Model Context Protocol (MCP) server for Perplexity's web search with sonar or sonar-pro.\n\n## Features\n\n- Provides a `search` tool for AI assistants to perform web searches\n- Uses Perplexity's chat completions API with the sonar/sonar-pro models\n\n## Tool: search\n\nThe server provides a `search` tool with the following input parameters:\n\n- `query` (required): The search query to perform\n- `search_recency_filter` (optional): Filter search results by recency (options: month, week, day, hour). If not specified, no time filtering is applied.\n\n## Configuration\n\n### Environment Variables\n\n- `PERPLEXITY_API_KEY`: Your Perplexity API key (required)\n\n## Response Format\n\nThe response from the `search` tool includes:\n\n- `content`: The search results content\n- `citations`: Array of citations for the information\n\n## License\n\nMIT ",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-perplexity-search",
          "npm_downloads": 5985,
          "npm_package_name": "mcp-perplexity-search",
          "npm_success": true,
          "npm_error": null
        },
        "arjunkmrm--exa-mcp-server": {
          "owner": "arjunkmrm",
          "name": "exa-mcp-server",
          "url": "https://github.com/arjunkmrm/exa-mcp-server",
          "imageUrl": "https://github.com/arjunkmrm.png",
          "description": "Connects AI assistants to the Exa AI Search API for real-time web searches, academic inquiries, and social media queries. Supports customizable search capabilities and live crawling for company and competitor research.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:55.050892",
          "collection_timestamp": "2025-10-02T15:10:35.704933",
          "stars": 1,
          "forks": 0,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-06-06T16:46:21Z",
          "updated_at": "2025-10-02T02:22:07Z",
          "open_issues": 0,
          "readme_content": "# Exa MCP Server üîç\n[![npm version](https://badge.fury.io/js/exa-mcp-server.svg)](https://www.npmjs.com/package/exa-mcp-server)\n[![smithery badge](https://smithery.ai/badge/exa)](https://smithery.ai/server/exa)\n\n## üÜï `exa-code`: fast, efficient web context for coding agents\n\nVibe coding should never have a bad vibe. `exa-code` is a huge step towards coding agents that never hallucinate.\n\nWhen your coding agent makes a search query, `exa-code` searches over billions\nof Github repos, docs pages, Stackoverflow posts, and more, to find the perfect, token-efficient context that the agent needs to code correctly. It's powered by the Exa search engine.\n\nExamples of queries you can make with `exa-code`:\n* use Exa search in python and make sure content is always livecrawled\n* use correct syntax for vercel ai sdk to call gpt-5 nano asking it how are you\n* how to set up a reproducible Nix Rust development environment\n\n**‚ú® Works with Cursor and Claude Code!** Use the HTTP-based configuration format:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.exa.ai/mcp\",\n      \"headers\": {\n        \"Remove-Me\": \"Disable web_search_exa tool if you're just coding. To 100% call exa-code, say 'use exa-code'.\"\n      }\n    }\n  }\n}\n```\n\nYou may include your exa api key in the url like this:\n```\nhttps://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY\n```\n\nYou may whitelist specific tools in the url with the `enabledTools` parameter which expects a url encoded array strings like this:\n```\nhttps://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY&enabledTools=%5B%22crawling_exa%ss%5D\n```\n\nYou can also use `exa-code` through [Smithery](https://smithery.ai/server/exa) without an Exa API key.\n\n---\n\nA Model Context Protocol (MCP) server that connects AI assistants like Claude to Exa AI's search capabilities, including web search, research tools, and our new code search feature.\n\n## Remote Exa MCP üåê\n\nConnect directly to Exa's hosted MCP server (instead of running it locally).\n\n### Remote Exa MCP URL\n\n```\nhttps://mcp.exa.ai/mcp\n```\n\n### Claude Desktop Configuration for Remote MCP\n\nAdd this to your Claude Desktop configuration file:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-remote\",\n        \"https://mcp.exa.ai/mcp\"\n      ]\n    }\n  }\n}\n```\n\n### Cursor and Claude Code Configuration for Remote MCP\n\nFor Cursor and Claude Code, use this HTTP-based configuration format:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.exa.ai/mcp\",\n      \"headers\": {}\n    }\n  }\n}\n```\n\n### NPM Installation\n\n```bash\nnpm install -g exa-mcp-server\n```\n\n### Using Claude Code\n\n```bash\nclaude mcp add exa -e EXA_API_KEY=YOUR_API_KEY -- npx -y exa-mcp-server\n```\n\n### Using Exa MCP through Smithery\n\nTo install the Exa MCP server via [Smithery](https://smithery.ai/server/exa), head over to:\n\n[smithery.ai/server/exa](https://smithery.ai/server/exa)\n\n\n## Configuration ‚öôÔ∏è\n\n### 1. Configure Claude Desktop to recognize the Exa MCP server\n\nYou can find claude_desktop_config.json inside the settings of Claude Desktop app:\n\nOpen the Claude Desktop app and enable Developer Mode from the top-left menu bar. \n\nOnce enabled, open Settings (also from the top-left menu bar) and navigate to the Developer Option, where you'll find the Edit Config button. Clicking it will open the claude_desktop_config.json file, allowing you to make the necessary edits. \n\nOR (if you want to open claude_desktop_config.json from terminal)\n\n#### For macOS:\n\n1. Open your Claude Desktop configuration:\n\n```bash\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n#### For Windows:\n\n1. Open your Claude Desktop configuration:\n\n```powershell\ncode %APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n### 2. Add the Exa server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"exa-mcp-server\"],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nReplace `your-api-key-here` with your actual Exa API key from [dashboard.exa.ai/api-keys](https://dashboard.exa.ai/api-keys).\n\n### 3. Available Tools & Tool Selection\n\nThe Exa MCP server includes powerful tools for developers and researchers:\n\n#### üî• **Featured: Code Search Tool**\n- **get_code_context_exa**: üÜï **NEW!** Search and get relevant code snippets, examples, and documentation from open source libraries, GitHub repositories, and programming frameworks. Perfect for finding up-to-date code documentation, implementation examples, API usage patterns, and best practices from real codebases.\n\n#### üåê **Other Available Tools**\n- **web_search_exa**: Performs real-time web searches with optimized results and content extraction.\n- **company_research**: Comprehensive company research tool that crawls company websites to gather detailed information about businesses.\n- **crawling**: Extracts content from specific URLs, useful for reading articles, PDFs, or any web page when you have the exact URL.\n- **linkedin_search**: Search LinkedIn for companies and people using Exa AI. Simply include company names, person names, or specific LinkedIn URLs in your query.\n- **deep_researcher_start**: Start a smart AI researcher for complex questions. The AI will search the web, read many sources, and think deeply about your question to create a detailed research report.\n- **deep_researcher_check**: Check if your research is ready and get the results. Use this after starting a research task to see if it's done and get your comprehensive report.\n\nYou can choose which tools to enable by adding the `--tools` parameter to your Claude Desktop configuration:\n\n#### üíª **Setup for Code Search Only** (Recommended for Developers)\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"exa-mcp-server\",\n        \"--tools=get_code_context_exa,web_search_exa\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\n#### Specify which tools to enable:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"exa-mcp-server\",\n        \"--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nFor enabling multiple tools, use a comma-separated list:\n\n```json\n{\n  \"mcpServers\": {\n    \"exa\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"exa-mcp-server\",\n        \"--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check\"\n      ],\n      \"env\": {\n        \"EXA_API_KEY\": \"your-api-key-here\"\n      }\n    }\n  }\n}\n```\n\nIf you don't specify any tools, all tools enabled by default will be used.\n\n### 4. Restart Claude Desktop\n\nFor the changes to take effect:\n\n1. Completely quit Claude Desktop (not just close the window)\n2. Start Claude Desktop again\n3. Look for the icon to verify the Exa server is connected\n\n## Using via NPX\n\nIf you prefer to run the server directly, you can use npx:\n\n```bash\n# Run with all tools enabled by default\nnpx exa-mcp-server\n\n# Enable specific tools only\nnpx exa-mcp-server --tools=web_search_exa\n\n# Enable multiple tools\nnpx exa-mcp-server --tools=web_search_exa,get_code_context_exa\n\n# List all available tools\nnpx exa-mcp-server --list-tools\n```\n\n---\n\nBuilt with ‚ù§Ô∏è by team Exa\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/exa-mcp-server",
          "npm_downloads": 95247,
          "npm_package_name": "exa-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "arkeodev--search-engine-with-rag-and-mcp": {
          "owner": "arkeodev",
          "name": "search-engine-with-rag-and-mcp",
          "url": "https://github.com/arkeodev/search-engine-with-rag-and-mcp",
          "imageUrl": "https://github.com/arkeodev.png",
          "description": "A search engine that integrates web search and content retrieval with Retrieval-Augmented Generation (RAG), facilitating standardized tool invocation through the Model Context Protocol (MCP). It supports both local and cloud-based language models and operates in multiple modes for enhanced versatility in information retrieval.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:56.104327",
          "collection_timestamp": "2025-10-02T15:10:43.204568",
          "stars": 2,
          "forks": 2,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-04-23T10:47:12Z",
          "updated_at": "2025-08-20T19:39:22Z",
          "open_issues": 2,
          "readme_content": "# Search Engine with RAG and MCP\n\nA powerful search engine that combines LangChain, Model Context Protocol (MCP), Retrieval-Augmented Generation (RAG), and Ollama to create an agentic AI system capable of searching the web, retrieving information, and providing relevant answers.\n\n## Features\n\n- Web search capabilities using the Exa API\n- Web content retrieval using FireCrawl\n- RAG (Retrieval-Augmented Generation) for more relevant information extraction\n- MCP (Model Context Protocol) server for standardized tool invocation\n- Support for both local LLMs via Ollama and cloud-based LLMs via OpenAI\n- Flexible architecture supporting direct search, agent-based search, or server mode\n- Comprehensive error handling and graceful fallbacks\n- Python 3.13+ with type hints\n- Asynchronous processing for efficient web operations\n\n## Architecture\n\nThis project integrates several key components:\n\n1. **Search Module**: Uses Exa API to search the web and FireCrawl to retrieve content\n2. **RAG Module**: Embeds documents, chunks them, and stores them in a FAISS vector store\n3. **MCP Server**: Provides a standardized protocol for tool invocation\n4. **Agent**: LangChain-based agent that uses the search and RAG capabilities\n\n## Project Structure\n\n```\nsearch-engine-with-rag-and-mcp/\n‚îú‚îÄ‚îÄ LICENSE              # MIT License\n‚îú‚îÄ‚îÄ README.md            # Project documentation\n‚îú‚îÄ‚îÄ data/                # Data directories\n‚îú‚îÄ‚îÄ docs/                # Documentation\n‚îÇ   ‚îî‚îÄ‚îÄ env_template.md  # Environment variables documentation\n‚îú‚îÄ‚îÄ logs/                # Log files directory (auto-created)\n‚îú‚îÄ‚îÄ src/                 # Main package (source code)\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      \n‚îÇ   ‚îú‚îÄ‚îÄ core/            # Core functionality\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py      # Main entry point\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py    # Web search module\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag.py       # RAG implementation\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py     # LangChain agent\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mcp_server.py # MCP server implementation\n‚îÇ   ‚îî‚îÄ‚îÄ utils/           # Utility modules\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ       ‚îú‚îÄ‚îÄ env.py       # Environment variable loading\n‚îÇ       ‚îî‚îÄ‚îÄ logger.py    # Logging configuration\n‚îú‚îÄ‚îÄ pyproject.toml       # Poetry configuration\n‚îú‚îÄ‚îÄ requirements.txt     # Project dependencies\n‚îî‚îÄ‚îÄ tests/               # Test directory\n```\n\n## Getting Started\n\n### Prerequisites\n\n- Python 3.13+\n- [Poetry](https://python-poetry.org/docs/#installation) (optional, for development)\n- API keys for Exa and FireCrawl\n- (Optional) Ollama installed locally\n- (Optional) OpenAI API key\n\n### Installation\n\n1. Clone the repository\n```bash\ngit clone https://github.com/yourusername/search-engine-with-rag-and-mcp.git\ncd search-engine-with-rag-and-mcp\n```\n\n2. Install dependencies\n```bash\n# Using pip\npip install -r requirements.txt\n\n# Or using poetry\npoetry install\n```\n\n3. Create a `.env` file (use docs/env_template.md as a reference)\n\n### Usage\n\nThe application has three main modes of operation:\n\n#### 1. Direct Search Mode (Default)\n\n```bash\n# Using pip\npython -m src.core.main \"your search query\"\n\n# Or using poetry\npoetry run python -m src.core.main \"your search query\"\n```\n\n#### 2. Agent Mode\n\n```bash\npython -m src.core.main --agent \"your search query\"\n```\n\n#### 3. MCP Server Mode\n\n```bash\npython -m src.core.main --server\n```\n\nYou can also specify custom host and port:\n\n```bash\npython -m src.core.main --server --host 0.0.0.0 --port 8080\n```\n\n### Using Ollama (Optional)\n\nTo use Ollama for local embeddings and LLM capabilities:\n\n1. Install Ollama: https://ollama.ai/\n2. Pull a model:\n```bash\nollama pull mistral:latest\n```\n3. Set the appropriate environment variables in your `.env` file:\n```\nOLLAMA_BASE_URL=http://localhost:11434\nOLLAMA_MODEL=mistral:latest\n```\n\n## Development\n\nThis project follows these best practices:\n\n- **Code formatting**: Black and isort for consistent code style\n- **Type checking**: mypy for static type checking\n- **Linting**: flake8 for code quality\n- **Testing**: pytest for unit and integration tests\n- **Environment Management**: python-dotenv for managing environment variables\n- **Logging**: Structured logging to both console and file\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgements\n\n- [LangChain](https://github.com/langchain-ai/langchain) for the agent framework\n- [Model Context Protocol](https://modelcontextprotocol.io/) for the standardized tool invocation\n- [Ollama](https://ollama.ai/) for local LLM capabilities\n- [Exa](https://exa.ai/) for web search capabilities\n- [FireCrawl](https://firecrawl.dev/) for web content retrieval ",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AshDevFr--discourse-mcp-server": {
          "owner": "AshDevFr",
          "name": "discourse-mcp-server",
          "url": "https://github.com/AshDevFr/discourse-mcp-server",
          "imageUrl": "https://github.com/AshDevFr.png",
          "description": "Search posts on a Discourse forum using the Model Context Protocol for enhanced access to discussions and user engagement.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:56.935411",
          "collection_timestamp": "2025-10-02T15:10:50.884871",
          "stars": 6,
          "forks": 4,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2025-03-10T21:47:18Z",
          "updated_at": "2025-08-19T12:04:15Z",
          "open_issues": 3,
          "readme_content": "# Discourse MCP Server\n\nNode.js server implementing Model Context Protocol (MCP) for Discourse search operation.\n\n## Features\n\n- Search Posts on a Discourse forum using MCP protocol.\n\n## API\n\n### Tools\n\n- **search_posts**\n    - Search posts on a Discourse forum\n    - Input: `query` (string)\n    - Returns an array of post objects\n\n## Usage with Claude Desktop\nAdd this to your `claude_desktop_config.json`:\n\n### Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"discourse\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"DISCOURSE_API_URL=https://try.discourse.org\",\n        \"-e\", \"DISCOURSE_API_KEY=1234\",\n        \"-e\", \"DISCOURSE_API_USERNAME=ash\",\n        \"ashdev/discourse-mcp-server\"\n      ]\n    }\n  }\n}\n```\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"discourse\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@ashdev/discourse-mcp-server\"\n      ],\n      \"env\": {\n        \"DISCOURSE_API_URL\": \"https://try.discourse.org\",\n        \"DISCOURSE_API_KEY\": \"1234\",\n        \"DISCOURSE_API_USERNAME\": \"ash\" \n      }\n    }\n  }\n}\n```\n\n## Build\n\nDocker build:\n\n```bash\ndocker build -t ashdev/discourse-mcp-server .\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "asusevski--opendota-mcp-server": {
          "owner": "asusevski",
          "name": "opendota-mcp-server",
          "url": "https://github.com/asusevski/opendota-mcp-server",
          "imageUrl": "https://github.com/asusevski.png",
          "description": "Access real-time Dota 2 statistics, match data, and player profiles through a standard interface. Retrieve hero statistics and insights into professional players and teams effortlessly.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:57.773174",
          "collection_timestamp": "2025-10-02T15:10:58.394659",
          "stars": 4,
          "forks": 6,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-03-02T23:28:59Z",
          "updated_at": "2025-03-12T22:32:05Z",
          "open_issues": 3,
          "readme_content": "# OpenDota MCP Server\n\nA Model Context Protocol (MCP) server implementation for accessing OpenDota API data. This server enables LLMs and AI assistants to retrieve real-time Dota 2 statistics, match data, player information, and more through a standard interface.\n\n## Features\n\n- Access player profiles, statistics, and match history\n- Retrieve detailed match information \n- Look up professional players and teams\n- Get hero statistics and rankings\n- Search for players by name\n- And more!\n\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/asusevski/opendota-mcp-server.git\ncd opendota-mcp-server\n\n# Option 1: Automated setup (works with bash, zsh, and other shells)\n./scripts/setup_env.sh\n\n# Option 2: Manual installation with uv\nuv add pyproject.toml\n\n# For development dependencies\nuv pip install -e \".[dev]\"\n```\n\n## Usage\n\n### Setting up your environment\n\n1. (Optional but recommended) Create an OpenDota API key at https://www.opendota.com/api-keys\n2. Set your API key as an environment variable:\n\n```bash\nexport OPENDOTA_API_KEY=your_api_key_here\n```\n\n### Running the server directly\n\n```bash\npython -m src.opendota_server.server\n```\n\n### Running the server with Claude Desktop\n\nFollow this: https://modelcontextprotocol.io/quickstart/user\n\nIf you use WSL, assuming you have cloned the repo and set up the python environment, this is how I wrote the claude_desktop_config.json:\n\n```json\n{\n  \"mcpServers\": {\n    \"opendota\": {\n      \"command\": \"wsl.exe\",\n      \"args\": [\n        \"--\",\n        \"bash\",\n        \"-c\",\n        \"cd ~/opendota-mcp-server && source .venv/bin/activate && python src/opendota_server/server.py\"\n      ]\n    }\n  }\n}\n```\n\n### Using the example client\n\n```bash\npython -m src.client\n```\n\n### Specific tools included:\n  - get_player_by_id - Retrieve player information by account ID\n  - get_player_recent_matches - Get recent matches for a player\n  - get_match_data - Get detailed data for a specific match\n  - get_player_win_loss - Get win/loss statistics for a player\n  - get_player_heroes - Get a player's most played heroes\n  - get_hero_stats - Get statistics for heroes\n  - search_player - Search for players by name\n  - get_pro_players - Get list of professional players\n  - get_pro_matches - Get recent professional matches\n  - get_player_peers - Get players who have played with a specified player\n  - get_heroes - Get list of all Dota 2 heroes\n  - get_player_totals - Get player's overall stats totals\n  - get_player_rankings - Get player hero rankings\n  - get_player_wordcloud - Get most common words used by player in chat\n  - get_team_info - Get information about a team\n  - get_public_matches - Get recent public matches\n  - get_match_heroes - Get heroes played in a specific match\n\n## License\n\nMIT\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "assafelovic--gptr-mcp": {
          "owner": "assafelovic",
          "name": "gptr-mcp",
          "url": "https://github.com/assafelovic/gptr-mcp",
          "imageUrl": "https://github.com/assafelovic.png",
          "description": "Autonomously explores and validates numerous sources for relevant, trustworthy, and up-to-date information to enhance research capabilities. Optimizes context usage to provide comprehensive insights for research projects.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:58.854650",
          "collection_timestamp": "2025-10-02T15:12:10.425561",
          "stars": 251,
          "forks": 34,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-30T16:47:15Z",
          "updated_at": "2025-09-30T11:41:56Z",
          "open_issues": 9,
          "readme_content": "<div align=\"center\" id=\"top\">\n\n<img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/20af8286-b386-44a5-9a83-3be1365139c3\" alt=\"Logo\" width=\"80\">\n\n# üîç GPT Researcher MCP Server\n\n[![Website](https://img.shields.io/badge/Official%20Website-gptr.dev-teal?style=for-the-badge&logo=world&logoColor=white&color=0891b2)](https://gptr.dev)\n[![Documentation](https://img.shields.io/badge/Documentation-DOCS-f472b6?logo=googledocs&logoColor=white&style=for-the-badge)](https://docs.gptr.dev/docs/gpt-researcher/mcp-server/getting-started)\n[![Discord Follow](https://dcbadge.vercel.app/api/server/QgZXvJAccX?style=for-the-badge&theme=clean-inverted&?compact=true)](https://discord.gg/QgZXvJAccX)\n\n</div>\n\n## Why GPT Researcher MCP?\n\nWhile LLM apps can access web search tools with MCP, **GPT Researcher MCP delivers deep research results.** Standard search tools return raw results requiring manual filtering, often containing irrelevant sources and wasting context window space.\n\nGPT Researcher autonomously explores and validates numerous sources, focusing only on relevant, trusted and up-to-date information. Though slightly slower than standard search (~30 seconds wait), it delivers:\n\n- ‚ú® Higher quality information\n- üìä Optimized context usage\n- üîé Comprehensive results\n- üß† Better reasoning for LLMs\n\n## üíª Claude Desktop Demo\nhttps://github.com/user-attachments/assets/ef97eea5-a409-42b9-8f6d-b82ab16c52a8\n\n## üöÄ Quick Start with Claude Desktop\n\n**Want to use this with Claude Desktop right away?** Here's the fastest path:\n\n1. **Install dependencies:**\n   ```bash\n   git clone https://github.com/assafelovic/gptr-mcp.git\n   pip install -r requirements.txt\n   ```\n\n2. **Set up your Claude Desktop config** at `~/Library/Application Support/Claude/claude_desktop_config.json`:\n   ```json\n   {\n     \"mcpServers\": {\n       \"gptr-mcp\": {\n         \"command\": \"python\",\n         \"args\": [\"/absolute/path/to/gpt-researcher/gptr-mcp/server.py\"],\n         \"env\": {\n           \"OPENAI_API_KEY\": \"your-openai-key-here\",\n           \"TAVILY_API_KEY\": \"your-tavily-key-here\"\n         }\n       }\n     }\n   }\n   ```\n\n3. **Restart Claude Desktop** and start researching! üéâ\n\nFor detailed setup instructions, see the [full Claude Desktop Integration section](#-claude-desktop-integration) below.\n\n### Resources\n- `research_resource`: Get web resources related to a given task via research.\n\n### Primary Tools\n\n- `deep_research`: Performs deep web research on a topic, finding the most reliable and relevant information\n- `quick_search`: Performs a fast web search optimized for speed over quality, returning search results with snippets. Supports any GPTR supported web retriever such as Tavily, Bing, Google, etc... Learn more [here](https://docs.gptr.dev/docs/gpt-researcher/search-engines)\n- `write_report`: Generate a report based on research results\n- `get_research_sources`: Get the sources used in the research\n- `get_research_context`: Get the full context of the research\n\n### Prompts\n\n- `research_query`: Create a research query prompt\n\n## Prerequisites\n\nBefore running the MCP server, make sure you have:\n\n1. Python 3.11 or higher installed\n   - **Important**: GPT Researcher >=0.12.16 requires Python 3.11+\n2. API keys for the services you plan to use:\n   - [OpenAI API key](https://platform.openai.com/api-keys)\n   - [Tavily API key](https://app.tavily.com)\n\nYou can also connect any other web search engines or MCP using GPTR supported retrievers. Check out the [docs here](https://docs.gptr.dev/docs/gpt-researcher/search-engines)\n\n## ‚öôÔ∏è Installation\n\n1. Clone the GPT Researcher repository:\n```bash\ngit clone https://github.com/assafelovic/gpt-researcher.git\ncd gpt-researcher\n```\n\n2. Install the gptr-mcp dependencies:\n```bash\ncd gptr-mcp\npip install -r requirements.txt\n```\n\n3. Set up your environment variables:\n   - Copy the `.env.example` file to create a new file named `.env`:\n   ```bash\n   cp .env.example .env\n   ```\n   - Edit the `.env` file and add your API keys and configure other settings:\n   ```bash\n   OPENAI_API_KEY=your_openai_api_key\n   TAVILY_API_KEY=your_tavily_api_key\n   ```\nYou can also add any other env variable for your GPT Researcher configuration.\n\n## üöÄ Running the MCP Server\n\nYou can run the MCP server in several ways:\n\n### Method 1: Directly using Python\n\n```bash\npython server.py\n```\n\n### Method 2: Using the MCP CLI (if installed)\n\n```bash\nmcp run server.py\n```\n\n### Method 3: Using Docker (recommended for production)\n\n#### Quick Start\n\nThe simplest way to run with Docker:\n\n```bash\n# Build and run with docker-compose\ndocker-compose up -d\n\n# Or manually:\ndocker build -t gptr-mcp .\ndocker run -d \\\n  --name gptr-mcp \\\n  -p 8000:8000 \\\n  --env-file .env \\\n  gptr-mcp\n```\n\n#### For n8n Integration\n\nIf you need to connect to an existing n8n network:\n\n```bash\n# First, start the container\ndocker-compose up -d\n\n# Then connect to your n8n network\ndocker network connect n8n-mcp-net gptr-mcp\n\n# Or create a shared network first\ndocker network create n8n-mcp-net\ndocker network connect n8n-mcp-net gptr-mcp\n```\n\n**Note**: The Docker image uses Python 3.11 to meet the requirements of gpt-researcher >=0.12.16. If you encounter errors during the build, ensure you're using the latest Dockerfile from this repository.\n\nOnce the server is running, you'll see output indicating that the server is ready to accept connections. You can verify it's working by:\n\n1. **SSE Endpoint**: Access the Server-Sent Events endpoint at http://localhost:8000/sse to get a session ID\n2. **MCP Communication**: Use the session ID to send MCP messages to http://localhost:8000/messages/?session_id=YOUR_SESSION_ID\n3. **Testing**: Run the test script with `python test_mcp_server.py`\n\n**Important for Docker/n8n Integration:**\n- The server binds to `0.0.0.0:8000` to work with Docker containers\n- Uses SSE transport for web-based MCP communication  \n- Session management requires getting a session ID from `/sse` endpoint first\n- Each client connection needs a unique session ID for proper communication\n\n## üö¶ Transport Modes & Best Practices\n\nThe GPT Researcher MCP server supports multiple transport protocols and automatically chooses the best one for your environment:\n\n### Transport Types\n\n| Transport | Use Case | When to Use |\n|-----------|----------|-------------|\n| **STDIO** | Claude Desktop, Local MCP clients | Default for local development |\n| **SSE** | Docker, Web clients, n8n integration | Auto-enabled in Docker |\n| **Streamable HTTP** | Modern web deployments | Advanced web deployments |\n\n### Automatic Detection\n\nThe server automatically detects your environment:\n\n```bash\n# Local development (default)\npython server.py\n# ‚ûú Uses STDIO transport (Claude Desktop compatible)\n\n# Docker environment  \ndocker run gptr-mcp\n# ‚ûú Auto-detects Docker, uses SSE transport\n\n# Manual override\nexport MCP_TRANSPORT=sse\npython server.py\n# ‚ûú Forces SSE transport\n```\n\n### Environment Variables\n\n| Variable | Description | Default | Example |\n|----------|-------------|---------|---------|\n| `MCP_TRANSPORT` | Force specific transport | `stdio` | `sse`, `streamable-http` |\n| `DOCKER_CONTAINER` | Force Docker mode | Auto-detected | `true` |\n\n### Configuration Examples\n\n#### For Claude Desktop (Local)\n```json\n// ~/Library/Application Support/Claude/claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"gpt-researcher\": {\n      \"command\": \"python\",\n      \"args\": [\"/absolute/path/to/server.py\"],\n      \"env\": {\n         \"...\"\n      }\n    }\n  }\n}\n```\n\n#### For Docker/Web Deployment\n```bash\n# Set transport explicitly for web deployment\nexport MCP_TRANSPORT=sse\npython server.py\n\n# Or use Docker (auto-detects)\ndocker-compose up -d\n```\n\n#### For n8n MCP Integration\n```bash\n# Use the container name as hostname\ndocker run --name gptr-mcp -p 8000:8000 gptr-mcp\n\n# In n8n, connect to: http://gptr-mcp:8000/sse\n```\n\n### Transport Endpoints\n\nWhen using SSE or HTTP transports:\n\n- **Health Check**: `GET /health`\n- **SSE Endpoint**: `GET /sse` (get session ID)\n- **MCP Messages**: `POST /messages/?session_id=YOUR_SESSION_ID`\n\n### Best Practices\n\n1. **Local Development**: Use default STDIO for Claude Desktop\n2. **Production**: Use Docker with automatic SSE detection\n3. **Testing**: Use health endpoints to verify connectivity\n4. **n8n Integration**: Always use container networking with Docker\n5. **Web Deployment**: Consider Streamable HTTP for modern clients\n\n## Integrating with Claude\n\nYou can integrate your MCP server with Claude using:\n\n**[Claude Desktop Integration](https://docs.gptr.dev/docs/gpt-researcher/mcp-server/claude-integration)** - For using with Claude desktop application on Mac\n\nFor detailed instructions, follow the link above.\n\n## üíª Claude Desktop Integration\n\nTo integrate your locally running MCP server with Claude for Mac, you'll need to:\n\n1. Make sure the MCP server is installed and running\n2. Configure Claude Desktop:\n   - Locate or create the configuration file at `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Add your local GPT Researcher MCP server to the configuration **with environment variables**\n   - Restart Claude to apply the configuration\n\n### ‚ö†Ô∏è Important: Environment Variables Required\n\nClaude Desktop launches your MCP server as a separate subprocess, so you **must** explicitly pass your API keys in the configuration. The server cannot access your shell's environment variables or `.env` file automatically.\n\n### Configuration Example\n\n```json\n{\n  \"mcpServers\": {\n    \"gptr-mcp\": {\n      \"command\": \"python\",\n      \"args\": [\"/absolute/path/to/your/server.py\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-actual-openai-key-here\",\n        \"TAVILY_API_KEY\": \"your-actual-tavily-key-here\"\n      }\n    }\n  }\n}\n```\n\n### Security Note\n\n**üîí Your Claude Desktop config contains sensitive API keys.** Protect it:\n\n```bash\nchmod 600 ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\nNever commit this file to version control.\n\n### Alternative: Environment Variable Script\n\nFor better security, create a wrapper script:\n\n**run_gptr_mcp.sh**:\n```bash\n#!/bin/bash\nsource /path/to/your/.env\npython /absolute/path/to/server.py\n```\n\nThen use it in Claude Desktop:\n```json\n{\n  \"mcpServers\": {\n    \"gptr-mcp\": {\n      \"command\": \"/absolute/path/to/run_gptr_mcp.sh\"\n    }\n  }\n}\n```\n\nFor complete step-by-step instructions, see the [Claude Desktop Integration guide](https://docs.gptr.dev/docs/gpt-researcher/mcp-server/claude-integration).\n\n## üìù Example Usage with Claude\n\n```\nUser: I'm considering investing in NVIDIA. Can you research the current state of the company, recent stock performance, latest product announcements, and analyst opinions?\n\nClaude: I'll help you research NVIDIA for investment purposes. This will take a moment as I conduct deep research to find the most up-to-date information about their stock performance, recent developments, and expert analysis.\n\n[Claude uses deep_research tool - this takes 30-40 seconds]\n\nClaude: Based on my research, here's a comprehensive analysis of NVIDIA's current state:\n\n## NVIDIA (NVDA) Current Status\n\n### Recent Stock Performance\n- Current price: $942.89 (as of my research)\n- YTD performance: +90.4% \n- 52-week range: $460.30 - $974.00\n- Market cap: ~$2.32 trillion\n\n### Recent Key Developments\n1. **Blackwell AI Platform**: At GTC 2024, NVIDIA unveiled the Blackwell architecture, their next-generation AI chip platform promising 4x performance improvement over Hopper. Major cloud providers (AWS, Google, Microsoft) have already committed to integrating Blackwell.\n\n2. **Q1 FY2025 Earnings (May 2024)**: \n   - Revenue: $26.0 billion (+262% YoY)\n   - Data Center revenue: $22.6 billion (+427% YoY)\n   - Gross margin: 78.4%\n   - Announced 10-for-1 stock split effective June 7, 2024\n\n3. **Supply Chain Expansion**: Increased investments in manufacturing capacity with TSMC to address ongoing chip shortages for their high-demand AI GPUs.\n\n### Analyst Consensus\n- Strong Buy consensus with 37 analysts rating it \"Buy,\" 5 \"Hold,\" and 0 \"Sell\"\n- Average price target: $1,042 (post-split adjusted: $104.20)\n- Key bull thesis: Continued AI infrastructure spending and NVIDIA's dominant position in AI chips\n- Key bear concerns: Valuation, potential competition from AMD, Intel, and custom silicon from tech giants\n\n### Industry Position\n- Dominant in AI GPU market with estimated 80-90% market share\n- Expanding ecosystem through CUDA software platform and industry partnerships\n- Diversifying beyond chips with DGX Cloud, AI software platforms, and automotive solutions\n```\n\n## üîß Troubleshooting\n\nIf you encounter issues while running the MCP server:\n\n### General Issues\n\n1. **API Keys**: Make sure your API keys are correctly set in the `.env` file\n2. **Python Version**: Check that you're using Python 3.11 or higher (required by gpt-researcher >=0.14.0)  \n3. **Dependencies**: Ensure all dependencies are installed correctly: `pip install -r requirements.txt`\n4. **Server Logs**: Check the server logs for error messages\n\n### Docker Issues\n\n1. **Container not accessible**: \n   - Verify the container is running: `docker ps | grep gptr-mcp`\n   - Check container logs: `docker logs gptr-mcp`\n   - Confirm the server is binding to 0.0.0.0:8000 (logs should show this)\n\n2. **n8n Integration Issues**:\n   - Ensure both containers are on the same Docker network\n   - Use the container name `gptr-mcp` as the hostname in n8n\n   - Set the MCP server URL to: `http://gptr-mcp:8000/sse`\n\n3. **Session ID Issues**:\n   - The server uses SSE transport which requires session management\n   - First, get a session ID by connecting to `/sse` endpoint\n   - Use the session ID in subsequent MCP requests: `/messages/?session_id=YOUR_ID`\n   - Each client needs its own session ID\n\n### n8n MCP Integration Steps\n\n1. **Get Session ID**:\n   ```bash\n   curl http://gptr-mcp:8000/sse\n   # Look for: data: /messages/?session_id=XXXXX\n   ```\n\n2. **Initialize MCP**:\n   ```bash\n   curl -X POST http://gptr-mcp:8000/messages/?session_id=YOUR_SESSION_ID \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {\"roots\": {\"listChanged\": true}}, \"clientInfo\": {\"name\": \"n8n-client\", \"version\": \"1.0.0\"}}}'\n   ```\n\n3. **Call Tools**:\n   ```bash\n   curl -X POST http://gptr-mcp:8000/messages/?session_id=YOUR_SESSION_ID \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/call\", \"params\": {\"name\": \"quick_search\", \"arguments\": {\"query\": \"test\"}}}'\n   ```\n\n### Testing the Server\n\nRun the included test script to verify functionality:\n\n```bash\npython test_mcp_server.py\n```\n\nThis will test:\n- SSE connection and session ID retrieval\n- MCP initialization  \n- Tool discovery and execution\n\n### Claude Desktop Issues\n\nIf your MCP server isn't working with Claude Desktop:\n\n1. **Server not appearing in Claude**:\n   - Check your `claude_desktop_config.json` syntax is valid JSON\n   - Ensure you're using **absolute paths** (not relative)\n   - Verify the path to `server.py` is correct\n   - Restart Claude Desktop completely\n\n2. **\"OPENAI_API_KEY not found\" error**:\n   - Make sure you added API keys to the `env` section in your config\n   - Don't forget **both** `OPENAI_API_KEY` and `TAVILY_API_KEY`\n   - API keys should be the actual keys, not placeholders\n\n3. **Tools not showing up**:\n   - Look for the üîß tools icon in Claude Desktop\n   - Check that Claude Desktop config file is in the right location:\n     - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n     - **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n4. **Python/Permission issues**:\n   - Make sure Python is accessible from the command line: `python --version`\n   - Try using full Python path: `\"command\": \"/usr/bin/python3\"` or `\"command\": \"python3\"`\n   - Check file permissions on your server.py file\n\n5. **Still not working?**\n   - Test the server manually: `python server.py` (should show STDIO transport message)\n   - Check Claude Desktop logs (if available)\n   - Try the alternative script method from the integration section above\n\n## üë£ Next Steps\n\n- Explore the [MCP protocol documentation](https://docs.anthropic.com/claude/docs/model-context-protocol) to better understand how to integrate with Claude\n- Learn about [GPT Researcher's core features](https://docs.gptr.dev/docs/gpt-researcher/getting-started/introduction) to enhance your research capabilities\n- Check out the [Advanced Usage](https://docs.gptr.dev/docs/gpt-researcher/mcp-server/advanced-usage) guide for more configuration options\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## üìû Support / Contact\n\n- [Community Discord](https://discord.gg/QgZXvJAccX)\n- Email: assaf.elovic@gmail.com\n\n<p align=\"right\">\n  <a href=\"#top\">‚¨ÜÔ∏è Back to Top</a>\n</p>\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "atlas-comstock--hika-mcp-server": {
          "owner": "atlas-comstock",
          "name": "hika-mcp-server",
          "url": "https://github.com/atlas-comstock/hika-mcp-server",
          "imageUrl": "https://github.com/atlas-comstock.png",
          "description": "Provides real-time streaming of AI-generated knowledge and perspectives through the Server-Sent Events (SSE) protocol, enhancing user search experiences by offering diverse cognitive insights.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:32:59.731695",
          "collection_timestamp": "2025-10-02T15:12:18.554850",
          "stars": 0,
          "forks": 1,
          "license": "No License",
          "language": null,
          "created_at": "2025-04-04T02:57:30Z",
          "updated_at": "2025-09-03T22:51:14Z",
          "open_issues": 1,
          "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/atlas-comstock-hika-mcp-server-badge.png)](https://mseep.ai/app/atlas-comstock-hika-mcp-server)\n\n# Hika MCP Server\n\n## Overview\n\nHika MCP Server is a Server-Sent Events (SSE) implementation for the Hika AI knowledge search tool. This server component facilitates real-time streaming of AI-generated perspectives and knowledge extensions to enhance the search experience.\n\nHika AI is a knowledge search tool that uses artificial intelligence to provide multiple cognitive perspectives (MCP) on search queries, helping users to broaden their understanding by exploring related knowledge domains or diving deeper into specific aspects of their questions.\n\n## Features\n\n- Real-time streaming of AI-generated content via SSE protocol\n- Multiple cognitive perspectives to enhance knowledge exploration\n- Authentication via JWT Bearer tokens\n- Easy integration with the Hika AI ecosystem\n\n## Prerequisites\n\n- Node.js (v14.0.0 or higher)\n- Understanding of Server-Sent Events (SSE)\n- Valid Hika AI authentication credentials\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/hikaai/mcp-server.git\ncd mcp-server\n\n# Install dependencies\nnpm install\n\n# Set up environment variables\ncp .env.example .env\n# Edit .env with your credentials\n```\n\n## Configuration\n\nSet the following environment variables:\n\n```\nPORT=3000\nHIKA_API_URL=https://api.hika.fyi\nJWT_SECRET=your_jwt_secret\n```\n\nOr use the provided configuration in your application:\n\n```javascript\n{\n  \"command\": \"\",\n  \"url\": \"https://hika.fyi/api/mcp/sse\",\n  \"env\": {\n    \"HIKA_AUTH\": \"Bearer your_jwt_token_here\"\n  }\n}\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\nnpm start\n```\n\n### Client Connection Example\n\n```javascript\nconst eventSource = new EventSource('https://hika.fyi/api/mcp/sse', {\n  headers: {\n    'Authorization': 'Bearer your_jwt_token_here'\n  }\n});\n\neventSource.onmessage = (event) => {\n  const data = JSON.parse(event.data);\n  console.log('Received perspective:', data);\n};\n\neventSource.onerror = (error) => {\n  console.error('SSE connection error:', error);\n  eventSource.close();\n};\n```\n\n## API Reference\n\n### SSE Endpoint\n\n```\nGET /api/mcp/sse\n```\n\n#### Headers\n\n- `Authorization`: Bearer token for authentication\n\n#### Events\n\nThe server emits the following event types:\n\n1. `perspective` - New AI-generated perspective on the search query\n2. `knowledge_extension` - Additional related knowledge domain\n3. `deep_dive` - In-depth analysis of a specific aspect\n4. `completion` - Signals the end of the stream\n\n#### Event Data Format\n\n```json\n{\n  \"type\": \"perspective\",\n  \"content\": {\n    \"title\": \"Historical Context\",\n    \"description\": \"Looking at the question from a historical perspective...\",\n    \"relevance_score\": 0.85\n  }\n}\n```\n\n## Authentication\n\nThe server uses JWT Bearer tokens for authentication. Tokens should be included in the `Authorization` header as follows:\n\n```\nAuthorization: Bearer eyJhbGciOiJFUzM4NCIsInR5cCI6ImF0K2p3dCIs...\n```\n\n## Error Handling\n\nThe server may return the following error codes:\n\n- `401` - Unauthorized (invalid or expired token)\n- `429` - Too Many Requests (rate limit exceeded)\n- `500` - Internal Server Error\n\n## Development\n\n### Running in Development Mode\n\n```bash\nnpm run dev\n```\n\n### Running Tests\n\n```bash\nnpm test\n```\n\n## Integration with Hika AI\n\nThis server component is designed to work seamlessly with the Hika AI knowledge search tool. When integrated, it provides real-time AI-generated perspectives that help users:\n\n- Quickly extend their knowledge into related domains\n- Explore different viewpoints on the same question\n- Dive deeper into specific aspects of complex topics\n\n## License\n\n[MIT License](LICENSE)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Support\n\nFor support, please contact support@hika.fyi or open an issue on GitHub.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "AudienseCo--mcp-tweetbinder": {
          "owner": "AudienseCo",
          "name": "mcp-tweetbinder",
          "url": "https://github.com/AudienseCo/mcp-tweetbinder",
          "imageUrl": "https://github.com/null.png",
          "description": "Access Twitter analytics and reporting data, enabling analysis of hashtags, users, and conversations. Generate detailed reports with engagement metrics and sentiment analysis in real-time.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:00.766518",
          "collection_timestamp": "2025-10-02T15:12:25.916931",
          "stars": 0,
          "forks": 0,
          "license": "Unknown",
          "language": "Unknown",
          "created_at": "",
          "updated_at": "",
          "open_issues": 0,
          "readme_content": "",
          "github_success": false,
          "github_error": "HTTP Error: 404 Client Error: Not Found for url: https://api.github.com/repos/AudienseCo/mcp-tweetbinder (Status: 404)",
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "babo072--schoolfoods": {
          "owner": "babo072",
          "name": "schoolfoods",
          "url": "https://github.com/babo072/schoolfoods",
          "imageUrl": "https://github.com/babo072.png",
          "description": "Retrieve school meal information by accessing detailed meal data through school names and dates, supporting various date formats. The server handles duplicate school names and provides suggestions for similar names to improve user experience.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:01.573564",
          "collection_timestamp": "2025-10-02T15:12:33.960849",
          "stars": 0,
          "forks": 1,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2025-04-07T03:25:53Z",
          "updated_at": "2025-04-07T04:18:17Z",
          "open_issues": 2,
          "readme_content": "# SchoolFoods\n\nSchoolFoodsÎäî Ï†ÑÍµ≠ ÌïôÍµêÏùò Í∏âÏãù Ï†ïÎ≥¥Î•º Ï°∞ÌöåÌï† Ïàò ÏûàÎäî ÏÑúÎπÑÏä§ÏûÖÎãàÎã§. Model Context Protocol(MCP)ÏùÑ ÏßÄÏõêÌïòÎ©∞, Îã§ÏñëÌïú Î∞©ÏãùÏúºÎ°ú ÌïôÍµê Í∏âÏãù Ï†ïÎ≥¥Î•º ÏâΩÍ≤å Ï°∞ÌöåÌï† Ïàò ÏûàÏäµÎãàÎã§.\n\n## Ï£ºÏöî Í∏∞Îä•\n\n- ÌïôÍµêÎ™ÖÏúºÎ°ú Í∏âÏãù Ï†ïÎ≥¥ Ï°∞Ìöå\n- Îã§ÏñëÌïú ÎÇ†Ïßú ÌòïÏãù ÏßÄÏõê (Ïò§Îäò, ÎÇ¥Ïùº, Î™®Î†à, YYYYMMDD)\n- ÎèôÏùºÌïú Ïù¥Î¶ÑÏùò ÌïôÍµê Í≤ÄÏÉâ Î∞è Ï†ïÎ≥¥ Ï†úÍ≥µ\n- Ïú†ÏÇ¨Ìïú ÌïôÍµêÎ™Ö Ï∂îÏ≤ú Í∏∞Îä•\n- Model Context Protocol(MCP) ÏßÄÏõê\n\n## ÏÑ§Ïπò Î∞©Î≤ï\n\n1. Ï†ÄÏû•ÏÜå ÌÅ¥Î°†\n```bash\ngit clone https://github.com/ÏÇ¨Ïö©ÏûêÎ™Ö/schoolfoods.git\ncd schoolfoods\n```\n\n2. ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò\n```bash\nnpm install\n```\n\n3. Îç∞Ïù¥ÌÑ∞ Ìè¥Îçî ÌôïÏù∏\n```\nschoolfoods/data Ìè¥ÎçîÏóê ÌïôÍµê Ï†ïÎ≥¥ JSON ÌååÏùºÏù¥ ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§.\n```\n\n## ÏÇ¨Ïö© Î∞©Î≤ï\n\n### ÏÑúÎ≤Ñ Ïã§Ìñâ\n```bash\nnode index.js\n```\n\n### MCP ÌîÑÎ°úÌÜ†ÏΩúÎ°ú Ïã§Ìñâ\n```bash\nnode index.js stdio\n```\n\n### ÌÖåÏä§Ìä∏ Ïã§Ìñâ\n```bash\n# Í∏∞Î≥∏ Í∏∞Îä• ÌÖåÏä§Ìä∏\nnode simple-test.js\n\n# Ï§ëÎ≥µ ÌïôÍµêÎ™Ö ÌÖåÏä§Ìä∏\nnode test-duplication.js\n```\n\n## API ÏÇ¨Ïö© ÏòàÏãú\n\n### MCP ÎèÑÍµ¨ Ìò∏Ï∂ú\n```javascript\n// MCP ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÏÑú ÌïôÍµê Í∏âÏãù Ï†ïÎ≥¥ ÏöîÏ≤≠\nconst response = await client.callTool(\"get_school_meal\", {\n  school_name: \"ÏÑúÏö∏Í≥†Îì±ÌïôÍµê\",\n  date: \"Ïò§Îäò\"\n});\n```\n\n## ÎèÑÍµ¨ ÏÑ§Î™Ö\n\n### get_school_meal\nÌïôÍµêÎ™ÖÍ≥º ÎÇ†ÏßúÎ•º ÏûÖÎ†•Î∞õÏïÑ Í∏âÏãù Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§.\n\n**ÏûÖÎ†• ÌååÎùºÎØ∏ÌÑ∞**:\n- `school_name`: ÌïôÍµê Ïù¥Î¶Ñ (Ïòà: \"ÏùòÏ†ïÎ∂ÄÍ≥†Îì±ÌïôÍµê\")\n- `date`: Í∏âÏãù Ï°∞Ìöå ÎÇ†Ïßú (YYYYMMDD ÌòïÏãù, 'Ïò§Îäò', 'ÎÇ¥Ïùº', 'Î™®Î†à' Îì±)\n\n**ÏùëÎãµ**:\n- Ï°∞Ïãù, Ï§ëÏãù, ÏÑùÏãù Ï†ïÎ≥¥\n- ÏπºÎ°úÎ¶¨ Ï†ïÎ≥¥\n- ÍµêÏú°Ï≤≠ Ï†ïÎ≥¥\n\n## Ï§ëÎ≥µ ÌïôÍµêÎ™Ö Ï≤òÎ¶¨\n\nÍ∞ôÏùÄ Ïù¥Î¶ÑÏùò ÌïôÍµêÍ∞Ä Ïó¨Îü¨ ÏßÄÏó≠Ïóê ÏûàÎäî Í≤ΩÏö∞, Î™®Îì† ÌïôÍµêÏùò Í∏âÏãù Ï†ïÎ≥¥Î•º Ìï®Íªò Ï†úÍ≥µÌï©ÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥ \"ÏÇºÏÑ±Ï¥àÎì±ÌïôÍµê\"Îäî Ï†ÑÍµ≠Ïóê 9Í∞úÍ∞Ä ÏûàÏúºÎ©∞, Ïù¥ Í≤ΩÏö∞ Í∞Å ÍµêÏú°Ï≤≠Î≥Ñ Î™®Îì† ÌïôÍµêÏùò Í∏âÏãù Ï†ïÎ≥¥Î•º ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§.\n\n## Îç∞Ïù¥ÌÑ∞ Ï∂úÏ≤ò\n\nÎ≥∏ ÏÑúÎπÑÏä§Îäî [ÎÇòÏù¥Ïä§ ÍµêÏú°Ï†ïÎ≥¥ Í∞úÎ∞© Ìè¨ÌÑ∏](https://open.neis.go.kr)Ïùò Í∏âÏãùÏãùÎã®Ï†ïÎ≥¥Î•º ÌôúÏö©Ìï©ÎãàÎã§.\n\n## ÎùºÏù¥ÏÑºÏä§\n\nÏù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî MIT ÎùºÏù¥ÏÑºÏä§ ÌïòÏóê Î∞∞Ìè¨Îê©ÎãàÎã§. ÏûêÏÑ∏Ìïú ÎÇ¥Ïö©ÏùÄ [LICENSE](LICENSE) ÌååÏùºÏùÑ Ï∞∏Ï°∞ÌïòÏÑ∏Ïöî. ",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "baidu-maps--mcp": {
          "owner": "baidu-maps",
          "name": "mcp",
          "url": "https://github.com/baidu-maps/mcp",
          "imageUrl": "https://github.com/baidu-maps.png",
          "description": "Provides access to various map services including geocoding, reverse geocoding, and route planning through the Baidu Map API, compatible with the MCP protocol.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:02.740346",
          "collection_timestamp": "2025-10-02T15:12:37.087782",
          "stars": 347,
          "forks": 41,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-20T07:10:14Z",
          "updated_at": "2025-10-02T02:53:11Z",
          "open_issues": 12,
          "readme_content": "<div align=\"center\">\n  <p>\n      <img align=\"center\" src=\"img/logo.png\", width=700></a>\n  </p>\n\n<!-- language -->\n[‰∏≠Êñá](./README_zh.md)| English \n\n<!-- icon -->\n<br>\n\n[![stars](https://img.shields.io/github/stars/baidu-maps/mcp?color=ccf)](https://github.com/baidu-maps/mcp)\n![python](https://img.shields.io/badge/python-3.10ÔΩû3.12-aff.svg)\n[![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)\n[![pypi](https://img.shields.io/pypi/v/mcp-server-baidu-maps)](https://pypi.org/project/mcp-server-baidu-maps/)\n[![npm](https://img.shields.io/npm/v/@baidumap/mcp-server-baidu-map)](https://www.npmjs.com/package/@baidumap/mcp-server-baidu-map)\n\n</div>\n<br>\n\n## üöÄ Introduction\n\n**Baidu Map MCP Server** is a fully MCP-compliant, open-source Location-Based Service (LBS) solution, providing a comprehensive suite of geospatial APIs and tools for developers and AI agents. As the first map service provider in China to support the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction), Baidu Map MCP Server bridges the gap between large language models (LLMs), AI agents, and real-world location data and services.\n\nWith Baidu Map MCP Server, you can easily empower your applications, LLMs, and agents with advanced mapping, geocoding, POI search, route planning, weather, traffic, and more ‚Äî all via standardized, developer-friendly MCP interfaces.\n\n**Key Features:**\n- **Full MCP Protocol Support:** Seamless integration with any MCP-compliant agent, LLM, or platform.\n- **Rich LBS Capabilities:** Geocoding, reverse geocoding, POI search, route planning (driving, walking, cycling, transit), weather, IP location, real-time traffic, and more.\n- **Cross-Platform SDKs:** Official Python and TypeScript SDKs, easy CLI and cloud deployment.\n- **Enterprise-Grade Data:** Powered by Baidu Maps' authoritative, up-to-date geospatial data.\n- **High Performance & Stability:** Recommended SSE (Server-Sent Events) access for low latency and high reliability.\n- **Open Source & Extensible:** MIT licensed, easy to customize and extend.\n\nWhether you are building a travel assistant, logistics platform, smart city solution, or an LLM-powered agent, Baidu Map MCP Server provides the essential geospatial intelligence and tools you need.\n\nThe MCP Server architecture enables:\n- **Seamless AI Integration**: Allows LLMs and agents to understand and process location data naturally\n- **Contextual Understanding**: Provides rich geospatial context for more intelligent decision-making\n- **Standardized Interfaces**: Consistent API design following MCP principles for easy integration\n- **Scalable Implementation**: Suitable for projects of any size, from small applications to enterprise solutions\n\nWhether you're building a navigation app, delivery service, smart city solution, or enhancing an AI agent with location awareness, Baidu Map MCP Server provides the tools and infrastructure you need to succeed.\n\n\n## üõ†Ô∏è Supported Tools & APIs\n\nBaidu Map MCP Server provides the following MCP-compliant APIs (tools):\n\n| Tool Name                | Description                                                                                  |\n|--------------------------|----------------------------------------------------------------------------------------------|\n| `map_geocode`            | Convert address to geographic coordinates.                                                   |\n| `map_reverse_geocode`    | Get address, region, and POI info from coordinates.                                         |\n| `map_search_places`      | Search for global POIs by keyword, type, region, or within a radius.                               |\n| `map_place_details`      | Get detailed info for a POI by its unique ID.                                               |\n| `map_directions_matrix`  | Batch route planning for multiple origins/destinations (driving, walking, cycling).         |\n| `map_directions`         | Plan routes between two points (driving, walking, cycling, transit).                        |\n| `map_weather`            | Query real-time and forecast weather by region or coordinates.                              |\n| `map_ip_location`        | Locate city and coordinates by IP address.                                                  |\n| `map_road_traffic`       | Query real-time traffic conditions for roads or regions.                                    |\n| `map_poi_extract`*       | Extract POI info from free text (requires advanced permission).                             |\n\n> *Some advanced features require additional permissions. See [Authorization](#authorization) for details.\n\nAll APIs follow the MCP protocol and can be called from any MCP-compliant client, LLM, or agent platform.\n\n## ‚ö° Quick Start\n\n### 1. Get Your API Key\n\nRegister and create a server-side API Key (AK) at [Baidu Maps Open Platform](https://lbsyun.baidu.com/apiconsole/key).\n**Be sure to enable ‚ÄúMCP (SSE)‚Äù service for best performance.**\n\n### 2. Python Integration\n\nInstall the SDK:\n```bash\npip install mcp-server-baidu-maps\n```\n\n**Run as a script:**\n```bash\npython -m mcp_server_baidu_maps\n```\n\n**Configure in your MCP client (e.g., Claude, Cursor):**\n```json\n{\n  \"mcpServers\": {\n    \"baidu-maps\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_server_baidu_maps\"],\n      \"env\": {\n        \"BAIDU_MAPS_API_KEY\": \"<YOUR_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\n### 3. Node.js/TypeScript Integration\n\nInstall:\n```bash\nnpm install @baidumap/mcp-server-baidu-map\n```\n\n**Configure in your MCP client:**\n```json\n{\n  \"mcpServers\": {\n    \"baidu-map\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@baidumap/mcp-server-baidu-map\"\n      ],\n      \"env\": {\n        \"BAIDU_MAP_API_KEY\": \"<YOUR_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\n### 4. Recommended: Use SSE for low-latency, stable access\n\nSee [SSE Quickstart](https://lbsyun.baidu.com/faq/api?title=mcpserver/quickstart).\n\n### 5. More Platforms\n\n- **Claude/Agent/ÂçÉÂ∏ÜAppBuilder**: See [README_zh.md](./README_zh.md) for detailed integration guides and advanced configuration.\n\n---\n\n## üöÄ Advanced Use Cases\n\n- **Travel Planning Assistant:**  \n  Use `map_search_places`, `map_directions`, and `map_weather` to build an agent that plans optimal sightseeing routes, checks weather, and recommends POIs.\n\n- **Batch Route Matrix:**  \n  Use `map_directions_matrix` to calculate multiple routes and durations for logistics or delivery optimization.\n\n- **Text-to-POI Extraction:**  \n  Use `map_poi_extract` to extract POIs from user input or travel notes (requires advanced permission).\n\n- **Real-time Traffic & Weather-aware Navigation:**  \n  Combine `map_road_traffic` and `map_weather` for dynamic, context-aware travel suggestions.\n\n- **Integration with Claude, Qianfan, AppBuilder:**  \n  Seamlessly connect Baidu Map MCP Server to LLMs and agent frameworks for natural language geospatial reasoning.\n\n**See [README_zh.md](./README_zh.md) for more detailed Chinese documentation, configuration, and examples.**\n\n---\n\n## ‚õ∞Ô∏è Advanced Tutorials\n- [Geocoding API Guide](https://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding)\n- [POI Search API Guide](https://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-placeapi)\n- [Route Planning API Guide](https://lbsyun.baidu.com/index.php?title=webapi/direction-api)\n- [MCP Integration Guide](https://lbsyun.baidu.com/index.php?title=mcp/guide)\n- [SDK Development Guide](https://lbsyun.baidu.com/index.php?title=mcp/sdk)\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors\n\n<a href=\"https://github.com/baidu-maps/mcp/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=baidu-maps/mcp&max=400&columns=20\"  width=\"200\"/>\n</a>\n\n\n## üåü Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=baidu-maps/mcp&type=Date)](https://star-history.com/#baidu-maps/mcp&Date)\n\n\n## üìÑ License\n[MIT](./LICENSE) ¬© baidu-maps\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp",
          "npm_downloads": 17508,
          "npm_package_name": "mcp",
          "npm_success": true,
          "npm_error": null
        },
        "baidubce--app-builder": {
          "owner": "baidubce",
          "name": "app-builder",
          "url": "https://github.com/baidubce/app-builder",
          "imageUrl": "https://github.com/baidubce.png",
          "description": "Integrates Baidu's search capabilities with AI language models to provide intelligent, real-time responses and information retrieval. Customizable features support various search scenarios with options for persona settings, model selection, and query enhancements.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:03.627165",
          "collection_timestamp": "2025-10-02T15:12:41.188599",
          "stars": 554,
          "forks": 134,
          "license": "Apache License 2.0",
          "language": "Python",
          "created_at": "2023-12-05T01:48:12Z",
          "updated_at": "2025-09-29T07:54:19Z",
          "open_issues": 20,
          "readme_content": "<div align=\"center\">\n<img src='docs/image/logo.png' alt='logo' width='700' >\n<br>\n\n[![License](https://img.shields.io/badge/license-Apache%202-blue.svg)](LICENSE)\n![Supported Python versions](https://img.shields.io/badge/python-3.9+-orange.svg)\n![Supported OSs](https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-yellow.svg)\n</div>\n\nÁÆÄ‰Ωì‰∏≠Êñá | [English](./docs/README_en.md) | [Êó•Êú¨Ë™û](./docs/README_ja.md)\n\n<br>\n\n\n## ‰ªÄ‰πàÊòØAppBuilder-SDK\n\nÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder-SDKÊòØ[ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder](https://appbuilder.cloud.baidu.com/)Èù¢ÂêëAIÂéüÁîüÂ∫îÁî®ÂºÄÂèëËÄÖÊèê‰æõÁöÑ‰∏ÄÁ´ôÂºèÂºÄÂèëÂπ≥Âè∞ÁöÑÂÆ¢Êà∑Á´ØSDK„ÄÇ\n\n### AppBuilder-SDK ÊúâÂì™‰∫õÂäüËÉΩÔºü\n\nÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder-SDKÊèê‰æõ‰∫Ü‰ª•‰∏ãAIÂ∫îÁî®ÂºÄÂèëËÄÖÁöÑÂøÖÂ§áÂäüËÉΩÔºö\n\n- **Ë∞ÉÁî®**\n    - Ë∞ÉÁî®Â§ßÊ®°ÂûãÔºåÂèØËá™Áî±Ë∞ÉÁî®ÊÇ®Âú®[ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜÂ§ßÊ®°ÂûãÂπ≥Âè∞](https://qianfan.cloud.baidu.com/)ÁöÑÊ®°ÂûãÔºåÂºÄÂèëÂπ∂Ë∞É‰ºòprompt\n    - Ë∞ÉÁî®ËÉΩÂäõÁªÑ‰ª∂ÔºåÊèê‰æõ40+‰∏™Ê∫ê‰∫éÁôæÂ∫¶ÁîüÊÄÅÁöÑ[‰ºòË¥®ÁªÑ‰ª∂](https://cloud.baidu.com/doc/AppBuilder/s/Glqb6dfiz#3%E3%80%81%E5%BC%80%E9%80%9A%E7%BB%84%E4%BB%B6%E6%9C%8D%E5%8A%A1)ÔºåËµãËÉΩAgentÂ∫îÁî®\n    - Ë∞ÉÁî®AIÂéüÁîüÂ∫îÁî®ÔºåÈÄöËøá[AppBuilderClient](/docs/BasisModule/Platform/Application/appbuilder_client.md)ÂèØËÆøÈóÆÂπ∂ÁÆ°ÁêÜÂú®ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder[ÁΩëÈ°µÁ´Ø](https://console.bce.baidu.com/ai_apaas/app)ÂèëÂ∏ÉÁöÑAIÂéüÁîüÂ∫îÁî®ÔºåÂπ∂ÂèØÊ≥®ÂÜåÊú¨Âú∞ÂáΩÊï∞ËÅîÂä®Á´Ø‰∫ëÁªÑ‰ª∂\n- **ÁºñÊéí**\n    - ÈÖçÁΩÆÁü•ËØÜÂ∫ìÔºåÈÄöËøá[KnowledgeBase](/docs/BasisModule/Platform/KnowledgeBase/knowledgebase.md)ÁÆ°ÁêÜÁü•ËØÜÂ∫ìÔºåËøõË°åÊñáÊ°£ÂèäÁü•ËØÜÂàáÁâáÁöÑÂ¢ûÂà†ÊîπÊü•ÔºåÈÖçÂêà[ÁΩëÈ°µÁ´Ø](https://console.bce.baidu.com/ai_apaas/app)ÂºÄÂèë‰∫ß‰∏öÁ∫ßÁöÑ`RAG`Â∫îÁî®\n    - ÁºñÊéíÂ∑•‰ΩúÊµÅÔºåÊèê‰æõ‰∫Ü`Message`„ÄÅ`Component`„ÄÅ`AgentRuntime`Â§öÁ∫ßÂ∑•‰ΩúÊµÅÊäΩË±°ÔºåÂÆûÁé∞Â∑•‰ΩúÊµÅÁºñÊéíÔºåÂπ∂ÂèØ‰∏éLangChain„ÄÅOpenAIÁ≠â‰∏öÁïåÁîüÊÄÅËÉΩÂäõÊâìÈÄö\n- **ÁõëÊéß**\n    - Êèê‰æõ‰∫ÜÂèØËßÜÂåñTracing„ÄÅËØ¶ÁªÜDebugLogÁ≠âÁõëÊéßÂ∑•ÂÖ∑ÔºåÂä©ÂäõÂºÄÂèëËÄÖÂú®Áîü‰∫ßÁéØÂ¢ÉÂ∫îÁî®\n- **ÈÉ®ÁΩ≤**\n    - `AgentRuntime`ÊîØÊåÅÈÉ®ÁΩ≤‰∏∫Âü∫‰∫é`Flask`‰∏é`gunicorn`ÁöÑAPIÊúçÂä°\n    - `AgentRuntime`ÊîØÊåÅÈÉ®ÁΩ≤‰∏∫Âü∫‰∫é`Chainlit`ÁöÑÂØπËØùÊ°Ü‰∫§‰∫íÂâçÁ´Ø\n    - Êèê‰æõ‰∫Ü`appbuilder_bce_deploy`Â∑•ÂÖ∑ÔºåÂèØÂø´ÈÄüÈÉ®ÁΩ≤Á®ãÂ∫èÂà∞ÁôæÂ∫¶‰∫ëÔºåÊèê‰æõÂÖ¨ÁΩëAPIÊúçÂä°ÔºåËÅîÂä®AppBuilderÂ∑•‰ΩúÊµÅ\n\n### ‰ΩøÁî® AppBuilder-SDK ÂèØ‰ª•ÊûÑÂª∫‰ªÄ‰πàÂ∫îÁî®Ôºü\n\n#### **‰∫ß‰∏öÁ∫ßRAGÂ∫îÁî®**\n\nAppBuilder-SDKÊèê‰æõÂ§öÁ±ªÂûãÁªÑ‰ª∂ÔºåË¶ÜÁõñ‰ª•‰∏ãÊûÑÂª∫‰∫ß‰∏öÁ∫ß`RAG`Â∫îÁî®ÁöÑÂÆåÊï¥Ê≠•È™§Ôºö\n- ÊñáÊ°£Ëß£ÊûêÔºàParserÔºâ\n- ÊñáÊ°£ÂàáÁâáÔºàChunkerÔºâ\n- ÂàáÁâáÂêëÈáèÂåñÔºàEmbeddingÔºâ\n- Á¥¢ÂºïÊûÑÂª∫ÔºàIndexingÔºâ\n- ÂàáÁâáÂè¨ÂõûÔºàRetrievalÔºâ\n- Á≠îÊ°àÁîüÊàêÔºàAnswer GenerationÔºâ\n\nAppBuilder-SDK‰∏ç‰ªÖÊèê‰æõ‰∫ÜÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÊèê‰æõÁöÑÂü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ÔºåÂêåÊó∂Êèê‰æõÁªèËøáÊ∑±Â∫¶‰ºòÂåñÁöÑÂ§ßÊ®°ÂûãÈ´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ÔºåÂèØ‰ª•ÁªÑÂêà‰∏ãË°®Êèê‰æõÁöÑÂéüÂ≠êËÉΩÂäõÁªÑ‰ª∂ÔºåÊûÑÂª∫‰∏™ÊÄßÂåñÁöÑRAGÂ∫îÁî®[RAG ÂéüÂ≠êËÉΩÂäõ CookBook](./cookbooks/end2end_application/rag/rag.ipynb)Ôºö\n\n\n| Èò∂ÊÆµ |ÁªÑ‰ª∂ÂêçÁß∞ | ÁªÑ‰ª∂Á±ªÂûã |ÁªÑ‰ª∂ÈìæÊé• |\n|--------|--------|--------|---|\n| ÊñáÊ°£Ëß£Êûê | ÊñáÊ°£Áü´Ê≠£Â¢ûÂº∫ (DocCropEnhance) | Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/doc_crop_enhance/README.md) |\n| ÊñáÊ°£Ëß£Êûê | ÊñáÊ°£Ê†ºÂºèËΩ¨Êç¢ (DocFormatConverter) | Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/doc_format_converter/README.md)|\n| ÊñáÊ°£Ëß£Êûê | ÊñáÊ°£Ëß£ÊûêÔºàDocParserÔºâ| Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/doc_parser/README.md) |\n| ÊñáÊ°£Ëß£Êûê | Ë°®Ê†ºÊäΩÂèñÁªÑ‰ª∂ÔºàExtractTableFromDocÔºâ| Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/extract_table/README.md) |\n| ÊñáÊ°£Ëß£Êûê | ÈÄöÁî®ÊñáÂ≠óËØÜÂà´-È´òÁ≤æÂ∫¶ÁâàÔºàGeneralOCRÔºâ| Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/general_ocr/README.md) |\n| ÊñáÊ°£ÂàáÁâá | ÊñáÊ°£ÂàáÂàÜÔºàDocSplitterÔºâ| Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/doc_splitter/README.md) |\n| ÂàáÁâáÂêëÈáèÂåñ | ÂêëÈáèËÆ°ÁÆóÔºàEmbeddingÔºâ | Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/embeddings/README.md) |\n| Á¥¢ÂºïÊûÑÂª∫ÂèäÂàáÁâáÂè¨Âõû | ÂêëÈáèÊ£ÄÁ¥¢-VectorDBÔºàBaiduVectorDBRetrieverÔºâ | Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/retriever/baidu_vdb/README.md) |\n| Á¥¢ÂºïÊûÑÂª∫ÂèäÂàáÁâáÂè¨Âõû | ÂêëÈáèÊ£ÄÁ¥¢-BESÔºàBaiduElasticSearchRetrieverÔºâ | Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/retriever/bes/README.md) |\n| ÊñáÊ°£ÂàáÁâáÂèäÁ≠îÊ°àÁîüÊàê | ÈóÆÁ≠îÂØπÊåñÊéòÔºàQAPairMiningÔºâ| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/qa_pair_mining/README.md) |\n| ÊñáÊ°£ÂàáÁâáÂèäÁ≠îÊ°àÁîüÊàê | Áõ∏‰ººÈóÆÁîüÊàêÔºàSimilarQuestionÔºâ| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/similar_question/README.md) |\n| Á≠îÊ°àÁîüÊàê| Ê†áÁ≠æÊäΩÂèñÔºàTagExtractionÔºâ| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/tag_extraction/README.md) |\n| Á≠îÊ°àÁîüÊàê | Â§çÊùÇQueryÂà§ÂÆöÔºàIsComplexQueryÔºâ| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/is_complex_query/README.md) |\n| Á≠îÊ°àÁîüÊàê | Â§çÊùÇQueryÂàÜËß£ÔºàQueryDecompositionÔºâ| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/query_decomposition/README.md) |\n| Á≠îÊ°àÁîüÊàê | Â§öËΩÆÊîπÂÜô (QueryRewrite)| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/query_rewrite/README.md) |\n| Á≠îÊ°àÁîüÊàê | ÈòÖËØªÁêÜËß£ÈóÆÁ≠îÔºàMRCÔºâ| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/mrc/README.md) |\n| Á≠îÊ°àÁîüÊàê | ÂπªËßâÊ£ÄÊµãÔºàHallucination DetectionÔºâ| È´òÁ∫ßËÉΩÂäõÁªÑ‰ª∂ | [ÈìæÊé•](./python/core/components/llms/hallucination_detection/README.md) |\n\n\n\n\n\n##  Â¶Ç‰ΩïÂÆâË£ÖAppBuilder-SDK\n\n#### ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder-SDK ÊúÄÊñ∞ÁâàÊú¨ 1.1.0 (2025-06-20)\n\nÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder-SDK Êõ¥Êñ∞ËÆ∞ÂΩï&ÊúÄÊñ∞ÁâπÊÄßËØ∑Êü•ÈòÖÊàë‰ª¨ÁöÑ[ÁâàÊú¨ËØ¥Êòé](/docs/DevelopGuide/ChangeLog/changelog.md)\n\n- `Python`ÁâàÊú¨ÂÆâË£ÖÔºåË¶ÅÊ±ÇPythonÁâàÊú¨ >= `3.9`\n\n```bash\npython3 -m pip install --upgrade appbuilder-sdk\n```\n- `Java` Âèä `Go` ÁâàÊú¨ÂÆâË£ÖÔºå‰ª•ÂèäÈÄöËøá`Docker`ÈïúÂÉè‰ΩøÁî®ÔºåËØ∑Êü•ÈòÖ[ÂÆâË£ÖËØ¥Êòé](/docs/QuickStart/StartFirstAINativeApplication/install.md)\n\n\n## Âø´ÈÄüÂºÄÂßã‰Ω†ÁöÑAIÂéüÁîüÂ∫îÁî®ÂºÄÂèë‰πãÊóÖ\n> - ËØ∑Âú®`>=3.9`ÁöÑPythonÁéØÂ¢ÉÂÆâË£Ö`appbuilder-sdk`Âêé‰ΩøÁî®ËØ•Á´ØÂà∞Á´ØÂ∫îÁî®Á§∫‰æã\n> - Á§∫‰æã‰∏≠‰ΩøÁî®ËØ∑ÊõøÊç¢‰∏∫ÊÇ®ÁöÑ‰∏™‰∫∫Token\n\n\n### 1. Ë∞ÉÁî®Â§ßÊ®°Âûã\n- ‰ΩøÁî®`Playground`ÁªÑ‰ª∂ÂèØËá™Áî±Ë∞ÉÁî®ÔºåÊÇ®Âú®ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜÂ§ßÊ®°ÂûãÂπ≥Âè∞ÊúâÊùÉÈôêÁöÑ‰ªª‰ΩïÊ®°ÂûãÔºåÂπ∂ÂèØËá™ÂÆö‰πâ`prompt`Ê®°Êùø ‰∏é Ê®°ÂûãÂèÇÊï∞\n\n#### ‰ª£Á†ÅÁ§∫‰æã\n\n```python\nimport appbuilder\nimport os\n\n# ËÆæÁΩÆÁéØÂ¢É‰∏≠ÁöÑTOKENÔºåËØ∑ÊõøÊç¢‰∏∫ÊÇ®ÁöÑ‰∏™‰∫∫TOKEN\nos.environ[\"APPBUILDER_TOKEN\"] = \"your api key\"\n\n# ÂÆö‰πâpromptÊ®°Êùø\ntemplate_str = \"‰Ω†ÊâÆÊºî{role}, ËØ∑ÂõûÁ≠îÊàëÁöÑÈóÆÈ¢ò„ÄÇ\\n\\nÈóÆÈ¢òÔºö{question}„ÄÇ\\n\\nÂõûÁ≠îÔºö\"\n\n# ÂÆö‰πâËæìÂÖ•ÔºåË∞ÉÁî®playgroundÁªÑ‰ª∂\ninput = appbuilder.Message({\"role\": \"javaÂ∑•Á®ãÂ∏à\", \"question\": \"ËØ∑ÁÆÄË¶ÅÂõûÁ≠îjavaËØ≠Ë®ÄÁöÑÂÜÖÂ≠òÂõûÊî∂Êú∫Âà∂ÊòØ‰ªÄ‰πàÔºåË¶ÅÊ±Ç100Â≠ó‰ª•ÂÜÖ\"})\n\nplayground = appbuilder.Playground(prompt_template=template_str, model=\"Qianfan-Agent-Speed-8K\")\n\n# ‰ª•ÊâìÂ≠óÊú∫ÁöÑÊñπÂºèÔºåÊµÅÂºèÂ±ïÁ§∫Â§ßÊ®°ÂûãÂõûÁ≠îÂÜÖÂÆπ\noutput = playground(input, stream=True, temperature=1e-10)\nfor stream_message in output.content:\n    print(stream_message)\n    \n# ÊµÅÂºèËæìÂá∫ÁªìÊùüÂêéÔºåÂèØÂÜçÊ¨°ÊâìÂç∞ÂÆåÊï¥ÁöÑÂ§ßÊ®°ÂûãÂØπËØùÁªìÊûúÔºåÈô§ÂõûÁ≠îÂÜÖÂÆπÂ§ñÔºåËøòÂåÖÊã¨tokenÁöÑÁî®ÈáèÊÉÖÂÜµ\nprint(output.model_dump_json(indent=4))\n\n```\n#### ÂõûÁ≠îÂ±ïÁ§∫\n\n```shell\nJavaËØ≠Ë®ÄÁöÑ\nÂÜÖÂ≠òÂõûÊî∂Êú∫Âà∂ÊòØÈÄöËøáÂûÉÂúæÂõûÊî∂Âô®ÔºàGarbage CollectorÔºâÊù•ÂÆûÁé∞ÁöÑ„ÄÇ\nÂûÉÂúæÂõûÊî∂Âô®‰ºöËá™Âä®Ê£ÄÊµã‰∏çÂÜç‰ΩøÁî®ÁöÑÂØπË±°ÔºåÂπ∂ÈáäÊîæÂÖ∂Âç†Áî®ÁöÑÂÜÖÂ≠òÁ©∫Èó¥Ôºå‰ªéËÄåÁ°Æ‰øùÁ≥ªÁªüÁöÑÂÜÖÂ≠ò‰∏ç‰ºöË¢´ËÄóÂ∞Ω„ÄÇ\nJavaÊèê‰æõ‰∫ÜÂ§öÁßçÂûÉÂúæÂõûÊî∂Âô®ÔºåÂ¶Ç‰∏≤Ë°åÂõûÊî∂Âô®„ÄÅÂπ∂Ë°åÂõûÊî∂Âô®„ÄÅCMSÂõûÊî∂Âô®ÂíåG1ÂõûÊî∂Âô®Á≠âÔºå‰ª•Êª°Ë∂≥‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑÊÄßËÉΩÈúÄÊ±Ç\n„ÄÇ\n\n{\n    \"content\": \"JavaËØ≠Ë®ÄÁöÑÂÜÖÂ≠òÂõûÊî∂Êú∫Âà∂ÊòØÈÄöËøáÂûÉÂúæÂõûÊî∂Âô®ÔºàGarbage CollectorÔºâÊù•ÂÆûÁé∞ÁöÑ„ÄÇÂûÉÂúæÂõûÊî∂Âô®‰ºöËá™Âä®Ê£ÄÊµã‰∏çÂÜç‰ΩøÁî®ÁöÑÂØπË±°ÔºåÂπ∂ÈáäÊîæÂÖ∂Âç†Áî®ÁöÑÂÜÖÂ≠òÁ©∫Èó¥Ôºå‰ªéËÄåÁ°Æ‰øùÁ≥ªÁªüÁöÑÂÜÖÂ≠ò‰∏ç‰ºöË¢´ËÄóÂ∞Ω„ÄÇJavaÊèê‰æõ‰∫ÜÂ§öÁßçÂûÉÂúæÂõûÊî∂Âô®ÔºåÂ¶Ç‰∏≤Ë°åÂõûÊî∂Âô®„ÄÅÂπ∂Ë°åÂõûÊî∂Âô®„ÄÅCMSÂõûÊî∂Âô®ÂíåG1ÂõûÊî∂Âô®Á≠âÔºå‰ª•Êª°Ë∂≥‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑÊÄßËÉΩÈúÄÊ±Ç„ÄÇ\",\n    \"name\": \"msg\",\n    \"mtype\": \"dict\",\n    \"id\": \"2bbee989-40e3-45e4-9802-e144cdc829a9\",\n    \"extra\": {},\n    \"token_usage\": {\n        \"prompt_tokens\": 35,\n        \"completion_tokens\": 70,\n        \"total_tokens\": 105\n    }\n}\n```\n\n### 2. Ë∞ÉÁî®ËÉΩÂäõÁªÑ‰ª∂\n- SDKÊèê‰æõ‰∫Ü40+‰∏™Ê∫ê‰∫éÁôæÂ∫¶ÁîüÊÄÅÁöÑ‰ºòË¥®ÁªÑ‰ª∂ÔºåÂàóË°®ÂèØËßÅ[ÁªÑ‰ª∂ÂàóË°®](https://cloud.baidu.com/doc/AppBuilder/s/Glqb6dfiz#3%E3%80%81%E5%BC%80%E9%80%9A%E7%BB%84%E4%BB%B6%E6%9C%8D%E5%8A%A1), Ë∞ÉÁî®ÂâçÈúÄË¶ÅÁî≥È¢Ü[ÂÖçË¥πËØïÁî®È¢ùÂ∫¶](https://console.bce.baidu.com/ai-engine/old/#/ai/ocr/overview/resource/list)\n- Á§∫‰æã‰∏≠ÁöÑÁªÑ‰ª∂‰∏∫`RAG with Baidu SearchÂ¢ûÂº∫Áâà`, ÁªìÂêàÁôæÂ∫¶ÊêúÁ¥¢ÁöÑÊêúÁ¥¢ÂºïÊìéÊäÄÊúØÂíåERNIEÊ®°ÂûãÁöÑËØ≠‰πâÁêÜËß£ËÉΩÂäõÔºåÂèØ‰ª•Êõ¥ÂáÜÁ°ÆÂú∞ÁêÜËß£Áî®Êà∑ÁöÑÊêúÁ¥¢ÊÑèÂõæÔºåÂπ∂Êèê‰æõ‰∏éÊêúÁ¥¢Êü•ËØ¢Áõ∏ÂÖ≥ÊÄßÊõ¥È´òÁöÑÊêúÁ¥¢ÁªìÊûú\n\n#### ‰ª£Á†ÅÁ§∫‰æã\n```python\nimport appbuilder\nimport os\n\n# ËÆæÁΩÆÁéØÂ¢É‰∏≠ÁöÑTOKENÔºå‰ΩøÁî®ËØ∑ÊõøÊç¢‰∏∫ÊÇ®ÁöÑ‰∏™‰∫∫TOKEN\nos.environ[\"APPBUILDER_TOKEN\"] = \"your api key\"\n\nrag_with_baidu_search_pro = appbuilder.RagWithBaiduSearchPro(model=\"ERNIE-3.5-8K\")\n\ninput = appbuilder.Message(\"9.11Âíå9.8Âì™‰∏™Â§ß\")\nresult = rag_with_baidu_search_pro.run(\n    message=input,\n    instruction=appbuilder.Message(\"‰Ω†ÊòØ‰∏ì‰∏öÁü•ËØÜÂä©Êâã\"))\n\n# ËæìÂá∫ËøêË°åÁªìÊûú\nprint(result.model_dump_json(indent=4))\n```\n\n#### ÂõûÁ≠îÂ±ïÁ§∫\n```shell\n{\n    \"content\": \"9.11Â∞è‰∫é9.8„ÄÇÂú®ÊØîËæÉ‰∏§‰∏™Â∞èÊï∞ÁöÑÂ§ßÂ∞èÊó∂ÔºåÈúÄË¶ÅÈÄê‰ΩçÊØîËæÉÂÆÉ‰ª¨ÁöÑÊï∞ÂÄºÔºåÂåÖÊã¨Êï¥Êï∞ÈÉ®ÂàÜÂíåÂ∞èÊï∞ÈÉ®ÂàÜ„ÄÇÂØπ‰∫é9.11Âíå9.8ÔºåÊï¥Êï∞ÈÉ®ÂàÜÈÉΩÊòØ9ÔºåÊâÄ‰ª•ÈúÄË¶ÅÂú®Â∞èÊï∞ÈÉ®ÂàÜËøõË°åÊØîËæÉ„ÄÇÂ∞èÊï∞ÁÇπÂêéÁöÑÁ¨¨‰∏Ä‰ΩçÊòØ1Âíå8ÔºåÊòæÁÑ∂1Â∞è‰∫é8ÔºåÊâÄ‰ª•9.11Â∞è‰∫é9.8„ÄÇ\",\n    \"name\": \"msg\",\n    \"mtype\": \"dict\",\n    \"id\": \"eb31b7de-dd6a-485f-adb9-1f7921a6f4bf\",\n    \"extra\": {\n        \"search_baidu\": [\n            {\n                \"content\": \"Â§ßÊ®°Âûã‚ÄòÊô∫ÂïÜ‚ÄôÂèóË¥®Áñë:9.11 vs 9...\",\n                \"icon\": \"https://appbuilder.bj.bcebos.com/baidu-search-rag-pro/icon/souhu.ico\",\n                \"url\": \"https://m.sohu.com/a/793754123_121924584/\",\n                \"ref_id\": \"2\",\n                \"site_name\": \"ÊêúÁãêÁΩë\",\n                \"title\": \"Â§ßÊ®°Âûã‚ÄòÊô∫ÂïÜ‚ÄôÂèóË¥®Áñë:9.11 vs 9.8ÁöÑÊØîËæÉÊè≠Á§∫AIÁêÜËß£ËÉΩÂäõÁöÑ...\"\n            },\n            {\n                \"content\": \"Á©∂Á´ü|9.11ÊØî9.8Â§ß?Â§ßÊ®°Âûã‰ª¨‰∏∫‰Ωï‰ºö...\",\n                \"icon\": \"https://appbuilder.bj.bcebos.com/baidu-search-rag-pro/icon/tencent.svg.png\",\n                \"url\": \"https://new.qq.com/rain/a/20240717A07JLV00\",\n                \"ref_id\": \"4\",\n                \"site_name\": \"ËÖæËÆØÁΩë\",\n                \"title\": \"Á©∂Á´ü|9.11ÊØî9.8Â§ß?Â§ßÊ®°Âûã‰ª¨‰∏∫‰Ωï‰ºöÂú®Â∞èÂ≠¶Êï∞Â≠¶È¢ò‰∏äÈõÜ‰Ωì...\"\n            },\n            ...\n        ]\n    },\n    \"token_usage\": {\n        \"completion_tokens\": 77,\n        \"prompt_tokens\": 2008,\n        \"total_tokens\": 2085\n    }\n}\n```\n\n\n### 3. Ë∞ÉÁî®AIÂéüÁîüÂ∫îÁî®\n- Á§∫‰æã‰∏≠ÁöÑÂ∫îÁî®‰∏∫Ôºö[ËØ¥Âî±ÂØºÂ∏à](https://appbuilder.baidu.com/s/3qfjXy7k)ÔºåÁÇπÂáªËØ•ËøûÊé•Âú®ÁΩëÈ°µÁ´ØËØïÁî®\n\n#### ‰ª£Á†ÅÁ§∫‰æã\n\n```python\nimport appbuilder\nimport os\n\n# ËÆæÁΩÆÁéØÂ¢É‰∏≠ÁöÑTOKENÔºåËØ∑ÊõøÊç¢‰∏∫ÊÇ®ÁöÑ‰∏™‰∫∫TOKEN\nos.environ[\"APPBUILDER_TOKEN\"] = \"your api key\"\n\n# ‰ªéAppBuilderÁΩëÈ°µËé∑ÂèñÂπ∂‰º†ÂÖ•Â∫îÁî®IDÔºå‰ª•‰∏ã‰∏∫ËØ¥Âî±ÂØºÂ∏àÂ∫îÁî®ID\napp_id = \"4678492a-5864-472e-810a-654538d3503c\"\n\napp_builder_client = appbuilder.AppBuilderClient(app_id)\nconversation_id = app_builder_client.create_conversation()\n\nanswer = app_builder_client.run(conversation_id, \"‰ª•‚Äú‰∏äÁè≠ÁãºÁãàÂç¥ÂèàËøΩÈÄêÊ¢¶ÊÉ≥‚Äú‰∏∫‰∏ªÈ¢òËøõË°å‰∏ÄÈ¶ñËØ¥Âî±Âàõ‰ΩúÔºå‰øùÊåÅÊäºÈüµ, ÊéßÂà∂Âú®200Â≠ó‰ª•ÂÜÖ\")\nprint(answer.content.answer)\n```\n\n#### ÂõûÁ≠îÂ±ïÁ§∫\n```shell\nÂ•ΩÁöÑÔºåÊàë‰ª¨Êù•‰ª•‚Äú‰∏äÁè≠ÁãºÁãàÂç¥ÂèàËøΩÈÄêÊ¢¶ÊÉ≥‚Äù‰∏∫‰∏ªÈ¢òÔºåËøõË°å‰∏ÄÊÆµÁÆÄÁü≠ÁöÑËØ¥Âî±Âàõ‰Ωú„ÄÇËøôÈáåÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÁ§∫‰æãÔºå‰Ω†ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÊÑüËßâËøõË°åË∞ÉÊï¥Ôºö\n\nIntro:\nÊúù‰πùÊôö‰∫îÔºåÁîüÊ¥ªÈáçÂéãÔºå\nÁãºÁãà‰∏äÁè≠ÔºåÂç¥ÂøÉÊÄÄÊ¢¶ÊÉ≥Ôºå\nÊØè‰∏ÄÂ§©ÔºåÈÉΩÊòØÊñ∞ÁöÑÊåëÊàòÔºå\n‰∏∫‰∫ÜÈÇ£Êú™Êù•ÔºåÊàëÂ•ãÂèëÂêëÂâç„ÄÇ\n\nVerse 1:\nÁ©ø‰∏äË•øË£ÖÔºåÊâìÂ•ΩÈ¢ÜÂ∏¶Ôºå\nÊ≠•ÂÖ•‰∫∫Áæ§ÔºåÂéªËøΩÈÄêÂêçÂà©Ôºå\nËôΩÁÑ∂ÁãºÁãàÔºåÂç¥‰∏çÊõæË®ÄË¥•Ôºå\nÂõ†‰∏∫ÂøÉ‰∏≠ÔºåÊúâÊ¢¶ÊÉ≥Âú®ÊøÄÂä±„ÄÇ\n\nHook:\n‰∏äÁè≠ÁãºÁãàÔºåÂç¥‰∏çÊõæÊîæÂºÉÔºå\nËøΩÈÄêÊ¢¶ÊÉ≥ÔºåÊòØÊàëÂøÉ‰∏≠ÁöÑÁÅ´ÁÇ¨Ôºå\nÁÖß‰∫ÆÂâçË∑ØÔºåÊåáÂºïÊàëÂâçË°åÔºå\nÊó†ËÆ∫Â§öÈöæÔºåÊàëÈÉΩË¶ÅÂùöÊåÅÂà∞Â∫ï„ÄÇ\n\nËøôÈ¶ñÂ∞èÊõ≤ÂÑø‰ª•‚Äú‰∏äÁè≠ÁãºÁãàÂç¥ÂèàËøΩÈÄêÊ¢¶ÊÉ≥‚Äù‰∏∫‰∏ªÈ¢òÔºåÈÄöËøáÊäºÈüµÁöÑÊñπÂºèË°®Ëææ‰∫Ü‰∏äÁè≠ÊóèËôΩÁÑ∂ÁîüÊ¥ªËâ∞ËæõÔºå‰ΩÜ‰æùÁÑ∂ÊÄÄÊè£Ê¢¶ÊÉ≥ÔºåÂãáÂæÄÁõ¥ÂâçÁöÑÁ≤æÁ•û„ÄÇÂ∏åÊúõ‰Ω†ÂñúÊ¨¢ÔºÅ\n```\n\n#### Êõ¥Â§öÁ§∫‰æã\n\n- Êõ¥Â§öAIÂéüÁîüÂ∫îÁî®Á§∫‰æãÔºåËØ∑ÊµèËßà[Â∫îÁî®ÂπøÂú∫](https://console.bce.baidu.com/ai_apaas/appCenter)\n- Êõ¥Â§ö‰ª£Á†ÅCookbookÔºåËØ∑ÊµèËßà [Cookbooks](./cookbooks/README.md)ÔºåÊàë‰ª¨Êúâ‰ª•‰∏ãcookbookÊé®ËçêÊÇ®‰ºòÂÖàÈòÖËØªÔºö\n\n| Â∫îÁî®Á±ªÂûã |Â∫îÁî®ÈìæÊé• | Êé®ËçêÁêÜÁî± |\n|--|--|--|\n| Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [ÈÄöÁî®ÊñáÂ≠óËØÜÂà´](/cookbooks/components/general_ocr.ipynb) | ‰ΩìÈ™åÁôæÂ∫¶AIÂºÄÊîæÂπ≥Âè∞Êèê‰æõÁöÑÈÄöÁî®ÊñáÂ≠óËØÜÂà´-È´òÁ≤æÂ∫¶ÁâàÁöÑÁ≤æÂáÜËØÜÂà´ÁªìÊûú |\n| Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂ | [Âü∫Á°ÄÁªÑ‰ª∂ÊúçÂä°Âåñ](/cookbooks/components/agent_runtime.ipynb) | Âü∫Á°ÄÁªÑ‰ª∂ÂèØÈÄöËøáflaskÂÆûÁé∞ÊúçÂä°ÂåñÈÉ®ÁΩ≤ Êàñ ÈÄöËøáchainlitÂÆûÁé∞ÂèØ‰∫§‰∫íÁöÑÂâçÁ´ØÈÉ®ÁΩ≤ÔºåÈõÜÊàêÂà∞ÊÇ®ÁöÑÁ≥ªÁªü‰∏≠ |\n| ÊµÅÁ®ãÁºñÊéí |  [Assistant SDK](/cookbooks/pipeline/assistant_function_call.ipynb) | Â≠¶‰π†Â¶Ç‰ΩïÁ∫Ø‰ª£Á†ÅÊÄÅÊê≠Âª∫‰∏Ä‰∏™AgentÂ∫îÁî®ÔºåÂπ∂ÂÆûÁé∞Ëá™ÂÆö‰πâÂ∑•‰ΩúÊµÅÁ®ãÂèäFunctionCall |\n| Á´ØÂà∞Á´ØÂ∫îÁî® |  [AppBuilder Client SDK](/cookbooks/agent_builder.ipynb) | ‰ΩøÁî®AppBuilderÁΩëÈ°µÁ´ØÂàõÂª∫Âπ∂ÂèëÂ∏É‰∏Ä‰∏™AgentÂ∫îÁî®ÂêéÔºåÈÄöËøáAppBuilderClient SDKÈõÜÊàêÂà∞‰Ω†ÁöÑÁ≥ªÁªü‰∏≠ |\n| Á´ØÂà∞Á´ØÂ∫îÁî® |  [AgentÂ∫îÁî®-Â∑•‰ΩúÊµÅAgent](/cookbooks/end2end_application/agent/chatflow.ipynb) | ‰ΩøÁî®AppBuilderÁΩëÈ°µÁ´ØÂàõÂª∫Âπ∂ÂèëÂ∏É‰∏Ä‰∏™Â∑•‰ΩúÊµÅAgentÂ∫îÁî®ÂêéÔºåÈÄöËøáAppBuilderClient SDKÈõÜÊàêÂà∞‰Ω†ÁöÑÁ≥ªÁªü‰∏≠ |\n| Á´ØÂà∞Á´ØÂ∫îÁî® |  [ÈÄöËøáAppBuilder-ToolCallÂäüËÉΩÂÆûÁé∞Á´Ø‰∫ëÁªÑ‰ª∂ËÅîÂä®ÁöÑAgent](/cookbooks/end2end_application/agent/tool_call.ipynb) | Â≠¶‰π†Agent„ÄÅFunctionCallÁöÑÁü•ËØÜÔºåÂπ∂ÊûÑÈÄ†Ë∞ÉÁî®Êú¨Âú∞ÁªÑ‰ª∂ÁöÑAgent |\n| Á´ØÂà∞Á´ØÂ∫îÁî® |  [ÁÆÄÂéÜÁ≠õÈÄâÂ∞èÂä©Êâã](/cookbooks/end2end_application/rag/rag.ipynb) | ÈÄöËøáÂØπÊú¨Âú∞ÁÆÄÂéÜÂ∫ìÁöÑÁÆÄÂéÜËøõË°åËß£Êûê„ÄÅÂàáÁâá„ÄÅÂàõÂª∫Á¥¢ÂºïÔºåÂÆûÁé∞Âü∫‰∫éJDËøõË°åÁÆÄÂéÜÁ≠õÈÄâÔºåÂπ∂ÂØπÁ≠õÈÄâÁöÑTop1ÁÆÄÂéÜËøõË°åÊÄªÁªì |\n| Á´ØÂà∞Á´ØÂ∫îÁî® |  [‰ºÅ‰∏öÁ∫ßÈóÆÁ≠îÁ≥ªÁªü](/cookbooks/end2end_application/rag/qa_system_2_dialogue.ipynb) | Â≠¶‰π†Â¶Ç‰ΩïÈÄöËøáSDK‰∏éÁΩëÈ°µÂπ≥Âè∞Êê≠ÈÖçÔºåÂÆûÁé∞Á¶ªÁ∫øÁü•ËØÜÂ∫ìÁîü‰∫ß‰∏éÂú®Á∫øÈóÆÁ≠î |\n| ËøõÈò∂Â∫îÁî® |  [‰ΩøÁî®appbuilder_bce_deployÈÉ®ÁΩ≤ÂÖ¨Êúâ‰∫ëÊúçÂä°](/cookbooks/advanced_application/cloud_deploy.ipynb) | ‰∏ÄÈîÆÂ∞ÜËá™Â∑±ÁöÑÊúçÂä°ÈÉ®ÁΩ≤Âà∞ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÔºåÈÉ®ÁΩ≤ÂêéÂèØ‰ª•Ëá™Âä®ÁîüÊàêÂÖ¨ÁΩëipÔºåËÅîÂä®Â∑•‰ΩúÊµÅÁöÑAPIËäÇÁÇπ |\n| ËøõÈò∂Â∫îÁî® |  [‰ΩøÁî®appbuilder_trace_serverÂÆûÁé∞ÂØπ‰ΩøÁî®Áä∂ÊÄÅÁöÑË∑üË∏™](/cookbooks/appbuilder_trace/trace.ipynb) | ‰ΩøÁî®Appbuilder-SDK TraceÂäüËÉΩÂÆûÁé∞ÂØπÁªÑ‰ª∂„ÄÅÂ∫îÁî®Ë∞ÉÁî®ÊÉÖÂÜµÁöÑËøΩË∏™|\n\n\n## ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder-SDK ËÉΩÂäõÂÖ®ÊôØÂõæ\n<div align=\"center\">\n<img src='docs/image/structure-cn.png' alt='wechat' width='800' >\n</div>\n\n\n## Áî®Êà∑ÊñáÊ°£\n\n## Github ÊñáÊ°£\n- [È¶ñÈ°µ](https://github.com/baidubce/app-builder/blob/master/docs/README.md)\n    - Âø´ÈÄü‰∏äÊâã: \n        - ÂºÄÂßã‰Ω†ÁöÑÁ¨¨‰∏Ä‰∏™AIÂéüÁîüÂ∫îÁî®: \n            - [ÂÆâË£Ö](https://github.com/baidubce/app-builder/blob/master/docs/QuickStart/StartFirstAINativeApplication/install.md)\n            - [Âø´ÈÄüÂºÄÂßã](https://github.com/baidubce/app-builder/blob/master/docs/QuickStart/StartFirstAINativeApplication/README.md)\n        - ‰∫ß‰∏öÂÆûË∑µÂ∫îÁî®ËåÉ‰æã: \n            - [SDK‰ΩøÁî®Á§∫‰æã](https://github.com/baidubce/app-builder/blob/master/docs/QuickStart/ExamplesOfIndustrialPracticeApplications/README.md)\n        - [SDKÂΩìÂâçÊîØÊåÅÁöÑÁºñÁ®ãËØ≠Ë®Ä](https://github.com/baidubce/app-builder/blob/master/docs/QuickStart/CurrentlySupportedProgrammingLanguages/README.md)\n    - Âü∫Á°Ä:\n        - Ê®°Âûã:\n            - [Ëé∑ÂèñÊ®°ÂûãÂàóË°®](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Model/get_model_list.md)\n        - [ÁªÑ‰ª∂](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Components)\n        - ÁõëÊéß:\n            - [TRACEÂü∫Á°ÄÂäüËÉΩ](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Trace/basic.md)\n            - [TRACEÊãìÂ±ïÂäüËÉΩ](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Trace/phoenix_method.md)\n        - ÈÉ®ÁΩ≤:\n            - [‰∫§‰∫íÂºèÂâçÁ´ØÈÉ®ÁΩ≤](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Deployment/AgentChainlit.md)\n            - [ÂÖ¨Êúâ‰∫ëÈÉ®ÁΩ≤](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Deployment/cloud.md)\n            - [API ËÆøÈóÆ](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Deployment/flask.md)\n            - [AgentRuntime](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Deployment/agentruntime.md)\n            - [UserSession](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Deployment/usersession.md)\n        - Âπ≥Âè∞:\n            - Â∫îÁî®:\n                - [AppBuilderClientÁªÑ‰ª∂](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Platform/Application/appbuilder_client.md)\n                - [Ëé∑ÂèñAppBuilderÂ∑≤ÂèëÂ∏ÉÁöÑÂ∫îÁî®ÂàóË°®](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Platform/Application/get_app_list.md)\n            - Áü•ËØÜÂ∫ì:\n                - [Áü•ËØÜÂ∫ìÁªÑ‰ª∂](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Platform/KnowledgeBase/knowledgebase.md)\n            - Ëá™ÂÆö‰πâÁªÑ‰ª∂:\n                - [Âü∫Á°ÄËÉΩÂäõÁªÑ‰ª∂](https://github.com/baidubce/app-builder/blob/master/docs/BasisModule/Platform/CustomComponents/components.md)\n    - Â∫îÁî®:\n        - Agent:\n            - [Âü∫Á°ÄÁü•ËØÜ](https://github.com/baidubce/app-builder/blob/master/docs/Application/Agent/BasicKnowledge/agent.md)\n            - [‰ΩøÁî®ÂÆòÊñπÁªÑ‰ª∂](https://github.com/baidubce/app-builder/blob/master/docs/Application/Agent/UseOfficialComponents/use_official_components.md)\n            - [ToolCall](https://github.com/baidubce/app-builder/blob/master/docs/Application/Agent/ToolCall/tool_call.md)\n            - [ToolChoice](https://github.com/baidubce/app-builder/blob/master/docs/Application/Agent/ToolChoice/tool_choice.md)\n            - [‰ΩøÁî®ÂºÇÊ≠•ÂíåÊµÅÂºèÂä†ÈÄüÂÆ¢Êà∑Á´ØË∞ÉÁî®](https://github.com/baidubce/app-builder/blob/master/docs/Tools/DocPass/DocPass.md)\n        - RAG:\n            - [Âü∫Á°ÄÁü•ËØÜ](https://github.com/baidubce/app-builder/blob/master/docs/Application/RAG/BasicKnowledge/rag.md)\n            - [Áü•ËØÜÂ∫ìÁÆ°ÁêÜ](https://github.com/baidubce/app-builder/blob/master/docs/Application/RAG/DatasetManage/dataset_manage.md)\n            - [Reference‰ø°ÊÅØÂ§ÑÁêÜ](https://github.com/baidubce/app-builder/blob/master/docs/Tools/DocPass/DocPass.md)\n        - Workflow:\n            - [Âü∫Á°ÄÁü•ËØÜ](https://github.com/baidubce/app-builder/blob/master/docs/Tools/DocPass/DocPass.md)\n            - [‰ªéÈõ∂‰ΩøÁî®WorkflowÁªÑË£Ö‰∏Ä‰∏™RAGÂ∫îÁî®](https://github.com/baidubce/app-builder/blob/master/docs/Tools/DocPass/DocPass.md)\n            - [‰ªéÈõ∂‰ΩøÁî®WorkflowÁªÑË£Ö‰∏Ä‰∏™AgentÂ∫îÁî®](https://github.com/baidubce/app-builder/blob/master/docs/Tools/DocPass/DocPass.md)\n    - ÂºÄÂèëËÄÖÊåáÂçó:\n        - [Â¶Ç‰ΩïË¥°ÁåÆ‰ª£Á†Å](https://github.com/baidubce/app-builder/blob/master/docs/DevelopGuide/HowToContributeCode/README.md)\n        - [‰∫åÊ¨°ÂºÄÂèë](https://github.com/baidubce/app-builder/blob/master/docs/DevelopGuide/AdvancedDevelopment/README.md)\n        - [ÁâàÊú¨ÂçáÁ∫ßÊó•Âøó](https://github.com/baidubce/app-builder/blob/master/docs/DevelopGuide/ChangeLog/changelog.md)\n        - [ÈîôËØØ‰ø°ÊÅØ](https://github.com/baidubce/app-builder/blob/master/docs/DevelopGuide/ErrorMessage/error_message.md)\n        - [ÁéØÂ¢ÉÂèÇÊï∞](https://github.com/baidubce/app-builder/blob/master/docs/DevelopGuide/EnvironmentalParameters/env.md)\n\n\n## ÂºÄÊ∫êÁ§æÂå∫‰∏éÊ¥ªÂä®\n<div align=\"center\">\n<h3>ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜAppBuilder-SDKÂæÆ‰ø°‰∫§ÊµÅÁæ§</h3>\n<img src='docs/image/wechat_group.png' alt='wechat' width='200' >\n</div>\n\n- [Github Issue](https://github.com/baidubce/app-builder/issues):  Êèê‰∫§ÂÆâË£Ö/‰ΩøÁî®ÈóÆÈ¢ò„ÄÅÊä•Âëäbug„ÄÅÂª∫ËÆÆÊñ∞ÁâπÊÄß„ÄÅÊ≤üÈÄöÂºÄÂèëËÆ°ÂàíÁ≠â\n\n- [ÁôæÂ∫¶Êô∫ËÉΩ‰∫ëÂçÉÂ∏ÜÁ§æÂå∫](https://cloud.baidu.com/qianfandev)\n\n## License\n\nAppBuilder-SDKÈÅµÂæ™Apache-2.0ÂºÄÊ∫êÂçèËÆÆ„ÄÇ\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/app-builder",
          "npm_downloads": 574746,
          "npm_package_name": "app-builder",
          "npm_success": true,
          "npm_error": null
        },
        "baranwang--mcp-trends-hub": {
          "owner": "baranwang",
          "name": "mcp-trends-hub",
          "url": "https://github.com/baranwang/mcp-trends-hub",
          "imageUrl": "https://github.com/baranwang.png",
          "description": "Aggregates trending topics from multiple platforms such as Weibo, Douyin, and Tencent News, providing real-time updates on the latest trends and insights. Supports integration with AI applications through the Model Context Protocol (MCP).",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:04.745448",
          "collection_timestamp": "2025-10-02T15:12:45.498646",
          "stars": 169,
          "forks": 21,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-20T13:06:42Z",
          "updated_at": "2025-09-29T06:47:29Z",
          "open_issues": 8,
          "readme_content": "# üî• Trends Hub\n\n[![smithery badge](https://smithery.ai/badge/@baranwang/mcp-trends-hub)](https://smithery.ai/server/@baranwang/mcp-trends-hub)\n[![NPM Version](https://img.shields.io/npm/v/mcp-trends-hub)](https://www.npmjs.com/package/mcp-trends-hub)\n![NPM License](https://img.shields.io/npm/l/mcp-trends-hub)\n\nÂü∫‰∫é Model Context Protocol (MCP) ÂçèËÆÆÁöÑÂÖ®ÁΩëÁÉ≠ÁÇπË∂ãÂäø‰∏ÄÁ´ôÂºèËÅöÂêàÊúçÂä°\n\n## Á§∫‰æãÊïàÊûú\n\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"./assets/case-dark.png\">\n  <img src=\"./assets/case-light.png\" alt=\"Trends Hub Á§∫‰æã\">\n</picture>\n\n## ‚ú® ÁâπÊÄß\n\n- üìä **‰∏ÄÁ´ôÂºèËÅöÂêà** - ËÅöÂêàÂÖ®ÁΩëÁÉ≠ÁÇπËµÑËÆØÔºå20+ ‰ºòË¥®Êï∞ÊçÆÊ∫ê\n- üîÑ **ÂÆûÊó∂Êõ¥Êñ∞** - ‰øùÊåÅ‰∏éÊ∫êÁ´ôÂêåÊ≠•ÁöÑÊúÄÊñ∞ÁÉ≠ÁÇπÊï∞ÊçÆ\n- üß© **MCP ÂçèËÆÆÊîØÊåÅ** - ÂÆåÂÖ®ÂÖºÂÆπ Model Context ProtocolÔºåËΩªÊùæÈõÜÊàêÂà∞ AI Â∫îÁî®\n- üîå **Êòì‰∫éÊâ©Â±ï** - ÁÆÄÂçïÈÖçÁΩÆÂç≥ÂèØÊ∑ªÂä†Ëá™ÂÆö‰πâ RSS Ê∫ê\n- üé® **ÁÅµÊ¥ªÂÆöÂà∂** - ÈÄöËøáÁéØÂ¢ÉÂèòÈáèËΩªÊùæË∞ÉÊï¥ËøîÂõûÂ≠óÊÆµ\n\n## üìñ ‰ΩøÁî®ÊåáÂçó\n\nÈ¶ñÂÖàÈúÄË¶Å‰∫ÜËß£ [MCP](https://modelcontextprotocol.io/introduction) ÂçèËÆÆÔºåÁÑ∂ÂêéÊåâÁÖß‰ª•‰∏ãÈÖçÁΩÆÊ∑ªÂä† Trends Hub ÊúçÂä°\n\n‰∏çÂêåÁöÑ MCP ÂÆ¢Êà∑Á´ØÂÆûÁé∞ÂèØËÉΩÊúâÊâÄ‰∏çÂêåÔºå‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂ∏∏ËßÅÁöÑÈÖçÁΩÆÁ§∫‰æãÔºö\n\n### JSON ÈÖçÁΩÆ\n\n<!-- usage-json-start -->\n```json\n{\n  \"mcpServers\": {\n    \"trends-hub\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-trends-hub@1.6.2\"\n      ]\n    }\n  }\n}\n```\n\n<!-- usage-json-end -->\n\n### ÂëΩ‰ª§Ë°åÈÖçÁΩÆ\n\n<!-- usage-bash-start -->\n```bash\nnpx -y mcp-trends-hub@1.6.2\n```\n\n<!-- usage-bash-end -->\n\n### ÂÆâË£Ö\n\n#### ‰ΩøÁî® Smithery ÂÆâË£Ö\n\nÈÄöËøá [Smithery](https://smithery.ai/server/@baranwang/mcp-trends-hub) ÂÆâË£Ö Trends HubÔºåÈÄÇÁî®‰∫é Claude Desktop ÂÆ¢Êà∑Á´ØÔºö\n\n```bash\nnpx -y @smithery/cli install @baranwang/mcp-trends-hub --client claude\n```\n\nÔºà‰ª•‰∏ã‰ªÖÈÄÇÁî®‰∫é MCP Ê®°ÂûãÂÆ¢Êà∑Á´ØÔºâ\n\n### ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè\n\n### `TRENDS_HUB_HIDDEN_FIELDS` - ÈöêËóèÁöÑÂ≠óÊÆµÂàóË°®\n\nÈÄöËøáÊ≠§ÁéØÂ¢ÉÂèòÈáèÂèØÊéßÂà∂ËøîÂõûÊï∞ÊçÆ‰∏≠ÁöÑÂ≠óÊÆµÊòæÁ§∫Ôºö\n\n- ‰ΩúÁî®‰∫éÊâÄÊúâÂ∑•ÂÖ∑Ôºö`{field-name}`Ôºå‰æãÂ¶Ç `cover`\n- ‰ΩúÁî®‰∫éÁâπÂÆöÂ∑•ÂÖ∑Ôºö`{tool-name}:{field-name}`Ôºå‰æãÂ¶Ç `get-toutiao-trending:cover`\n\nÂ§ö‰∏™ÈÖçÁΩÆÁî®Ë•øÊñáÈÄóÂè∑ÂàÜÈöîÔºå‰æãÂ¶ÇÔºö\n\n```jsonc\n{\n  \"mcpServers\": {\n    \"trends-hub\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-trends-hub\"],\n      \"env\": {\n        \"TRENDS_HUB_HIDDEN_FIELDS\": \"cover,get-nytimes-news:description\" // ÈöêËóèÊâÄÊúâÂ∑•ÂÖ∑ÁöÑÂ∞ÅÈù¢ËøîÂõûÂíåÁ∫ΩÁ∫¶Êó∂Êä•Êñ∞ÈóªÁöÑÊèèËø∞\n      }\n    }\n  }\n}\n```\n\n### `TRENDS_HUB_CUSTOM_RSS_URL` - Ëá™ÂÆö‰πâ RSS ËÆ¢ÈòÖÊ∫ê\n\nTrend Hub ÊîØÊåÅÈÄöËøáÁéØÂ¢ÉÂèòÈáèÊ∑ªÂä†Ëá™ÂÆö‰πâ RSS Ê∫êÔºö\n\n```jsonc\n{\n  \"mcpServers\": {\n    \"trends-hub\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-trends-hub\"],\n      \"env\": {\n        \"TRENDS_HUB_CUSTOM_RSS_URL\": \"https://news.yahoo.com/rss\" // Ê∑ªÂä† Yahoo Êñ∞Èóª RSS\n      }\n    }\n  }\n}\n```\n\nÈÖçÁΩÆÂêéÂ∞ÜËá™Âä®Ê∑ªÂä†`custom-rss`Â∑•ÂÖ∑ÔºåÁî®‰∫éËé∑ÂèñÊåáÂÆöÁöÑ RSS ËÆ¢ÈòÖÊ∫êÂÜÖÂÆπ\n\n## üõ†Ô∏è ÊîØÊåÅÁöÑÂ∑•ÂÖ∑\n\n<!-- tools-start -->\n| Â∑•ÂÖ∑ÂêçÁß∞ | ÊèèËø∞ |\n| --- | --- |\n| get-36kr-trending | Ëé∑Âèñ 36 Ê∞™ÁÉ≠Ê¶úÔºåÊèê‰æõÂàõ‰∏ö„ÄÅÂïÜ‰∏ö„ÄÅÁßëÊäÄÈ¢ÜÂüüÁöÑÁÉ≠Èó®ËµÑËÆØÔºåÂåÖÂê´ÊäïËûçËµÑÂä®ÊÄÅ„ÄÅÊñ∞ÂÖ¥‰∫ß‰∏öÂàÜÊûêÂíåÂïÜ‰∏öÊ®°ÂºèÂàõÊñ∞‰ø°ÊÅØ |\n| get-9to5mac-news | Ëé∑Âèñ 9to5Mac ËãπÊûúÁõ∏ÂÖ≥Êñ∞ÈóªÔºåÂåÖÂê´ËãπÊûú‰∫ßÂìÅÂèëÂ∏É„ÄÅiOS Êõ¥Êñ∞„ÄÅMac Á°¨‰ª∂„ÄÅÂ∫îÁî®Êé®ËçêÂèäËãπÊûúÂÖ¨Âè∏Âä®ÊÄÅÁöÑËã±ÊñáËµÑËÆØ |\n| get-bbc-news | Ëé∑Âèñ BBC Êñ∞ÈóªÔºåÊèê‰æõÂÖ®ÁêÉÊñ∞Èóª„ÄÅËã±ÂõΩÊñ∞Èóª„ÄÅÂïÜ‰∏ö„ÄÅÊîøÊ≤ª„ÄÅÂÅ•Â∫∑„ÄÅÊïôËÇ≤„ÄÅÁßëÊäÄ„ÄÅÂ®±‰πêÁ≠âËµÑËÆØ |\n| get-bilibili-rank | Ëé∑ÂèñÂìîÂì©ÂìîÂì©ËßÜÈ¢ëÊéíË°åÊ¶úÔºåÂåÖÂê´ÂÖ®Á´ô„ÄÅÂä®Áîª„ÄÅÈü≥‰πê„ÄÅÊ∏∏ÊàèÁ≠âÂ§ö‰∏™ÂàÜÂå∫ÁöÑÁÉ≠Èó®ËßÜÈ¢ëÔºåÂèçÊò†ÂΩì‰∏ãÂπ¥ËΩª‰∫∫ÁöÑÂÜÖÂÆπÊ∂àË¥πË∂ãÂäø |\n| get-douban-rank | Ëé∑ÂèñË±ÜÁì£ÂÆûÊó∂ÁÉ≠Èó®Ê¶úÂçïÔºåÊèê‰æõÂΩìÂâçÁÉ≠Èó®ÁöÑÂõæ‰π¶„ÄÅÁîµÂΩ±„ÄÅÁîµËßÜÂâß„ÄÅÁªºËâ∫Á≠â‰ΩúÂìÅ‰ø°ÊÅØÔºåÂåÖÂê´ËØÑÂàÜÂíåÁÉ≠Â∫¶Êï∞ÊçÆ |\n| get-douyin-trending | Ëé∑ÂèñÊäñÈü≥ÁÉ≠ÊêúÊ¶úÂçïÔºåÂ±ïÁ§∫ÂΩì‰∏ãÊúÄÁÉ≠Èó®ÁöÑÁ§æ‰ºöËØùÈ¢ò„ÄÅÂ®±‰πê‰∫ã‰ª∂„ÄÅÁΩëÁªúÁÉ≠ÁÇπÂíåÊµÅË°åË∂ãÂäø |\n| get-gcores-new | Ëé∑ÂèñÊú∫Ê†∏ÁΩëÊ∏∏ÊàèÁõ∏ÂÖ≥ËµÑËÆØÔºåÂåÖÂê´ÁîµÂ≠êÊ∏∏ÊàèËØÑÊµã„ÄÅÁé©ÂÆ∂ÊñáÂåñ„ÄÅÊ∏∏ÊàèÂºÄÂèëÂíåÊ∏∏ÊàèÂë®Ëæπ‰∫ßÂìÅÁöÑÊ∑±Â∫¶ÂÜÖÂÆπ |\n| get-ifanr-news | Ëé∑ÂèñÁà±ËåÉÂÑøÁßëÊäÄÂø´ËÆØÔºåÂåÖÂê´ÊúÄÊñ∞ÁöÑÁßëÊäÄ‰∫ßÂìÅ„ÄÅÊï∞Á†ÅËÆæÂ§á„ÄÅ‰∫íËÅîÁΩëÂä®ÊÄÅÁ≠âÂâçÊ≤øÁßëÊäÄËµÑËÆØ |\n| get-infoq-news | Ëé∑Âèñ InfoQ ÊäÄÊúØËµÑËÆØÔºåÂåÖÂê´ËΩØ‰ª∂ÂºÄÂèë„ÄÅÊû∂ÊûÑËÆæËÆ°„ÄÅ‰∫ëËÆ°ÁÆó„ÄÅAIÁ≠â‰ºÅ‰∏öÁ∫ßÊäÄÊúØÂÜÖÂÆπÂíåÂâçÊ≤øÂºÄÂèëËÄÖÂä®ÊÄÅ |\n| get-juejin-article-rank | Ëé∑ÂèñÊéòÈáëÊñáÁ´†Ê¶úÔºåÂåÖÂê´ÂâçÁ´ØÂºÄÂèë„ÄÅÂêéÁ´ØÊäÄÊúØ„ÄÅ‰∫∫Â∑•Êô∫ËÉΩ„ÄÅÁßªÂä®ÂºÄÂèëÂèäÊäÄÊúØÊû∂ÊûÑÁ≠âÈ¢ÜÂüüÁöÑÈ´òË¥®Èáè‰∏≠ÊñáÊäÄÊúØÊñáÁ´†ÂíåÊïôÁ®ã |\n| get-netease-news-trending | Ëé∑ÂèñÁΩëÊòìÊñ∞ÈóªÁÉ≠ÁÇπÊ¶úÔºåÂåÖÂê´Êó∂ÊîøË¶ÅÈóª„ÄÅÁ§æ‰ºö‰∫ã‰ª∂„ÄÅË¥¢ÁªèËµÑËÆØ„ÄÅÁßëÊäÄÂä®ÊÄÅÂèäÂ®±‰πê‰ΩìËÇ≤ÁöÑÂÖ®Êñπ‰Ωç‰∏≠ÊñáÊñ∞ÈóªËµÑËÆØ |\n| get-nytimes-news | Ëé∑ÂèñÁ∫ΩÁ∫¶Êó∂Êä•Êñ∞ÈóªÔºåÂåÖÂê´ÂõΩÈôÖÊîøÊ≤ª„ÄÅÁªèÊµéÈáëËûç„ÄÅÁ§æ‰ºöÊñáÂåñ„ÄÅÁßëÂ≠¶ÊäÄÊúØÂèäËâ∫ÊúØËØÑËÆ∫ÁöÑÈ´òË¥®ÈáèËã±ÊñáÊàñ‰∏≠ÊñáÂõΩÈôÖÊñ∞ÈóªËµÑËÆØ |\n| get-smzdm-rank | Ëé∑Âèñ‰ªÄ‰πàÂÄºÂæó‰π∞ÁÉ≠Èó®ÔºåÂåÖÂê´ÂïÜÂìÅÊé®Ëçê„ÄÅ‰ºòÊÉ†‰ø°ÊÅØ„ÄÅË¥≠Áâ©ÊîªÁï•„ÄÅ‰∫ßÂìÅËØÑÊµãÂèäÊ∂àË¥πÁªèÈ™åÂàÜ‰∫´ÁöÑÂÆûÁî®‰∏≠ÊñáÊ∂àË¥πÁ±ªËµÑËÆØ |\n| get-sspai-rank | Ëé∑ÂèñÂ∞ëÊï∞Ê¥æÁÉ≠Ê¶úÔºåÂåÖÂê´Êï∞Á†Å‰∫ßÂìÅËØÑÊµã„ÄÅËΩØ‰ª∂Â∫îÁî®Êé®Ëçê„ÄÅÁîüÊ¥ªÊñπÂºèÊåáÂçóÂèäÊïàÁéáÂ∑•‰ΩúÊäÄÂ∑ßÁöÑ‰ºòË¥®‰∏≠ÊñáÁßëÊäÄÁîüÊ¥ªÁ±ªÂÜÖÂÆπ |\n| get-tencent-news-trending | Ëé∑ÂèñËÖæËÆØÊñ∞ÈóªÁÉ≠ÁÇπÊ¶úÔºåÂåÖÂê´ÂõΩÂÜÖÂ§ñÊó∂‰∫ã„ÄÅÁ§æ‰ºöÁÉ≠ÁÇπ„ÄÅË¥¢ÁªèËµÑËÆØ„ÄÅÂ®±‰πêÂä®ÊÄÅÂèä‰ΩìËÇ≤Ëµõ‰∫ãÁöÑÁªºÂêàÊÄß‰∏≠ÊñáÊñ∞ÈóªËµÑËÆØ |\n| get-thepaper-trending | Ëé∑ÂèñÊæéÊπÉÊñ∞ÈóªÁÉ≠Ê¶úÔºåÂåÖÂê´Êó∂ÊîøË¶ÅÈóª„ÄÅË¥¢ÁªèÂä®ÊÄÅ„ÄÅÁ§æ‰ºö‰∫ã‰ª∂„ÄÅÊñáÂåñÊïôËÇ≤ÂèäÊ∑±Â∫¶Êä•ÈÅìÁöÑÈ´òË¥®Èáè‰∏≠ÊñáÊñ∞ÈóªËµÑËÆØ |\n| get-theverge-news | Ëé∑Âèñ The Verge Êñ∞ÈóªÔºåÂåÖÂê´ÁßëÊäÄÂàõÊñ∞„ÄÅÊï∞Á†Å‰∫ßÂìÅËØÑÊµã„ÄÅ‰∫íËÅîÁΩëË∂ãÂäøÂèäÁßëÊäÄÂÖ¨Âè∏Âä®ÊÄÅÁöÑËã±ÊñáÁßëÊäÄËµÑËÆØ |\n| get-toutiao-trending | Ëé∑Âèñ‰ªäÊó•Â§¥Êù°ÁÉ≠Ê¶úÔºåÂåÖÂê´Êó∂ÊîøË¶ÅÈóª„ÄÅÁ§æ‰ºö‰∫ã‰ª∂„ÄÅÂõΩÈôÖÊñ∞Èóª„ÄÅÁßëÊäÄÂèëÂ±ïÂèäÂ®±‰πêÂÖ´Âç¶Á≠âÂ§öÈ¢ÜÂüüÁöÑÁÉ≠Èó®‰∏≠ÊñáËµÑËÆØ |\n| get-weibo-trending | Ëé∑ÂèñÂæÆÂçöÁÉ≠ÊêúÊ¶úÔºåÂåÖÂê´Êó∂‰∫ãÁÉ≠ÁÇπ„ÄÅÁ§æ‰ºöÁé∞Ë±°„ÄÅÂ®±‰πêÊñ∞Èóª„ÄÅÊòéÊòüÂä®ÊÄÅÂèäÁΩëÁªúÁÉ≠ËÆÆËØùÈ¢òÁöÑÂÆûÊó∂ÁÉ≠Èó®‰∏≠ÊñáËµÑËÆØ |\n| get-weread-rank | Ëé∑ÂèñÂæÆ‰ø°ËØª‰π¶ÊéíË°åÊ¶úÔºåÂåÖÂê´ÁÉ≠Èó®Â∞èËØ¥„ÄÅÁïÖÈîÄ‰π¶Á±ç„ÄÅÊñ∞‰π¶Êé®ËçêÂèäÂêÑÁ±ªÊñáÂ≠¶‰ΩúÂìÅÁöÑÈòÖËØªÊï∞ÊçÆÂíåÊéíÂêç‰ø°ÊÅØ |\n| get-zhihu-trending | Ëé∑ÂèñÁü•‰πéÁÉ≠Ê¶úÔºåÂåÖÂê´Êó∂‰∫ãÁÉ≠ÁÇπ„ÄÅÁ§æ‰ºöËØùÈ¢ò„ÄÅÁßëÊäÄÂä®ÊÄÅ„ÄÅÂ®±‰πêÂÖ´Âç¶Á≠âÂ§öÈ¢ÜÂüüÁöÑÁÉ≠Èó®ÈóÆÁ≠îÂíåËÆ®ËÆ∫ÁöÑ‰∏≠ÊñáËµÑËÆØ |\n\n\n<!-- tools-end -->\n\nÊõ¥Â§öÊï∞ÊçÆÊ∫êÊ≠£Âú®ÊåÅÁª≠Â¢ûÂä†‰∏≠\n\n## È∏£Ë∞¢\n\n- [DailyHotApi](https://github.com/imsyy/DailyHotApi)\n- [RSSHub](https://github.com/DIYgod/RSSHub)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-trends-hub",
          "npm_downloads": 13001,
          "npm_package_name": "mcp-trends-hub",
          "npm_success": true,
          "npm_error": null
        },
        "baranwang--mcp-deep-research": {
          "owner": "baranwang",
          "name": "mcp-deep-research",
          "url": "https://github.com/baranwang/mcp-deep-research",
          "imageUrl": "https://github.com/baranwang.png",
          "description": "Search the web for information using the Tavily API to enhance research capabilities with configurable search parameters.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:05.540944",
          "collection_timestamp": "2025-10-02T15:12:58.966999",
          "stars": 3,
          "forks": 1,
          "license": "No License",
          "language": "JavaScript",
          "created_at": "2025-03-29T16:51:05Z",
          "updated_at": "2025-08-22T21:23:19Z",
          "open_issues": 0,
          "readme_content": "# MCP Deep Research\n\n[![smithery badge](https://smithery.ai/badge/@baranwang/mcp-deep-research)](https://smithery.ai/server/@baranwang/mcp-deep-research)\n[![NPM Version](https://img.shields.io/npm/v/mcp-deep-research)](https://www.npmjs.com/package/mcp-deep-research)\n![NPM License](https://img.shields.io/npm/l/mcp-deep-research)\n\n[ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-hans.md) | English\n\n## Overview\n\nMCP Deep Research is a tool that allows you to search the web for information. It is built with the [Model Context Protocol](https://modelcontextprotocol.com/) and the [Tavily API](https://tavily.com/).\n\n## Configuration\n\n```jsonc\n{\n  \"mcpServers\": {\n    \"deep-research\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-deep-research@latest\"],\n      \"env\": {\n        \"TAVILY_API_KEY\": \"your_tavily_api_key\", // Required\n        \"MAX_SEARCH_KEYWORDS\": \"5\", // Optional, default 5\n        \"MAX_PLANNING_ROUNDS\": \"5\" // Optional, default 5\n      }\n    }\n  }\n}\n```\n\nThe tool can be configured using the following environment variables:\n\n- `TAVILY_API_KEY`: The API key for the [Tavily](https://tavily.com/) API.\n- `MAX_SEARCH_KEYWORDS`: The maximum number of search keywords to use.\n- `MAX_PLANNING_ROUNDS`: The maximum number of planning rounds to use.\n- `TAVILY_HTTP_PROXY`/`TAVILY_HTTPS_PROXY`: The proxy address for the Tavily API.\n\n### Use with Smithery\n\nInstall via [Smithery](https://smithery.ai/server/@baranwang/mcp-deep-research), compatible with Claude Desktop client:\n\n```bash\nnpx -y @smithery/cli install @baranwang/mcp-deep-research --client claude\n```\n\n## Compatibility Notice\n\nThis MCP server is optimized for prompt-based MCP clients. For MCP clients implemented using function calling mechanisms, the performance and results may not be optimal.\n\nVerified prompt-based MCP clients:\n\n- [Claude Desktop](https://claude.ai/download)\n- [Cursor](https://www.cursor.com/)\n- [Cline](https://github.com/cline/cline)\n- [ChatWise](https://chatwise.app/)\n\nVerified function calling-based MCP clients:\n\n- [Cherry Studio](https://cherry-ai.com/)",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-deep-research",
          "npm_downloads": 538,
          "npm_package_name": "mcp-deep-research",
          "npm_success": true,
          "npm_error": null
        },
        "bbangjooo--mcp-installer": {
          "owner": "bbangjooo",
          "name": "mcp-installer",
          "url": "https://github.com/bbangjooo/mcp-installer",
          "imageUrl": "https://github.com/bbangjooo.png",
          "description": "Discover and connect to Model Context Protocol servers using tools for finding, collecting configuration, and local installation of MCP servers.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:06.545647",
          "collection_timestamp": "2025-10-02T15:13:02.985428",
          "stars": 4,
          "forks": 2,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-31T11:54:42Z",
          "updated_at": "2025-09-02T00:43:24Z",
          "open_issues": 0,
          "readme_content": "# MCP Installer\n\n[![smithery badge](https://smithery.ai/badge/@bbangjooo/mcp-finder-mcp-server)](https://smithery.ai/server/@bbangjooo/mcp-finder-mcp-server)\n\n## Introduction\n\nMCP Installer serves the following tools\n\n- find-mcp: finding Model Context Protocol (MCP) servers from registry\n- collect-config: collecting config to be used for connection to mcp server\n- install-mcp: installing mcp server to your local machine\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js (v14.0.0 or higher)\n- npm or yarn\n- SMITHERY_API_KEY (https://smithery.ai/)\n\n## Installation\n\nYou can install MCP Installer using the following command:\n\n```bash\nnpm install @bbangjo/mcp-installer\nnpx @bbangjo/mcp-installer --client <client-type> --key <your-smithery-api-key>\n```\n\nWhere:\n\n- `<client-type>`: Currently supported clients are 'cursor' or 'claude'\n- `<your-smithery-api-key>`: Enter your Smithery API key\n\nExample:\n\n```bash\nnpx @bbangjo/mcp-installer --client cursor --key your_smithery_api_key_here\n```\n\nUpon successful installation, you will see the message \"‚úÖ MCP server installed successfully.\"\n\n**Note**: Depending on the client type, the configuration file will be created in the following locations:\n\n- Cursor:\n\n  - Windows: `%APPDATA%\\Cursor\\mcp.json`\n  - macOS: `~/.cursor/mcp.json`\n  - Linux: `~/.config/Cursor/mcp.json`\n\n- Claude:\n  - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n  - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n  - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n## Local setup\n\n1. Install dependencies\n\n```bash\nnpm install\n```\n\n2. Set up environment variables\n   Create a `.env` file in the project root directory and add the following:\n\n```\nSMITHERY_API_KEY=your_api_key_here\n```\n\n3. Running the server:\n\n```bash\nnpm run build\nnode build/index.js\n```\n\nThe server will display the message \"MCP Finder Server running on stdio\" when successfully started.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-installer",
          "npm_downloads": 796,
          "npm_package_name": "mcp-installer",
          "npm_success": true,
          "npm_error": null
        }
      }
    },
    "developer-tools": {
      "category": "developer-tools",
      "categoryDisplay": "Developer Tools",
      "description": "Tools and integrations that enhance the development workflow and environment management.",
      "totalRepositories": 11,
      "repositories": {
        "jagan-shanmugam--mattermost-mcp-host": {
          "owner": "jagan-shanmugam",
          "name": "mattermost-mcp-host",
          "url": "https://github.com/jagan-shanmugam/mattermost-mcp-host",
          "imageUrl": "https://github.com/jagan-shanmugam.png",
          "description": "Connects Mattermost to Model Context Protocol (MCP) servers, enabling interactions with a LangGraph-based AI agent for executing tools and automating user requests directly within Mattermost channels.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:07.460883",
          "collection_timestamp": "2025-10-03T04:27:23.548690",
          "stars": 27,
          "forks": 16,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-03T18:38:07Z",
          "updated_at": "2025-09-28T13:00:47Z",
          "open_issues": 6,
          "readme_content": "# Mattermost MCP Host\n\nA Mattermost integration that connects to Model Context Protocol (MCP) servers, leveraging a LangGraph-based AI agent to provide an intelligent interface for interacting with users and executing tools directly within Mattermost.\n\n![Version](https://img.shields.io/badge/version-0.1.0-blue)\n![Python](https://img.shields.io/badge/python-3.13.1%2B-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![Package Manager](https://img.shields.io/badge/package%20manager-uv-purple)\n\n\n\n## Demo\n\n### 1. Github Agent in support channel - searches the existing issues and PRs and creates a new issue if not found\n![Description of your GIF](./demo/demo-3.gif)   \n\n\n### 2. Search internet and post to a channel using Mattermost-MCP-server\n![Description of your GIF](./demo/demo-2.gif)\n\n#### Scroll below for full demo in YouTube\n\n## Features\n\n- ü§ñ **Langgraph Agent Integration**: Uses a LangGraph agent to understand user requests and orchestrate responses.\n- üîå **MCP Server Integration**: Connects to multiple MCP servers defined in `mcp-servers.json`.\n- üõ†Ô∏è **Dynamic Tool Loading**: Automatically discovers tools from connected MCP servers and makes them available to the AI agent. Converts MCP tools to langchain structured tools.\n- üí¨ **Thread-Aware Conversations**: Maintains conversational context within Mattermost threads for coherent interactions.\n- üîÑ **Intelligent Tool Use**: The AI agent can decide when to use available tools (including chaining multiple calls) to fulfill user requests.\n- üîç **MCP Capability Discovery**: Allows users to list available servers, tools, resources, and prompts via direct commands.\n- #Ô∏è‚É£ **Direct Command Interface**: Interact directly with MCP servers using a command prefix (default: `#`).\n\n\n## Overview\n\nThe integration works as follows:\n\n1.  **Mattermost Connection (`mattermost_client.py`)**: Connects to the Mattermost server via API and WebSocket to listen for messages in a specified channel.\n2.  **MCP Connections (`mcp_client.py`)**: Establishes connections (primarily `stdio`) to each MCP server defined in `src/mattermost_mcp_host/mcp-servers.json`. It discovers available tools on each server.\n3.  **Agent Initialization (`agent/llm_agent.py`)**: A `LangGraphAgent` is created, configured with the chosen LLM provider and the dynamically loaded tools from all connected MCP servers.\n4.  **Message Handling (`main.py`)**:\n    *   If a message starts with the command prefix (`#`), it's parsed as a direct command to list servers/tools or call a specific tool via the corresponding `MCPClient`.\n    *   Otherwise, the message (along with thread history) is passed to the `LangGraphAgent`.\n5.  **Agent Execution**: The agent processes the request, potentially calling one or more MCP tools via the `MCPClient` instances, and generates a response.\n6.  **Response Delivery**: The final response from the agent or command execution is posted back to the appropriate Mattermost channel/thread.\n\n## Setup\n1.  **Clone the repository:**\n    ```bash\n    git clone <repository-url>\n    cd mattermost-mcp-host\n    ```\n\n2.  **Install:**\n    *   Using uv (recommended):\n        ```bash\n        # Install uv if you don't have it yet\n        # curl -LsSf https://astral.sh/uv/install.sh | sh \n\n        # Activate venv\n        source .venv/bin/activate\n        \n        # Install the package with uv\n        uv sync\n\n        # To install dev dependencies\n        uv sync --dev --all-extras\n        ```\n\n3.  **Configure Environment (`.env` file):**\n    Copy the `.env.example` and fill in the values or\n    Create a `.env` file in the project root (or set environment variables):\n    ```env\n    # Mattermost Details\n    MATTERMOST_URL=http://your-mattermost-url\n    MATTERMOST_TOKEN=your-bot-token # Needs permissions to post, read channel, etc.\n    MATTERMOST_TEAM_NAME=your-team-name\n    MATTERMOST_CHANNEL_NAME=your-channel-name # Channel for the bot to listen in\n    # MATTERMOST_CHANNEL_ID= # Optional: Auto-detected if name is provided\n\n    # LLM Configuration (Azure OpenAI is default)\n    DEFAULT_PROVIDER=azure\n    AZURE_OPENAI_ENDPOINT=your-azure-endpoint\n    AZURE_OPENAI_API_KEY=your-azure-api-key\n    AZURE_OPENAI_DEPLOYMENT=your-deployment-name # e.g., gpt-4o\n    # AZURE_OPENAI_API_VERSION= # Optional, defaults provided\n\n    # Optional: Other providers (install with `[all]` extra)\n    # OPENAI_API_KEY=...\n    # ANTHROPIC_API_KEY=...\n    # GOOGLE_API_KEY=...\n\n    # Command Prefix\n    COMMAND_PREFIX=# \n    ```\n    See `.env.example` for more options.\n\n4.  **Configure MCP Servers:**\n    Edit `src/mattermost_mcp_host/mcp-servers.json` to define the MCP servers you want to connect to. See `src/mattermost_mcp_host/mcp-servers-example.json`.\n    Depending on the server configuration, you might `npx`, `uvx`, `docker` installed in your system and in path.\n\n5.  **Start the Integration:**\n    ```bash\n    mattermost-mcp-host\n    ```\n\n\n## Prerequisites\n\n- Python 3.13.1+\n- uv package manager\n- Mattermost server instance\n- Mattermost Bot Account with API token\n- Access to a LLM API (Azure OpenAI)\n\n### Optional\n- One or more MCP servers configured in `mcp-servers.json` \n- Tavily web search requires `TAVILY_API_KEY` in `.env` file\n\n\n## Usage in Mattermost\n\nOnce the integration is running and connected:\n\n1.  **Direct Chat:** Simply chat in the configured channel or with the bot. The AI agent will respond, using tools as needed. It maintains context within message threads.\n2.  **Direct Commands:** Use the command prefix (default `#`) for specific actions:\n    *   `#help` - Display help information.\n    *   `#servers` - List configured and connected MCP servers.\n    *   `#<server_name> tools` - List available tools for `<server_name>`.\n    *   `#<server_name> call <tool_name> <json_arguments>` - Call `<tool_name>` on `<server_name>` with arguments provided as a JSON string.\n        *   Example: `#my-server call echo '{\"message\": \"Hello MCP!\"}'`\n    *   `#<server_name> resources` - List available resources for `<server_name>`.\n    *   `#<server_name> prompts` - List available prompts for `<server_name>`.\n\n\n\n## Next Steps\n- ‚öôÔ∏è **Configurable LLM Backend**: Supports multiple AI providers (Azure OpenAI default, OpenAI, Anthropic Claude, Google Gemini) via environment variables.\n\n## Mattermost Setup\n\n1. **Create a Bot Account**\n- Go to Integrations > Bot Accounts > Add Bot Account\n- Give it a name and description\n- Save the access token in the .env file\n\n2. **Required Bot Permissions**\n- post_all\n- create_post\n- read_channel\n- create_direct_channel\n- read_user\n\n3. **Add Bot to Team/Channel**\n- Invite the bot to your team\n- Add bot to desired channels\n\n### Troubleshooting\n\n1. **Connection Issues**\n- Verify Mattermost server is running\n- Check bot token permissions\n- Ensure correct team/channel names\n\n2. **AI Provider Issues**\n- Validate API keys\n- Check API quotas and limits\n- Verify network access to API endpoints\n\n3. **MCP Server Issues**\n- Check server logs\n- Verify server configurations\n- Ensure required dependencies are installed and env variables are defined\n\n\n## Demos\n\n### Create issue via chat using Github MCP server\n![Description of your GIF](./demo/demo-1.gif)  \n\n### (in YouTube)\n[![AI Agent in Action in Mattermost](./demo/supercut-thumbnail.png)](https://youtu.be/s6CZY81DRrU)\n\n\n## Contributing\n\nPlease feel free to open a PR.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jakenuts--mcp-cli-exec": {
          "owner": "jakenuts",
          "name": "mcp-cli-exec",
          "url": "https://github.com/jakenuts/mcp-cli-exec",
          "imageUrl": "https://github.com/jakenuts.png",
          "description": "Execute shell commands in a specified directory and obtain structured output, including execution results such as success status, stdout, stderr, and error handling. Enhance automation workflows with detailed command management capabilities.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:07.952911",
          "collection_timestamp": "2025-10-03T04:27:26.968917",
          "stars": 6,
          "forks": 2,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-02-27T19:37:52Z",
          "updated_at": "2025-09-26T16:50:55Z",
          "open_issues": 2,
          "readme_content": "# mcp-cli-exec MCP Server\n\nA powerful CLI command execution MCP server that enables running shell commands with structured output. This package focuses specifically on command execution functionality, differentiating it from other MCP CLI tools.\n\n## Features\n\n### Tools\n\n#### cli-exec-raw\nExecute a raw CLI command and return structured output\n- Takes a command string and optional timeout (default: 5 minutes)\n- Returns detailed execution results including stdout, stderr, exit code\n- Handles errors gracefully with structured error responses\n\n#### cli-exec\nExecute one or more CLI commands in a specific working directory\n- Supports single commands, && chained commands, or array of commands\n- All commands execute in the specified working directory\n- Returns detailed results for each command:\n  - Success/failure status\n  - Exit code\n  - stdout and stderr (ANSI codes stripped)\n  - Execution duration\n  - Working directory\n- Stops on first command failure\n- Optional timeout per command (default: 5 minutes)\n\nNote: Due to execution context limitations, each command runs independently. Directory changes (cd) within commands do not affect subsequent commands. All commands execute in the initially specified working directory.\n\n### Output Format\n\nCommands return structured results including:\n- Success/failure status\n- Exit code\n- stdout and stderr (with ANSI codes stripped)\n- Execution duration\n- Working directory\n- Detailed error information if applicable\n\n### Example Usage\n\n#### cli-exec-raw\nSimple command execution:\n```json\n{\n  \"command\": \"echo Hello World\"\n}\n```\n\nWith timeout:\n```json\n{\n  \"command\": \"long-running-script.sh\",\n  \"timeout\": 300000\n}\n```\n\n#### cli-exec\nSingle command in specific directory:\n```json\n{\n  \"workingDirectory\": \"/path/to/project\",\n  \"commands\": \"npm install\"\n}\n```\n\nMultiple commands (all run in the same working directory):\n```json\n{\n  \"workingDirectory\": \"C:\\\\project\",\n  \"commands\": [\n    \"dir /b\",\n    \"npm run build\"\n  ]\n}\n```\n\n## Installation\n\nOptionally install from npm:\n\n```bash\nnpm install -g mcp-cli-exec\n# or with pnpm\npnpm add -g mcp-cli-exec\n```\nOr just use npx in your configuration\n\n### For Cline VSCode Extension\n\nAdd to `%APPDATA%/Code - Insiders/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-cli-exec\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-cli-exec\"]\n    }\n  }\n}\n```\n\n### For Claude Desktop\n\nAdd to the appropriate config file:\n\nWindows: `%APPDATA%/Claude/claude_desktop_config.json`\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-cli-exec\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-cli-exec\"]\n    }\n  }\n}\n```\n\n### Special Windows Configuration\n\nIf you encounter the ENOENT spawn npx issue on Windows, use this alternative configuration that specifies the full paths:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-cli-exec\": {\n      \"command\": \"C:\\\\Users\\\\jim\\\\AppData\\\\Roaming\\\\nvm\\\\v22.1.0\\\\node.exe\",\n      \"args\": [\n        \"C:\\\\Users\\\\jim\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\bin\\\\npx-cli.js\",\n        \"-y\",\n        \"mcp-cli-exec\"\n      ]\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\npnpm install\n```\n\nBuild the server:\n```bash\npnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\npnpm run watch\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. The MCP Inspector provides helpful debugging tools:\n\n```bash\npnpm run inspector\n```\n\nThis will provide a URL to access the inspector in your browser, where you can:\n- View all MCP messages\n- Inspect request/response payloads\n- Test tools interactively\n- Monitor server state\n\n## Error Handling\n\nThe server includes comprehensive error handling:\n- Input validation for all tool parameters\n- Structured error responses\n- Command timeout handling\n- Working directory validation\n- ANSI code stripping for clean output\n\n## Technical Details\n\n- Built with TypeScript and the MCP SDK\n- Uses execa for reliable command execution\n- Default command timeout: 5 minutes\n- Supports Windows and Unix-like systems (use appropriate commands for your OS, e.g., 'dir' vs 'ls')\n- Executes commands sequentially, stopping on first failure\n- Each command runs independently in the specified working directory\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-cli-exec",
          "npm_downloads": 4285,
          "npm_package_name": "mcp-cli-exec",
          "npm_success": true,
          "npm_error": null
        },
        "Jake-Mok-Nelson--mcp-find-similar-github-issues": {
          "owner": "Jake-Mok-Nelson",
          "name": "mcp-find-similar-github-issues",
          "url": "https://github.com/Jake-Mok-Nelson/mcp-find-similar-github-issues",
          "imageUrl": "https://github.com/Jake-Mok-Nelson.png",
          "description": "Helps support engineers quickly find similar GitHub issues to enhance troubleshooting efficiency using similarity scoring and ranked issue details with direct links.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:08.600388",
          "collection_timestamp": "2025-10-03T04:27:34.036629",
          "stars": 2,
          "forks": 4,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-05T22:32:05Z",
          "updated_at": "2025-05-06T05:58:42Z",
          "open_issues": 1,
          "readme_content": "# GitHub Support Assistant\n\nAn MCP server that helps support engineers find similar GitHub issues to speed up troubleshooting.\n\n## Setup\n\n1. Install dependencies:\n```\nnpm install\n```\n\n2. Set your GitHub token as an environment variable:\n```\nexport GITHUB_TOKEN=your_github_personal_access_token\n```\n\n3. Build the server:\n```\nnpm run build\n```\n\n#### Integrating with Claude:\nUpdate the claude desktop configuration, e.g.\n`code ~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\nUpdate it to include the full path that this repository was cloned to:\n```\n{\n    \"mcpServers\": {\n        \"find-similar-github-issues\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"/Users/<repo_path>/build/index.js\"\n            ]\n        }\n    }\n}\n```\n\n## Features\n\n- Searches for similar issues in a GitHub repository based on issue description\n- Calculates similarity scores to rank results\n- Returns formatted issue details with links\n\n## Usage\n\nThe server provides one tool:\n\n### find-similar-issues\n\nFinds GitHub issues similar to a given description.\n\n**Parameters:**\n- `owner`: GitHub repository owner/organization\n- `repo`: GitHub repository name\n- `issueDescription`: Description of the issue to find similar ones for\n- `maxResults`: Maximum number of similar issues to return (default: 5)\n\n## Implementation Notes\n\nThis implementation uses a simple Jaccard similarity coefficient to compare text. For production use, consider implementing more sophisticated NLP techniques for better similarity matching.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jalehman--mcp-sage": {
          "owner": "jalehman",
          "name": "mcp-sage",
          "url": "https://github.com/jalehman/mcp-sage",
          "imageUrl": "https://github.com/jalehman.png",
          "description": "Provides detailed second opinions, code reviews, and implementation plans by leveraging large context models with automatic model selection based on token count. It integrates file context into prompts for accurate assistance, enabling multi-model debates and self-debate workflows for complex codebases.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:09.145058",
          "collection_timestamp": "2025-10-03T04:27:41.244774",
          "stars": 7,
          "forks": 4,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-04-18T17:13:55Z",
          "updated_at": "2025-09-23T07:54:58Z",
          "open_issues": 1,
          "readme_content": "# `mcp-sage`\n[![smithery badge](https://smithery.ai/badge/@jalehman/mcp-sage)](https://smithery.ai/server/@jalehman/mcp-sage)\n\nAn MCP (Model Context Protocol) server that provides tools for sending prompts to OpenAI's GPT-5, GPT-4.1, Google's Gemini 2.5 Pro, or Anthropic's Claude Opus 4.1 based on token count and configuration. The tools embed all referenced filepaths (recursively for folders) in the prompt. This is useful for getting second opinions or detailed code reviews from models that can handle large amounts of context accurately.\n\n## Rationale\n\nI make heavy use of Claude Code. It's a great product that works well for my workflow. Newer models with large amounts of context seem really useful though for dealing with more complex codebases where more context is needed. This lets me continue to use Claude Code as a development tool while leveraging the large context capabilities of GPT-5, Gemini 2.5 Pro, and other models to augment Claude Code's limited context.\n\n## Model Selection\n\nThe server automatically selects the appropriate model based on token count, with configuration defined in `models.yaml`:\n\n- For smaller contexts (‚â§ 400K tokens): Uses OpenAI's GPT-5 (if OPENAI_API_KEY is set)\n- For medium contexts (‚â§ 1M tokens): Uses Google's Gemini 2.5 Pro (if GEMINI_API_KEY is set)  \n- For fallback (‚â§ 1M tokens): Uses OpenAI's GPT-4.1\n- If the content exceeds 1M tokens: Returns an informative error\n\nFallback behavior:\n- **API Key Fallback**:\n  - If OPENAI_API_KEY is missing, Gemini will be used for all contexts within its 1M token limit\n  - If GEMINI_API_KEY is missing, only smaller contexts can be processed with OpenAI models\n  - If required API keys are missing, an informative error is returned\n\n## Inspiration\n\nThis project draws inspiration from two other open source projects:\n\n- [simonw/files-to-prompt](https://github.com/simonw/files-to-prompt) for the file compression\n- [asadm/vibemode](https://github.com/asadm/vibemode) for the idea and prompt to send the entire repo to Gemini for wholesale edit suggestions\n- [PhialsBasement/Chain-of-Recursive-Thoughts](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) inspiration for the debate functionality\n\n## Overview\n\nThis project implements an MCP server that exposes two primary tools:\n\n### `sage-opinion`\n\n1. Takes a prompt and a list of file/dir paths as input\n2. Packs the files into a structured XML format\n3. Measures the token count and selects the appropriate model:\n   - GPT-5 for ‚â§ 400K tokens\n   - Gemini 2.5 Pro for > 400K and ‚â§ 1M tokens\n   - GPT-4.1 as fallback for ‚â§ 1M tokens\n4. Sends the combined prompt + context to the selected model\n5. Returns the model's response\n\n### `sage-review`\n\n1. Takes an instruction for code changes and a list of file/dir paths as input\n2. Packs the files into a structured XML format\n3. Measures the token count and selects the appropriate model:\n   - GPT-5 for ‚â§ 400K tokens\n   - Gemini 2.5 Pro for > 400K and ‚â§ 1M tokens\n   - GPT-4.1 as fallback for ‚â§ 1M tokens\n4. Creates a specialized prompt instructing the model to format responses using SEARCH/REPLACE blocks\n5. Sends the combined context + instruction to the selected model\n6. Returns edit suggestions formatted as SEARCH/REPLACE blocks for easy implementation\n\n### Debate Mode\n\nBoth `sage-opinion` and `sage-review` support an optional debate mode that can be enabled by adding `debate: true` to the arguments. When enabled, the system orchestrates a structured debate between multiple models to generate higher-quality responses.\n\n--------------------------------------------------------------------\n#### 1. Multi-Model Debate Flow\n```mermaid\nflowchart TD\n  S0[Start Debate] -->|determine models, judge, budgets| R1\n\n  subgraph R1[\"Round 1\"]\n    direction TB\n    R1GEN[\"Generation Phase<br/>*ALL models run in parallel*\"]\n    R1GEN --> R1CRIT[\"Critique Phase<br/>*ALL models critique others in parallel*\"]\n  end\n\n  subgraph RN[\"Rounds 2 to N\"]\n    direction TB\n    SYNTH[\"Synthesis Phase<br/>*every model refines own plan*\"]\n    SYNTH --> CONS[Consensus Check]\n    CONS -->|Consensus reached| JUDGE\n    CONS -->|No consensus & round < N| CRIT[\"Critique Phase<br/>*models critique in parallel*\"]\n    CRIT --> SYNTH\n  end\n\n  R1 --> RN\n  JUDGE[Judgment Phase<br/>*judge model selects/merges response*]\n  JUDGE --> FP[Final Response]\n\n  classDef round fill:#e2eafe,stroke:#4169E1;\n  class R1GEN,R1CRIT,SYNTH,CRIT round;\n  style FP fill:#D0F0D7,stroke:#2F855A,stroke-width:2px\n  style JUDGE fill:#E8E8FF,stroke:#555,stroke-width:1px\n```\n\nKey phases in the multi-model debate:\n\n**Setup Phase**\n- The system determines available models, selects a judge, and allocates token budgets\n\n**Round 1**\n- **Generation Phase** - Every available model (A, B, C, etc.) generates its response in parallel\n- **Critique Phase** - Each model reviews all other responses (never its own) and produces structured critiques in parallel\n\n**Rounds 2 to N** (N defaults to 3)\n1. **Synthesis Phase** - Each model improves its previous response using critiques it received (models work in parallel)\n2. **Consensus Check** - The judge model scores similarity between all current responses\n   - If score ‚â• 0.9, the debate stops early and jumps to Judgment\n3. **Critique Phase** - If consensus is not reached AND we're not in the final round, each model critiques all other responses again (in parallel)\n\n**Judgment Phase**\n- After completing all rounds (or reaching early consensus), the judge model (Claude Opus 4.1 by default):\n  - For sage-opinion: Selects the single best response (no synthesis)\n  - For sage-review: Can either select the best response OR merge multiple responses\n  - Provides a confidence score for its selection/synthesis\n\n--------------------------------------------------------------------\n#### 2. Self-Debate Flow - Single Model Available\n```mermaid\nflowchart TD\n  SD0[Start Self-Debate] --> R1\n\n  subgraph R1[\"Round 1 - Initial Responses\"]\n    direction TB\n    P1[Generate Response 1] --> P2[Generate Response 2<br/>*different approach*]\n    P2 --> P3[Generate Response 3<br/>*different approach*]\n  end\n\n  subgraph RN[\"Rounds 2 to N\"]\n    direction TB\n    REF[Generate Improved Response<br/>*addresses weaknesses in all previous responses*]\n    DEC{More rounds left?}\n    REF --> DEC\n    DEC -->|Yes| REF\n  end\n\n  R1 --> RN\n  DEC -->|No| FP[Final Response = last response generated]\n\n  style FP fill:#D0F0D7,stroke:#2F855A,stroke-width:2px\n```\n\nWhen only one model is available, a [Chain of Recursive Thoughts (CoRT)](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) approach is used:\n\n1. **Initial Burst** - The model generates three distinct responses, each taking a different approach\n2. **Refinement Rounds** - For each subsequent round (2 to N, default N=3):\n   - The model reviews all previous responses\n   - It critiques them internally, identifying strengths and weaknesses\n   - It produces one new improved response that addresses limitations in earlier responses\n3. **Final Selection** - The last response generated becomes the final output\n\n--------------------------------------------------------------------\n### What Actually Happens in Code (quick reference)\n\n| Phase / Functionality | Code Location | Notes |\n|-----------------------|---------------|-------|\n| Generation Prompts    | prompts/debatePrompts.generatePrompt | Creates initial responses from each model |\n| Critique Prompts      | prompts/debatePrompts.critiquePrompt | Uses \"## Critique of {ID}\" sections |\n| Synthesis Prompts     | prompts/debatePrompts.synthesizePrompt | Model revises its own response |\n| Consensus Check       | orchestrator/debateOrchestrator | Judge model returns JSON with `consensusScore` |\n| Judgment              | prompts/debatePrompts.judgePrompt    | Judge returns final response + confidence |\n| Self-Debate Prompt    | prompts/debatePrompts.selfDebatePrompt | [Chain-of-Recursive-Thoughts](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) loop |\n\n#### Performance and Cost Considerations\n\n**‚ö†Ô∏è Important:** When using debate mode:\n- It can take more time to complete (2-5 minutes with multiple models)\n- Consumes more API tokens due to multiple rounds of debate\n- Incurs higher costs than single-model approaches\n\n**Typical resource usage:**\n- Multi-model debate: 2-4x more tokens than a single model approach\n- Processing time: 2-5 minutes depending on complexity and model availability\n- API costs vary by models used and complexity\n\n## Prerequisites\n\n- Node.js (v18 or later)\n- API keys for the models you want to use:\n  - **OpenAI API key** (for GPT-5 and GPT-4.1)\n  - **Google Gemini API key** (for Gemini 2.5 Pro)\n  - **Anthropic API key** (for Claude Opus 4.1 as judge in debates)\n\n**Note:** While the server can function with just one API key, it works best when all three are provided. This enables:\n- Optimal model selection based on token count\n- Multi-model debates for higher quality responses\n- Claude Opus 4.1 as an impartial judge in debate mode\n\n## Installation\n\n### Installing via Smithery\n\nTo install Sage for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jalehman/mcp-sage):\n\n```bash\nnpx -y @smithery/cli install @jalehman/mcp-sage --client claude\n```\n\n### Installing manually\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-username/mcp-sage.git\ncd mcp-sage\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Environment Variables\n\nSet the following environment variables:\n\n- `OPENAI_API_KEY`: Your OpenAI API key (for GPT-5 and GPT-4.1 models)\n- `GEMINI_API_KEY`: Your Google Gemini API key (for Gemini 2.5 Pro)\n- `ANTHROPIC_API_KEY`: Your Anthropic API key (for Claude Opus 4.1)\n\n**Recommended:** Provide all three API keys for the best experience. This ensures:\n- The server can select the optimal model for any token count\n- Debate mode works with multiple diverse models\n- Claude Opus 4.1 serves as an effective judge in debates\n\n## Usage\n\nAfter building with `npm run build`, add the following to your MCP configuration:\n\n```sh\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key node /path/to/this/repo/dist/index.js\n```\n\nYou can also use environment variables set elsewhere, like in your shell profile.\n\n## Prompting\n\nTo get a second opinion on something just ask for a second opinion.\n\nTo get a code review, ask for a code review or expert review.\n\nBoth of these benefit from providing paths of files that you wnat to be included in context, but if omitted the host LLM will probably infer what to include.\n\n### Debugging and Monitoring\n\nThe server provides detailed monitoring information via the MCP logging capability. These logs include:\n\n- Token usage statistics and model selection\n- Number of files and documents included in the request\n- Request processing time metrics\n- Error information when token limits are exceeded\n\nLogs are sent via the MCP protocol's `notifications/message` method, ensuring they don't interfere with the JSON-RPC communication. MCP clients with logging support will display these logs appropriately.\n\nExample log entries:\n```\nToken usage: 1,234 tokens. Selected model: gpt-5-2025-08-07 (limit: 400,000 tokens)\nFiles included: 3, Document count: 3\nSending request to OpenAI gpt-5-2025-08-07 with 1,234 tokens...\nReceived response from gpt-5-2025-08-07 in 982ms\n```\n\n```\nToken usage: 435,678 tokens. Selected model: gemini-2.5-pro (limit: 1,000,000 tokens)\nFiles included: 25, Document count: 18\nSending request to Gemini with 435,678 tokens...\nReceived response from gemini-2.5-pro in 3240ms\n```\n\n### Using the Tools\n\n#### sage-opinion Tool\n\nThe `sage-opinion` tool accepts the following parameters:\n\n- `prompt` (string, required): The prompt to send to the selected model\n- `paths` (array of strings, required): List of file paths to include as context\n- `debate` (boolean, optional): Enable multi-model debate mode for higher quality responses\n\nExample MCP tool call (using JSON-RPC 2.0):\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"sage-opinion\",\n    \"arguments\": {\n      \"prompt\": \"Explain how this code works\",\n      \"paths\": [\"path/to/file1.js\", \"path/to/file2.js\"]\n    }\n  }\n}\n```\n\n#### sage-review Tool\n\nThe `sage-review` tool accepts the following parameters:\n\n- `instruction` (string, required): The specific changes or improvements needed\n- `paths` (array of strings, required): List of file paths to include as context\n- `debate` (boolean, optional): Enable multi-model debate mode for higher quality responses\n\nExample MCP tool call (using JSON-RPC 2.0):\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"sage-review\",\n    \"arguments\": {\n      \"instruction\": \"Add error handling to the function\",\n      \"paths\": [\"path/to/file1.js\", \"path/to/file2.js\"]\n    }\n  }\n}\n```\n\nThe response will contain SEARCH/REPLACE blocks that you can use to implement the suggested changes:\n\n```\n<<<<<<< SEARCH\nfunction getData() {\n  return fetch('/api/data')\n    .then(res => res.json());\n}\n=======\nfunction getData() {\n  return fetch('/api/data')\n    .then(res => {\n      if (!res.ok) {\n        throw new Error(`HTTP error! Status: ${res.status}`);\n      }\n      return res.json();\n    })\n    .catch(error => {\n      console.error('Error fetching data:', error);\n      throw error;\n    });\n}\n>>>>>>> REPLACE\n```\n\nWhen using debate mode with either tool, the system will:\n\n1. Generate initial responses from multiple models (GPT-5 and Gemini by default)\n2. Have models critique each other's responses\n3. Allow models to refine their responses based on critiques\n4. Use a judge model (Claude Opus 4.1 by default) to select or synthesize the best response\n\nThis results in more thoughtful and comprehensive responses at the cost of additional time and API usage.\n\n## Running the Tests\n\nTo test the tools:\n\n```bash\n# Test the sage-opinion tool\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key node test/run-test.js\n\n# Test the sage-review tool\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key node test/test-expert.js\n\n# Test debate mode\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key ANTHROPIC_API_KEY=your_anthropic_key node test/run-sage-opinion-debate.js\n```\n\n**Note**: Tests using debate mode may take 2-5 minutes to run as they orchestrate multi-model interactions.\n\n## Project Structure\n\n- `src/index.ts`: The main MCP server implementation with tool definitions\n- `src/pack.ts`: Tool for packing files into a structured XML format\n- `src/tokenCounter.ts`: Utilities for counting tokens in a prompt\n- `src/gemini.ts`: Gemini API client implementation\n- `src/openai.ts`: OpenAI API client implementation for O3 model\n- `src/orchestrator/debateOrchestrator.ts`: Multi-model debate orchestration\n- `src/prompts/debatePrompts.ts`: Templates for debate prompts and instructions\n- `test/run-test.js`: Test for the sage-opinion tool\n- `test/test-expert.js`: Test for the sage-review tool\n- `test/run-sage-opinion-debate.js`: Test for debate mode functionality\n\n## License\n\nISC\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jamsocket--forevervm": {
          "owner": "jamsocket",
          "name": "forevervm",
          "url": "https://github.com/jamsocket/forevervm",
          "imageUrl": "https://github.com/jamsocket.png",
          "description": "Enable agents to execute Python code seamlessly within a REPL environment, allowing for on-the-fly script creation and execution. It enhances automation and coding capabilities directly within workflows.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:09.649104",
          "collection_timestamp": "2025-10-03T04:27:44.864199",
          "stars": 217,
          "forks": 20,
          "license": "MIT License",
          "language": "Rust",
          "created_at": "2025-01-18T14:15:35Z",
          "updated_at": "2025-09-18T11:53:49Z",
          "open_issues": 2,
          "readme_content": "[foreverVM](https://forevervm.com)\n==================================\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/jamsocket/forevervm?style=social)](https://github.com/jamsocket/forevervm)\n[![Chat on Discord](https://img.shields.io/discord/939641163265232947?color=404eed&label=discord)](https://discord.gg/N5sEpsuhh9)\n\n| repo                                                | version                     |\n|-----------------------------------------------------|------------------------------|\n| [cli](https://github.com/jamsocket/forevervm) | [![npm](https://img.shields.io/npm/v/forevervm)](https://www.npmjs.com/package/forevervm) |\n| [sdk](https://github.com/jamsocket/forevervm) | [![npm](https://img.shields.io/npm/v/@forevervm/sdk)](https://www.npmjs.com/package/@forevervm/sdk) |\n\nforeverVM provides an API for running arbitrary, stateful Python code securely.\n\nThe core concepts in foreverVM are **machines** and **instructions**.\n\n**Machines** represent a stateful Python process. You interact with a machine by running **instructions**\n(Python statements and expressions) on it, and receiving the results. A machine processes one instruction\nat a time.\n\nGetting started\n---------------\n\nYou will need an API token (if you need one, reach out to [paul@jamsocket.com](mailto:paul@jamsocket.com)).\n\nThe easiest way to try out foreverVM is using the CLI. First, you will need to log in:\n\n```bash\nnpx forevervm login\n```\n\nOnce logged in, you can open a REPL interface with a new machine:\n\n```bash\nnpx forevervm repl\n```\n\nWhen foreverVM starts your machine, it gives it an ID that you can later use to reconnect to it. You can reconnect to a machine like this:\n\n```bash\nnpx forevervm repl [machine_name]\n```\n\nYou can list your machines (in reverse order of creation) like this:\n\n```bash\nnpx forevervm machine list\n```\n\nYou don't need to terminate machines -- foreverVM will automatically swap them from memory to disk when they are idle, and then\nautomatically swap them back when needed. This is what allows foreverVM to run repls ‚Äúforever‚Äù.\n\nUsing the API\n-------------\n\n```typescript\nimport { ForeverVM } from '@forevervm/sdk'\n\nconst token = process.env.FOREVERVM_TOKEN\nif (!token) {\n  throw new Error('FOREVERVM_TOKEN is not set')\n}\n\n// Initialize foreverVM\nconst fvm = new ForeverVM({ token })\n\n// Connect to a new machine.\nconst repl = fvm.repl()\n\n// Execute some code\nlet execResult = repl.exec('4 + 4')\n\n// Get the result\nconsole.log('result:', await execResult.result)\n\n// We can also print stdout and stderr\nexecResult = repl.exec('for i in range(10):\\n  print(i)')\n\nfor await (const output of execResult.output) {\n  console.log(output.stream, output.data)\n}\n\nprocess.exit(0)\n```\n\nWorking with Tags\n----------------\n\nYou can create machines with tags and filter machines by tags:\n\n```typescript\nimport { ForeverVM } from '@forevervm/sdk'\n\nconst fvm = new ForeverVM({ token: process.env.FOREVERVM_TOKEN })\n\n// Create a machine with tags\nconst machineResponse = await fvm.createMachine({\n  tags: { \n    env: 'production', \n    owner: 'user123',\n    project: 'demo'\n  }\n})\n\n// List machines filtered by tags\nconst productionMachines = await fvm.listMachines({\n  tags: { env: 'production' }\n})\n```\n\nMemory Limits\n----------------\n\nYou can create machines with memory limits by specifying the memory size in megabytes:\n\n```typescript\n// Create a machine with 512MB memory limit\nconst machineResponse = await fvm.createMachine({\n  memory_mb: 512,\n})\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/forevervm",
          "npm_downloads": 2784,
          "npm_package_name": "forevervm",
          "npm_success": true,
          "npm_error": null
        },
        "jango-blockchained--mcp-freecad": {
          "owner": "jango-blockchained",
          "name": "mcp-freecad",
          "url": "https://github.com/jango-blockchained/mcp-freecad",
          "imageUrl": "https://github.com/jango-blockchained.png",
          "description": "Integrates AI assistants with FreeCAD for interaction and manipulation of CAD models. Provides a standardized protocol for executing commands and receiving real-time updates, facilitating intelligent automation and integration with design workflows.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:10.315597",
          "collection_timestamp": "2025-10-03T04:27:52.305807",
          "stars": 14,
          "forks": 2,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-31T04:41:49Z",
          "updated_at": "2025-09-14T20:26:46Z",
          "open_issues": 4,
          "readme_content": "# üõ†Ô∏è MCP-FreeCAD Integration\n\n> **Status:** Active Development - Clean, organized codebase with multiple connection methods and comprehensive tool providers.\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)\n[![Code style: flake8](https://img.shields.io/badge/code%20style-flake8-orange.svg)](https://flake8.pycqa.org/en/latest/)\n[![Project Status: Active](https://img.shields.io/badge/repo%20status-active-green.svg)]()\n\nThis project provides a robust integration between AI assistants and FreeCAD CAD software using the **Model Context Protocol (MCP)**. It allows external applications to interact with FreeCAD through a standardized interface, offering multiple connection methods and specialized tools.\n\n---\n\n## ü§ñ **AI Provider Models (2025)**\n\nThe MCP-FreeCAD integration supports multiple AI providers with the latest 2025 models. Choose the right model for your specific use case:\n\n### **OpenAI Models**\n\n#### **Production Models:**\n- **gpt-4o** - Default multimodal model (text, image, audio)\n  - Context: 128K tokens\n  - Pricing: ~$5 per 1M input tokens\n  - Best for: General CAD tasks, multimodal interactions\n\n- **gpt-4.1** - Next-generation with 1M token context\n  - Features: Text, Image, Audio, Video support\n  - Pricing: ~$2.5 per 1M input tokens\n  - Best for: Complex CAD projects, large document analysis\n\n- **gpt-4-turbo** - Fast, cost-effective\n  - Context: 128K tokens\n  - Best for: High-volume operations, batch processing\n\n#### **Reasoning Models:**\n- **o3** - Advanced reasoning for complex CAD logic\n  - Pricing: ~$10 per 1M input tokens\n  - Best for: Complex geometry calculations, design optimization\n\n- **o4-mini** / **o4-mini-high** - Cost-effective reasoning\n  - Pricing: ~$0.15 per 1M input tokens\n  - Best for: Simple calculations, quick iterations\n\n### **Anthropic Claude Models**\n\n#### **Claude 4 Series (2025):**\n- **claude-opus-4** - Most advanced model\n  - Max Context: 200K tokens\n  - Pricing: $15/$75 per million tokens (input/output)\n  - Features: Extended thinking, tool use, memory handling\n  - Best for: Complex CAD workflows, autonomous design tasks\n\n- **claude-sonnet-4** - Balanced efficiency\n  - Max Context: 200K tokens  \n  - Pricing: $3/$15 per million tokens\n  - Features: Superior coding, hybrid reasoning\n  - Best for: General CAD operations, scripting assistance\n\n- **claude-haiku-3.5** - Fast, lightweight\n  - Best for: Quick queries, simple operations\n\n### **Google AI Models**\n\n#### **Gemini 2.5 Series (Latest):**\n- **gemini-2.5-pro-preview-05-06** - Most advanced\n  - Context: 1M tokens\n  - Features: Enhanced reasoning, thinking mode\n  - Best for: Complex CAD analysis, large assemblies\n\n- **gemini-2.5-flash-preview-04-17** - Performance optimized\n  - Features: Adaptive thinking, cost-effective\n  - Best for: Balanced performance and cost\n\n#### **Gemini 2.0 Series (Stable):**\n- **gemini-2.0-flash-001** - Production ready\n  - Features: 2x faster than Gemini 1.5 Pro\n  - Best for: Real-time CAD assistance\n\n- **gemini-2.0-flash-lite** - Cost-optimized\n  - Best for: High-volume, simple operations\n\n### **OpenRouter (Unified Access)**\n\nOpenRouter provides access to all models through a single API:\n\n#### **Model Format:** `provider/model-name`\n\n**Popular Models:**\n- `anthropic/claude-sonnet-4` - Recommended general use\n- `openai/gpt-4o` - OpenAI's flagship\n- `google/gemini-2.5-pro-preview` - Google's latest\n\n**Free Models (50-1000 requests/day):**\n- `deepseek/deepseek-r1` - Advanced reasoning\n- `deepseek/deepseek-v3` - General purpose\n- `google/gemini-2.5-flash-preview` - Google free tier\n\n### **Model Selection Guide**\n\n| **Use Case** | **Recommended Model** | **Alternative** |\n|-------------|---------------------|----------------|\n| **General CAD Work** | `claude-sonnet-4` | `gpt-4o`, `gemini-2.0-flash-001` |\n| **Complex Reasoning** | `claude-opus-4` | `o3`, `gemini-2.5-pro-preview-05-06` |\n| **Multimodal Tasks** | `gpt-4o` | `gpt-4.1`, `claude-opus-4` |\n| **Cost-Effective** | `o4-mini` | `claude-haiku-3.5`, `gemini-2.0-flash-lite` |\n| **High Volume** | `gpt-4-turbo` | `claude-sonnet-4`, `gemini-2.0-flash-001` |\n| **Free Usage** | `deepseek/deepseek-r1` | `google/gemini-2.5-flash-preview` |\n\n### **Configuration Example**\n\n```json\n{\n  \"providers\": {\n    \"anthropic\": {\n      \"enabled\": true,\n      \"model\": \"claude-sonnet-4\",\n      \"thinking_mode\": true,\n      \"max_tokens\": 64000\n    },\n    \"openai\": {\n      \"enabled\": true,\n      \"model\": \"gpt-4o\",\n      \"max_tokens\": 32000\n    },\n    \"google\": {\n      \"enabled\": true,\n      \"model\": \"gemini-2.0-flash-001\",\n      \"thinking_mode\": true\n    },\n    \"openrouter\": {\n      \"enabled\": true,\n      \"model\": \"anthropic/claude-sonnet-4\",\n      \"free_models\": [\"deepseek/deepseek-r1\"]\n    }\n  }\n}\n```\n\n### **API Usage Examples**\n\n```python\n# Using specific provider\nfrom freecad_ai import CADAssistant\n\n# Initialize with Claude Sonnet 4\nassistant = CADAssistant(provider=\"anthropic\", model=\"claude-sonnet-4\")\n\n# Create complex geometry\nresult = assistant.generate_cad_script(\n    \"Create a parametric gear with 20 teeth, 5mm module, and 20¬∞ pressure angle\"\n)\n\n# Using OpenRouter for cost optimization\nassistant_free = CADAssistant(\n    provider=\"openrouter\", \n    model=\"deepseek/deepseek-r1\"\n)\n\n# Quick operations with free model\nresult = assistant_free.create_primitive(\"box\", length=10, width=5, height=3)\n```\n\n---\n\n## üöÄ **Quick Start**\n\n### Option 1: FreeCAD Addon (Recommended for Users)\nFor the best user experience with GUI integration:\n\nüì¶ **[FreeCAD MCP Integration Addon](freecad-ai/README.md)**\n\n- üß† **Claude 4 with Thinking Mode** - Advanced AI reasoning\n- ü§ñ **Multi-Provider Support** - Claude, Gemini, OpenRouter with 13+ models  \n- üé® **Modern GUI** - Professional tabbed interface\n- üîó **Universal Connections** - All MCP connection methods\n- üìä **Performance Monitoring** - Real-time diagnostics\n\n### Option 2: MCP Server (For Developers/Integration)\n\n```bash\n# Clone the repository\ngit clone https://github.com/jango-blockchained/mcp-freecad.git\ncd mcp-freecad\n\n# Install dependencies\npip install -r requirements.txt\n\n# Start the MCP server\npython -m src.mcp_freecad.main\n\n# Or with custom config\npython -m src.mcp_freecad.main --config my_config.json --debug\n```\n\n---\n\n## üèóÔ∏è **Architecture Overview**\n\n### Core Components\n\n```\nsrc/mcp_freecad/\n‚îú‚îÄ‚îÄ main.py                 # Main entry point\n‚îú‚îÄ‚îÄ __init__.py            # Package exports and registry\n‚îú‚îÄ‚îÄ client/                # FreeCAD connection management\n‚îÇ   ‚îî‚îÄ‚îÄ freecad_connection_manager.py\n‚îú‚îÄ‚îÄ server/                # MCP server implementation\n‚îÇ   ‚îî‚îÄ‚îÄ freecad_mcp_server.py\n‚îú‚îÄ‚îÄ tools/                 # Tool providers\n‚îÇ   ‚îú‚îÄ‚îÄ base.py           # Base tool provider class\n‚îÇ   ‚îú‚îÄ‚îÄ primitives.py     # Primitive shapes (box, cylinder, etc.)\n‚îÇ   ‚îú‚îÄ‚îÄ model_manipulation.py # Transform, boolean ops, etc.\n‚îÇ   ‚îú‚îÄ‚îÄ export_import.py  # File format handling\n‚îÇ   ‚îú‚îÄ‚îÄ measurement.py    # Analysis tools\n‚îÇ   ‚îî‚îÄ‚îÄ code_generator.py # Code generation\n‚îú‚îÄ‚îÄ core/                  # Core infrastructure\n‚îÇ   ‚îú‚îÄ‚îÄ server.py         # FastAPI-based server\n‚îÇ   ‚îú‚îÄ‚îÄ cache.py          # Resource caching\n‚îÇ   ‚îú‚îÄ‚îÄ diagnostics.py    # Performance monitoring\n‚îÇ   ‚îî‚îÄ‚îÄ recovery.py       # Connection recovery\n‚îî‚îÄ‚îÄ connections/           # Connection backends\n```\n\n### Connection Methods\n\nThe system supports multiple ways to connect to FreeCAD:\n\n1. **üöÄ Launcher** (Recommended) - Uses AppImage with AppRun\n2. **üîå Server** - Socket-based connection to FreeCAD server\n3. **üåâ Bridge** - CLI-based connection using FreeCAD executable\n4. **üì° RPC** - XML-RPC connection to FreeCAD\n5. **üì¶ Wrapper** - Subprocess wrapper connection\n6. **üé≠ Mock** - For testing without FreeCAD\n\n---\n\n## üõ†Ô∏è **Available Tools**\n\n### Primitive Creation\n- `create_box` - Create box primitives\n- `create_cylinder` - Create cylinders\n- `create_sphere` - Create spheres  \n- `create_cone` - Create cones\n\n### Model Manipulation\n- `transform` - Move, rotate objects\n- `boolean_operation` - Union, difference, intersection\n- `fillet_edge` - Round edges\n- `chamfer_edge` - Chamfer edges\n- `mirror` - Mirror objects across planes\n- `scale` - Scale objects uniformly or non-uniformly\n\n### Document Management\n- `create_document` - Create new documents\n- `list_documents` - List open documents\n- `list_objects` - List objects in documents\n\n### Export/Import\n- `export_stl` - Export to STL format\n- Additional formats coming soon\n\n---\n\n## üìã **Usage Examples**\n\n### Python API\n\n```python\nfrom src.mcp_freecad import FreeCADConnection, PrimitiveToolProvider\n\n# Create connection (auto-selects best method)\nfc = FreeCADConnection(auto_connect=True)\n\nif fc.is_connected():\n    print(f\"Connected via: {fc.get_connection_type()}\")\n    \n    # Create a document\n    doc_name = fc.create_document(\"MyProject\")\n    \n    # Create objects\n    box = fc.create_box(length=20, width=10, height=5)\n    cylinder = fc.create_cylinder(radius=3, height=10)\n    \n    # Export\n    fc.export_stl(box, \"my_box.stl\")\n```\n\n### Tool Provider Usage\n\n```python\nfrom src.mcp_freecad.tools.primitives import PrimitiveToolProvider\n\n# Initialize tool provider\nprimitives = PrimitiveToolProvider()\n\n# Execute tools\nresult = await primitives.execute_tool(\"create_box\", {\n    \"length\": 10.0,\n    \"width\": 5.0, \n    \"height\": 3.0\n})\n\nprint(f\"Created: {result.result['object_id']}\")\n```\n\n### MCP Server Integration\n\n```python\nfrom src.mcp_freecad.core.server import MCPServer\nfrom src.mcp_freecad import TOOL_PROVIDERS\n\n# Setup server\nserver = MCPServer()\n\n# Register tool providers\nserver.register_tool(\"primitives\", TOOL_PROVIDERS[\"primitives\"]())\nserver.register_tool(\"model_manipulation\", TOOL_PROVIDERS[\"model_manipulation\"]())\n\n# Initialize and run\nawait server.initialize()\n```\n\n---\n\n## ‚öôÔ∏è **Configuration**\n\n### Basic Configuration (`config.json`)\n\n```json\n{\n  \"server\": {\n    \"name\": \"mcp-freecad-server\",\n    \"version\": \"0.7.11\"\n  },\n  \"freecad\": {\n    \"connection_method\": \"auto\",\n    \"host\": \"localhost\",\n    \"port\": 12345,\n    \"freecad_path\": \"freecad\"\n  },\n  \"tools\": {\n    \"enable_primitives\": true,\n    \"enable_model_manipulation\": true,\n    \"enable_export_import\": true\n  }\n}\n```\n\n### Connection Method Configuration\n\n```json\n{\n  \"freecad\": {\n    \"connection_method\": \"launcher\",\n    \"use_apprun\": true,\n    \"apprun_path\": \"/path/to/squashfs-root/AppRun\",\n    \"script_path\": \"/path/to/freecad_launcher_script.py\"\n  }\n}\n```\n\n---\n\n## üîß **Development**\n\n### Project Structure\n\n- **`src/mcp_freecad/`** - Main package\n- **`freecad-ai/`** - FreeCAD GUI addon\n- **`tests/`** - Test suite\n- **`docs/`** - Documentation\n- **`scripts/`** - Setup and utility scripts\n\n### Adding New Tools\n\n1. Create a new tool provider in `src/mcp_freecad/tools/`\n2. Inherit from `ToolProvider` base class\n3. Implement required methods (`tool_schema`, `execute_tool`)\n4. Register in `TOOL_PROVIDERS` in `__init__.py`\n\n```python\nfrom .base import ToolProvider, ToolResult, ToolSchema\n\nclass MyToolProvider(ToolProvider):\n    @property\n    def tool_schema(self) -> ToolSchema:\n        return ToolSchema(\n            name=\"my_tool\",\n            description=\"My custom tool\",\n            parameters={...},\n            returns={...}\n        )\n    \n    async def execute_tool(self, tool_id: str, params: Dict[str, Any]) -> ToolResult:\n        # Implementation\n        return self.format_result(status=\"success\", result=result)\n```\n\n### Testing\n\n```bash\n# Run tests\npython -m pytest tests/\n\n# Run with coverage\npython -m pytest tests/ --cov=src --cov-report=html\n\n# Run specific test\npython -m pytest tests/test_primitives.py -v\n```\n\n---\n\n## üê≥ **Docker Support**\n\n```bash\n# Build and run with Docker Compose\ndocker compose up\n\n# Build from scratch\ndocker compose build --no-cache\ndocker compose up\n```\n\n---\n\n## üìö **Documentation**\n\n- [FreeCAD Integration Guide](docs/FREECAD_INTEGRATION.md)\n- [Connection Methods](docs/CONNECTION_METHODS.md)\n- [Tool Development](docs/TOOL_DEVELOPMENT.md)\n- [Configuration Reference](docs/CONFIGURATION.md)\n\n---\n\n## ü§ù **Contributing**\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Add tests\n5. Submit a pull request\n\n---\n\n## üìÑ **License**\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\n## üôè **Acknowledgments**\n\n- FreeCAD development team for the excellent CAD software\n- Anthropic for the Model Context Protocol (MCP) framework\n- Contributors and community members\n\n---\n\n<div align=\"center\">\n<sub>\nüõ†Ô∏è <strong>MCP-FreeCAD Integration</strong> - Bridging AI and CAD through advanced connectivity<br>\nCrafted with ‚ù§Ô∏è by jango-blockchained ‚Ä¢ 2025\n</sub>\n</div>\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jankowtf--mcp-hitchcode": {
          "owner": "jankowtf",
          "name": "mcp-hitchcode",
          "url": "https://github.com/jankowtf/mcp-hitchcode",
          "imageUrl": "https://github.com/jankowtf.png",
          "description": "Create custom tools for Cursor IDE that provide structured coding assistance and code templates. Easily deploy the server on Heroku or run it locally using Docker.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:10.815690",
          "collection_timestamp": "2025-10-03T04:27:59.466994",
          "stars": 2,
          "forks": 3,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-02-24T16:45:36Z",
          "updated_at": "2025-03-15T13:48:09Z",
          "open_issues": 2,
          "readme_content": "# MCP Server Template for Cursor IDE\n\nA simple template for creating custom tools for Cursor IDE using Model Context Protocol (MCP). Create your own repository from this template, modify the tools, and connect them to your Cursor IDE.\n\n![Server Mood Response](docs/images/server-mood.png)\n\n## Quick Start\n\n1. Click \"Deploy to Heroku\" button\n\n    [![Deploy to Heroku](https://www.herokucdn.com/deploy/button.svg)](https://heroku.com/deploy?template=https://github.com/kirill-markin/weaviate-mcp-server)\n\n2. After deployment, configure Cursor:\n   - Open Cursor Settings ‚Üí Features\n   - Add new MCP server\n   - Use your Heroku URL with `/sse` path (e.g., `https://<your-app-name>.herokuapp.com/sse`)\n\n3. Test your agent's mood in Cursor:\n   - Ask your agent \"Please ask about our server mood and let me know how it is.\"\n   - The server will respond with a cheerful message and a heart ‚ù§Ô∏è\n\n## Alternative Setup Methods\n\nYou can run the server in three ways: using Docker, traditional Python setup, or directly in Cursor IDE.\n\n### Docker Setup\n\nThe project includes Docker support for easy deployment:\n\n1. Initial setup:\n```bash\n# Clone the repository\ngit clone https://github.com/kirill-markin/weaviate-mcp-server.git\ncd weaviate-mcp-server\n\n# Create environment file\ncp .env.example .env\n```\n\n2. Build and run using Docker Compose:\n```bash\n# Build and start the server\ndocker compose up --build -d\n\n# View logs\ndocker compose logs -f\n\n# Check server status\ndocker compose ps\n\n# Stop the server\ndocker compose down\n```\n\n3. The server will be available at:\n   - SSE endpoint: http://localhost:8000/sse\n\n4. Quick test:\n```bash\n# Test the server endpoint\ncurl -i http://localhost:8000/sse\n```\n\n5. Connect to Cursor IDE:\n   - Open Cursor Settings ‚Üí Features\n   - Add new MCP server\n   - Type: Select \"sse\"\n   - URL: Enter `http://localhost:8000/sse`\n\n### Traditional Setup\n\nFirst, install the uv package manager:\n\n```bash\n# Install uv on macOS\nbrew install uv\n# Or install via pip (any OS)\npip install uv\n```\n\nStart the server using either stdio (default) or SSE transport:\n\n```bash\n# Install the package with development dependencies\nuv pip install -e \".[dev]\"\n\n# Using stdio transport (default)\nuv run mcp-hitchcode\n\n# Using SSE transport on custom port\nuv run mcp-hitchcode --transport sse --port 8000\n\n# Run tests\nuv run pytest -v\n```\n\nAfter installation, you can connect the server directly to Cursor IDE:\n\n1. Right-click on the `cursor-run-mcp-server.sh` file in Cursor\n2. Select \"Copy Path\" to copy the absolute path\n3. Open Cursor Settings (gear icon)\n4. Navigate to Features tab\n5. Scroll down to \"MCP Servers\"\n6. Click \"Add new MCP server\"\n7. Fill in the form:\n   - Name: Choose any name (e.g., \"my-mcp-server-1\")\n   - Type: Select \"stdio\" (not \"sse\" because we run the server locally)\n   - Command: Paste the absolute path to `cursor-run-mcp-server.sh` that you copied earlier. For example: `/Users/kirillmarkin/weaviate-mcp-server/cursor-run-mcp-server.sh`\n\n### Environment Variables\n\nAvailable environment variables (can be set in `.env`):\n\n- `MCP_SERVER_PORT` (default: 8000) - Port to run the server on\n- `MCP_SERVER_HOST` (default: 0.0.0.0) - Host to bind the server to\n- `DEBUG` (default: false) - Enable debug mode\n- `MCP_USER_AGENT` - Custom User-Agent for website fetching\n\n## Additional options\n\n### Installing via Smithery\n\n[![smithery badge](https://smithery.ai/badge/@kirill-markin/example-mcp-server)](https://smithery.ai/server/@kirill-markin/example-mcp-server)\n\nTo install MCP Server Template for Cursor IDE for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kirill-markin/example-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @kirill-markin/example-mcp-server --client claude\n```\n\n### Glama server review\n\n<a href=\"https://glama.ai/mcp/servers/jgisqn8zco\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/jgisqn8zco/badge\" alt=\"Server Template for Cursor IDE MCP server\" /></a>\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "janwilmake--openapi-mcp-server": {
          "owner": "janwilmake",
          "name": "openapi-mcp-server",
          "url": "https://github.com/janwilmake/openapi-mcp-server",
          "imageUrl": "https://github.com/janwilmake.png",
          "description": "Enables exploration and understanding of OpenAPI specifications with a simple interface for retrieving overviews and detailed explanations of API operations. Supports both JSON and YAML formats for seamless integration with Claude Desktop and Cursor clients.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:11.384641",
          "collection_timestamp": "2025-10-03T04:28:03.033508",
          "stars": 826,
          "forks": 89,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2024-12-07T18:14:50Z",
          "updated_at": "2025-10-01T22:15:20Z",
          "open_issues": 7,
          "readme_content": "# OpenAPI MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@janwilmake/openapi-mcp-server)](https://smithery.ai/server/@janwilmake/openapi-mcp-server) [![janwilmake/openapi-mcp-server context](https://badge.forgithub.com/janwilmake/openapi-mcp-server?excludePathPatterns=*.yaml)](https://uithub.com/janwilmake/openapi-mcp-server?excludePathPatterns=*.yaml)\n\nA Model Context Protocol (MCP) server for Claude/Cursor that enables searching and exploring OpenAPI specifications through oapis.org.\n\n- Demo: https://x.com/janwilmake/status/1903497808134496583\n- HN Thread: https://news.ycombinator.com/item?id=43447278\n- OpenAPISearch: https://github.com/janwilmake/openapisearch\n- OAPIS: https://github.com/janwilmake/oapis\n\nThe MCP works by applying a 3 step process :\n\n1. It figures out the openapi identifier you need\n2. It requests a summary of that in simple language\n3. It determines which endpoints you need, and checks out how exactly they work (again, in simple language)\n\n## Features\n\n- Get an overview of any OpenAPI specification\n- Retrieve details about specific API operations\n- Support for both JSON and YAML formats\n- Tested with Claude Desktop and Cursor\n\n| Summary                                       | Prompt it                                                                                                                                                                                                                                                                                                                                                 |\n| --------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Basic understanding of the OpenAPI MCP Server | [![](https://b.lmpify.com/overview)](https://lmpify.com?q=https%3A%2F%2Fuuithub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3DREADME.md%26pathPatterns%3Dopenapi-mcp.drawio.png%0A%0ACan%20you%20explain%20what%20OpenAPI%20MCP%20Server%20does%20and%20how%20I%20can%20use%20it%20with%20Claude%20Desktop%3F)                     |\n| Core implementation details of the MCP server | [![](https://b.lmpify.com/implementation)](https://lmpify.com?q=https%3A%2F%2Fuuithub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3Dindex.js%26pathPatterns%3Dpackage.json%0A%0AHow%20does%20the%20OpenAPI%20MCP%20Server%20handle%20API%20requests%3F%20Can%20you%20explain%20the%20tool%20handlers%3F)                           |\n| How to extend or contribute to the project    | [![](https://b.lmpify.com/extend)](https://lmpify.com?q=https%3A%2F%2Fuuithub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3Dindex.js%26pathPatterns%3Dpackage.json%26pathPatterns%3DREADME.md%0A%0AI'd%20like%20to%20add%20support%20for%20a%20new%20feature%20to%20the%20OpenAPI%20MCP%20Server.%20Where%20should%20I%20start%3F) |\n\n## Installation\n\n### Installing via Smithery\n\nOur hosted smithery URL is https://smithery.ai/server/@janwilmake/openapi-mcp-server\n\nTo install openapi-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@janwilmake/openapi-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @janwilmake/openapi-mcp-server --client claude\n```\n\nFor other clients, see the [smithery page](https://smithery.ai/server/@janwilmake/openapi-mcp-server) for instructions.\n\n### Installing using stdio\n\n```\n{\n  \"mcpServers\": {\n    \"openapi-mcp-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/openapi-mcp-server/index.js\"],\n      \"env\": {\n        \"DEBUG\": \"true\"\n      }\n    }\n  }\n}\n```\n\n## Usage in Claude\n\nOnce installed, you can ask Claude to:\n\n- \"Find information about the Stripe API\"\n- \"Explain how to use the GitHub API's repository endpoints\"\n\nClaude will use the MCP server to:\n\n1. First get an overview of the requested API\n2. Then retrieve specific operation details as needed\n\n## Requirements\n\n- Node.js >= 16.17.0\n- Claude Desktop, Cursor, or any other MCP client.\n\n## License\n\nMIT\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/openapi-mcp-server",
          "npm_downloads": 10334,
          "npm_package_name": "openapi-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "janwilmake--uithub-mcp": {
          "owner": "janwilmake",
          "name": "uithub-mcp",
          "url": "https://github.com/janwilmake/uithub-mcp",
          "imageUrl": "https://github.com/janwilmake.png",
          "description": "Enables natural language exploration and analysis of GitHub repositories by retrieving their contents with advanced filtering options. Integrates with Claude Desktop for enhanced code understanding and discussion.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:11.923692",
          "collection_timestamp": "2025-10-03T04:28:06.536003",
          "stars": 15,
          "forks": 2,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-12T18:43:06Z",
          "updated_at": "2025-09-27T12:23:50Z",
          "open_issues": 2,
          "readme_content": "# UIThub MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@janwilmake/uithub-mcp)](https://smithery.ai/server/@janwilmake/uithub-mcp)\n\nModel Context Protocol (MCP) server for interacting with the [uithub API](https://uithub.com), which provides a convenient way to fetch GitHub repository contents.\n\nThis MCP server allows Claude to retrieve and analyze code from GitHub repositories, making it a powerful tool for understanding and discussing code.\n\n## TODO\n\n- ‚úÖ Simple MCP Server for Claude Desktop\n- Make MCP for cursor too https://docs.cursor.com/context/model-context-protocol\n- MCP cline support https://github.com/cline/mcp-marketplace\n- Button to learn to install MCPs on separate page.\n- Add patch api to MCP Server\n\n## Features\n\n- Retrieve repository contents with smart filtering options\n- Specify file extensions to include or exclude\n- Integrate with Claude Desktop for natural language exploration of repositories\n\n## Installation\n\n### Installing via Smithery\n\nTo install uithub-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@janwilmake/uithub-mcp):\n\n```bash\nnpx -y @smithery/cli install @janwilmake/uithub-mcp --client claude\n```\n\n### Manual Installation\n1. `npx uithub-mcp init`\n2. restart claude\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/uithub-mcp",
          "npm_downloads": 936,
          "npm_package_name": "uithub-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "jar285--github_mcp_analyzer": {
          "owner": "jar285",
          "name": "github_mcp_analyzer",
          "url": "https://github.com/jar285/github_mcp_analyzer",
          "imageUrl": "https://github.com/jar285.png",
          "description": "Enable real-time analysis of GitHub repositories by retrieving metadata, analyzing issues, accessing documentation, and visualizing activity metrics.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:12.466684",
          "collection_timestamp": "2025-10-03T04:28:18.246463",
          "stars": 0,
          "forks": 1,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-04-17T02:10:06Z",
          "updated_at": "2025-04-17T07:07:02Z",
          "open_issues": 0,
          "readme_content": "# GitHub Repository Analyzer MCP Server\n\nA Model Context Protocol (MCP) server that enables Large Language Models to analyze GitHub repositories in real-time. This server provides tools for retrieving repository information, analyzing issues, accessing documentation, and visualizing activity.\n\n## Features\n\n- **Repository Information Tool**: Retrieve basic metadata about GitHub repositories\n- **Issue Analysis Tool**: List and categorize repository issues\n- **README Access Resource**: Access repository documentation\n- **Commit History Tool**: Analyze recent code changes\n- **Activity Analysis Tool**: Calculate repository activity metrics\n- **Visualization Tool**: Create visual charts of repository activity\n\n## Prerequisites\n\n- Python 3.10 or higher\n- GitHub account and Personal Access Token\n\n## Installation\n\n1. Clone this repository:\n\n```bash\ngit clone <repository-url>\ncd github-repo-analyzer\n```\n\n2. Create and activate a virtual environment:\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n4. Create a `.env` file with your GitHub API token:\n\n```bash\ncp .env.example .env\n```\n\nEdit the `.env` file and replace `your_github_token_here` with your actual GitHub Personal Access Token.\n\n## Usage\n\n### Running the Server\n\nTo start the server in development mode with the MCP Inspector:\n\n```bash\nmcp dev src/server.py\n```\n\nThis will open a web interface in your browser where you can test the server's tools.\n\n### Registering with Claude Desktop\n\nTo register the server with Claude Desktop:\n\n```bash\nmcp install src/server.py\n```\n\nAfter registering, restart Claude Desktop. You can then interact with the GitHub Repository Analyzer by asking Claude questions about GitHub repositories.\n\n### Example Prompts for Claude\n\n- \"Can you analyze the GitHub repository 'modelcontextprotocol/python-sdk' and tell me about its purpose and activity level?\"\n- \"What are the top 5 open issues in the 'openai/openai-python' repository?\"\n- \"How active has the 'anthropics/anthropic-sdk-python' repository been in the last 30 days?\"\n- \"Please read the README of the 'microsoft/TypeScript' repository and explain its main features.\"\n- \"Generate a chart showing the commit activity for 'facebook/react' over the last 60 days.\"\n\n## Development\n\n### Project Structure\n\n```\ngithub-repo-analyzer/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ github_tools.py  # GitHub API client implementation\n‚îÇ   ‚îî‚îÄ‚îÄ server.py        # MCP server implementation\n‚îú‚îÄ‚îÄ requirements.txt     # Dependencies\n‚îú‚îÄ‚îÄ .env.example         # Example environment variables\n‚îú‚îÄ‚îÄ .gitignore           # Git ignore file\n‚îî‚îÄ‚îÄ README.md            # Project documentation\n```\n\n### Adding New Tools\n\nTo add a new tool to the server, follow these steps:\n\n1. Add the necessary functionality to the `GitHubAPIClient` class in `github_tools.py`\n2. Register the tool with the MCP server in `server.py` using the `@server.tool` decorator\n3. Test the tool using the MCP Inspector\n\n## Testing\n\nTo test the server, use the MCP Inspector as described in the Usage section. You can also write unit tests for the GitHub API client functionality.\n\n## Security Considerations\n\n- Never commit your GitHub API token to version control\n- Use the minimum required scopes for your GitHub token\n- Be mindful of GitHub API rate limits\n\n## License\n\n[MIT License](LICENSE)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jasonjmcghee--claude-debugs-for-you": {
          "owner": "jasonjmcghee",
          "name": "claude-debugs-for-you",
          "url": "https://github.com/jasonjmcghee/claude-debugs-for-you",
          "imageUrl": "https://github.com/jasonjmcghee.png",
          "description": "Interactively debug code with breakpoints, evaluate expressions, and enhance the coding experience using LLMs. The server is language-agnostic and works with valid launch configurations in Visual Studio Code.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:13.060796",
          "collection_timestamp": "2025-10-03T04:28:25.353707",
          "stars": 434,
          "forks": 40,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-01-17T05:54:24Z",
          "updated_at": "2025-10-02T19:40:19Z",
          "open_issues": 12,
          "readme_content": "# <img src=\"./images/claude-debugs-for-you.png\" width=\"64\" height=\"64\" alt=\"description\" align=\"center\"> Claude Debugs For You\n\n[![Badge](https://img.shields.io/badge/Visual%20Studio%20Marketplace-0.1.1-blue.svg)](https://marketplace.visualstudio.com/items?itemName=JasonMcGhee.claude-debugs-for-you)\n\n_aka Vibe Debugging_\n\n### Enable Claude (or any other LLM) to interactively debug your code\n\nThis is an [MCP](https://docs.anthropic.com/en/docs/build-with-claude/mcp) Server and VS Code extension which enables claude to interactively debug and evaluate expressions.\n\nThat means it should also work with other models / clients etc. but I only demonstrate it with Claude Desktop and Continue here.\n\nIt's language-agnostic, assuming debugger console support and valid launch.json for debugging in VSCode.\n\n## Getting Started\n\n1. Download the extension from [releases](https://github.com/jasonjmcghee/claude-debugs-for-you/releases/) or [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=JasonMcGhee.claude-debugs-for-you)\n2. Install the extension\n  - If using `.vsix` directly, go to the three dots in \"Extensions\" in VS Code and choose \"Install from VSIX...\"\n3. You will see a new status menu item \"Claude Debugs For You\" which shows if it is running properly (check) or failed to startup (x)\n\n<img width=\"314\" alt=\"Screenshot 2025-03-22 at 9 51 22‚ÄØPM\" src=\"https://github.com/user-attachments/assets/2cd65e0d-4c1d-4fb6-b9ea-3995149b4043\" />\n\nYou can click this status menu for the commands available\n\n<img width=\"510\" alt=\"Screenshot 2025-03-22 at 9 59 22‚ÄØPM\" src=\"https://github.com/user-attachments/assets/54e339e3-81f8-4ef2-a201-6742aa2c97a8\" />\n\n### Follow one of the options below, depending on your setup\n\n<details>\n  <summary>If using stdio (classic, required for Claude Desktop)</summary>\n\n4. Copy the stdio server path to your clipboard by searching vs code commands for \"Copy MCP Debug Server stdio path to clipboard\"\n\n5. Paste the following (BUT UPDATE THE PATH TO THE COPIED ONE!) in your `claude_desktop_config.json` or edit accordingly if you use other MCP servers\n\n```\n{\n  \"mcpServers\": {\n    \"debug\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/mcp-debug.js\"\n      ]\n    }\n  }\n}\n```\n\n6. Start Claude desktop (or other MCP client)\n    1. Note: You may need to restart it, if it was already running.\n    2. You can skip this step if using Continue/Cursor or other built-in to VS Code\n</details>\n\n<details>\n  <summary>If using `/sse` (e.g. Cursor)</summary>\n\n4. Retrieve the MCP server sse address by using the \"Copy MCP Debug Server sse address to clipboard\" command\n    1. You can just write it out server URL of \"http://localhost:4711/sse\", or whatever port you setup in settings.\n5. Add it wherever you need to based on your client\n    1. You may need to hit \"refresh\" depending on client: this is required in Cursor\n6. Start MCP client\n   1. Note: You may need to restart it, if it was already running.\n   2. You can skip this step if using Continue/Cursor or other built-in to VS Code\n\n</details>\n\n### You're ready to debug!\n\n_[VS Code Debugging Documentation](https://code.visualstudio.com/Docs/editor/debugging)_\n\nOpen a project containing a `.vscode/launch.json` with the first configuration setup to debug a specific file with `${file}`.\n\nSee [Run  an Example](#run-an-example) below, and/or watch a demo video.\n\n## Contributing\n\nFind bugs or have an idea that will improve this? Please open a pull request or log an issue.\n\nDoes this readme suck? Help me improve it!\n\n## Demo\n\n### Using [Continue](https://github.com/continuedev/continue)\n\nIt figures out the problem, and then suggests a fix, which we just click to apply\n\nhttps://github.com/user-attachments/assets/3a0a879d-2db7-4a3f-ab43-796c22a0f1ef\n\n<details>\n  <summary>How do I set this up with Continue? / Show MCP Configuration</summary>\n\n  [Read the docs!](https://docs.continue.dev/customize/tools)\n\n  Configuration:\n  \n  ```json\n  {\n    ...\n    \"experimental\": {\n      \"modelContextProtocolServers\": [\n        {\n          \"transport\": {\n            \"type\": \"stdio\",\n            \"command\": \"node\",\n            \"args\": [\n              \"/Users/jason/Library/Application Support/Code/User/globalStorage/jasonmcghee.claude-debugs-for-you/mcp-debug.js\"\n            ]\n          }\n        }\n      ]\n    }\n  }\n  ```\n\n  You'll also need to choose a model capable of using tools.\n\n  When the list of tools pops up, make sure to click \"debug\" in the list of your tools, and set it to be \"Automatic\".\n\n  ### Troubleshooting\n\n  If you are seeing MCP errors in continue, try disabling / re-enabling the continue plugin\n\n</details>\n\nIf helpful, this is what my configuration looks like! But it's nearly the same as Claude Desktop.\n\n\n### Using Claude Desktop\n\nIn this example, I made it intentionally very cautious (make no assumptions etc - same prompt as below) but you can ask it to do whatever.\n\nhttps://github.com/user-attachments/assets/ef6085f7-11a2-4eea-bb60-b5a54873b5d5\n\n## Developing\n\n- Clone / Open this repo with VS Code\n- Run `npm run install` and `npm run compile`\n- Hit \"run\" which will open a new VSCode\n- Otherwise same as \"Getting Started applies\"\n- To rebuild, `npm run compile`\n\n## Package\n\n```bash\nvsce package\n```\n\n\n## Run an Example\n\nOpen `examples/python` in a VS Code window\n\nEnter the prompt:\n\n```\ni am building `longest_substring_with_k_distinct` and for some reason it's not working quite right. can you debug it step by step using breakpoints and evaluating expressions to figure out where it goes wrong? make sure to use the debug tool to get access and debug! don't make any guesses as to the problem up front. DEBUG!\n```\n\n## Other things worth mentioning\n\nWhen you start multiple vs code windows, you'll see a pop-up. You can gracefully hand-off \"Claude Debugs For You\" between windows.\n\nYou can also disable autostart. Then you'll just need to click the status menu and select \"Start Server\".\n\n<img width=\"395\" alt=\"Screenshot 2025-03-22 at 10 08 52‚ÄØPM\" src=\"https://github.com/user-attachments/assets/2b6d1b61-a2c6-4447-8054-b4dd02a716e8\" />\n\n\n## Short list of ideas\n\n- [ ] It should use ripgrep to find what you ask for, rather than list files + get file content.\n- [x] Add support for conditional breakpoints\n- [ ] Add \"fix\" tool by allowing MCP to insert a CodeLens or \"auto fix\" suggestion so the user can choose to apply a recommended change or not.\n- Your idea here!\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        }
      }
    },
    "developeasdfr-tools": {
      "category": "developer-tools",
      "categoryDisplay": "Developer Tools",
      "description": "Tools and integrations that enhance the development workflow and environment management.",
      "totalRepositories": 11,
      "repositories": {
        "jagan-shanmugam--mattermost-mcp-host": {
          "owner": "jagan-shanmugam",
          "name": "mattermost-mcp-host",
          "url": "https://github.com/jagan-shanmugam/mattermost-mcp-host",
          "imageUrl": "https://github.com/jagan-shanmugam.png",
          "description": "Connects Mattermost to Model Context Protocol (MCP) servers, enabling interactions with a LangGraph-based AI agent for executing tools and automating user requests directly within Mattermost channels.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:07.460883",
          "collection_timestamp": "2025-10-03T04:27:23.548690",
          "stars": 27,
          "forks": 16,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-03T18:38:07Z",
          "updated_at": "2025-09-28T13:00:47Z",
          "open_issues": 6,
          "readme_content": "# Mattermost MCP Host\n\nA Mattermost integration that connects to Model Context Protocol (MCP) servers, leveraging a LangGraph-based AI agent to provide an intelligent interface for interacting with users and executing tools directly within Mattermost.\n\n![Version](https://img.shields.io/badge/version-0.1.0-blue)\n![Python](https://img.shields.io/badge/python-3.13.1%2B-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![Package Manager](https://img.shields.io/badge/package%20manager-uv-purple)\n\n\n\n## Demo\n\n### 1. Github Agent in support channel - searches the existing issues and PRs and creates a new issue if not found\n![Description of your GIF](./demo/demo-3.gif)   \n\n\n### 2. Search internet and post to a channel using Mattermost-MCP-server\n![Description of your GIF](./demo/demo-2.gif)\n\n#### Scroll below for full demo in YouTube\n\n## Features\n\n- ü§ñ **Langgraph Agent Integration**: Uses a LangGraph agent to understand user requests and orchestrate responses.\n- üîå **MCP Server Integration**: Connects to multiple MCP servers defined in `mcp-servers.json`.\n- üõ†Ô∏è **Dynamic Tool Loading**: Automatically discovers tools from connected MCP servers and makes them available to the AI agent. Converts MCP tools to langchain structured tools.\n- üí¨ **Thread-Aware Conversations**: Maintains conversational context within Mattermost threads for coherent interactions.\n- üîÑ **Intelligent Tool Use**: The AI agent can decide when to use available tools (including chaining multiple calls) to fulfill user requests.\n- üîç **MCP Capability Discovery**: Allows users to list available servers, tools, resources, and prompts via direct commands.\n- #Ô∏è‚É£ **Direct Command Interface**: Interact directly with MCP servers using a command prefix (default: `#`).\n\n\n## Overview\n\nThe integration works as follows:\n\n1.  **Mattermost Connection (`mattermost_client.py`)**: Connects to the Mattermost server via API and WebSocket to listen for messages in a specified channel.\n2.  **MCP Connections (`mcp_client.py`)**: Establishes connections (primarily `stdio`) to each MCP server defined in `src/mattermost_mcp_host/mcp-servers.json`. It discovers available tools on each server.\n3.  **Agent Initialization (`agent/llm_agent.py`)**: A `LangGraphAgent` is created, configured with the chosen LLM provider and the dynamically loaded tools from all connected MCP servers.\n4.  **Message Handling (`main.py`)**:\n    *   If a message starts with the command prefix (`#`), it's parsed as a direct command to list servers/tools or call a specific tool via the corresponding `MCPClient`.\n    *   Otherwise, the message (along with thread history) is passed to the `LangGraphAgent`.\n5.  **Agent Execution**: The agent processes the request, potentially calling one or more MCP tools via the `MCPClient` instances, and generates a response.\n6.  **Response Delivery**: The final response from the agent or command execution is posted back to the appropriate Mattermost channel/thread.\n\n## Setup\n1.  **Clone the repository:**\n    ```bash\n    git clone <repository-url>\n    cd mattermost-mcp-host\n    ```\n\n2.  **Install:**\n    *   Using uv (recommended):\n        ```bash\n        # Install uv if you don't have it yet\n        # curl -LsSf https://astral.sh/uv/install.sh | sh \n\n        # Activate venv\n        source .venv/bin/activate\n        \n        # Install the package with uv\n        uv sync\n\n        # To install dev dependencies\n        uv sync --dev --all-extras\n        ```\n\n3.  **Configure Environment (`.env` file):**\n    Copy the `.env.example` and fill in the values or\n    Create a `.env` file in the project root (or set environment variables):\n    ```env\n    # Mattermost Details\n    MATTERMOST_URL=http://your-mattermost-url\n    MATTERMOST_TOKEN=your-bot-token # Needs permissions to post, read channel, etc.\n    MATTERMOST_TEAM_NAME=your-team-name\n    MATTERMOST_CHANNEL_NAME=your-channel-name # Channel for the bot to listen in\n    # MATTERMOST_CHANNEL_ID= # Optional: Auto-detected if name is provided\n\n    # LLM Configuration (Azure OpenAI is default)\n    DEFAULT_PROVIDER=azure\n    AZURE_OPENAI_ENDPOINT=your-azure-endpoint\n    AZURE_OPENAI_API_KEY=your-azure-api-key\n    AZURE_OPENAI_DEPLOYMENT=your-deployment-name # e.g., gpt-4o\n    # AZURE_OPENAI_API_VERSION= # Optional, defaults provided\n\n    # Optional: Other providers (install with `[all]` extra)\n    # OPENAI_API_KEY=...\n    # ANTHROPIC_API_KEY=...\n    # GOOGLE_API_KEY=...\n\n    # Command Prefix\n    COMMAND_PREFIX=# \n    ```\n    See `.env.example` for more options.\n\n4.  **Configure MCP Servers:**\n    Edit `src/mattermost_mcp_host/mcp-servers.json` to define the MCP servers you want to connect to. See `src/mattermost_mcp_host/mcp-servers-example.json`.\n    Depending on the server configuration, you might `npx`, `uvx`, `docker` installed in your system and in path.\n\n5.  **Start the Integration:**\n    ```bash\n    mattermost-mcp-host\n    ```\n\n\n## Prerequisites\n\n- Python 3.13.1+\n- uv package manager\n- Mattermost server instance\n- Mattermost Bot Account with API token\n- Access to a LLM API (Azure OpenAI)\n\n### Optional\n- One or more MCP servers configured in `mcp-servers.json` \n- Tavily web search requires `TAVILY_API_KEY` in `.env` file\n\n\n## Usage in Mattermost\n\nOnce the integration is running and connected:\n\n1.  **Direct Chat:** Simply chat in the configured channel or with the bot. The AI agent will respond, using tools as needed. It maintains context within message threads.\n2.  **Direct Commands:** Use the command prefix (default `#`) for specific actions:\n    *   `#help` - Display help information.\n    *   `#servers` - List configured and connected MCP servers.\n    *   `#<server_name> tools` - List available tools for `<server_name>`.\n    *   `#<server_name> call <tool_name> <json_arguments>` - Call `<tool_name>` on `<server_name>` with arguments provided as a JSON string.\n        *   Example: `#my-server call echo '{\"message\": \"Hello MCP!\"}'`\n    *   `#<server_name> resources` - List available resources for `<server_name>`.\n    *   `#<server_name> prompts` - List available prompts for `<server_name>`.\n\n\n\n## Next Steps\n- ‚öôÔ∏è **Configurable LLM Backend**: Supports multiple AI providers (Azure OpenAI default, OpenAI, Anthropic Claude, Google Gemini) via environment variables.\n\n## Mattermost Setup\n\n1. **Create a Bot Account**\n- Go to Integrations > Bot Accounts > Add Bot Account\n- Give it a name and description\n- Save the access token in the .env file\n\n2. **Required Bot Permissions**\n- post_all\n- create_post\n- read_channel\n- create_direct_channel\n- read_user\n\n3. **Add Bot to Team/Channel**\n- Invite the bot to your team\n- Add bot to desired channels\n\n### Troubleshooting\n\n1. **Connection Issues**\n- Verify Mattermost server is running\n- Check bot token permissions\n- Ensure correct team/channel names\n\n2. **AI Provider Issues**\n- Validate API keys\n- Check API quotas and limits\n- Verify network access to API endpoints\n\n3. **MCP Server Issues**\n- Check server logs\n- Verify server configurations\n- Ensure required dependencies are installed and env variables are defined\n\n\n## Demos\n\n### Create issue via chat using Github MCP server\n![Description of your GIF](./demo/demo-1.gif)  \n\n### (in YouTube)\n[![AI Agent in Action in Mattermost](./demo/supercut-thumbnail.png)](https://youtu.be/s6CZY81DRrU)\n\n\n## Contributing\n\nPlease feel free to open a PR.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jakenuts--mcp-cli-exec": {
          "owner": "jakenuts",
          "name": "mcp-cli-exec",
          "url": "https://github.com/jakenuts/mcp-cli-exec",
          "imageUrl": "https://github.com/jakenuts.png",
          "description": "Execute shell commands in a specified directory and obtain structured output, including execution results such as success status, stdout, stderr, and error handling. Enhance automation workflows with detailed command management capabilities.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:07.952911",
          "collection_timestamp": "2025-10-03T04:27:26.968917",
          "stars": 6,
          "forks": 2,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-02-27T19:37:52Z",
          "updated_at": "2025-09-26T16:50:55Z",
          "open_issues": 2,
          "readme_content": "# mcp-cli-exec MCP Server\n\nA powerful CLI command execution MCP server that enables running shell commands with structured output. This package focuses specifically on command execution functionality, differentiating it from other MCP CLI tools.\n\n## Features\n\n### Tools\n\n#### cli-exec-raw\nExecute a raw CLI command and return structured output\n- Takes a command string and optional timeout (default: 5 minutes)\n- Returns detailed execution results including stdout, stderr, exit code\n- Handles errors gracefully with structured error responses\n\n#### cli-exec\nExecute one or more CLI commands in a specific working directory\n- Supports single commands, && chained commands, or array of commands\n- All commands execute in the specified working directory\n- Returns detailed results for each command:\n  - Success/failure status\n  - Exit code\n  - stdout and stderr (ANSI codes stripped)\n  - Execution duration\n  - Working directory\n- Stops on first command failure\n- Optional timeout per command (default: 5 minutes)\n\nNote: Due to execution context limitations, each command runs independently. Directory changes (cd) within commands do not affect subsequent commands. All commands execute in the initially specified working directory.\n\n### Output Format\n\nCommands return structured results including:\n- Success/failure status\n- Exit code\n- stdout and stderr (with ANSI codes stripped)\n- Execution duration\n- Working directory\n- Detailed error information if applicable\n\n### Example Usage\n\n#### cli-exec-raw\nSimple command execution:\n```json\n{\n  \"command\": \"echo Hello World\"\n}\n```\n\nWith timeout:\n```json\n{\n  \"command\": \"long-running-script.sh\",\n  \"timeout\": 300000\n}\n```\n\n#### cli-exec\nSingle command in specific directory:\n```json\n{\n  \"workingDirectory\": \"/path/to/project\",\n  \"commands\": \"npm install\"\n}\n```\n\nMultiple commands (all run in the same working directory):\n```json\n{\n  \"workingDirectory\": \"C:\\\\project\",\n  \"commands\": [\n    \"dir /b\",\n    \"npm run build\"\n  ]\n}\n```\n\n## Installation\n\nOptionally install from npm:\n\n```bash\nnpm install -g mcp-cli-exec\n# or with pnpm\npnpm add -g mcp-cli-exec\n```\nOr just use npx in your configuration\n\n### For Cline VSCode Extension\n\nAdd to `%APPDATA%/Code - Insiders/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-cli-exec\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-cli-exec\"]\n    }\n  }\n}\n```\n\n### For Claude Desktop\n\nAdd to the appropriate config file:\n\nWindows: `%APPDATA%/Claude/claude_desktop_config.json`\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-cli-exec\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"mcp-cli-exec\"]\n    }\n  }\n}\n```\n\n### Special Windows Configuration\n\nIf you encounter the ENOENT spawn npx issue on Windows, use this alternative configuration that specifies the full paths:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-cli-exec\": {\n      \"command\": \"C:\\\\Users\\\\jim\\\\AppData\\\\Roaming\\\\nvm\\\\v22.1.0\\\\node.exe\",\n      \"args\": [\n        \"C:\\\\Users\\\\jim\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\bin\\\\npx-cli.js\",\n        \"-y\",\n        \"mcp-cli-exec\"\n      ]\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\npnpm install\n```\n\nBuild the server:\n```bash\npnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\npnpm run watch\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. The MCP Inspector provides helpful debugging tools:\n\n```bash\npnpm run inspector\n```\n\nThis will provide a URL to access the inspector in your browser, where you can:\n- View all MCP messages\n- Inspect request/response payloads\n- Test tools interactively\n- Monitor server state\n\n## Error Handling\n\nThe server includes comprehensive error handling:\n- Input validation for all tool parameters\n- Structured error responses\n- Command timeout handling\n- Working directory validation\n- ANSI code stripping for clean output\n\n## Technical Details\n\n- Built with TypeScript and the MCP SDK\n- Uses execa for reliable command execution\n- Default command timeout: 5 minutes\n- Supports Windows and Unix-like systems (use appropriate commands for your OS, e.g., 'dir' vs 'ls')\n- Executes commands sequentially, stopping on first failure\n- Each command runs independently in the specified working directory\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/mcp-cli-exec",
          "npm_downloads": 4285,
          "npm_package_name": "mcp-cli-exec",
          "npm_success": true,
          "npm_error": null
        },
        "Jake-Mok-Nelson--mcp-find-similar-github-issues": {
          "owner": "Jake-Mok-Nelson",
          "name": "mcp-find-similar-github-issues",
          "url": "https://github.com/Jake-Mok-Nelson/mcp-find-similar-github-issues",
          "imageUrl": "https://github.com/Jake-Mok-Nelson.png",
          "description": "Helps support engineers quickly find similar GitHub issues to enhance troubleshooting efficiency using similarity scoring and ranked issue details with direct links.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:08.600388",
          "collection_timestamp": "2025-10-03T04:27:34.036629",
          "stars": 2,
          "forks": 4,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-03-05T22:32:05Z",
          "updated_at": "2025-05-06T05:58:42Z",
          "open_issues": 1,
          "readme_content": "# GitHub Support Assistant\n\nAn MCP server that helps support engineers find similar GitHub issues to speed up troubleshooting.\n\n## Setup\n\n1. Install dependencies:\n```\nnpm install\n```\n\n2. Set your GitHub token as an environment variable:\n```\nexport GITHUB_TOKEN=your_github_personal_access_token\n```\n\n3. Build the server:\n```\nnpm run build\n```\n\n#### Integrating with Claude:\nUpdate the claude desktop configuration, e.g.\n`code ~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n\nUpdate it to include the full path that this repository was cloned to:\n```\n{\n    \"mcpServers\": {\n        \"find-similar-github-issues\": {\n            \"command\": \"node\",\n            \"args\": [\n                \"/Users/<repo_path>/build/index.js\"\n            ]\n        }\n    }\n}\n```\n\n## Features\n\n- Searches for similar issues in a GitHub repository based on issue description\n- Calculates similarity scores to rank results\n- Returns formatted issue details with links\n\n## Usage\n\nThe server provides one tool:\n\n### find-similar-issues\n\nFinds GitHub issues similar to a given description.\n\n**Parameters:**\n- `owner`: GitHub repository owner/organization\n- `repo`: GitHub repository name\n- `issueDescription`: Description of the issue to find similar ones for\n- `maxResults`: Maximum number of similar issues to return (default: 5)\n\n## Implementation Notes\n\nThis implementation uses a simple Jaccard similarity coefficient to compare text. For production use, consider implementing more sophisticated NLP techniques for better similarity matching.\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jalehman--mcp-sage": {
          "owner": "jalehman",
          "name": "mcp-sage",
          "url": "https://github.com/jalehman/mcp-sage",
          "imageUrl": "https://github.com/jalehman.png",
          "description": "Provides detailed second opinions, code reviews, and implementation plans by leveraging large context models with automatic model selection based on token count. It integrates file context into prompts for accurate assistance, enabling multi-model debates and self-debate workflows for complex codebases.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:09.145058",
          "collection_timestamp": "2025-10-03T04:27:41.244774",
          "stars": 7,
          "forks": 4,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-04-18T17:13:55Z",
          "updated_at": "2025-09-23T07:54:58Z",
          "open_issues": 1,
          "readme_content": "# `mcp-sage`\n[![smithery badge](https://smithery.ai/badge/@jalehman/mcp-sage)](https://smithery.ai/server/@jalehman/mcp-sage)\n\nAn MCP (Model Context Protocol) server that provides tools for sending prompts to OpenAI's GPT-5, GPT-4.1, Google's Gemini 2.5 Pro, or Anthropic's Claude Opus 4.1 based on token count and configuration. The tools embed all referenced filepaths (recursively for folders) in the prompt. This is useful for getting second opinions or detailed code reviews from models that can handle large amounts of context accurately.\n\n## Rationale\n\nI make heavy use of Claude Code. It's a great product that works well for my workflow. Newer models with large amounts of context seem really useful though for dealing with more complex codebases where more context is needed. This lets me continue to use Claude Code as a development tool while leveraging the large context capabilities of GPT-5, Gemini 2.5 Pro, and other models to augment Claude Code's limited context.\n\n## Model Selection\n\nThe server automatically selects the appropriate model based on token count, with configuration defined in `models.yaml`:\n\n- For smaller contexts (‚â§ 400K tokens): Uses OpenAI's GPT-5 (if OPENAI_API_KEY is set)\n- For medium contexts (‚â§ 1M tokens): Uses Google's Gemini 2.5 Pro (if GEMINI_API_KEY is set)  \n- For fallback (‚â§ 1M tokens): Uses OpenAI's GPT-4.1\n- If the content exceeds 1M tokens: Returns an informative error\n\nFallback behavior:\n- **API Key Fallback**:\n  - If OPENAI_API_KEY is missing, Gemini will be used for all contexts within its 1M token limit\n  - If GEMINI_API_KEY is missing, only smaller contexts can be processed with OpenAI models\n  - If required API keys are missing, an informative error is returned\n\n## Inspiration\n\nThis project draws inspiration from two other open source projects:\n\n- [simonw/files-to-prompt](https://github.com/simonw/files-to-prompt) for the file compression\n- [asadm/vibemode](https://github.com/asadm/vibemode) for the idea and prompt to send the entire repo to Gemini for wholesale edit suggestions\n- [PhialsBasement/Chain-of-Recursive-Thoughts](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) inspiration for the debate functionality\n\n## Overview\n\nThis project implements an MCP server that exposes two primary tools:\n\n### `sage-opinion`\n\n1. Takes a prompt and a list of file/dir paths as input\n2. Packs the files into a structured XML format\n3. Measures the token count and selects the appropriate model:\n   - GPT-5 for ‚â§ 400K tokens\n   - Gemini 2.5 Pro for > 400K and ‚â§ 1M tokens\n   - GPT-4.1 as fallback for ‚â§ 1M tokens\n4. Sends the combined prompt + context to the selected model\n5. Returns the model's response\n\n### `sage-review`\n\n1. Takes an instruction for code changes and a list of file/dir paths as input\n2. Packs the files into a structured XML format\n3. Measures the token count and selects the appropriate model:\n   - GPT-5 for ‚â§ 400K tokens\n   - Gemini 2.5 Pro for > 400K and ‚â§ 1M tokens\n   - GPT-4.1 as fallback for ‚â§ 1M tokens\n4. Creates a specialized prompt instructing the model to format responses using SEARCH/REPLACE blocks\n5. Sends the combined context + instruction to the selected model\n6. Returns edit suggestions formatted as SEARCH/REPLACE blocks for easy implementation\n\n### Debate Mode\n\nBoth `sage-opinion` and `sage-review` support an optional debate mode that can be enabled by adding `debate: true` to the arguments. When enabled, the system orchestrates a structured debate between multiple models to generate higher-quality responses.\n\n--------------------------------------------------------------------\n#### 1. Multi-Model Debate Flow\n```mermaid\nflowchart TD\n  S0[Start Debate] -->|determine models, judge, budgets| R1\n\n  subgraph R1[\"Round 1\"]\n    direction TB\n    R1GEN[\"Generation Phase<br/>*ALL models run in parallel*\"]\n    R1GEN --> R1CRIT[\"Critique Phase<br/>*ALL models critique others in parallel*\"]\n  end\n\n  subgraph RN[\"Rounds 2 to N\"]\n    direction TB\n    SYNTH[\"Synthesis Phase<br/>*every model refines own plan*\"]\n    SYNTH --> CONS[Consensus Check]\n    CONS -->|Consensus reached| JUDGE\n    CONS -->|No consensus & round < N| CRIT[\"Critique Phase<br/>*models critique in parallel*\"]\n    CRIT --> SYNTH\n  end\n\n  R1 --> RN\n  JUDGE[Judgment Phase<br/>*judge model selects/merges response*]\n  JUDGE --> FP[Final Response]\n\n  classDef round fill:#e2eafe,stroke:#4169E1;\n  class R1GEN,R1CRIT,SYNTH,CRIT round;\n  style FP fill:#D0F0D7,stroke:#2F855A,stroke-width:2px\n  style JUDGE fill:#E8E8FF,stroke:#555,stroke-width:1px\n```\n\nKey phases in the multi-model debate:\n\n**Setup Phase**\n- The system determines available models, selects a judge, and allocates token budgets\n\n**Round 1**\n- **Generation Phase** - Every available model (A, B, C, etc.) generates its response in parallel\n- **Critique Phase** - Each model reviews all other responses (never its own) and produces structured critiques in parallel\n\n**Rounds 2 to N** (N defaults to 3)\n1. **Synthesis Phase** - Each model improves its previous response using critiques it received (models work in parallel)\n2. **Consensus Check** - The judge model scores similarity between all current responses\n   - If score ‚â• 0.9, the debate stops early and jumps to Judgment\n3. **Critique Phase** - If consensus is not reached AND we're not in the final round, each model critiques all other responses again (in parallel)\n\n**Judgment Phase**\n- After completing all rounds (or reaching early consensus), the judge model (Claude Opus 4.1 by default):\n  - For sage-opinion: Selects the single best response (no synthesis)\n  - For sage-review: Can either select the best response OR merge multiple responses\n  - Provides a confidence score for its selection/synthesis\n\n--------------------------------------------------------------------\n#### 2. Self-Debate Flow - Single Model Available\n```mermaid\nflowchart TD\n  SD0[Start Self-Debate] --> R1\n\n  subgraph R1[\"Round 1 - Initial Responses\"]\n    direction TB\n    P1[Generate Response 1] --> P2[Generate Response 2<br/>*different approach*]\n    P2 --> P3[Generate Response 3<br/>*different approach*]\n  end\n\n  subgraph RN[\"Rounds 2 to N\"]\n    direction TB\n    REF[Generate Improved Response<br/>*addresses weaknesses in all previous responses*]\n    DEC{More rounds left?}\n    REF --> DEC\n    DEC -->|Yes| REF\n  end\n\n  R1 --> RN\n  DEC -->|No| FP[Final Response = last response generated]\n\n  style FP fill:#D0F0D7,stroke:#2F855A,stroke-width:2px\n```\n\nWhen only one model is available, a [Chain of Recursive Thoughts (CoRT)](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) approach is used:\n\n1. **Initial Burst** - The model generates three distinct responses, each taking a different approach\n2. **Refinement Rounds** - For each subsequent round (2 to N, default N=3):\n   - The model reviews all previous responses\n   - It critiques them internally, identifying strengths and weaknesses\n   - It produces one new improved response that addresses limitations in earlier responses\n3. **Final Selection** - The last response generated becomes the final output\n\n--------------------------------------------------------------------\n### What Actually Happens in Code (quick reference)\n\n| Phase / Functionality | Code Location | Notes |\n|-----------------------|---------------|-------|\n| Generation Prompts    | prompts/debatePrompts.generatePrompt | Creates initial responses from each model |\n| Critique Prompts      | prompts/debatePrompts.critiquePrompt | Uses \"## Critique of {ID}\" sections |\n| Synthesis Prompts     | prompts/debatePrompts.synthesizePrompt | Model revises its own response |\n| Consensus Check       | orchestrator/debateOrchestrator | Judge model returns JSON with `consensusScore` |\n| Judgment              | prompts/debatePrompts.judgePrompt    | Judge returns final response + confidence |\n| Self-Debate Prompt    | prompts/debatePrompts.selfDebatePrompt | [Chain-of-Recursive-Thoughts](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) loop |\n\n#### Performance and Cost Considerations\n\n**‚ö†Ô∏è Important:** When using debate mode:\n- It can take more time to complete (2-5 minutes with multiple models)\n- Consumes more API tokens due to multiple rounds of debate\n- Incurs higher costs than single-model approaches\n\n**Typical resource usage:**\n- Multi-model debate: 2-4x more tokens than a single model approach\n- Processing time: 2-5 minutes depending on complexity and model availability\n- API costs vary by models used and complexity\n\n## Prerequisites\n\n- Node.js (v18 or later)\n- API keys for the models you want to use:\n  - **OpenAI API key** (for GPT-5 and GPT-4.1)\n  - **Google Gemini API key** (for Gemini 2.5 Pro)\n  - **Anthropic API key** (for Claude Opus 4.1 as judge in debates)\n\n**Note:** While the server can function with just one API key, it works best when all three are provided. This enables:\n- Optimal model selection based on token count\n- Multi-model debates for higher quality responses\n- Claude Opus 4.1 as an impartial judge in debate mode\n\n## Installation\n\n### Installing via Smithery\n\nTo install Sage for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jalehman/mcp-sage):\n\n```bash\nnpx -y @smithery/cli install @jalehman/mcp-sage --client claude\n```\n\n### Installing manually\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-username/mcp-sage.git\ncd mcp-sage\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Environment Variables\n\nSet the following environment variables:\n\n- `OPENAI_API_KEY`: Your OpenAI API key (for GPT-5 and GPT-4.1 models)\n- `GEMINI_API_KEY`: Your Google Gemini API key (for Gemini 2.5 Pro)\n- `ANTHROPIC_API_KEY`: Your Anthropic API key (for Claude Opus 4.1)\n\n**Recommended:** Provide all three API keys for the best experience. This ensures:\n- The server can select the optimal model for any token count\n- Debate mode works with multiple diverse models\n- Claude Opus 4.1 serves as an effective judge in debates\n\n## Usage\n\nAfter building with `npm run build`, add the following to your MCP configuration:\n\n```sh\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key node /path/to/this/repo/dist/index.js\n```\n\nYou can also use environment variables set elsewhere, like in your shell profile.\n\n## Prompting\n\nTo get a second opinion on something just ask for a second opinion.\n\nTo get a code review, ask for a code review or expert review.\n\nBoth of these benefit from providing paths of files that you wnat to be included in context, but if omitted the host LLM will probably infer what to include.\n\n### Debugging and Monitoring\n\nThe server provides detailed monitoring information via the MCP logging capability. These logs include:\n\n- Token usage statistics and model selection\n- Number of files and documents included in the request\n- Request processing time metrics\n- Error information when token limits are exceeded\n\nLogs are sent via the MCP protocol's `notifications/message` method, ensuring they don't interfere with the JSON-RPC communication. MCP clients with logging support will display these logs appropriately.\n\nExample log entries:\n```\nToken usage: 1,234 tokens. Selected model: gpt-5-2025-08-07 (limit: 400,000 tokens)\nFiles included: 3, Document count: 3\nSending request to OpenAI gpt-5-2025-08-07 with 1,234 tokens...\nReceived response from gpt-5-2025-08-07 in 982ms\n```\n\n```\nToken usage: 435,678 tokens. Selected model: gemini-2.5-pro (limit: 1,000,000 tokens)\nFiles included: 25, Document count: 18\nSending request to Gemini with 435,678 tokens...\nReceived response from gemini-2.5-pro in 3240ms\n```\n\n### Using the Tools\n\n#### sage-opinion Tool\n\nThe `sage-opinion` tool accepts the following parameters:\n\n- `prompt` (string, required): The prompt to send to the selected model\n- `paths` (array of strings, required): List of file paths to include as context\n- `debate` (boolean, optional): Enable multi-model debate mode for higher quality responses\n\nExample MCP tool call (using JSON-RPC 2.0):\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"sage-opinion\",\n    \"arguments\": {\n      \"prompt\": \"Explain how this code works\",\n      \"paths\": [\"path/to/file1.js\", \"path/to/file2.js\"]\n    }\n  }\n}\n```\n\n#### sage-review Tool\n\nThe `sage-review` tool accepts the following parameters:\n\n- `instruction` (string, required): The specific changes or improvements needed\n- `paths` (array of strings, required): List of file paths to include as context\n- `debate` (boolean, optional): Enable multi-model debate mode for higher quality responses\n\nExample MCP tool call (using JSON-RPC 2.0):\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"sage-review\",\n    \"arguments\": {\n      \"instruction\": \"Add error handling to the function\",\n      \"paths\": [\"path/to/file1.js\", \"path/to/file2.js\"]\n    }\n  }\n}\n```\n\nThe response will contain SEARCH/REPLACE blocks that you can use to implement the suggested changes:\n\n```\n<<<<<<< SEARCH\nfunction getData() {\n  return fetch('/api/data')\n    .then(res => res.json());\n}\n=======\nfunction getData() {\n  return fetch('/api/data')\n    .then(res => {\n      if (!res.ok) {\n        throw new Error(`HTTP error! Status: ${res.status}`);\n      }\n      return res.json();\n    })\n    .catch(error => {\n      console.error('Error fetching data:', error);\n      throw error;\n    });\n}\n>>>>>>> REPLACE\n```\n\nWhen using debate mode with either tool, the system will:\n\n1. Generate initial responses from multiple models (GPT-5 and Gemini by default)\n2. Have models critique each other's responses\n3. Allow models to refine their responses based on critiques\n4. Use a judge model (Claude Opus 4.1 by default) to select or synthesize the best response\n\nThis results in more thoughtful and comprehensive responses at the cost of additional time and API usage.\n\n## Running the Tests\n\nTo test the tools:\n\n```bash\n# Test the sage-opinion tool\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key node test/run-test.js\n\n# Test the sage-review tool\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key node test/test-expert.js\n\n# Test debate mode\nOPENAI_API_KEY=your_openai_key GEMINI_API_KEY=your_gemini_key ANTHROPIC_API_KEY=your_anthropic_key node test/run-sage-opinion-debate.js\n```\n\n**Note**: Tests using debate mode may take 2-5 minutes to run as they orchestrate multi-model interactions.\n\n## Project Structure\n\n- `src/index.ts`: The main MCP server implementation with tool definitions\n- `src/pack.ts`: Tool for packing files into a structured XML format\n- `src/tokenCounter.ts`: Utilities for counting tokens in a prompt\n- `src/gemini.ts`: Gemini API client implementation\n- `src/openai.ts`: OpenAI API client implementation for O3 model\n- `src/orchestrator/debateOrchestrator.ts`: Multi-model debate orchestration\n- `src/prompts/debatePrompts.ts`: Templates for debate prompts and instructions\n- `test/run-test.js`: Test for the sage-opinion tool\n- `test/test-expert.js`: Test for the sage-review tool\n- `test/run-sage-opinion-debate.js`: Test for debate mode functionality\n\n## License\n\nISC\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jamsocket--forevervm": {
          "owner": "jamsocket",
          "name": "forevervm",
          "url": "https://github.com/jamsocket/forevervm",
          "imageUrl": "https://github.com/jamsocket.png",
          "description": "Enable agents to execute Python code seamlessly within a REPL environment, allowing for on-the-fly script creation and execution. It enhances automation and coding capabilities directly within workflows.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:09.649104",
          "collection_timestamp": "2025-10-03T04:27:44.864199",
          "stars": 217,
          "forks": 20,
          "license": "MIT License",
          "language": "Rust",
          "created_at": "2025-01-18T14:15:35Z",
          "updated_at": "2025-09-18T11:53:49Z",
          "open_issues": 2,
          "readme_content": "[foreverVM](https://forevervm.com)\n==================================\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/jamsocket/forevervm?style=social)](https://github.com/jamsocket/forevervm)\n[![Chat on Discord](https://img.shields.io/discord/939641163265232947?color=404eed&label=discord)](https://discord.gg/N5sEpsuhh9)\n\n| repo                                                | version                     |\n|-----------------------------------------------------|------------------------------|\n| [cli](https://github.com/jamsocket/forevervm) | [![npm](https://img.shields.io/npm/v/forevervm)](https://www.npmjs.com/package/forevervm) |\n| [sdk](https://github.com/jamsocket/forevervm) | [![npm](https://img.shields.io/npm/v/@forevervm/sdk)](https://www.npmjs.com/package/@forevervm/sdk) |\n\nforeverVM provides an API for running arbitrary, stateful Python code securely.\n\nThe core concepts in foreverVM are **machines** and **instructions**.\n\n**Machines** represent a stateful Python process. You interact with a machine by running **instructions**\n(Python statements and expressions) on it, and receiving the results. A machine processes one instruction\nat a time.\n\nGetting started\n---------------\n\nYou will need an API token (if you need one, reach out to [paul@jamsocket.com](mailto:paul@jamsocket.com)).\n\nThe easiest way to try out foreverVM is using the CLI. First, you will need to log in:\n\n```bash\nnpx forevervm login\n```\n\nOnce logged in, you can open a REPL interface with a new machine:\n\n```bash\nnpx forevervm repl\n```\n\nWhen foreverVM starts your machine, it gives it an ID that you can later use to reconnect to it. You can reconnect to a machine like this:\n\n```bash\nnpx forevervm repl [machine_name]\n```\n\nYou can list your machines (in reverse order of creation) like this:\n\n```bash\nnpx forevervm machine list\n```\n\nYou don't need to terminate machines -- foreverVM will automatically swap them from memory to disk when they are idle, and then\nautomatically swap them back when needed. This is what allows foreverVM to run repls ‚Äúforever‚Äù.\n\nUsing the API\n-------------\n\n```typescript\nimport { ForeverVM } from '@forevervm/sdk'\n\nconst token = process.env.FOREVERVM_TOKEN\nif (!token) {\n  throw new Error('FOREVERVM_TOKEN is not set')\n}\n\n// Initialize foreverVM\nconst fvm = new ForeverVM({ token })\n\n// Connect to a new machine.\nconst repl = fvm.repl()\n\n// Execute some code\nlet execResult = repl.exec('4 + 4')\n\n// Get the result\nconsole.log('result:', await execResult.result)\n\n// We can also print stdout and stderr\nexecResult = repl.exec('for i in range(10):\\n  print(i)')\n\nfor await (const output of execResult.output) {\n  console.log(output.stream, output.data)\n}\n\nprocess.exit(0)\n```\n\nWorking with Tags\n----------------\n\nYou can create machines with tags and filter machines by tags:\n\n```typescript\nimport { ForeverVM } from '@forevervm/sdk'\n\nconst fvm = new ForeverVM({ token: process.env.FOREVERVM_TOKEN })\n\n// Create a machine with tags\nconst machineResponse = await fvm.createMachine({\n  tags: { \n    env: 'production', \n    owner: 'user123',\n    project: 'demo'\n  }\n})\n\n// List machines filtered by tags\nconst productionMachines = await fvm.listMachines({\n  tags: { env: 'production' }\n})\n```\n\nMemory Limits\n----------------\n\nYou can create machines with memory limits by specifying the memory size in megabytes:\n\n```typescript\n// Create a machine with 512MB memory limit\nconst machineResponse = await fvm.createMachine({\n  memory_mb: 512,\n})\n```\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/forevervm",
          "npm_downloads": 2784,
          "npm_package_name": "forevervm",
          "npm_success": true,
          "npm_error": null
        },
        "jango-blockchained--mcp-freecad": {
          "owner": "jango-blockchained",
          "name": "mcp-freecad",
          "url": "https://github.com/jango-blockchained/mcp-freecad",
          "imageUrl": "https://github.com/jango-blockchained.png",
          "description": "Integrates AI assistants with FreeCAD for interaction and manipulation of CAD models. Provides a standardized protocol for executing commands and receiving real-time updates, facilitating intelligent automation and integration with design workflows.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:10.315597",
          "collection_timestamp": "2025-10-03T04:27:52.305807",
          "stars": 14,
          "forks": 2,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-03-31T04:41:49Z",
          "updated_at": "2025-09-14T20:26:46Z",
          "open_issues": 4,
          "readme_content": "# üõ†Ô∏è MCP-FreeCAD Integration\n\n> **Status:** Active Development - Clean, organized codebase with multiple connection methods and comprehensive tool providers.\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)\n[![Code style: flake8](https://img.shields.io/badge/code%20style-flake8-orange.svg)](https://flake8.pycqa.org/en/latest/)\n[![Project Status: Active](https://img.shields.io/badge/repo%20status-active-green.svg)]()\n\nThis project provides a robust integration between AI assistants and FreeCAD CAD software using the **Model Context Protocol (MCP)**. It allows external applications to interact with FreeCAD through a standardized interface, offering multiple connection methods and specialized tools.\n\n---\n\n## ü§ñ **AI Provider Models (2025)**\n\nThe MCP-FreeCAD integration supports multiple AI providers with the latest 2025 models. Choose the right model for your specific use case:\n\n### **OpenAI Models**\n\n#### **Production Models:**\n- **gpt-4o** - Default multimodal model (text, image, audio)\n  - Context: 128K tokens\n  - Pricing: ~$5 per 1M input tokens\n  - Best for: General CAD tasks, multimodal interactions\n\n- **gpt-4.1** - Next-generation with 1M token context\n  - Features: Text, Image, Audio, Video support\n  - Pricing: ~$2.5 per 1M input tokens\n  - Best for: Complex CAD projects, large document analysis\n\n- **gpt-4-turbo** - Fast, cost-effective\n  - Context: 128K tokens\n  - Best for: High-volume operations, batch processing\n\n#### **Reasoning Models:**\n- **o3** - Advanced reasoning for complex CAD logic\n  - Pricing: ~$10 per 1M input tokens\n  - Best for: Complex geometry calculations, design optimization\n\n- **o4-mini** / **o4-mini-high** - Cost-effective reasoning\n  - Pricing: ~$0.15 per 1M input tokens\n  - Best for: Simple calculations, quick iterations\n\n### **Anthropic Claude Models**\n\n#### **Claude 4 Series (2025):**\n- **claude-opus-4** - Most advanced model\n  - Max Context: 200K tokens\n  - Pricing: $15/$75 per million tokens (input/output)\n  - Features: Extended thinking, tool use, memory handling\n  - Best for: Complex CAD workflows, autonomous design tasks\n\n- **claude-sonnet-4** - Balanced efficiency\n  - Max Context: 200K tokens  \n  - Pricing: $3/$15 per million tokens\n  - Features: Superior coding, hybrid reasoning\n  - Best for: General CAD operations, scripting assistance\n\n- **claude-haiku-3.5** - Fast, lightweight\n  - Best for: Quick queries, simple operations\n\n### **Google AI Models**\n\n#### **Gemini 2.5 Series (Latest):**\n- **gemini-2.5-pro-preview-05-06** - Most advanced\n  - Context: 1M tokens\n  - Features: Enhanced reasoning, thinking mode\n  - Best for: Complex CAD analysis, large assemblies\n\n- **gemini-2.5-flash-preview-04-17** - Performance optimized\n  - Features: Adaptive thinking, cost-effective\n  - Best for: Balanced performance and cost\n\n#### **Gemini 2.0 Series (Stable):**\n- **gemini-2.0-flash-001** - Production ready\n  - Features: 2x faster than Gemini 1.5 Pro\n  - Best for: Real-time CAD assistance\n\n- **gemini-2.0-flash-lite** - Cost-optimized\n  - Best for: High-volume, simple operations\n\n### **OpenRouter (Unified Access)**\n\nOpenRouter provides access to all models through a single API:\n\n#### **Model Format:** `provider/model-name`\n\n**Popular Models:**\n- `anthropic/claude-sonnet-4` - Recommended general use\n- `openai/gpt-4o` - OpenAI's flagship\n- `google/gemini-2.5-pro-preview` - Google's latest\n\n**Free Models (50-1000 requests/day):**\n- `deepseek/deepseek-r1` - Advanced reasoning\n- `deepseek/deepseek-v3` - General purpose\n- `google/gemini-2.5-flash-preview` - Google free tier\n\n### **Model Selection Guide**\n\n| **Use Case** | **Recommended Model** | **Alternative** |\n|-------------|---------------------|----------------|\n| **General CAD Work** | `claude-sonnet-4` | `gpt-4o`, `gemini-2.0-flash-001` |\n| **Complex Reasoning** | `claude-opus-4` | `o3`, `gemini-2.5-pro-preview-05-06` |\n| **Multimodal Tasks** | `gpt-4o` | `gpt-4.1`, `claude-opus-4` |\n| **Cost-Effective** | `o4-mini` | `claude-haiku-3.5`, `gemini-2.0-flash-lite` |\n| **High Volume** | `gpt-4-turbo` | `claude-sonnet-4`, `gemini-2.0-flash-001` |\n| **Free Usage** | `deepseek/deepseek-r1` | `google/gemini-2.5-flash-preview` |\n\n### **Configuration Example**\n\n```json\n{\n  \"providers\": {\n    \"anthropic\": {\n      \"enabled\": true,\n      \"model\": \"claude-sonnet-4\",\n      \"thinking_mode\": true,\n      \"max_tokens\": 64000\n    },\n    \"openai\": {\n      \"enabled\": true,\n      \"model\": \"gpt-4o\",\n      \"max_tokens\": 32000\n    },\n    \"google\": {\n      \"enabled\": true,\n      \"model\": \"gemini-2.0-flash-001\",\n      \"thinking_mode\": true\n    },\n    \"openrouter\": {\n      \"enabled\": true,\n      \"model\": \"anthropic/claude-sonnet-4\",\n      \"free_models\": [\"deepseek/deepseek-r1\"]\n    }\n  }\n}\n```\n\n### **API Usage Examples**\n\n```python\n# Using specific provider\nfrom freecad_ai import CADAssistant\n\n# Initialize with Claude Sonnet 4\nassistant = CADAssistant(provider=\"anthropic\", model=\"claude-sonnet-4\")\n\n# Create complex geometry\nresult = assistant.generate_cad_script(\n    \"Create a parametric gear with 20 teeth, 5mm module, and 20¬∞ pressure angle\"\n)\n\n# Using OpenRouter for cost optimization\nassistant_free = CADAssistant(\n    provider=\"openrouter\", \n    model=\"deepseek/deepseek-r1\"\n)\n\n# Quick operations with free model\nresult = assistant_free.create_primitive(\"box\", length=10, width=5, height=3)\n```\n\n---\n\n## üöÄ **Quick Start**\n\n### Option 1: FreeCAD Addon (Recommended for Users)\nFor the best user experience with GUI integration:\n\nüì¶ **[FreeCAD MCP Integration Addon](freecad-ai/README.md)**\n\n- üß† **Claude 4 with Thinking Mode** - Advanced AI reasoning\n- ü§ñ **Multi-Provider Support** - Claude, Gemini, OpenRouter with 13+ models  \n- üé® **Modern GUI** - Professional tabbed interface\n- üîó **Universal Connections** - All MCP connection methods\n- üìä **Performance Monitoring** - Real-time diagnostics\n\n### Option 2: MCP Server (For Developers/Integration)\n\n```bash\n# Clone the repository\ngit clone https://github.com/jango-blockchained/mcp-freecad.git\ncd mcp-freecad\n\n# Install dependencies\npip install -r requirements.txt\n\n# Start the MCP server\npython -m src.mcp_freecad.main\n\n# Or with custom config\npython -m src.mcp_freecad.main --config my_config.json --debug\n```\n\n---\n\n## üèóÔ∏è **Architecture Overview**\n\n### Core Components\n\n```\nsrc/mcp_freecad/\n‚îú‚îÄ‚îÄ main.py                 # Main entry point\n‚îú‚îÄ‚îÄ __init__.py            # Package exports and registry\n‚îú‚îÄ‚îÄ client/                # FreeCAD connection management\n‚îÇ   ‚îî‚îÄ‚îÄ freecad_connection_manager.py\n‚îú‚îÄ‚îÄ server/                # MCP server implementation\n‚îÇ   ‚îî‚îÄ‚îÄ freecad_mcp_server.py\n‚îú‚îÄ‚îÄ tools/                 # Tool providers\n‚îÇ   ‚îú‚îÄ‚îÄ base.py           # Base tool provider class\n‚îÇ   ‚îú‚îÄ‚îÄ primitives.py     # Primitive shapes (box, cylinder, etc.)\n‚îÇ   ‚îú‚îÄ‚îÄ model_manipulation.py # Transform, boolean ops, etc.\n‚îÇ   ‚îú‚îÄ‚îÄ export_import.py  # File format handling\n‚îÇ   ‚îú‚îÄ‚îÄ measurement.py    # Analysis tools\n‚îÇ   ‚îî‚îÄ‚îÄ code_generator.py # Code generation\n‚îú‚îÄ‚îÄ core/                  # Core infrastructure\n‚îÇ   ‚îú‚îÄ‚îÄ server.py         # FastAPI-based server\n‚îÇ   ‚îú‚îÄ‚îÄ cache.py          # Resource caching\n‚îÇ   ‚îú‚îÄ‚îÄ diagnostics.py    # Performance monitoring\n‚îÇ   ‚îî‚îÄ‚îÄ recovery.py       # Connection recovery\n‚îî‚îÄ‚îÄ connections/           # Connection backends\n```\n\n### Connection Methods\n\nThe system supports multiple ways to connect to FreeCAD:\n\n1. **üöÄ Launcher** (Recommended) - Uses AppImage with AppRun\n2. **üîå Server** - Socket-based connection to FreeCAD server\n3. **üåâ Bridge** - CLI-based connection using FreeCAD executable\n4. **üì° RPC** - XML-RPC connection to FreeCAD\n5. **üì¶ Wrapper** - Subprocess wrapper connection\n6. **üé≠ Mock** - For testing without FreeCAD\n\n---\n\n## üõ†Ô∏è **Available Tools**\n\n### Primitive Creation\n- `create_box` - Create box primitives\n- `create_cylinder` - Create cylinders\n- `create_sphere` - Create spheres  \n- `create_cone` - Create cones\n\n### Model Manipulation\n- `transform` - Move, rotate objects\n- `boolean_operation` - Union, difference, intersection\n- `fillet_edge` - Round edges\n- `chamfer_edge` - Chamfer edges\n- `mirror` - Mirror objects across planes\n- `scale` - Scale objects uniformly or non-uniformly\n\n### Document Management\n- `create_document` - Create new documents\n- `list_documents` - List open documents\n- `list_objects` - List objects in documents\n\n### Export/Import\n- `export_stl` - Export to STL format\n- Additional formats coming soon\n\n---\n\n## üìã **Usage Examples**\n\n### Python API\n\n```python\nfrom src.mcp_freecad import FreeCADConnection, PrimitiveToolProvider\n\n# Create connection (auto-selects best method)\nfc = FreeCADConnection(auto_connect=True)\n\nif fc.is_connected():\n    print(f\"Connected via: {fc.get_connection_type()}\")\n    \n    # Create a document\n    doc_name = fc.create_document(\"MyProject\")\n    \n    # Create objects\n    box = fc.create_box(length=20, width=10, height=5)\n    cylinder = fc.create_cylinder(radius=3, height=10)\n    \n    # Export\n    fc.export_stl(box, \"my_box.stl\")\n```\n\n### Tool Provider Usage\n\n```python\nfrom src.mcp_freecad.tools.primitives import PrimitiveToolProvider\n\n# Initialize tool provider\nprimitives = PrimitiveToolProvider()\n\n# Execute tools\nresult = await primitives.execute_tool(\"create_box\", {\n    \"length\": 10.0,\n    \"width\": 5.0, \n    \"height\": 3.0\n})\n\nprint(f\"Created: {result.result['object_id']}\")\n```\n\n### MCP Server Integration\n\n```python\nfrom src.mcp_freecad.core.server import MCPServer\nfrom src.mcp_freecad import TOOL_PROVIDERS\n\n# Setup server\nserver = MCPServer()\n\n# Register tool providers\nserver.register_tool(\"primitives\", TOOL_PROVIDERS[\"primitives\"]())\nserver.register_tool(\"model_manipulation\", TOOL_PROVIDERS[\"model_manipulation\"]())\n\n# Initialize and run\nawait server.initialize()\n```\n\n---\n\n## ‚öôÔ∏è **Configuration**\n\n### Basic Configuration (`config.json`)\n\n```json\n{\n  \"server\": {\n    \"name\": \"mcp-freecad-server\",\n    \"version\": \"0.7.11\"\n  },\n  \"freecad\": {\n    \"connection_method\": \"auto\",\n    \"host\": \"localhost\",\n    \"port\": 12345,\n    \"freecad_path\": \"freecad\"\n  },\n  \"tools\": {\n    \"enable_primitives\": true,\n    \"enable_model_manipulation\": true,\n    \"enable_export_import\": true\n  }\n}\n```\n\n### Connection Method Configuration\n\n```json\n{\n  \"freecad\": {\n    \"connection_method\": \"launcher\",\n    \"use_apprun\": true,\n    \"apprun_path\": \"/path/to/squashfs-root/AppRun\",\n    \"script_path\": \"/path/to/freecad_launcher_script.py\"\n  }\n}\n```\n\n---\n\n## üîß **Development**\n\n### Project Structure\n\n- **`src/mcp_freecad/`** - Main package\n- **`freecad-ai/`** - FreeCAD GUI addon\n- **`tests/`** - Test suite\n- **`docs/`** - Documentation\n- **`scripts/`** - Setup and utility scripts\n\n### Adding New Tools\n\n1. Create a new tool provider in `src/mcp_freecad/tools/`\n2. Inherit from `ToolProvider` base class\n3. Implement required methods (`tool_schema`, `execute_tool`)\n4. Register in `TOOL_PROVIDERS` in `__init__.py`\n\n```python\nfrom .base import ToolProvider, ToolResult, ToolSchema\n\nclass MyToolProvider(ToolProvider):\n    @property\n    def tool_schema(self) -> ToolSchema:\n        return ToolSchema(\n            name=\"my_tool\",\n            description=\"My custom tool\",\n            parameters={...},\n            returns={...}\n        )\n    \n    async def execute_tool(self, tool_id: str, params: Dict[str, Any]) -> ToolResult:\n        # Implementation\n        return self.format_result(status=\"success\", result=result)\n```\n\n### Testing\n\n```bash\n# Run tests\npython -m pytest tests/\n\n# Run with coverage\npython -m pytest tests/ --cov=src --cov-report=html\n\n# Run specific test\npython -m pytest tests/test_primitives.py -v\n```\n\n---\n\n## üê≥ **Docker Support**\n\n```bash\n# Build and run with Docker Compose\ndocker compose up\n\n# Build from scratch\ndocker compose build --no-cache\ndocker compose up\n```\n\n---\n\n## üìö **Documentation**\n\n- [FreeCAD Integration Guide](docs/FREECAD_INTEGRATION.md)\n- [Connection Methods](docs/CONNECTION_METHODS.md)\n- [Tool Development](docs/TOOL_DEVELOPMENT.md)\n- [Configuration Reference](docs/CONFIGURATION.md)\n\n---\n\n## ü§ù **Contributing**\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Add tests\n5. Submit a pull request\n\n---\n\n## üìÑ **License**\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\n## üôè **Acknowledgments**\n\n- FreeCAD development team for the excellent CAD software\n- Anthropic for the Model Context Protocol (MCP) framework\n- Contributors and community members\n\n---\n\n<div align=\"center\">\n<sub>\nüõ†Ô∏è <strong>MCP-FreeCAD Integration</strong> - Bridging AI and CAD through advanced connectivity<br>\nCrafted with ‚ù§Ô∏è by jango-blockchained ‚Ä¢ 2025\n</sub>\n</div>\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jankowtf--mcp-hitchcode": {
          "owner": "jankowtf",
          "name": "mcp-hitchcode",
          "url": "https://github.com/jankowtf/mcp-hitchcode",
          "imageUrl": "https://github.com/jankowtf.png",
          "description": "Create custom tools for Cursor IDE that provide structured coding assistance and code templates. Easily deploy the server on Heroku or run it locally using Docker.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:10.815690",
          "collection_timestamp": "2025-10-03T04:27:59.466994",
          "stars": 2,
          "forks": 3,
          "license": "MIT License",
          "language": "Python",
          "created_at": "2025-02-24T16:45:36Z",
          "updated_at": "2025-03-15T13:48:09Z",
          "open_issues": 2,
          "readme_content": "# MCP Server Template for Cursor IDE\n\nA simple template for creating custom tools for Cursor IDE using Model Context Protocol (MCP). Create your own repository from this template, modify the tools, and connect them to your Cursor IDE.\n\n![Server Mood Response](docs/images/server-mood.png)\n\n## Quick Start\n\n1. Click \"Deploy to Heroku\" button\n\n    [![Deploy to Heroku](https://www.herokucdn.com/deploy/button.svg)](https://heroku.com/deploy?template=https://github.com/kirill-markin/weaviate-mcp-server)\n\n2. After deployment, configure Cursor:\n   - Open Cursor Settings ‚Üí Features\n   - Add new MCP server\n   - Use your Heroku URL with `/sse` path (e.g., `https://<your-app-name>.herokuapp.com/sse`)\n\n3. Test your agent's mood in Cursor:\n   - Ask your agent \"Please ask about our server mood and let me know how it is.\"\n   - The server will respond with a cheerful message and a heart ‚ù§Ô∏è\n\n## Alternative Setup Methods\n\nYou can run the server in three ways: using Docker, traditional Python setup, or directly in Cursor IDE.\n\n### Docker Setup\n\nThe project includes Docker support for easy deployment:\n\n1. Initial setup:\n```bash\n# Clone the repository\ngit clone https://github.com/kirill-markin/weaviate-mcp-server.git\ncd weaviate-mcp-server\n\n# Create environment file\ncp .env.example .env\n```\n\n2. Build and run using Docker Compose:\n```bash\n# Build and start the server\ndocker compose up --build -d\n\n# View logs\ndocker compose logs -f\n\n# Check server status\ndocker compose ps\n\n# Stop the server\ndocker compose down\n```\n\n3. The server will be available at:\n   - SSE endpoint: http://localhost:8000/sse\n\n4. Quick test:\n```bash\n# Test the server endpoint\ncurl -i http://localhost:8000/sse\n```\n\n5. Connect to Cursor IDE:\n   - Open Cursor Settings ‚Üí Features\n   - Add new MCP server\n   - Type: Select \"sse\"\n   - URL: Enter `http://localhost:8000/sse`\n\n### Traditional Setup\n\nFirst, install the uv package manager:\n\n```bash\n# Install uv on macOS\nbrew install uv\n# Or install via pip (any OS)\npip install uv\n```\n\nStart the server using either stdio (default) or SSE transport:\n\n```bash\n# Install the package with development dependencies\nuv pip install -e \".[dev]\"\n\n# Using stdio transport (default)\nuv run mcp-hitchcode\n\n# Using SSE transport on custom port\nuv run mcp-hitchcode --transport sse --port 8000\n\n# Run tests\nuv run pytest -v\n```\n\nAfter installation, you can connect the server directly to Cursor IDE:\n\n1. Right-click on the `cursor-run-mcp-server.sh` file in Cursor\n2. Select \"Copy Path\" to copy the absolute path\n3. Open Cursor Settings (gear icon)\n4. Navigate to Features tab\n5. Scroll down to \"MCP Servers\"\n6. Click \"Add new MCP server\"\n7. Fill in the form:\n   - Name: Choose any name (e.g., \"my-mcp-server-1\")\n   - Type: Select \"stdio\" (not \"sse\" because we run the server locally)\n   - Command: Paste the absolute path to `cursor-run-mcp-server.sh` that you copied earlier. For example: `/Users/kirillmarkin/weaviate-mcp-server/cursor-run-mcp-server.sh`\n\n### Environment Variables\n\nAvailable environment variables (can be set in `.env`):\n\n- `MCP_SERVER_PORT` (default: 8000) - Port to run the server on\n- `MCP_SERVER_HOST` (default: 0.0.0.0) - Host to bind the server to\n- `DEBUG` (default: false) - Enable debug mode\n- `MCP_USER_AGENT` - Custom User-Agent for website fetching\n\n## Additional options\n\n### Installing via Smithery\n\n[![smithery badge](https://smithery.ai/badge/@kirill-markin/example-mcp-server)](https://smithery.ai/server/@kirill-markin/example-mcp-server)\n\nTo install MCP Server Template for Cursor IDE for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kirill-markin/example-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @kirill-markin/example-mcp-server --client claude\n```\n\n### Glama server review\n\n<a href=\"https://glama.ai/mcp/servers/jgisqn8zco\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/jgisqn8zco/badge\" alt=\"Server Template for Cursor IDE MCP server\" /></a>\n\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "janwilmake--openapi-mcp-server": {
          "owner": "janwilmake",
          "name": "openapi-mcp-server",
          "url": "https://github.com/janwilmake/openapi-mcp-server",
          "imageUrl": "https://github.com/janwilmake.png",
          "description": "Enables exploration and understanding of OpenAPI specifications with a simple interface for retrieving overviews and detailed explanations of API operations. Supports both JSON and YAML formats for seamless integration with Claude Desktop and Cursor clients.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:11.384641",
          "collection_timestamp": "2025-10-03T04:28:03.033508",
          "stars": 826,
          "forks": 89,
          "license": "MIT License",
          "language": "JavaScript",
          "created_at": "2024-12-07T18:14:50Z",
          "updated_at": "2025-10-01T22:15:20Z",
          "open_issues": 7,
          "readme_content": "# OpenAPI MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@janwilmake/openapi-mcp-server)](https://smithery.ai/server/@janwilmake/openapi-mcp-server) [![janwilmake/openapi-mcp-server context](https://badge.forgithub.com/janwilmake/openapi-mcp-server?excludePathPatterns=*.yaml)](https://uithub.com/janwilmake/openapi-mcp-server?excludePathPatterns=*.yaml)\n\nA Model Context Protocol (MCP) server for Claude/Cursor that enables searching and exploring OpenAPI specifications through oapis.org.\n\n- Demo: https://x.com/janwilmake/status/1903497808134496583\n- HN Thread: https://news.ycombinator.com/item?id=43447278\n- OpenAPISearch: https://github.com/janwilmake/openapisearch\n- OAPIS: https://github.com/janwilmake/oapis\n\nThe MCP works by applying a 3 step process :\n\n1. It figures out the openapi identifier you need\n2. It requests a summary of that in simple language\n3. It determines which endpoints you need, and checks out how exactly they work (again, in simple language)\n\n## Features\n\n- Get an overview of any OpenAPI specification\n- Retrieve details about specific API operations\n- Support for both JSON and YAML formats\n- Tested with Claude Desktop and Cursor\n\n| Summary                                       | Prompt it                                                                                                                                                                                                                                                                                                                                                 |\n| --------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Basic understanding of the OpenAPI MCP Server | [![](https://b.lmpify.com/overview)](https://lmpify.com?q=https%3A%2F%2Fuuithub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3DREADME.md%26pathPatterns%3Dopenapi-mcp.drawio.png%0A%0ACan%20you%20explain%20what%20OpenAPI%20MCP%20Server%20does%20and%20how%20I%20can%20use%20it%20with%20Claude%20Desktop%3F)                     |\n| Core implementation details of the MCP server | [![](https://b.lmpify.com/implementation)](https://lmpify.com?q=https%3A%2F%2Fuuithub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3Dindex.js%26pathPatterns%3Dpackage.json%0A%0AHow%20does%20the%20OpenAPI%20MCP%20Server%20handle%20API%20requests%3F%20Can%20you%20explain%20the%20tool%20handlers%3F)                           |\n| How to extend or contribute to the project    | [![](https://b.lmpify.com/extend)](https://lmpify.com?q=https%3A%2F%2Fuuithub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3Dindex.js%26pathPatterns%3Dpackage.json%26pathPatterns%3DREADME.md%0A%0AI'd%20like%20to%20add%20support%20for%20a%20new%20feature%20to%20the%20OpenAPI%20MCP%20Server.%20Where%20should%20I%20start%3F) |\n\n## Installation\n\n### Installing via Smithery\n\nOur hosted smithery URL is https://smithery.ai/server/@janwilmake/openapi-mcp-server\n\nTo install openapi-mcp-server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@janwilmake/openapi-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @janwilmake/openapi-mcp-server --client claude\n```\n\nFor other clients, see the [smithery page](https://smithery.ai/server/@janwilmake/openapi-mcp-server) for instructions.\n\n### Installing using stdio\n\n```\n{\n  \"mcpServers\": {\n    \"openapi-mcp-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/openapi-mcp-server/index.js\"],\n      \"env\": {\n        \"DEBUG\": \"true\"\n      }\n    }\n  }\n}\n```\n\n## Usage in Claude\n\nOnce installed, you can ask Claude to:\n\n- \"Find information about the Stripe API\"\n- \"Explain how to use the GitHub API's repository endpoints\"\n\nClaude will use the MCP server to:\n\n1. First get an overview of the requested API\n2. Then retrieve specific operation details as needed\n\n## Requirements\n\n- Node.js >= 16.17.0\n- Claude Desktop, Cursor, or any other MCP client.\n\n## License\n\nMIT\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/openapi-mcp-server",
          "npm_downloads": 10334,
          "npm_package_name": "openapi-mcp-server",
          "npm_success": true,
          "npm_error": null
        },
        "janwilmake--uithub-mcp": {
          "owner": "janwilmake",
          "name": "uithub-mcp",
          "url": "https://github.com/janwilmake/uithub-mcp",
          "imageUrl": "https://github.com/janwilmake.png",
          "description": "Enables natural language exploration and analysis of GitHub repositories by retrieving their contents with advanced filtering options. Integrates with Claude Desktop for enhanced code understanding and discussion.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:11.923692",
          "collection_timestamp": "2025-10-03T04:28:06.536003",
          "stars": 15,
          "forks": 2,
          "license": "No License",
          "language": "TypeScript",
          "created_at": "2025-03-12T18:43:06Z",
          "updated_at": "2025-09-27T12:23:50Z",
          "open_issues": 2,
          "readme_content": "# UIThub MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@janwilmake/uithub-mcp)](https://smithery.ai/server/@janwilmake/uithub-mcp)\n\nModel Context Protocol (MCP) server for interacting with the [uithub API](https://uithub.com), which provides a convenient way to fetch GitHub repository contents.\n\nThis MCP server allows Claude to retrieve and analyze code from GitHub repositories, making it a powerful tool for understanding and discussing code.\n\n## TODO\n\n- ‚úÖ Simple MCP Server for Claude Desktop\n- Make MCP for cursor too https://docs.cursor.com/context/model-context-protocol\n- MCP cline support https://github.com/cline/mcp-marketplace\n- Button to learn to install MCPs on separate page.\n- Add patch api to MCP Server\n\n## Features\n\n- Retrieve repository contents with smart filtering options\n- Specify file extensions to include or exclude\n- Integrate with Claude Desktop for natural language exploration of repositories\n\n## Installation\n\n### Installing via Smithery\n\nTo install uithub-mcp for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@janwilmake/uithub-mcp):\n\n```bash\nnpx -y @smithery/cli install @janwilmake/uithub-mcp --client claude\n```\n\n### Manual Installation\n1. `npx uithub-mcp init`\n2. restart claude\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "https://www.npmjs.com/package/uithub-mcp",
          "npm_downloads": 936,
          "npm_package_name": "uithub-mcp",
          "npm_success": true,
          "npm_error": null
        },
        "jar285--github_mcp_analyzer": {
          "owner": "jar285",
          "name": "github_mcp_analyzer",
          "url": "https://github.com/jar285/github_mcp_analyzer",
          "imageUrl": "https://github.com/jar285.png",
          "description": "Enable real-time analysis of GitHub repositories by retrieving metadata, analyzing issues, accessing documentation, and visualizing activity metrics.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:12.466684",
          "collection_timestamp": "2025-10-03T04:28:18.246463",
          "stars": 0,
          "forks": 1,
          "license": "No License",
          "language": "Python",
          "created_at": "2025-04-17T02:10:06Z",
          "updated_at": "2025-04-17T07:07:02Z",
          "open_issues": 0,
          "readme_content": "# GitHub Repository Analyzer MCP Server\n\nA Model Context Protocol (MCP) server that enables Large Language Models to analyze GitHub repositories in real-time. This server provides tools for retrieving repository information, analyzing issues, accessing documentation, and visualizing activity.\n\n## Features\n\n- **Repository Information Tool**: Retrieve basic metadata about GitHub repositories\n- **Issue Analysis Tool**: List and categorize repository issues\n- **README Access Resource**: Access repository documentation\n- **Commit History Tool**: Analyze recent code changes\n- **Activity Analysis Tool**: Calculate repository activity metrics\n- **Visualization Tool**: Create visual charts of repository activity\n\n## Prerequisites\n\n- Python 3.10 or higher\n- GitHub account and Personal Access Token\n\n## Installation\n\n1. Clone this repository:\n\n```bash\ngit clone <repository-url>\ncd github-repo-analyzer\n```\n\n2. Create and activate a virtual environment:\n\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n4. Create a `.env` file with your GitHub API token:\n\n```bash\ncp .env.example .env\n```\n\nEdit the `.env` file and replace `your_github_token_here` with your actual GitHub Personal Access Token.\n\n## Usage\n\n### Running the Server\n\nTo start the server in development mode with the MCP Inspector:\n\n```bash\nmcp dev src/server.py\n```\n\nThis will open a web interface in your browser where you can test the server's tools.\n\n### Registering with Claude Desktop\n\nTo register the server with Claude Desktop:\n\n```bash\nmcp install src/server.py\n```\n\nAfter registering, restart Claude Desktop. You can then interact with the GitHub Repository Analyzer by asking Claude questions about GitHub repositories.\n\n### Example Prompts for Claude\n\n- \"Can you analyze the GitHub repository 'modelcontextprotocol/python-sdk' and tell me about its purpose and activity level?\"\n- \"What are the top 5 open issues in the 'openai/openai-python' repository?\"\n- \"How active has the 'anthropics/anthropic-sdk-python' repository been in the last 30 days?\"\n- \"Please read the README of the 'microsoft/TypeScript' repository and explain its main features.\"\n- \"Generate a chart showing the commit activity for 'facebook/react' over the last 60 days.\"\n\n## Development\n\n### Project Structure\n\n```\ngithub-repo-analyzer/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ github_tools.py  # GitHub API client implementation\n‚îÇ   ‚îî‚îÄ‚îÄ server.py        # MCP server implementation\n‚îú‚îÄ‚îÄ requirements.txt     # Dependencies\n‚îú‚îÄ‚îÄ .env.example         # Example environment variables\n‚îú‚îÄ‚îÄ .gitignore           # Git ignore file\n‚îî‚îÄ‚îÄ README.md            # Project documentation\n```\n\n### Adding New Tools\n\nTo add a new tool to the server, follow these steps:\n\n1. Add the necessary functionality to the `GitHubAPIClient` class in `github_tools.py`\n2. Register the tool with the MCP server in `server.py` using the `@server.tool` decorator\n3. Test the tool using the MCP Inspector\n\n## Testing\n\nTo test the server, use the MCP Inspector as described in the Usage section. You can also write unit tests for the GitHub API client functionality.\n\n## Security Considerations\n\n- Never commit your GitHub API token to version control\n- Use the minimum required scopes for your GitHub token\n- Be mindful of GitHub API rate limits\n\n## License\n\n[MIT License](LICENSE)\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        },
        "jasonjmcghee--claude-debugs-for-you": {
          "owner": "jasonjmcghee",
          "name": "claude-debugs-for-you",
          "url": "https://github.com/jasonjmcghee/claude-debugs-for-you",
          "imageUrl": "https://github.com/jasonjmcghee.png",
          "description": "Interactively debug code with breakpoints, evaluate expressions, and enhance the coding experience using LLMs. The server is language-agnostic and works with valid launch configurations in Visual Studio Code.",
          "enhanced": false,
          "processed": true,
          "got_data": true,
          "processing_timestamp": "2025-10-03T14:33:13.060796",
          "collection_timestamp": "2025-10-03T04:28:25.353707",
          "stars": 434,
          "forks": 40,
          "license": "MIT License",
          "language": "TypeScript",
          "created_at": "2025-01-17T05:54:24Z",
          "updated_at": "2025-10-02T19:40:19Z",
          "open_issues": 12,
          "readme_content": "# <img src=\"./images/claude-debugs-for-you.png\" width=\"64\" height=\"64\" alt=\"description\" align=\"center\"> Claude Debugs For You\n\n[![Badge](https://img.shields.io/badge/Visual%20Studio%20Marketplace-0.1.1-blue.svg)](https://marketplace.visualstudio.com/items?itemName=JasonMcGhee.claude-debugs-for-you)\n\n_aka Vibe Debugging_\n\n### Enable Claude (or any other LLM) to interactively debug your code\n\nThis is an [MCP](https://docs.anthropic.com/en/docs/build-with-claude/mcp) Server and VS Code extension which enables claude to interactively debug and evaluate expressions.\n\nThat means it should also work with other models / clients etc. but I only demonstrate it with Claude Desktop and Continue here.\n\nIt's language-agnostic, assuming debugger console support and valid launch.json for debugging in VSCode.\n\n## Getting Started\n\n1. Download the extension from [releases](https://github.com/jasonjmcghee/claude-debugs-for-you/releases/) or [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=JasonMcGhee.claude-debugs-for-you)\n2. Install the extension\n  - If using `.vsix` directly, go to the three dots in \"Extensions\" in VS Code and choose \"Install from VSIX...\"\n3. You will see a new status menu item \"Claude Debugs For You\" which shows if it is running properly (check) or failed to startup (x)\n\n<img width=\"314\" alt=\"Screenshot 2025-03-22 at 9 51 22‚ÄØPM\" src=\"https://github.com/user-attachments/assets/2cd65e0d-4c1d-4fb6-b9ea-3995149b4043\" />\n\nYou can click this status menu for the commands available\n\n<img width=\"510\" alt=\"Screenshot 2025-03-22 at 9 59 22‚ÄØPM\" src=\"https://github.com/user-attachments/assets/54e339e3-81f8-4ef2-a201-6742aa2c97a8\" />\n\n### Follow one of the options below, depending on your setup\n\n<details>\n  <summary>If using stdio (classic, required for Claude Desktop)</summary>\n\n4. Copy the stdio server path to your clipboard by searching vs code commands for \"Copy MCP Debug Server stdio path to clipboard\"\n\n5. Paste the following (BUT UPDATE THE PATH TO THE COPIED ONE!) in your `claude_desktop_config.json` or edit accordingly if you use other MCP servers\n\n```\n{\n  \"mcpServers\": {\n    \"debug\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/mcp-debug.js\"\n      ]\n    }\n  }\n}\n```\n\n6. Start Claude desktop (or other MCP client)\n    1. Note: You may need to restart it, if it was already running.\n    2. You can skip this step if using Continue/Cursor or other built-in to VS Code\n</details>\n\n<details>\n  <summary>If using `/sse` (e.g. Cursor)</summary>\n\n4. Retrieve the MCP server sse address by using the \"Copy MCP Debug Server sse address to clipboard\" command\n    1. You can just write it out server URL of \"http://localhost:4711/sse\", or whatever port you setup in settings.\n5. Add it wherever you need to based on your client\n    1. You may need to hit \"refresh\" depending on client: this is required in Cursor\n6. Start MCP client\n   1. Note: You may need to restart it, if it was already running.\n   2. You can skip this step if using Continue/Cursor or other built-in to VS Code\n\n</details>\n\n### You're ready to debug!\n\n_[VS Code Debugging Documentation](https://code.visualstudio.com/Docs/editor/debugging)_\n\nOpen a project containing a `.vscode/launch.json` with the first configuration setup to debug a specific file with `${file}`.\n\nSee [Run  an Example](#run-an-example) below, and/or watch a demo video.\n\n## Contributing\n\nFind bugs or have an idea that will improve this? Please open a pull request or log an issue.\n\nDoes this readme suck? Help me improve it!\n\n## Demo\n\n### Using [Continue](https://github.com/continuedev/continue)\n\nIt figures out the problem, and then suggests a fix, which we just click to apply\n\nhttps://github.com/user-attachments/assets/3a0a879d-2db7-4a3f-ab43-796c22a0f1ef\n\n<details>\n  <summary>How do I set this up with Continue? / Show MCP Configuration</summary>\n\n  [Read the docs!](https://docs.continue.dev/customize/tools)\n\n  Configuration:\n  \n  ```json\n  {\n    ...\n    \"experimental\": {\n      \"modelContextProtocolServers\": [\n        {\n          \"transport\": {\n            \"type\": \"stdio\",\n            \"command\": \"node\",\n            \"args\": [\n              \"/Users/jason/Library/Application Support/Code/User/globalStorage/jasonmcghee.claude-debugs-for-you/mcp-debug.js\"\n            ]\n          }\n        }\n      ]\n    }\n  }\n  ```\n\n  You'll also need to choose a model capable of using tools.\n\n  When the list of tools pops up, make sure to click \"debug\" in the list of your tools, and set it to be \"Automatic\".\n\n  ### Troubleshooting\n\n  If you are seeing MCP errors in continue, try disabling / re-enabling the continue plugin\n\n</details>\n\nIf helpful, this is what my configuration looks like! But it's nearly the same as Claude Desktop.\n\n\n### Using Claude Desktop\n\nIn this example, I made it intentionally very cautious (make no assumptions etc - same prompt as below) but you can ask it to do whatever.\n\nhttps://github.com/user-attachments/assets/ef6085f7-11a2-4eea-bb60-b5a54873b5d5\n\n## Developing\n\n- Clone / Open this repo with VS Code\n- Run `npm run install` and `npm run compile`\n- Hit \"run\" which will open a new VSCode\n- Otherwise same as \"Getting Started applies\"\n- To rebuild, `npm run compile`\n\n## Package\n\n```bash\nvsce package\n```\n\n\n## Run an Example\n\nOpen `examples/python` in a VS Code window\n\nEnter the prompt:\n\n```\ni am building `longest_substring_with_k_distinct` and for some reason it's not working quite right. can you debug it step by step using breakpoints and evaluating expressions to figure out where it goes wrong? make sure to use the debug tool to get access and debug! don't make any guesses as to the problem up front. DEBUG!\n```\n\n## Other things worth mentioning\n\nWhen you start multiple vs code windows, you'll see a pop-up. You can gracefully hand-off \"Claude Debugs For You\" between windows.\n\nYou can also disable autostart. Then you'll just need to click the status menu and select \"Start Server\".\n\n<img width=\"395\" alt=\"Screenshot 2025-03-22 at 10 08 52‚ÄØPM\" src=\"https://github.com/user-attachments/assets/2b6d1b61-a2c6-4447-8054-b4dd02a716e8\" />\n\n\n## Short list of ideas\n\n- [ ] It should use ripgrep to find what you ask for, rather than list files + get file content.\n- [x] Add support for conditional breakpoints\n- [ ] Add \"fix\" tool by allowing MCP to insert a CodeLens or \"auto fix\" suggestion so the user can choose to apply a recommended change or not.\n- Your idea here!\n",
          "github_success": true,
          "github_error": null,
          "npm_url": "",
          "npm_downloads": 0,
          "npm_package_name": null,
          "npm_success": false,
          "npm_error": "No NPM package found"
        }
      }
    }
  },
  "processing_completed": "2025-10-03T14:35:00.628442"
}
