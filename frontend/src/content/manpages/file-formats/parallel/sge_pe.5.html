<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>sge_pe - Grid Engine parallel environment configuration file format</title>
    <style>
        body { font-family: monospace; margin: 20px; line-height: 1.4; }
        a { color: #0066cc; }
        pre { white-space: pre-wrap; }
    </style>
</head>
<body>
    <div id="main-content">
<section class="p-strip is-bordered">
<div class="row">
<div class="col-3 u-hide--small u-hide" id="toc">
</div>
<div id="tableWrapper">
<p id="distroAndSection"></p>

Provided by: <a href="https://launchpad.net/ubuntu/questing/+package/gridengine-common">gridengine-common_8.1.9+dfsg-13.1_all</a> <br><br><pre>
</pre><h4><b>NAME</b></h4><pre>
       sge_pe - Grid Engine parallel environment configuration file format

</pre><h4><b>DESCRIPTION</b></h4><pre>
       Parallel  environments  are  parallel  programming  and  runtime environments supporting the execution of
       shared memory or distributed memory parallelized applications. Parallel environments usually require some
       kind of setup to be operational before starting  parallel  applications.   Examples  of  common  parallel
       environments  are  OpenMP on shared memory multiprocessor systems, and Message Passing Interface (MPI) on
       shared memory or distributed systems.

       <u>sge_pe</u> allows for the definition of interfaces to  arbitrary  parallel  environments.   Once  a  parallel
       environment  is  defined  or modified with the <b>-ap</b> or <b>-mp</b> options to <u><a href="../man1/qconf.1.html">qconf</a></u>(1) and linked with one or more
       queues via <u>pe_list</u> in <u><a href="../man5/queue_conf.5.html">queue_conf</a></u>(5) the environment can be requested for a job  via  the  <b>-pe</b>  switch  to
       <u><a href="../man1/qsub.1.html">qsub</a></u>(1)  together  with  a  request for a numeric range of parallel processes to be allocated by the job.
       Additional <b>-l</b> options may be used to specify more detailed job requirements.

       Note, Grid Engine allows backslashes (\) be used to escape newline  characters.  The  backslash  and  the
       newline are replaced with a space character before any interpretation.

</pre><h4><b>FORMAT</b></h4><pre>
       The format of a <u>sge_pe</u> file is defined as follows:

   <b>pe_name</b>
       The  name  of  the  parallel  environment  in  the format for <u>pe_name</u> in <u><a href="../man1/sge_types.1.html">sge_types</a></u>(1).  To be used in the
       <u><a href="../man1/qsub.1.html">qsub</a></u>(1) <b>-pe</b> switch.

   <b>slots</b>
       The total number of slots (normally one per parallel process or thread) allowed to be filled concurrently
       under the parallel environment.  Type is integer, valid values are 0 to 9999999.

   <b>user_lists</b>
   <b>xuser_lists</b>
       A comma-separated list of user access list names (see <u><a href="../man5/access_list.5.html">access_list</a></u>(5)).

       Each user contained in at  least  one  of  the  <b>user_lists</b>  access  lists  has  access  to  the  parallel
       environment.  If  the  <b>user_lists</b>  parameter  is  set  to  NONE  (the default) any user has access if not
       explicitly excluded via the <b>xuser_lists</b> parameter.

       Each user contained in at least one of the <b>xuser_lists</b> access lists is not allowed to access the parallel
       environment. If the <b>xuser_lists</b> parameter is set to NONE (the default) any user has access.

       If a user is contained both in an access list in <b>xuser_lists</b> and <b>user_lists</b> the user is denied access  to
       the parallel environment.

   <b>start_proc_args</b>
   <b>stop_proc_args</b>
       The  command  line  respectively of a startup or shutdown procedure (an executable command, plus possible
       arguments) for the parallel environment, or "none" for no procedure  (typically  for  tightly  integrated
       PEs).   The  command  line is started directly, not in a shell.  An optional prefix "<u>user</u><b>@</b>" specifies the
       username under which the procedure is to be started.   In  that  case  see  the  SECURITY  section  below
       concerning security issues running as a privileged user.

       The  startup procedure is invoked by <u><a href="../man8/sge_shepherd.8.html">sge_shepherd</a></u>(8) on the master node of the job prior to executing the
       job script. Its purpose is to setup the parallel  environment  according  to  its  needs.   The  shutdown
       procedure  is  invoked  by  <u><a href="../man8/sge_shepherd.8.html">sge_shepherd</a></u>(8) after the job script has finished. Its purpose is to stop the
       parallel environment and to remove it from  all  participating  systems.   The  standard  output  of  the
       procedure  is  redirected  to  the  file <u>REQUEST</u>.po<u>JID</u> in the job's working directory (see <u><a href="../man1/qsub.1.html">qsub</a></u>(1)), with
       <u>REQUEST</u> being the name of the job as displayed by  <u><a href="../man1/qstat.1.html">qstat</a></u>(1),  and  <u>JID</u>  being  the  job's  identification
       number.  Likewise, the standard error output is redirected to <u>REQUEST</u>.pe<u>JID</u>.  If the <b>-e</b> or <b>-o</b> options are
       given on job submission, the PE error and standard output is merged into the paths specified.

       The  following  special variables, expanded at runtime, can be used (besides any other strings which have
       to be interpreted by the start and stop procedures) to constitute a command line:

       <u>$pe_hostfile</u>
              The pathname of a file containing a detailed description of the layout of the parallel environment
              to be setup by the start-up procedure. Each line of the file refers to a host  on  which  parallel
              processes  are  to be run. The first entry of each line denotes the hostname, the second entry the
              number of parallel processes to be run on the host, the third entry the name of  the  queue.   The
              entries are separated by spaces.  If <b>-binding</b> <b>pe</b> is specified on job submission, the fourth column
              is  the  core  binding specification as colon-separated socket-core pairs, like "0,0:0,1", meaning
              the first core on the first socket and the second core  on  the  first  socket  can  be  used  for
              binding.   Otherwise it will be "UNDEFINED".  With the obsolete queue <b>processors</b> specification the
              fourth entry could be a multi-processor configuration (or "&lt;NULL&gt;").

       <u>$host</u>  The name of the host on which the startup or stop procedures are run.

       <u>$ja_task_id</u>
              The array job task index (0 if not an array job).

       <u>$job_owner</u>
              The user name of the job owner.

       <u>$job_id</u>
              Grid Engine's unique job identification number.

       <u>$job_name</u>
              The name of the job.

       <u>$pe</u>    The name of the parallel environment in use.

       <u>$pe_slots</u>
              Number of slots granted for the job.

       <u>$processors</u>
              The <b>processors</b> string as contained in the queue configuration (see <u><a href="../man5/queue_conf.5.html">queue_conf</a></u>(5))  of  the  master
              queue (the queue in which the startup and stop procedures are run).

       <u>$queue</u> The cluster queue of the master queue instance.

       <u>$sge_cell</u>
              The SGE_CELL environment variable (useful for locating files).

       <u>$sge_root</u>
              The SGE_ROOT environment variable (useful for locating files).

       <u>$stdin_path</u>
              The standard input path.

       <u>$stderr_path</u>
              The standard error path.

       <u>$stdout_path</u>
              The standard output path.

       <u>$merge_stderr</u>

       <u>$fs_stdin_host</u>

       <u>$fs_stdin_path</u>

       <u>$fs_stdin_tmp_path</u>

       <u>$fs_stdin_file_staging</u>

       <u>$fs_stdout_host</u>

       <u>$fs_stdout_path</u>

       <u>$fs_stdout_tmp_path</u>

       <u>$fs_stdout_file_staging</u>

       <u>$fs_stderr_host</u>

       <u>$fs_stderr_path</u>

       <u>$fs_stderr_tmp_path</u>

       <u>$fs_stderr_file_staging</u>

       The  start  and  stop commands are run with the same environment setting as that of the job to be started
       afterwards (see <u><a href="../man1/qsub.1.html">qsub</a></u>(1)).

   <b>allocation_rule</b>
       The allocation rule is interpreted by the scheduler thread and helps  the  scheduler  to  decide  how  to
       distribute  parallel  processes among the available machines. If, for instance, a parallel environment is
       built for shared memory applications only, all parallel  processes  have  to  be  assigned  to  a  single
       machine,  no  matter  how  many  suitable  machines are available.  If, however, the parallel environment
       follows the distributed memory paradigm,  an  even  distribution  of  processes  among  machines  may  be
       favorable, as may packing processes onto the minimum number of machines.

       The current version of the scheduler only understands the following allocation rules:

       <u>int</u>    An  integer,  fixing the number of processes per host. If it is 1, all processes have to reside on
              different hosts. If the special name <b>$pe_slots</b> is used, the full range of processes  as  specified
              with  the  <u><a href="../man1/qsub.1.html">qsub</a></u>(1) <b>-pe</b> switch has to be allocated on a single host (no matter what value belonging
              to the range is finally chosen for the job to be allocated).

       <b>$fill_up</b>
              Starting from the best suitable host/queue, all available slots are allocated. Further  hosts  and
              queues are "filled up" as long as a job still requires slots for parallel tasks.

       <b>$round_robin</b>
              From  all suitable hosts, a single slot is allocated until all tasks requested by the parallel job
              are dispatched. If more tasks are requested than suitable hosts are found, allocation starts again
              from the first host.  The allocation scheme walks through suitable hosts in a  most-suitable-first
              order.

   <b>control_slaves</b>
       This parameter can be set to TRUE or FALSE (the default). It indicates whether Grid Engine is the creator
       of  the  slave  tasks  of  a  parallel application via <u><a href="../man8/sge_execd.8.html">sge_execd</a></u>(8) and <u><a href="../man8/sge_shepherd.8.html">sge_shepherd</a></u>(8) and thus has full
       control over all processes in a parallel application  ("tight integration").  This enables:

       •      resource limits are enforced for all tasks, even on slave hosts;

       •      resource consumption is properly accounted on all hosts;

       •      proper control of tasks, with no need to write a customized terminate method to ensure that  whole
              job  is  finished  on  <u>qdel</u>  and  that  tasks  are  properly  reaped  in  the case of abnormal job
              termination;

       •      all tasks are started with the appropriate nice value which was  configured  as  <b>priority</b>  in  the
              queue configuration;

       •      propagation  of  the  job environment to slave hosts, e.g. so that they write into the appropriate
              per-job temporary directory specified by TMPDIR, which  is  created  on  each  host  and  properly
              cleaned up.

       To gain control over the slave tasks of a parallel application, a sophisticated PE interface is required,
       which works closely together with Grid Engine facilities, typically interpreting the Grid Engine hostfile
       and  starting  remote  tasks  with <u><a href="../man1/qrsh.1.html">qrsh</a></u>(1) and its <b>-inherit</b> option.  See, for instance, the <b>$SGE_ROOT/mpi</b>
       directory and the howto pages ⟨<a href="http://arc.liv.ac.uk/SGE/howto/">http://arc.liv.ac.uk/SGE/howto/</a>
       #Tight%20Integration%20of%20Parallel%20Libraries⟩.

       Please set the <b>control_slaves</b> parameter to false for all other PE interfaces.

   <b>job_is_first_task</b>
       The <b>job_is_first_task</b> parameter can be set to TRUE or FALSE. A value of  TRUE  indicates  that  the  Grid
       Engine  job script already contains one of the tasks of the parallel application (and the number of slots
       reserved for the job is the number of slots requested with the -pe switch).  FALSE indicates that the job
       script (and its child processes) is not part of the parallel program, just being used  to  kick  off  the
       tasks that do the work; then the number of slots reserved for the job in the master queue is increased by
       1, as indicated by <u>qstat</u>/<u>qhost</u>.

       This  should  be  TRUE for the common modern MPI implementations with tight integration.  Consider if the
       allocation rule is <b>$fill_up</b>, and a job is allocated only a single slot on the master host;  then  one  of
       the  MPI  processes  actually runs in that slot, and should be accounted as such, so the job is the first
       task.

       If wallclock accounting is used (<b>execd_params</b> <b>ACCT_RESERVED_USAGE</b>
        and/or <b>SHARETREE_RESERVED_USAGE</b> Is <b>TRUE</b>) and <b>control_slaves</b>  is  set  to  FALSE,  the  <b>job_is_first_task</b>
       parameter  influences  the  accounting  for  the  job:  A value of TRUE means that accounting for CPU and
       requested memory gets multiplied by the number of slots requested with the -pe switch.  FALSE  means  the
       accounting information gets multiplied by number of slots + 1.  Otherwise, the only significant effect of
       the parameter is on the display of the job.

   <b>urgency_slots</b>
       For  pending  jobs  with  a slot range PE request with different minimum and maximum, the number of slots
       they will actually use is not determined. This setting specifies the method to be used by Grid Engine  to
       assess the number of slots such jobs might finally get.

       The  assumed  slot  allocation  has  a  meaning  when  determining  the  resource-request-based  priority
       contribution for numeric resources as described in <u><a href="../man5/sge_priority.5.html">sge_priority</a></u>(5) and is displayed when <u><a href="../man1/qstat.1.html">qstat</a></u>(1) is  run
       without <b>-g</b> <b>t</b> option.

       The following methods are supported:

       <u>int</u>    The specified integer number is directly used as prospective slot amount.

       <b>min</b>    The slot range minimum is used as prospective slot amount. If no lower bound is specified with the
              range, 1 is assumed.

       <b>max</b>    The  slot  range  maximum is used as prospective slot amount.  If no upper bound is specified with
              the range, the absolute maximum possible due to the PE's <b>slots</b> setting is assumed.

       <b>avg</b>    The average of all numbers occurring within the job's PE range request is assumed.

   <b>accounting_summary</b>
       This parameter is only checked if <b>control_slaves</b> (see above) is set to TRUE and thus Grid Engine  is  the
       creator of the slave tasks of a parallel application via <u><a href="../man8/sge_execd.8.html">sge_execd</a></u>(8) and <u><a href="../man8/sge_shepherd.8.html">sge_shepherd</a></u>(8).  In this case,
       accounting information is available for every single slave task started by Grid Engine.

       The  <b>accounting_summary</b>  parameter  can  be  set  to TRUE or FALSE. A value of TRUE indicates that only a
       single accounting record is written to the <u><a href="../man5/accounting.5.html">accounting</a></u>(5) file, containing the accounting summary  of  the
       whole job, including all slave tasks, while a value of FALSE indicates an individual <u><a href="../man5/accounting.5.html">accounting</a></u>(5) record
       is written for every slave task, as well as for the master task.

       <b>Note:</b>  When  running  tightly  integrated  jobs with <u>SHARETREE_RESERVED_USAGE</u> set, and <u>accounting_summary</u>
       enabled in the parallel environment, reserved usage will only be reported  by  the  master  task  of  the
       parallel  job.   No  per-parallel  task  usage  records  will  be  sent  from execd to qmaster, which can
       significantly reduce load on the qmaster when running large, tightly integrated parallel jobs.   However,
       this removes the only post-hoc information about which hosts a job used.

   <b>qsort_args</b> <u><b>library</b></u> <u><b>qsort-function</b></u> [<u><b>arg1</b></u> ...]
       Specifies  a  method for specifying the queues/hosts and order that should be used to schedule a parallel
       job.  For details, and the API, consult the header file <u>$SGE_ROOT/include/sge_pqs_api.h</u>.  <u>library</u> is  the
       path  to  the  qsort dynamic library, <u>qsort-function</u> is the name of the qsort function implemented by the
       library, and the <u>arg</u>s are arguments passed to <u>qsort</u>.  Substitutions from the hard requested resource list
       for the job are made for any strings of the form $<u>resource</u>, where  <u>resource</u>  is  the  full  name  of  the
       resource  as  defined  in the <u><a href="../man5/complex.5.html">complex</a></u>(5) list.  If <u>resource</u> is not requested in the job, a null string is
       substituted.

</pre><h4><b>RESTRICTIONS</b></h4><pre>
       <b>Note</b> that the functionality of the start and stop procedures  remains  the  full  responsibility  of  the
       administrator  configuring  the  parallel  environment.   Grid  Engine  will  invoke these procedures and
       evaluate their exit status.  A non-zero exit status will put the queue into an error state.  If the start
       procedure has a non-zero exit status, the job will be re-queued.

</pre><h4><b>SECURITY</b></h4><pre>
       If <b>start_proc_args</b>, or <b>stop_proc_args</b> is specified with a <u>user</u><b>@</b> prefix, the same considerations apply  as
       for the prolog and epilog, as described in the SECURITY section of <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5).

</pre><h4><b>SEE</b> <b>ALSO</b></h4><pre>
       <u><a href="../man1/sge_intro.1.html">sge_intro</a></u>(1),  <u>sge</u><b>__</b><u><a href="../man1/types.1.html">types</a></u>(1),  <u><a href="../man1/qconf.1.html">qconf</a></u>(1), <u><a href="../man1/qdel.1.html">qdel</a></u>(1), <u><a href="../man1/qmod.1.html">qmod</a></u>(1), <u><a href="../man1/qrsh.1.html">qrsh</a></u>(1), <u><a href="../man1/qsub.1.html">qsub</a></u>(1), <u><a href="../man5/access_list.5.html">access_list</a></u>(5), <u><a href="../man5/sge_conf.5.html">sge_conf</a></u>(5),
       <u><a href="../man8/sge_qmaster.8.html">sge_qmaster</a></u>(8), <u><a href="../man8/sge_shepherd.8.html">sge_shepherd</a></u>(8).

</pre><h4><b>FILES</b></h4><pre>
       <u>$SGE_ROOT/include/sge_pqs_api.h</u>

</pre><h4><b>COPYRIGHT</b></h4><pre>
       See <u><a href="../man1/sge_intro.1.html">sge_intro</a></u>(1) for a full statement of rights and permissions.

SGE 8.1.3pre                                       2012-09-11                                          <u><a href="../man5/SGE_PE.5.html">SGE_PE</a></u>(5)
</pre>
 </div>
</div></section>
</div>
</body>
</html>