{
  "category": "texttospeech",
  "categoryDisplay": "Text-to-Speech",
  "description": "Tools for converting text-to-speech and vice-versa",
  "totalRepositories": 4,
  "repositories": {
    "daisys-ai--daisys-mcp": {
      "owner": "daisys-ai",
      "name": "daisys-mcp",
      "url": "https://github.com/daisys-ai/daisys-mcp",
      "imageUrl": "",
      "description": "Generate high-quality text-to-speech and text-to-voice outputs using the [DAISYS](https://www.daisys.ai/) platform and make it able to play and store audio generated.",
      "stars": 10,
      "forks": 5,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-12T06:30:39Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/daisys-ai-daisys-mcp-badge.png)](https://mseep.ai/app/daisys-ai-daisys-mcp)\n\n# Daisys MCP server\n[![smithery badge](https://smithery.ai/badge/@daisys-ai/daisys-mcp)](https://smithery.ai/server/@daisys-ai/daisys-mcp)\n\nDaisys-mcp is a beta version and doesn't have a stable release yet. But you can try it out by doing the following:\n\n1. Get an account on [Daisys](https://www.daisys.ai/) and create an username and password.\n\n\nIf you run on mac os run the following command:\n```bash\nbrew install portaudio\n```\n\nIf you run on linux run the following command:\n```bash\nsudo apt install portaudio19-dev libjack-dev\n```\n\n2. Add the following configuration to the mcp config file in your MCP client ([Claude Desktop](https://claude.ai/download), [Cursor](https://www.cursor.com/), [mcp-cli](https://github.com/chrishayuk/mcp-cli), [mcp-vscode](https://code.visualstudio.com/docs/copilot/chat/mcp-servers), etc.):\n```json\n{\n  \"mcpServers\": {\n    \"daisys-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"daisys-mcp\"],\n      \"env\": {\n        \"DAISYS_EMAIL\": \"{Your Daisys Email}\",\n        \"DAISYS_PASSWORD\": \"{Your Daisys Password}\",\n        \"DAISYS_BASE_STORAGE_PATH\": \"{Path where you want to store your audio files}\"\n      }\n    }\n  }\n}\n```\n\n## To build from source:\n\n1. clone the repository: `git clone https://github.com/daisys-ai/daisys-mcp.git`\n\n2. cd into the repository: `cd daisys-mcp`\n\n3. Install `uv` (Python package manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh` or see the `uv` [repo](https://github.com/astral-sh/uv) for additional install methods.\n\n4. Create a virtual environment and install dependencies [using uv](https://github.com/astral-sh/uv):\n\n```bash\nuv venv\n# source .venv/Scripts/activate (Windows)\nsource .venv/bin/activate (mac and linux)\nuv pip install -e .\n```\n\n5. Add the following to your config file in your MCP client ([Claude Desktop](https://claude.ai/download), [Cursor](https://www.cursor.com/), [mcp-cli](https://github.com/chrishayuk/mcp-cli), [mcp-vscode](https://code.visualstudio.com/docs/copilot/chat/mcp-servers), etc.):\n```json\n{\n    \"mcpServers\": {\n        \"daisys-mcp\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"{installation_path}/daisys-mcp\",\n                \"run\",\n                \"-m\",\n                \"daisys_mcp.server\"\n            ],\n            \"env\": {\n                \"DAISYS_EMAIL\": \"{Your Daisys Email}\",\n                \"DAISYS_PASSWORD\": \"{Your Daisys Password}\",\n                \"DAISYS_BASE_STORAGE_PATH\": \"{Path where you want to store your audio files}\"\n            }\n        }\n    }\n}\n```\n\n## Common Issues\n\nIf you get any issues with portaudio on linux, you can try installing it manually:\n```bash\nsudo apt-get update\nsudo apt-get install -y portaudio19-dev\n```\n\n## Contributing\n\nIf you want to contribute or run from source:\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/daisys-ai/daisys-mcp.git\ncd daisys_mcp\n```\n\n2. Create a virtual environment and install dependencies [using uv](https://github.com/astral-sh/uv):\n\n```bash\nuv venv\nsource .venv/bin/activate\nuv pip install -e .\nuv pip install -e \".[dev]\"\n```\n\n3. Copy `.env.example` to `.env` and add your DAISYS username and password:\n\n```bash\ncp .env.example .env\n# Edit .env and add your DAISYS username and password\n```\n\n4. Test the server by running the tests:\n\n```bash\nuv run pytest\n```\n\nyou can also run a full integration test with:\n\n```bash\nuv run pytest -m 'requires_credentials' # ⚠️ Running full integration tests does costs tokens on the Daisys platform \n```\n\n5. Debug and test locally with MCP Inspector: `uv run mcp dev daisys_mcp/server.py`\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "audio",
        "texttospeech",
        "voice",
        "voice outputs",
        "text voice",
        "text speech"
      ],
      "category": "texttospeech"
    },
    "mbailey--voice-mcp": {
      "owner": "mbailey",
      "name": "voice-mcp",
      "url": "https://github.com/mbailey/voice-mcp",
      "imageUrl": "",
      "description": "Complete voice interaction server supporting speech-to-text, text-to-speech, and real-time voice conversations through local microphone, OpenAI-compatible APIs, and LiveKit integration",
      "stars": 328,
      "forks": 42,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-04T12:39:17Z",
      "readme_content": "# VoiceMode\n\n\n> **Install via:** `uv tool install voice-mode` | [getvoicemode.com](https://getvoicemode.com)\n\n[![PyPI Downloads](https://static.pepy.tech/badge/voice-mode)](https://pepy.tech/project/voice-mode)\n[![PyPI Downloads](https://static.pepy.tech/badge/voice-mode/month)](https://pepy.tech/project/voice-mode)\n[![PyPI Downloads](https://static.pepy.tech/badge/voice-mode/week)](https://pepy.tech/project/voice-mode)\n\nNatural voice conversations for AI assistants. VoiceMode brings human-like voice interactions to Claude Code, AI code editors through the Model Context Protocol (MCP).\n\n## 🖥️ Compatibility\n\n**Runs on:** Linux • macOS • Windows (WSL) • NixOS | **Python:** 3.10+\n\n## ✨ Features\n\n- **🎙️ Natural Voice Conversations** with Claude Code - ask questions and hear responses\n- **🗣️ Supports local Voice Models** - works with any OpenAI API compatible STT/TTS services\n- **⚡ Real-time** - low-latency voice interactions with automatic transport selection\n- **🔧 MCP Integration** - seamless with Claude Code (and other MCP clients)\n- **🎯 Silence detection** - automatically stops recording when you stop speaking (no more waiting!)\n- **🔄 Multiple transports** - local microphone or LiveKit room-based communication  \n\n## 🎯 Simple Requirements\n\n**All you need to get started:**\n\n1. **🎤 Computer with microphone and speakers**\n2. **🔑 OpenAI API Key** (Recommended, if only as a backup for local services)\n\n## Quick Start\n\n### Automatic Installation (Recommended)\n\nInstall Claude Code with VoiceMode configured and ready to run on Linux, macOS, and Windows WSL:\n\n```bash\n# Download and run the installer\ncurl -O https://getvoicemode.com/install.sh && bash install.sh\n\n# While local voice services can be installed automatically, we recommend\n# providing an OpenAI API key as a fallback in case local services are unavailable\nexport OPENAI_API_KEY=your-openai-key  # Optional but recommended\n\n# Start a voice conversation\nclaude converse\n```\n\nThis installer will:\n- Install all system dependencies (Node.js, audio libraries, etc.)\n- Install Claude Code if not already installed\n- Configure VoiceMode as an MCP server\n- Set up your system for voice conversations\n\n### Manual Installation\n\nFor manual setup steps, see the [Getting Started Guide](docs/tutorials/getting-started.md).\n\n## 🎬 Demo\n\nWatch VoiceMode in action with Claude Code:\n\n[![VoiceMode Demo](https://img.youtube.com/vi/cYdwOD_-dQc/maxresdefault.jpg)](https://www.youtube.com/watch?v=cYdwOD_-dQc)\n\nThe `converse` function makes voice interactions natural - it automatically waits for your response by default, creating a real conversation flow.\n\n## Installation\n\n### Prerequisites\n- Python >= 3.10\n- [Astral UV](https://github.com/astral-sh/uv) - Package manager (install with `curl -LsSf https://astral.sh/uv/install.sh | sh`)\n- OpenAI API Key (or compatible service)\n\n#### System Dependencies\n\n<details>\n<summary><strong>Ubuntu/Debian</strong></summary>\n\n```bash\nsudo apt update\nsudo apt install -y ffmpeg libasound2-dev libasound2-plugins libportaudio2 portaudio19-dev pulseaudio pulseaudio-utils python3-dev \n```\n\n**Note for WSL2 users**: WSL2 requires additional audio packages (pulseaudio, libasound2-plugins) for microphone access.\n</details>\n\n<details>\n<summary><strong>Fedora/RHEL</strong></summary>\n\n```bash\nsudo dnf install alsa-lib-devel ffmpeg portaudio-devel python3-devel\n```\n</details>\n\n<details>\n<summary><strong>macOS</strong></summary>\n\n```bash\n# Install Homebrew if not already installed\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install dependencies\nbrew install ffmpeg node portaudio\n```\n</details>\n\n<details>\n<summary><strong>Windows (WSL)</strong></summary>\n\nFollow the Ubuntu/Debian instructions above within WSL.\n</details>\n\n<details>\n<summary><strong>NixOS</strong></summary>\n\nVoiceMode includes a flake.nix with all required dependencies. You can either:\n\n1. **Use the development shell** (temporary):\n```bash\nnix develop github:mbailey/voicemode\n```\n\n2. **Install system-wide** (see Installation section below)\n</details>\n\n### Quick Install\n\n```bash\n# Using Claude Code (recommended)\nclaude mcp add --scope user voicemode uvx --refresh voice-mode\n```\n\n### Configuration for AI Coding Assistants\n\n> 📖 **Looking for detailed setup instructions?** Check our comprehensive [Getting Started Guide](docs/tutorials/getting-started.md) for step-by-step instructions!\n\nBelow are quick configuration snippets. For full installation and setup instructions, see the integration guides above.\n\n<details>\n<summary><strong>Claude Code (CLI)</strong></summary>\n\n```bash\nclaude mcp add --scope user voicemode -- uvx --refresh voice-mode\n```\n\nOr with environment variables:\n```bash\nclaude mcp add --scope user --env OPENAI_API_KEY=your-openai-key voicemode -- uvx --refresh voice-mode\n```\n</details>\n\n### Alternative Installation Options\n\n<details>\n<summary><strong>From source</strong></summary>\n\n```bash\ngit clone https://github.com/mbailey/voicemode.git\ncd voicemode\nuv tool install -e .\n```\n</details>\n\n<details>\n<summary><strong>NixOS Installation Options</strong></summary>\n\n**1. Install with nix profile (user-wide):**\n```bash\nnix profile install github:mbailey/voicemode\n```\n\n**2. Add to NixOS configuration (system-wide):**\n```nix\n# In /etc/nixos/configuration.nix\nenvironment.systemPackages = [\n  (builtins.getFlake \"github:mbailey/voicemode\").packages.${pkgs.system}.default\n];\n```\n\n**3. Add to home-manager:**\n```nix\n# In home-manager configuration\nhome.packages = [\n  (builtins.getFlake \"github:mbailey/voicemode\").packages.${pkgs.system}.default\n];\n```\n\n**4. Run without installing:**\n```bash\nnix run github:mbailey/voicemode\n```\n</details>\n\n## Configuration\n\n- 📖 **[Getting Started](docs/tutorials/getting-started.md)** - Step-by-step setup guide\n- 🔧 **[Configuration Reference](docs/guides/configuration.md)** - All environment variables\n\n### Quick Setup\n\nThe only required configuration is your OpenAI API key:\n\n```bash\nexport OPENAI_API_KEY=\"your-key\"\n```\n\n## Local STT/TTS Services\n\nFor privacy-focused or offline usage, VoiceMode supports local speech services:\n\n- **[Whisper.cpp](docs/guides/whisper-setup.md)** - Local speech-to-text with OpenAI-compatible API\n- **[Kokoro](docs/guides/kokoro-setup.md)** - Local text-to-speech with multiple voice options\n\nThese services provide the same API interface as OpenAI, allowing seamless switching between cloud and local processing.\n\n## Troubleshooting\n\n### Common Issues\n\n- **No microphone access**: Check system permissions for terminal/application\n  - **WSL2 Users**: Additional audio packages (pulseaudio, libasound2-plugins) required for microphone access\n- **UV not found**: Install with `curl -LsSf https://astral.sh/uv/install.sh | sh`\n- **OpenAI API error**: Verify your `OPENAI_API_KEY` is set correctly\n- **No audio output**: Check system audio settings and available devices\n\n### Audio Saving\n\nTo save all audio files (both TTS output and STT input):\n\n```bash\nexport VOICEMODE_SAVE_AUDIO=true\n```\n\nAudio files are saved to: `~/.voicemode/audio/YYYY/MM/` with timestamps in the filename.\n\n## Documentation\n\n📚 **[Read the full documentation at voice-mode.readthedocs.io](https://voice-mode.readthedocs.io)**\n\n### Getting Started\n\n- **[Getting Started](docs/tutorials/getting-started.md)** - Step-by-step setup for all supported tools\n- **[Configuration Guide](docs/guides/configuration.md)** - Complete environment variable reference\n\n### Development\n\n- **[Development Setup](docs/tutorials/development-setup.md)** - Local development guide\n\n### Service Guides\n\n- **[Whisper.cpp Setup](docs/guides/whisper-setup.md)** - Local speech-to-text configuration\n- **[Kokoro Setup](docs/guides/kokoro-setup.md)** - Local text-to-speech configuration\n- **[LiveKit Integration](docs/guides/livekit-setup.md)** - Real-time voice communication\n\n## Links\n\n- **Website**: [getvoicemode.com](https://getvoicemode.com)\n- **Documentation**: [voice-mode.readthedocs.io](https://voice-mode.readthedocs.io)\n- **GitHub**: [github.com/mbailey/voicemode](https://github.com/mbailey/voicemode)\n- **PyPI**: [pypi.org/project/voice-mode](https://pypi.org/project/voice-mode/)\n\n### Community\n\n- **Twitter/X**: [@getvoicemode](https://twitter.com/getvoicemode)\n- **YouTube**: [@getvoicemode](https://youtube.com/@getvoicemode)\n\n## See Also\n\n- 🚀 [Getting Started](docs/tutorials/getting-started.md) - Setup instructions for all supported tools\n- 🔧 [Configuration Reference](docs/guides/configuration.md) - Environment variables and options\n- 🎤 [Local Services Setup](docs/guides/kokoro-setup.md) - Run TTS/STT locally for privacy\n\n## License\n\nMIT - A [Failmode](https://failmode.com) Project\n\n---\nmcp-name: com.failmode/voicemode\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "voice",
        "texttospeech",
        "livekit",
        "texttospeech tools",
        "text speech",
        "voice mcp"
      ],
      "category": "texttospeech"
    },
    "mberg--kokoro-tts-mcp": {
      "owner": "mberg",
      "name": "kokoro-tts-mcp",
      "url": "https://github.com/mberg/kokoro-tts-mcp",
      "imageUrl": "",
      "description": "MCP Server that uses the open weight Kokoro TTS models to convert text-to-speech. Can convert text to MP3 on a local driver or auto-upload to an S3 bucket.",
      "stars": 59,
      "forks": 14,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T06:37:41Z",
      "readme_content": "<a href=\"https://glama.ai/mcp/servers/@mberg/kokoro-tts-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mberg/kokoro-tts-mcp/badge\" alt=\"Kokoro Text to Speech Server MCP server\" />\n</a>\n\n## Kokoro Text to Speech (TTS) MCP Server\n\nKokoro Text to Speech MCP server that generates .mp3 files with option to upload to S3.\n\nUses: https://huggingface.co/spaces/hexgrad/Kokoro-TTS\n\n## Configuration\n\n* Clone to a local repo.\n* Download the [Kokoro Onnx Weights](https://github.com/thewh1teagle/kokoro-onnx) for [kokoro-v1.0.onnx](https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/kokoro-v1.0.onnx) and [voices-v1.0.bin](https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/voices-v1.0.bin) and store in the same repo.\n\nAdd the following to your MCP configs. Update with your own values.\n\n```\n  \"kokoro-tts-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/toyourlocal/kokoro-tts-mcp\",\n        \"run\",\n        \"mcp-tts.py\"\n      ],\n      \"env\": {\n        \"TTS_VOICE\": \"af_heart\",\n        \"TTS_SPEED\": \"1.0\",\n        \"TTS_LANGUAGE\": \"en-us\",\n        \"AWS_ACCESS_KEY_ID\": \"\",\n        \"AWS_SECRET_ACCESS_KEY\": \"\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"AWS_S3_FOLDER\": \"mp3\",\n        \"S3_ENABLED\": \"true\",\n        \"MP3_FOLDER\": \"/path/to/mp3\"\n      } \n    }\n```\n\n### Install ffmmeg\n\nThis is needed to convert .wav to .mp3 files\n\nFor mac:\n\n``` \nbrew install ffmpeg\n```\n\nTo run locally add these to your .env file.  See env.example and copy to .env and modify with your own values.\n\n### Supported Environment Variables\n\n- `AWS_ACCESS_KEY_ID`: Your AWS access key ID\n- `AWS_SECRET_ACCESS_KEY`: Your AWS secret access key\n- `AWS_S3_BUCKET_NAME`: S3 bucket name\n- `AWS_S3_REGION`: S3 region (e.g., us-east-1)\n- `AWS_S3_FOLDER`: Folder path within the S3 bucket\n- `AWS_S3_ENDPOINT_URL`: Optional custom endpoint URL for S3-compatible storage\n- `MCP_HOST`: Host to bind the server to (default: 0.0.0.0)\n- `MCP_PORT`: Port to listen on (default: 9876)\n- `MCP_CLIENT_HOST`: Hostname for client connections to the server (default: localhost)\n- `DEBUG`: Enable debug mode (set to \"true\" or \"1\")\n- `S3_ENABLED`: Enable S3 uploads (set to \"true\" or \"1\")\n- `MP3_FOLDER`: Path to store MP3 files (default is 'mp3' folder in script directory)\n- `MP3_RETENTION_DAYS`: Number of days to keep MP3 files before automatic deletion\n- `DELETE_LOCAL_AFTER_S3_UPLOAD`: Whether to delete local MP3 files after successful S3 upload (set to \"true\" or \"1\")\n- `TTS_VOICE`: Default voice for the TTS client (default: af_heart)\n- `TTS_SPEED`: Default speed for the TTS client (default: 1.0)\n- `TTS_LANGUAGE`: Default language for the TTS client (default: en-us)\n\n## Running the Server Locally\n\nPreferred method use UV \n```\nuv run mcp-tts.py\n```\n\n\n## Using the TTS Client\n\nThe `mcp_client.py` script allows you to send TTS requests to the server. It can be used as follows:\n\n### Connection Settings\n\nWhen running the server and client on the same machine:\n- Server should bind to `0.0.0.0` (all interfaces) or `127.0.0.1` (localhost only)\n- Client should connect to `localhost` or `127.0.0.1`\n\n\n### Basic Usage\n\n```bash\npython mcp_client.py --text \"Hello, world!\"\n```\n\n### Reading Text from a File\n\n```bash\npython mcp_client.py --file my_text.txt\n```\n\n### Customizing Voice and Speed\n\n```bash\npython mcp_client.py --text \"Hello, world!\" --voice \"en_female\" --speed 1.2\n```\n\n### Disabling S3 Upload\n\n```bash\npython mcp_client.py --text \"Hello, world!\" --no-s3\n```\n\n### Command-line Options\n\n```bash\npython mcp_client.py --help\n```\n\n## MP3 File Management\n\nThe TTS server generates MP3 files that are stored locally and optionally uploaded to S3. You can configure how these files are managed:\n\n### Local Storage\n\n- Set `MP3_FOLDER` in your `.env` file to specify where MP3 files are stored\n- Files are kept in this folder unless automatically deleted\n\n### Automatic Cleanup\n\n- Set `MP3_RETENTION_DAYS=30` (or any number) to automatically delete files older than that number of days\n- Set `DELETE_LOCAL_AFTER_S3_UPLOAD=true` to delete local files immediately after successful S3 upload\n\n### S3 Integration\n\n- Enable/disable S3 uploads with `S3_ENABLED=true` or `DISABLE_S3=true`\n- Configure AWS credentials and bucket settings in the `.env` file\n- S3 uploads can be disabled per-request using the client's `--no-s3` option\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "texttospeech",
        "mp3",
        "text",
        "speech convert",
        "texttospeech tools",
        "text speech"
      ],
      "category": "texttospeech"
    },
    "transcribe-app--mcp-transcribe": {
      "owner": "transcribe-app",
      "name": "mcp-transcribe",
      "url": "https://github.com/transcribe-app/mcp-transcribe",
      "imageUrl": "",
      "description": "This service provides fast and reliable transcriptions for audio/video files and voice memos. It allows LLMs to interact with the text content of audio/video file.",
      "stars": 2,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-18T01:58:41Z",
      "readme_content": "<h3 align=\"center\">Transcribe MCP</h3>\n\n<p align=\"center\">\n  Automate your transcriptions with AI.\n  <br />\n  <a href=\"https://transcribe.com\"><strong>Website</strong></a> \n</p>\n\n# About\n\nTranscribe MCP instantly connects your account to assistants like Claude, Windsurf, Cursor, and more so they can automate tasks on your behalf. The Local Server can add local files for transcription and return result to your Assistant in seconds.\n\n# Features\n- ⚡ Fast, lightweight and LLM-friendly. No special ASR models needed, no setup and fighting python packages, results in seconds.\n- 🏆 High-quality transcriptions. Works with noisy audio, over 100 languages supported, featuring word-level timestamps and speaker separation.\n- 🔋 Wide variety of formats out-of-the-box and Cloud storage for your audio notes and records.\n- 👥 Collaboration support via Transcribe.com teams feature\n\n## 🚀 Local installation: Claude Desktop\n\n🔹 Get your private MCP integration URL\n- Sign in to the Transcribe [online editor](https://transcribe.com/app)\n- Copy your private URL from Automation popup\n\n🔹 Download pre-built Desktop Extension (DXT): [Download DXT](https://transcribe.com/mcp-integration#jumpto=mcp_download_dxt)\n\n📦 The DXT includes:\n\n- ✅ One-click installation in Claude Desktop\n- ✅ Secure environment variable configuration\n- ✅ Automatic dependency management\n- ✅ Built-in error handling and debugging\n- ✅ The DXT file is automatically updated for the latest features and fixes\n\n### Option 1: Double-Click Installation (Recommended)\n- Double-click the .dxt file\n- Claude Desktop will automatically install the extension\n- Follow the configuration prompts\n\n### Option 2: Manual Installation\n- Open Claude Desktop\n- Go to Settings → Extensions\n- Click \"Install Extension\" and select the .dxt file\n\n### Configuration\nDuring installation, you'll be prompted to configure MCP integration URL. Paste your private URL.\n\n## 🚀 Local installation: Other assistants\n\n🔹 Get your private MCP integration URL\n- Sign in to the Transcribe [online editor](https://transcribe.com/app)\n- Copy your private URL from Automation popup\n\n🔹 Before installing the server, ensure you have Node.js and Git\n- Download from: https://nodejs.org/\n- Verify Node with: node --version\n- Verify NPX with: npx --version\n\n🔹 Add Local Server via your assistant settings and use this snippet for server setup:\n\n```\n{\n  \"key\": \"transcribe-local\",\n  \"command\": \"npx\",\n  \"args\": [\n    \"args\": [\"-y\", \"github:transcribe-app/mcp-transcribe\"],\n  ],\n  \"env\": {\n    \"MCP_INTEGRATION_URL\": \"<your-MCP-integration-URL>\"\n  }\n}\n```\n\n### Configuration\nReplace \\<your-MCP-integration-URL\\> with your private URL.\n\n---\n\n## ⚡ Available Tools\n\nList of tools is expanded with each new version.\n\n1\\. `convert-to-text`: converts audio to text and returns the text immediately.\n- Note: This tool use your time credits.\n- Note: Remote server expect public-accessible URL, Local Server can use both URL and a path to local file in your file system.\n\n2\\. `get-balance`: returns balance of your account.\n\n3\\. `read-transcriptions`: returns content of ready transcriptions with optional filtering/search.\n\n4\\. `update-transcription`: renames or deletes transcriptions in your account at Transcribe.com\n\n\n## 💡 Security Notes\n\n- **Private URL**: Store your private URL securely, do not share it with others\n\n## ⚠️ Troubleshooting\n\n### \"MCP_INTEGRATION_URL environment variable is required\"\n- Sign in to the Transcribe [online editor](https://transcribe.com/app)\n- Copy your private URL from Automation popup\n- Add it as server's \"MCP_INTEGRATION_URL\" environment variable in your AI assistant settings\n\n### Extension Won't Install\n- Ensure you have the latest Claude Desktop version\n- Check that `node` is installed and in your PATH",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "texttospeech",
        "transcribe",
        "transcriptions",
        "texttospeech tools",
        "mcp transcribe",
        "transcribe app"
      ],
      "category": "texttospeech"
    }
  }
}
