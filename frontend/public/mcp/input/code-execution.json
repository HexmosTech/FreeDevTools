{
  "category": "code-execution",
  "categoryDisplay": "Code Execution",
  "description": "Code execution servers. Allow LLMs to execute code in a secure environment, e.g. for coding agents.",
  "totalRepositories": 91,
  "repositories": {
    "0xjcf--MCP_CodeAnalysis": {
      "owner": "0xjcf",
      "name": "MCP_CodeAnalysis",
      "url": "https://github.com/0xjcf/MCP_CodeAnalysis",
      "imageUrl": "https://github.com/0xjcf.png",
      "description": "The Code Analysis MCP server helps developers analyze and improve their code by using advanced AI tools. It processes codebases to identify metrics, dependencies, and offers real-time insights for better coding practices.",
      "stars": 4,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-10T18:13:28Z",
      "readme_content": "# MCP Code Analysis\n\nA powerful codebase analysis toolkit that leverages the Model Context Protocol (MCP) for AI-assisted code understanding and transformation.\n\n## Features\n\n- **Code Analysis**: Parse and analyze codebases with abstract syntax trees\n- **Context Generation**: Create rich contextual information for AI models\n- **Tool Integration**: Built on the MCP SDK for seamless AI tool integration\n- **Extensible Architecture**: Plugin-based system for custom analyzers\n\n## Requirements\n\n- Node.js 18+\n- NPM 9+\n- Redis (optional, only required for production environments)\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/mcp-codeanalysis.git\ncd mcp-codeanalysis\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Redis Configuration (Optional)\n\nRedis is used for session storage in production environments. For development and testing, the system will automatically fall back to an in-memory session store if Redis is not available.\n\n> **Note**: There is a known issue with Redis connectivity where operations may fail even when Redis is running. See the \"Tech Debt\" section in `plan.md` for details. For now, you can use the `./use-memory-session.sh` script to run the server with the memory session store. For more information, see [Redis Troubleshooting Guide](./docs/redis-troubleshooting.md).\n\nTo install Redis:\n\n```bash\n# Ubuntu/Debian\nsudo apt-get install redis-server\n\n# macOS\nbrew install redis\n\n# Windows (using WSL is recommended)\n# For native Windows, download from https://redis.io/download\n```\n\nBy default, the application tries to connect to Redis at `redis://localhost:6379`. You can configure the Redis connection using environment variables:\n\n```bash\n# Set custom Redis URL\nexport REDIS_URL=redis://custom-host:6379\n\n# Force memory session store even if Redis is available\nexport FORCE_MEMORY_SESSION=true\n```\n\n## Development\n\n```bash\n# Run in development mode\nnpm run dev\n\n# Run tests\nnpm test\n\n# Run linting\nnpm run lint\n```\n\n## Usage\n\n```bash\n# Start the MCP server\nnpm start\n\n# Run CLI tool\nnode ./tools/mcp-stdio-client.js --task \"Analyze dependencies\" --files \"src/*.ts\"\n```\n\n## Documentation\n\n- [Session Store Architecture](./docs/session-store.md)\n- [Redis Integration](./docs/redis-integration.md)\n- [MCP Protocol](./docs/mcp-protocol.md)\n\n## License\n\nMIT\n\n# CodeAnalysis MCP Server\n\nA comprehensive Model Context Protocol (MCP) server for advanced code analysis, providing tools and insights through an extensible architecture.\n\n## 🚀 Features\n\n- **Basic Code Analysis**: Syntax and structure analysis\n- **Code Metrics**: Complexity, line counts, and code quality metrics\n- **Dependency Analysis**: Package and import relationship visualization\n- **Knowledge Graph**: Code relationships visualization and querying\n- **Memory System**: Store and retrieve insights about codebases\n- **Visualizations**: Generate diagrams in multiple formats (Mermaid, DOT, ASCII)\n- **Socio-Technical Analysis**: Understand team and code relationships\n- **Multi-Repository Analysis**: Cross-repository relationship analysis\n- **Evolution Planning**: Code improvement recommendations\n- **Live Watching**: Monitor code changes in real-time\n- **IDE Integration**: Tools for editor integration\n- **Developer Tools**: Enhanced AI-assisted development workflow support\n\n## 📋 Prerequisites\n\n- Node.js 18+\n- npm or yarn\n- Redis (optional for development, recommended for production)\n\n## 🛠️ Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-username/codeanalysis-mcp.git\ncd codeanalysis-mcp\n\n# Install dependencies\npnpm install\n\n# Build the project\npnpm build\n```\n\n## 🖥️ Usage\n\nThe CodeAnalysis MCP server can be used in two ways:\n\n### 1. As an MCP Server\n\n```bash\n# Start the MCP server\npnpm start\n```\n\nThis starts the MCP server that can be connected to by any MCP client like Claude Desktop, Cursor, or others.\n\n### 2. Using the CLI\n\nThe project includes a comprehensive CLI for direct interaction:\n\n```bash\n# Get help\npnpm run cli --help\n\n# Analyze a repository or directory\npnpm run cli analyze repo ./src\n\n# Check code quality\npnpm run cli quality analyze ./src\n```\n\n### 3. Using Developer Tools for AI-Assisted Development\n\nThe project includes special tools designed to enhance AI-assisted development:\n\n```bash\n# Generate code context for AI assistants\nnode tools/ai-dev-helper.js --task=\"Implement new feature\" --search=\"related functionality\"\n\n# Run example client\nnode examples/dev-tools-client.js\n```\n\nSee the [Developer Tools Guide](docs/dev-tools-guide.md) for detailed information.\n\n## 📊 Example Commands\n\n### Basic Analysis\n\n```bash\n# Analyze a local directory\npnpm run cli analyze repo ./src\n\n# Analyze a specific file\npnpm run cli analyze file ./src/server.ts\n```\n\n### Code Metrics\n\n```bash\n# Get code metrics with function details\npnpm run cli metrics analyze ./src --functions\n\n# Save metrics to a file\npnpm run cli metrics analyze ./src -o metrics-report.json\n```\n\n### Dependency Analysis\n\n```bash\n# Analyze dependencies in Mermaid format\npnpm run cli dependencies analyze ./src -f mermaid -o deps.mmd\n\n# Visualize dependencies\npnpm run cli visualize dependencies -p ./src --format mermaid\n```\n\n### Code Quality\n\n```bash\n# Run quality analysis\npnpm run cli quality analyze ./src\n\n# Generate HTML report\npnpm run cli quality analyze ./src --html -o quality-report.html\n```\n\n### Knowledge Graph\n\n```bash\n# Build knowledge graph\npnpm run cli knowledge build ./src\n\n# Query the knowledge graph\npnpm run cli knowledge query ./src \"type:function AND complexity>5\"\n\n# Export as diagram\npnpm run cli knowledge export ./src -f mermaid\n```\n\n### Insights & Memory\n\n```bash\n# Store an insight\npnpm run cli insights store -r ./src -t code-pattern -c \"Refactoring opportunity\"\n\n# Retrieve insights\npnpm run cli insights retrieve -r ./src\n```\n\n### Developer Tools\n\n```bash\n# Prepare context for AI interactions\nnode tools/ai-dev-helper.js --task=\"Fix authentication bug\" --files=\"src/auth/*.ts\" --search=\"login\"\n\n# Use with AI prompts\n# Copy content from the generated ai-context.json file into your AI assistant prompt\n# or use the template in templates/ai-prompt-template.md\n```\n\n## 🏗️ Architecture\n\nThe project follows the MCP architecture with these components:\n\n1. **MCP Server**: Core server implementation using the MCP protocol\n2. **Analysis Features**: Modular code analysis capabilities\n3. **CLI**: Command-line interface for direct interaction\n4. **Transport Layer**: Communication mechanism (stdio by default)\n\n## 🔌 Integration with MCP Clients\n\nThis server is compatible with any MCP-compliant client, including:\n\n- Claude Desktop App\n- Cursor Editor\n- Continue\n- Other MCP-compatible tools\n\n## 📝 Path Specification\n\nCommands accept paths in various formats:\n\n- Local directory: `./src` or `/absolute/path/to/dir`\n- Local file: `./src/file.ts` or `/path/to/file.ts`\n- Repository URL: `https://github.com/username/repo`\n\n## 🤝 Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## 📄 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n# MCP SDK State Management Architecture\n\nThis project implements stateful tools for the Model Context Protocol (MCP) SDK, providing a framework for building tools that maintain context between invocations.\n\n## Architecture Overview\n\nThe state management architecture is organized into several modular components:\n\n```\nsrc/state/\n├── helpers/\n│   └── statefulTool.ts       # Main entry point for stateful tool creation\n├── machines/\n│   └── toolMachine.ts        # XState machine for tool execution flow\n├── services/\n│   ├── toolService.ts        # Core execution service for tools\n│   ├── redisToolExecutionService.ts  # Distributed execution service\n│   ├── redisSessionStore.ts  # Redis-based session persistence\n│   └── types.ts              # Shared type definitions\n```\n\n## Core Components\n\n### Stateful Tool Helper (`statefulTool.ts`)\n\nThe central integration point with the MCP SDK, providing:\n\n- Tool registration with session management\n- MCP-compliant response formatting\n- In-memory session management\n- Helper functions for session access and manipulation\n\n```typescript\n// Creating a stateful tool with state persistence\ncreateStatefulTool(server, \"my-tool\", schema, handler);\n\n// With description\ncreateStatefulTool(server, \"my-tool\", \"My stateful tool\", schema, handler);\n```\n\n### Tool Machine (`toolMachine.ts`)\n\nXState-based state machine that defines the execution flow for tools:\n\n- State transitions (idle, toolSelected, parametersSet, executing, etc.)\n- Context management for parameters, results, and history\n- Error handling and recovery paths\n\nThis component delegates session management to the statefulTool implementation.\n\n### Tool Service (`toolService.ts`)\n\nCore execution service that coordinates tool state transitions:\n\n- Manages tool selection, parameter validation, and execution\n- Tracks execution history\n- Handles execution results and errors\n\n### Types (`types.ts`)\n\nShared type definitions that ensure consistency across the state management system:\n\n- SessionData: Structure for storing tool state\n- SessionStore: Interface for session storage implementations\n- ExecutionResult: Standard response format for tools\n\n## Integration with MCP SDK\n\nThe architecture integrates with the MCP SDK by:\n\n1. Extending the tool registration pattern with state management\n2. Maintaining compatibility with MCP's response format\n3. Providing session and context tracking for stateful operations\n\n## Usage Example\n\n```typescript\nimport { createServer } from \"@modelcontextprotocol/sdk\";\nimport { createStatefulTool } from \"./state/helpers/statefulTool\";\nimport { z } from \"zod\";\n\nconst server = createServer();\n\n// Register a stateful tool\ncreateStatefulTool(\n  server,\n  \"counter\",\n  \"A tool that maintains a count between invocations\",\n  {\n    action: z.enum([\"increment\", \"decrement\", \"reset\"]),\n  },\n  async (params) => {\n    // Get session ID from params (or a new one will be created)\n    const sessionId = params.sessionId;\n\n    // Process the action\n    let count = 0;\n\n    // Tool logic with state manipulation...\n\n    return { count };\n  }\n);\n\nserver.listen(3000);\n```\n\n## Distributed State Management\n\nFor distributed environments, the Redis-based implementations provide:\n\n- Session persistence across server restarts\n- Distributed locking for concurrent access\n- TTL-based session cleanup\n- Error handling for network/connection issues\n\n## Testing\n\nThe components include comprehensive test suites to verify:\n\n- Tool state transitions\n- Session management\n- Error handling and recovery\n- Response formatting\n- Distributed operation (with Redis)\n\n## AI Development Tools\n\nThe CodeAnalysis MCP Server provides specialized tools for AI-assisted development. These tools help collect code context that can be fed to AI systems for more effective assistance.\n\n### Client Scripts\n\nThe repository includes several client scripts in the `tools/` directory:\n\n- **HTTP Client** (`tools/http-client.js`): Connects to the MCP server via HTTP transport (default).\n\n  ```bash\n  node tools/http-client.js --task \"Your task description\" --files \"src/features/*.ts\" --search \"session\"\n  ```\n\n- **Raw Client** (`tools/mcp-raw-client.js`): A simpler client that only captures server information.\n\n  ```bash\n  node tools/mcp-raw-client.js --task \"Your task description\"\n  ```\n\n- **Simple Client** (`tools/simple-client.js`): Communicates with the server via stdio.\n  ```bash\n  node tools/simple-client.js --task \"Your task description\" --files \"src/features/*.ts\"\n  ```\n\nAll client scripts generate an `ai-context.json` file in the project root. This file contains valuable context about your codebase that can be shared with AI assistants to provide better-informed responses.\n\n### Prompt Template\n\nA prompt template for AI assistants is available at `templates/ai-prompt-template.md`. This template helps structure your requests to AI assistants with proper context from the MCP tools.\n\n### Server Transport Modes\n\nThe MCP server supports two transport modes:\n\n1. **HTTP Transport** (default): Runs on port 3000 by default. Best for client-server architecture.\n2. **Stdio Transport**: For direct process communication. Set the `STDIO_TRANSPORT=true` environment variable to enable.\n\n## Session Storage Architecture\n\nMCP Code Analysis now features a modular session store architecture with automatic backend detection:\n\n- **Flexible Storage**: Automatically switches between Redis and in-memory storage\n- **Development Friendly**: Run without Redis during development\n- **Production Ready**: Use Redis for persistence in production environments\n- **Automatic Fallback**: Gracefully falls back to memory storage when Redis is unavailable\n\nFor more details, see the [Session Store Architecture](docs/session-store.md) documentation.\n\n## Requirements\n\n- Node.js 18+\n- npm or yarn\n- Redis (optional for development, recommended for production)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_codeanalysis",
        "codebases",
        "coding",
        "code analysis",
        "mcp_codeanalysis code",
        "code execution"
      ],
      "category": "code-execution"
    },
    "302ai--302_sandbox_mcp": {
      "owner": "302ai",
      "name": "302_sandbox_mcp",
      "url": "https://github.com/302ai/302_sandbox_mcp",
      "imageUrl": "https://github.com/302ai.png",
      "description": "The 302AI Sandbox Server allows AI models to safely run code, execute commands, and manage files in a controlled remote Linux environment.",
      "stars": 21,
      "forks": 2,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-28T08:48:59Z",
      "readme_content": "# <p align=\"center\">🤖 302AI Sandbox MCP Server🚀✨</p>\n\n<p align=\"center\">An MCP service with code sandbox that allows AI assistants to safely execute arbitrary code.</p>\n\n<p align=\"center\"><a href=\"https://www.npmjs.com/package/@302ai/sandbox-mcp\" target=\"blank\"><img src=\"https://file.302.ai/gpt/imgs/github/20250102/72a57c4263944b73bf521830878ae39a.png\" /></a></p >\n\n<p align=\"center\"><a href=\"README_zh.md\">中文</a> | <a href=\"README.md\">English</a> | <a href=\"README_ja.md\">日本語</a></p>\n\n![](docs/302_Sandbox_MCP_Server_en.png) \n\n## Previews\n\nHere are some usage examples\n\n![](docs/302_Sandbox_MCP_Server_en_screenshot_01.png)     \n\n![](docs/302_Sandbox_MCP_Server_en_screenshot_02.png)     \n\nHere is the list of supported tools\n\n![](docs/302_Sandbox_MCP_Server_en_screenshot_03.png)\n\n\n## ✨ Features ✨\n\n- 🔧 Dynamic Loading - Automatically update tool list from remote server.\n- 🌐 Multi modes supported, you can use `stdin` mode locally, or host it as a remote HTTP server\n\n## 🚀 Tool List\n- [One-click Code Execution](https://302ai.apifox.cn/api-276039652)\n- [Create Sandbox](https://302ai.apifox.cn/api-276079606)\n- [Query Your Sandbox List](https://302ai.apifox.cn/api-276086526)\n- [Destroy Sandbox](https://302ai.apifox.cn/api-276092957)\n- [Run-Code](https://302ai.apifox.cn/api-276100061)\n- [Run Command Line](https://302ai.apifox.cn/api-276106261)\n- [Query File Information at Specified Path](https://302ai.apifox.cn/api-276110558)\n- [Import File Data into Sandbox](https://302ai.apifox.cn/api-276123813)\n- [Export Sandbox Files](https://302ai.apifox.cn/api-276123525)\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`     \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"302ai-sandbox-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@302ai/sandbox-mcp\"],\n      \"env\": {\n        \"302AI_API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n    }\n  }\n}\n```\n\nTo use with Cherry Studio, add the server config:\n\n```json\n{\n  \"mcpServers\": {\n    \"Li2ZXXJkvhAALyKOFeO4N\": {\n      \"name\": \"302ai-sandbox-mcp\",\n      \"description\": \"\",\n      \"isActive\": true,\n      \"registryUrl\": \"\",\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@302ai/sandbox-mcp@0.2.0\"\n      ],\n      \"env\": {\n        \"302AI_API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n    }\n  }\n}\n```\n\nTo use with ChatWise, copy the following content to clipboard\n```json\n{\n  \"mcpServers\": {\n    \"302ai-sandbox-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@302ai/sandbox-mcp\"],\n      \"env\": {\n        \"302AI_API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n    }\n  }\n}\n```\nGo to Settings -> Tools -> Add button -> Select Import from Clipboard\n![](docs/302_Sandbox_MCP_Server_en_screenshot_04.jpg)\n\n### Find Your 302AI_API_KEY [here](https://dash.302.ai/apis/list)\n[Using Tutorials](https://help.302.ai/en/docs/API-guan-li)\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## ✨ About 302.AI ✨\n[302.AI](https://302.ai/en/) is an enterprise-oriented AI application platform that offers pay-as-you-go services, ready-to-use solutions, and an open-source ecosystem.✨\n1. 🧠 Integrates the latest and most comprehensive AI capabilities and brands, including but not limited to language models, image models, voice models, and video models.\n2. 🚀 Develops deep applications based on foundation models - we develop real AI products, not just simple chatbots\n3. 💰 Zero monthly fee, all features are pay-per-use, fully open, achieving truly low barriers with high potential.\n4. 🛠 Powerful management backend for teams and SMEs - one person manages, many people use.\n5. 🔗 All AI capabilities provide API access, all tools are open source and customizable (in progress).\n6. 💡 Strong development team, launching 2-3 new applications weekly, products updated daily. Developers interested in joining are welcome to contact us.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sandbox",
        "302_sandbox_mcp",
        "servers",
        "execution servers",
        "coding agents",
        "sandbox server"
      ],
      "category": "code-execution"
    },
    "AB498--code-context-provider-mcp": {
      "owner": "AB498",
      "name": "code-context-provider-mcp",
      "url": "https://github.com/AB498/code-context-provider-mcp",
      "imageUrl": "https://github.com/AB498.png",
      "description": "Provides detailed directory structure and code symbol analysis for JavaScript, TypeScript, and Python projects, enabling efficient navigation and understanding of codebases. Customizable analysis depth and file patterns are supported for handling large or complex projects.",
      "stars": 18,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-30T12:15:35Z",
      "readme_content": "# Code Context Provider MCP\n\n### MCP server that provides code context and analysis for AI assistants. Extracts directory structure and code symbols using WebAssembly Tree-sitter parsers with Zero Native Dependencies.\n\n<div align=\"center\" style=\"text-align:center;font-family: monospace; display: flex; align-items: center; justify-content: center; width: 100%; gap: 10px\">\n    <a href=\"https://nextjs-boilerplate-ashy-nine-64.vercel.app/demo-context-provider\"><img\n            src=\"https://komarev.com/ghpvc/?username=AB498&label=DEMO&style=for-the-badge&color=CC0000\" /></a>\n    <a href=\"https://discord.gg/ZeeqSBpjU2\"><img\n            src=\"https://img.shields.io/discord/1095854826786668545?style=for-the-badge&color=0000CC\" alt=\"Discord\"></a>\n    <a href=\"https://img.shields.io/badge/License-MIT-yellow.svg\"><img\n            src=\"https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge&color=00CC00\" alt=\"License: MIT\"></a>\n    <a href=\"https://www.npmjs.com/package/code-context-provider-mcp\"><img\n            src=\"https://img.shields.io/npm/v/code-context-provider-mcp?style=for-the-badge\" alt=\"PyPi\"></a>\n</div>\n\n---\n\n## Features\n\n- Generate directory tree structure\n- Analyze JavaScript/TypeScript and Python files\n- Extract code symbols (functions, variables, classes, imports, exports)\n- Compatible with the MCP protocol for seamless integration with AI assistants\n\n## Quick Usage (MCP Setup)\n\n### Installing via Smithery\n\nTo install Code Context Provider for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@AB498/code-context-provider-mcp):\n\n```bash\nnpx -y @smithery/cli install @AB498/code-context-provider-mcp --client claude\n```\n\n### Windows\n\n```json\n{\n  \"mcpServers\": {\n    \"code-context-provider-mcp\": {\n      \"command\": \"cmd.exe\",\n      \"args\": [\n        \"/c\",\n        \"npx\",\n        \"-y\",\n        \"code-context-provider-mcp@latest\"\n      ]\n    }\n  }\n}\n```\n\n### MacOS/Linux\n\n```json\n{\n  \"mcpServers\": {\n    \"code-context-provider-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"code-context-provider-mcp@latest\"\n      ]\n    }\n  }\n}\n```\n\nOR install globally with `npm`:\n```bash\nnpm install -g code-context-provider-mcp\n```\nThen use it by running:\n```bash\ncode-context-provider-mcp # if you're not using @latest, you may want to clear the cache for latest version using `Remove-Item -Path \"$env:LOCALAPPDATA\\npm-cache\\_npx\" -Recurse -Force` for windows and `rm -rf ~/.npm/_npx` for linux/macos\n```\n\n## Available Tools\n\n### `get_code_context`\n\nAnalyzes a directory and returns its structure along with code symbols (optional).\n\nParameters:\n- `absolutePath` (string, required): Absolute path to the directory to analyze\n- `analyzeJs` (boolean, optional): Whether to analyze JavaScript/TypeScript and Python files (default: false)\n- `includeSymbols` (boolean, optional): Whether to include code symbols in the response (default: false)\n- `symbolType` (enum, optional): Type of symbols to include if includeSymbols is true (options: 'functions', 'variables', 'classes', 'imports', 'exports', 'all', default: 'all')\n- `filePatterns` (array of strings, optional): File patterns to analyze (e.g. ['*.js', '*.py', 'config.*'])\n- `maxDepth` (number, optional): Maximum directory depth to analyze (default: 5 levels)\n\nNote: Anonymous functions are automatically filtered out of the results.\n\n## Example Output Text On Tool Call\n\n```\nDirectory structure for: C:\\Users\\Admin\\Desktop\\mcp\\context-provider-mcp\n\nCode Analysis Summary:\n- Files analyzed: 3\n- Total functions: 29\n- Total variables: 162\n- Total classes: 0\n\nNote: Symbol analysis is supported for JavaScript/TypeScript (.js, .jsx, .ts, .tsx) and Python (.py) files only.\n\nCode analysis limited to a maximum depth of 5 directory levels (default).\n\n├── index.js (39 KB)\n│   └── [Analyzed: 22 functions, 150 variables, 0 classes]\n│       Functions:\n│       - initializeTreeSitter [39:0]\n│       - getLanguageFromExtension [107:0]\n│       - getPosition [138:24]\n```\n\n\n## File Pattern Examples\n\nYou can use the `filePatterns` parameter to specify which files to analyze. This is useful for complex projects with multiple languages or specific files of interest.\n\nExamples:\n- `[\"*.js\", \"*.py\"]` - Analyze all JavaScript and Python files\n- `[\"config.*\"]` - Analyze all configuration files regardless of extension\n- `[\"package.json\", \"*.config.js\"]` - Analyze package.json and any JavaScript config files\n- `[\".ts\", \".tsx\", \".py\"]` - Analyze TypeScript and Python files (using extension format)\n\nThe file pattern matching supports:\n- Simple glob patterns with wildcards (*)\n- Direct file extensions (with or without the dot)\n- Exact file names\n\n## Handling Large Projects\n\nFor very large projects, you can use the `maxDepth` parameter to limit how deeply the tool will traverse directories:\n\n- `maxDepth: 2` - Only analyze the root directory and one level of subdirectories\n- `maxDepth: 3` - Analyze the root, and two levels of subdirectories\n- `maxDepth: 0` - Only analyze files in the root directory\n\nThis is particularly useful when:\n- Working with large monorepos\n- Analyzing projects with many dependencies\n- Focusing only on the main source code and not third-party libraries\n\n## Supported Languages\n\nCode symbol analysis is supported for:\n- JavaScript (.js)\n- JSX (.jsx)\n- TypeScript (.ts)\n- TSX (.tsx)\n- Python (.py)\n\nUsing the `filePatterns` parameter allows you to include other file types in the directory structure, though symbolic analysis may be limited.\n\n## Development\n\n### [Development] Setting up the Development Environment\n\n```bash\n# Clone the repository\ngit clone https://github.com/your-username/code-context-provider-mcp.git\ncd code-context-provider-mcp\n\n# Install dependencies\nnpm install\n\n# Set up WASM parsers\nnpm run setup\n```\n\n### [Development] Post-Installation\n\nAfter installation, the package's `prepare` script automatically runs to download the WASM parsers. If for some reason the download fails, users can manually run the setup:\n\n```bash\nnpx code-context-provider-mcp-setup\n```\n\n## License\n\nMIT\n\n## For more information or help\n\n- [Email (abcd49800@gmail.com)](mailto:abcd49800@gmail.com)\n- [Discord (CodePlayground)](https://discord.gg/ZeeqSBpjU2)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "codebases",
        "llms",
        "coding",
        "code context",
        "llms execute",
        "code secure"
      ],
      "category": "code-execution"
    },
    "Alec2435--python_mcp": {
      "owner": "Alec2435",
      "name": "python_mcp",
      "url": "https://github.com/Alec2435/python_mcp",
      "imageUrl": "https://github.com/Alec2435.png",
      "description": "Provides an interactive Python REPL environment that allows execution of Python code and maintains session history for review. Outputs from executed code are captured and accessible for each session.",
      "stars": 56,
      "forks": 15,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-06T23:54:03Z",
      "readme_content": "# python_local MCP Server\n\nAn MCP Server that provides an interactive Python REPL (Read-Eval-Print Loop) environment.\n\n## Components\n\n### Resources\n\nThe server provides access to REPL session history:\n- Custom `repl://` URI scheme for accessing session history\n- Each session's history can be viewed as a text/plain resource\n- History shows input code and corresponding output for each execution\n\n### Tools\n\nThe server implements one tool:\n- `python_repl`: Executes Python code in a persistent session\n  - Takes `code` (Python code to execute) and `session_id` as required arguments\n  - Maintains separate state for each session\n  - Supports both expressions and statements\n  - Captures and returns stdout/stderr output\n\n## Configuration\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n<details>\n  <summary>Development/Unpublished Servers Configuration</summary>\n  ```json\n  \"mcpServers\": {\n    \"python_local\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/python_local\",\n        \"run\",\n        \"python_local\"\n      ]\n    }\n  }\n  ```\n</details>\n\n<details>\n  <summary>Published Servers Configuration</summary>\n  ```json\n  \"mcpServers\": {\n    \"python_local\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"python_local\"\n      ]\n    }\n  }\n  ```\n</details>\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory /path/to/python_local run python-local\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "python_mcp",
        "python",
        "llms",
        "llms execute",
        "python_mcp provides",
        "execution python"
      ],
      "category": "code-execution"
    },
    "AnEntrypoint--mcp-glootie": {
      "owner": "AnEntrypoint",
      "name": "mcp-glootie",
      "url": "https://github.com/AnEntrypoint/mcp-glootie",
      "imageUrl": "https://github.com/AnEntrypoint.png",
      "description": "Execute JavaScript code snippets securely in a sandboxed environment with comprehensive error handling and memory management. Supports ESM modules, dynamic imports, and access to native Node.js APIs.",
      "stars": 103,
      "forks": 9,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-04T10:03:16Z",
      "readme_content": "![cd6d6b01e938ef486734ce8dd2544ae5-1](https://github.com/user-attachments/assets/c080416f-5fa3-44d0-aa36-8aa2cac0a7d2)\n\nMCP (Model Context Protocol) server for development tools with optimized execution and vector embeddings.\n\nThe aim of the current version is to make more thoroughly investigated outputs than regular tooling, which will save you on rounds of physical interaction with the agent\n\nbenchmark prompt:\n\n``` always use glootie ```\n\nmy preferred prompts look somethinig like:\n\n```always continuously track and update caveats with the caveat tool, always hypothesize and test ideas in glootie and playwright execute first before implementing them, only implment when you're sure something will work, use the tooling to always eliminate double implementations, DRY code is mandatory, generalization is mandatory, architectural foresight is mandatory, immediately implement changes that should be made across the board, use the code insight tools in glootie to improve your ourput and immediately fix anything that goes against policy, a stitch in time saves nine. use ast-grep for codebase wide pattern base replaces etc whenever needed, dont make any comments always eliminate any coments you see immediatley, dont make any mocks simulations fallbacks or failovers, our code must only have one primary implementation per concern, keep specs in specs/ and track their progress, you are not finished till all specs are recorded, tracked, all the parts of the codebase they use noted, end to end verified, and caveats recorded, never report further problems and finish, if they can be solved track them troubleshoot and iterate until they're fixed, if any problems warnings issues or errors or unexpected behaviors are encountered track them immediately and treat the solving of all known errors as a hard barrier that prevents you from finishing, you may only finish when all known issues are fully end-to-end verified to be resolved, that means that as a final step you must do a full error discovery run to find further issues and check the entire project to make sure it works as expected, end to end, tracking any new issues found immediately and iterating on troubleshooting them till an entire run of all the program features are fully end to end tested and known to work, no exceptions. we want to apply frameworking foresight thoughout our work process so that generalizations, dryness, automated frameworking, convention over configuration and code minimization is always enforced, every letter counts. we want compehensive and easy to use globals for debugging in our code and often use them in our code executions as possible, to get absolute truth on whats going on when fixing problems, we should never ever guess when changing code, first principals only.```\n\n## Features\n\n### Built-in Auto-Hooks\n- **Auto-linting**: Automatically lints files after editing operations (built into tools)\n- **Context management**: Intelligent context awareness and session tracking\n- **Zero configuration**: Works automatically without separate processes\n- **Multi-language support**: ESLint and ast-grep integration for various languages\n\n### Available Tools\n\n#### Core Tools\n- **begin** - Initialize the system and set working directory context\n- **execute** - Multi-language code execution with automatic runtime detection\n  - **JavaScript/TypeScript** - Execute with Node.js or Deno\n  - **Go** - Execute with `go run` (when Go CLI available)\n  - **Rust** - Compile and execute with `rustc` (when Rust CLI available)\n  - **Python** - Execute with `python3` (when Python CLI available)\n  - **C** - Compile and execute with `gcc` (when GCC available)\n  - **C++** - Compile and execute with `g++` (when G++ available)\n  - **Bash** - Run bash commands securely\n\n#### Analysis Tools\n- **searchcode** - Semantic code search with AI-powered vector embeddings across all supported languages\n- **ast_tool** - Unified AST operations combining code analysis, pattern search, safe replacement, and linting\n\n#### Execution Tools\n- **execute** - Multi-language code execution with built-in async job management and progress tracking\n\n#### Utility Tools\n- **caveat** - Record, view, and delete technological caveats encountered during development. Important for tracking limitations, constraints, and considerations that inform future work.\n- **error_handling** - Enhanced error recovery and reporting\n- **shared_hooks** - Shared functionality across tools\n- **utilities** - Common utility functions and helpers\n- **mcp_pagination** - MCP pagination utilities for handling large datasets\n\n\n### Language Runtime Requirements\n\nFor full multi-language support, install the following CLI tools:\n\n- **Go**: `go` - Install from https://golang.org/\n- **Rust**: `rustc` and `cargo` - Install from https://rustup.rs/\n- **Python**: `python3` - Usually pre-installed on Linux/macOS\n- **C**: `gcc` - Install build-essential or Xcode Command Line Tools\n- **C++**: `g++` - Included with gcc installation\n- **Node.js**: `node` (≥16.0.0) - Install from https://nodejs.org/\n- **Deno**: `deno` - Install from https://deno.land/\n\n**Note**: The tools automatically detect which language runtimes are available and enable features accordingly.\n\n## Client Configuration\n\n### Claude Code\n\n#### Windows\nOn Windows, npx commands require the `cmd /c` wrapper:\n```bash\nclaude mcp add glootie -- cmd /c npx -y mcp-glootie@latest\n```\n\n#### macOS/Linux\n```bash\n# Using npx (recommended - always gets latest version)\nclaude mcp add glootie npx -s local -- -y mcp-glootie@latest\n\n# For local development (replace /path/to with actual path)\nclaude mcp add glootie -- node /path/to/mcp-glootie/src/index.js\n```\n\n### Cursor\nAdd to your Cursor `mcpServers.json` configuration:\n```json\n{\n  \"mcpServers\": {\n    \"glootie\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\",\"mcp-glootie@latest\"],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": [\n        \"execute\",\n        \"searchcode\",\n        \"ast_tool\",\n        \"caveat\"\n      ]\n    }\n  }\n}\n```\n\n### GitHub Copilot\nAdd to your GitHub Copilot `mcpServers.json` configuration:\n```json\n{\n  \"mcpServers\": {\n    \"glootie\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\",\"mcp-glootie@latest\"],\n      \"env\": {},\n      \"type\": \"local\",\n      \"tools\": [\n        \"execute\",\n        \"searchcode\",\n        \"ast_tool\",\n        \"caveat\"\n      ]\n    }\n  }\n}\n```\n\n### VSCode\nAdd to your VSCode MCP configuration:\n```json\n{\n    \"servers\": {\n        \"glootie\": {\n            \"command\": \"npx\",\n            \"args\": [\"-y\",\"mcp-glootie@latest\"],\n            \"env\": {},\n            \"type\": \"stdio\"\n        }\n    },\n    \"inputs\": []\n}\n```\n\n**Note**: For Claude Code local development, replace `/path/to/mcp-glootie` with the actual path to your cloned repository. The global installation uses the `mcp-glootie` command directly.\n\n### Built-in Auto-Hooks\n\n#### Zero-Configuration Auto-Linting\n\nGlootie includes built-in auto-linting that works automatically without any setup:\n\n- **Automatic Detection**: Tools automatically detect when files are modified\n- **Smart Linting**: Uses ESLint when available, falls back to ast-grep patterns\n- **Multi-Language**: Supports JavaScript, TypeScript, Python, and more\n- **Zero Setup**: No separate processes or configuration required\n\n## Tools\n\n### Core AST Tools\n\n#### ast_tool\nUnified AST operations combining code analysis, pattern search, safe replacement, and linting in one powerful tool. This consolidates the previous 4 separate AST tools to reduce choice paralysis and provide a consistent interface.\n\n**Operations:**\n- **analyze** - Parse code structure, count functions/classes/imports, validate syntax\n- **search** - Find structural code patterns using AST matching with wildcards\n- **replace** - Safely transform code patterns while preserving syntax\n- **lint** - Apply custom linting rules using AST patterns\n\n**Key Features:**\n- Single unified interface for all AST operations\n- Intelligent file reading (accepts either code or filePath)\n- Multi-language support (JavaScript, TypeScript, Go, Rust, Python, C, C++)\n- Advanced ast-grep pattern matching with YAML configuration support\n- Relational constraints and composite rule types\n- Automatic ignore pattern filtering\n- Advanced pattern syntax with wildcards ($VARIABLE)\n- Safe AST-based transformations with automatic backups\n\n**Examples:**\n```javascript\n// Analyze code structure\nast_tool(operation=\"analyze\", path=\"./src\", analysisType=\"detailed\")\n\n// Find React components\nast_tool(operation=\"search\", pattern=\"const $NAME = ($PROPS) => { $BODY }\")\n\n// Replace console.log with logger\nast_tool(operation=\"replace\", pattern=\"console.log($MSG)\", replacement=\"logger.info($MSG)\")\n\n// Lint for code quality issues\nast_tool(operation=\"lint\", path=\"./src\", rules=[custom_rules])\n```\n\n**Common Patterns:**\n```\nfunction $NAME($ARGS) { $BODY }           # Find function declarations\nconst $NAME = ($PROPS) => { $BODY }        # Find React components\ninterface $NAME { $MEMBERS }              # Find TypeScript interfaces\nconsole.log($ARGS)                       # Find console.log calls\nvar $NAME = $VALUE → let $NAME = $VALUE      # Convert var to let/const\n```\n\n### Execution Tools\n\n#### execute\nExecute code in multiple languages with automatic runtime detection and CLI tool integration.\n\n#### batch_execute\nCoordinate multiple tools in single operations for efficiency across different languages. Now supports intelligent file reading for AST operations.\n\n**Key Improvements:**\n- Automatic file reading when filePath provided without code\n- Improved error handling and validation\n- Better integration with AST tools\n\n### Analysis Tools\n\n#### searchcode\nSearch for code patterns across your multi-language codebase with semantic vector embeddings.\n\n#### execute\nMulti-language code execution with 3-second threshold optimization and cross-tool status sharing.\n\n**Key Features:**\n- **3-second threshold**: Fast operations (< 3 seconds) return direct responses to save cycles and latency\n- **Cross-tool status sharing**: Execution results automatically shared with subsequent tool calls\n- **Smart optimization**: Time-based execution tracking for optimal performance\n- **Multi-language support**: JavaScript, TypeScript, Go, Rust, Python, C, C++, Bash\n- **Status indicators**: Clear markers help agents track execution across tools\n\n**Usage:**\n```javascript\n// Execute code (automatically optimized based on execution time)\nexecute(code=\"console.log('Hello world')\", runtime=\"nodejs\")\n\n// Fast executions (< 3 seconds) return direct responses\n// Status automatically shared with subsequent tool calls\n```\n\n#### sequentialthinking\nStructure complex thoughts systematically for better analysis.\n\n#### caveat\nRecord, view, and delete technological caveats encountered during development. This tool helps track system limitations, constraints, and important considerations that inform future work.\n\n**Features:**\n- **Record caveats**: Document technological limitations, API constraints, performance considerations\n- **View caveats**: Display all recorded caveats with timestamps for easy reference\n- **Delete caveats**: Remove caveats that are no longer relevant or have been resolved\n- **Persistent storage**: Caveats are stored locally and displayed during MCP initialization\n- **Informative context**: Caveats help agents understand project constraints and limitations\n\n**Usage:**\n```javascript\n// Record a new caveat\ncaveat(action=\"record\", text=\"This API endpoint has rate limiting of 100 requests per minute\")\n\n// View all caveats\ncaveat(action=\"view\")\n\n// Delete a caveat by ID or text\ncaveat(action=\"delete\", id=\"cav_1234567890123_abcde\")\n```\n\n**Important:** The caveat tool displays recorded caveats during MCP server initialization to inform future work. Use it to document any technological limitations that could impact development decisions.\n\n## Testing\n\nThe project includes a comprehensive performance testing suite (`test-runner.cjs`) that:\n\n- **Parallel Testing**: Runs baseline vs MCP-optimized tests simultaneously\n- **Real-time Monitoring**: Incremental file writing prevents stuck processes\n- **Comprehensive Analysis**: Tracks tool usage, performance metrics, and MCP server status\n- **Automatic Reporting**: Generates detailed analysis reports and suggestions\n\n### Test Runner Features\n\n- **Optimized Incremental File Writing**: Step data written every 25 operations for better performance\n- **Process Monitoring**: Real-time updates during test execution\n- **Working Directory Fixes**: Critical fix for analyzing correct codebase instead of parent directories\n- **Error Recovery**: Graceful handling of failed tests with detailed error reporting\n- **Performance Metrics**: Measures speed improvements and tool effectiveness\n- **Status Tracking**: Proper MCP server status tracking for baseline vs MCP tests\n\nRun tests with:\n```bash\nnode test-runner.cjs\n```\n\n## Architecture\n\n- Clean, simple implementation following KISS principles\n- Minimal dependencies and straightforward code structure\n- Future-proof design with clear separation of concerns\n- Focus on essential functionality without unnecessary complexity\n- Robust testing infrastructure with incremental progress tracking\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "esm",
        "apis",
        "llms execute",
        "execution servers",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "Automata-Labs-team--code-sandbox-mcp": {
      "owner": "Automata-Labs-team",
      "name": "code-sandbox-mcp",
      "url": "https://github.com/Automata-Labs-team/code-sandbox-mcp",
      "imageUrl": "https://github.com/Automata-Labs-team.png",
      "description": "Securely execute code in isolated Docker containers, providing a controlled environment for code execution. This MCP server supports custom Docker images, file operations, and command execution with real-time logging.",
      "stars": 270,
      "forks": 31,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-03T17:09:00Z",
      "readme_content": "# Code Sandbox MCP 🐳\n[![smithery badge](https://smithery.ai/badge/@Automata-Labs-team/code-sandbox-mcp)](https://smithery.ai/server/@Automata-Labs-team/code-sandbox-mcp)\n\nA secure sandbox environment for executing code within Docker containers. This MCP server provides AI applications with a safe and isolated environment for running code while maintaining security through containerization.\n\n## 🌟 Features\n\n- **Flexible Container Management**: Create and manage isolated Docker containers for code execution\n- **Custom Environment Support**: Use any Docker image as your execution environment\n- **File Operations**: Easy file and directory transfer between host and containers\n- **Command Execution**: Run any shell commands within the containerized environment\n- **Real-time Logging**: Stream container logs and command output in real-time\n- **Auto-Updates**: Built-in update checking and automatic binary updates\n- **Multi-Platform**: Supports Linux, macOS, and Windows\n\n## 🚀 Installation\n\n### Prerequisites\n\n- Docker installed and running\n  - [Install Docker for Linux](https://docs.docker.com/engine/install/)\n  - [Install Docker Desktop for macOS](https://docs.docker.com/desktop/install/mac/)\n  - [Install Docker Desktop for Windows](https://docs.docker.com/desktop/install/windows-install/)\n\n### Quick Install\n\n#### Linux, MacOS\n```bash\ncurl -fsSL https://raw.githubusercontent.com/Automata-Labs-team/code-sandbox-mcp/main/install.sh | bash\n```\n\n#### Windows\n```powershell\n# Run in PowerShell\nirm https://raw.githubusercontent.com/Automata-Labs-team/code-sandbox-mcp/main/install.ps1 | iex\n```\n\nThe installer will:\n1. Check for Docker installation\n2. Download the appropriate binary for your system\n3. Create necessary configuration files\n\n### Manual Installation\n\n1. Download the latest release for your platform from the [releases page](https://github.com/Automata-Labs-team/code-sandbox-mcp/releases)\n2. Place the binary in a directory in your PATH\n3. Make it executable (Unix-like systems only):\n   ```bash\n   chmod +x code-sandbox-mcp\n   ```\n\n## 🛠️ Available Tools\n\n#### `sandbox_initialize`\nInitialize a new compute environment for code execution.\nCreates a container based on the specified Docker image.\n\n**Parameters:**\n- `image` (string, optional): Docker image to use as the base environment\n  - Default: 'python:3.12-slim-bookworm'\n\n**Returns:**\n- `container_id` that can be used with other tools to interact with this environment\n\n#### `copy_project`\nCopy a directory to the sandboxed filesystem.\n\n**Parameters:**\n- `container_id` (string, required): ID of the container returned from the initialize call\n- `local_src_dir` (string, required): Path to a directory in the local file system\n- `dest_dir` (string, optional): Path to save the src directory in the sandbox environment\n\n#### `write_file`\nWrite a file to the sandboxed filesystem.\n\n**Parameters:**\n- `container_id` (string, required): ID of the container returned from the initialize call\n- `file_name` (string, required): Name of the file to create\n- `file_contents` (string, required): Contents to write to the file\n- `dest_dir` (string, optional): Directory to create the file in (Default: ${WORKDIR})\n\n#### `sandbox_exec`\nExecute commands in the sandboxed environment.\n\n**Parameters:**\n- `container_id` (string, required): ID of the container returned from the initialize call\n- `commands` (array, required): List of command(s) to run in the sandboxed environment\n  - Example: [\"apt-get update\", \"pip install numpy\", \"python script.py\"]\n\n#### `copy_file`\nCopy a single file to the sandboxed filesystem.\n\n**Parameters:**\n- `container_id` (string, required): ID of the container returned from the initialize call\n- `local_src_file` (string, required): Path to a file in the local file system\n- `dest_path` (string, optional): Path to save the file in the sandbox environment\n\n#### `sandbox_stop`\nStop and remove a running container sandbox.\n\n**Parameters:**\n- `container_id` (string, required): ID of the container to stop and remove\n\n**Description:**\nGracefully stops the specified container with a 10-second timeout and removes it along with its volumes.\n\n#### Container Logs Resource\nA dynamic resource that provides access to container logs.\n\n**Resource Path:** `containers://{id}/logs`  \n**MIME Type:** `text/plain`  \n**Description:** Returns all container logs from the specified container as a single text resource.\n\n## 🔐 Security Features\n\n- Isolated execution environment using Docker containers\n- Resource limitations through Docker container constraints\n- Separate stdout and stderr streams\n\n\n## 🔧 Configuration\n\n### Claude Desktop\n\nThe installer automatically creates the configuration file. If you need to manually configure it:\n\n#### Linux\n```json\n// ~/.config/Claude/claude_desktop_config.json\n{\n    \"mcpServers\": {\n        \"code-sandbox-mcp\": {\n            \"command\": \"/path/to/code-sandbox-mcp\",\n            \"args\": [],\n            \"env\": {}\n        }\n    }\n}\n```\n\n#### macOS\n```json\n// ~/Library/Application Support/Claude/claude_desktop_config.json\n{\n    \"mcpServers\": {\n        \"code-sandbox-mcp\": {\n            \"command\": \"/path/to/code-sandbox-mcp\",\n            \"args\": [],\n            \"env\": {}\n        }\n    }\n}\n```\n\n#### Windows\n```json\n// %APPDATA%\\Claude\\claude_desktop_config.json\n{\n    \"mcpServers\": {\n        \"code-sandbox-mcp\": {\n            \"command\": \"C:\\\\path\\\\to\\\\code-sandbox-mcp.exe\",\n            \"args\": [],\n            \"env\": {}\n        }\n    }\n}\n```\n\n### Other AI Applications\n\nFor other AI applications that support MCP servers, configure them to use the `code-sandbox-mcp` binary as their code execution backend.\n\n## 🛠️ Development\n\nIf you want to build the project locally or contribute to its development, see [DEVELOPMENT.md](DEVELOPMENT.md).\n\n## 📝 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "servers",
        "sandbox",
        "execution servers",
        "llms execute",
        "securely execute"
      ],
      "category": "code-execution"
    },
    "DynamicEndpoints--Autogen_MCP": {
      "owner": "DynamicEndpoints",
      "name": "Autogen_MCP",
      "url": "https://github.com/DynamicEndpoints/Autogen_MCP",
      "imageUrl": "https://github.com/DynamicEndpoints.png",
      "description": "Facilitates the creation and management of AI agents that engage in natural language interactions and collaborate to solve problems. Supports orchestration of both individual and group conversations with customizable configurations and built-in error handling.",
      "stars": 15,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T01:15:10Z",
      "readme_content": "# Enhanced AutoGen MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@DynamicEndpoints/autogen_mcp)](https://smithery.ai/server/@DynamicEndpoints/autogen_mcp)\n\nA comprehensive MCP server that provides deep integration with Microsoft's AutoGen framework v0.9+, featuring the latest capabilities including prompts, resources, advanced workflows, and enhanced agent types. This server enables sophisticated multi-agent conversations through a standardized Model Context Protocol interface.\n\n## 🚀 Latest Features (v0.2.0)\n\n### ✨ **Enhanced MCP Support**\n- **Prompts**: Pre-built templates for common workflows (code review, research, creative writing)\n- **Resources**: Real-time access to agent status, chat history, and configurations\n- **Dynamic Content**: Template-based prompts with arguments and embedded resources\n- **Latest MCP SDK**: Version 1.12.3 with full feature support\n\n### 🤖 **Advanced Agent Types**\n- **Assistant Agents**: Enhanced with latest LLM capabilities\n- **Conversable Agents**: Flexible conversation patterns\n- **Teachable Agents**: Learning and memory persistence\n- **Retrievable Agents**: Knowledge base integration\n- **Multimodal Agents**: Image and document processing (when available)\n\n### 🔄 **Sophisticated Workflows**\n- **Code Generation**: Architect → Developer → Reviewer → Executor pipeline\n- **Research Analysis**: Researcher → Analyst → Critic → Synthesizer workflow\n- **Creative Writing**: Multi-stage creative collaboration\n- **Problem Solving**: Structured approach to complex problems\n- **Code Review**: Security → Performance → Style review teams\n- **Custom Workflows**: Build your own agent collaboration patterns\n\n### 🎯 **Enhanced Chat Capabilities**\n- **Smart Speaker Selection**: Auto, manual, random, round-robin modes\n- **Nested Conversations**: Hierarchical agent interactions\n- **Swarm Intelligence**: Coordinated multi-agent problem solving\n- **Memory Management**: Persistent agent knowledge and preferences\n- **Quality Checks**: Built-in validation and improvement loops\n\n## 🛠️ Available Tools\n\n### Core Agent Management\n- `create_agent` - Create agents with advanced configurations\n- `create_workflow` - Build complete multi-agent workflows\n- `get_agent_status` - Detailed agent metrics and health monitoring\n\n### Conversation Execution\n- `execute_chat` - Enhanced two-agent conversations\n- `execute_group_chat` - Multi-agent group discussions\n- `execute_nested_chat` - Hierarchical conversation structures\n- `execute_swarm` - Swarm-based collaborative problem solving\n\n### Workflow Orchestration\n- `execute_workflow` - Run predefined workflow templates\n- `manage_agent_memory` - Handle agent learning and persistence\n- `configure_teachability` - Enable/configure agent learning capabilities\n\n## 📝 Available Prompts\n\n### `autogen-workflow`\nCreate sophisticated multi-agent workflows with customizable parameters:\n- **Arguments**: `task_description`, `agent_count`, `workflow_type`\n- **Use case**: Rapid workflow prototyping and deployment\n\n### `code-review`\nSet up collaborative code review with specialized agents:\n- **Arguments**: `code`, `language`, `focus_areas`\n- **Use case**: Comprehensive code quality assessment\n\n### `research-analysis`\nDeploy research teams for in-depth topic analysis:\n- **Arguments**: `topic`, `depth`\n- **Use case**: Academic research, market analysis, technical investigation\n\n## 📊 Available Resources\n\n### `autogen://agents/list`\nLive list of active agents with status and capabilities\n\n### `autogen://workflows/templates`\nAvailable workflow templates and configurations\n\n### `autogen://chat/history`\nRecent conversation history and interaction logs\n\n### `autogen://config/current`\nCurrent server configuration and settings\n\n## Installation\n\n### Installing via Smithery\n\nTo install AutoGen Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@DynamicEndpoints/autogen_mcp):\n\n```bash\nnpx -y @smithery/cli install @DynamicEndpoints/autogen_mcp --client claude\n```\n\n### Manual Installation\n\n1. **Clone the repository:**\n```bash\ngit clone https://github.com/yourusername/autogen-mcp.git\ncd autogen-mcp\n```\n\n2. **Install Node.js dependencies:**\n```bash\nnpm install\n```\n\n3. **Install Python dependencies:**\n```bash\npip install -r requirements.txt --user\n```\n\n4. **Build the TypeScript project:**\n```bash\nnpm run build\n```\n\n5. **Set up configuration:**\n```bash\ncp .env.example .env\ncp config.json.example config.json\n# Edit .env and config.json with your settings\n```\n\n## Configuration\n\n### Environment Variables\n\nCreate a `.env` file from the template:\n\n```bash\n# Required\nOPENAI_API_KEY=your-openai-api-key-here\n\n# Optional - Path to configuration file\nAUTOGEN_MCP_CONFIG=config.json\n\n# Enhanced Features\nENABLE_PROMPTS=true\nENABLE_RESOURCES=true\nENABLE_WORKFLOWS=true\nENABLE_TEACHABILITY=true\n\n# Performance Settings\nMAX_CHAT_TURNS=10\nDEFAULT_OUTPUT_FORMAT=json\n```\n\n### Configuration File\n\nUpdate `config.json` with your preferences:\n\n```json\n{\n  \"llm_config\": {\n    \"config_list\": [\n      {\n        \"model\": \"gpt-4o\",\n        \"api_key\": \"your-openai-api-key\"\n      }\n    ],\n    \"temperature\": 0.7\n  },\n  \"enhanced_features\": {\n    \"prompts\": { \"enabled\": true },\n    \"resources\": { \"enabled\": true },\n    \"workflows\": { \"enabled\": true }\n  }\n}\n```\n\n## Usage Examples\n\n### Using with Claude Desktop\n\nAdd to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"autogen\": {\n      \"command\": \"node\",\n      \"args\": [\"path/to/autogen-mcp/build/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-key-here\"\n      }\n    }\n  }\n}\n```\n\n### Command Line Testing\n\nTest the server functionality:\n\n```bash\n# Run comprehensive tests\npython test_server.py\n\n# Test CLI interface\npython cli_example.py create_agent \"researcher\" \"assistant\" \"You are a research specialist\"\npython cli_example.py execute_workflow \"code_generation\" '{\"task\":\"Hello world\",\"language\":\"python\"}'\n```\n\n### Using Prompts\n\nThe server provides several built-in prompts:\n\n1. **autogen-workflow** - Create multi-agent workflows\n2. **code-review** - Set up collaborative code review\n3. **research-analysis** - Deploy research teams\n\n### Accessing Resources\n\nAvailable resources provide real-time data:\n\n- `autogen://agents/list` - Current active agents\n- `autogen://workflows/templates` - Available workflow templates  \n- `autogen://chat/history` - Recent conversation history\n- `autogen://config/current` - Server configuration\n\n## Workflow Examples\n\n### Code Generation Workflow\n\n```json\n{\n  \"workflow_name\": \"code_generation\",\n  \"input_data\": {\n    \"task\": \"Create a REST API endpoint\",\n    \"language\": \"python\",\n    \"requirements\": [\"FastAPI\", \"Pydantic\", \"Error handling\"]\n  },\n  \"quality_checks\": true\n}\n```\n\n### Research Workflow\n\n```json\n{\n  \"workflow_name\": \"research\", \n  \"input_data\": {\n    \"topic\": \"AI Ethics in 2025\",\n    \"depth\": \"comprehensive\"\n  },\n  \"output_format\": \"markdown\"\n}\n```\n\n## Advanced Features\n\n### Agent Types\n\n- **Assistant Agents**: LLM-powered conversational agents\n- **User Proxy Agents**: Code execution and human interaction\n- **Conversable Agents**: Flexible conversation patterns\n- **Teachable Agents**: Learning and memory persistence (when available)\n- **Retrievable Agents**: Knowledge base integration (when available)\n\n### Chat Modes\n\n- **Two-Agent Chat**: Direct conversation between agents\n- **Group Chat**: Multi-agent discussions with smart speaker selection\n- **Nested Chat**: Hierarchical conversation structures  \n- **Swarm Intelligence**: Coordinated problem solving (experimental)\n\n### Memory Management\n\n- Persistent agent memory across sessions\n- Conversation history tracking\n- Learning from interactions (teachable agents)\n- Memory cleanup and optimization\n\n## Troubleshooting\n\n### Common Issues\n\n1. **API Key Errors**: Ensure your OpenAI API key is valid and has sufficient credits\n2. **Import Errors**: Install all dependencies with `pip install -r requirements.txt --user`\n3. **Build Failures**: Check Node.js version (>= 18) and run `npm install`\n4. **Chat Failures**: Verify agent creation succeeded before attempting conversations\n\n### Debug Mode\n\nEnable detailed logging:\n\n```bash\nexport LOG_LEVEL=DEBUG\npython test_server.py\n```\n\n### Performance Tips\n\n- Use `gpt-4o-mini` for faster, cost-effective operations\n- Enable caching for repeated operations\n- Set appropriate timeout values for long-running workflows\n- Use quality checks only when needed (increases execution time)\n\n## Development\n\n### Running Tests\n\n```bash\n# Full test suite\npython test_server.py\n\n# Individual workflow tests  \npython -c \"\nimport asyncio\nfrom src.autogen_mcp.workflows import WorkflowManager\nwm = WorkflowManager()\nprint(asyncio.run(wm.execute_workflow('code_generation', {'task': 'test'})))\n\"\n```\n\n### Building\n\n```bash\nnpm run build\nnpm run lint\n```\n\n### Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Add tests for new functionality\n5. Submit a pull request\n\n## Version History\n\n### v0.2.0 (Latest)\n- ✨ Enhanced MCP support with prompts and resources\n- 🤖 Advanced agent types (teachable, retrievable)\n- 🔄 Sophisticated workflows with quality checks\n- 🎯 Smart speaker selection and nested conversations\n- 📊 Real-time resource monitoring\n- 🧠 Memory management and persistence\n\n### v0.1.0\n- Basic AutoGen integration\n- Simple agent creation and chat execution\n- MCP tool interface\n\n## Support\n\nFor issues and questions:\n- Check the troubleshooting section above\n- Review the test examples in `test_server.py`\n- Open an issue on GitHub with detailed reproduction steps\n\n## License\n\nMIT License - see LICENSE file for details.\n\n# OpenAI API Key (optional, can also be set in config.json)\nOPENAI_API_KEY=your-openai-api-key\n```\n\n### Server Configuration\n\n1. Copy `config.json.example` to `config.json`:\n```bash\ncp config.json.example config.json\n```\n\n2. Configure the server settings:\n```json\n{\n  \"llm_config\": {\n    \"config_list\": [\n      {\n        \"model\": \"gpt-4\",\n        \"api_key\": \"your-openai-api-key\"\n      }\n    ],\n    \"temperature\": 0\n  },\n  \"code_execution_config\": {\n    \"work_dir\": \"workspace\",\n    \"use_docker\": false\n  }\n}\n```\n\n## Available Operations\n\nThe server supports three main operations:\n\n### 1. Creating Agents\n\n```json\n{\n  \"name\": \"create_agent\",\n  \"arguments\": {\n    \"name\": \"tech_lead\",\n    \"type\": \"assistant\",\n    \"system_message\": \"You are a technical lead with expertise in software architecture and design patterns.\"\n  }\n}\n```\n\n### 2. One-on-One Chat\n\n```json\n{\n  \"name\": \"execute_chat\",\n  \"arguments\": {\n    \"initiator\": \"agent1\",\n    \"responder\": \"agent2\",\n    \"message\": \"Let's discuss the system architecture.\"\n  }\n}\n```\n\n### 3. Group Chat\n\n```json\n{\n  \"name\": \"execute_group_chat\",\n  \"arguments\": {\n    \"agents\": [\"agent1\", \"agent2\", \"agent3\"],\n    \"message\": \"Let's review the proposed solution.\"\n  }\n}\n```\n\n## Error Handling\n\nCommon error scenarios include:\n\n1. Agent Creation Errors\n```json\n{\n  \"error\": \"Agent already exists\"\n}\n```\n\n2. Execution Errors\n```json\n{\n  \"error\": \"Agent not found\"\n}\n```\n\n3. Configuration Errors\n```json\n{\n  \"error\": \"AUTOGEN_MCP_CONFIG environment variable not set\"\n}\n```\n\n## Architecture\n\nThe server follows a modular architecture:\n\n```\nsrc/\n├── autogen_mcp/\n│   ├── __init__.py\n│   ├── agents.py      # Agent management and configuration\n│   ├── config.py      # Configuration handling and validation\n│   ├── server.py      # MCP server implementation\n│   └── workflows.py   # Conversation workflow management\n```\n\n## License\n\nMIT License - See LICENSE file for details\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "autogen_mcp",
        "llms",
        "coding",
        "llms execute",
        "dynamicendpoints autogen_mcp",
        "autogen_mcp facilitates"
      ],
      "category": "code-execution"
    },
    "JohanLi233--mcp-sandbox": {
      "owner": "JohanLi233",
      "name": "mcp-sandbox",
      "url": "https://github.com/JohanLi233/mcp-sandbox",
      "imageUrl": "https://github.com/JohanLi233.png",
      "description": "Enables safe and isolated execution of Python code within Docker containers, managing virtual Python environments, and facilitating code execution workflows. Supports package management and automatic resource cleanup to ensure security and session isolation.",
      "stars": 27,
      "forks": 8,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-16T17:40:36Z",
      "readme_content": "# MCP Sandbox\n\n<p align=\"center\">\n  <img src=\"assets/mcp_logo.svg\" alt=\"MCP Sandbox Logo\" width=\"120\" height=\"120\" />\n</p>\n\n\n# Feel free to try on [mcp sandbox](http://www.mcpsandbox.xyz/)\n\n[![Python Version](https://img.shields.io/badge/python-3.12%2B-blue)](https://www.python.org/downloads/release/python-3120/)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![UV](https://img.shields.io/badge/UV-Package%20Manager-blueviolet)](https://github.com/astral-sh/uv)\n[![MCP](https://img.shields.io/badge/MCP-Compatible-brightgreen)](https://github.com/estitesc/mission-control-link)\n\n[中文文档](README_zh.md) | English\n\n# Demo \n<p align=\"center\">\n  <img src=\"assets/demo.gif\" alt=\"demo\" width=\"1280\"/>\n</p>\n\nPython MCP Sandbox is an interactive Python code execution tool that allows users and LLMs to safely execute Python code and install packages in isolated Docker containers.\n\n# Viby\n[Viby](https://github.com/JohanLi233/viby) works with mcp sandbox\n\n## Features\n\n- 🐳 **Docker Isolation**: Securely run Python code in isolated Docker containers\n- 📦 **Package Management**: Easily install and manage Python packages\n- 📊 **File Generation**: Support for generating files and accessing them via web links\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/JohanLi233/python-mcp-sandbox.git\ncd python-mcp-sandbox\n\nuv venv\nuv sync\n\n# Start the server\nuv run main.py\n```\n\nThe default SSE endpoint is http://localhost:8000/sse, and you can interact with it via the MCP Inspector through SSE or any other client that supports SSE connections.\n\n### Available Tools\n\n1. **create_sandbox**: Creates a new Python Docker sandbox and returns its ID for subsequent code execution and package installation\n2. **list_sandboxes**: Lists all existing sandboxes (Docker containers) for reuse\n3. **execute_python_code**: Executes Python code in a specified Docker sandbox\n4. **install_package_in_sandbox**: Installs Python packages in a specified Docker sandbox\n5. **check_package_installation_status**: Checks if a package is installed or installation status in a Docker sandbox\n6. **execute_terminal_command**: Executes a terminal command in the specified Docker sandbox. Parameters: `sandbox_id` (string), `command` (string). Returns `stdout`, `stderr`, `exit_code`.\n7. **upload_file_to_sandbox**: Uploads a local file to the specified Docker sandbox. Parameters: `sandbox_id` (string), `local_file_path` (string), `dest_path` (string, optional, default: `/app/results`).\n\n## Project Structure\n\n```\npython-mcp-sandbox/\n├── main.py                    # Application entry point\n├── requirements.txt           # Project dependencies\n├── Dockerfile                 # Docker configuration for Python containers\n├── results/                   # Directory for generated files\n├── mcp_sandbox/               # Main package directory\n│   ├── __init__.py\n│   ├── models.py              # Pydantic models\n│   ├── api/                   # API related components\n│   │   ├── __init__.py\n│   │   └── routes.py          # API route definitions\n│   ├── core/                  # Core functionality\n│   │   ├── __init__.py\n│   │   ├── docker_manager.py  # Docker container management\n│   │   └── mcp_tools.py       # MCP tools\n│   └── utils/                 # Utilities\n│       ├── __init__.py\n│       ├── config.py          # Configuration constants\n│       ├── file_manager.py    # File management\n│       └── task_manager.py    # Periodic task management\n└── README.md                  # Project documentation\n```\n\n## Example Prompt\n```\nI've configured a Python code execution sandbox for you. You can run Python code using the following steps:\n\n1. First, use the \"list_sandboxes\" tool to view all existing sandboxes (Docker containers).\n   - You can reuse an existing sandbox_id if a sandbox exists, do not create a new one.\n   - If you need a new sandbox, use the \"create_sandbox\" tool.\n   - Each sandbox is an isolated Python environment, and the sandbox_id is required for all subsequent operations.\n\n2. If you need to install packages, use the \"install_package_in_sandbox\" tool\n   - Parameters: sandbox_id and package_name (e.g., numpy, pandas)\n   - This starts asynchronous installation and returns immediately with status\n\n3. After installing packages, you can check their installation status using the \"check_package_installation_status\" tool\n   - Parameters: sandbox_id and package_name (name of the package to check)\n   - If the package is still installing, you need to check again using this tool\n\n4. Use the \"execute_python_code\" tool to run your code\n   - Parameters: sandbox_id and code (Python code)\n   - Returns output, errors and links to any generated files\n   - All generated files are stored inside the sandbox, and file_links are direct HTTP links for inline viewing\n\nExample workflow:\n- Use list_sandboxes to check for available sandboxes, if no available sandboxes, use create_sandbox to create a new one → Get sandbox_id\n- Use install_package_in_sandbox to install necessary packages (like pandas, matplotlib), with the sandbox_id parameter\n- Use check_package_installation_status to verify package installation, with the same sandbox_id parameter\n- Use execute_python_code to run your code, with the sandbox_id parameter\n\nCode execution happens in a secure sandbox. Generated files (images, CSVs, etc.) will be provided as direct HTTP links, which can viewed inline in the browser.\n\nRemember not to use plt.show() in your Python code. For visualizations:\n- Save figures to files using plt.savefig() instead of plt.show()\n- For data, use methods like df.to_csv() or df.to_excel() to save as files\n- All saved files will automatically appear as HTTP links in the results, which you can open or embed directly.\n```\n\n## MCP Example Config\n\nBelow is an example config for claude:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcpSandbox\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"supergateway\", \"--sse\",  \"http://localhost:8000/sse\"]\n    }\n  }\n}\n```\n\n## MCP Example Config for Online Demo\n```json\n{\n  \"mcpServers\": {\n    \"mcpSandbox\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"supergateway\", \"--sse\",  \"http://115.190.87.78/sse?api_key=<API_KEY>\"]\n    }\n  }\n}\n```\n\nModify the `serverUrl` as needed for your environment.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sandbox",
        "llms",
        "execution",
        "llms execute",
        "mcp sandbox",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "KunihiroS--claude-code-mcp": {
      "owner": "KunihiroS",
      "name": "claude-code-mcp",
      "url": "https://github.com/KunihiroS/claude-code-mcp",
      "imageUrl": "https://github.com/KunihiroS.png",
      "description": "Provides tools for code explanation, review, and testing by executing commands through the Claude CLI with real-time feedback. Handles client requests in JSON format and processes commands securely.",
      "stars": 30,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-11T08:34:11Z",
      "readme_content": "# claude-code-mcp Project\n\n\n## [0.1.6] - 2025-09-11\n\n### Security Update\n- Update @anthropic-ai/claude-code version.\n\n## Overview\n\nThe claude-code-mcp project is an MCP server for Claude Code.\n\nIt calls the locally installed Claude Code command and provides the following tools: `explain_code`, `review_code`, `fix_code`, `edit_code`, `test_code`, `simulate_command`, and `your_own_query`. The server is implemented using Node.js and the MCP SDK, receiving JSON format requests from clients via stdio. Internally, it adopts Base64 encoding to smoothly process special characters (newlines, quotation marks, etc.) in natural language text, resulting in improved stability and flexibility. Its main roles are receiving requests, encoding input, generating and executing commands, and returning execution results in JSON format.\nThis project has been confirmed to work in Claude Code CLI environments (Ubuntu/WSL2, etc.).\n\n<a href=\"https://glama.ai/mcp/servers/@KunihiroS/claude-code-mcp\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@KunihiroS/claude-code-mcp/badge\" alt=\"claude-code-mcp MCP server\" />\n</a>\n\n💡\nMCP Host with less capable LLM, can tame and make use of Claude power💪!\nWith claude-code-mcp, you can also call Claude Code from Claude Desktop!! 😇😜😎 (unconfirmed)\n\n## Functions\n\nThe main roles of the server are:\n\n-   **Request Reception:** Receive JSON format tool requests from clients (e.g. `code`, `context`, `focus_areas`, etc.).\n-   **Input Processing:** Internally Base64 encode the received natural language text.\n-   **Tool Selection and Command Generation:** Based on the tool name in the request, assemble a command string for the query using a fixed template or free format (`your_own_query`).\n-   **Command Execution:** Use Node.js's `child_process.spawn` to execute the assembled command and get the result from standard output.\n-   **Result Return:** Return the execution result to the client in JSON format.\n\n## Getting Started\n\n### Prerequisites\n\n-   Node.js (>= v18 recommended, tested with v22.14.0)\n-   npm (or yarn)\n-   Claude Code command installed and auth completed.\n    https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview\n\n### Installation & Usage\n\nThere are several ways to use `claude-code-mcp`:\n\n**1. Using npx (Recommended for quick use)**\n\nYou can run the server directly without installation using `npx`:\n\n```bash\nnpx @kunihiros/claude-code-mcp\n```\n\n**2. Global Installation**\n\nInstall the package globally:\n\n```bash\nnpm install -g claude-code-mcp\n```\n\nThen, you can run it as a command:\n\n```bash\nclaude-code-mcp\n```\n\n**3. Local Installation (For development)**\n\nClone the repository and install dependencies:\n\n```bash\ngit clone https://github.com/KunihiroS/claude-code-mcp.git\ncd claude-code-mcp/claude-code-server\nnpm install\nnpm run build\n```\nYou can then run the built script directly:\n```bash\nnode build/index.js\n```\n\n### Configuration\n\n**Environment Variables:**\n\nRegardless of the installation method, you need to configure the environment variables. Create **one** of the following files:\n\n1.  **Using MCP Host Settings (Recommended for `npx`):** Configure environment variables directly within your MCP Host's settings (see \"MCP Host Configuration\" below). This is the easiest way when using `npx`.\n2.  **Using a `.env` file:** Create a `.env` file in the directory where you run the `npx @kunihiros/claude-code-mcp` command.\n3.  **Using a global config file:** Create a `.claude-code-mcp.env` file in your home directory (`~/.claude-code-mcp.env`).\n\nIf using a file (`.env` or `~/.claude-code-mcp.env`), add the following content, adjusting the `CLAUDE_BIN` path:\n\n```dotenv\n# .env or ~/.claude-code-mcp.env\nCLAUDE_BIN=/path/to/your/claude/executable  # REQUIRED: Set the full path to your Claude CLI\nLOG_LEVEL=info                             # Optional: Set log level (e.g., debug, info, warn, error)\n```\n\n**MCP Host Configuration (Recommended for `npx`):**\n\nAdd the following to your MCP Host application settings (e.g., Claude Desktop settings). This method allows you to set environment variables directly.\n\n```json\n    \"claude-code-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@kunihiros/claude-code-mcp\"\n      ],\n      \"env\": {\n        \"CLAUDE_BIN\": \"/path/to/your/claude/executable\", // REQUIRED: Set the absolute path\n        \"LOG_LEVEL\": \"info\"                             // Optional: Set log level\n      },\n      \"disabled\": false\n    }\n```\n*(Restarting the host application might be required.)*\n\n**Alternative MCP Host Configuration (Global Install / Local Dev):**\n\nIf you installed the package globally or are running it locally from the cloned repository, and the `claude-code-mcp` command is in your system's PATH, you can use:\n\n```json\n    \"claude-code-server\": {\n      \"command\": \"claude-code-mcp\",\n      \"disabled\": false\n    }\n```\nIn this case, you **must** configure environment variables using a `.env` file or the global `~/.claude-code-mcp.env` file as described above.\n\n## Environment Variables Details\n\nThis server uses the following environment variables (set via MCP Host `env` settings, `.env`, or `~/.claude-code-mcp.env`):\n\n-   `CLAUDE_BIN`: Specifies the path to the Claude CLI executable. **(Required)**\n    Example: `/home/linuxbrew/.linuxbrew/bin/claude` or `C:\\Users\\YourUser\\AppData\\Local\\bin\\claude.exe`\n-   `LOG_LEVEL`: Specifies the log level. (Optional, defaults to `info`). Possible values: `debug`, `info`, `warn`, `error`.\n\n## Available Tools\n\nThe `claude-code-mcp` server provides the following tools:\n\n- `explain_code`: Provides a detailed explanation of the given code.\n- `review_code`: Reviews the given code.\n- `fix_code`: Fixes bugs or issues in the given code.\n- `edit_code`: Edits the given code based on instructions.\n- `test_code`: Generates tests for the given code.\n- `simulate_command`: Simulates the execution of a given command.\n- `your_own_query`: Sends a custom query with context.\n\n## Note\n\n- Log file (`claude-code-mcp.log`) location:\n    - Attempts to create in the project root first.\n    - Falls back to the user's home directory (`~/.claude-code-mcp.log`).\n    - Finally falls back to `/tmp/claude-code-mcp.log`.\n- Log rotation is not implemented yet (be careful with log file size).\n- Primarily tested with Claude CLI on Ubuntu/WSL2.\n\n## License\n\nThis project is licensed under the MIT License - see below for details.\n\n```\nMIT License\n\nCopyright (c) 2024 KunihiroS\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```\n\n## Disclaimer\n\nThis software is provided for educational and research purposes only. This project is not officially associated with or endorsed by Anthropic. Claude is a trademark of Anthropic.\n\nThe project uses the Claude CLI as a dependency, but is an independent, community-driven effort. Users should ensure they comply with Anthropic's terms of service when using this project.\n\nThe maintainers of this project are not responsible for any misuse of the software or violations of the terms of service of any third-party APIs or services.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "code",
        "llms execute",
        "execute code",
        "code execution"
      ],
      "category": "code-execution"
    },
    "LaurieWired--GhidraMCP": {
      "owner": "LaurieWired",
      "name": "GhidraMCP",
      "url": "https://github.com/LaurieWired/GhidraMCP",
      "imageUrl": "https://github.com/LaurieWired.png",
      "description": "Enables autonomous reverse engineering of applications using Ghidra's analysis tools, facilitating decompilation, binary analysis, and method renaming automation. Integrates with various MCP clients to improve reverse engineering processes.",
      "stars": 6182,
      "forks": 465,
      "license": "Apache License 2.0",
      "language": "Java",
      "updated_at": "2025-10-03T20:49:46Z",
      "readme_content": "[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)\n[![GitHub release (latest by date)](https://img.shields.io/github/v/release/LaurieWired/GhidraMCP)](https://github.com/LaurieWired/GhidraMCP/releases)\n[![GitHub stars](https://img.shields.io/github/stars/LaurieWired/GhidraMCP)](https://github.com/LaurieWired/GhidraMCP/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/LaurieWired/GhidraMCP)](https://github.com/LaurieWired/GhidraMCP/network/members)\n[![GitHub contributors](https://img.shields.io/github/contributors/LaurieWired/GhidraMCP)](https://github.com/LaurieWired/GhidraMCP/graphs/contributors)\n[![Follow @lauriewired](https://img.shields.io/twitter/follow/lauriewired?style=social)](https://twitter.com/lauriewired)\n\n![ghidra_MCP_logo](https://github.com/user-attachments/assets/4986d702-be3f-4697-acce-aea55cd79ad3)\n\n\n# ghidraMCP\nghidraMCP is an Model Context Protocol server for allowing LLMs to autonomously reverse engineer applications. It exposes numerous tools from core Ghidra functionality to MCP clients.\n\nhttps://github.com/user-attachments/assets/36080514-f227-44bd-af84-78e29ee1d7f9\n\n\n# Features\nMCP Server + Ghidra Plugin\n\n- Decompile and analyze binaries in Ghidra\n- Automatically rename methods and data\n- List methods, classes, imports, and exports\n\n# Installation\n\n## Prerequisites\n- Install [Ghidra](https://ghidra-sre.org)\n- Python3\n- MCP [SDK](https://github.com/modelcontextprotocol/python-sdk)\n\n## Ghidra\nFirst, download the latest [release](https://github.com/LaurieWired/GhidraMCP/releases) from this repository. This contains the Ghidra plugin and Python MCP client. Then, you can directly import the plugin into Ghidra.\n\n1. Run Ghidra\n2. Select `File` -> `Install Extensions`\n3. Click the `+` button\n4. Select the `GhidraMCP-1-2.zip` (or your chosen version) from the downloaded release\n5. Restart Ghidra\n6. Make sure the GhidraMCPPlugin is enabled in `File` -> `Configure` -> `Developer`\n7. *Optional*: Configure the port in Ghidra with `Edit` -> `Tool Options` -> `GhidraMCP HTTP Server`\n\nVideo Installation Guide:\n\n\nhttps://github.com/user-attachments/assets/75f0c176-6da1-48dc-ad96-c182eb4648c3\n\n\n\n## MCP Clients\n\nTheoretically, any MCP client should work with ghidraMCP.  Three examples are given below.\n\n## Example 1: Claude Desktop\nTo set up Claude Desktop as a Ghidra MCP client, go to `Claude` -> `Settings` -> `Developer` -> `Edit Config` -> `claude_desktop_config.json` and add the following:\n\n```json\n{\n  \"mcpServers\": {\n    \"ghidra\": {\n      \"command\": \"python\",\n      \"args\": [\n        \"/ABSOLUTE_PATH_TO/bridge_mcp_ghidra.py\",\n        \"--ghidra-server\",\n        \"http://127.0.0.1:8080/\"\n      ]\n    }\n  }\n}\n```\n\nAlternatively, edit this file directly:\n```\n/Users/YOUR_USER/Library/Application Support/Claude/claude_desktop_config.json\n```\n\nThe server IP and port are configurable and should be set to point to the target Ghidra instance. If not set, both will default to localhost:8080.\n\n## Example 2: Cline\nTo use GhidraMCP with [Cline](https://cline.bot), this requires manually running the MCP server as well. First run the following command:\n\n```\npython bridge_mcp_ghidra.py --transport sse --mcp-host 127.0.0.1 --mcp-port 8081 --ghidra-server http://127.0.0.1:8080/\n```\n\nThe only *required* argument is the transport. If all other arguments are unspecified, they will default to the above. Once the MCP server is running, open up Cline and select `MCP Servers` at the top.\n\n![Cline select](https://github.com/user-attachments/assets/88e1f336-4729-46ee-9b81-53271e9c0ce0)\n\nThen select `Remote Servers` and add the following, ensuring that the url matches the MCP host and port:\n\n1. Server Name: GhidraMCP\n2. Server URL: `http://127.0.0.1:8081/sse`\n\n## Example 3: 5ire\nAnother MCP client that supports multiple models on the backend is [5ire](https://github.com/nanbingxyz/5ire). To set up GhidraMCP, open 5ire and go to `Tools` -> `New` and set the following configurations:\n\n1. Tool Key: ghidra\n2. Name: GhidraMCP\n3. Command: `python /ABSOLUTE_PATH_TO/bridge_mcp_ghidra.py`\n\n# Building from Source\n1. Copy the following files from your Ghidra directory to this project's `lib/` directory:\n- `Ghidra/Features/Base/lib/Base.jar`\n- `Ghidra/Features/Decompiler/lib/Decompiler.jar`\n- `Ghidra/Framework/Docking/lib/Docking.jar`\n- `Ghidra/Framework/Generic/lib/Generic.jar`\n- `Ghidra/Framework/Project/lib/Project.jar`\n- `Ghidra/Framework/SoftwareModeling/lib/SoftwareModeling.jar`\n- `Ghidra/Framework/Utility/lib/Utility.jar`\n- `Ghidra/Framework/Gui/lib/Gui.jar`\n2. Build with Maven by running:\n\n`mvn clean package assembly:single`\n\nThe generated zip file includes the built Ghidra plugin and its resources. These files are required for Ghidra to recognize the new extension.\n\n- lib/GhidraMCP.jar\n- extensions.properties\n- Module.manifest\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ghidramcp",
        "coding",
        "llms",
        "lauriewired ghidramcp",
        "ghidramcp enables",
        "llms execute"
      ],
      "category": "code-execution"
    },
    "Leghis--smart-e2b": {
      "owner": "Leghis",
      "name": "smart-e2b",
      "url": "https://github.com/Leghis/smart-e2b",
      "imageUrl": "https://github.com/Leghis.png",
      "description": "Execute JavaScript and Python code securely in cloud environments with integrated file management, session reuse for performance optimization, and automatic handling of timeouts and errors. Seamlessly compatible with Claude AI Desktop for enhanced functionality.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-04-06T13:43:54Z",
      "readme_content": "# SMART-E2B\n[![smithery badge](https://smithery.ai/badge/@Leghis/smart-e2b)](https://smithery.ai/server/@Leghis/smart-e2b)\n\nUn serveur MCP (Model Context Protocol) qui intègre E2B pour exécuter du code dans des environnements sandbox sécurisés dans le cloud, spécialement conçu pour fonctionner avec Claude AI Desktop.\n\n## Caractéristiques\n\n- Exécution sécurisée de code JavaScript et Python dans le cloud\n- Gestion de fichiers intégrée (upload, lecture, liste)\n- Réutilisation intelligente des sessions sandbox pour optimiser les performances\n- Gestion automatique des timeouts et des erreurs\n- Compatible avec Claude AI Desktop via MCP\n\n## Prérequis\n\n- Node.js (v16 ou supérieur)\n- Clé API E2B (obtenue sur [e2b.dev](https://e2b.dev))\n- Claude AI Desktop\n\n## Installation\n\n### Installing via Smithery\n\nTo install smart-e2b for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Leghis/smart-e2b):\n\n```bash\nnpx -y @smithery/cli install @Leghis/smart-e2b --client claude\n```\n\n### Installing Manually\n```bash\n# Installation globale depuis NPM\nnpm install -g smart-e2b\n\n# OU installation directe depuis GitHub\nnpm install -g git+https://github.com/Leghis/smart-e2b.git\n```\n\n## Configuration avec Claude AI Desktop\n\n1. Ouvrez Claude AI Desktop\n2. Allez dans les paramètres > onglet Développeur > Modifier la configuration\n3. Ajoutez la configuration suivante au fichier `claude_desktop_config.json` :\n\n```json\n{\n  \"mcpServers\": {\n    \"smart-e2b\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"smart-e2b\"],\n      \"env\": {\n        \"E2B_API_KEY\": \"\"\n      }\n    }\n  }\n}\n```\n\n4. Redémarrez Claude AI Desktop\n\n## Utilisation\n\nUne fois configuré, vous pourrez accéder aux outils SMART-E2B directement depuis les conversations avec Claude AI Desktop.\n\n### Outils disponibles\n\n- **executeJavaScript** : Exécute du code JavaScript dans un sandbox cloud\n- **executePython** : Exécute du code Python dans un sandbox cloud\n- **uploadFile** : Téléverse un fichier dans le sandbox\n- **listFiles** : Liste les fichiers dans un répertoire du sandbox\n- **readFile** : Lit le contenu d'un fichier dans le sandbox\n\n### Exemples\n\nVoici quelques exemples d'utilisation avec Claude AI Desktop :\n\n#### Exécution de code JavaScript\n\n```\nJe voudrais tester ce code JavaScript :\n\nfunction fibonacci(n) {\n  if (n <= 1) return n;\n  return fibonacci(n-1) + fibonacci(n-2);\n}\n\nconsole.log(fibonacci(10));\n```\n\n#### Exécution de code Python\n\n```\nPourrais-tu exécuter ce code Python pour analyser des données ?\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Générer des données aléatoires\ndata = np.random.normal(0, 1, 1000)\n\n# Calculer les statistiques\nmean = np.mean(data)\nstd = np.std(data)\n\nprint(f\"Moyenne: {mean:.4f}\")\nprint(f\"Écart-type: {std:.4f}\")\n\n# Créer un histogramme\nplt.hist(data, bins=30)\nplt.title('Distribution normale')\nplt.savefig('histogram.png')\n```\n\n## Développement\n\nPour contribuer ou modifier le projet :\n\n```bash\n# Cloner le dépôt\ngit clone https://github.com/Leghis/smart-e2b.git\ncd smart-e2b\n\n# Installer les dépendances\nnpm install\n\n# Compiler\nnpm run build\n\n# Tester localement\nnpm start\n```\n\n## Licence\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "servers",
        "execution servers",
        "llms execute",
        "code securely"
      ],
      "category": "code-execution"
    },
    "MladenSU--cli-mcp-server": {
      "owner": "MladenSU",
      "name": "cli-mcp-server",
      "url": "https://github.com/MladenSU/cli-mcp-server",
      "imageUrl": "https://github.com/MladenSU.png",
      "description": "Execute controlled command-line operations with features for command whitelisting, path validation, and execution controls to ensure secure operation.",
      "stars": 145,
      "forks": 24,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T10:58:51Z",
      "readme_content": "# CLI MCP Server\n\n---\n\nA secure Model Context Protocol (MCP) server implementation for executing controlled command-line operations with\ncomprehensive security features.\n\n![License](https://img.shields.io/badge/license-MIT-blue.svg)\n![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)\n![MCP Protocol](https://img.shields.io/badge/MCP-Compatible-green)\n[![smithery badge](https://smithery.ai/badge/cli-mcp-server)](https://smithery.ai/protocol/cli-mcp-server)\n[![Python Tests](https://github.com/MladenSU/cli-mcp-server/actions/workflows/python-tests.yml/badge.svg)](https://github.com/MladenSU/cli-mcp-server/actions/workflows/python-tests.yml)\n\n<a href=\"https://glama.ai/mcp/servers/q89277vzl1\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/q89277vzl1/badge\" /></a>\n\n---\n\n# Table of Contents\n\n1. [Overview](#overview)\n2. [Features](#features)\n3. [Configuration](#configuration)\n4. [Available Tools](#available-tools)\n    - [run_command](#run_command)\n    - [show_security_rules](#show_security_rules)\n5. [Usage with Claude Desktop](#usage-with-claude-desktop)\n    - [Development/Unpublished Servers Configuration](#developmentunpublished-servers-configuration)\n    - [Published Servers Configuration](#published-servers-configuration)\n6. [Security Features](#security-features)\n7. [Error Handling](#error-handling)\n8. [Development](#development)\n    - [Prerequisites](#prerequisites)\n    - [Building and Publishing](#building-and-publishing)\n    - [Debugging](#debugging)\n9. [License](#license)\n\n---\n\n## Overview\n\nThis MCP server enables secure command-line execution with robust security measures including command whitelisting, path\nvalidation, and execution controls. Perfect for providing controlled CLI access to LLM applications while maintaining security.\n\n## Features\n\n- 🔒 Secure command execution with strict validation\n- ⚙️ Configurable command and flag whitelisting with 'all' option\n- 🛡️ Path traversal prevention and validation\n- 🚫 Shell operator injection protection\n- ⏱️ Execution timeouts and length limits\n- 📝 Detailed error reporting\n- 🔄 Async operation support\n- 🎯 Working directory restriction and validation\n\n## Configuration\n\nConfigure the server using environment variables:\n\n| Variable             | Description                                          | Default            |\n|---------------------|------------------------------------------------------|-------------------|\n| `ALLOWED_DIR`       | Base directory for command execution (Required)      | None (Required)   |\n| `ALLOWED_COMMANDS`  | Comma-separated list of allowed commands or 'all'    | `ls,cat,pwd`      |\n| `ALLOWED_FLAGS`     | Comma-separated list of allowed flags or 'all'       | `-l,-a,--help`    |\n| `MAX_COMMAND_LENGTH`| Maximum command string length                        | `1024`            |\n| `COMMAND_TIMEOUT`   | Command execution timeout (seconds)                  | `30`              |\n| `ALLOW_SHELL_OPERATORS` | Allow shell operators (&&, \\|\\|, \\|, >, etc.)    | `false`           |\n\nNote: Setting `ALLOWED_COMMANDS` or `ALLOWED_FLAGS` to 'all' will allow any command or flag respectively.\n\n## Installation\n\nTo install CLI MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/protocol/cli-mcp-server):\n\n```bash\nnpx @smithery/cli install cli-mcp-server --client claude\n```\n\n## Available Tools\n\n### run_command\n\nExecutes whitelisted CLI commands within allowed directories.\n\n**Input Schema:**\n```json\n{\n  \"command\": {\n    \"type\": \"string\",\n    \"description\": \"Single command to execute (e.g., 'ls -l' or 'cat file.txt')\"\n  }\n}\n```\n\n**Security Notes:**\n- Shell operators (&&, |, >, >>) are not supported by default, but can be enabled with `ALLOW_SHELL_OPERATORS=true`\n- Commands must be whitelisted unless ALLOWED_COMMANDS='all'\n- Flags must be whitelisted unless ALLOWED_FLAGS='all'\n- All paths are validated to be within ALLOWED_DIR\n\n### show_security_rules\n\nDisplays current security configuration and restrictions, including:\n- Working directory\n- Allowed commands\n- Allowed flags\n- Security limits (max command length and timeout)\n\n## Usage with Claude Desktop\n\nAdd to your `~/Library/Application\\ Support/Claude/claude_desktop_config.json`:\n\n> Development/Unpublished Servers Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"cli-mcp-server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"<path/to/the/repo>/cli-mcp-server\",\n        \"run\",\n        \"cli-mcp-server\"\n      ],\n      \"env\": {\n        \"ALLOWED_DIR\": \"</your/desired/dir>\",\n        \"ALLOWED_COMMANDS\": \"ls,cat,pwd,echo\",\n        \"ALLOWED_FLAGS\": \"-l,-a,--help,--version\",\n        \"MAX_COMMAND_LENGTH\": \"1024\",\n        \"COMMAND_TIMEOUT\": \"30\",\n        \"ALLOW_SHELL_OPERATORS\": \"false\"\n      }\n    }\n  }\n}\n```\n\n> Published Servers Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"cli-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"cli-mcp-server\"\n      ],\n      \"env\": {\n        \"ALLOWED_DIR\": \"</your/desired/dir>\",\n        \"ALLOWED_COMMANDS\": \"ls,cat,pwd,echo\",\n        \"ALLOWED_FLAGS\": \"-l,-a,--help,--version\",\n        \"MAX_COMMAND_LENGTH\": \"1024\",\n        \"COMMAND_TIMEOUT\": \"30\",\n        \"ALLOW_SHELL_OPERATORS\": \"false\"\n      }\n    }\n  }\n}\n```\n> In case it's not working or showing in the UI, clear your cache via `uv clean`.\n\n## Security Features\n\n- ✅ Command whitelist enforcement with 'all' option\n- ✅ Flag validation with 'all' option\n- ✅ Path traversal prevention and normalization\n- ✅ Shell operator blocking (with opt-in support via `ALLOW_SHELL_OPERATORS=true`)\n- ✅ Command length limits\n- ✅ Execution timeouts\n- ✅ Working directory restrictions\n- ✅ Symlink resolution and validation\n\n## Error Handling\n\nThe server provides detailed error messages for:\n\n- Security violations (CommandSecurityError)\n- Command timeouts (CommandTimeoutError)\n- Invalid command formats\n- Path security violations\n- Execution failures (CommandExecutionError)\n- General command errors (CommandError)\n\n## Development\n\n### Prerequisites\n\n- Python 3.10+\n- MCP protocol library\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n    ```bash\n    uv sync\n    ```\n\n2. Build package distributions:\n    ```bash\n    uv build\n    ```\n\n   > This will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n   ```bash\n   uv publish --token {{YOUR_PYPI_API_TOKEN}}\n   ```\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with\nthis command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory {{your source code local directory}}/cli-mcp-server run cli-mcp-server\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\nFor more information or support, please open an issue on the project repository.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execute",
        "execution",
        "llms execute",
        "execution controls",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "SDGLBL--mcp-claude-code": {
      "owner": "SDGLBL",
      "name": "mcp-claude-code",
      "url": "https://github.com/SDGLBL/mcp-claude-code",
      "imageUrl": "https://github.com/SDGLBL.png",
      "description": "Enhances coding workflows by directly executing commands to modify and analyze project files. Integrates with various clients for file access and targeted code modification, with robust command execution and error handling capabilities.",
      "stars": 269,
      "forks": 31,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T12:06:21Z",
      "readme_content": "# MCP Claude Code\n\nAn implementation of Claude Code capabilities using the Model Context Protocol (MCP).\n\n## Overview\n\nThis project provides an MCP server that implements Claude Code-like functionality, allowing Claude to directly execute instructions for modifying and improving project files. By leveraging the Model Context Protocol, this implementation enables seamless integration with various MCP clients including Claude Desktop.\n\n![example](./doc/example2.gif)\n\n## Features\n\n- **Code Understanding**: Analyze and understand codebases through file access and pattern searching\n- **Code Modification**: Make targeted edits to files with proper permission handling\n- **Enhanced Command Execution**: Run commands and scripts in various languages with improved error handling and shell support\n- **File Operations**: Manage files with proper security controls through shell commands\n- **Code Discovery**: Find relevant files and code patterns across your project with high-performance searching\n- **Agent Delegation**: Delegate complex tasks to specialized sub-agents that can work concurrently\n- **Multiple LLM Provider Support**: Configure any LiteLLM-compatible model for agent operations\n- **Jupyter Notebook Support**: Read and edit Jupyter notebooks with full cell and output handling\n\n## Tools Implemented\n\n| Tool              | Description                                                                                                                       |\n| ----------------- | --------------------------------------------------------------------------------------------------------------------------------- |\n| `read`            | Read file contents with line numbers, offset, and limit capabilities                                                              |\n| `write`           | Create or overwrite files                                                                                                         |\n| `edit`            | Make line-based edits to text files                                                                                               |\n| `multi_edit`      | Make multiple precise text replacements in a single file operation with atomic transactions                                       |\n| `directory_tree`  | Get a recursive tree view of directories                                                                                          |\n| `grep`            | Fast pattern search in files with ripgrep integration for best performance ([docs](./doc/migration_SearchContentTool_to_Grep.md)) |\n| `content_replace` | Replace patterns in file contents                                                                                                 |\n| `grep_ast`        | Search code with AST context showing matches within functions, classes, and other structures                                      |\n| `run_command`     | Execute shell commands (also used for directory creation, file moving, and directory listing)                                     |\n| `notebook_read`   | Extract and read source code from all cells in a Jupyter notebook with outputs                                                    |\n| `notebook_edit`   | Edit, insert, or delete cells in a Jupyter notebook                                                                               |\n| `think`           | Structured space for complex reasoning and analysis without making changes                                                        |\n| `dispatch_agent`  | Launch one or more agents that can perform tasks using read-only tools concurrently                                               |\n| `batch`           | Execute multiple tool invocations in parallel or serially in a single request                                                     |\n| `todo_write`      | Create and manage a structured task list                                                                                          |\n| `todo_read`       | Read a structured task list                                                                                                       |\n\n## Getting Started\n\nFor detailed installation and configuration instructions, please refer to [INSTALL.md](./doc/INSTALL.md).\n\nFor detailed tutorial of 0.3 version, please refer to [TUTORIAL.md](./doc/TUTORIAL.md)\n\n## Security\n\nThis implementation follows best practices for securing access to your filesystem:\n\n- Permission prompts for file modifications and command execution\n- Restricted access to specified directories only\n- Input validation and sanitization\n- Proper error handling and reporting\n\n## Development\n\nTo contribute to this project:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "sdglbl",
        "code",
        "llms execute",
        "code execution",
        "coding agents"
      ],
      "category": "code-execution"
    },
    "Synohara--supercollider-mcp": {
      "owner": "Synohara",
      "name": "supercollider-mcp",
      "url": "https://github.com/Synohara/supercollider-mcp",
      "imageUrl": "https://github.com/Synohara.png",
      "description": "Execute SuperCollider synths using the SuperCollider programming language through an MCP server interface. Integrate audio synthesis capabilities into LLM applications on macOS with Apple Silicon, facilitating sound generation workflows utilizing supercolliderjs within the MCP framework.",
      "stars": 6,
      "forks": 3,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-14T12:32:10Z",
      "readme_content": "# SuperCollider MCP Server\n\nThe SuperCollider MCP Server is a [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server for the SuperCollider programming language that allows to execute synth using supercolliderjs.\n\n## Prerequisites\n\n1. Install [SuperCollider](https://supercollider.github.io/downloads) on your machine.\n2. Node.js and npm should be installed on your machine. You can download it from [Node.js official website](https://nodejs.org/).\n\n## Compatibility\n\nThis project has been tested and confirmed to work only on macOS with Apple Silicon (M1) processors. Compatibility with other operating systems or processor architectures has not been verified.\n\n## Installation\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-supercollider\": {\n      \"command\": [\n        \"npx\", \n        \"-y\",\n        \"@makotyo/mcp-supercollider\"]\n    }\n  }\n}\n```\n\n\n### Usage with VS Code\n\nAdd the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing Ctrl + Shift + P and typing Preferences: Open User Settings (JSON).\n\nOptionally, you can add it to a file called .vscode/mcp.json in your workspace. This will allow you to share the configuration with others.\n\n> Note that the mcp key is not needed in the .vscode/mcp.json file.\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"mcp-supercollider\": {\n        \"command\": \"npx\",\n        \"args\": [\n          \"-y\",\n          \"@makotyo/mcp-supercollider\"\n        ]\n      }\n    }\n  }\n}\n```",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "synths",
        "macos",
        "supercollider synths",
        "llm applications",
        "llms execute"
      ],
      "category": "code-execution"
    },
    "Tsuchijo--matlab-mcp": {
      "owner": "Tsuchijo",
      "name": "matlab-mcp",
      "url": "https://github.com/Tsuchijo/matlab-mcp",
      "imageUrl": "https://github.com/Tsuchijo.png",
      "description": "Integrate with MATLAB to create and execute MATLAB scripts and functions via MCP clients. Supports automation of MATLAB programming tasks within various applications.",
      "stars": 32,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-26T18:58:11Z",
      "readme_content": "# MATLAB MCP Server\n\nThis Model Context Protocol (MCP) server provides integration with MATLAB, allowing you to create and execute MATLAB scripts and functions through Claude or other MCP clients.\n\n## Setup Requirements\n\n- Python 3.11 (Python 3.13 and 3.12 are not currently supported by MATLAB Engine)\n- MATLAB R2024a (or compatible version)\n- uv package manager\n\n## Installation\n\n1. Create and set up the Python environment:\n```bash\n# Pin Python version\nuv python pin 3.11\n\n# Create virtual environment\nuv venv\n\n# Activate virtual environment\nsource .venv/bin/activate\n\n# Install MCP\nuv add \"mcp[cli]\"\n```\n\n2. Install MATLAB Engine\nThe MATLAB Engine will be installed automatically when the server first runs, using the MATLAB installation specified in the `MATLAB_PATH` environment variable.\n\n## Directory Structure\n\n- `matlab_server.py`: The main MCP server implementation\n- `matlab_scripts/`: Directory where all MATLAB scripts and functions are saved (created automatically)\n- `pyproject.toml`: Python project configuration\n- `.python-version`: Specifies Python version for uv\n\n## Claude Desktop Integration\n\n1. Open your Claude Desktop configuration:\n```bash\n# On macOS\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n2. Add the MATLAB server configuration:\n```json\n{\n    \"mcpServers\": {\n        \"matlab\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/matlab-mcp\",\n                \"run\",\n                \"matlab_server.py\"\n            ],\n            \"env\": {\n                \"MATLAB_PATH\": \"/Applications/MATLAB_R2024a.app\"\n            }\n        }\n    }\n}\n```\n\nMake sure to:\n- Replace `/absolute/path/to/matlab-mcp` with the actual path to your project directory\n- Verify the `MATLAB_PATH` points to your MATLAB installation\n- Use absolute paths (not relative)\n\n## Features\n\nThe server provides several tools:\n\n1. `create_matlab_script`: Create a new MATLAB script file\n   - Scripts are saved in the `matlab_scripts` directory\n   - File names must be valid MATLAB identifiers\n\n2. `create_matlab_function`: Create a new MATLAB function file\n   - Functions are saved in the `matlab_scripts` directory\n   - Must include valid function definition\n\n3. `execute_matlab_script`: Run a MATLAB script and get results\n   - Returns output text, generated figures, and workspace variables\n   - Can pass arguments to scripts\n\n4. `call_matlab_function`: Call a MATLAB function with arguments\n   - Returns function output and any generated figures\n\n## Testing\n\nYou can test the server using the MCP Inspector:\n```bash\n# Make sure you're in your virtual environment\nsource .venv/bin/activate\n\n# Run the inspector\nMATLAB_PATH=/Applications/MATLAB_R2024a.app mcp dev matlab_server.py\n```\n\nExample test script:\n```matlab\nt = 0:0.01:2*pi;\ny = sin(t);\nplot(t, y);\ntitle('Test Plot');\nxlabel('Time');\nylabel('Amplitude');\n```\n\n## Script Storage\n\n- All MATLAB scripts and functions are saved in the `matlab_scripts` directory\n- This directory is created automatically when the server starts\n- Files are named `<script_name>.m` or `<function_name>.m`\n- The directory is in the same location as `matlab_server.py`\n\n## Environment Variables\n\n- `MATLAB_PATH`: Path to your MATLAB installation\n  - Default: `/Applications/MATLAB_R2024a.app`\n  - Set in Claude Desktop config or when running directly\n\n## Troubleshooting\n\n1. **MATLAB Engine Installation Fails**\n   - Verify MATLAB_PATH is correct\n   - Try installing engine manually:\n     ```bash\n     cd $MATLAB_PATH/extern/engines/python\n     python setup.py install\n     ```\n\n2. **Python Version Issues**\n   - Make sure you're using Python 3.11\n   - Check with: `python --version`\n   - Use `uv python pin 3.11` if needed\n\n3. **Script Execution Errors**\n   - Check the `matlab_scripts` directory exists\n   - Verify script syntax is valid\n   - Look for error messages in MATLAB output\n\n## Updates and Maintenance\n\n- Keep your MATLAB installation updated\n- Update Python packages as needed: `uv pip install --upgrade mcp[cli]`\n- Check MATLAB engine compatibility when updating Python",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "matlab",
        "llms",
        "scripts",
        "matlab scripts",
        "execute matlab",
        "llms execute"
      ],
      "category": "code-execution"
    },
    "Tsuchijo--sandbox-mcp": {
      "owner": "Tsuchijo",
      "name": "sandbox-mcp",
      "url": "https://github.com/Tsuchijo/sandbox-mcp",
      "imageUrl": "https://github.com/Tsuchijo.png",
      "description": "Isolated Docker environments for executing code in various programming languages, managing package installations, and running commands within containers.",
      "stars": 11,
      "forks": 4,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-08-08T02:58:03Z",
      "readme_content": "# Sandbox MCP Server\n\nAn MCP server that provides isolated Docker environments for code execution. This server allows you to:\n- Create containers with any Docker image\n- Write and execute code in multiple programming languages\n- Install packages and set up development environments\n- Run commands in isolated containers\n\n## Prerequisites\n\n- Python 3.9 or higher\n- Docker installed and running\n- uv package manager (recommended)\n- Docker MCP server (recommended)\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone <your-repo-url>\ncd sandbox_server\n```\n\n2. Create and activate a virtual environment with uv:\n```bash\nuv venv\nsource .venv/bin/activate  # On Unix/MacOS\n# Or on Windows:\n# .venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n```bash\nuv pip install .\n```\n\n## Integration with Claude Desktop\n\n1. Open Claude Desktop's configuration file:\n- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n2. Add the sandbox server configuration:\n```json\n{\n    \"mcpServers\": {\n        \"sandbox\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/sandbox_server\",\n                \"run\",\n                \"sandbox_server.py\"\n            ],\n            \"env\": {\n                \"PYTHONPATH\": \"/absolute/path/to/sandbox_server\"\n            }\n        }\n    }\n}\n```\n\nReplace `/absolute/path/to/sandbox_server` with the actual path to your project directory.\n\n3. Restart Claude Desktop\n\n## Usage Examples\n\n### Basic Usage\n\nOnce connected to Claude Desktop, you can:\n\n1. Create a Python container:\n```\nCould you create a Python container and write a simple hello world program?\n```\n\n2. Run code in different languages:\n```\nCould you create a C program that calculates the fibonacci sequence and run it?\n```\n\n3. Install packages and use them:\n```\nCould you create a Python script that uses numpy to generate and plot some random data?\n```\n\n### Saving and Reproducing Environments\n\nThe server provides several ways to save and reproduce your development environments:\n\n#### Creating Persistent Containers\n\nWhen creating a container, you can make it persistent:\n```\nCould you create a persistent Python container with numpy and pandas installed?\n```\n\nThis will create a container that:\n- Stays running after Claude Desktop closes\n- Can be accessed directly through Docker\n- Preserves all installed packages and files\n\nThe server will provide instructions for:\n- Accessing the container directly (`docker exec`)\n- Stopping and starting the container\n- Removing it when no longer needed\n\n#### Saving Container State\n\nAfter setting up your environment, you can save it as a Docker image:\n```\nCould you save the current container state as an image named 'my-ds-env:v1'?\n```\n\nThis will:\n1. Create a new Docker image with all your:\n   - Installed packages\n   - Created files\n   - Configuration changes\n2. Provide instructions for reusing the environment\n\nYou can then share this image or use it as a starting point for new containers:\n```\nCould you create a new container using the my-ds-env:v1 image?\n```\n\n#### Generating Dockerfiles\n\nTo make your environment fully reproducible, you can generate a Dockerfile:\n```\nCould you export a Dockerfile that recreates this environment?\n```\n\nThe generated Dockerfile will include:\n- Base image specification\n- Created files\n- Template for additional setup steps\n\nYou can use this Dockerfile to:\n1. Share your environment setup with others\n2. Version control your development environment\n3. Modify and customize the build process\n4. Deploy to different systems\n\n#### Recommended Workflow\n\nFor reproducible development environments:\n\n1. Create a persistent container:\n```\nCreate a persistent Python container for data science work\n```\n\n2. Install needed packages and set up the environment:\n```\nInstall numpy, pandas, and scikit-learn in the container\n```\n\n3. Test your setup:\n```\nCreate and run a test script to verify the environment\n```\n\n4. Save the state:\n```\nSave this container as 'ds-workspace:v1'\n```\n\n5. Export a Dockerfile:\n```\nGenerate a Dockerfile for this environment\n```\n\nThis gives you multiple options for recreating your environment:\n- Use the saved Docker image directly\n- Build from the Dockerfile with modifications\n- Access the original container if needed\n\n## Security Notes\n\n- All code executes in isolated Docker containers\n- Containers are automatically removed after use\n- File systems are isolated between containers\n- Host system access is restricted\n\n## Project Structure\n\n```\nsandbox_server/\n├── sandbox_server.py     # Main server implementation\n├── pyproject.toml        # Project configuration\n└── README.md            # This file\n```\n\n## Available Tools\n\nThe server provides three main tools:\n\n1. `create_container_environment`: Creates a new Docker container with specified image\n2. `create_file_in_container`: Creates a file in a container\n3. `execute_command_in_container`: Runs commands in a container\n4. `save_container_state`: Saves the container state to a persistent container\n5. `export_dockerfile`: exports a docker file to create a persistant environment\n6. `exit_container`: closes a container to cleanup environment when finished\n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "environments",
        "execution",
        "llms execute",
        "execution servers",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "WilliamCloudQi--matlab-mcp-server": {
      "owner": "WilliamCloudQi",
      "name": "matlab-mcp-server",
      "url": "https://github.com/WilliamCloudQi/matlab-mcp-server",
      "imageUrl": "https://github.com/WilliamCloudQi.png",
      "description": "Integrates MATLAB with AI to execute MATLAB code, generate scripts from natural language descriptions, and access MATLAB documentation directly through your AI assistant.",
      "stars": 47,
      "forks": 18,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-02T17:05:56Z",
      "readme_content": "# MATLAB MCP Server\n\n\n![GitHub Logo](https://github.com/WilliamCloudQi/matlab-mcp-server/blob/main/-------matlab-mcp-----.png)\n## We welcome contributions from everyone.\n\n## A powerful MCP server that integrates MATLAB with AI, allowing you to execute MATLAB code, generate MATLAB scripts from natural language descriptions, and access MATLAB documentation directly through your AI assistant.\n\n<a href=\"https://glama.ai/mcp/servers/t3mmsdxvmd\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/t3mmsdxvmd/badge\" alt=\"MATLAB Server MCP server\" />\n</a>\n\n## Features\n\n### Resources\n- Access MATLAB documentation via `matlab://documentation/getting-started` URI\n- Get started guide with examples and usage instructions\n\n### Tools\n- `execute_matlab_code` - Execute MATLAB code and get results\n  - Run any MATLAB commands or scripts\n  - Option to save scripts for future reference\n  - View output directly in your conversation\n  \n- `generate_matlab_code` - Generate MATLAB code from natural language\n  - Describe what you want to accomplish in plain language\n  - Get executable MATLAB code in response\n  - Option to save generated scripts\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Requirements\n\n- MATLAB installed on your system\n- Node.js (v14 or higher)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MATLAB MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@WilliamCloudQi/matlab-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @WilliamCloudQi/matlab-mcp-server --client claude\n```\n\n### 1. Install the package\n\n```bash\nnpm install -g matlab-mcp-server\n```\n\nOr clone the repository and build it yourself:\n\n```bash\ngit clone https://github.com/username/matlab-mcp-server.git\ncd matlab-mcp-server\nnpm install\nnpm run build\n```\n\n### 2. Configure cline to use the server\n\nTo use with cline , add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"matlab-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/matlab-server/build/index.js\"],\n      \"env\": {\n        \"MATLAB_PATH\": \"/path/to/matlab/executable\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nReplace `/path/to/matlab/executable` with the path to your MATLAB executable:\n- Windows: Usually `C:\\\\Program Files\\\\MATLAB\\\\R2023b\\\\bin\\\\matlab.exe`\n- macOS: Usually `/Applications/MATLAB_R2023b.app/bin/matlab`\n- Linux: Usually `/usr/local/MATLAB/R2023b/bin/matlab`\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/williamcloudqi-matlab-mcp-server-badge.png)](https://mseep.ai/app/williamcloudqi-matlab-mcp-server)\n\n[![smithery badge](https://smithery.ai/badge/@WilliamCloudQi/matlab-mcp-server)](https://smithery.ai/server/@WilliamCloudQi/matlab-mcp-server)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "matlab",
        "llms",
        "coding",
        "execute matlab",
        "matlab ai",
        "matlab documentation"
      ],
      "category": "code-execution"
    },
    "YuChenSSR--symbolica-mcp": {
      "owner": "YuChenSSR",
      "name": "symbolica-mcp",
      "url": "https://github.com/YuChenSSR/symbolica-mcp",
      "imageUrl": "https://github.com/YuChenSSR.png",
      "description": "Facilitates symbolic computing, mathematical analysis, and data visualization for scientific and engineering applications using libraries like NumPy, SciPy, and Matplotlib in a containerized setup. Supports complex matrix calculations, statistical analysis, and machine learning tasks.",
      "stars": 10,
      "forks": 2,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-07-28T02:42:49Z",
      "readme_content": "# symbolica-mcp\n\nA scientific computing Model Context Protocol (MCP) server allows AI, such as Claude, to perform symbolic computing, conduct calculations, analyze data, and generate visualizations. This is particularly useful for scientific and engineering applications, including quantum computing, all within a containerized environment.\n\n## Features\n\n- Run scientific computing operations with NumPy, SciPy, SymPy, Pandas\n- Perform symbolic mathematics and solve differential equations\n- Support for linear algebra operations and matrix manipulations\n- Quantum computing analysis\n- Create data visualizations with Matplotlib and Seaborn\n- Perform machine learning operations with scikit-learn\n- Execute tensor operations and complex matrix calculations\n- Analyze data sets with statistical tools\n- Cross-platform support (automatically detects Windows, macOS, and Linux), especially for users with Mac M series chips\n- Works on both Intel/AMD (x86_64) and ARM processors\n\n## Quick Start\n\n### Using the Docker image\n\n```bash\n# Pull the image from Docker Hub\ndocker pull ychen94/computing-mcp:latest\n\n# Run the container (automatically detects host OS)\ndocker run -i --rm -v /tmp:/app/shared ychen94/computing-mcp:latest\n```\n\nFor Windows users:\n```powershell\ndocker run -i --rm -v $env:TEMP:/app/shared ychen94/computing-mcp:latest\n```\n\n### Integrating with Claude for Desktop\n\n1. Open Claude for Desktop\n2. Open Settings ➝ Developer ➝ Edit Config\n3. Add the following configuration:\n\nFor MacOS/Linux:\n```json\n{\n  \"mcpServers\": {\n    \"computing-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"/tmp:/app/shared\",\n        \"ychen94/computing-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\nFor Windows:\n```json\n{\n  \"mcpServers\": {\n    \"computing-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"%TEMP%:/app/shared\",\n        \"ychen94/computing-mcp:latest\"\n      ]\n    }\n  }\n}\n```\n\n\n\n## Examples\n\n### Tensor Products\n\n```\nCan you calculate and visualize the tensor product of two matrices? Please run:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define two matrices\nA = np.array([[1, 2], \n              [3, 4]])\nB = np.array([[5, 6],\n              [7, 8]])\n\n# Calculate tensor product using np.kron (Kronecker product)\ntensor_product = np.kron(A, B)\n\n# Display the result\nprint(\"Matrix A:\")\nprint(A)\nprint(\"\\nMatrix B:\")\nprint(B)\nprint(\"\\nTensor Product A ⊗ B:\")\nprint(tensor_product)\n\n# Create a visualization of the tensor product\nplt.figure(figsize=(8, 6))\nplt.imshow(tensor_product, cmap='viridis')\nplt.colorbar(label='Value')\nplt.title('Visualization of Tensor Product A ⊗ B')\n```\n\n### Symbolic Mathematics\n\n```\nCan you solve this differential equation? Please run:\nimport sympy as sp\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define symbolic variable\nx = sp.Symbol('x')\ny = sp.Function('y')(x)\n\n# Define the differential equation: y''(x) + 2*y'(x) + y(x) = 0\ndiff_eq = sp.Eq(sp.diff(y, x, 2) + 2*sp.diff(y, x) + y, 0)\n\n# Solve the equation\nsolution = sp.dsolve(diff_eq)\nprint(\"Solution:\")\nprint(solution)\n\n# Plot a particular solution (C1=1, C2=0)\nsolution_func = solution.rhs.subs({sp.symbols('C1'): 1, sp.symbols('C2'): 0})\nprint(\"Particular solution:\")\nprint(solution_func)\n\n# Create a numerical function we can evaluate\nsolution_lambda = sp.lambdify(x, solution_func)\n\n# Plot the solution\nx_vals = np.linspace(0, 5, 100)\ny_vals = [float(solution_lambda(x_val)) for x_val in x_vals]\n\nplt.figure(figsize=(10, 6))\nplt.plot(x_vals, y_vals)\nplt.grid(True)\nplt.title(\"Solution to y''(x) + 2*y'(x) + y(x) = 0\")\nplt.xlabel('x')\nplt.ylabel('y(x)')\nplt.show()\n```\n\n### Data Analysis\n\n```\nCan you perform a clustering analysis on this dataset? Please run:\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\n# Create a sample dataset\nnp.random.seed(42)\nn_samples = 300\n\n# Create three clusters\ncluster1 = np.random.normal(loc=[2, 2], scale=0.5, size=(n_samples//3, 2))\ncluster2 = np.random.normal(loc=[7, 7], scale=0.5, size=(n_samples//3, 2))\ncluster3 = np.random.normal(loc=[2, 7], scale=0.5, size=(n_samples//3, 2))\n\n# Combine clusters\nX = np.vstack([cluster1, cluster2, cluster3])\n\n# Create DataFrame\ndf = pd.DataFrame(X, columns=['Feature1', 'Feature2'])\nprint(df.head())\n\n# Standardize data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply KMeans clustering\nkmeans = KMeans(n_clusters=3, random_state=42)\ndf['Cluster'] = kmeans.fit_predict(X_scaled)\n\n# Plot the clusters\nplt.figure(figsize=(10, 6))\nfor cluster_id in range(3):\n    cluster_data = df[df['Cluster'] == cluster_id]\n    plt.scatter(cluster_data['Feature1'], cluster_data['Feature2'], \n                label=f'Cluster {cluster_id}', alpha=0.7)\n\n# Plot cluster centers\ncenters = scaler.inverse_transform(kmeans.cluster_centers_)\nplt.scatter(centers[:, 0], centers[:, 1], s=200, c='red', marker='X', label='Centers')\n\nplt.title('K-Means Clustering Results')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\nplt.grid(True)\n```\n\n### Quantum Computing\n\n![quantum example](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-23/UaybujIK2o3tLUtR.png)\n\n### Gallery\n\n**laser physics**:\n![laser](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-23/4t06m3iM17NXpW6O.png)\n\n**elliptic integral**:\n![elliptic integral](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-23/rvshlS2blGv7jnoi.png)\n![elliptic integral pic](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-23/oRGJIHgKQV8kMMHd.png)\n\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Permission errors with volume mounts**\n   - Ensure the mount directory exists and has appropriate permissions\n\n2. **Plot pciture files not appearing**\n   - Check the path in your host system: `/tmp` for macOS/Linux or your temp folder for Windows\n   - Verify Docker has permissions to write to the mount location\n   - check the mcp tool's output content\n     ![find the pic](https://raw.githubusercontent.com/YuChenSSR/pics/master/imgs/2025-03-23/Ik3JZeLhdptLqgq3.png)\n     then open it in the terminal or your picture viewer.\n\n      ⭐️ ⭐️\n     I use the [iterm-mcp-server](https://github.com/ferrislucas/iterm-mcp) or other terminals' mcp servers to open the file  without interrupting your workflow. \n      ⭐️ ⭐️\n\n\n\n### Support\n\nIf you encounter issues, please open a GitHub issue with:\n1. Error messages\n2. Your operating system and Docker version\n3. Steps to reproduce the problem\n\n## License\nThis project is licensed under the MIT License.   \nFor more details, please see the LICENSE file in [this project repository](https://github.com/YuChenSSR/symbolica-mcp).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "computing",
        "llms",
        "symbolic computing",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "ZbigniewTomanek--my-mcp-server": {
      "owner": "ZbigniewTomanek",
      "name": "my-mcp-server",
      "url": "https://github.com/ZbigniewTomanek/my-mcp-server",
      "imageUrl": "https://github.com/ZbigniewTomanek.png",
      "description": "Provides tools for interacting with local file systems and executing commands, allowing LLMs to access and manipulate data securely. Implements a standardized protocol for seamless integration with various AI models.",
      "stars": 24,
      "forks": 1,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-08-04T13:15:11Z",
      "readme_content": "# MCP Tools\n\nA custom Model Context Protocol (MCP) server implementation that provides file system and command execution tools for Claude Desktop and other LLM clients.\n\n## What is the Model Context Protocol?\n\nThe Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs). Much like a USB-C port provides a standardized way to connect devices to various peripherals, MCP provides a standardized way to connect AI models to different data sources and tools.\n\nThis project implements a FastMCP server with several useful tools that enable Claude and other LLMs to interact with your local file system and execute commands. It extends LLMs' capabilities with local system access in a controlled way through well-defined tool interfaces.\n\n## Key Benefits of MCP\n\n- **Standardized Integration**: MCP provides a growing list of pre-built integrations that your LLM can directly plug into\n- **Vendor Flexibility**: Easily switch between LLM providers and vendors (Claude, GPT-4o, Gemini, etc.)\n- **Security**: Best practices for securing your data within your infrastructure\n- **Tool Exposure**: Encapsulate existing tools and make them accessible to any MCP-compatible LLM client\n\n## Features\n\nThe MCP server provides the following file system and command execution tools:\n\n- **execute_shell_command**: Execute shell commands and get stdout/stderr results\n- **show_file**: View file contents with optional line range specification\n- **search_in_file**: Search for patterns in files using regular expressions\n- **edit_file**: Make precise changes to files with string replacements and line operations\n- **write_file**: Write or append content to files\n\n## MCP Architecture\n\nMCP follows a client-server architecture:\n\n- **Hosts**: LLM applications (like Claude Desktop or IDEs) that initiate connections\n- **Clients**: Maintain 1:1 connections with servers, inside the host application\n- **Servers**: Provide context, tools, and prompts to clients (this project implements a server)\n\n## Prerequisites\n\n- Python 3.10 or higher\n- An MCP-compatible client (Claude Desktop, or any other client that supports MCP)\n\n## Installation\n\n1. [Install uv](https://docs.astral.sh/uv/getting-started/installation/)\n2. Clone this repository or download the source code\n3. Run `uv run mcp install` to install the MCP server\n4. Run `which uv` to get an absolute path to the `uv` executable\n5. Update your MCP server configuration in Claude Desktop to use the absolute path to the `uv` executable\n\nMy MCP server configuration looks like this:\n\n```json\n{\n  \"globalShortcut\": \"\",\n  \"mcpServers\": {\n    \"zbigniew-mcp\": {\n      \"command\": \"/Users/zbigniewtomanek/.local/bin/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"--with\",\n        \"marker-pdf\",\n        \"mcp\",\n        \"run\",\n        \"/Users/zbigniewtomanek/PycharmProjects/my-mcp-tools/server.py\"\n      ]\n    }\n  }\n}\n```\n\n\n## Usage\n\n### Connecting from Claude Desktop\n\n1. Open Claude Desktop\n2. Connect to the MCP server using the identifier \"zbigniew-mcp\"\n\n> **Note**: While this implementation focuses on Claude Desktop, MCP is designed to be compatible with any MCP-compatible tool or LLM client, providing flexibility in implementation and integration.\n\n## Available Tools\n\n### execute_shell_command\n\nExecute shell commands safely using a list of arguments:\n\n```python\nexecute_shell_command([\"ls\", \"-la\"])\nexecute_shell_command([\"grep\", \"-r\", \"TODO\", \"./src\"])\nexecute_shell_command([\"python\", \"analysis.py\", \"--input\", \"data.csv\"])\nexecute_shell_command([\"uname\", \"-a\"])\n```\n\n### show_file\n\nView file contents with optional line range specification:\n\n```python\nshow_file(\"/path/to/file.txt\")\nshow_file(\"/path/to/file.txt\", num_lines=10)\nshow_file(\"/path/to/file.txt\", start_line=5, num_lines=10)\n```\n\n### search_in_file\n\nSearch for patterns in files using regular expressions:\n\n```python\nsearch_in_file(\"/path/to/script.py\", r\"def\\s+\\w+\\s*\\(\")\nsearch_in_file(\"/path/to/code.py\", r\"#\\s*TODO\", case_sensitive=False)\n```\n\n### edit_file\n\nMake precise changes to files:\n\n```python\n# Replace text\nedit_file(\"config.json\", replacements={\"\\\"debug\\\": false\": \"\\\"debug\\\": true\"})\n\n# Insert at line 5\nedit_file(\"script.py\", line_operations=[{\"operation\": \"insert\", \"line\": 5, \"content\": \"# New comment\"}])\n\n# Delete lines 10-15\nedit_file(\"file.txt\", line_operations=[{\"operation\": \"delete\", \"start_line\": 10, \"end_line\": 15}])\n\n# Replace line 20\nedit_file(\"file.txt\", line_operations=[{\"operation\": \"replace\", \"line\": 20, \"content\": \"Updated content\"}])\n```\n\n### write_file\n\nWrite or append content to files:\n\n```python\n# Overwrite file\nwrite_file(\"/path/to/file.txt\", \"New content\")\n\n# Append to file\nwrite_file(\"/path/to/log.txt\", \"Log entry\", mode=\"a\")\n```\n\n### fetch_page\n\nFetch the contents of a web page to a PDF (requires chromium installed) and then parses it to markdown using local LLMs:\n\n```python\nfetch_page(\"https://example.com\")\n```\n\n## Transport Mechanisms\n\nMCP supports multiple transport methods for communication between clients and servers:\n\n- **Standard Input/Output (stdio)**: Uses standard input/output for communication, ideal for local processes\n- **Server-Sent Events (SSE)**: Enables server-to-client streaming with HTTP POST requests for client-to-server communication\n\nThis implementation uses a local MCP server that communicates via text input/output.\n\n## Extending with Your Own Tools\n\nYou can easily extend this MCP server by adding new tools with the `@mcp.tool` decorator. Follow the pattern in server.py to create new tools that expose additional functionality to your LLM clients.\n\n## Related Projects\n\n- [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters): Use MCP with LangChain\n- [MCP-Bridge](https://github.com/SecretiveShell/MCP-Bridge): Map MCP tools to OpenAI's format\n\n## Security Considerations\n\nThe MCP server provides Claude with access to your local system. Be mindful of the following:\n\n- The server executes shell commands as your user\n- It can read, write, and modify files on your system\n- Consider limiting access to specific directories if security is a concern\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "code",
        "llms execute",
        "execution servers",
        "coding agents"
      ],
      "category": "code-execution"
    },
    "a2888409--CSAPP": {
      "owner": "a2888409",
      "name": "CSAPP",
      "url": "https://github.com/a2888409/CSAPP",
      "imageUrl": "https://github.com/a2888409.png",
      "description": "A high-performance HTTP server utilizing the epoll model for efficient connection and task management, supporting event-driven architecture and timer management for handling inactive connections. Includes implementations of memory allocation, a simple proxy server, and a basic shell for process management and signal handling.",
      "stars": 4,
      "forks": 3,
      "license": "No License",
      "language": "C",
      "updated_at": "2021-09-03T11:30:14Z",
      "readme_content": "# 基于epoll模型的http服务器 + CSAPP_lab\n基于epoll模型的http服务器 + CSAPP一书配套的实验中，其中3个经典实验的源码<br>\n###http：基于epoll模型的http服务器<br>\n采用epoll模型，实现了统一事件源，并通过时间堆管理定时器回收非活动连接。<br>\n通过一个线程池实现对任务的处理，然后使用状态机解析HTTP报文，请求了静态文件。<br>\n<br>\n###malloclab-handout：基于分离适配算法的内存分配器<br>\n采用双向链表结构维护分配器，每次分配一个内存块时，通过链表头指针查找到一个大小合适的块，并进行可选的分割。性能较隐式空闲链表分配器提升了大约20%。\n<br>\n###proxylab-handout：实现了一个简单的代理程序\n<br>\n###shlab-handout：Tiny Shell<br>\n实现了一个简易shell程序，主要涉及进程管理和信号处理。定义了一个数据结构管理job，实现了job的add，delete，fg，bg等功能。并正确的处理了SIGINT，SIGCHLD，SIGTSTP信号。\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "csapp",
        "servers",
        "server",
        "execution servers",
        "llms execute",
        "code execution"
      ],
      "category": "code-execution"
    },
    "alfonsograziano--node-code-sandbox-mcp": {
      "owner": "alfonsograziano",
      "name": "node-code-sandbox-mcp",
      "url": "https://github.com/alfonsograziano/node-code-sandbox-mcp",
      "imageUrl": "https://github.com/alfonsograziano.png",
      "description": "Run arbitrary JavaScript code in isolated Docker containers with the capability for on-the-fly npm dependency installation and management of sandbox sessions for flexible code execution.",
      "stars": 109,
      "forks": 23,
      "license": "No License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T20:06:51Z",
      "readme_content": "# 🐢🚀 Node.js Sandbox MCP Server\n\nNode.js server implementing the Model Context Protocol (MCP) for running arbitrary JavaScript in ephemeral Docker containers with on‑the‑fly npm dependency installation.\n\n![Website Preview](https://raw.githubusercontent.com/alfonsograziano/node-code-sandbox-mcp/master/assets/images/website_homepage.png)\n\n👉 [Look at the official website](https://jsdevai.com/)\n\n📦 [Available on Docker Hub](https://hub.docker.com/r/mcp/node-code-sandbox)\n\n## Features\n\n- Start and manage isolated Node.js sandbox containers\n- Execute arbitrary shell commands inside containers\n- Install specified npm dependencies per job\n- Run ES module JavaScript snippets and capture stdout\n- Tear down containers cleanly\n- **Detached Mode:** Keep the container alive after script execution (e.g. for long-running servers)\n\n> Note: Containers run with controlled CPU/memory limits.\n\n## Explore Cool Use Cases\n\nIf you want ideas for cool and powerful ways to use this library, check out the [use cases section on the website](https://jsdevai.com/#use-cases)\nIt contains a curated list of prompts, examples, and creative experiments you can try with the Node.js Sandbox MCP Server.\n\n## ⚠️ Prerequisites\n\nTo use this MCP server, Docker must be installed and running on your machine.\n\n**Tip:** Pre-pull any Docker images you'll need to avoid delays during first execution.\n\nExample recommended images:\n\n- node:lts-slim\n- mcr.microsoft.com/playwright:v1.55.0-noble\n- alfonsograziano/node-chartjs-canvas:latest\n\n## Getting started\n\nIn order to get started with this MCP server, first of all you need to connect it to a client (for example Claude Desktop).\n\nOnce it's running, you can test that it's fully working with a couple of test prompts:\n\n- Validate that the tool can run:\n\n  ```markdown\n  Create and run a JS script with a console.log(\"Hello World\")\n  ```\n\n  This should run a console.log and in the tool response you should be able to see Hello World.\n\n- Validate that you can install dependencies and save files\n\n  ```markdown\n  Create and run a JS script that generates a QR code for the URL `https://nodejs.org/en`, and save it as `qrcode.png` **Tip:** Use the `qrcode` package.\n  ```\n\n  This should create a file in your mounted directory (for example the Desktop) called \"qrcode.png\"\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\nYou can follow the [Official Guide](https://modelcontextprotocol.io/quickstart/user) to install this MCP server\n\n```json\n{\n  \"mcpServers\": {\n    \"js-sandbox\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\",\n        \"/var/run/docker.sock:/var/run/docker.sock\",\n        \"-v\",\n        \"$HOME/Desktop/sandbox-output:/root\",\n        \"-e\",\n        \"FILES_DIR=$HOME/Desktop/sandbox-output\",\n        \"-e\",\n        \"SANDBOX_MEMORY_LIMIT=512m\", // optional\n        \"-e\",\n        \"SANDBOX_CPU_LIMIT=0.75\", // optional\n        \"mcp/node-code-sandbox\"\n      ]\n    }\n  }\n}\n```\n\nor with NPX:\n\n```json\n{\n  \"mcpServers\": {\n    \"node-code-sandbox-mcp\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"node-code-sandbox-mcp\"],\n      \"env\": {\n        \"FILES_DIR\": \"/Users/alfonsograziano/Desktop/node-sandbox\",\n        \"SANDBOX_MEMORY_LIMIT\": \"512m\", // optional\n        \"SANDBOX_CPU_LIMIT\": \"0.75\" // optional\n      }\n    }\n  }\n}\n```\n\n> Note: Ensure your working directory points to the built server, and Docker is installed/running.\n\n### Docker\n\nRun the server in a container (mount Docker socket if needed), and pass through your desired host output directory as an env var:\n\n```shell\n# Build locally if necessary\n# docker build -t mcp/node-code-sandbox .\n\ndocker run --rm -it \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v \"$HOME/Desktop/sandbox-output\":\"/root\" \\\n  -e FILES_DIR=\"$HOME/Desktop/sandbox-output\" \\\n  -e SANDBOX_MEMORY_LIMIT=\"512m\" \\\n  -e SANDBOX_CPU_LIMIT=\"0.5\" \\\n  mcp/node-code-sandbox stdio\n```\n\nThis bind-mounts your host folder into the container at the **same absolute path** and makes `FILES_DIR` available inside the MCP server.\n\n#### Ephemeral usage – **no persistent storage**\n\n```bash\ndocker run --rm -it \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  alfonsograziano/node-code-sandbox-mcp stdio\n```\n\n### Usage with VS Code\n\n**Quick install** buttons (VS Code & Insiders):\n\nInstall js-sandbox-mcp (NPX) Install js-sandbox-mcp (Docker)\n\n**Manual configuration**: Add to your VS Code `settings.json` or `.vscode/mcp.json`:\n\n```json\n\"mcp\": {\n    \"servers\": {\n        \"js-sandbox\": {\n            \"command\": \"docker\",\n            \"args\": [\n                \"run\",\n                \"-i\",\n                \"--rm\",\n                \"-v\", \"/var/run/docker.sock:/var/run/docker.sock\",\n                \"-v\", \"$HOME/Desktop/sandbox-output:/root\", // optional\n                \"-e\", \"FILES_DIR=$HOME/Desktop/sandbox-output\",  // optional\n                \"-e\", \"SANDBOX_MEMORY_LIMIT=512m\",\n                \"-e\", \"SANDBOX_CPU_LIMIT=1\",\n                \"mcp/node-code-sandbox\"\n              ]\n        }\n    }\n}\n```\n\n## API\n\n## Tools\n\n### run_js_ephemeral\n\nRun a one-off JS script in a brand-new disposable container.\n\n**Inputs:**\n\n- `image` (string, optional): Docker image to use (default: `node:lts-slim`).\n- `code` (string, required): JavaScript source to execute.\n- `dependencies` (array of `{ name, version }`, optional): NPM packages and versions to install (default: `[]`).\n\n**Behavior:**\n\n1. Creates a fresh container.\n2. Writes your `index.js` and a minimal `package.json`.\n3. Installs the specified dependencies.\n4. Executes the script.\n5. Tears down (removes) the container.\n6. Returns the captured stdout.\n7. If your code saves any files in the current directory, these files will be returned automatically.\n   - Images (e.g., PNG, JPEG) are returned as `image` content.\n   - Other files (e.g., `.txt`, `.json`) are returned as `resource` content.\n   - Note: the file saving feature is currently available only in the ephemeral tool.\n\n> **Tip:** To get files back, simply save them during your script execution.\n\n**Example Call:**\n\n```jsonc\n{\n  \"name\": \"run_js_ephemeral\",\n  \"arguments\": {\n    \"image\": \"node:lts-slim\",\n    \"code\": \"console.log('One-shot run!');\",\n    \"dependencies\": [{ \"name\": \"lodash\", \"version\": \"^4.17.21\" }],\n  },\n}\n```\n\n**Example to save a file:**\n\n```javascript\nimport fs from 'fs/promises';\n\nawait fs.writeFile('hello.txt', 'Hello world!');\nconsole.log('Saved hello.txt');\n```\n\nThis will return the console output **and** the `hello.txt` file.\n\n### sandbox_initialize\n\nStart a fresh sandbox container.\n\n- **Input**:\n  - `image` (_string_, optional, default: `node:lts-slim`): Docker image for the sandbox\n  - `port` (_number_, optional): If set, maps this container port to the host\n- **Output**: Container ID string\n\n### sandbox_exec\n\nRun shell commands inside the running sandbox.\n\n- **Input**:\n  - `container_id` (_string_): ID from `sandbox_initialize`\n  - `commands` (_string[]_): Array of shell commands to execute\n- **Output**: Combined stdout of each command\n\n### run_js\n\nInstall npm dependencies and execute JavaScript code.\n\n- **Input**:\n  - `container_id` (_string_): ID from `sandbox_initialize`\n  - `code` (_string_): JS source to run (ES modules supported)\n  - `dependencies` (_array of `{ name, version }`_, optional, default: `[]`): npm package names → semver versions\n  - `listenOnPort` (_number_, optional): If set, leaves the process running and exposes this port to the host (**Detached Mode**)\n\n- **Behavior:**\n  1. Creates a temp workspace inside the container\n  2. Writes `index.js` and a minimal `package.json`\n  3. Runs `npm install --omit=dev --ignore-scripts --no-audit --loglevel=error`\n  4. Executes `node index.js` and captures stdout, or leaves process running in background if `listenOnPort` is set\n  5. Cleans up workspace unless running in detached mode\n\n- **Output**: Script stdout or background execution notice\n\n### sandbox_stop\n\nTerminate and remove the sandbox container.\n\n- **Input**:\n  - `container_id` (_string_): ID from `sandbox_initialize`\n- **Output**: Confirmation message\n\n### search_npm_packages\n\nSearch for npm packages by a search term and get their name, description, and a README snippet.\n\n- **Input**:\n  - `searchTerm` (_string_, required): The term to search for in npm packages. Should contain all relevant context. Use plus signs (+) to combine related terms (e.g., \"react+components\" for React component libraries).\n  - `qualifiers` (_object_, optional): Optional qualifiers to filter the search results:\n    - `author` (_string_, optional): Filter by package author name\n    - `maintainer` (_string_, optional): Filter by package maintainer name\n    - `scope` (_string_, optional): Filter by npm scope (e.g., \"@vue\" for Vue.js packages)\n    - `keywords` (_string_, optional): Filter by package keywords\n    - `not` (_string_, optional): Exclude packages matching this criteria (e.g., \"insecure\")\n    - `is` (_string_, optional): Include only packages matching this criteria (e.g., \"unstable\")\n    - `boostExact` (_string_, optional): Boost exact matches for this term in search results\n\n- **Behavior:**\n  1. Searches the npm registry using the provided search term and qualifiers\n  2. Returns up to 5 packages sorted by popularity\n  3. For each package, provides name, description, and README snippet (first 500 characters)\n\n- **Output**: JSON array containing package details with name, description, and README snippet\n\n## Usage Tips\n\n- **Session-based tools** (`sandbox_initialize` ➔ `run_js` ➔ `sandbox_stop`) are ideal when you want to:\n  - Keep a long-lived sandbox container open.\n  - Run multiple commands or scripts in the same environment.\n  - Incrementally install and reuse dependencies.\n- **One-shot execution** with `run_js_ephemeral` is perfect for:\n  - Quick experiments or simple scripts.\n  - Cases where you don't need to maintain state or cache dependencies.\n  - Clean, atomic runs without worrying about manual teardown.\n- **Detached mode** is useful when you want to:\n  - Spin up servers or long-lived services on-the-fly\n  - Expose and test endpoints from running containers\n\nChoose the workflow that best fits your use-case!\n\n## Build\n\nCompile and bundle:\n\n```shell\nnpm install\nnpm run build\n```\n\n## License\n\nMIT License\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\nDAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE\nOR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "sandbox",
        "servers",
        "llms execute",
        "code sandbox",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "apvlv--davinci-resolve-mcp": {
      "owner": "apvlv",
      "name": "davinci-resolve-mcp",
      "url": "https://github.com/apvlv/davinci-resolve-mcp",
      "imageUrl": "https://github.com/apvlv.png",
      "description": "Connect and control DaVinci Resolve projects, manage media, and execute Python code through an AI interface for enhanced video editing automation.",
      "stars": 32,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-01T19:59:09Z",
      "readme_content": "# DaVinci Resolve MCP Server\n\nA Model Context Protocol (MCP) server for interacting with DaVinci Resolve and Fusion. This server allows AI assistants like Claude to directly interact with and control DaVinci Resolve through the Model Context Protocol.\n\n## Features\n\n- Two-way communication: Connect Claude AI to DaVinci Resolve through the MCP protocol\n- Project management: Create, open, and manage DaVinci Resolve projects\n- Timeline manipulation: Create, modify, and navigate timelines\n- Media management: Import, organize, and manage media in the Media Pool\n- Fusion integration: Create and modify Fusion compositions\n- Scene inspection: Get detailed information about the current DaVinci Resolve project\n- Code execution: Run arbitrary Python code in DaVinci Resolve from Claude\n\n## Installation\n\n### Prerequisites\n\n- DaVinci Resolve Studio (version 17 or higher recommended)\n- Python 3.8 or higher\n- Claude Desktop (for AI integration)\n\n### Setup\n\n1. Clone this repository:\n   ```\n   git clone https://github.com/apvlv/davinci-resolve-mcp.git\n   cd davinci-resolve-mcp\n   ```\n\n2. Install the required dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n\n3. Install the MCP server in Claude Desktop:\n   ```\n   mcp install src/resolve_mcp/server.py\n   ```\n\n   Alternatively, you can install with the editable flag for development:\n   ```\n   mcp install src/resolve_mcp/server.py --with-editable .\n   ```\n\n## Usage\n\n### With Claude Desktop\n\n1. Start DaVinci Resolve\n2. In Claude Desktop, connect to the \"DaVinci Resolve MCP\" server\n3. You can now interact with DaVinci Resolve through Claude\n\n### With 5ire\n\n[5ire](https://5ire.app/) is an open-source cross-platform desktop AI assistant and MCP client that's compatible with this server.\n\n1. Install 5ire from [GitHub](https://github.com/nanbingxyz/5ire) or using Homebrew on macOS:\n   ```\n   brew tap brewforge/extras\n   brew install --cask 5ire\n   ```\n2. Start DaVinci Resolve\n3. In 5ire, add the DaVinci Resolve MCP server\n4. Connect to the server using your preferred AI model (OpenAI, Claude, etc.)\n5. You can now interact with DaVinci Resolve through 5ire\n\n## Available Commands\n\n### Resources (Information Retrieval)\n\n- `project://current` - Get information about the current project\n- `project://timelines` - Get a list of timelines in the current project\n- `timeline://current` - Get information about the current timeline\n- `mediapool://folders` - Get a list of folders in the media pool\n- `mediapool://current` - Get information about the current media pool folder\n- `storage://volumes` - Get a list of mounted volumes in the media storage\n- `system://status` - Get the current status of the DaVinci Resolve connection\n\n### Project Management\n\n- `create_project(name)` - Create a new DaVinci Resolve project\n- `load_project(name)` - Load an existing DaVinci Resolve project\n- `save_project()` - Save the current DaVinci Resolve project\n\n### Timeline Management\n\n- `create_timeline(name)` - Create a new timeline in the current project\n- `set_current_timeline(index)` - Set the current timeline by index (1-based)\n\n### Media Management\n\n- `import_media(file_paths)` - Import media files into the current media pool folder\n- `create_folder(name)` - Create a new folder in the current media pool folder\n- `create_timeline_from_clips(name, clip_indices)` - Create a new timeline from clips in the current media pool folder\n\n### Fusion Integration\n\n- `add_fusion_comp_to_clip(timeline_index, track_type, track_index, item_index)` - Add a Fusion composition to a clip in the timeline\n- `create_fusion_node(node_type, parameters)` - Create a specific Fusion node in the current composition\n- `create_fusion_node_chain(node_chain)` - Create a chain of connected Fusion nodes in the current composition\n\n### Page Navigation\n\n- `open_page(page_name)` - Open a specific page in DaVinci Resolve (media, edit, fusion, color, fairlight, deliver)\n\n### Advanced Operations\n\n- `execute_python(code)` - Execute arbitrary Python code in DaVinci Resolve\n- `execute_lua(script)` - Execute a Lua script in DaVinci Resolve's Fusion\n\n## Examples\n\n- \"Create a new project named 'My Documentary'\"\n- \"Import all video files from the Downloads folder\"\n- \"Create a new timeline with the selected clips\"\n- \"Apply a Fusion effect to the selected clip\"\n- \"Get information about the current project\"\n- \"Switch to the Color page\"\n- \"Save the current project\"\n- \"Create a folder named 'Raw Footage' in the media pool\"\n- \"Create a Blur node in the current Fusion composition\"\n- \"Create a Text node with the content 'Hello World'\"\n- \"Create a chain of nodes: MediaIn -> Blur -> ColorCorrector -> MediaOut\"\n\n## Technical Details\n\nThe server uses the Model Context Protocol to communicate between Claude and DaVinci Resolve. It leverages DaVinci Resolve's Python API to control the application.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "automation",
        "code",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "auchenberg--claude-code-mcp": {
      "owner": "auchenberg",
      "name": "claude-code-mcp",
      "url": "https://github.com/auchenberg/claude-code-mcp",
      "imageUrl": "https://github.com/auchenberg.png",
      "description": "Integrate software engineering capabilities through a standardized MCP interface, enabling the execution of shell commands, code analysis, and file management. This tool enhances development workflows by providing seamless access to various coding resources.",
      "stars": 173,
      "forks": 33,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-10-03T17:12:28Z",
      "readme_content": "# Claude Code MCP\n\nClaude Code MCP is an implementation of [Claude Code](https://gist.github.com/transitive-bullshit/487c9cb52c75a9701d312334ed53b20c) as a [Model Context Protocol (MCP)](https://modelcontextprotocol.io) server. This project allows you to use Claude Code's powerful software engineering capabilities through the standardized MCP interface.\n\n# ⚠️ DISCLAIMER ⚠️\nClaude Code MCP is a auto-generated project by DevinAI, who was prompted to analyse the Claude Code codebase, and generate an MCP server.\n\nThis is a proof of concept that I don't advise anyone to use.\n\n## What is Claude Code?\n\nClaude Code is Anthropic's CLI tool for software engineering tasks, powered by Claude. It provides a set of tools and capabilities that help developers with:\n\n- Code generation and editing\n- Code review and analysis\n- Debugging and troubleshooting\n- File system operations\n- Shell command execution\n- Project exploration and understanding\n\nThe original implementation is available as a JavaScript module that defines prompts and tools for interacting with Claude's API.\n\n## What is MCP?\n\nThe Model Context Protocol (MCP) is a standardized interface for AI models that enables consistent interaction patterns across different models and providers. MCP defines:\n\n- **Tools**: Functions that models can call to perform actions\n- **Resources**: External data that models can access\n- **Prompts**: Predefined conversation templates\n\nBy implementing Claude Code as an MCP server, we make its capabilities available to any MCP-compatible client, allowing for greater interoperability and flexibility.\n\n## Features\n\n- Full implementation of Claude Code functionality as an MCP server\n- Provides tools for file operations, shell commands, and code analysis\n- Exposes resources for accessing file system and environment information\n- Includes prompts for general CLI interaction and code review\n- Compatible with any MCP client\n- TypeScript implementation with full type safety\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/auchenberg/claude-code-mcp.git\ncd claude-code-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### Running as a standalone server\n\n```bash\n# Start the server\nnpm start\n```\n\n### Using with MCP clients\n\nClaude Code MCP can be used with any MCP client. Here's an example of how to connect to it using the MCP TypeScript SDK:\n\n```typescript\nimport { Client } from \"@modelcontextprotocol/sdk/client/index.js\";\nimport { StdioClientTransport } from \"@modelcontextprotocol/sdk/client/stdio.js\";\n\nconst transport = new StdioClientTransport({\n  command: \"node\",\n  args: [\"dist/index.js\"]\n});\n\nconst client = new Client(\n  {\n    name: \"example-client\",\n    version: \"1.0.0\"\n  },\n  {\n    capabilities: {\n      prompts: {},\n      resources: {},\n      tools: {}\n    }\n  }\n);\n\nawait client.connect(transport);\n\n// Use Claude Code through MCP\nconst result = await client.callTool({\n  name: \"bash\",\n  arguments: {\n    command: \"ls -la\"\n  }\n});\n\nconsole.log(result);\n```\n\n## Available Tools\n\nClaude Code MCP provides the following tools:\n\n- **bash**: Execute shell commands with security restrictions and timeout options\n- **readFile**: Read files from the filesystem with options for line offsets and limits\n- **listFiles**: List files and directories with detailed metadata\n- **searchGlob**: Search for files matching a glob pattern\n- **grep**: Search for text in files with regex pattern support\n- **think**: A no-op tool for thinking through complex problems\n- **codeReview**: Analyze and review code for bugs, security issues, and best practices\n- **editFile**: Create or edit files with specified content\n\n### Tool Details\n\n#### bash\n\n```typescript\n{\n  command: string;  // The shell command to execute\n  timeout?: number; // Optional timeout in milliseconds (max 600000)\n}\n```\n\nThe bash tool includes security restrictions that prevent execution of potentially dangerous commands like `curl`, `wget`, and others.\n\n#### readFile\n\n```typescript\n{\n  file_path: string; // The absolute path to the file to read\n  offset?: number;   // The line number to start reading from\n  limit?: number;    // The number of lines to read\n}\n```\n\n#### searchGlob\n\n```typescript\n{\n  pattern: string;  // The glob pattern to match files against\n  path?: string;    // The directory to search in (defaults to current working directory)\n}\n```\n\n#### grep\n\n```typescript\n{\n  pattern: string;   // The regular expression pattern to search for\n  path?: string;     // The directory to search in (defaults to current working directory)\n  include?: string;  // File pattern to include in the search (e.g. \"*.js\", \"*.{ts,tsx}\")\n}\n```\n\n## Available Resources\n\n- **file**: Access file contents (`file://{path}`)\n  - Provides direct access to file contents with proper error handling\n  - Returns the full text content of the specified file\n\n- **directory**: List directory contents (`dir://{path}`)\n  - Returns a JSON array of file information objects\n  - Each object includes name, path, isDirectory, size, and modified date\n\n- **environment**: Get system environment information (`env://info`)\n  - Returns information about the system environment\n  - Includes Node.js version, npm version, OS info, and environment variables\n\n## Available Prompts\n\n- **generalCLI**: General CLI prompt for Claude Code\n  - Provides a comprehensive system prompt for Claude to act as a CLI tool\n  - Includes guidelines for tone, style, proactiveness, and following conventions\n  - Automatically includes environment details\n\n- **codeReview**: Prompt for reviewing code\n  - Specialized prompt for code review tasks\n  - Analyzes code for bugs, security vulnerabilities, performance issues, and best practices\n\n- **prReview**: Prompt for reviewing pull requests\n  - Specialized prompt for PR review tasks\n  - Analyzes PR changes and provides comprehensive feedback\n\n- **initCodebase**: Initialize a new CLAUDE.md file with codebase documentation\n  - Creates documentation for build/lint/test commands and code style guidelines\n  - Useful for setting up a new project with Claude Code\n\n## Development\n\n```bash\n# Run in development mode with auto-reload\nnpm run dev\n```\n\n## Architecture\n\nClaude Code MCP is built with a modular architecture:\n\n```\nclaude-code-mcp/\n├── src/\n│   ├── server/\n│   │   ├── claude-code-server.ts  # Main server setup\n│   │   ├── tools.ts               # Tool implementations\n│   │   ├── prompts.ts             # Prompt definitions\n│   │   └── resources.ts           # Resource implementations\n│   ├── utils/\n│   │   ├── bash.ts                # Shell command utilities\n│   │   └── file.ts                # File system utilities\n│   └── index.ts                   # Entry point\n├── package.json\n├── tsconfig.json\n└── README.md\n```\n\nThe implementation follows these key principles:\n\n1. **Modularity**: Each component (tools, prompts, resources) is implemented in a separate module\n2. **Type Safety**: Full TypeScript type definitions for all components\n3. **Error Handling**: Comprehensive error handling for all operations\n4. **Security**: Security restrictions for potentially dangerous operations\n\n## Implementation Details\n\n### MCP Server Setup\n\nThe main server is set up in `claude-code-server.ts`:\n\n```typescript\nexport async function setupClaudeCodeServer(server: McpServer): Promise<void> {\n  // Set up Claude Code tools\n  setupTools(server);\n  \n  // Set up Claude Code prompts\n  setupPrompts(server);\n  \n  // Set up Claude Code resources\n  setupResources(server);\n}\n```\n\n### Tool Implementation\n\nTools are implemented using the MCP SDK's tool registration method:\n\n```typescript\nserver.tool(\n  \"toolName\",\n  \"Tool description\",\n  {\n    // Zod schema for tool arguments\n    param1: z.string().describe(\"Parameter description\"),\n    param2: z.number().optional().describe(\"Optional parameter description\")\n  },\n  async ({ param1, param2 }) => {\n    // Tool implementation\n    return {\n      content: [{ type: \"text\", text: \"Result\" }]\n    };\n  }\n);\n```\n\n### Resource Implementation\n\nResources are implemented using the MCP SDK's resource registration method:\n\n```typescript\nserver.resource(\n  \"resourceName\",\n  new ResourceTemplate(\"resource://{variable}\", { list: undefined }),\n  async (uri, variables) => {\n    // Resource implementation\n    return {\n      contents: [{\n        uri: uri.href,\n        text: \"Resource content\"\n      }]\n    };\n  }\n);\n```\n\n## License\n\nMIT\n\n## Acknowledgements\n\n- [Claude Code](https://gist.github.com/transitive-bullshit/487c9cb52c75a9701d312334ed53b20c) by Anthropic\n- [Model Context Protocol](https://modelcontextprotocol.io)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Disclaimer\n\nThis project is not officially affiliated with Anthropic. Claude Code is a product of Anthropic, and this project is an independent implementation of Claude Code as an MCP server.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "code",
        "llms execute",
        "code execution",
        "execute code"
      ],
      "category": "code-execution"
    },
    "axliupore--mcp-code-runner": {
      "owner": "axliupore",
      "name": "mcp-code-runner",
      "url": "https://github.com/axliupore/mcp-code-runner",
      "imageUrl": "https://github.com/axliupore.png",
      "description": "Execute code securely within a Docker environment while leveraging the MCP protocol. This server offers capabilities for running arbitrary code and retrieving execution results.",
      "stars": 14,
      "forks": 4,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T11:25:45Z",
      "readme_content": "# mcp-code-runner\n\n[![smithery badge](https://smithery.ai/badge/@axliupore/mcp-code-runner)](https://smithery.ai/server/@axliupore/mcp-code-runner)\n\n\n基于 MCP 协议的代码执行器，最后是通过 Docker 来进行代码执行的，所以本机上需要有 Docker 的环境.\n\n## 支持功能\n\n- [x] 支持 MCP 协议\n- [x] 支持代码执行，获得代码执行的结果\n- [ ] 获取代码执行的时间、内存等信息",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "execution",
        "llms",
        "servers",
        "execution servers",
        "llms execute",
        "code securely"
      ],
      "category": "code-execution"
    },
    "babelcloud--gbox": {
      "owner": "babelcloud",
      "name": "gbox",
      "url": "https://github.com/babelcloud/gbox",
      "imageUrl": "https://github.com/babelcloud.png",
      "description": "A self-hostable sandbox for executing commands, reading and writing files, and browsing the web across various platforms like iOS and Android. The server supports executing Linux commands and Python scripts, making it suitable for running complex analyses and generating documents like PDFs and diagrams.",
      "stars": 141,
      "forks": 43,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-10-03T22:32:23Z",
      "readme_content": "# GBOX\n\n![GBOX Animation](https://github.com/user-attachments/assets/50a6ebb4-d432-4364-b651-1738855a4b1f)\n\n**GBOX** provides environments for AI Agents to operate computer and mobile devices.\n\n![GBOX Introduction](https://github.com/user-attachments/assets/eded50bd-4498-4bca-85f8-fb3ec272e032)\n\n*Mobile Scenario:*\nYour agents can use GBOX to develop/test android apps, or run apps on the Android to complete various tasks(mobile automation).\n\n*Desktop Scenario:*\nYour agents can use GBOX to operate desktop apps such as browser, terminal, VSCode, etc(desktop automation).\n\n*MCP:* \nYou can also plug GBOX MCP to any Agent you like, such as Cursor, Claude Code. These agents will instantly get the ability to operate computer and mobile devices.\n\n## Installation\n\n### System Requirements\n\n- MacOS \n  - Version: 10.15 or later\n  - [Homebrew](https://brew.sh)\n\n> Note: Using gbox on other platforms, please check npm package [@gbox.ai/cli](https://www.npmjs.com/package/@gbox.ai/cli) for installation instructions. You can also login to [GBOX.AI](https://gbox.ai) to use web-based dashboard.\n\n### Installation Steps\n\n```bash\n# Install via Homebrew (on MacOS)\nbrew install gbox\n# Login to gbox.ai\ngbox login\n\n# Export MCP config and merge into Claude Code/Cursor\ngbox mcp export --merge-to claude-code\ngbox mcp export --merge-to cursor\n```\n\n### Command Line Usage\n\nCheck [GBOX CLI Reference](https://docs.gbox.ai/cli) for detailed usage.\n\n### SDK Usage\n\nCheck [GBOX SDK Reference](https://docs.gbox.ai/sdk) for detailed usage.\n\n## Use GBOX as a MCP Server(Login required)\n\nUsing GBOX CLI to configure MCP server to your Claude Code/Cursor:\n```bash\n# Export MCP config for Cursor\ngbox mcp export --merge-to cursor\n\n# Export MCP config for Claude Code\ngbox mcp export --merge-to claude-code --scope project\n\n```\n\nOr copy paste the following content into your Claude Code/Cursor MCP config:\n```json\n{\n  \"mcpServers\": {\n    \"gbox-android\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@gbox.ai/mcp-android-server@latest\"\n      ]\n    }\n  }\n}\n```\n> Note:\n> - Currently, GBOX MCP can only control Android environments.\n> - If you need Cursor/Claude Code to control your local Android device, please check [Register Local Device](https://docs.gbox.ai/cli/register-local-device)\n\n## Android MCP Use Cases\n\n| Use Case | Demo |\n|----------|------|\n| Claude Code Develop/Test Android App | [![Claude Code Develop/Test Android App](https://img.youtube.com/vi/IzlZFsqC4CY/maxresdefault.jpg)](https://www.youtube.com/watch?v=IzlZFsqC4CY) |\n| Claude Code Compare Prices on eCommerce Apps | [![Claude Code Compare Prices on eCommerce Apps](https://img.youtube.com/vi/Op3ZSVg-qg8/maxresdefault.jpg)](https://www.youtube.com/watch?v=Op3ZSVg-qg8) |\n\n\n## Environments\nCurrently, GBOX supports the following environments:\n- Android\n- Linux Desktop/Browser\n\n### Android Environment\nThere are three types of Android environments, you can choose based on your needs:\n\n**1. Cloud Virtual Device:** \n\nLogin to [GBOX.AI](https://gbox.ai) to get a cloud virtual device. Best for testing and development.\n\n**2. Cloud Physical Device:** \n\nLogin to [GBOX.AI](https://gbox.ai) to get a cloud physical device. Cloud physical device is a real Android phone that you can use for production scenarios.\n\n**3. Local Physical Device:** \n\nUse your own physical device [Register Local Device](https://docs.gbox.ai/cli/register-local-device). Your local device can be any Android device that have Developer Mode enabled. Best for production scenarios and personal use.\n\n### Linux Desktop/Browser Environment\n\nLogin to [GBOX.AI](https://gbox.ai) to get a Linux desktop/browser environment. Best for testing and development.\n\n## Develop gbox\n\n### Prerequisites\n\n- Go 1.21 or later\n- Make\n- pnpm (via corepack)\n- Node.js 16.13 or later\n\n### Build\n\n```bash\n# Build all components\nmake build\n\n# Create distribution package\nmake dist\n```\n\n### Running Services\n\n```bash\n# MCP Server\ncd packages/mcp-server && pnpm dev\n\n# MCP Inspector\ncd packages/mcp-server && pnpm inspect\n```\n\n### Contributing\n\nWe welcome contributions! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b username/feature-name`)\n3. Commit your changes (`git commit -m 'Add some feature'`)\n4. Push to the branch (`git push origin username/feature-name`)\n5. Open a Pull Request\n\n### Things to Know about Dev and Debug Locally\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "server",
        "servers",
        "execution servers",
        "llms execute",
        "code execution"
      ],
      "category": "code-execution"
    },
    "bazinga012--mcp_code_executor": {
      "owner": "bazinga012",
      "name": "mcp_code_executor",
      "url": "https://github.com/bazinga012/mcp_code_executor",
      "imageUrl": "https://github.com/bazinga012.png",
      "description": "Execute Python code within a specified Conda environment, enabling access to libraries and dependencies. Supports incremental code generation for handling large code blocks that may exceed token limits.",
      "stars": 191,
      "forks": 38,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-29T08:04:25Z",
      "readme_content": "# MCP Code Executor\n[![smithery badge](https://smithery.ai/badge/@bazinga012/mcp_code_executor)](https://smithery.ai/server/@bazinga012/mcp_code_executor)\n\nThe MCP Code Executor is an MCP server that allows LLMs to execute Python code within a specified Python environment. This enables LLMs to run code with access to libraries and dependencies defined in the environment. It also supports incremental code generation for handling large code blocks that may exceed token limits.\n\n<a href=\"https://glama.ai/mcp/servers/45ix8xode3\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/45ix8xode3/badge\" alt=\"Code Executor MCP server\" /></a>\n\n## Features\n\n- Execute Python code from LLM prompts\n- Support for incremental code generation to overcome token limitations\n- Run code within a specified environment (Conda, virtualenv, or UV virtualenv)\n- Install dependencies when needed\n- Check if packages are already installed\n- Dynamically configure the environment at runtime\n- Configurable code storage directory\n\n## Prerequisites\n\n- Node.js installed\n- One of the following:\n  - Conda installed with desired Conda environment created\n  - Python virtualenv\n  - UV virtualenv\n\n## Setup\n\n1. Clone this repository:\n\n```bash\ngit clone https://github.com/bazinga012/mcp_code_executor.git\n```\n\n2. Navigate to the project directory:\n\n```bash \ncd mcp_code_executor\n```\n\n3. Install the Node.js dependencies:\n\n```bash\nnpm install\n```\n\n4. Build the project:\n\n```bash\nnpm run build\n```\n\n## Configuration\n\nTo configure the MCP Code Executor server, add the following to your MCP servers configuration file:\n\n### Using Node.js\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-code-executor\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/mcp_code_executor/build/index.js\" \n      ],\n      \"env\": {\n        \"CODE_STORAGE_DIR\": \"/path/to/code/storage\",\n        \"ENV_TYPE\": \"conda\",\n        \"CONDA_ENV_NAME\": \"your-conda-env\"\n      }\n    }\n  }\n}\n```\n\n### Using Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-code-executor\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"mcp-code-executor\"\n      ]\n    }\n  }\n}\n```\n\n> **Note:** The Dockerfile has been tested with the venv-uv environment type only. Other environment types may require additional configuration.\n\n### Environment Variables\n\n#### Required Variables\n- `CODE_STORAGE_DIR`: Directory where the generated code will be stored\n\n#### Environment Type (choose one setup)\n- **For Conda:**\n  - `ENV_TYPE`: Set to `conda`\n  - `CONDA_ENV_NAME`: Name of the Conda environment to use\n\n- **For Standard Virtualenv:**\n  - `ENV_TYPE`: Set to `venv`\n  - `VENV_PATH`: Path to the virtualenv directory\n\n- **For UV Virtualenv:**\n  - `ENV_TYPE`: Set to `venv-uv`\n  - `UV_VENV_PATH`: Path to the UV virtualenv directory\n\n## Available Tools\n\nThe MCP Code Executor provides the following tools to LLMs:\n\n### 1. `execute_code`\nExecutes Python code in the configured environment. Best for short code snippets.\n```json\n{\n  \"name\": \"execute_code\",\n  \"arguments\": {\n    \"code\": \"import numpy as np\\nprint(np.random.rand(3,3))\",\n    \"filename\": \"matrix_gen\"\n  }\n}\n```\n\n### 2. `install_dependencies`\nInstalls Python packages in the environment.\n```json\n{\n  \"name\": \"install_dependencies\",\n  \"arguments\": {\n    \"packages\": [\"numpy\", \"pandas\", \"matplotlib\"]\n  }\n}\n```\n\n### 3. `check_installed_packages`\nChecks if packages are already installed in the environment.\n```json\n{\n  \"name\": \"check_installed_packages\",\n  \"arguments\": {\n    \"packages\": [\"numpy\", \"pandas\", \"non_existent_package\"]\n  }\n}\n```\n\n### 4. `configure_environment`\nDynamically changes the environment configuration.\n```json\n{\n  \"name\": \"configure_environment\",\n  \"arguments\": {\n    \"type\": \"conda\",\n    \"conda_name\": \"new_env_name\"\n  }\n}\n```\n\n### 5. `get_environment_config`\nGets the current environment configuration.\n```json\n{\n  \"name\": \"get_environment_config\",\n  \"arguments\": {}\n}\n```\n\n### 6. `initialize_code_file`\nCreates a new Python file with initial content. Use this as the first step for longer code that may exceed token limits.\n```json\n{\n  \"name\": \"initialize_code_file\",\n  \"arguments\": {\n    \"content\": \"def main():\\n    print('Hello, world!')\\n\\nif __name__ == '__main__':\\n    main()\",\n    \"filename\": \"my_script\"\n  }\n}\n```\n\n### 7. `append_to_code_file`\nAppends content to an existing Python code file. Use this to add more code to a file created with initialize_code_file.\n```json\n{\n  \"name\": \"append_to_code_file\",\n  \"arguments\": {\n    \"file_path\": \"/path/to/code/storage/my_script_abc123.py\",\n    \"content\": \"\\ndef another_function():\\n    print('This was appended to the file')\\n\"\n  }\n}\n```\n\n### 8. `execute_code_file`\nExecutes an existing Python file. Use this as the final step after building up code with initialize_code_file and append_to_code_file.\n```json\n{\n  \"name\": \"execute_code_file\",\n  \"arguments\": {\n    \"file_path\": \"/path/to/code/storage/my_script_abc123.py\"\n  }\n}\n```\n\n### 9. `read_code_file`\nReads the content of an existing Python code file. Use this to verify the current state of a file before appending more content or executing it.\n```json\n{\n  \"name\": \"read_code_file\",\n  \"arguments\": {\n    \"file_path\": \"/path/to/code/storage/my_script_abc123.py\"\n  }\n}\n```\n\n## Usage\n\nOnce configured, the MCP Code Executor will allow LLMs to execute Python code by generating a file in the specified `CODE_STORAGE_DIR` and running it within the configured environment.\n\nLLMs can generate and execute code by referencing this MCP server in their prompts.\n\n### Handling Large Code Blocks\n\nFor larger code blocks that might exceed LLM token limits, use the incremental code generation approach:\n\n1. **Initialize a file** with the basic structure using `initialize_code_file`\n2. **Add more code** in subsequent calls using `append_to_code_file`\n3. **Verify the file content** if needed using `read_code_file`\n4. **Execute the complete code** using `execute_code_file`\n\nThis approach allows LLMs to write complex, multi-part code without running into token limitations.\n\n## Backward Compatibility\n\nThis package maintains backward compatibility with earlier versions. Users of previous versions who only specified a Conda environment will continue to work without any changes to their configuration.\n\n## Contributing\n\nContributions are welcome! Please open an issue or submit a pull request.\n\n## License\n\nThis project is licensed under the MIT License.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_code_executor",
        "llms",
        "coding",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "biegehydra--BifrostMCP": {
      "owner": "biegehydra",
      "name": "BifrostMCP",
      "url": "https://github.com/biegehydra/BifrostMCP",
      "imageUrl": "https://github.com/biegehydra.png",
      "description": "Expose VSCode's development tools and language features to AI tools, enabling advanced code navigation, analysis, and manipulation. Seamlessly integrates with the development environment to enhance productivity and efficiency when working with AI coding assistants.",
      "stars": 175,
      "forks": 31,
      "license": "GNU Affero General Public License v3.0",
      "language": "TypeScript",
      "updated_at": "2025-10-03T04:12:56Z",
      "readme_content": "# Bifrost - VSCode Dev Tools MCP Server\n<a href=\"https://marketplace.visualstudio.com/items?itemName=ConnorHallman.bifrost-mcp\">\n  <img src=\"https://img.shields.io/visual-studio-marketplace/d/ConnorHallman.bifrost-mcp?label=VSCode%20Extension%20Downloads&cacheSeconds=3600\" \n       alt=\"VSCode Extension Downloads\" \n       width=\"250\">\n</a>\n\nThis VS Code extension provides a Model Context Protocol (MCP) server that exposes VSCode's powerful development tools and language features to AI tools. It enables advanced code navigation, analysis, and manipulation capabilities when using AI coding assistants that support the MCP protocol.\n\n![image](https://raw.githubusercontent.com/biegehydra/BifrostMCP/refs/heads/master/src/images/cursor.png)\n\n## Table of Contents\n- [Features](#features)\n- [Installation/Usage](#usage)\n- [Multi-Project Support](#multiple-project-support)\n- [Available Tools](#available-tools)\n- [Available Commands](#available-commands)\n- [Troubleshooting](#troubleshooting)\n- [Contributing](#contributing)\n- [Debugging](#debugging)\n- [License](#license)\n\n## Features\n\n- **Language Server Integration**: Access VSCode's language server capabilities for any supported language\n- **Code Navigation**: Find references, definitions, implementations, and more\n- **Symbol Search**: Search for symbols across your workspace\n- **Code Analysis**: Get semantic tokens, document symbols, and type information\n- **Smart Selection**: Use semantic selection ranges for intelligent code selection\n- **Code Actions**: Access refactoring suggestions and quick fixes\n- **HTTP/SSE Server**: Exposes language features over an MCP-compatible HTTP server\n- **AI Assistant Integration**: Ready to work with AI assistants that support the MCP protocol\n\n## Usage\n\n### Installation\n\n1. Install [the extension](https://marketplace.visualstudio.com/items?itemName=ConnorHallman.bifrost-mcp) from the VS Code marketplace\n2. Install any language-specific extensions you need for your development\n3. Open your project in VS Code\n\n### Configuration\n\nThe extension will automatically start an MCP server when activated. To configure an AI assistant to use this server:\n\n1. The server runs on port 8008 by default (configurable with `bifrost.config.json`)\n2. Configure your MCP-compatible AI assistant to connect to:\n   - SSE endpoint: `http://localhost:8008/sse`\n   - Message endpoint: `http://localhost:8008/message`\n\n### LLM Rules\nI have also provided sample rules that can be used in .cursorrules files for better results.\n\n[Example Cursor Rules](https://github.com/biegehydra/BifrostMCP/blob/master/ExampleCursorRules.md)\n\n[Example MDC Rules](https://github.com/biegehydra/BifrostMCP/blob/master/example.mdc)\n\n### Cline Installation\n- Step 1. Install [Supergateway](https://github.com/supercorp-ai/supergateway)\n- Step 2. Add config to cline\n- Step 3. It will show up red but seems to work fine\n\n#### Windows Config\n```json\n{\n  \"mcpServers\": {\n    \"Bifrost\": {\n      \"command\": \"cmd\",\n      \"args\": [\n        \"/c\",\n        \"npx\",\n        \"-y\",\n        \"supergateway\",\n        \"--sse\",\n        \"http://localhost:8008/sse\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": [],\n      \"timeout\": 600\n    }\n  }\n}\n```\n\n#### Mac/Linux Config\n```json\n{\n  \"mcpServers\": {\n    \"Bifrost\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"supergateway\",\n        \"--sse\",\n        \"http://localhost:8008/sse\"\n      ],\n      \"disabled\": false,\n      \"autoApprove\": [],\n      \"timeout\": 600\n    }\n  }\n}\n```\n\n### Roo Code Installation\n- Step 1: Add the SSE config to your global or project-based MCP configuration\n```json\n{\n  \"mcpServers\": {\n    \"Bifrost\": {\n      \"url\": \"http://localhost:8008/sse\"\n    }\n  }\n}\n```\n\n![Screenshot_78](https://github.com/user-attachments/assets/55588c9e-7f88-4830-b87f-184018873ca1)\n\nFollow this video to install and use with cursor\n\n#### FOR NEW VERSIONS OF CURSOR, USE THIS CODE\n```json\n{\n  \"mcpServers\": {\n    \"Bifrost\": {\n      \"url\": \"http://localhost:8008/sse\"\n    }\n  }\n}\n```\n\n## Multiple Project Support\n\nWhen working with multiple projects, each project can have its own dedicated MCP server endpoint and port. This is useful when you have multiple VS Code windows open or are working with multiple projects that need language server capabilities.\n\n### Project Configuration\n\nCreate a `bifrost.config.json` file in your project root:\n\n```json\n{\n    \"projectName\": \"MyProject\",\n    \"description\": \"Description of your project\",\n    \"path\": \"/my-project\",\n    \"port\": 5642\n}\n```\n\nThe server will use this configuration to:\n- Create project-specific endpoints (e.g., `http://localhost:5642/my-project/sse`)\n- Provide project information to AI assistants\n- Use a dedicated port for each project\n- Isolate project services from other running instances\n\n### Example Configurations\n\n1. Backend API Project:\n```json\n{\n    \"projectName\": \"BackendAPI\",\n    \"description\": \"Node.js REST API with TypeScript\",\n    \"path\": \"/backend-api\",\n    \"port\": 5643\n}\n```\n\n2. Frontend Web App:\n```json\n{\n    \"projectName\": \"FrontendApp\",\n    \"description\": \"React frontend application\",\n    \"path\": \"/frontend-app\",\n    \"port\": 5644\n}\n```\n\n### Port Configuration\n\nEach project should specify its own unique port to avoid conflicts when multiple VS Code instances are running:\n\n- The `port` field in `bifrost.config.json` determines which port the server will use\n- If no port is specified, it defaults to 8008 for backwards compatibility\n- Choose different ports for different projects to ensure they can run simultaneously\n- The server will fail to start if the configured port is already in use, requiring you to either:\n  - Free up the port\n  - Change the port in the config\n  - Close the other VS Code instance using that port\n\n### Connecting to Project-Specific Endpoints\n\nUpdate your AI assistant configuration to use the project-specific endpoint and port:\n\n```json\n{\n  \"mcpServers\": {\n    \"BackendAPI\": {\n      \"url\": \"http://localhost:5643/backend-api/sse\"\n    },\n    \"FrontendApp\": {\n      \"url\": \"http://localhost:5644/frontend-app/sse\"\n    }\n  }\n}\n```\n\n### Backwards Compatibility\n\nIf no `bifrost.config.json` is present, the server will use the default configuration:\n- Port: 8008\n- SSE endpoint: `http://localhost:8008/sse`\n- Message endpoint: `http://localhost:8008/message`\n\nThis maintains compatibility with existing configurations and tools.\n\n## Available Tools\n\nThe extension provides access to many VSCode language features including:\n\n* **find\\_usages**: Locate all symbol references.\n* **go\\_to\\_definition**: Jump to symbol definitions instantly.\n* **find\\_implementations**: Discover implementations of interfaces/abstract methods.\n* **get\\_hover\\_info**: Get rich symbol docs on hover.\n* **get\\_document\\_symbols**: Outline all symbols in a file.\n* **get\\_completions**: Context-aware auto-completions.\n* **get\\_signature\\_help**: Function parameter hints and overloads.\n* **get\\_rename\\_locations**: Safely get location of places to perform a rename across the project.\n* **rename**: Perform rename on a symbol\n* **get\\_code\\_actions**: Quick fixes, refactors, and improvements.\n* **get\\_semantic\\_tokens**: Enhanced highlighting data.\n* **get\\_call\\_hierarchy**: See incoming/outgoing call relationships.\n* **get\\_type\\_hierarchy**: Visualize class and interface inheritance.\n* **get\\_code\\_lens**: Inline insights (references, tests, etc.).\n* **get\\_selection\\_range**: Smart selection expansion for code blocks.\n* **get\\_type\\_definition**: Jump to underlying type definitions.\n* **get\\_declaration**: Navigate to symbol declarations.\n* **get\\_document\\_highlights**: Highlight all occurrences of a symbol.\n* **get\\_workspace\\_symbols**: Search symbols across your entire workspace.\n\n## Requirements\n\n- Visual Studio Code version 1.93.0 or higher\n- Appropriate language extensions for the languages you want to work with (e.g., C# extension for C# files)\n\n### Available Commands\n\n- `Bifrost MCP: Start Server` - Manually start the MCP server on port 8008\n- `Bifrost MCP: Start Server on port` - Manually start the MCP server on specified port\n- `Bifrost MCP: Stop Server` - Stop the running MCP server\n- `Bifrost MCP: Open Debug Panel` - Open the debug panel to test available tools\n\n![image](https://raw.githubusercontent.com/biegehydra/BifrostMCP/refs/heads/master/src/images/commands.png)\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=biegehydra/BifrostMCP&type=Date)](https://star-history.com/#biegehydra/BifrostMCP&Date)\n\n## Example Tool Usage\n\n### Find References\n```json\n{\n  \"name\": \"find_usages\",\n  \"arguments\": {\n    \"textDocument\": {\n      \"uri\": \"file:///path/to/your/file\"\n    },\n    \"position\": {\n      \"line\": 10,\n      \"character\": 15\n    },\n    \"context\": {\n      \"includeDeclaration\": true\n    }\n  }\n}\n```\n\n### Workspace Symbol Search\n```json\n{\n  \"name\": \"get_workspace_symbols\",\n  \"arguments\": {\n    \"query\": \"MyClass\"\n  }\n}\n```\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. Ensure you have the appropriate language extensions installed for your project\n2. Check that your project has loaded correctly in VSCode\n3. Verify that port 8008 is available on your system\n4. Check the VSCode output panel for any error messages\n\n## Contributing\nHere are [Vscodes commands](https://github.com/microsoft/vscode-docs/blob/main/api/references/commands.md?plain=1) if you want to add additional functionality go ahead. I think we still need rename and a few others.\nPlease feel free to submit issues or pull requests to the [GitHub repository](https://github.com/biegehydra/csharplangmcpserver).\n\n`vsce package`\n\n## Debugging\nUse the `MCP: Open Debug Panel` command\n![image](https://raw.githubusercontent.com/biegehydra/BifrostMCP/refs/heads/master/src/images/debug_panel.png)\n\n## License\n\nThis extension is licensed under the APGL-3.0 License.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vscode",
        "coding",
        "llms",
        "vscode development",
        "llms execute",
        "coding agents"
      ],
      "category": "code-execution"
    },
    "block--vscode-mcp": {
      "owner": "block",
      "name": "vscode-mcp",
      "url": "https://github.com/block/vscode-mcp",
      "imageUrl": "https://github.com/block.png",
      "description": "Enables AI agents to interact with VS Code for tasks such as modifying files, opening projects, and checking extension statuses. This facilitates a more efficient integration of AI assistance into the coding environment.",
      "stars": 74,
      "forks": 13,
      "license": "Apache License 2.0",
      "language": "TypeScript",
      "updated_at": "2025-09-14T07:44:46Z",
      "readme_content": "# VSCode MCP\n\nThis monorepo contains the VSCode MCP Server and its companion VSCode Extension, which together enable AI agents and assistants, like Goose or Claude, to interact with VSCode through the Model Context Protocol.\n\n## Project Structure\n\n```\nvscode-mcp/\n├── server/    # MCP server implementation\n└── extension/ # VS Code extension\n```\n\n## Quick Start\n\n1. Install the MCP Server\n\n```bash\nnpx vscode-mcp-server install\n```\n\n2. Install the MCP Extension\n\n> [MCP Extension](https://marketplace.visualstudio.com/items?itemName=block.vscode-mcp-extension)\n\n## Configuration\n\n### Goose Desktop Setup\n\n![Goose Settings](assets/GooseSettings.png)\n\n- ID: `code-mcp`\n- Name: `VS Code`\n- Description: `Allows interaction with VS Code through the Model Context Protocol`\n- Command: `npx vscode-mcp-server`\n\n### Claude Desktop Setup\n\nAdd this to your Claude Desktop config file (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"vscode-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"vscode-mcp-server\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n## Available Tools\n\nThe Code MCP server provides the following tools for AI agents to interact with VS Code:\n\n### `create_diff`\n\nCreates and shows a diff for modifying existing files:\n\n- Shows changes preview before applying\n- Requires user approval\n- Only works with existing files\n\n### `open_file`\n\nOpens files in the VS Code editor:\n\n- Used for viewing new or modified files\n\n### `open_project`\n\nOpens a project folder in VS Code:\n\n- Sets up working directory for AI agent\n\n### `check_extension_status`\n\nChecks if extension is installed and responding\n\n### `get_extension_port`\n\nGets the port number for VS Code MCP Extension\n\n### `list_available_projects`\n\nShows projects from port registry file\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.\n\nCopyright 2025 Block, Inc.\n\nThis product includes software developed at [Block, Inc.](https://block.xyz/)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vscode",
        "coding",
        "code",
        "vs code",
        "block vscode",
        "vscode mcp"
      ],
      "category": "code-execution"
    },
    "bmorphism--babashka-mcp-server": {
      "owner": "bmorphism",
      "name": "babashka-mcp-server",
      "url": "https://github.com/bmorphism/babashka-mcp-server",
      "imageUrl": "https://github.com/bmorphism.png",
      "description": "Execute Babashka (Clojure) scripts, manage command execution, cache command results, and access command history while utilizing configurable command timeouts.",
      "stars": 15,
      "forks": 4,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-25T16:17:50Z",
      "readme_content": "# Babashka MCP Server\n\nA Model Context Protocol server for interacting with [Babashka](https://github.com/babashka/babashka), a native Clojure interpreter for scripting.\n\n## Features\n\n- Execute Babashka code through MCP tools\n- Cache recent command results\n- Access command history through MCP resources\n- Configurable command timeouts\n\n## Prerequisites\n\n### Install Babashka\n\nBabashka can be installed in several ways:\n\n#### macOS\n```bash\nbrew install borkdude/brew/babashka\n```\n\n#### Linux\n```bash\nbash < <(curl -s https://raw.githubusercontent.com/babashka/babashka/master/install)\n```\n\n#### Windows\n```powershell\n# Using scoop\nscoop install babashka\n```\n\nFor other installation methods, see the [official Babashka installation guide](https://github.com/babashka/babashka#installation).\n\n### Verify Installation\n\nAfter installation, verify Babashka works:\n```bash\n# Check version\nbb --version\n\n# Try a simple expression\nbb -e '(+ 1 2 3)'\n\n# Run a script from string\nbb -e '(defn hello [x] (str \"Hello, \" x \"!\")) (hello \"World\")'\n\n# Use -i flag to process lines of input\nls | bb -i '(take 2 *input*)'\n```\n\n## Installation\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the MCP server\nnpm run build\n```\n\n## Configuration\n\nThe server can be configured through environment variables:\n\n- `BABASHKA_PATH`: Path to the Babashka executable (default: \"bb\")\n\n## Tools\n\n### execute\n\nExecute Babashka code with optional timeout:\n\n```typescript\n{\n  name: \"execute\",\n  arguments: {\n    code: string;      // Babashka code to execute\n    timeout?: number;  // Timeout in milliseconds (default: 30000)\n  }\n}\n```\n\nExample:\n```typescript\n{\n  name: \"execute\",\n  arguments: {\n    code: \"(+ 1 2 3)\",\n    timeout: 5000\n  }\n}\n```\n\n## Resources\n\nThe server maintains a cache of recent command executions accessible through:\n\n- `babashka://commands/{index}` - Access specific command results by index\n\n## Babashka Language Features\n\n### Tail Call Optimization (TCO)\n\nBabashka supports explicit tail call optimization through the `recur` special form, but does not implement automatic TCO. For example:\n\n```clojure\n;; This will cause stack overflow\n(defn countdown [n]\n  (if (zero? n)\n    :done\n    (countdown (dec n))))\n\n;; This works with TCO using recur\n(defn countdown [n]\n  (if (zero? n)\n    :done\n    (recur (dec n))))\n```\n\n## Useful Resources\n\n### Official Resources\n- [Babashka GitHub Repository](https://github.com/babashka/babashka) - The main Babashka project\n- [Babashka Book](https://book.babashka.org) - Official documentation\n- [Babashka Examples](https://github.com/babashka/babashka/blob/master/doc/examples.md) - Collection of example scripts\n\n### Community Tools & Libraries\n- [pod-babashka-buddy](https://github.com/babashka/pod-babashka-buddy) - Cryptographic API for Babashka\n- [bb-clis](https://github.com/cldwalker/bb-clis) - Collection of useful Babashka CLI scripts\n- [bb-scripts](https://github.com/vedang/bb-scripts) - Various utility scripts for Babashka\n\n### Development Tools\n- [setup-babashka](https://github.com/turtlequeue/setup-babashka) - GitHub Actions for installing Babashka\n- [babashka-docker-action](https://github.com/tzafrirben/babashka-docker-action) - Run Babashka scripts in GitHub Actions\n\n## Development\n\nThis server is designed to eventually become self-hosting, meaning it will be rewritten in Babashka itself. The current TypeScript implementation serves as a reference and starting point.\n\n## Roadmap\n\n1. **Self-Hosted Implementation**\n   - Rewrite the MCP server in Babashka\n   - Leverage Babashka's native capabilities for better performance\n   - Remove Node.js dependency\n   - Maintain full compatibility with MCP protocol\n   - Support all current features:\n     - Command execution\n     - Resource management\n     - Command history\n     - Timeout handling\n\n2. **Enhanced Features**\n   - Add support for Babashka pods\n   - Implement file watching capabilities\n   - Add REPL integration\n   - Support for multiple Babashka instances\n\n3. **Performance Optimizations**\n   - Implement caching strategies\n   - Optimize resource usage\n   - Reduce startup time\n\n4. **Testing & Documentation**\n   - Comprehensive test suite\n   - API documentation\n   - Usage examples\n   - Performance benchmarks\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "clojure",
        "llms",
        "scripts",
        "llms execute",
        "execution servers",
        "clojure scripts"
      ],
      "category": "code-execution"
    },
    "cfdude--super-shell-mcp": {
      "owner": "cfdude",
      "name": "super-shell-mcp",
      "url": "https://github.com/cfdude/super-shell-mcp",
      "imageUrl": "https://github.com/cfdude.png",
      "description": "Execute shell commands securely across Windows, macOS, and Linux platforms using automatic shell detection and command management. Features include whitelisting of commands with varying security levels and comprehensive logging for command execution.",
      "stars": 7,
      "forks": 6,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-09-16T13:49:16Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/cfdude-super-shell-mcp-badge.png)](https://mseep.ai/app/cfdude-super-shell-mcp)\n\n# Super Shell MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@cfdude/super-shell-mcp)](https://smithery.ai/package/@cfdude/super-shell-mcp)\n\nAn MCP (Model Context Protocol) server for executing shell commands across multiple platforms (Windows, macOS, Linux). This server provides a secure way to execute shell commands with built-in whitelisting and approval mechanisms.\n\n> 🎉 **Now available as a Claude Desktop Extension!** Install with one click using the `.dxt` package - no developer tools or configuration required.\n\n## Features\n\n- Execute shell commands through MCP on Windows, macOS, and Linux\n- Automatic platform detection and shell selection\n- Support for multiple shells:\n  - **Windows**: cmd.exe, PowerShell\n  - **macOS**: zsh, bash, sh\n  - **Linux**: bash, sh, zsh\n- Command whitelisting with security levels:\n  - **Safe**: Commands that can be executed without approval\n  - **Requires Approval**: Commands that need explicit approval before execution\n  - **Forbidden**: Commands that are explicitly blocked\n- Platform-specific command whitelists\n- Non-blocking approval workflow for potentially dangerous commands\n- Comprehensive logging system with file-based logs\n- Comprehensive command management tools\n- Platform information tool for diagnostics\n\n## Installation\n\n### Option 1: Claude Desktop Extension (.dxt) - Recommended\n\n**One-Click Installation for Claude Desktop:**\n\n1. **Download** the `super-shell-mcp.dxt` file from the [latest release](https://github.com/cfdude/super-shell-mcp/releases)\n2. **Quick Install**: Double-click the `.dxt` file while Claude Desktop is open\n   \n   **OR**\n   \n   **Manual Install**: \n   - Open Claude Desktop\n   - Go to **Settings** > **Extensions**\n   - Click **\"Add Extension\"**\n   - Select the downloaded `super-shell-mcp.dxt` file\n\n3. **Configure** (optional): Set custom shell path if needed\n4. **Start using** - The extension is ready to use immediately!\n\n✅ **Benefits of DXT Installation:**\n- No developer tools required (Node.js, Python, etc.)\n- No manual configuration files\n- Automatic dependency management\n- One-click installation and updates\n- Secure credential storage in OS keychain\n\n### Option 2: Installing via Smithery\n\nTo install Super Shell MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/package/@cfdude/super-shell-mcp):\n\n```bash\nnpx -y @smithery/cli install @cfdude/super-shell-mcp --client claude\n```\n\n### Option 3: Installing Manually\n\n```bash\n# Clone the repository\ngit clone https://github.com/cfdude/super-shell-mcp.git\ncd super-shell-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### For Claude Desktop Extension Users (.dxt)\n\nIf you installed using the `.dxt` extension (Option 1), **you're ready to go!** No additional configuration needed. The extension handles everything automatically:\n\n- ✅ **Automatic startup** when Claude Desktop launches\n- ✅ **Platform detection** and appropriate shell selection  \n- ✅ **Built-in security** with command whitelisting and approval workflows\n- ✅ **Optional configuration** via Claude Desktop's extension settings\n\n### For Manual Installation Users\n\nIf you installed manually (Option 2 or 3), you'll need to configure Claude Desktop or your MCP client:\n\n#### Starting the Server Manually\n\n```bash\nnpm start\n```\n\nOr directly:\n\n```bash\nnode build/index.js\n```\n\n#### Manual Configuration for MCP Clients\n\nFor manual installations, both Roo Code and Claude Desktop use a similar configuration format for MCP servers:\n\n##### Using NPX (Recommended for Manual Setup)\n\nThe easiest way to use Super Shell MCP is with NPX, which automatically installs and runs the package from npm without requiring manual setup. The package is available on NPM at [https://www.npmjs.com/package/super-shell-mcp](https://www.npmjs.com/package/super-shell-mcp).\n\n##### Roo Code Configuration with NPX\n\n```json\n\"super-shell\": {\n  \"command\": \"npx\",\n  \"args\": [\n    \"-y\",\n    \"super-shell-mcp\"\n  ],\n  \"alwaysAllow\": [],\n  \"disabled\": false\n}\n```\n\n##### Claude Desktop Configuration with NPX\n\n```json\n\"super-shell\": {\n  \"command\": \"npx\",\n  \"args\": [\n    \"-y\",\n    \"super-shell-mcp\"\n  ],\n  \"alwaysAllow\": false,\n  \"disabled\": false\n}\n```\n\n#### Option 2: Using Local Installation\n\nIf you prefer to use a local installation, add the following to your Roo Code MCP settings configuration file (located at `~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`):\n\n```json\n\"super-shell\": {\n  \"command\": \"node\",\n  \"args\": [\n    \"/path/to/super-shell-mcp/build/index.js\"\n  ],\n  \"alwaysAllow\": [],\n  \"disabled\": false\n}\n```\n\nYou can optionally specify a custom shell by adding a shell parameter:\n\n```json\n\"super-shell\": {\n  \"command\": \"node\",\n  \"args\": [\n    \"/path/to/super-shell-mcp/build/index.js\",\n    \"--shell=/usr/bin/bash\"\n  ],\n  \"alwaysAllow\": [],\n  \"disabled\": false\n}\n```\nWindows 11 example\n```json\n\"super-shell\": {\n      \"command\": \"C:\\\\Program Files\\\\nodejs\\\\node.exe\",\n      \"args\": [\n        \"C:\\\\Program Files\\\\nodejs\\\\node_modules\\\\npm\\\\bin\\\\npx-cli.js\",\n        \"-y\",\n        \"super-shell-mcp\",\n        \"C:\\\\Users\\\\username\"\n      ],\n      \"alwaysAllow\": [],\n      \"disabled\": false\n    }\n```\n\n#### Claude Desktop Configuration\n\nAdd the following to your Claude Desktop configuration file (located at `~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n\"super-shell\": {\n  \"command\": \"node\",\n  \"args\": [\n    \"/path/to/super-shell-mcp/build/index.js\"\n  ],\n  \"alwaysAllow\": false,\n  \"disabled\": false\n}\n```\nFor Windows users, the configuration file is typically located at `%APPDATA%\\Claude\\claude_desktop_config.json`.\n\n### Platform-Specific Configuration\n\n#### Windows\n- Default shell: cmd.exe (or PowerShell if available)\n- Configuration paths:\n  - Roo Code: `%APPDATA%\\Code\\User\\globalStorage\\rooveterinaryinc.roo-cline\\settings\\cline_mcp_settings.json`\n  - Claude Desktop: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- Shell path examples:\n  - cmd.exe: `C:\\\\Windows\\\\System32\\\\cmd.exe`\n  - PowerShell: `C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe`\n  - PowerShell Core: `C:\\\\Program Files\\\\PowerShell\\\\7\\\\pwsh.exe`\n\n#### macOS\n- Default shell: /bin/zsh\n- Configuration paths:\n  - Roo Code: `~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n  - Claude Desktop: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Shell path examples:\n  - zsh: `/bin/zsh`\n  - bash: `/bin/bash`\n  - sh: `/bin/sh`\n\n#### Linux\n- Default shell: /bin/bash (or $SHELL environment variable)\n- Configuration paths:\n  - Roo Code: `~/.config/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n  - Claude Desktop: `~/.config/Claude/claude_desktop_config.json`\n- Shell path examples:\n  - bash: `/bin/bash`\n  - sh: `/bin/sh`\n  - zsh: `/usr/bin/zsh`\n\n\nYou can optionally specify a custom shell:\n\n```json\n\"super-shell\": {\n  \"command\": \"node\",\n  \"args\": [\n    \"/path/to/super-shell-mcp/build/index.js\",\n    \"--shell=C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\"\n  ],\n  \"alwaysAllow\": false,\n  \"disabled\": false\n}\n```\n\nReplace `/path/to/super-shell-mcp` with the actual path where you cloned the repository.\n\n> **Note**:\n> - For Roo Code: Setting `alwaysAllow` to an empty array `[]` is recommended for security reasons, as it will prompt for approval before executing any commands. If you want to allow specific commands without prompting, you can add their names to the array, for example: `\"alwaysAllow\": [\"execute_command\", \"get_whitelist\"]`.\n> - For Claude Desktop: Setting `alwaysAllow` to `false` is recommended for security reasons. Claude Desktop uses a boolean value instead of an array, where `false` means all commands require approval and `true` means all commands are allowed without prompting.\n>\n> **Important**: The `alwaysAllow` parameter is processed by the MCP client (Roo Code or Claude Desktop), not by the Super Shell MCP server itself. The server will work correctly with either format, as the client handles the approval process before sending requests to the server.\n\n### Available Tools\nThe server exposes the following MCP tools:\n\n#### `get_platform_info`\n\nGet information about the current platform and shell.\n\n```json\n{}\n```\n\n\n#### `execute_command`\n\nExecute a shell command on the current platform.\n\n```json\n{\n  \"command\": \"ls\",\n  \"args\": [\"-la\"]\n}\n```\n\n#### `get_whitelist`\n\nGet the list of whitelisted commands.\n\n```json\n{}\n```\n\n#### `add_to_whitelist`\n\nAdd a command to the whitelist.\n\n```json\n{\n  \"command\": \"python3\",\n  \"securityLevel\": \"safe\",\n  \"description\": \"Run Python 3 scripts\"\n}\n```\n\n#### `update_security_level`\n\nUpdate the security level of a whitelisted command.\n\n```json\n{\n  \"command\": \"python3\",\n  \"securityLevel\": \"requires_approval\"\n}\n```\n\n#### `remove_from_whitelist`\n\nRemove a command from the whitelist.\n\n```json\n{\n  \"command\": \"python3\"\n}\n```\n\n#### `get_pending_commands`\n\nGet the list of commands pending approval.\n\n```json\n{}\n```\n\n#### `approve_command`\n\nApprove a pending command.\n\n```json\n{\n  \"commandId\": \"command-uuid-here\"\n}\n```\n\n#### `deny_command`\n\nDeny a pending command.\n\n```json\n{\n  \"commandId\": \"command-uuid-here\",\n  \"reason\": \"This command is potentially dangerous\"\n}\n```\n\n## Default Whitelisted Commands\n\nThe server includes platform-specific command whitelists that are automatically selected based on the detected platform.\n\n### Common Safe Commands (All Platforms)\n\n- `echo` - Print text to standard output\n\n### Unix-like Safe Commands (macOS/Linux)\n\n- `ls` - List directory contents\n- `pwd` - Print working directory\n- `echo` - Print text to standard output\n- `cat` - Concatenate and print files\n- `grep` - Search for patterns in files\n- `find` - Find files in a directory hierarchy\n- `cd` - Change directory\n- `head` - Output the first part of files\n- `tail` - Output the last part of files\n- `wc` - Print newline, word, and byte counts\n\n### Windows-specific Safe Commands\n\n- `dir` - List directory contents\n- `type` - Display the contents of a text file\n- `findstr` - Search for strings in files\n- `where` - Locate programs\n- `whoami` - Display current user\n- `hostname` - Display computer name\n- `ver` - Display operating system version\n### Commands Requiring Approval\n\n#### Windows Commands Requiring Approval\n\n- `copy` - Copy files\n- `move` - Move files\n- `mkdir` - Create directories\n- `rmdir` - Remove directories\n- `rename` - Rename files\n- `attrib` - Change file attributes\n\n#### Unix Commands Requiring Approval\n\n\n- `mv` - Move (rename) files\n- `cp` - Copy files and directories\n- `mkdir` - Create directories\n- `touch` - Change file timestamps or create empty files\n- `chmod` - Change file mode bits\n- `chown` - Change file owner and group\n\n### Forbidden Commands\n\n#### Windows Forbidden Commands\n\n- `del` - Delete files\n- `erase` - Delete files\n- `format` - Format a disk\n- `runas` - Execute a program as another user\n\n#### Unix Forbidden Commands\n\n- `rm` - Remove files or directories\n- `sudo` - Execute a command as another user\n\n## Security Considerations\n\n- All commands are executed with the permissions of the user running the MCP server\n- Commands requiring approval are held in a queue until explicitly approved\n- Forbidden commands are never executed\n- The server uses Node.js's `execFile` instead of `exec` to prevent shell injection\n- Arguments are validated against allowed patterns when specified\n\n## Extending the Whitelist\n\nYou can extend the whitelist by using the `add_to_whitelist` tool. For example:\n\n```json\n{\n  \"command\": \"npm\",\n  \"securityLevel\": \"requires_approval\",\n  \"description\": \"Node.js package manager\"\n}\n```\n\n## NPM Package Information\n\nSuper Shell MCP is available as an npm package at [https://www.npmjs.com/package/super-shell-mcp](https://www.npmjs.com/package/super-shell-mcp).\n\n### Benefits of Using NPX\n\nUsing the NPX method (as shown in Option 1 of the Configuration section) offers several advantages:\n\n1. **No Manual Setup**: No need to clone the repository, install dependencies, or build the project\n2. **Automatic Updates**: Always uses the latest published version\n3. **Cross-Platform Compatibility**: Works the same way on Windows, macOS, and Linux\n4. **Simplified Configuration**: Shorter configuration with no absolute paths\n5. **Reduced Maintenance**: No local files to manage or update\n\n### Using from GitHub\n\nIf you prefer to use the latest development version directly from GitHub:\n\n```json\n\"super-shell\": {\n  \"command\": \"npx\",\n  \"args\": [\n    \"-y\",\n    \"github:cfdude/super-shell-mcp\"\n  ],\n  \"alwaysAllow\": [],  // For Roo Code\n  \"disabled\": false\n}\n```\n\n### Publishing Your Own Version\n\nIf you want to publish your own modified version to npm:\n\n1. Update the package.json with your details\n2. Ensure the \"bin\" field is properly configured:\n   ```json\n   \"bin\": {\n     \"super-shell-mcp\": \"./build/index.js\"\n   }\n   ```\n3. Publish to npm:\n   ```bash\n   npm publish\n   ```\n\n## NPX Best Practices\n\nFor optimal integration with MCP clients using NPX, this project follows these best practices:\n\n1. **Executable Entry Point**: The main file includes a shebang line (`#!/usr/bin/env node`) and is made executable during build.\n\n2. **Package Configuration**:\n   - `\"type\": \"module\"` - Ensures ES Modules are used\n   - `\"bin\"` field - Maps the command name to the entry point\n   - `\"files\"` field - Specifies which files to include when publishing\n   - `\"prepare\"` script - Ensures compilation happens on install\n\n3. **TypeScript Configuration**:\n   - `\"module\": \"NodeNext\"` - Proper ES Modules support\n   - `\"moduleResolution\": \"NodeNext\"` - Consistent with ES Modules\n\n4. **Automatic Installation and Execution**:\n   - The MCP client configuration uses `npx -y` to automatically install and run the package\n   - No terminal window is tied up as the process runs in the background\n\n5. **Publishing Process**:\n   ```bash\n   # Update version in package.json\n   npm version patch  # or minor/major as appropriate\n   \n   # Build and publish\n   npm publish\n   ```\n\nThese practices ensure the MCP server can be started automatically by the MCP client without requiring a separate terminal window, improving user experience and operational efficiency.\n\n## Troubleshooting\n\n### Cross-Platform Issues\n\n#### Windows-Specific Issues\n\n1. **PowerShell Script Execution Policy**\n   - **Issue**: PowerShell may block script execution with the error \"Execution of scripts is disabled on this system\"\n   - **Solution**: Run PowerShell as Administrator and execute `Set-ExecutionPolicy RemoteSigned` or use the `-ExecutionPolicy Bypass` parameter when configuring the shell\n\n2. **Path Separators**\n   - **Issue**: Windows uses backslashes (`\\`) in paths, which need to be escaped in JSON\n   - **Solution**: Use double backslashes (`\\\\`) in JSON configuration files, e.g., `C:\\\\Windows\\\\System32\\\\cmd.exe`\n\n3. **Command Not Found**\n   - **Issue**: Windows doesn't have Unix commands like `ls`, `grep`, etc.\n   - **Solution**: Use Windows equivalents (`dir` instead of `ls`, `findstr` instead of `grep`)\n\n#### macOS/Linux-Specific Issues\n\n1. **Shell Permissions**\n   - **Issue**: Permission denied when executing commands\n   - **Solution**: Ensure the shell has appropriate permissions with `chmod +x /path/to/shell`\n\n2. **Environment Variables**\n   - **Issue**: Environment variables not available in MCP server\n   - **Solution**: Set environment variables in the shell's profile file (`.zshrc`, `.bashrc`, etc.)\n\n### General Troubleshooting\n\n1. **Shell Detection Issues**\n   - **Issue**: Server fails to detect the correct shell\n   - **Solution**: Explicitly specify the shell path in the configuration\n\n2. **Command Execution Timeout**\n   - **Issue**: Commands taking too long and timing out\n   - **Solution**: Increase the timeout value in the command service constructor\n\n### Logging System\n\nThe server includes a comprehensive logging system that writes logs to a file for easier debugging and monitoring:\n\n1. **Log File Location**\n   - Default: `logs/super-shell-mcp.log` in the server's directory\n   - The logs directory is created automatically and tracked by Git (with a .gitkeep file)\n   - Log files themselves are excluded from Git via .gitignore\n   - Contains detailed information about server operations, command execution, and approval workflow\n\n2. **Log Levels**\n   - **INFO**: General operational information\n   - **DEBUG**: Detailed debugging information\n   - **ERROR**: Error conditions and exceptions\n\n3. **Viewing Logs**\n   - Use standard file viewing commands to check logs:\n     ```bash\n     # View the entire log\n     cat logs/super-shell-mcp.log\n     \n     # Follow log updates in real-time\n     tail -f logs/super-shell-mcp.log\n     ```\n\n4. **Log Content**\n   - Server startup and configuration\n   - Command execution requests and results\n   - Approval workflow events (pending, approved, denied)\n   - Error conditions and troubleshooting information\n\n3. **Whitelist Management**\n   - **Issue**: Need to add custom commands to whitelist\n   - **Solution**: Use the `add_to_whitelist` tool to add commands specific to your environment\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "commands",
        "llms",
        "execute",
        "llms execute",
        "commands securely",
        "command management"
      ],
      "category": "code-execution"
    },
    "charles-adedotun--Lilith-Shell": {
      "owner": "charles-adedotun",
      "name": "Lilith-Shell",
      "url": "https://github.com/charles-adedotun/Lilith-Shell",
      "imageUrl": "https://github.com/charles-adedotun.png",
      "description": "Execute terminal commands securely and efficiently with enhanced security controls. Ideal for development systems, it enables seamless integration with AI assistants supporting the Model Context Protocol.",
      "stars": 0,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-03-21T02:10:13Z",
      "readme_content": "# Lilith Shell\n\n⚠️ **IMPORTANT SECURITY WARNING**: This MCP server grants AI assistants unrestricted ability to execute terminal commands on your system. **Only use in controlled environments like virtual machines (VMs) or development systems you can afford to rebuild.**\n\n## About\n\nLilith Shell is an enhanced MCP server that empowers AI assistants to execute terminal commands on your system with improved security controls and testing. Due to the unrestricted access this provides, it's crucial to use this software responsibly and be fully aware of the security risks involved.\n\n**Note**: This server is compatible with any AI assistant that supports the Model Context Protocol (MCP). The provided configuration and setup instructions are specifically tailored for Claude Desktop, which offers comprehensive support for all MCP features.\n\n## Features\n\n- Execute shell commands with security validation\n- Capture command output (stdout/stderr)\n- Set working directory\n- Handle command timeouts\n- Improved test coverage\n- Enhanced security controls\n- FastMCP integration\n\n## API\n\n### Tools\n\n- **execute_command**\n  - Execute shell commands and return their output\n  - **Inputs**:\n    - `command` (string): Command to execute\n    - `directory` (string, optional): Working directory\n  - **Returns**:\n    - Command exit code\n    - Standard output\n    - Standard error\n  - **Features**:\n    - 5-minute timeout\n    - Working directory support\n    - Error handling\n    - Security validation\n\n## Installation\n\n### Prerequisites\n\n- **Claude Desktop** with an active Claude Pro/Enterprise subscription\n  - Download from: [Claude AI](https://claude.ai/download)\n- **Python 3.10** or higher\n- **Git**\n- **uv** (required for package management)\n\n# Windows Installation\n\n1. Install Prerequisites:\n\n   **Option A** - Using winget (if available on your system):\n   ```powershell\n   winget install python git\n   ```\n\n   **Option B** - Manual installation (recommended):\n   - Download and install Python from [python.org](https://www.python.org)\n   - Download and install Git from [git-scm.com](https://git-scm.com)\n\n2. Install uv:\n\n   Open Command Prompt (`cmd.exe`) as administrator and run:\n   ```powershell\n   powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n   ```\n\n   If you encounter any issues, you may need to restart your terminal or computer for the changes to take effect.\n\n3. Clone and set up the project:\n   ```cmd\n   git clone https://github.com/charles-adedotun/Lilith-Shell.git\n   cd Lilith-Shell\n   ```\n\n   Then create a virtual environment. Try these commands in order until one works:\n   ```cmd\n   python -m venv venv\n   ```\n\n   If that doesn't work, try:\n   ```cmd\n   python3 -m venv venv\n   ```\n\n   Then activate the environment:\n   ```cmd\n   venv\\Scripts\\activate\n   ```\n\n4. Install dependencies:\n   ```cmd\n   uv pip install -e \".[dev]\"\n   ```\n\n**Note**: If you installed Python from [python.org](https://www.python.org), you'll typically use `python`. If you installed via winget or from the Microsoft Store, you might need to use `python3`. Try both commands if one doesn't work.\n\n### macOS Installation\n\n1. Install Prerequisites:\n   ```bash\n   brew install python git uv\n   ```\n\n2. Clone and set up the project:\n   ```bash\n   git clone https://github.com/charles-adedotun/Lilith-Shell.git\n   cd Lilith-Shell\n   python3 -m venv venv\n   source venv/bin/activate\n   ```\n\n3. Install dependencies:\n   ```bash\n   uv pip install -e \".[dev]\"\n   ```\n\n## Configuration\n\n### Windows\n\nLocate the correct configuration directory - try these paths in order:\n\n1. `%APPDATA%\\Claude\\` (typically `C:\\Users\\[YourUsername]\\AppData\\Roaming\\Claude\\`)\n2. `%LOCALAPPDATA%\\AnthropicClaude\\` (typically `C:\\Users\\[YourUsername]\\AppData\\Local\\AnthropicClaude\\`)\n\nCreate or edit `claude_desktop_config.json` in the correct directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"lilith-shell\": {\n      \"command\": \"C:/path/to/cloned/Lilith-Shell/venv/Scripts/python.exe\",\n      \"args\": [\n        \"C:/path/to/cloned/Lilith-Shell/src/lilith_shell/executor.py\"\n      ],\n      \"env\": {\n        \"PYTHONPATH\": \"C:/path/to/cloned/Lilith-Shell/src\"\n      }\n    }\n  }\n}\n```\n\n#### Important Notes for Windows:\n\n- Use forward slashes (`/`) in paths, not backslashes (`\\`)\n- Replace `[YourUsername]` with your actual Windows username\n- File must be named exactly `claude_desktop_config.json`\n- If both possible config locations exist, try each until successful\n\n### macOS\n\nCreate or edit `~/Library/Application Support/Claude/claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"lilith-shell\": {\n      \"command\": \"/path/to/cloned/Lilith-Shell/venv/bin/python\",\n      \"args\": [\n        \"/path/to/cloned/Lilith-Shell/src/lilith_shell/executor.py\"\n      ],\n      \"env\": {\n        \"PYTHONPATH\": \"/path/to/cloned/Lilith-Shell/src\"\n      }\n    }\n  }\n}\n```\n\n#### Important Notes for macOS:\n\n- Replace `[YourUsername]` with your actual username\n- You can use `$HOME` instead of `/Users/[YourUsername]` if preferred\n- File must be named exactly `claude_desktop_config.json`\n- The `command` path should point to the Python interpreter inside your virtual environment (`venv/bin/python`), not the system Python\n\n### After Configuration\n\n1. Restart Claude Desktop completely (quit/exit, not just close the window).\n2. Click the 🔌 icon to verify the server appears in the \"Installed MCP Servers\" list.\n3. If the server doesn't appear, check Claude's logs:\n   - **Windows**: `%APPDATA%\\Claude\\Logs\\mcp*.log` or `%LOCALAPPDATA%\\AnthropicClaude\\Logs\\mcp*.log`\n   - **macOS**: `~/Library/Logs/Claude/mcp*.log`\n\n## Security Considerations\n\nThis server executes commands with your user privileges. **Take these precautions:**\n\n- Use **only** in VMs or disposable development environments.\n- **Never** use on production systems or machines with sensitive data.\n- Consider implementing command restrictions if needed.\n- Monitor system access and activity.\n- Keep backups of important data.\n\n**Disclaimer**: The developers are not responsible for any damages or losses resulting from the use of this software. Use it at your own risk.\n\n## Troubleshooting\n\nIf you encounter issues:\n\n1. **Check logs:**\n   - **Windows**: `%APPDATA%\\Claude\\Logs\\mcp*.log` or `%LOCALAPPDATA%\\AnthropicClaude\\Logs\\mcp*.log`\n   - **macOS**: `~/Library/Logs/Claude/mcp*.log`\n\n2. **Verify installation:**\n   - Ensure `uv` is properly installed and in your PATH.\n   - Check that `mcp` package is installed: `pip show mcp`.\n   - Verify Python version is 3.10 or higher.\n\n3. **Configuration issues:**\n   - Double-check all paths in `claude_desktop_config.json`.\n   - Verify JSON syntax is valid.\n   - Ensure proper path separators for your OS.\n   - Confirm config file is in the correct location.\n\n4. **Environment issues:**\n   - Make sure `virtualenv` is activated if using one.\n   - Verify `PYTHONPATH` is set correctly.\n   - Check file permissions.\n\n5. **Test server manually:**\n   ```bash\n   # First, make sure you're in the Lilith-Shell directory:\n   cd /path/to/cloned/Lilith-Shell\n\n   # For macOS:\n   ./venv/bin/python src/lilith_shell/executor.py\n\n   # For Windows:\n   .\\venv\\Scripts\\python.exe src\\lilith_shell\\executor.py\n\n   # The executor will appear to hang with no output - this is normal.\n   # It's waiting for connections from Claude Desktop.\n   # Use Ctrl+C to stop it.\n   ```\n\n6. **Connection issues:**\n   - If you get \"Could not connect to MCP server\" errors, ensure you're using the virtual environment's Python interpreter in your config file.\n   - For macOS: Use `/path/to/cloned/Lilith-Shell/venv/bin/python`\n   - For Windows: Use `C:/path/to/cloned/Lilith-Shell/venv/Scripts/python.exe`\n\n## Testing\n\nAfter setup, try these commands in Claude Desktop:\n\n```text\nCan you run 'pwd' and tell me what directory we're in?\n```\n\nor\n\n```text\nCan you list the files in my home directory? Which of them are larger than 200 MB?\n```\n\n## Acknowledgments\n\nThis project is a fork of [Pandoras-Shell](https://github.com/Zelaron/Pandoras-Shell) by Christian Hägg, with significant enhancements to security, testing, and functionality. The original project provided the foundation and inspiration for Lilith Shell.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "execute",
        "llms execute",
        "execution servers",
        "execute code"
      ],
      "category": "code-execution"
    },
    "chrishayuk--mcp-code-sandbox": {
      "owner": "chrishayuk",
      "name": "mcp-code-sandbox",
      "url": "https://github.com/chrishayuk/mcp-code-sandbox",
      "imageUrl": "https://github.com/chrishayuk.png",
      "description": "Provides secure execution environments for Python code within isolated sandboxes, enabling file management and package installation. Supports modular integration with various MCP clients for enhanced code execution workflows.",
      "stars": 11,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-10-03T22:32:21Z",
      "readme_content": "# MCP Code Sandbox Server\n\nAn extensible Message Communication Protocol (MCP) server that provides secure code execution capabilities in isolated sandbox environments. This server follows the MCP standard, making it compatible with Claude for Desktop and other MCP clients.\n\n## Features\n\n- Create isolated sandbox environments for code execution\n- Execute Python code securely\n- Perform file operations (listing, reading, writing)\n- Install Python packages in the sandbox\n- Extensible architecture with abstracted code interpreter interface\n- Modular design with clean separation of concerns\n\n## Architecture\n\nThe server is built with a modular, extensible architecture:\n\n### Core Components\n\n- **Abstract Interpreter Interface**: Allows different code execution backends to be integrated\n- **Sandbox Administration**: Tools for creating and managing sandbox environments\n- **Code Execution**: Tools for running code and installing packages\n- **File Operations**: Tools for managing files within sandboxes\n\n### Project Structure\n\n```\n├── src/\n│   └── sandbox/\n│       ├── __pycache__/\n│       ├── e2b/\n│       │   ├── __pycache__/\n│       │   ├── __init__.py\n│       │   ├── e2b_file_interface.py\n│       │   └── e2b_interpreter.py\n│       ├── __init__.py\n│       ├── code_interpreter.py\n│       ├── file_interface.py\n│       └── interpreter_factory.py\n├── tools/\n│   ├── __pycache__/\n│   ├── __init__.py\n│   ├── code_execution_tools.py\n│   ├── file_tools.py\n│   └── sandbox_tools.py\n├── main.py\n├── .env\n├── .gitignore\n├── .python-version\n├── pyproject.toml\n├── README.md\n└── uv.lock\n```\n\n## Prerequisites\n\n- Python 3.10 or higher\n- E2B API key (for the default E2B interpreter)\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/yourusername/mcp-code-sandbox.git\n   cd mcp-code-sandbox\n   ```\n\n2. Set up a virtual environment:\n   ```bash\n   # Using venv\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   \n   # Or using uv (recommended)\n   uv init\n   uv venv\n   source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n   ```\n\n3. Install the required packages:\n   ```bash\n   # Using pip\n   pip install fastmcp python-dotenv e2b-code-interpreter\n   \n   # Or using uv\n   uv add fastmcp python-dotenv e2b-code-interpreter\n   ```\n\n4. Configure environment variables:\n   ```\n   # Create a .env file with the following variables\n   E2B_API_KEY=your_e2b_api_key_here\n   INTERPRETER_TYPE=e2b  # Default, can be changed to other implemented interpreters\n   ```\n\n## Usage\n\n### Running the Server Standalone\n\nYou can run the server directly from the command line:\n\n```bash\npython main.py\n```\n\nThis will start the server using the stdio transport, making it compatible with Claude for Desktop.\n\n### Using with Claude for Desktop\n\n1. Make sure you have the latest version of Claude for Desktop installed\n\n2. Open your Claude for Desktop configuration file:\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n3. Add your code sandbox server configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"code-sandbox\": {\n         \"command\": \"python\",\n         \"args\": [\n           \"/ABSOLUTE/PATH/TO/main.py\"\n         ]\n       }\n     }\n   }\n   ```\n\n   Or if you're using `uv`:\n   ```json\n   {\n     \"mcpServers\": {\n       \"code-sandbox\": {\n         \"command\": \"uv\",\n         \"args\": [\n           \"--directory\",\n           \"/ABSOLUTE/PATH/TO/PROJECT_DIRECTORY\",\n           \"run\",\n           \"main.py\"\n         ]\n       }\n     }\n   }\n   ```\n\n4. Save the file and restart Claude for Desktop\n\n## Available Tools\n\nThe server provides the following tools:\n\n### Sandbox Administration\n- **create_sandbox**: Create a new sandbox environment\n- **close_sandbox**: Close and clean up a sandbox\n- **get_sandbox_status**: Check status of sandboxes\n\n### Code Execution\n- **execute_code**: Run Python code in a sandbox\n- **install_package**: Install a Python package\n- **create_run_close**: All-in-one tool that creates a sandbox, runs code, and cleans up\n\n### File Operations\n- **list_files**: List files in the sandbox\n- **read_file**: Read the contents of a file\n- **write_file**: Write content to a file\n- **upload_file**: Upload a file to the sandbox\n\n## Extending with New Interpreters\n\nThe system is designed to be extensible. To add a new code interpreter:\n\n1. Create a new directory under `src/sandbox/` for your interpreter implementation\n2. Implement the interfaces defined in `src/sandbox/code_interpreter.py` and `src/sandbox/file_interface.py`\n3. Add the new interpreter type to the `src/sandbox/interpreter_factory.py`\n4. Configure the environment variable `INTERPRETER_TYPE` to your new interpreter\n\nExample of implementing a new interpreter:\n\n```python\n# src/sandbox/my_backend/my_interpreter.py\nfrom src.sandbox.code_interpreter import CodeInterpreter, ExecutionResult\nfrom src.sandbox.file_interface import FileInterface\n\nclass MyFileInterface(FileInterface):\n    # Implement the required methods\n    \nclass MyInterpreter(CodeInterpreter):\n    # Implement the required methods\n\n# Update src/sandbox/interpreter_factory.py to include your new interpreter\n```\n\n## Module Descriptions\n\n### Sandbox Core (`src/sandbox/`)\n- `code_interpreter.py`: Abstract base class for code interpreters\n- `file_interface.py`: Abstract interface for file operations\n- `interpreter_factory.py`: Factory for creating code interpreter instances\n\n### E2B Implementation (`src/sandbox/e2b/`)\n- `e2b_interpreter.py`: E2B implementation of the code interpreter\n- `e2b_file_interface.py`: E2B implementation of file operations\n\n### Tools (`tools/`)\n- `sandbox_tools.py`: Tools for sandbox administration\n- `code_execution_tools.py`: Tools for code execution\n- `file_tools.py`: Tools for file operations\n\n### Main Application\n- `main.py`: Main application entry point\n\n## Troubleshooting\n\nIf you encounter issues:\n\n- Make sure you have the correct API key for your chosen interpreter\n- Check the logs for detailed error messages\n- Verify that all required packages are installed\n- Ensure Claude for Desktop is configured with the correct path to your script\n\n## Security Considerations\n\n- The code execution happens in sandboxed environments for safety\n- Do not use this server to execute untrusted code in production environments\n- The server does not currently implement authentication - it should only be used in trusted environments\n\n## License\n\n[MIT License](LICENSE)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "sandboxes",
        "sandbox",
        "llms",
        "code sandbox",
        "llms execute",
        "code secure"
      ],
      "category": "code-execution"
    },
    "ckanthony--openapi-mcp": {
      "owner": "ckanthony",
      "name": "openapi-mcp",
      "url": "https://github.com/ckanthony/openapi-mcp",
      "imageUrl": "",
      "description": "OpenAPI-MCP: Dockerized MCP Server to allow your AI agent to access any API with existing api docs.",
      "stars": 140,
      "forks": 30,
      "license": "No License",
      "language": "Go",
      "updated_at": "2025-09-30T15:19:57Z",
      "readme_content": "# OpenAPI-MCP: Dockerized MCP Server to allow your AI agent to access any API with existing api docs\n\n[![Go Reference](https://pkg.go.dev/badge/github.com/ckanthony/openapi-mcp.svg)](https://pkg.go.dev/github.com/ckanthony/openapi-mcp)\n[![CI](https://github.com/ckanthony/openapi-mcp/actions/workflows/ci.yml/badge.svg)](https://github.com/ckanthony/openapi-mcp/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/gh/ckanthony/openapi-mcp/branch/main/graph/badge.svg)](https://codecov.io/gh/ckanthony/openapi-mcp)\n![](https://badge.mcpx.dev?type=dev 'MCP Dev')\n\n![openapi-mcp logo](openapi-mcp.png)\n\n**Generate MCP tool definitions directly from a Swagger/OpenAPI specification file.**\n\nOpenAPI-MCP is a dockerized MCP server that reads a `swagger.json` or `openapi.yaml` file and generates a corresponding [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) toolset. This allows MCP-compatible clients like [Cursor](https://cursor.sh/) to interact with APIs described by standard OpenAPI specifications. Now you can enable your AI agent to access any API by simply providing its OpenAPI/Swagger specification - no additional coding required.\n\n## Table of Contents\n\n-   [Why OpenAPI-MCP?](#why-openapi-mcp)\n-   [Features](#features)\n-   [Installation](#installation)\n    -   [Using the Pre-built Docker Hub Image (Recommended)](#using-the-pre-built-docker-hub-image-recommended)\n    -   [Building Locally (Optional)](#building-locally-optional)\n-   [Running the Weatherbit Example (Step-by-Step)](#running-the-weatherbit-example-step-by-step)\n-   [Command-Line Options](#command-line-options)\n    -   [Environment Variables](#environment-variables)\n\n## Demo\n\nRun the demo yourself: [Running the Weatherbit Example (Step-by-Step)](#running-the-weatherbit-example-step-by-step)\n\n![demo](https://github.com/user-attachments/assets/4d457137-5da4-422a-b323-afd4b175bd56)\n\n## Why OpenAPI-MCP?\n\n-   **Standard Compliance:** Leverage your existing OpenAPI/Swagger documentation.\n-   **Automatic Tool Generation:** Create MCP tools without manual configuration for each endpoint.\n-   **Flexible API Key Handling:** Securely manage API key authentication for the proxied API without exposing keys to the MCP client.\n-   **Local & Remote Specs:** Works with local specification files or remote URLs.\n-   **Dockerized Tool:** Easily deploy and run as a containerized service with Docker.\n\n## Features\n\n-   **OpenAPI v2 (Swagger) & v3 Support:** Parses standard specification formats.\n-   **Schema Generation:** Creates MCP tool schemas from OpenAPI operation parameters and request/response definitions.\n-   **Secure API Key Management:**\n    -   Injects API keys into requests (`header`, `query`, `path`, `cookie`) based on command-line configuration.\n        -   Loads API keys directly from flags (`--api-key`), environment variables (`--api-key-env`), or `.env` files located alongside local specs.\n        -   Keeps API keys hidden from the end MCP client (e.g., the AI assistant).\n-   **Server URL Detection:** Uses server URLs from the spec as the base for tool interactions (can be overridden).\n-   **Filtering:** Options to include/exclude specific operations or tags (`--include-tag`, `--exclude-tag`, `--include-op`, `--exclude-op`).\n-   **Request Header Injection:** Pass custom headers (e.g., for additional auth, tracing) via the `REQUEST_HEADERS` environment variable.\n\n## Installation\n\n### Docker\n\nThe recommended way to run this tool is via [Docker](https://hub.docker.com/r/ckanthony/openapi-mcp).\n\n#### Using the Pre-built Docker Hub Image (Recommended)\n\nAlternatively, you can use the pre-built image available on [Docker Hub](https://hub.docker.com/r/ckanthony/openapi-mcp).\n\n1.  **Pull the Image:**\n    ```bash\n    docker pull ckanthony/openapi-mcp:latest\n    ```\n2.  **Run the Container:**\n    Follow the `docker run` examples above, but replace `openapi-mcp:latest` with `ckanthony/openapi-mcp:latest`.\n\n#### Building Locally (Optional)\n\n1.  **Build the Docker Image Locally:**\n    ```bash\n    # Navigate to the repository root\n    cd openapi-mcp\n    # Build the Docker image (tag it as you like, e.g., openapi-mcp:latest)\n    docker build -t openapi-mcp:latest .\n    ```\n\n2.  **Run the Container:**\n    You need to provide the OpenAPI specification and any necessary API key configuration when running the container.\n\n    *   **Example 1: Using a local spec file and `.env` file:**\n        -   Create a directory (e.g., `./my-api`) containing your `openapi.json` or `swagger.yaml`.\n        -   If the API requires a key, create a `.env` file in the *same directory* (e.g., `./my-api/.env`) with `API_KEY=your_actual_key` (replace `API_KEY` if your `--api-key-env` flag is different).\n        ```bash\n        docker run -p 8080:8080 --rm \\\\\n            -v $(pwd)/my-api:/app/spec \\\\\n            --env-file $(pwd)/my-api/.env \\\\\n            openapi-mcp:latest \\\\\n            --spec /app/spec/openapi.json \\\\\n            --api-key-env API_KEY \\\\\n            --api-key-name X-API-Key \\\\\n            --api-key-loc header\n        ```\n        *(Adjust `--spec`, `--api-key-env`, `--api-key-name`, `--api-key-loc`, and `-p` as needed.)*\n\n    *   **Example 2: Using a remote spec URL and direct environment variable:**\n        ```bash\n        docker run -p 8080:8080 --rm \\\\\n            -e SOME_API_KEY=\"your_actual_key\" \\\\\n            openapi-mcp:latest \\\\\n            --spec https://petstore.swagger.io/v2/swagger.json \\\\\n            --api-key-env SOME_API_KEY \\\\\n            --api-key-name api_key \\\\\n            --api-key-loc header\n        ```\n\n    *   **Key Docker Run Options:**\n        *   `-p <host_port>:8080`: Map a port on your host to the container's default port 8080.\n        *   `--rm`: Automatically remove the container when it exits.\n        *   `-v <host_path>:<container_path>`: Mount a local directory containing your spec into the container. Use absolute paths or `$(pwd)/...`. Common container path: `/app/spec`.\n        *   `--env-file <path_to_host_env_file>`: Load environment variables from a local file (for API keys, etc.). Path is on the host.\n        *   `-e <VAR_NAME>=\"<value>\"`: Pass a single environment variable directly.\n        *   `openapi-mcp:latest`: The name of the image you built locally.\n        *   `--spec ...`: **Required.** Path to the spec file *inside the container* (e.g., `/app/spec/openapi.json`) or a public URL.\n        *   `--port 8080`: (Optional) Change the internal port the server listens on (must match the container port in `-p`).\n        *   `--api-key-env`, `--api-key-name`, `--api-key-loc`: Required if the target API needs an API key.\n        *   (See `--help` for all command-line options by running `docker run --rm openapi-mcp:latest --help`)\n\n\n## Running the Weatherbit Example (Step-by-Step)\n\nThis repository includes an example using the [Weatherbit API](https://www.weatherbit.io/). Here's how to run it using the public Docker image:\n\n1.  **Find OpenAPI Specs (Optional Knowledge):**\n    Many public APIs have their OpenAPI/Swagger specifications available online. A great resource for discovering them is [APIs.guru](https://apis.guru/). The Weatherbit specification used in this example (`weatherbitio-swagger.json`) was sourced from there.\n\n2.  **Get a Weatherbit API Key:**\n    *   Go to [Weatherbit.io](https://www.weatherbit.io/) and sign up for an account (they offer a free tier).\n    *   Find your API key in your Weatherbit account dashboard.\n\n3.  **Clone this Repository:**\n    You need the example files from this repository.\n    ```bash\n    git clone https://github.com/ckanthony/openapi-mcp.git\n    cd openapi-mcp\n    ```\n\n4.  **Prepare Environment File:**\n    *   Navigate to the example directory: `cd example/weather`\n    *   Copy the example environment file: `cp .env.example .env`\n    *   Edit the new `.env` file and replace `YOUR_WEATHERBIT_API_KEY_HERE` with the actual API key you obtained from Weatherbit.\n\n5.  **Run the Docker Container:**\n    From the `openapi-mcp` **root directory** (the one containing the `example` folder), run the following command:\n    ```bash\n    docker run -p 8080:8080 --rm \\\\\n        -v $(pwd)/example/weather:/app/spec \\\\\n        --env-file $(pwd)/example/weather/.env \\\\\n        ckanthony/openapi-mcp:latest \\\\\n        --spec /app/spec/weatherbitio-swagger.json \\\\\n        --api-key-env API_KEY \\\\\n        --api-key-name key \\\\\n        --api-key-loc query\n    ```\n    *   `-v $(pwd)/example/weather:/app/spec`: Mounts the local `example/weather` directory (containing the spec and `.env` file) to `/app/spec` inside the container.\n    *   `--env-file $(pwd)/example/weather/.env`: Tells Docker to load environment variables (specifically `API_KEY`) from your `.env` file.\n    *   `ckanthony/openapi-mcp:latest`: Uses the public Docker image.\n    *   `--spec /app/spec/weatherbitio-swagger.json`: Points to the spec file inside the container.\n    *   The `--api-key-*` flags configure how the tool should inject the API key (read from the `API_KEY` env var, named `key`, placed in the `query` string).\n\n6.  **Access the MCP Server:**\n    The MCP server should now be running and accessible at `http://localhost:8080` for compatible clients.\n\n**Using Docker Compose (Example):**\n\nA `docker-compose.yml` file is provided in the `example/` directory to demonstrate running the Weatherbit API example using the *locally built* image.\n\n1.  **Prepare Environment File:** Copy `example/weather/.env.example` to `example/weather/.env` and add your actual Weatherbit API key:\n    ```dotenv\n    # example/weather/.env\n    API_KEY=YOUR_ACTUAL_WEATHERBIT_KEY\n    ```\n\n2.  **Run with Docker Compose:** Navigate to the `example` directory and run:\n    ```bash\n    cd example\n    # This builds the image locally based on ../Dockerfile\n    # It does NOT use the public Docker Hub image\n    docker-compose up --build\n    ```\n    *   `--build`: Forces Docker Compose to build the image using the `Dockerfile` in the project root before starting the service.\n    *   Compose will read `example/docker-compose.yml`, build the image, mount `./weather`, read `./weather/.env`, and start the `openapi-mcp` container with the specified command-line arguments.\n    *   The MCP server will be available at `http://localhost:8080`.\n\n3.  **Stop the service:** Press `Ctrl+C` in the terminal where Compose is running, or run `docker-compose down` from the `example` directory in another terminal.\n\n## Command-Line Options\n\nThe `openapi-mcp` command accepts the following flags:\n\n| Flag                 | Description                                                                                                         | Type          | Default                          |\n|----------------------|---------------------------------------------------------------------------------------------------------------------|---------------|----------------------------------|\n| `--spec`             | **Required.** Path or URL to the OpenAPI specification file.                                                          | `string`      | (none)                           |\n| `--port`             | Port to run the MCP server on.                                                                                      | `int`         | `8080`                           |\n| `--api-key`          | Direct API key value (use `--api-key-env` or `.env` file instead for security).                                       | `string`      | (none)                           |\n| `--api-key-env`      | Environment variable name containing the API key. If spec is local, also checks `.env` file in the spec's directory. | `string`      | (none)                           |\n| `--api-key-name`     | **Required if key used.** Name of the API key parameter (header, query, path, or cookie name).                       | `string`      | (none)                           |\n| `--api-key-loc`      | **Required if key used.** Location of API key: `header`, `query`, `path`, or `cookie`.                              | `string`      | (none)                           |\n| `--include-tag`      | Tag to include (can be repeated). If include flags are used, only included items are exposed.                       | `string slice`| (none)                           |\n| `--exclude-tag`      | Tag to exclude (can be repeated). Exclusions apply after inclusions.                                                | `string slice`| (none)                           |\n| `--include-op`       | Operation ID to include (can be repeated).                                                                          | `string slice`| (none)                           |\n| `--exclude-op`       | Operation ID to exclude (can be repeated).                                                                          | `string slice`| (none)                           |\n| `--base-url`         | Manually override the target API server base URL detected from the spec.                                              | `string`      | (none)                           |\n| `--name`             | Default name for the generated MCP toolset (used if spec has no title).                                             | `string`      | \"OpenAPI-MCP Tools\"            |\n| `--desc`             | Default description for the generated MCP toolset (used if spec has no description).                                | `string`      | \"Tools generated from OpenAPI spec\" |\n\n**Note:** You can get this list by running the tool with the `--help` flag (e.g., `docker run --rm ckanthony/openapi-mcp:latest --help`).\n\n### Environment Variables\n\n*   `REQUEST_HEADERS`: Set this environment variable to a JSON string (e.g., `'{\"X-Custom\": \"Value\"}'`) to add custom headers to *all* outgoing requests to the target API.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "openapi",
        "api",
        "llms execute",
        "mcp openapi",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "codacy--codacy-mcp-server": {
      "owner": "codacy",
      "name": "codacy-mcp-server",
      "url": "https://github.com/codacy/codacy-mcp-server",
      "imageUrl": "https://github.com/codacy.png",
      "description": "Access and manage code quality, security, and repository data from the Codacy API, enabling analysis of repository metrics and issues. Integrates with development workflows for seamless management of code quality and security checks.",
      "stars": 49,
      "forks": 15,
      "license": "Other",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:31:15Z",
      "readme_content": "# Codacy MCP Server\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/7be4b119dc1e420198f3495017b57c89)](https://app.codacy.com/gh/codacy/codacy-mcp-server/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n\n\nMCP Server for the Codacy API, enabling access to repositories, files, quality, coverage, security and more.\n\n\n## Table of Contents\n- [Features / Tools](#features--tools)\n  - [Repository Setup and Management](#repository-setup-and-management)\n  - [Organization and Repository Management](#organization-and-repository-management)\n  - [Code Quality and Analysis](#code-quality-and-analysis)\n  - [File Management and Analysis](#file-management-and-analysis)\n  - [Security Analysis](#security-analysis)\n  - [Pull Request Analysis](#pull-request-analysis)\n  - [Tool and Pattern Management](#tool-and-pattern-management)\n  - [CLI Analysis](#cli-analysis)\n- [Setup](#setup)\n  - [Requirements](#requirements)\n  - [Personal API Access Token](#personal-api-access-token)\n  - [Install](#install)\n    - [Cursor, Windsurf, and others](#cursor-windsurf-and-others)\n    - [VS Code with Copilot](#vs-code-with-copilot)\n- [Troubleshooting](#troubleshooting)\n- [Contribute](#contribute)\n- [Codacy-CLI Support](#codacy-cli-support)\n- [License](#license)\n  \n\n## Features / Tools\n\nThe following tools are available through the Codacy MCP Server:\n\n### Repository Setup and Management\n\n- `codacy_setup_repository`: Add or follow a repository in Codacy if not already present. This tool ensures the repository is registered with Codacy, allowing further analysis and management.\n\n### Organization and Repository Management\n\n- `codacy_list_organizations`: List organizations with pagination support.\n- `codacy_list_organization_repositories`: List repositories in an organization with pagination support.\n- `codacy_get_repository_with_analysis`: Get repository with analysis information, including metrics for Grade, Issues, Duplication, Complexity, and Coverage.\n\n### Code Quality and Analysis\n\n- `codacy_list_repository_issues`: Lists and filters code quality issues in a repository. This is the primary tool for investigating general code quality concerns (e.g. best practices, performance, complexity, style) but NOT security issues. For security-related issues, use the SRM items tool instead. Features include:\n\n  - Pagination support for handling large result sets\n  - Filtering by multiple criteria including severity, category, and language\n  - Author-based filtering for accountability\n  - Branch-specific analysis\n  - Pattern-based searching\n\n  Common use cases:\n\n  - Code quality audits\n  - Technical debt assessment\n  - Style guide compliance checks\n  - Performance issue investigation\n  - Complexity analysis\n\n### File Management and Analysis\n\n- `codacy_list_files`: List files in a repository with pagination support.\n- `codacy_get_file_issues`: Get the issue list for a file in a repository.\n- `codacy_get_file_coverage`: Get coverage information for a file in the head commit of a repository branch.\n- `codacy_get_file_clones`: Get the list of duplication clones (identical or very similar code segments) for a file in a repository.\n- `codacy_get_file_with_analysis`: Get detailed analysis information for a file, including metrics for Grade, Issues, Duplication, Complexity, and Coverage.\n\n### Security Analysis\n\n- `codacy_search_organization_srm_items`: Primary tool to list security items/issues/vulnerabilities/findings across an organization. Results are related to the organization's security and risk management (SRM) dashboard on Codacy.\n- `codacy_search_repository_srm_items`: List security items/issues/vulnerabilities/findings for a specific repository.\n\nBoth tools provide comprehensive security analysis including:\n\n- SAST (Code scanning)\n- Secrets (Secret scanning)\n- SCA (Dependency scanning)\n- IaC (Infrastructure-as-code scanning)\n- CICD (CI/CD scanning)\n- DAST (Dynamic Application Security Testing)\n- PenTesting (Penetration testing)\n\n### Pull Request Analysis\n\n- `codacy_list_repository_pull_requests`: List pull requests from a repository that the user has access to.\n- `codacy_get_repository_pull_request`: Get detailed information about a specific pull request.\n- `codacy_list_pull_request_issues`: Returns a list of issues found in a pull request (new or fixed issues).\n- `codacy_get_pull_request_files_coverage`: Get diff coverage information for all files in a pull request.\n- `codacy_get_pull_request_git_diff`: Returns the human-readable Git diff of a pull request.\n\n### Tool and Pattern Management\n\n- `codacy_list_tools`: List all code analysis tools available in Codacy.\n- `codacy_list_repository_tools`: Get analysis tools settings and available tools for a repository.\n- `codacy_get_pattern`: Get the definition of a specific pattern.\n- `codacy_list_repository_tool_patterns`: List the patterns of a tool available for a repository.\n- `codacy_get_issue`: Get detailed information about a specific issue.\n\n### CLI Analysis\n\n- `codacy_cli_analyze`: Run quality analysis locally using Codacy CLI. Features include:\n  - Analyze specific files or entire directories\n  - Use specific tools or all available tools\n  - Get immediate results without waiting for scheduled analysis\n  - Apply fixes based on Codacy configuration\n\n## Setup\n\n### Requirements\n\nEnsure your machine has the following tools installed:\n\n- git\n- node.js\n  - ensure that the `npx` command runs without issues.\n\nFor local analysis, the MCP Server requires the [Codacy CLI](https://github.com/codacy/codacy-cli-v2) to be installed. If it is not available, the MCP Server will attempt to install it for you. Codacy CLI v2 runs on macOS, Linux, and Windows (only with WSL).\n\n### Personal API Access Token\n\nGet your Codacy's Account API Token from your [Codacy Account](https://app.codacy.com/account/access-management).\n\nYou'll need it later in the setup.\n\n### Install\n\nIn supported IDEs like VS Code, Cursor, and Windsurf, the easiest way to install Codacy's MCP Server is to do it from the Codacy extension. If you haven't yet, install the extension from within your IDE, or from any of the available marketplaces ([Microsoft](https://marketplace.visualstudio.com/items?itemName=codacy-app.codacy), [OpenVSX](https://open-vsx.org/extension/codacy-app/codacy)). From the extension panel, just click on Add Codacy MCP Server. Restart your IDE afterwards.\n\nWithout the extension, you can still use and install the MCP Server:\n\n#### Cursor, Windsurf, and others\n\nYou can use the one-click install for Cursor:\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/install-mcp?name=codacy&config=eyJjb21tYW5kIjoibnB4IC15IEBjb2RhY3kvY29kYWN5LW1jcEBsYXRlc3QiLCJlbnYiOnsiQ09EQUNZX0FDQ09VTlRfVE9LRU4iOiI8WW91ciBwZXJzb25hbCB0b2tlbj4ifX0%3D) \n\nOtherwise, depending on what you are connecting the MCP Server to, you can use the following methods:\n\n- Cursor: edit the `.cursor/mcp.json` file to add the following\n- Windsurf: edit the `.codeium/windsurf/mcp_config.json` file to add the following\n- Claude Desktop: edit the `claude_desktop_config.json` file to add the following\n\n```json\n{\n  \"mcpServers\": {\n    \"codacy\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@codacy/codacy-mcp\"],\n      \"env\": {\n        \"CODACY_ACCOUNT_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n\n#### VS Code with Copilot\n\nYou can use the one-click install for VS Code:\n\n[![Install with Codacy in VS Code](https://img.shields.io/badge/VS_Code-Install_Codacy_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=codacy&inputs=%5B%7B%22id%22%3A%22codacy_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22Codacy%20Account%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40codacy%2Fcodacy-mcp%40latest%22%5D%2C%22env%22%3A%7B%22CODACY_ACCOUNT_TOKEN%22%3A%22%24%7Binput%3Acodacy_token%7D%22%7D%7D) [![Install with Codacy in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Codacy_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=codacy&inputs=%5B%7B%22id%22%3A%22codacy_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22Codacy%20Account%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40codacy%2Fcodacy-mcp%40latest%22%5D%2C%22env%22%3A%7B%22CODACY_ACCOUNT_TOKEN%22%3A%22%24%7Binput%3Acodacy_token%7D%22%7D%7D&quality=insiders) \n\nOtherwise, if you wish to set it up manually:\n\n1. For connecting the MCP Server to Copilot in VS Code, add the following to the global config of the IDE:\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [],\n    \"servers\": {\n      \"codacy\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@codacy/codacy-mcp\"],\n        \"env\": {\n          \"CODACY_ACCOUNT_TOKEN\": \"<YOUR_TOKEN>\"\n        }\n      }\n    }\n  }\n}\n```\n\nYou can open the user settings.json file in:\n\n`View > Command Palette > Preferences: Open User Settings (JSON)`\n\nOr open the general settings.json file directly, which according to your OS should be located in:\n\n- for macOS: `~/Library/Application Support/Code/User/settings.json`\n- for Windows: `%APPDATA%\\Code\\User\\settings.json`\n- for Linux: `~/.config/Code/User/settings.json`\n\nDon't forget to update the value of `CODACY_ACCOUNT_TOKEN` with your token.\n\n2. Make sure you have Agent mode enabled: [vscode://settings/chat.agent.enabled](vscode://settings/chat.agent.enabled)\n\n3. Open the Copilot chat and switch the mode to `Agent`. You can check that the MCP server was enabled correctly by clicking on the `Select tools` icon, which should list all the available Codacy tools.\n\n![Copilot Agent with Codacy tools](docs/copilot_agent.png)\n\n## Troubleshooting\n\n### Claude Desktop and NVM\n\nWhen using NVM with Claude Desktop, NPX may not work. You should first install the MCP Server globally, and then use Node directly:\n\n```bash\nnpm install -g @codacy/codacy-mcp\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"codacy\": {\n      \"command\": \"/Users/yourusername/.nvm/versions/node/vXX.X.X/bin/node\",\n      \"args\": [\"/path-to/codacy-mcp/dist/index.js\"],\n      \"env\": {\n        \"CODACY_ACCOUNT_TOKEN\": \"<YOUR_TOKEN>\"\n      }\n    }\n  }\n}\n```\n\n## Contribute\n\nTo work locally on the MCP Server code, run:\n\n```bash\nnpm install\nnpm run update-api\nnpm run build\n```\n\n### Testing with Inspector\n\nYou can test the MCP server using the inspector tool. You can either set a `CODACY_ACCOUNT_TOKEN` environment variable or pass it inline:\n\n```bash\nCODACY_ACCOUNT_TOKEN=your_token_here npm run inspect\n```\n\nThis will build the project and launch the MCP inspector with your Codacy token.\n\n### Testing with an Agent\n\nYou can test your local instance configuring the MCP Server as follows:\n\n```\n\"codacy\": {\n  \"command\": \"/path/to/bin/node\",\n  \"args\": [\n    \"/path/to/codacy-mcp-server/dist/index.js\"\n  ],\n  \"env\": {\n    \"CODACY_ACCOUNT_TOKEN\": \"<YOUR_TOKEN>\"\n  }\n}\n```\n\n## Codacy-CLI Support\n\nIn order to use the [Codacy-CLI](https://github.com/codacy/codacy-cli-v2), it needs to be installed. Whenever the MCP Server will receive a request to analyze, it will try to install the CLI and initialize it.\n\nIn case you want to use a specific version of our CLI, send a `CODACY_CLI_VERSION` env variable in the MCP Server configuration.\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "codacy",
        "coding",
        "llms execute",
        "execution servers",
        "management code"
      ],
      "category": "code-execution"
    },
    "colesmcintosh--numpy-mcp": {
      "owner": "colesmcintosh",
      "name": "numpy-mcp",
      "url": "https://github.com/colesmcintosh/numpy-mcp",
      "imageUrl": "https://github.com/colesmcintosh.png",
      "description": "Perform numerical computations using NumPy, including basic arithmetic operations and linear algebra tasks such as matrix multiplication and statistical analysis. Interface seamlessly with LLMs through a standardized MCP protocol.",
      "stars": 2,
      "forks": 2,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-05-30T23:36:07Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/colesmcintosh-numpy-mcp-badge.png)](https://mseep.ai/app/colesmcintosh-numpy-mcp)\n\n# NumPy MCP Server\n\n<div align=\"center\">\n\n<strong>A Model Context Protocol (MCP) server for numerical computations with NumPy</strong>\n\n[![MIT licensed][mit-badge]][mit-url]\n\n</div>\n\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: ./LICENSE\n[python-badge]: https://img.shields.io/badge/python-3.8%2B-blue.svg\n[python-url]: https://www.python.org/downloads/\n\nA Model Context Protocol (MCP) server that provides mathematical calculations and operations using NumPy. This server exposes various mathematical tools through a standardized MCP interface, making it easy to perform numerical computations directly through Claude or other MCP-compatible LLMs.\n\n## Features\n\n- Basic arithmetic operations (addition)\n- Linear algebra computations (matrix multiplication, eigendecomposition)\n- Statistical analysis (mean, median, standard deviation, min, max)\n- Polynomial fitting\n\n## Installation\n\n### Quick Setup with Claude Desktop\n\nThe fastest way to get started is to install this server directly in Claude Desktop:\n\n```bash\n# Install the server in Claude Desktop\nmcp install server.py --name \"NumPy Calculator\"\n```\n\n### Manual Installation\n\nThis project uses UV for dependency management. To install:\n\n```bash\n# Install UV if you haven't already\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Clone the repository\ngit clone https://github.com/yourusername/math-mcp.git\ncd math-mcp\n\n# Create virtual environment and install dependencies\nuv venv\nsource .venv/bin/activate  # On Unix/macOS\n# or\n# .venv\\Scripts\\activate  # On Windows\nuv pip install -r requirements.txt\n```\n\n## Usage\n\n### Development Testing\n\nTest the server locally with the MCP Inspector:\n\n```bash\nmcp dev server.py\n```\n\n### Claude Desktop Integration\n\n1. Install the server in Claude Desktop:\n   ```bash\n   mcp install server.py --name \"NumPy Calculator\"\n   ```\n\n2. The server will now be available in Claude Desktop under \"NumPy Calculator\"\n\n3. You can use it by asking Claude to perform mathematical operations, for example:\n   - \"Calculate the eigenvalues of matrix [[1, 2], [3, 4]]\"\n   - \"Find the mean and standard deviation of [1, 2, 3, 4, 5]\"\n   - \"Multiply matrices [[1, 0], [0, 1]] and [[2, 3], [4, 5]]\"\n\n### Direct Execution\n\nFor advanced usage or custom deployments:\n\n```bash\npython server.py\n# or\nmcp run server.py\n```\n\n## Available Functions\n\nThe server provides the following mathematical functions through the MCP interface:\n\n### Basic Arithmetic\n\n- `add(a: int, b: int) -> int`: Add two integers together\n\n### Linear Algebra\n\n- `matrix_multiply(matrix_a: List[List[float]], matrix_b: List[List[float]]) -> List[List[float]]`: Multiply two matrices\n- `eigen_decomposition(matrix: List[List[float]]) -> Tuple[List[float], List[List[float]]]`: Compute eigenvalues and eigenvectors of a square matrix\n\n### Statistics\n\n- `statistical_analysis(data: List[float]) -> dict[str, float]`: Calculate basic statistics for a dataset including:\n  - Mean\n  - Median\n  - Standard deviation\n  - Minimum value\n  - Maximum value\n\n### Data Analysis\n\n- `polynomial_fit(x: List[float], y: List[float], degree: int = 2) -> List[float]`: Fit a polynomial of specified degree to the given data points\n\n## Development\n\n### Project Structure\n\n```\nmath-mcp/\n├── requirements.txt\n├── README.md\n└── server.py\n```\n\n### Code Quality\n\nThis project adheres to strict code quality standards:\n- Type hints throughout the codebase\n- Comprehensive docstrings following Google style\n- Error handling for numerical operations\n\n## Dependencies\n\n- NumPy: For numerical computations and linear algebra operations\n- FastMCP: For Model Context Protocol server implementation\n\n## License\n\nThis project is licensed under the MIT License.\n\n## Acknowledgments\n\n- NumPy team for their excellent scientific computing library\n- Model Context Protocol (MCP) for enabling standardized LLM interactions\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "code",
        "llms execute",
        "seamlessly llms",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "crazyrabbitLTC--mcp-code-review-server": {
      "owner": "crazyrabbitLTC",
      "name": "mcp-code-review-server",
      "url": "https://github.com/crazyrabbitLTC/mcp-code-review-server",
      "imageUrl": "https://github.com/crazyrabbitLTC.png",
      "description": "Perform structured code reviews by analyzing various codebases using Large Language Models to identify issues and provide recommendations for improvements. Supports multiple LLM providers and handles chunking for large projects.",
      "stars": 28,
      "forks": 22,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-24T08:15:07Z",
      "readme_content": "# Code Review Server\n\nA custom MCP server that performs code reviews using Repomix and LLMs.\n\n## Features\n\n- Flatten codebases using Repomix\n- Analyze code with Large Language Models\n- Get structured code reviews with specific issues and recommendations\n- Support for multiple LLM providers (OpenAI, Anthropic, Gemini)\n- Handles chunking for large codebases\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/code-review-server.git\ncd code-review-server\n\n# Install dependencies\nnpm install\n\n# Build the server\nnpm run build\n```\n\n## Configuration\n\nCreate a `.env` file in the root directory based on the `.env.example` template:\n\n```bash\ncp .env.example .env\n```\n\nEdit the `.env` file to set up your preferred LLM provider and API key:\n\n```bash\n# LLM Provider Configuration\nLLM_PROVIDER=OPEN_AI\nOPENAI_API_KEY=your_openai_api_key_here\n```\n\n## Usage\n\n### As an MCP Server\n\nThe code review server implements the Model Context Protocol (MCP) and can be used with any MCP client:\n\n```bash\n# Start the server\nnode build/index.js\n```\n\nThe server exposes two main tools:\n\n1. `analyze_repo`: Flattens a codebase using Repomix\n2. `code_review`: Performs a code review using an LLM\n\n## When to Use MCP Tools\n\nThis server provides two distinct tools for different code analysis needs:\n\n### analyze_repo\n\n**Use this tool when you need to:**\n- Get a high-level overview of a codebase's structure and organization\n- Flatten a repository into a textual representation for initial analysis\n- Understand the directory structure and file contents without detailed review\n- Prepare for a more in-depth code review\n- Quickly scan a codebase to identify relevant files for further analysis\n\n**Example situations:**\n- \"I want to understand the structure of this repository before reviewing it\"\n- \"Show me what files and directories are in this codebase\"\n- \"Give me a flattened view of the code to understand its organization\"\n\n### code_review\n\n**Use this tool when you need to:**\n- Perform a comprehensive code quality assessment\n- Identify specific security vulnerabilities, performance bottlenecks, or code quality issues\n- Get actionable recommendations for improving code\n- Conduct a detailed review with severity ratings for issues\n- Evaluate a codebase against best practices\n\n**Example situations:**\n- \"Review this codebase for security vulnerabilities\"\n- \"Analyze the performance of these specific JavaScript files\"\n- \"Give me a detailed code quality assessment of this repository\"\n- \"Review my code and tell me how to improve its maintainability\"\n\n**When to use parameters:**\n- `specificFiles`: When you only want to review certain files, not the entire repository\n- `fileTypes`: When you want to focus on specific file extensions (e.g., .js, .ts)\n- `detailLevel`: Use 'basic' for a quick overview or 'detailed' for in-depth analysis\n- `focusAreas`: When you want to prioritize certain aspects (security, performance, etc.)\n\n### Using the CLI Tool\n\nFor testing purposes, you can use the included CLI tool:\n\n```bash\nnode build/cli.js <repo_path> [options]\n```\n\nOptions:\n- `--files <file1,file2>`: Specific files to review\n- `--types <.js,.ts>`: File types to include in the review\n- `--detail <basic|detailed>`: Level of detail (default: detailed)\n- `--focus <areas>`: Areas to focus on (security,performance,quality,maintainability)\n\nExample:\n\n```bash\nnode build/cli.js ./my-project --types .js,.ts --detail detailed --focus security,quality\n```\n\n## Development\n\n```bash\n# Run tests\nnpm test\n\n# Watch mode for development\nnpm run watch\n\n# Run the MCP inspector tool\nnpm run inspector\n```\n\n## LLM Integration\n\nThe code review server integrates directly with multiple LLM provider APIs:\n\n- **OpenAI** (default: gpt-4o)\n- **Anthropic** (default: claude-3-opus-20240307)\n- **Gemini** (default: gemini-1.5-pro)\n\n### Provider Configuration\n\nConfigure your preferred LLM provider in the `.env` file:\n\n```bash\n# Set which provider to use\nLLM_PROVIDER=OPEN_AI  # Options: OPEN_AI, ANTHROPIC, or GEMINI\n\n# Provider API Keys (add your key for the chosen provider)\nOPENAI_API_KEY=your-openai-api-key\nANTHROPIC_API_KEY=your-anthropic-api-key\nGEMINI_API_KEY=your-gemini-api-key\n```\n\n### Model Configuration\n\nYou can optionally specify which model to use for each provider:\n\n```bash\n# Optional: Override the default models\nOPENAI_MODEL=gpt-4-turbo\nANTHROPIC_MODEL=claude-3-sonnet-20240229\nGEMINI_MODEL=gemini-1.5-flash-preview\n```\n\n### How the LLM Integration Works\n\n1. The `code_review` tool processes code using Repomix to flatten the repository structure\n2. The code is formatted and chunked if necessary to fit within LLM context limits\n3. A detailed prompt is generated based on the focus areas and detail level\n4. The prompt and code are sent directly to the LLM API of your chosen provider\n5. The LLM response is parsed into a structured format\n6. The review is returned as a JSON object with issues, strengths, and recommendations\n\nThe implementation includes retry logic for resilience against API errors and proper formatting to ensure the most relevant code is included in the review.\n\n## Code Review Output Format\n\nThe code review is returned in a structured JSON format:\n\n```json\n{\n  \"summary\": \"Brief summary of the code and its purpose\",\n  \"issues\": [\n    {\n      \"type\": \"SECURITY|PERFORMANCE|QUALITY|MAINTAINABILITY\",\n      \"severity\": \"HIGH|MEDIUM|LOW\",\n      \"description\": \"Description of the issue\",\n      \"line_numbers\": [12, 15],\n      \"recommendation\": \"Recommended fix\"\n    }\n  ],\n  \"strengths\": [\"List of code strengths\"],\n  \"recommendations\": [\"List of overall recommendations\"]\n}\n```\n\n## License\n\nMIT ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "codebases",
        "llm",
        "llms execute",
        "code reviews",
        "code review"
      ],
      "category": "code-execution"
    },
    "dagger--container-use": {
      "owner": "dagger",
      "name": "container-use",
      "url": "https://github.com/dagger/container-use",
      "imageUrl": "",
      "description": "Containerized environments for coding agents. Multiple agents can work independently, isolated in fresh containers and git branches. No conflicts, many experiments. Full execution history, terminal access to agent environments, git workflow. Any agent/model/infra stack.",
      "stars": 3110,
      "forks": 157,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-10-03T06:11:34Z",
      "readme_content": "<div align=\"center\">\n  <img src=\"./docs/images/container-use.png\" align=\"center\" alt=\"Container use: Development environments for coding agents.\" />\n  <h1 align=\"center\">container-use</h2>\n  <p align=\"center\">Containerized environments for coding agents. (📦🤖) (📦🤖) (📦🤖)</p>\n  <p align=\"center\">\n    <img src=\"https://img.shields.io/badge/stability-experimental-orange.svg\" alt=\"Experimental\" />\n    <a href=\"https://opensource.org/licenses/Apache-2.0\">\n      <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\">\n    </a>\n    <a href=\"https://container-use.com/discord\">\n      <img src=\"https://img.shields.io/discord/707636530424053791?logo=discord&logoColor=white&label=Discord&color=7289DA\" alt=\"Discord\">\n    </a>\n    <a href=\"https://github.com/clinebot/awesome-claude-code\">\n      <img src=\"https://awesome.re/mentioned-badge.svg\" alt=\"Mentioned in Awesome Claude Code\">\n    </a>\n  </p>\n</div>\n\n**Container Use** lets coding agents do their work in parallel environments without getting in your way. Go from babysitting one agent at a time to enabling multiple agents to work safely and independently with your preferred stack. See the [full documentation](https://container-use.com).\n\n<p align='center'>\n    <img src='./docs/images/demo.gif' width='700' alt='container-use demo'>\n</p>\n\nIt's an open-source MCP server that works as a CLI tool with Claude Code, Cursor, and other MCP-compatible agents. Powered by [Dagger](https://dagger.io).\n\n* 📦 **Isolated Environments**: Each agent gets a fresh container in its own git branch - run multiple agents without conflicts, experiment safely, discard failures instantly.\n* 👀 **Real-time Visibility**: See complete command history and logs of what agents actually did, not just what they claim.\n* 🚁 **Direct Intervention**: Drop into any agent's terminal to see their state and take control when they get stuck.\n* 🎮 **Environment Control**: Standard git workflow - just `git checkout <branch_name>` to review any agent's work.\n* 🌎 **Universal Compatibility**: Works with any agent, model, or infrastructure - no vendor lock-in.\n\n---\n\n🦺 This project is in early development and actively evolving. Submit issues and/or reach out to us on [Discord](https://container-use.com/discord) in the #container-use channel.\n\n---\n\n## Quick Start\n\n### Install\n\n```sh\n# macOS (recommended)\nbrew install dagger/tap/container-use\n\n# All platforms\ncurl -fsSL https://raw.githubusercontent.com/dagger/container-use/main/install.sh | bash\n```\n\n### Setup with Your Agent\n\nContainer Use works with any MCP-compatible agent. The setup is always the same: **add `container-use stdio` as an MCP server**.\n\n**👉 [Complete setup guide for all agents (Cursor, Goose, VSCode, etc.)](https://container-use.com/quickstart)**\n\n**Example with Claude Code:**\n\n```sh\n# Add Container Use MCP server\ncd /path/to/repository\nclaude mcp add container-use -- container-use stdio\n\n# Add agent rules (optional)\ncurl https://raw.githubusercontent.com/dagger/container-use/main/rules/agent.md >> CLAUDE.md\n```\n\n<details>\n<summary>💡 Command Shortcut</summary>\n\nThe `container-use` command is also available as `cu` for convenience. Both commands work identically:\n- `container-use stdio` (used in documentation)\n- `cu stdio` (shortcut)\n\n</details>\n\n### Try It\n\nAsk your agent to create something:\n> Create a hello world app in python using flask\n\nYour agent will work in an isolated environment and give you URLs to view the app and explore the code!",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "environments",
        "agents",
        "agent",
        "agent environments",
        "execution servers",
        "coding agents"
      ],
      "category": "code-execution"
    },
    "e2b-dev--mcp-server": {
      "owner": "e2b-dev",
      "name": "mcp-server",
      "url": "https://github.com/e2b-dev/mcp-server",
      "imageUrl": "https://github.com/e2b-dev.png",
      "description": "Integrates code execution and interpretation capabilities for AI applications, enhancing agent functionality through the E2B Sandbox. Compatible with JavaScript and Python editions for dynamic code manipulation.",
      "stars": 333,
      "forks": 52,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-03T16:50:09Z",
      "readme_content": "![E2B MCP Server Preview Light](/readme-assets/mcp-server-light.png#gh-light-mode-only)\n![E2B MCP Server Preview Dark](/readme-assets/mcp-server-dark.png#gh-dark-mode-only)\n\n# E2B MCP Server\n\n[![smithery badge](https://smithery.ai/badge/e2b)](https://smithery.ai/server/e2b)\n\nThis repository contains the source code for the [E2B](https://e2b.dev) MCP server.\n\nThe E2B MCP server allows you to add [code interpreting capabilities](https://github.com/e2b-dev/code-interpreter) to your Claude Desktop app via the E2B Sandbox. See demo [here](https://x.com/mishushakov/status/1863286108433317958).\n\n\nAvailable in two editions:\n\n- [JavaScript](packages/js/README.md)\n\n- [Python](packages/python/README.md)\n\n\n### Installing via Smithery\n\nYou can also install E2B for Claude Desktop automatically via [Smithery](https://smithery.ai/server/e2b):\n\n```bash\nnpx @smithery/cli install e2b --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "e2b",
        "llms",
        "sandbox",
        "e2b dev",
        "llms execute",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "essenecrucix-netizen--jarvis": {
      "owner": "essenecrucix-netizen",
      "name": "jarvis",
      "url": "https://github.com/essenecrucix-netizen/jarvis",
      "imageUrl": "https://github.com/essenecrucix-netizen.png",
      "description": "An intelligent coding assistant that supports multiple AI models for code generation, modifications, and technical discussions. It can handle various file types for text extraction and data parsing to facilitate development tasks.",
      "stars": 1,
      "forks": 2,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-01-15T00:11:47Z",
      "readme_content": "# J.A.R.V.I.S. - AI Code Assistant\n\nJ.A.R.V.I.S. is an intelligent coding assistant that leverages multiple state-of-the-art language models to help you with code generation, modifications, and technical discussions.\n\n## Features\n\n- **Multi-Model Support**: Choose between different AI models for your coding needs:\n  - DeepSeek Coder V3\n  - Gemini 2.0 Flash Experimental\n  - Grok 2\n  - Qwen 2.5 Coder\n  - Llama 3.3 70B Instruct\n  - Claude 3.5 Sonnet\n  - GPT-4 Turbo\n  - GPT-4o\n  - o1 Preview\n\n- **File Attachment Support**:\n  - PDF files with text extraction\n  - Microsoft Word documents (.docx)\n  - Excel spreadsheets with sheet parsing\n  - Images with OCR capabilities\n  - Enhanced Markdown with GFM support\n  - All major programming languages\n  - Configuration files\n  - Text and documentation files\n  - File preview with syntax highlighting\n  - Multiple file upload support\n  - Progress indicators and file size display\n  - Type-specific icons and preview buttons\n\n- **Real-Time Updates**:\n  - WebSocket-based notifications\n  - Instant feedback for code changes\n  - Real-time workspace updates\n  - Automatic change notifications\n\n- **Workspace Management**:\n  - Create and manage multiple workspaces\n  - View workspace history\n  - Delete workspaces when no longer needed\n  - Rename workspaces\n  - Browse workspace file structure\n\n- **Code Generation & Modification**:\n  - Generate new code based on natural language prompts\n  - Modify existing code with AI assistance\n  - Preview changes before applying them\n  - View diffs of proposed changes\n\n- **Interactive Chat**:\n  - Discuss code and technical concepts\n  - Get explanations about existing code\n  - Context-aware responses based on workspace content\n  - Attach files for additional context\n\n## Technical Stack\n\n- **Backend**:\n  - Flask web framework\n  - Flask-SocketIO for WebSocket support\n  - Eventlet for async operations\n\n- **Frontend**:\n  - Pure JavaScript\n  - TailwindCSS for styling\n  - CodeMirror for code editing\n  - Socket.IO client for real-time notifications\n  - PDF.js for PDF processing\n  - Mammoth.js for Word documents\n  - XLSX.js for Excel files\n  - Tesseract.js for OCR\n  - Marked and Unified.js for Markdown\n\n## Installation\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n3. Set up your environment variables in `.env`:\n   ```\n   DEEPSEEK_API_KEY=your_deepseek_api_key\n   GROK_API_KEY=your_grok_api_key\n   GOOGLE_API_KEY=your_google_api_key\n   ANTHROPIC_API_KEY=your_anthropic_api_key\n   OPENAI_API_KEY=your_openai_api_key\n   ```\n\n## Usage\n\n1. Start the server:\n   ```bash\n   python app.py\n   ```\n2. Open your browser and navigate to `http://localhost:5000`\n3. Create a new workspace or select an existing one\n4. Choose your preferred AI model\n5. Start coding with AI assistance!\n\n## Model Capabilities\n\n- **DeepSeek Coder V3**: Specialized in code generation and modification\n- **Gemini 2.0 Pro**: Advanced code generation and natural language understanding\n- **Grok 2**: Advanced language model for code and natural language\n- **Qwen 2.5 Coder**: Specialized 32B model for code generation\n- **Llama 3.3 70B Instruct**: Large context window and strong code generation capabilities\n- **Claude 3.5 Sonnet**: Advanced reasoning and code understanding\n\n## Contributing\n\nContributions are welcome! Please feel free to submit pull requests.\n\n## Special Thanks\n\n- **Nikole Cardoso** for her invaluable contributions and support\n- **Guilherme Guirro** for his expertise and guidance\n- **Felipe Santos** for his dedication and insights\n\nTheir contributions have been instrumental in making J.A.R.V.I.S. better.\n\n## Platform Compatibility\n\nThis application has been tested and confirmed working on:\n- Linux (native)\n- Windows Subsystem for Linux (WSL 2)\n- Windows (native, no admin privileges required)\n\nThe application uses directory junctions on Windows to avoid requiring admin privileges, while maintaining symlink functionality on Unix-like systems.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "code",
        "llms execute",
        "coding agents",
        "coding assistant"
      ],
      "category": "code-execution"
    },
    "ezyang--codemcp": {
      "owner": "ezyang",
      "name": "codemcp",
      "url": "https://github.com/ezyang/codemcp",
      "imageUrl": "https://github.com/ezyang.png",
      "description": "Enhance file management by reading, writing, and editing text and image files with powerful MCP tools. Supports efficient file operations with optional customization parameters.",
      "stars": 1559,
      "forks": 133,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T08:02:56Z",
      "readme_content": "# codemcp\n\nMake Claude Desktop a pair programming assistant by installing codemcp.  With\nit, you can directly ask Claude to implement features, fix bugs and do\nrefactors on a codebase on your computer; Claude will directly edit files and\nrun tests.  Say goodbye to copying code in and out of Claude's chat window!\n\n![Screenshot of Claude Desktop with codemcp](static/screenshot.png?raw=true)\n\ncodemcp offers similar functionality to other AI coding software (Claude Code,\nCursor, Cline, Aider), but it occupies a unique point in the design space:\n\n1. It's intended to be used with **Claude Pro**, Anthropic's $20/mo\n   subscription offering.  I like paying for my usage with a subscription plan\n   because it means **zero marginal cost** for agent actions; no more feeling\n   bad that you wasted five bucks on a changeset that doesn't work.\n\n   Note that if you have Claude Max ($100/mo), Claude Code can also be used\n   with subscription based pricing.  The value proposition for codemcp is\n   murkier in this case (and it is definitely inferior to Claude Code in some\n   respects), but you can still use codemcp with Claude Max if you prefer some\n   of the other UI decisions it makes.  (Also, it's open source, so you can\n   change it if you don't like it, unlike Claude Code!)\n\n2. It's built around **auto-accept by default**.  I want my agent to get as\n   far as it can without my supervision, so I can review everything in one go at\n   the end.  There are two key things that codemcp does differently than most\n   coding agents: we **forbid unrestricted shell**, instead requiring you to\n   predeclare commands the agent can use in ``codemcp.toml``, and we **Git\n   version all LLM edits**, so you can roll back agent changes on a\n   fine-grained basis and don't have to worry about forgetting to commit\n   changes.\n\n3. It's **IDE agnostic**: you ask Claude to make changes, it makes them, and\n   then you can use your favorite IDE setup to review the changes and make\n   further edits.  I use vim as my daily driver editor, and coding environments\n   that require VSCode or a specific editor are a turn off for me.\n\n## IMPORTANT: For master users - Major changes for token efficiency\n\nTo improve codemcp's token efficiency, on master I am in the process of\nchanging codemcp back into a multi-tool tool (instead of a single tool whose\ninstructions are blatted into chat when you InitProject).  This means you have\nto manually approve tool use.  Because tool use approval is persistent across\nmultiple chats, I think this is a reasonable tradeoff to make, but if you\nreally don't like, file a bug at\n[refined-claude](https://github.com/ezyang/refined-claude/issues) browser\nextension for supporting auto-approve tool use.\n\n## Installation\n\nI recommend this specific way of installing and using codemcp:\n\n1. Install `uv` and install git, if they are not installed already.\n\n2. Install [claude-mcp](https://chromewebstore.google.com/detail/mcp-for-claudeai/jbdhaamjibfahpekpnjeikanebpdpfpb) on your browser.\n   This enables you to connect to SSE MCP servers directly from the website,\n   which means you don't need to use Claude Desktop and can easily have\n   multiple chat windows going in parallel.  We expect this extension should\n   be soon obsoleted by the rollout of\n   [Integrations](https://www.anthropic.com/news/integrations).  At time of\n   writing, however, Integrations have not yet arrived for Claude Pro subscribers.\n\n3. Run codemcp using ``uvx --from git+https://github.com/ezyang/codemcp@prod codemcp serve``.\n   You can add ``--port 1234`` if you need it to listen on a non-standard port.\n\n   Pro tip: if you like to live dangerously, you can change `prod` to `main`.  If\n   you want to pin to a specific release, replace it with `0.3.0` or similar.\n\n   Pro tip: you can run codemcp remotely!  If you use\n   [Tailscale](https://tailscale.com/) and trust all devices on your Tailnet,\n   you can do this securely by passing ``--host 100.101.102.103`` (replace the\n   IP with the Tailscale IP address of your node.  This IP typically lives in\n   the 100.64.0.0/10 range.)  **WARNING:** Anyone with access to this MCP can perform\n   arbitrary code execution on your computer, it is **EXTREMELY** unlikely you want to\n   bind to 0.0.0.0.\n\n4. Configure claude-mcp with URL: ``http://127.0.0.1:8000/sse`` (replace the port if needed.)\n\n5. Unfortunately, the web UI inconsistently displays the hammer icon.  However, you can verify\n   that the MCP server is working by looking for \"[MCP codemcp] SSE connection opened\" in the\n   Console, or by asking Claude what tools it has available (it should say\n   tools from codemcp are available.)\n\nIf you prefer to use Claude Desktop or have unusual needs, check out [INSTALL.md](INSTALL.md) for\ninstallation instructions for a variety of non-standard situations.\n\n## Usage\n\nFirst, you must create a `codemcp.toml` file in the Git repository checkout\nyou want to work on.  If you want the agent to be able to do things like run\nyour formatter or run tests, add the commands to execute them in the commands\nsection (note: these commands need to appropriately setup any virtual\nenvironment they need):\n\n```toml\nformat = [\"./run_format.sh\"]\ntest = [\"./run_test.sh\"]\n```\n\nThe ``format`` command is special; it is always run after every file edit.\n\nNext, in Claude Desktop, we recommend creating a Project and putting this in\nthe Project Instructions:\n\n```\nInitialize codemcp with $PROJECT_DIR\n```\n\nWhere `$PROJECT_DIR` is the path to the project you want to work on.\n\nThen chat with Claude about what changes you want to make to the project.\nEvery time codemcp makes a change to your code, it will generate a commit.\n\nTo see some sample transcripts using this tool, check out:\n\n- [Implement a new feature](https://claude.ai/share/a229d291-6800-4cb8-a0df-896a47602ca0)\n- [Fix failing tests](https://claude.ai/share/2b7161ef-5683-4261-ad45-fabc3708f950)\n- [Do a refactor](https://claude.ai/share/f005b43c-a657-43e5-ad9f-4714a5cd746f)\n\ncodemcp will generate a commit per chat and amend it as it is working on your feature.\n\n## Philosophy\n\n- When you get rate limited, take the time to do something else (review\n  Claude's code, review someone else's code, make plans, do some meetings)\n\n- This is *not* an autonomous agent.  At minimum, you have to intervene after\n  every chat to review the changes and request the next change.  While you\n  *can* ask for a long list of things to be done in a single chat, you will\n  likely hit Claude Desktop's output limit and have to manually \"continue\" the\n  agent anyway.  Embrace it, and use the interruptions to make sure Claude is\n  doing the right thing.\n\n- When Claude goes off the rails, it costs you time rather than dollars.\n  Behave accordingly: if time is the bottleneck, watch Claude's incremental\n  output carefully.\n\n## Configuration\n\nHere are all the config options supported by `codemcp.toml`:\n\n```toml\nproject_prompt = \"\"\"\nBefore beginning work on this feature, write a short haiku.  Do this only once.\n\"\"\"\n\n[commands]\nformat = [\"./run_format.sh\"]\ntest = [\"./run_test.sh\"]\n```\n\nThe `project_prompt` will be loaded when you initialize the project in chats.\n\nThe `commands` section allows you to configure commands for specific tools.  The\nnames are told to the LLM, who will decide when it wants to run them.  You can add\ninstructions how to use tools in the `project_prompt`; we also support a more verbose\nsyntax where you can give specific instructions on a tool-by-tool basis:\n\n```\n[commands.test]\ncommand = [\"./run_test.sh\"]\ndoc = \"Accepts a pytest-style test selector as an argument to run a specific test.\"\n```\n\n## Troubleshooting\n\nTo run the server with inspector, use:\n\n```\nPYTHONPATH=. mcp dev codemcp/__main__.py\n```\n\nLogs are written to `~/.codemcp/codemcp.log`. The log level can be set in a global configuration file at `~/.codemcprc`:\n\n```toml\n[logger]\nverbosity = \"INFO\"  # Can be DEBUG, INFO, WARNING, ERROR, or CRITICAL\n```\n\nLogging is not configurable on a per project basis, but this shouldn't matter\nmuch because it's difficult to use Claude Desktop in parallel on multiple\nprojects anyway.\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "codemcp",
        "llms",
        "coding",
        "llms execute",
        "codemcp enhance",
        "ezyang codemcp"
      ],
      "category": "code-execution"
    },
    "formulahendry--mcp-server-code-runner": {
      "owner": "formulahendry",
      "name": "mcp-server-code-runner",
      "url": "https://github.com/formulahendry/mcp-server-code-runner",
      "imageUrl": "https://github.com/formulahendry.png",
      "description": "Run code snippets in various programming languages and view the results instantly. Supports a wide range of languages for testing and debugging code snippets efficiently.",
      "stars": 205,
      "forks": 26,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T16:51:12Z",
      "readme_content": "# Code Runner MCP Server\n[![NPM Downloads](https://img.shields.io/npm/d18m/mcp-server-code-runner)](https://www.npmjs.com/package/mcp-server-code-runner) [![smithery badge](https://smithery.ai/badge/@formulahendry/mcp-server-code-runner)](https://smithery.ai/server/@formulahendry/mcp-server-code-runner) [![Docker Pulls](https://img.shields.io/docker/pulls/formulahendry/mcp-server-code-runner)](https://hub.docker.com/r/formulahendry/mcp-server-code-runner)\n\nMCP Server for running code snippet and show the result.\n\nIt supports running multiple programming languages: **JavaScript, PHP, Python, Perl, Perl 6, Ruby, Go, Lua, Groovy, PowerShell, BAT/CMD, BASH/SH, F# Script, C# Script, VBScript, TypeScript, CoffeeScript, Scala, Swift, Julia, Crystal, OCaml Script, R, AppleScript, Elixir, Clojure, Racket, Scheme, AutoHotkey, AutoIt, Kotlin Script, Dart, Haskell, Ni, Lisp, Kit, V, SCSS, Sass**. Full list could be seen here in [constants.ts](https://github.com/formulahendry/mcp-server-code-runner/blob/main/src/constants.ts).\n\n<a href=\"https://glama.ai/mcp/servers/d3mluq4vy9\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/d3mluq4vy9/badge\" alt=\"mcp-server-code-runner MCP server\" />\n</a>\n\n## Setup\n\n### npx for VS Code\n\nInstall the Code Runner MCP server in VS Code using below buttons:\n\n[![Install in VS Code](https://img.shields.io/badge/Install_MCP_Server_(npx)-VS_Code-0098FF)](https://vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522mcp-server-code-runner%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522mcp-server-code-runner%2540latest%2522%255D%257D) [![Install in VS Code Insiders](https://img.shields.io/badge/Install_MCP_Server_(npx)-VS_Code_Insiders-24bfa5)](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522mcp-server-code-runner%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522mcp-server-code-runner%2540latest%2522%255D%257D)\n\nAlternatively, you can add configuration in `settings.json`:\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [],\n    \"servers\": {\n      \"mcp-server-code-runner\": {\n        \"command\": \"npx\",\n        \"args\": [\n          \"-y\",\n          \"mcp-server-code-runner@latest\"\n        ],\n      }\n    }\n  }\n}\n```\n\n### npx for Claude Desktop\n\nConfiguration in `claude_desktop_config.json`: \n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-code-runner\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-server-code-runner@latest\"\n      ],\n    }\n  }\n}\n```\n\n### Docker\n\nUse VS Code as example. Install the Code Runner MCP server in VS Code using below buttons:\n\n[![Install in VS Code](https://img.shields.io/badge/Install_MCP_Server_(Docker)-VS_Code-0098FF)](https://vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522mcp-server-code-runner%2522%252C%2522command%2522%253A%2522docker%2522%252C%2522args%2522%253A%255B%2522run%2522%252C%2522--rm%2522%252C%2522-i%2522%252C%2522formulahendry%252Fmcp-server-code-runner%2522%255D%257D) [![Install in VS Code Insiders](https://img.shields.io/badge/Install_MCP_Server_(Docker)-VS_Code_Insiders-24bfa5)](https://insiders.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%2522mcp-server-code-runner%2522%252C%2522command%2522%253A%2522docker%2522%252C%2522args%2522%253A%255B%2522run%2522%252C%2522--rm%2522%252C%2522-i%2522%252C%2522formulahendry%252Fmcp-server-code-runner%2522%255D%257D)\n\nAlternatively, you can add configuration in `settings.json`:\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [],\n    \"servers\": {\n      \"mcp-server-code-runner\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"-i\",\n          \"formulahendry/mcp-server-code-runner\"\n        ]\n      }\n    }\n  }\n}\n```\n\n### npx issue on Widnows\n\nOn Windows, [MCP servers may fail to connect with `npx`](https://github.com/modelcontextprotocol/servers/issues/40).\n\nYou could try below two workarounds:\n\n#### use bunx\n\n1. Install [Bun](https://bun.sh/docs/installation).\n2. In configuration, change `npx` with `bunx`.\n\n#### use cmd\n\nBelow is VS Code configuration in `settings.json`:\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [],\n    \"servers\": {\n      \"mcp-server-code-runner\": {\n        \"command\": \"cmd\",\n        \"args\": [\n          \"/c\",\n          \"npx\",\n          \"-y\",\n          \"mcp-server-code-runner@latest\"\n        ],\n      }\n    }\n  }\n}\n```\n\n## Run with [Streamable HTTP Transport](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http)\n\n```shell\nnpm install -g mcp-server-code-runner@latest\nmcp-server-code-runner --transport http\n```\n\n## Usage\n\nBefore using Code Runner MCP Server, please make sure interpreter or compiler of the programming language you want to run is set in `PATH` environment variable.\n\nTry below prompts in the application which has configured Code Runner MCP Server:\n\n* `Run the JavaScript Code: console.log(5+6)`\n* `Where is temporary folder in my OS? Use run-code tool`\n* `How many CPUs do I have in my machine? Use run-code tool`\n\n![](./images/usage-confirm.png)\n\n![](./images/usage-result.png)\n\n## Build your own MCP Server\n\nWant to build your own MCP Server? Try [Yeoman Generator for MCP Server](https://www.npmjs.com/package/generator-mcp) to create your MCP Server project!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "snippets",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "g0t4--mcp-server-commands": {
      "owner": "g0t4",
      "name": "mcp-server-commands",
      "url": "https://github.com/g0t4/mcp-server-commands",
      "imageUrl": "https://github.com/g0t4.png",
      "description": "An MCP server that executes shell commands or scripts, returning both standard output and error messages. It supports the execution of various commands and allows input via stdin for enhanced functionality.",
      "stars": 198,
      "forks": 34,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:31:55Z",
      "readme_content": "## Tools\n\nTools are for LLMs to request. Claude Sonnet 3.5 intelligently uses `run_command`. And, initial testing shows promising results with [Groq Desktop with MCP](https://github.com/groq/groq-desktop-beta) and `llama4` models.\n\nCurrently, just one command to rule them all!\n\n- `run_command` - run a command, i.e. `hostname` or `ls -al` or `echo \"hello world\"` etc\n  - Returns `STDOUT` and `STDERR` as text\n  - Optional `stdin` parameter means your LLM can\n    - pass code in `stdin` to commands like `fish`, `bash`, `zsh`, `python`\n    - create files with `cat >> foo/bar.txt` from the text in `stdin`\n\n> [!WARNING]\n> Be careful what you ask this server to run!\n> In Claude Desktop app, use `Approve Once` (not `Allow for This Chat`) so you can review each command, use `Deny` if you don't trust the command.\n> Permissions are dictated by the user that runs the server.\n> DO NOT run with `sudo`.\n\n## Video walkthrough\n\n<a href=\"https://youtu.be/0-VPu1Pc18w\"><img src=\"https://img.youtube.com/vi/0-VPu1Pc18w/maxresdefault.jpg\" width=\"480\" alt=\"YouTube Thumbnail\"></a>\n\n## Prompts\n\nPrompts are for users to include in chat history, i.e. via `Zed`'s slash commands (in its AI Chat panel)\n\n- `run_command` - generate a prompt message with the command output\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nGroq Desktop (beta, macOS) uses `~/Library/Application Support/groq-desktop-app/settings.json`\n\n### Use the published npm package\n\nPublished to npm as [mcp-server-commands](https://www.npmjs.com/package/mcp-server-commands) using this [workflow](https://github.com/g0t4/mcp-server-commands/actions)\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-commands\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-commands\"]\n    }\n  }\n}\n```\n\n### Use a local build (repo checkout)\n\nMake sure to run `npm run build`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-commands\": {\n      // works b/c of shebang in index.js\n      \"command\": \"/path/to/mcp-server-commands/build/index.js\"\n    }\n  }\n}\n```\n\n## Local Models\n\n- Most models are trained such that they don't think they can run commands for you.\n  - Sometimes, they use tools w/o hesitation... other times, I have to coax them.\n  - Use a system prompt or prompt template to instruct that they should follow user requests. Including to use `run_commands` without double checking.\n- Ollama is a great way to run a model locally (w/ Open-WebUI)\n\n```sh\n# NOTE: make sure to review variants and sizes, so the model fits in your VRAM to perform well!\n\n# Probably the best so far is [OpenHands LM](https://www.all-hands.dev/blog/introducing-openhands-lm-32b----a-strong-open-coding-agent-model)\nollama pull https://huggingface.co/lmstudio-community/openhands-lm-32b-v0.1-GGUF\n\n# https://ollama.com/library/devstral\nollama pull devstral\n\n# Qwen2.5-Coder has tool use but you have to coax it\nollama pull qwen2.5-coder\n```\n\n### HTTP / OpenAPI\n\nThe server is implemented with the `STDIO` transport.\nFor `HTTP`, use [`mcpo`](https://github.com/open-webui/mcpo) for an `OpenAPI` compatible web server interface.\nThis works with [`Open-WebUI`](https://github.com/open-webui/open-webui)\n\n```bash\nuvx mcpo --port 3010 --api-key \"supersecret\" -- npx mcp-server-commands\n\n# uvx runs mcpo => mcpo run npx => npx runs mcp-server-commands\n# then, mcpo bridges STDIO <=> HTTP\n```\n\n> [!WARNING]\n> I briefly used `mcpo` with `open-webui`, make sure to vet it for security concerns.\n\n### Logging\n\nClaude Desktop app writes logs to `~/Library/Logs/Claude/mcp-server-mcp-server-commands.log`\n\nBy default, only important messages are logged (i.e. errors).\nIf you want to see more messages, add `--verbose` to the `args` when configuring the server.\n\nBy the way, logs are written to `STDERR` because that is what Claude Desktop routes to the log files.\nIn the future, I expect well formatted log messages to be written over the `STDIO` transport to the MCP client (note: not Claude Desktop app).\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "executes",
        "commands",
        "llms execute",
        "execution servers",
        "server commands"
      ],
      "category": "code-execution"
    },
    "garc33--js-sandbox-mcp-server": {
      "owner": "garc33",
      "name": "js-sandbox-mcp-server",
      "url": "https://github.com/garc33/js-sandbox-mcp-server",
      "imageUrl": "https://github.com/garc33.png",
      "description": "Provides a secure JavaScript execution environment with configurable execution time and memory limits, enabling the safe execution of JavaScript code in isolation.",
      "stars": 5,
      "forks": 6,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-08-29T07:30:10Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/garc33-js-sandbox-mcp-server-badge.png)](https://mseep.ai/app/garc33-js-sandbox-mcp-server)\n\n# js-sandbox MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@garc33/js-sandbox-mcp-server)](https://smithery.ai/server/@garc33/js-sandbox-mcp-server)\n\nA Model Context Protocol server that provides a secure JavaScript execution environment.\n\n<a href=\"https://glama.ai/mcp/servers/agatnhlgki\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/agatnhlgki/badge\" alt=\"JavaScript Sandbox Server MCP server\" />\n</a>\n\n## Features\n\n### Tools\n- `execute_js` - Executes JavaScript code in an isolated environment\n  - Parameters:\n    - `code` (required): JavaScript code to execute\n    - `timeout` (optional): Maximum execution time in milliseconds (100-30000ms)\n    - `memory` (optional): Memory limit in bytes (1MB-100MB)\n  - Returns the result of code execution\n\n### Security\n- Isolated code execution in a controlled environment\n- Configurable execution time and memory limits\n- Protection against malicious code\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nDevelopment mode with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install JavaScript Sandbox Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@garc33/js-sandbox-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @garc33/js-sandbox-mcp-server --client claude\n```\n\nTo use with Claude Desktop, add the server configuration:\n\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nWindows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"js-sandbox\": {\n      \"command\": \"/path/to/js-sandbox/build/index.js\"\n    }\n  }\n}\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "garc33",
        "javascript",
        "garc33 js",
        "llms execute",
        "secure javascript"
      ],
      "category": "code-execution"
    },
    "gianlucamazza--mcp_python_toolbox": {
      "owner": "gianlucamazza",
      "name": "mcp_python_toolbox",
      "url": "https://github.com/gianlucamazza/mcp_python_toolbox",
      "imageUrl": "https://github.com/gianlucamazza.png",
      "description": "Facilitates management and development of Python projects by performing file operations, analyzing and formatting code, managing dependencies, and executing scripts within a secure environment.",
      "stars": 5,
      "forks": 5,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-07-18T11:03:00Z",
      "readme_content": "# MCP Python Toolbox\n\nA Model Context Protocol (MCP) server that provides a comprehensive set of tools for Python development, enabling AI assistants like Claude to effectively work with Python code and projects.\n\n## Overview\n\nMCP Python Toolbox implements a Model Context Protocol server that gives Claude the ability to perform Python development tasks through a standardized interface. It enables Claude to:\n\n- Read, write, and manage files within a workspace\n- Analyze, format, and lint Python code\n- Manage virtual environments and dependencies\n- Execute Python code safely\n\n## Features\n\n### File Operations (`FileOperations`)\n- Safe file operations within a workspace directory\n- Path validation to prevent unauthorized access outside workspace\n- Read and write files with line-specific operations\n- Create and delete files and directories\n- List directory contents with detailed metadata (size, type, modification time)\n- Automatic parent directory creation when writing files\n\n### Code Analysis (`CodeAnalyzer`)\n- Parse and analyze Python code structure using AST\n- Extract detailed information about:\n  - Import statements and their aliases\n  - Function definitions with arguments and decorators\n  - Class definitions with base classes and methods\n  - Global variable assignments\n- Format code using:\n  - Black (default)\n  - PEP8 (using autopep8)\n- Comprehensive code linting using Pylint with detailed reports\n\n### Project Management (`ProjectManager`)\n- Create and manage virtual environments with pip support\n- Flexible dependency management:\n  - Install from requirements.txt\n  - Install from pyproject.toml\n  - Support for specific package versions\n- Advanced dependency handling:\n  - Check for version conflicts between packages\n  - List all installed packages with versions\n  - Update packages to specific versions\n  - Generate requirements.txt from current environment\n\n### Code Execution (`CodeExecutor`)\n- Execute Python code in a controlled environment\n- Uses project's virtual environment for consistent dependencies\n- Temporary file management for code execution\n- Capture stdout, stderr, and exit codes\n- Support for custom working directories\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/gianlucamazza/mcp_python_toolbox.git\ncd mcp_python_toolbox\n```\n\n2. Create and activate a virtual environment:\n```bash\npython -m venv .venv\nsource .venv/bin/activate  # Linux/Mac\n# or\n.venv\\Scripts\\activate  # Windows\n```\n\n3. Install the package in development mode:\n```bash\npip install -e \".[dev]\"\n```\n\n## Usage\n\n### Running as a CLI Tool\n\nThe simplest way to start the server is using the CLI:\n\n```bash\n# Start with current directory as workspace\npython -m mcp_python_toolbox\n\n# Or specify a workspace directory\npython -m mcp_python_toolbox --workspace /path/to/your/project\n```\n\n### Setting Up with Claude Desktop\n\nClaude Desktop can automatically launch and manage the MCP Python Toolbox server. Here's how to configure it:\n\n1. Install and set up the MCP Python Toolbox as described above\n2. Add a configuration entry for the Python Toolbox in Claude Desktop's MCP tools configuration:\n\n```json\n\"python-toolbox\": {\n  \"command\": \"/Users/username/path/to/mcp_python_toolbox/.venv/bin/python\",\n  \"args\": [\n    \"-m\",\n    \"mcp_python_toolbox\",\n    \"--workspace\",\n    \"/Users/username/path/to/workspace\"\n  ],\n  \"env\": {\n    \"PYTHONPATH\": \"/Users/username/path/to/mcp_python_toolbox/src\",\n    \"PATH\": \"/opt/homebrew/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\",\n    \"VIRTUAL_ENV\": \"/Users/username/path/to/mcp_python_toolbox/.venv\",\n    \"PYTHONHOME\": \"\"\n  }\n}\n```\n\n3. Customize the paths to match your environment\n4. Claude Desktop will automatically start the MCP server when needed\n5. Claude will now have access to Python development tools through the MCP interface\n\n### Programmatic Usage\n\n```python\nfrom mcp_python_toolbox import PythonToolboxServer\n\nserver = PythonToolboxServer(workspace_root=\"/path/to/your/project\")\nserver.setup()\nserver.run()\n```\n\n### Core Module Examples\n\n#### File Operations\n```python\nfrom mcp_python_toolbox.core import FileOperations\n\nfile_ops = FileOperations(workspace_root=\"/path/to/project\")\n\n# Read file contents\ncontent = file_ops.read_file(\"src/example.py\")\n# Read specific lines\nlines = file_ops.read_file(\"src/example.py\", start_line=10, end_line=20)\n\n# Write to file\nfile_ops.write_file(\"output.txt\", \"Hello, World!\")\n# Append to file\nfile_ops.write_file(\"log.txt\", \"New entry\\n\", mode='a')\n\n# List directory contents\ncontents = file_ops.list_directory(\"src\")\nfor item in contents:\n    print(f\"{item['name']} - {item['type']} - {item['size']} bytes\")\n```\n\n#### Code Analysis\n```python\nfrom mcp_python_toolbox.core import CodeAnalyzer\n\nanalyzer = CodeAnalyzer(workspace_root=\"/path/to/project\")\n\n# Analyze Python file structure\nanalysis = analyzer.parse_python_file(\"src/example.py\")\nprint(f\"Found {len(analysis['functions'])} functions\")\nprint(f\"Found {len(analysis['classes'])} classes\")\n\n# Format code\nformatted = analyzer.format_code(code, style='black')\n\n# Lint code\nissues = analyzer.lint_code(\"src/example.py\")\nfor issue in issues:\n    print(f\"Line {issue['line']}: {issue['message']}\")\n```\n\n#### Project Management\n```python\nfrom mcp_python_toolbox.core import ProjectManager\n\npm = ProjectManager(workspace_root=\"/path/to/project\")\n\n# Create virtual environment\npm.create_virtual_environment()\n\n# Install dependencies\npm.install_dependencies()  # from requirements.txt or pyproject.toml\npm.install_dependencies(\"requirements-dev.txt\")  # from specific file\n\n# Check for conflicts\nconflicts = pm.check_dependency_conflicts()\nif conflicts:\n    print(\"Found dependency conflicts:\")\n    for conflict in conflicts:\n        print(f\"{conflict['package']} requires {conflict['requires']}\")\n\n# Update packages\npm.update_package(\"requests\")  # to latest\npm.update_package(\"flask\", version=\"2.0.0\")  # to specific version\n```\n\n#### Code Execution\n```python\nfrom mcp_python_toolbox.core import CodeExecutor\n\nexecutor = CodeExecutor(workspace_root=\"/path/to/project\")\n\ncode = '''\ndef greet(name):\n    return f\"Hello, {name}!\"\n\nprint(greet(\"World\"))\n'''\n\nresult = executor.execute_code(code)\nprint(f\"Output: {result['stdout']}\")\nprint(f\"Errors: {result['stderr']}\")\nprint(f\"Exit code: {result['exit_code']}\")\n```\n\n## Development\n\n### Running Tests\n\n```bash\npytest\n```\n\n### Type Checking\n\n```bash\nmypy src/mcp_python_toolbox\n```\n\n### Linting\n\n```bash\npylint src/mcp_python_toolbox\n```\n\n### Formatting\n\n```bash\nblack src/mcp_python_toolbox\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n\n- Implements the [Model Context Protocol](https://github.com/modelcontextprotocol/servers) specification\n- Built with modern Python development tools and best practices\n- Uses industry-standard formatting (Black) and linting (Pylint) tools\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_python_toolbox",
        "python",
        "llms",
        "mcp_python_toolbox facilitates",
        "llms execute",
        "code managing"
      ],
      "category": "code-execution"
    },
    "gwbischof--outsource-mcp": {
      "owner": "gwbischof",
      "name": "outsource-mcp",
      "url": "https://github.com/gwbischof/outsource-mcp",
      "imageUrl": "",
      "description": "Give your AI assistant its own AI assistants. For example: \"Could you ask openai to generate an image of a dog?\"",
      "stars": 23,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T15:18:22Z",
      "readme_content": "# Outsource MCP\n\nAn MCP (Model Context Protocol) server that enables AI applications to outsource tasks to various model providers through a unified interface.\n\n<img width=\"1154\" alt=\"image\" src=\"https://github.com/user-attachments/assets/cd364a7c-eae5-4c58-bc1f-fdeea6cb8434\" />\n\n<img width=\"1103\" alt=\"image\" src=\"https://github.com/user-attachments/assets/55924981-83e9-4811-9f51-b049595b7505\" />\n\n\nCompatible with any AI tool that supports the Model Context Protocol, including Claude Desktop, Cline, and other MCP-enabled applications.\nBuilt with [FastMCP](https://github.com/mcp/fastmcp) for the MCP server implementation and [Agno](https://github.com/agno-agi/agno) for AI agent capabilities.\n\n## Features\n\n- 🤖 **Multi-Provider Support**: Access 20+ AI providers through a single interface\n- 📝 **Text Generation**: Generate text using models from OpenAI, Anthropic, Google, and more\n- 🎨 **Image Generation**: Create images using DALL-E 3 and DALL-E 2\n- 🔧 **Simple API**: Consistent interface with just three parameters: provider, model, and prompt\n- 🔑 **Flexible Authentication**: Only configure API keys for the providers you use\n\n## Configuration\n\nAdd the following configuration to your MCP client. Consult your MCP client's documentation for specific configuration details.\n\n```json\n{\n  \"mcpServers\": {\n    \"outsource-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\"--from\", \"git+https://github.com/gwbischof/outsource-mcp.git\", \"outsource-mcp\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-openai-key\",\n        \"ANTHROPIC_API_KEY\": \"your-anthropic-key\",\n        \"GOOGLE_API_KEY\": \"your-google-key\",\n        \"GROQ_API_KEY\": \"your-groq-key\",\n        \"DEEPSEEK_API_KEY\": \"your-deepseek-key\",\n        \"XAI_API_KEY\": \"your-xai-key\",\n        \"PERPLEXITY_API_KEY\": \"your-perplexity-key\",\n        \"COHERE_API_KEY\": \"your-cohere-key\",\n        \"FIREWORKS_API_KEY\": \"your-fireworks-key\",\n        \"HUGGINGFACE_API_KEY\": \"your-huggingface-key\",\n        \"MISTRAL_API_KEY\": \"your-mistral-key\",\n        \"NVIDIA_API_KEY\": \"your-nvidia-key\",\n        \"OLLAMA_HOST\": \"http://localhost:11434\",\n        \"OPENROUTER_API_KEY\": \"your-openrouter-key\",\n        \"TOGETHER_API_KEY\": \"your-together-key\",\n        \"CEREBRAS_API_KEY\": \"your-cerebras-key\",\n        \"DEEPINFRA_API_KEY\": \"your-deepinfra-key\",\n        \"SAMBANOVA_API_KEY\": \"your-sambanova-key\"\n      }\n    }\n  }\n}\n```\n\nNote: The environment variables are optional. Only include the API keys for the providers you want to use.\n\n## Quick Start\n\nOnce installed and configured, you can use the tools in your MCP client:\n\n1. **Generate text**: Use the `outsource_text` tool with provider \"openai\", model \"gpt-4o-mini\", and prompt \"Write a haiku about coding\"\n2. **Generate images**: Use the `outsource_image` tool with provider \"openai\", model \"dall-e-3\", and prompt \"A futuristic city skyline at sunset\"\n\n## Tools\n\n### outsource_text\nCreates an Agno agent with a specified provider and model to generate text responses. \n\n**Arguments:**\n- `provider`: The provider name (e.g., \"openai\", \"anthropic\", \"google\", \"groq\", etc.)\n- `model`: The model name (e.g., \"gpt-4o\", \"claude-3-5-sonnet-20241022\", \"gemini-2.0-flash-exp\")\n- `prompt`: The text prompt to send to the model\n\n### outsource_image\nGenerates images using AI models.\n\n**Arguments:**\n- `provider`: The provider name (currently only \"openai\" is supported)\n- `model`: The model name (\"dall-e-3\" or \"dall-e-2\")\n- `prompt`: The image generation prompt\n\nReturns the URL of the generated image.\n\n> **Note**: Image generation is currently only supported by OpenAI models (DALL-E 2 and DALL-E 3). Other providers only support text generation.\n\n## Supported Providers\n\nThe following providers are supported. Use the provider name (in parentheses) as the `provider` argument:\n\n### Core Providers\n- **OpenAI** (`openai`) - GPT-4, GPT-3.5, DALL-E, etc. | [Models](https://platform.openai.com/docs/models)\n- **Anthropic** (`anthropic`) - Claude 3.5, Claude 3, etc. | [Models](https://docs.anthropic.com/en/docs/about-claude/models/overview)\n- **Google** (`google`) - Gemini Pro, Gemini Flash, etc. | [Models](https://ai.google.dev/models)\n- **Groq** (`groq`) - Llama 3, Mixtral, etc. | [Models](https://console.groq.com/docs/models)\n- **DeepSeek** (`deepseek`) - DeepSeek Chat & Coder | [Models](https://api-docs.deepseek.com/api/list-models)\n- **xAI** (`xai`) - Grok models | [Models](https://docs.x.ai/docs/models)\n- **Perplexity** (`perplexity`) - Sonar models | [Models](https://docs.perplexity.ai/guides/model-cards)\n\n### Additional Providers\n- **Cohere** (`cohere`) - Command models | [Models](https://docs.cohere.com/v2/docs/models)\n- **Mistral AI** (`mistral`) - Mistral Large, Medium, Small | [Models](https://docs.mistral.ai/getting-started/models/models_overview/)\n- **NVIDIA** (`nvidia`) - Various models | [Models](https://build.nvidia.com/models)\n- **HuggingFace** (`huggingface`) - Open source models | [Models](https://huggingface.co/models)\n- **Ollama** (`ollama`) - Local models | [Models](https://ollama.com/library)\n- **Fireworks AI** (`fireworks`) - Fast inference | [Models](https://fireworks.ai/models?view=list)\n- **OpenRouter** (`openrouter`) - Multi-provider access | [Models](https://openrouter.ai/docs/overview/models)\n- **Together AI** (`together`) - Open source models | [Models](https://docs.together.ai/docs/serverless-models)\n- **Cerebras** (`cerebras`) - Fast inference | [Models](https://cerebras.ai/models)\n- **DeepInfra** (`deepinfra`) - Optimized models | [Models](https://deepinfra.com/docs/models)\n- **SambaNova** (`sambanova`) - Enterprise models | [Models](https://docs.sambanova.ai/cloud/docs/get-started/supported-models)\n\n### Enterprise Providers\n- **AWS Bedrock** (`aws` or `bedrock`) - AWS-hosted models | [Models](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html)\n- **Azure AI** (`azure`) - Azure-hosted models | [Models](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/foundry-models-overview)\n- **IBM WatsonX** (`ibm` or `watsonx`) - IBM models | [Models](https://www.ibm.com/docs/en/software-hub/5.1.x?topic=install-foundation-models)\n- **LiteLLM** (`litellm`) - Universal interface | [Models](https://docs.litellm.ai/docs/providers)\n- **Vercel v0** (`vercel` or `v0`) - Vercel AI | [Models](https://sdk.vercel.ai/docs/introduction)\n- **Meta Llama** (`meta`) - Direct Meta access | [Models](https://www.llama.com/get-started/)\n\n### Environment Variables\n\nEach provider requires its corresponding API key:\n\n| Provider | Environment Variable | Example |\n|----------|---------------------|---------|\n| OpenAI | `OPENAI_API_KEY` | sk-... |\n| Anthropic | `ANTHROPIC_API_KEY` | sk-ant-... |\n| Google | `GOOGLE_API_KEY` | AIza... |\n| Groq | `GROQ_API_KEY` | gsk_... |\n| DeepSeek | `DEEPSEEK_API_KEY` | sk-... |\n| xAI | `XAI_API_KEY` | xai-... |\n| Perplexity | `PERPLEXITY_API_KEY` | pplx-... |\n| Cohere | `COHERE_API_KEY` | ... |\n| Fireworks | `FIREWORKS_API_KEY` | ... |\n| HuggingFace | `HUGGINGFACE_API_KEY` | hf_... |\n| Mistral | `MISTRAL_API_KEY` | ... |\n| NVIDIA | `NVIDIA_API_KEY` | nvapi-... |\n| Ollama | `OLLAMA_HOST` | http://localhost:11434 |\n| OpenRouter | `OPENROUTER_API_KEY` | ... |\n| Together | `TOGETHER_API_KEY` | ... |\n| Cerebras | `CEREBRAS_API_KEY` | ... |\n| DeepInfra | `DEEPINFRA_API_KEY` | ... |\n| SambaNova | `SAMBANOVA_API_KEY` | ... |\n| AWS Bedrock | AWS credentials | Via AWS CLI/SDK |\n| Azure AI | Azure credentials | Via Azure CLI/SDK |\n| IBM WatsonX | `IBM_WATSONX_API_KEY` | ... |\n| Meta Llama | `LLAMA_API_KEY` | ... |\n\n**Note**: Only configure the API keys for providers you plan to use.\n\n## Examples\n\n### Text Generation\n```\n# Using OpenAI\nprovider: openai\nmodel: gpt-4o-mini\nprompt: Write a haiku about coding\n\n# Using Anthropic\nprovider: anthropic\nmodel: claude-3-5-sonnet-20241022\nprompt: Explain quantum computing in simple terms\n\n# Using Google\nprovider: google\nmodel: gemini-2.0-flash-exp\nprompt: Create a recipe for chocolate chip cookies\n```\n\n### Image Generation\n```\n# Using DALL-E 3\nprovider: openai\nmodel: dall-e-3\nprompt: A serene Japanese garden with cherry blossoms\n\n# Using DALL-E 2\nprovider: openai\nmodel: dall-e-2\nprompt: A futuristic cityscape at sunset\n```\n\n## Development\n\n### Prerequisites\n\n- Python 3.11 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n\n### Setup\n\n```bash\ngit clone https://github.com/gwbischof/outsource-mcp.git\ncd outsource-mcp\nuv sync\n```\n\n### Testing with MCP Inspector\n\nThe MCP Inspector allows you to test the server interactively:\n\n```bash\nmcp dev server.py\n```\n\n### Running Tests\n\nThe test suite includes integration tests that verify both text and image generation:\n\n```bash\n# Run all tests\nuv run pytest\n```\n\n**Note:** Integration tests require API keys to be set in your environment.\n\n## Troubleshooting\n\n### Common Issues\n\n1. **\"Error: Unknown provider\"**\n   - Check that you're using a supported provider name from the list above\n   - Provider names are case-insensitive\n\n2. **\"Error: OpenAI API error\"** \n   - Verify your API key is correctly set in the environment variables\n   - Check that your API key has access to the requested model\n   - Ensure you have sufficient credits/quota\n\n3. **\"Error: No image was generated\"**\n   - This can happen if the image generation request fails\n   - Try a simpler prompt or different model (dall-e-2 vs dall-e-3)\n\n4. **Environment variables not working**\n   - Make sure to restart your MCP client after updating the configuration\n   - Verify the configuration file location for your specific MCP client\n   - Check that the environment variables are properly formatted in the configuration\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ai",
        "agents",
        "coding",
        "coding agents",
        "ai assistant",
        "ai assistants"
      ],
      "category": "code-execution"
    },
    "hdresearch--mcp-python": {
      "owner": "hdresearch",
      "name": "mcp-python",
      "url": "https://github.com/hdresearch/mcp-python",
      "imageUrl": "https://github.com/hdresearch.png",
      "description": "Execute Python code with a persistent session, manage variables, and install packages through the MCP protocol.",
      "stars": 28,
      "forks": 14,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-17T16:02:34Z",
      "readme_content": "# Python REPL MCP Server\n\nThis MCP server provides a Python REPL (Read-Eval-Print Loop) as a tool. It allows execution of Python code through the MCP protocol with a persistent session.\n\n## Setup\n\nNo setup needed! The project uses `uv` for dependency management.\n\n## Running the Server\n\nSimply run:\n\n```bash\nuv run src/python_repl/server.py\n```\n\n## Usage with Claude Desktop\n\nAdd this configuration to your Claude Desktop config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"python-repl\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/absolute/path/to/python-repl-server\",\n        \"run\",\n        \"mcp_python\"\n      ]\n    }\n  }\n}\n```\n\nThe server provides three tools:\n\n1. `execute_python`: Execute Python code with persistent variables\n\n   - `code`: The Python code to execute\n   - `reset`: Optional boolean to reset the session\n\n2. `list_variables`: Show all variables in the current session\n\n3. `install_package`: Install a package from pypi\n\n## Examples\n\nSet a variable:\n\n```python\na = 42\n```\n\nUse the variable:\n\n```python\nprint(f\"The value is {a}\")\n```\n\nList all variables:\n\n```python\n# Use the list_variables tool\n```\n\nReset the session:\n\n```python\n# Use execute_python with reset=true\n```\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. Here are some ways you can contribute:\n\n- Report bugs\n- Suggest new features\n- Improve documentation\n- Add test cases\n- Submit code improvements\n\nBefore submitting a PR, please ensure:\n\n1. Your code follows the existing style\n2. You've updated documentation as needed\n3. Maybe write some tests?\n\nFor major changes, please open an issue first to discuss what you would like to change.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "python",
        "coding",
        "llms execute",
        "execution servers",
        "execute code"
      ],
      "category": "code-execution"
    },
    "hileamlakB--PRIMS": {
      "owner": "hileamlakB",
      "name": "PRIMS",
      "url": "https://github.com/hileamlakB/PRIMS",
      "imageUrl": "",
      "description": "submitted code in an isolated environment.",
      "stars": 18,
      "forks": 11,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-29T11:23:05Z",
      "readme_content": "<p align=\"left\">\n  <img src=\"primslogo.png\" alt=\"PRIMS Logo\" width=\"200\"/>\n  <a href=\"#\"><img src=\"https://img.shields.io/badge/status-alpha-orange?style=for-the-badge\" alt=\"Status: Alpha\"/></a>\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/license-MIT-blue?style=for-the-badge\" alt=\"License: MIT\"/></a>\n</p>\n\n# PRIMS – Python Runtime Interpreter MCP Server\n\nPRIMS is a tiny open-source **Model Context Protocol (MCP)** server that lets LLM agents run arbitrary Python code in a secure, throw-away sandbox.\n\n•   **One tool, one job.**  Exposes a single MCP tool – `run_code` – that executes user-supplied Python and streams back `stdout / stderr`.\n\n•   **Isolated & reproducible.**  Each call spins up a fresh virtual-env, installs any requested pip packages, mounts optional read-only files, then nukes the workspace.\n\n•   **Zero config.**  Works over MCP/stdio or drop it in Docker.\n\n---\n\n## Quick-start\n\n### 1. Local development environment\n\n```bash\nchmod +x scripts/setup_env.sh   # once, to make the script executable\n./scripts/setup_env.sh          # creates .venv & installs deps\n\n# activate the venv in each new shell\nsource .venv/bin/activate\n```\n\n### 2. Launch the server\n\n```bash\npython -m server.main         # binds http://0.0.0.0:9000/mcp\n```\n\n### 3. Docker\n\n```bash\n# Quick one-liner (build + run)\nchmod +x scripts/docker_run.sh\n./scripts/docker_run.sh         # prints the MCP URL when ready\n```\n\n\n## Examples\n\n### List available tools\n\nYou can use the provided script to list all tools exposed by the server:\n\n```bash\npython examples/list_tools.py\n```\n\nExpected output (tool names and descriptions may vary):\n\n```\nAvailable tools:\n- run_code: Execute Python code in a secure sandbox with optional dependencies & file mounts.\n- list_dir: List files/directories in your session workspace.\n- preview_file: Preview up to 8 KB of a text file from your session workspace.\n- persist_artifact: Upload an output/ file to a presigned URL for permanent storage.\n- mount_file: Download a remote file once per session to `mounts/<path>`.\n```\n\n### Run code via the MCP server\n\n```bash\npython examples/run_code.py\n```\n\n### Mount a dataset once & reuse it\n\n```bash\npython examples/mount_and_run.py\n```\n\nThis mounts a CSV with `mount_file` and then reads it inside `run_code` without re-supplying the URL.\n\n### Inspect your session workspace\n\n```bash\npython examples/inspect_workspace.py\n```\n\nThis shows how to use the **`list_dir`** and **`preview_file`** tools to browse files your code created.\n\n### Persist an artifact to permanent storage\n\nThe **`persist_artifact`** tool uploads a file from your `output/` directory to a presigned URL.\n\nExample (Python):\n\n```python\nawait client.call_tool(\"persist_artifact\", {\n    \"relative_path\": \"plots/plot.png\",\n    \"presigned_url\": \"https://bucket.s3.amazonaws.com/...signature...\",\n})\n```\n\n### Download an artifact\n\nSmall artifacts can be fetched directly:\n\n```bash\ncurl -H \"mcp-session-id: <your-session-id>\" \\\n     http://localhost:9000/artifacts/plots/plot.png -o plot.png\n```\n\n---\n\n## Available tools\n\n| Tool                | Purpose |\n|---------------------|---------------------------------------------------------------|\n| `run_code`          | Execute Python in an isolated sandbox with optional pip deps. |\n| `list_dir`          | List files/directories inside your session workspace.        |\n| `preview_file`      | Return up to 8 KB of a text file for quick inspection.        |\n| `persist_artifact`  | Upload an `output/` file to a client-provided presigned URL. |\n| `mount_file`        | Download a remote file once per session to `mounts/<path>`. |\n\nSee the `examples/` directory for end-to-end demos.\n\n## Contributing\nContributions are welcome! Feel free to open issues, suggest features, or submit pull requests to help improve PRIMS.\n\n\nIf you find this project useful, please consider leaving a ⭐ to show your support.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "code",
        "llms execute",
        "execution servers",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "hloiseaufcms--mcp-gopls": {
      "owner": "hloiseaufcms",
      "name": "mcp-gopls",
      "url": "https://github.com/hloiseaufcms/mcp-gopls",
      "imageUrl": "https://github.com/hloiseaufcms.png",
      "description": "Enhance AI assistants with Go code analysis capabilities by leveraging the Language Server Protocol for tasks like code navigation, diagnostics, and suggestions. Interact with Go tools for efficient coding workflows.",
      "stars": 44,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "Go",
      "updated_at": "2025-10-03T19:00:55Z",
      "readme_content": "# MCP LSP Go\n\nA Model Context Protocol (MCP) server that allows AI assistants like Claude to interact with Go's Language Server Protocol (LSP) and benefit from advanced Go code analysis features.\n\n## Overview\n\nThis MCP server helps AI assistants to:\n\n- Use LSP to analyze Go code\n- Navigate to definitions and find references\n- Check code diagnostics\n- Get hover information for symbols\n- Get completion suggestions\n\n## Architecture\n\nThis project uses the [mark3labs/mcp-go](https://github.com/mark3labs/mcp-go) library to implement the Model Context Protocol. The MCP integration enables seamless communication between AI assistants and Go tools.\n\nThe server communicates with [gopls](https://github.com/golang/tools/tree/master/gopls), the official language server for Go, via the Language Server Protocol (LSP).\n\n## Features\n\n- **LSP Integration**: Connection to Go's Language Server Protocol for code analysis\n- **Code Navigation**: Finding definitions and references in the code\n- **Code Quality**: Getting diagnostics and errors\n- **Advanced Information**: Hover information and completion suggestions\n\n## Project Structure\n\n```bash\n.\n├── cmd\n│   └── mcp-gopls        # Application entry point\n├── pkg\n│   ├── lsp             # LSP client to communicate with gopls\n│   │   ├── client      # LSP client implementation\n│   │   └── protocol    # LSP protocol types and features\n│   ├── server          # MCP server\n│   └── tools           # MCP tools exposing LSP features\n```\n\n## Installation\n\n```bash\ngo install github.com/hloiseaufcms/mcp-gopls/cmd/mcp-gopls@latest\n```\n\n## Add to Cursor\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-gopls\": {\n      \"command\": \"mcp-gopls\"\n    }\n  }\n} \n```\n\n## MCP Tools\n\nThe MCP server provides the following tools:\n\n| Tool | Description |\n|-------|-------------|\n| `go_to_definition` | Navigate to the definition of a symbol |\n| `find_references` | Find all references to a symbol |\n| `check_diagnostics` | Get diagnostics for a file |\n| `get_hover_info` | Get detailed information about a symbol |\n| `get_completion` | Get completion suggestions at a position |\n| `analyze_coverage` | Analyze test coverage for Go code |\n\n## Usage Example\n\nUsing the server with AI assistants that support MCP:\n\n```Markdown\n# Ask the AI to get information about the code\nCan you find the definition of the `ServeStdio` function in this project?\n\n# Ask for diagnostics\nAre there any errors in my main.go file?\n\n# Ask for information about a symbol\nWhat does the Context.WithTimeout function do in Go?\n```\n\n## Development\n\n```bash\ngit clone https://github.com/hloiseaufcms/mcp-gopls.git\ncd mcp-gopls\ngo mod tidy\ngo build -o mcp-gopls cmd/mcp-gopls/main.go\n./mcp-gopls\n```\n\n## Prerequisites\n\n- Go 1.21 or higher\n- gopls installed (`go install golang.org/x/tools/gopls@latest`)\n\n## Integration with Ollama\n\nThis MCP server can be used with any tool that supports the MCP protocol. For Ollama integration:\n\n1. Make sure Ollama is running\n2. The MCP server runs independently and communicates through stdin/stdout\n3. Configure your client to use the MCP server as a tool provider\n\n## License\n\nApache License 2.0",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "code",
        "execution",
        "coding agents",
        "code execution",
        "code analysis"
      ],
      "category": "code-execution"
    },
    "jacklandis29--codechecker-mcp": {
      "owner": "jacklandis29",
      "name": "codechecker-mcp",
      "url": "https://github.com/jacklandis29/codechecker-mcp",
      "imageUrl": "https://github.com/jacklandis29.png",
      "description": "Provides intelligent real-time code analysis and suggestions directly within the Cursor IDE by leveraging OpenAI's GPT models.",
      "stars": 3,
      "forks": 3,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-03T19:59:41Z",
      "readme_content": "# CodeChecker MCP\n\nA code review tool for Cursor IDE that uses OpenAI's GPT models to provide intelligent code analysis and suggestions.\n\n## Features\n\n- Real-time code review using OpenAI's GPT models\n- Integration with Cursor IDE through MCP protocol\n- Support for both SSE and stdio transport modes\n- Detailed code analysis with specific improvement suggestions\n\n## Prerequisites\n\n- Python 3.10 or higher\n- OpenAI API key\n- Cursor IDE\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/jacklandis29/codechecker-mcp.git\ncd codechecker-mcp\n```\n\n2. Create and activate a virtual environment:\n```bash\npython -m venv venv\nsource venv/bin/activate  # On Windows use: venv\\Scripts\\activate\n```\n\n3. Install dependencies:\n```bash\npip install -e .\n```\n\n4. Create a `.env` file in the project root and add your OpenAI API key:\n```bash\nOPENAI_API_KEY=your_api_key_here\n```\n\n## Usage\n\n1. Start the server:\n```bash\npython main.py --transport sse --port 8000\n```\n\n2. Configure Cursor IDE:\n   - Open Cursor settings\n   - Add the following configuration:\n```json\n{\n  \"mcp\": {\n    \"endpoint\": \"http://127.0.0.1:8000/sse\",\n    \"enabled\": true\n  }\n}\n```\n\n3. Use the code review tool in Cursor IDE by selecting code and providing context for review.\n\n## Configuration\n\n- `--transport`: Choose between \"sse\" (for Cursor IDE integration) or \"stdio\" (for command-line usage)\n- `--port`: Specify the port number for the SSE server (default: 8000)\n\n## License\n\nMIT License ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "codechecker",
        "coding",
        "code",
        "codechecker mcp",
        "code analysis",
        "code execution"
      ],
      "category": "code-execution"
    },
    "jigarbhoye04--MatlabMCP": {
      "owner": "jigarbhoye04",
      "name": "MatlabMCP",
      "url": "https://github.com/jigarbhoye04/MatlabMCP",
      "imageUrl": "https://github.com/jigarbhoye04.png",
      "description": "Execute MATLAB code seamlessly from Python, enabling efficient computation and data analysis with a shared MATLAB session that optimizes performance and resource utilization.",
      "stars": 20,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-27T09:06:12Z",
      "readme_content": "# MATLAB MCP Integration\n\nThis is an implementation of a Model Context Protocol (MCP) server for MATLAB. It allows MCP clients (like LLM agents or Claude Desktop) to interact with a shared MATLAB session using the MATLAB Engine API for Python.\n\n## Features\n\n*   **Execute MATLAB Code:** Run arbitrary MATLAB code snippets via the `runMatlabCode` tool.\n*   **Retrieve Variables:** Get the value of variables from the MATLAB workspace using the `getVariable` tool.\n*   **Structured Communication:** Tools return results and errors as structured JSON for easier programmatic use by clients.\n*   **Non-Blocking Execution:** MATLAB engine calls are run asynchronously using `asyncio.to_thread` to prevent blocking the server.\n*   **Standard Logging:** Uses Python's standard `logging` module, outputting to `stderr` for visibility in client logs.\n*   **Shared Session:** Connects to an existing shared MATLAB session.\n\n> [!TIP]\n> MatlabMCP wikipedia by DEVIN.\n Checkout [DeepWiki](https://deepwiki.com/jigarbhoye04/MatlabMCP) for more detailed and illustrative information about architecture.\n\n## Requirements\n\n*   Python 3.12 or higher\n*   MATLAB (**R2023a or higher recommended** - check MATLAB Engine API for Python compatibility) with the MATLAB Engine API for Python installed.\n*   `numpy` Python package.\n\n## Installation\n\n1.  Clone this repository:\n    ```bash\n    git clone https://github.com/jigarbhoye04/MatlabMCP.git\n    cd MatlabMCP\n    ```\n\n2.  Set up a Python virtual environment (recommended):\n    ```bash\n    # Install uv if you haven't already: https://github.com/astral-sh/uv\n    uv init\n    uv venv\n    source .venv/bin/activate  # On Windows use: .venv\\Scripts\\activate\n    ```\n\n3.  Install dependencies:\n    ```bash\n    uv pip sync\n    ```\n\n4.  Ensure MATLAB is installed and the MATLAB Engine API for Python is configured for your Python environment. See [MATLAB Documentation](https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html).\n\n5.  **Start MATLAB and share its engine:** Run the following command in the MATLAB Command Window:\n    ```matlab\n    matlab.engine.shareEngine\n    ```\n    You can verify it's shared by running `matlab.engine.isEngineShared` in MATLAB (it should return `true` or `1`). The MCP server needs this shared engine to connect.\n\n## Configuration (for Claude Desktop)\n\nTo use this server with Claude Desktop:\n\n1.  Go to Claude Desktop -> Settings -> Developer -> Edit Config.\n2.  This will open `claude_desktop_config.json`. Add or modify the `mcpServers` section to include the `MatlabMCP` configuration:\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"MatlabMCP\": {\n          \"command\": \"C:\\\\Users\\\\username\\\\.local\\\\bin\\\\uv.exe\", // Path to your uv executable\n          \"args\": [\n            \"--directory\",\n            \"C:\\\\Users\\\\username\\\\Desktop\\\\MatlabMCP\\\\\", // ABSOLUTE path to the cloned repository directory\n            \"run\",\n            \"main.py\"\n          ]\n          // Optional: Add environment variables if needed\n          // \"env\": {\n          //   \"MY_VAR\": \"value\"\n          // }\n        }\n        // Add other MCP servers here if you have them\n      }\n    }\n    ```\n3.  **IMPORTANT:** Replace `C:\\\\Users\\\\username\\\\...` paths with the correct **absolute paths** for your system.\n4.  Save the file and **restart Claude Desktop**.\n5.  **Logging:** Server logs (from Python's `logging` module) will appear in Claude Desktop's MCP log files (accessible via `tail -f ~/Library/Logs/Claude/mcp-server-MatlabMCP.log` on macOS or checking `%APPDATA%\\Claude\\logs\\` on Windows).\n\n\n## Development\n\nProject Structure:\n```\nMatlabMCP/\n├── .venv/                     # Virtual environment created by uv\n├── Docs/\n│   └── Images/\n│   └── Updates.md             # Documentation for updates and changes\n├── main.py                    # The MCP server script\n├── pyproject.toml             # Project metadata and dependencies\n├── README.md                  # This file\n└── uv.lock                    # Lock file for dependencies\n```\n\n## Documentation\nCheck out [Updates](./Docs/Updates.md) for detailed documentation on the server's features, usage, and development notes.\n\n## Contributing\nContributions are welcome! If you have any suggestions or improvements, feel free to open an issue or submit a pull request.\n\nLet's make this even better together!\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "matlab",
        "matlabmcp",
        "llms",
        "execute matlab",
        "llms execute",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "jjsantos01--jupyter-notebook-mcp": {
      "owner": "jjsantos01",
      "name": "jupyter-notebook-mcp",
      "url": "https://github.com/jjsantos01/jupyter-notebook-mcp",
      "imageUrl": "https://github.com/jjsantos01.png",
      "description": "Connects Jupyter Notebook to Claude AI through the Model Context Protocol, facilitating direct interaction to execute code, analyze data, and create visualizations within the notebook interface.",
      "stars": 110,
      "forks": 21,
      "license": "MIT License",
      "language": "Jupyter Notebook",
      "updated_at": "2025-09-27T11:36:15Z",
      "readme_content": "# JupyterMCP - Jupyter Notebook Model Context Protocol Integration\n\nJupyterMCP connects [Jupyter Notebook](https://jupyter.org/) to [Claude AI](https://claude.ai/chat) through the Model Context Protocol (MCP), allowing Claude to directly interact with and control Jupyter Notebooks. This integration enables AI-assisted code execution, data analysis, visualization, and more.\n\n## ⚠️ Compatibility Warning\n\n**This tool is compatible ONLY with Jupyter Notebook version 6.x.**\n\nIt does NOT work with:\n\n- Jupyter Lab\n- Jupyter Notebook v7.x\n- VS Code Notebooks\n- Google Colab\n- Any other notebook interfaces\n\n## Features\n\n- **Two-way communication**: Connect Claude AI to Jupyter Notebook through a WebSocket-based server\n- **Cell manipulation**: Insert, execute, and manage notebook cells\n- **Notebook management**: Save notebooks and retrieve notebook information\n- **Cell execution**: Run specific cells or execute all cells in a notebook\n- **Output retrieval**: Get output content from executed cells with text limitation options\n\n## Components\n\nThe system consists of three main components:\n\n1. **WebSocket Server (`jupyter_ws_server.py`)**: Sets up a WebSocket server inside Jupyter that bridges communication between notebook and external clients\n2. **Client JavaScript (`client.js`)**: Runs in the notebook to handle operations (inserting cells, executing code, etc.)\n3. **MCP Server (`jupyter_mcp_server.py`)**: Implements the Model Context Protocol and connects to the WebSocket server\n\n## Installation\n\n### Prerequisites\n\n- [Python 3.12 or newer](https://www.python.org/downloads/) (probably also work with older versions, but not tested)\n- [`uv` package manager](/README.md#installing-uv)\n- [Claude AI desktop application](https://claude.ai/download)\n\n#### Installing uv\n\nIf you're on Mac:\n\n```bash\nbrew install uv\n```\n\nOn Windows (PowerShell):\n\n```bash\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nFor other platforms, see the [uv installation guide](https://docs.astral.sh/uv/getting-started/installation/).\n\n### Setup\n\n1. Clone or download this repository to your computer:\n\n   ```bash\n   git clone https://github.com/jjsantos01/jupyter-notebook-mcp.git\n   ```\n\n2. Create virtual environment with required packages an install `jupyter-mcp` kernel, so it can be recognized by your jupyter installation, if you had one before.\n\n   ```bash\n   uv run python -m ipykernel install --name jupyter-mcp\n   ```\n\n3. (optional) Install additional Python packages for your analysis:\n\n   ```bash\n   uv pip install seaborn\n   ```\n\n4. Configure Claude desktop integration:\n   Go to `Claude` > `Settings` > `Developer` > `Edit Config` > `claude_desktop_config.json` to include the following:\n\n   ```json\n      {\n       \"mcpServers\": {\n           \"jupyter\": {\n               \"command\": \"uv\",\n               \"args\": [\n                   \"--directory\",\n                   \"/ABSOLUTE/PATH/TO/PARENT/REPO/FOLDER/src\",\n                   \"run\",\n                   \"jupyter_mcp_server.py\"\n               ]\n           }\n       }\n   }\n   ```\n\n   Replace `/ABSOLUTE/PATH/TO/` with the actual path to the `src` folder on your system. For example:\n   - Windows: `\"C:\\\\Users\\\\MyUser\\\\GitHub\\\\jupyter-notebook-mcp\\\\src\\\\\"`\n   - Mac: `/Users/MyUser/GitHub/jupyter-notebook-mcp/src/`\n\n   If you had previously opened Claude, then `File` > `Exit` and open it again.\n\n## Usage\n\n### Starting the Connection\n\n1. Start your Jupyter Notebook (version 6.x) server:\n\n   ```bash\n   uv run jupyter nbclassic\n   ```\n\n2. Create a new Jupyter Notebook and make sure that you choose the `jupyter-mcp` kernel: `kernel` -> `change kernel` -> `jupyter-mcp`\n\n3. In a notebook cell, run the following code to initialize the WebSocket server:\n\n   ```python\n   import sys\n   sys.path.append('/path/to/jupyter-notebook-mcp/src')  # Add the path to where the scripts are located\n   \n   from jupyter_ws_server import setup_jupyter_mcp_integration\n   \n   # Start the WebSocket server inside Jupyter\n   server, port = setup_jupyter_mcp_integration()\n   ```\n\n   Don't forget to replace here `'/path/to/jupyter-notebook-mcp/src'` with `src` folder on your system. For example:\n   - Windows: `\"C:\\\\Users\\\\MyUser\\\\GitHub\\\\jupyter-notebook-mcp\\\\src\\\\\"`\n   - Mac: `/Users/MyUser/GitHub/jupyter-notebook-mcp/src/`\n\n   ![Notebook setup](/assets/img/notebook-setup.png)\n\n4. Launch Claude desktop with MCP enabled.\n\n### Using with Claude\n\nOnce connected, Claude will have access to the following tools:\n\n- `ping` - Check server connectivity\n- `insert_and_execute_cell` - Insert a cell at the specified position and execute it\n- `save_notebook` - Save the current Jupyter notebook\n- `get_cells_info` - Get information about all cells in the notebook\n- `get_notebook_info` - Get information about the current notebook\n- `run_cell` - Run a specific cell by its index\n- `run_all_cells` - Run all cells in the notebook\n- `get_cell_text_output` - Get the output content of a specific cell\n- `get_image_output` - Get the images output of a specific cell\n- `edit_cell_content` - Edit the content of an existing cell\n- `set_slideshow_type`- Set the slide show type for cell\n\n## ⚠️ DISCLAIMER\n\nThis is an experimental project and should be used with caution. This tool runs arbitrary Python code in your computer, which could potentially modify or delete data if not used carefully. Always back up your important projects and data.\n\n## Example Prompts\n\nAsk Claude to perform notebook operations:\n\n### Python example\n\nYou can check the [example notebook](/notebooks/example_notebook.ipynb) and the [video demo](https://x.com/jjsantoso/status/1906780778807390562)\n\n```plain\nYou have access to a Jupyter Notebook server.\n\nI need to create a presentation about Python's Seaborn library.  \nThe content is as follows:\n\n- What is Seaborn?\n- Long vs. Wide data format\n- Advantages of Seaborn over Matplotlib\n- Commonly used Seaborn functions\n- Live demonstration (comparison of Seaborn vs. Matplotlib)\n  - Bar plot\n  - Line plot\n  - Scatter plot\n\nFor each concept, I want the main explanations provided in markdown cells, followed by one or more Python code cells demonstrating its usage. Keep the text concise—the cells shouldn't exceed 10 lines each.\n\nUse appropriate slideshow types for each cell to make the presentation visually appealing.\n```\n\n[Check Here the full conversation](https://claude.ai/share/420b6aa6-b84b-437f-a6a6-89d310c36d52)\n\n### Stata example\n\nFor this example, you need the [Stata Software](https://www.stata.com/) (v17 or later), which is not open source. If you already have Stata, you need to install the [`stata-setup`](https://pypi.org/project/stata-setup/) package:\n\n```bash\nuv pip install stata-setup\n```\n\nThen, at the begining of your notebook, you need to additionally include:\n\n```python\nimport stata_setup\nstata_setup.config('your_stata_installation_directory', 'your_stata_edition')\n```\n\nYou can check the [example notebook](/notebooks/stata_example.ipynb) and the [video demo](https://x.com/jjsantoso/status/1906780784800731251)\n\nThis exercise comes from [Professor John Robert Warren webpage](https://www.rob-warren.com/soc3811_stata_exercises.html)\n\n```plain\nYou have access to a Jupyter Notebook server. By default it runs Python, but you can run Stata (v18) code in this server using the %%stata magic, for example:\n\n%%stata\ndisplay \"hello world\"\n\nRun the available tools to solve the exercise, execute the code, and interpret the results.\n\n**EXERCISE:**\n\nIn this exercise, you will use data from the American Community Survey (ACS). The ACS is a product of the U.S. Census Bureau and involves interviewing millions of Americans each year. For an introduction to the ACS, visit the ACS website (here).\n\nFor this exercise, I have created a data file containing two variables collected from respondents of the 2010 ACS who lived in one of two metropolitan areas: Minneapolis/St Paul and Duluth/Superior. The two variables are: (1) People's poverty status and (2) the time it takes people to commute to work.\n\nUse STATA syntax files you already have (from the first assignment or class examples) and modify them to accomplish the following goals.\n\n1. Read the data file (`\"./stata_assignment_2.dat\"`) for this assignment into STATA.\n2. Be sure to declare \"zero\" as a missing value for `TRANTIME`, the commuting time variable.\n3. Create a new dichotomous poverty variable that equals \"1\" if a person's income-to-poverty-line ratio (`POVRATIO`) is less than 100, and \"0\" otherwise; see the bottom of the assignment for an example of how to do this in STATA.\n4. Separately for Minneapolis/St Paul and Duluth/Superior, produce:\n   - a histogram of the commuting time (`TRANTIME`) variable.\n   - measures of central tendency and spread for commuting time.\n   - a frequency distribution for the poverty status (0 vs 1) variable.\n5. Separately for Minneapolis/St Paul and Duluth/Superior, use STATA code to produce:\n   - a 95% confidence interval for the mean commuting time.\n   - a 95% confidence interval for the proportion of people who are poor. See below for an example of how to do this in STATA.\n\nUse the results from step #4 above to:\n\n6. Separately for Minneapolis/St Paul and Duluth/Superior, manually calculate:\n   - a 95% confidence interval for the mean commuting time.\n   - a 95% confidence interval for the proportion of people who are poor.\n7. Confirm that your answers from steps #5 and #6 match.\n\nBased on the results above, answer this question:\n\n8. How do you interpret the confidence intervals calculated in steps #5 and #6 above?\n\n9. Finally, create a do file (.do) with the all the Stata code and the answers as comments.\n\n---\n\n**DESCRIPTION OF VARIABLES IN \"STATA ASSIGNMENT 2.DAT\"**\n\n**METAREAD** (Column 4-7)  \nMetropolitan Area  \n- `2240`: Duluth-Superior, MN/WI  \n- `5120`: Minneapolis-St. Paul, MN  \n\n**POVRATIO** (Column 18-20)  \nRatio of person's income to the poverty threshold:  \n- `<100`: Below Poverty Line  \n- `100`: At Poverty Line  \n- `>100`: Above Poverty Line  \n\n**TRANTIME** (Column 21-23)  \nTravel time to work  \n- `0`: Zero minutes  \n- `1`: 1 Minute  \n- etc.\n\n```\n\n[Check Here the full conversation](https://claude.ai/share/97b5a546-9375-434d-8224-561706782880)\n\n## Testing with External Client\n\nYou can test the functionality without using Claude Desktop with the included external client:\n\n```bash\nuv run python src/jupyter_ws_external_client.py\n```\n\nThis will provide an interactive menu to test some available functions.\n\nFor automated testing of all commands:\n\n```bash\nuv run python src/jupyter_ws_external_client.py --batch\n```\n\n## Troubleshooting\n\n- **Connection Issues**: If you experience connection timeouts, the client includes a reconnection mechanism. You can also try restarting the WebSocket server.\n- **Cell Execution Problems**: If cell execution doesn't work, check that the cell content is valid Python/Markdown and that the notebook kernel is running.\n- **WebSocket Port Conflicts**: If the default port (8765) is already in use, the server will automatically try to find an available port.\n\n## Limitations\n\n- Only supports Jupyter Notebook 6.x\n- Text output from cells is limited to 1500 characters by default\n- Does not support advanced Jupyter widget interactions\n- Connection may timeout after periods of inactivity\n\n## License\n\n[MIT](/LICENSE)\n\n## Other Jupyter MCPs\n\nThis project is inspired by similar MCP integrations for Jupyter as:\n\n- [ihrpr](https://github.com/ihrpr/mcp-server-jupyter)\n- [Datalayer](https://github.com/datalayer/jupyter-mcp-server/tree/main)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "jupyter",
        "execution",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "juehang--vscode-mcp-server": {
      "owner": "juehang",
      "name": "vscode-mcp-server",
      "url": "https://github.com/juehang/vscode-mcp-server",
      "imageUrl": "https://github.com/juehang.png",
      "description": "Integrate directly with a VS Code workspace to list files, read and edit code, search symbols, check diagnostics, and execute shell commands, enabling AI models to enhance coding workflows.",
      "stars": 256,
      "forks": 46,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T04:39:27Z",
      "readme_content": "# VS Code MCP Server\n\nA Visual Studio Code extension (available on the [Marketplace](https://marketplace.visualstudio.com/items?itemName=JuehangQin.vscode-mcp-server)) that allows Claude and other MCP clients to code directly in VS Code! Inspired by [Serena](https://github.com/oraios/serena), but using VS Code's built-in capabilities. Perfect for extending existing coding agents like Claude Code with VS Code-specific capabilities (symbol search, document outlines) without duplicating tools they already have. Note that this extension uses the streamable HTTP API, not the SSE API.\n\nThis extension can allow for execution of shell commands. This means that there is a potential security risk, so use with caution, and ensure that you trust the MCP client that you are using and that the port is not exposed to anything. Authentication would help, but as the MCP authentication spec is still in flux, this has not been implemented for now.\n\nPRs are welcome!\n\n## Demo Video\nhttps://github.com/user-attachments/assets/20b87dfb-fc39-4710-a910-b9481dde1e90\n\n## Installation\n\n1. Install the extension from the [Marketplace](https://marketplace.visualstudio.com/items?itemName=JuehangQin.vscode-mcp-server) or clone this repository and run `npm install` and `npm run compile` to build it.\n\n## Claude Desktop Configuration\n\nClaude Desktop can be configured to use this extension as an MCP server. To do this, your `claude_desktop_config.json` file should look like this:\n```\n{\n  \"mcpServers\": {\n    \"vscode-mcp-server\": {\n        \"command\": \"npx\",\n        \"args\": [\"mcp-remote@next\", \"http://localhost:3000/mcp\"]\n    }\n\n  }\n}\n```\n\nI also like to use this extension in a Claude project, as it allows me to specify additional instructions for Claude. I find the following prompt to work well:\n```\nYou are working on an existing codebase, which you can access using your tools. These code tools interact with a VS Code workspace.\n\nWORKFLOW ESSENTIALS:\n1. Always start exploration with list_files_code on root directory (.) first\n2. CRITICAL: Run get_diagnostics_code after EVERY set of code changes before completing tasks\n3. For small edits (≤10 lines): use replace_lines_code with exact original content\n4. For large changes, new files, or uncertain content: use create_file_code with overwrite=true\n\nEXPLORATION STRATEGY:\n- Start: list_files_code with path='.' (never recursive on root)\n- Understand structure: read key files like package.json, README, main entry points\n- Find symbols: use search_symbols_code for functions/classes, get_document_symbols_code for file overviews\n- Before editing: read_file_code the target file to understand current content\n\nEDITING BEST PRACTICES:\n- Small modifications: replace_lines_code (requires exact original content match)\n- If replace_lines_code fails: read_file_code the target lines, then retry with correct content\n- Large changes: create_file_code with overwrite=true is more reliable\n- After any changes: get_diagnostics_code to check for errors\n\nPLANNING REQUIREMENTS:\nBefore making code modifications, present a comprehensive plan including:\n- Confidence level (1-10) and reasoning\n- Specific tools you'll use and why\n- Files you'll modify and approach (small edits vs complete rewrites)\n- How you'll verify the changes work (diagnostics, testing, etc.)\n\nERROR HANDLING:\n- Let errors happen naturally - don't add unnecessary try/catch blocks\n- For tool failures: follow the specific recovery guidance in each tool's description\n- If uncertain about file content: use read_file_code to verify before making changes\n\nAPPROVAL PROCESS:\nIMPORTANT: Only run code modification tools after presenting a plan and receiving explicit approval. Each change requires separate approval.\n\nDo not add tests unless specifically requested. If you believe testing is important, explain why and let the user decide.\n```\n\nFor context efficiency when exploring codebases, consider adding this to your CLAUDE.md:\n```\n## VS Code Symbol Tools for Context Efficiency\nUse VS Code symbol tools to reduce context consumption:\n- `get_document_symbols_code` for file structure overview instead of reading entire files\n- `search_symbols_code` to find symbols by name across the project\n- `get_symbol_definition_code` for type info and docs without full file context\n- Workflow: get outline → search symbols → get definitions → read implementation only when needed\n```\n\n\n\nThis extension serves as a Model Context Protocol (MCP) server, exposing VS Code's filesystem and editing capabilities to MCP clients.\n\n## Features\n\nThe VS Code MCP Server extension implements an MCP-compliant server that allows AI models and other MCP clients to:\n\n- **List files and directories** in your VS Code workspace\n- **Read file contents** with encoding support and size limits\n- **Search for symbols** across your workspace\n- **Get symbol definitions** and hover information by line and symbol name\n- **Create new files** using VS Code's WorkspaceEdit API\n- **Make line replacements** in files\n- **Check for diagnostics** (errors and warnings) in your workspace\n- **Execute shell commands** in the integrated terminal with shell integration\n- **Toggle the server** on and off via a status bar item\n\nThis extension enables AI assistants and other tools to interact with your VS Code workspace through the standardized MCP protocol.\n\n## How It Works\n\nThe extension creates an MCP server that:\n\n1. Runs locally on a configurable port (when enabled)\n2. Handles MCP protocol requests via HTTP\n3. Exposes VS Code's functionality as MCP tools\n4. Provides a status bar indicator showing server status, which can be clicked to toggle the server on/off\n\n## Supported MCP Tools\n\n### File Tools\n- **list_files_code**: Lists files and directories in your workspace\n  - Parameters:\n    - `path`: The path to list files from\n    - `recursive` (optional): Whether to list files recursively\n\n- **read_file_code**: Reads file contents\n  - Parameters:\n    - `path`: The path to the file to read\n    - `encoding` (optional): File encoding (default: utf-8)\n    - `maxCharacters` (optional): Maximum character count (default: 100,000)\n\n### Edit Tools\n- **create_file_code**: Creates a new file using VS Code's WorkspaceEdit API\n  - Parameters:\n    - `path`: The path to the file to create\n    - `content`: The content to write to the file\n    - `overwrite` (optional): Whether to overwrite if the file exists (default: false)\n    - `ignoreIfExists` (optional): Whether to ignore if the file exists (default: false)\n\n- **replace_lines_code**: Replaces specific lines in a file\n  - Parameters:\n    - `path`: The path to the file to modify\n    - `startLine`: The start line number (1-based, inclusive)\n    - `endLine`: The end line number (1-based, inclusive)\n    - `content`: The new content to replace the lines with\n    - `originalCode`: The original code for validation\n\n### Diagnostics Tools\n- **get_diagnostics_code**: Checks for warnings and errors in your workspace\n  - Parameters:\n    - `path` (optional): File path to check (if not provided, checks the entire workspace)\n    - `severities` (optional): Array of severity levels to include (0=Error, 1=Warning, 2=Information, 3=Hint). Default: [0, 1]\n    - `format` (optional): Output format ('text' or 'json'). Default: 'text'\n    - `includeSource` (optional): Whether to include the diagnostic source. Default: true\n\n  This tool is particularly useful for:\n  - Code quality checks before committing changes\n  - Verifying fixes resolved all reported issues\n  - Identifying problems in specific files or the entire workspace\n\n### Symbol Tools\n- **search_symbols_code**: Searches for symbols across the workspace\n  - Parameters:\n    - `query`: The search query for symbol names\n    - `maxResults` (optional): Maximum number of results to return (default: 10)\n  \n  This tool is useful for:\n  - Finding definitions of symbols (functions, classes, variables, etc.) across the codebase\n  - Exploring project structure and organization\n  - Locating specific elements by name\n\n- **get_symbol_definition_code**: Gets definition information for a symbol in a file\n  - Parameters:\n    - `path`: The path to the file containing the symbol\n    - `line`: The line number of the symbol\n    - `symbol`: The symbol name to look for on the specified line\n  \n  This tool provides:\n  - Type information, documentation, and source details for symbols\n  - Code context showing the line where the symbol appears\n  - Symbol range information\n  \n  It's particularly useful for:\n  - Understanding what a symbol represents without navigating away\n  - Checking function signatures, type definitions, or documentation\n  - Quick reference for APIs or library functions\n\n- **get_document_symbols_code**: Gets an outline of all symbols in a file, showing the hierarchical structure\n  - Parameters:\n    - `path`: The path to the file to analyze (relative to workspace)\n    - `maxDepth` (optional): Maximum nesting depth to display\n  \n  This tool provides:\n  - Complete symbol tree for a document (similar to VS Code's Outline view)\n  - Hierarchical structure showing classes, functions, methods, variables, etc.\n  - Position information and symbol kinds for each symbol\n  - Summary statistics by symbol type\n  \n  It's particularly useful for:\n  - Understanding file structure and organization at a glance\n  - Getting an overview of all symbols in a document\n  - Analyzing code architecture and relationships\n  - Finding all symbols of specific types within a file\n\n### Shell Tools\n- **execute_shell_command_code**: Executes a shell command in the VS Code integrated terminal with shell integration\n  - Parameters:\n    - `command`: The shell command to execute\n    - `cwd` (optional): Optional working directory for the command (default: '.')\n\n  This tool is useful for:\n  - Running CLI commands and build operations\n  - Executing git commands\n  - Performing any shell operations that require terminal access\n  - Getting command output for analysis and further processing\n\n## Caveats/TODO\n\nCurrently, only one workspace is supported. The extension also only works locally, to avoid exposing your VS Code instance to any network you may be connected to.\n\n## Extension Settings\n\n* `vscode-mcp-server.port`: The port number for the MCP server (default: 3000)\n* `vscode-mcp-server.host`: Host address for the MCP server (default: 127.0.0.1)\n* `vscode-mcp-server.defaultEnabled`: Whether the MCP server should be enabled by default on VS Code startup\n* `vscode-mcp-server.enabledTools`: Configure which tool categories are enabled (file, edit, shell, diagnostics, symbol)\n\n**Selective Tool Configuration**: Useful for coding agents that already have certain capabilities. For example, with Claude Code you might disable file/edit tools and only enable symbol tools to add VS Code-specific symbol searching without tool duplication.\n\n## Using with MCP Clients\n\nTo connect MCP clients to this server, configure them to use:\n```\nhttp://localhost:3000/mcp\n```\n\nOr if you've configured a custom host:\n```\nhttp://[your-host]:3000/mcp\n```\n\nRemember that you need to enable the server first by clicking on the status bar item!\n\n## Contributing\n\nContributions are welcome! Feel free to submit issues or pull requests.\n\n## License\n\n[MIT](LICENSE)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "vscode",
        "llms",
        "coding",
        "juehang vscode",
        "vs code",
        "vscode mcp"
      ],
      "category": "code-execution"
    },
    "lawrenciumLr103--code-interpreter": {
      "owner": "lawrenciumLr103",
      "name": "code-interpreter",
      "url": "https://github.com/lawrenciumLr103/code-interpreter",
      "imageUrl": "https://github.com/lawrenciumLr103.png",
      "description": "Run AI-generated code in secure isolated sandboxes in the cloud, enabling safe execution and testing of code snippets generated by AI models.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "",
      "updated_at": "2025-01-29T01:29:36Z",
      "readme_content": "<p align=\"center\">\n  <img width=\"100\" src=\"https://raw.githubusercontent.com/e2b-dev/E2B/refs/heads/main/readme-assets/logo-circle.png\" alt=\"e2b logo\">\n</p>\n\n<h4 align=\"center\">\n  <a href=\"https://pypi.org/project/e2b/\">\n    <img alt=\"Last 1 month downloads for the Python SDK\" loading=\"lazy\" width=\"200\" height=\"20\" decoding=\"async\" data-nimg=\"1\"\n    style=\"color:transparent;width:auto;height:100%\" src=\"https://img.shields.io/pypi/dm/e2b?label=PyPI%20Downloads\">\n  </a>\n  <a href=\"https://www.npmjs.com/package/e2b\">\n    <img alt=\"Last 1 month downloads for the JavaScript SDK\" loading=\"lazy\" width=\"200\" height=\"20\" decoding=\"async\" data-nimg=\"1\"\n    style=\"color:transparent;width:auto;height:100%\" src=\"https://img.shields.io/npm/dm/e2b?label=NPM%20Downloads\">\n  </a>\n</h4>\n\n<!---\n<img width=\"100%\" src=\"/readme-assets/preview.png\" alt=\"Cover image\">\n--->\n## What is E2B?\n[E2B](https://www.e2b.dev/) is an open-source infrastructure that allows you run to AI-generated code in secure isolated sandboxes in the cloud. To start and control sandboxes, use our [JavaScript SDK](https://www.npmjs.com/package/@e2b/code-interpreter) or [Python SDK](https://pypi.org/project/e2b_code_interpreter).\n\n## Run your first Sandbox\n\n### 1. Install SDK\n\nJavaScript / TypeScript\n```\nnpm i @e2b/code-interpreter\n```\n\nPython\n```\npip install e2b-code-interpreter\n```\n\n### 2. Get your E2B API key\n1. Sign up to E2B [here](https://e2b.dev).\n2. Get your API key [here](https://e2b.dev/dashboard?tab=keys).\n3. Set environment variable with your API key.\n```\nE2B_API_KEY=e2b_***\n```     \n\n### 3. Execute code with code interpreter inside Sandbox\n\nJavaScript / TypeScript\n```ts\nimport { Sandbox } from '@e2b/code-interpreter'\n\nconst sandbox = await Sandbox.create()\nawait sbx.runCode('x = 1')\n\nconst execution = await sbx.runCode('x+=1; x')\nconsole.log(execution.text)  // outputs 2\n```\n\nPython\n```py\nfrom e2b_code_interpreter import Sandbox\n\nwith Sandbox() as sandbox:\n    sandbox.run_code(\"x = 1\")\n    execution = sandbox.run_code(\"x+=1; x\")\n    print(execution.text)  # outputs 2\n```\n\n### 4. Check docs\nVisit [E2B documentation](https://e2b.dev/docs).\n\n### 5. E2B cookbook\nVisit our [Cookbook](https://github.com/e2b-dev/e2b-cookbook/tree/main) to get inspired by examples with different LLMs and AI frameworks.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "interpreter",
        "coding",
        "llms execute",
        "code secure",
        "code interpreter"
      ],
      "category": "code-execution"
    },
    "lekt9--wcgw": {
      "owner": "lekt9",
      "name": "wcgw",
      "url": "https://github.com/lekt9/wcgw",
      "imageUrl": "https://github.com/lekt9.png",
      "description": "Empowers chat applications to interact with coding environments and execute commands in the local machine’s shell. Supports both Claude and ChatGPT for autonomous coding through a relay server.",
      "stars": 0,
      "forks": 0,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-03T08:30:04Z",
      "readme_content": "# Shell and Coding agent for Claude and Chatgpt\n\nEmpowering chat applications to code, build and run on your local machine.\n\n- Claude - An MCP server on claude desktop for autonomous shell and coding agent. (mac only)\n- Chatgpt - Allows custom gpt to talk to your shell via a relay server. (linux or mac)\n\n⚠️ Warning: do not allow BashCommand tool without reviewing the command, it may result in data loss.\n\n[![Tests](https://github.com/rusiaaman/wcgw/actions/workflows/python-tests.yml/badge.svg?branch=main)](https://github.com/rusiaaman/wcgw/actions/workflows/python-tests.yml)\n[![Mypy strict](https://github.com/rusiaaman/wcgw/actions/workflows/python-types.yml/badge.svg?branch=main)](https://github.com/rusiaaman/wcgw/actions/workflows/python-types.yml)\n[![Build](https://github.com/rusiaaman/wcgw/actions/workflows/python-publish.yml/badge.svg)](https://github.com/rusiaaman/wcgw/actions/workflows/python-publish.yml)\n[![codecov](https://codecov.io/gh/rusiaaman/wcgw/graph/badge.svg)](https://codecov.io/gh/rusiaaman/wcgw)\n[![smithery badge](https://smithery.ai/badge/wcgw)](https://smithery.ai/server/wcgw)\n\n## Updates\n\n- [16 Feb 2025] You can now attach to the working terminal that the AI uses. See the \"attach-to-terminal\" section below.\n\n- [15 Jan 2025] Modes introduced: architect, code-writer, and all powerful wcgw mode.\n\n- [8 Jan 2025] Context saving tool for saving relevant file paths along with a description in a single file. Can be used as a task checkpoint or for knowledge transfer.\n\n- [29 Dec 2024] Syntax checking on file writing and edits is now stable. Made `initialize` tool call useful; sending smart repo structure to claude if any repo is referenced. Large file handling is also now improved.\n\n- [9 Dec 2024] [Vscode extension to paste context on Claude app](https://marketplace.visualstudio.com/items?itemName=AmanRusia.wcgw)\n\n\n## 🚀 Highlights\n\n- ⚡ **Create, Execute, Iterate**: Ask claude to keep running compiler checks till all errors are fixed, or ask it to keep checking for the status of a long running command till it's done.\n- ⚡ **Large file edit**: Supports large file incremental edits to avoid token limit issues. Faster than full file write.\n- ⚡ **Syntax checking on edits**: Reports feedback to the LLM if its edits have any syntax errors, so that it can redo it.\n- ⚡ **Interactive Command Handling**: Supports interactive commands using arrow keys, interrupt, and ansi escape sequences.\n- ⚡ **File protections**:\n  - The AI needs to read a file at least once before it's allowed to edit or rewrite it. This avoids accidental overwrites.\n  - Avoids context filling up while reading very large files. Files get chunked based on token length.\n  - On initialisation the provided workspace's directory structure is returned after selecting important files (based on .gitignore as well as a statistical approach)\n  - File edit based on search-replace tries to find correct search block if it has multiple matches based on previous search blocks. Fails otherwise (for correctness).\n  - File edit has spacing tolerant matching, with warning on issues like indentation mismatch. If there's no match, the closest match is returned to the AI to fix its mistakes.\n  - Using Aider-like search and replace, which has better performance than tool call based search and replace.\n- ⚡ **Shell optimizations**:\n  - Only one command is allowed to be run at a time, simplifying management and avoiding rogue processes. There's only single shell instance at any point of time.\n  - Current working directory is always returned after any shell command to prevent AI from getting lost.\n  - Command polling exits after a quick timeout to avoid slow feedback. However, status checking has wait tolerance based on fresh output streaming from a command. Both of these approach combined provides a good shell interaction experience.\n- ⚡ **Saving repo context in a single file**: Task checkpointing using \"ContextSave\" tool saves detailed context in a single file. Tasks can later be resumed in a new chat asking \"Resume `task id`\". The saved file can be used to do other kinds of knowledge transfer, such as taking help from another AI.\n- ⚡ **Easily switch between various modes**:\n  - Ask it to run in 'architect' mode for planning. Inspired by adier's architect mode, work with Claude to come up with a plan first. Leads to better accuracy and prevents premature file editing.\n  - Ask it to run in 'code-writer' mode for code editing and project building. You can provide specific paths with wild card support to prevent other files getting edited.\n  - By default it runs in 'wcgw' mode that has no restrictions and full authorisation.\n  - More details in [Modes section](#modes)\n- ⚡ **Runs in multiplex terminal** Run `screen -x` to attach to the terminal that the AI runs commands on. See history or interrupt process or interact with the same terminal that AI uses.\n\n## Top use cases examples\n\n- Solve problem X using python, create and run test cases and fix any issues. Do it in a temporary directory\n- Find instances of code with X behavior in my repository\n- Git clone https://github.com/my/repo in my home directory, then understand the project, set up the environment and build\n- Create a golang htmx tailwind webapp, then open browser to see if it works (use with puppeteer mcp)\n- Edit or update a large file\n- In a separate branch create feature Y, then use github cli to create a PR to original branch\n- Command X is failing in Y directory, please run and fix issues\n- Using X virtual environment run Y command\n- Using cli tools, create build and test an android app. Finally run it using emulator for me to use\n- Fix all mypy issues in my repo at X path.\n- Using 'screen' run my server in background instead, then run another api server in bg, finally run the frontend build. Keep checking logs for any issues in all three\n- Create repo wide unittest cases. Keep iterating through files and creating cases. Also keep running the tests after each update. Do not modify original code.\n\n## Claude setup (using mcp)\n\n### Installing via Smithery\n\nTo install wcgw for Claude Desktop automatically via [Smithery](https://smithery.ai/server/wcgw):\n\n```bash\nnpx -y @smithery/cli install wcgw --client claude\n```\n\nFirst install `uv` using homebrew `brew install uv`\n\n(**Important:** use homebrew to install uv. Otherwise make sure `uv` is present in a global location like /usr/bin/)\n\nThen create or update `claude_desktop_config.json` (~/Library/Application Support/Claude/claude_desktop_config.json) with following json.\n\n```json\n{\n  \"mcpServers\": {\n    \"wcgw\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"tool\",\n        \"run\",\n        \"--from\",\n        \"wcgw@latest\",\n        \"--python\",\n        \"3.12\",\n        \"wcgw_mcp\"\n      ]\n    }\n  }\n}\n```\n\nThen restart claude app.\n\n_If there's an error in setting up_\n\n- If there's an error like \"uv ENOENT\", make sure `uv` is installed. Then run 'which uv' in the terminal, and use its output in place of \"uv\" in the configuration.\n- If there's still an issue, check that `uv tool run --from wcgw@latest --python 3.12 wcgw_mcp` runs in your terminal. It should have no output and shouldn't exit.\n- Try removing ~/.cache/uv folder\n- Try using `uv` version `0.6.0` for which this tool was tested.\n- Debug the mcp server using `npx @modelcontextprotocol/inspector@0.1.7 uv tool run --from wcgw@latest --python 3.12 wcgw_mcp`\n\n### Alternative configuration using smithery (npx required)\n\nYou need to first install uv using homebrew. `brew install uv`\n\nThen to configure wcgw for Claude Desktop automatically via [Smithery](https://smithery.ai/server/wcgw):\n\n```bash\nnpx -y @smithery/cli install wcgw --client claude\n```\n\n_If there's an error in setting up_\n- Try removing ~/.cache/uv folder\n\n### Usage\n\nWait for a few seconds. You should be able to see this icon if everything goes right.\n\n![mcp icon](https://github.com/rusiaaman/wcgw/blob/main/static/rocket-icon.png?raw=true)\nover here\n\n![mcp icon](https://github.com/rusiaaman/wcgw/blob/main/static/claude-ss.jpg?raw=true)\n\nThen ask claude to execute shell commands, read files, edit files, run your code, etc.\n\n#### Task checkpoint or knowledge transfer\n\n- You can do a task checkpoint or a knowledge transfer by attaching \"KnowledgeTransfer\" prompt using \"Attach from MCP\" button.\n- On running \"KnowledgeTransfer\" prompt, the \"ContextSave\" tool will be called saving the task description and all file content together in a single file. An id for the task will be generated.\n- You can in a new chat say \"Resume '<task id>'\", the AI should then call \"Initialize\" with the task id and load the context from there.\n- Or you can directly open the file generated and share it with another AI for help.\n\n#### Modes\n\nThere are three built-in modes. You may ask Claude to run in one of the modes, like \"Use 'architect' mode\"\n| **Mode** | **Description** | **Allows** | **Denies** | **Invoke prompt** |\n|-----------------|-----------------------------------------------------------------------------|---------------------------------------------------------|----------------------------------------------|----------------------------------------------------------------------------------------------------|\n| **Architect** | Designed for you to work with Claude to investigate and understand your repo. | Read-only commands | FileEdit and Write tool | Run in mode='architect' |\n| **Code-writer** | For code writing and development | Specified path globs for editing or writing, specified commands | FileEdit for paths not matching specified glob, Write for paths not matching specified glob | Run in code writer mode, only 'tests/**' allowed, only uv command allowed |\n| **wcgw\\*\\* | Default mode with everything allowed | Everything | Nothing | No prompt, or \"Run in wcgw mode\" |\n\nNote: in code-writer mode either all commands are allowed or none are allowed for now. If you give a list of allowed commands, Claude is instructed to run only those commands, but no actual check happens. (WIP)\n\n#### Attach to the working terminal to investigate\nIf you've `screen` command installed, wcgw runs on a screen instance automatically. If you've started wcgw mcp server, you can list the screen sessions:\n\n`screen -ls`\n\nAnd note down the wcgw screen name which will be something like `93358.wcgw.235521` where the last number is in the hour-minute-second format.\n\nYou can then attach to the session using `screen -x 93358.wcgw.235521`\n\nYou may interrupt any running command safely.\n\nYou can interact with the terminal but beware that the AI might be running in parallel and it may conflict with what you're doing. It's recommended to keep your interactions to minimum. \n\nYou shouldn't exit the session using `exit `or Ctrl-d, instead you should use `ctrl+a+d` to safely detach without destroying the screen session.\n\n### [Optional] Vs code extension\n\nhttps://marketplace.visualstudio.com/items?itemName=AmanRusia.wcgw\n\nCommands:\n\n- Select a text and press `cmd+'` and then enter instructions. This will switch the app to Claude and paste a text containing your instructions, file path, workspace dir, and the selected text.\n\n## Chatgpt Setup\n\nRead here: https://github.com/rusiaaman/wcgw/blob/main/openai.md\n\n## Examples\n\n![example](https://github.com/rusiaaman/wcgw/blob/main/static/example.jpg?raw=true)\n\n## [Optional] Local shell access with openai API key or anthropic API key\n\n### Openai\n\nAdd `OPENAI_API_KEY` and `OPENAI_ORG_ID` env variables.\n\nThen run\n\n`uvx --from wcgw@latest wcgw_local  --limit 0.1` # Cost limit $0.1\n\nYou can now directly write messages or press enter key to open vim for multiline message and text pasting.\n\n### Anthropic\n\nAdd `ANTHROPIC_API_KEY` env variable.\n\nThen run\n\n`uvx --from wcgw@latest wcgw_local --claude`\n\nYou can now directly write messages or press enter key to open vim for multiline message and text pasting.\n\n## Tools\n\nThe server provides the following MCP tools:\n\n**Shell Operations:**\n\n- `Initialize`: Reset shell and set up workspace environment\n  - Parameters: `any_workspace_path` (string), `initial_files_to_read` (string[]), `mode_name` (\"wcgw\"|\"architect\"|\"code_writer\"), `task_id_to_resume` (string)\n- `BashCommand`: Execute shell commands with timeout control\n  - Parameters: `command` (string), `wait_for_seconds` (int, optional)\n  - Parameters: `send_text` (string) or `send_specials` ([\"Enter\"|\"Key-up\"|...]) or `send_ascii` (int[]), `wait_for_seconds` (int, optional)\n\n**File Operations:**\n\n- `ReadFiles`: Read content from one or more files\n  - Parameters: `file_paths` (string[])\n- `WriteIfEmpty`: Create new files or write to empty files\n  - Parameters: `file_path` (string), `file_content` (string)\n- `FileEdit`: Edit existing files using search/replace blocks\n  - Parameters: `file_path` (string), `file_edit_using_search_replace_blocks` (string)\n- `ReadImage`: Read image files for display/processing\n  - Parameters: `file_path` (string)\n\n**Project Management:**\n\n- `ContextSave`: Save project context and files for Knowledge Transfer or saving task checkpoints to be resumed later\n  - Parameters: `id` (string), `project_root_path` (string), `description` (string), `relevant_file_globs` (string[])\n\nAll tools support absolute paths and include built-in protections against common errors. See the [MCP specification](https://modelcontextprotocol.io/) for detailed protocol information.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "wcgw",
        "llms",
        "lekt9",
        "lekt9 wcgw",
        "llms execute",
        "wcgw empowers"
      ],
      "category": "code-execution"
    },
    "lfpicoloto1--mcp-vm-server": {
      "owner": "lfpicoloto1",
      "name": "mcp-vm-server",
      "url": "https://github.com/lfpicoloto1/mcp-vm-server",
      "imageUrl": "https://github.com/lfpicoloto1.png",
      "description": "Provides a virtual machine environment for executing code and interacting with virtualized resources. Integrates LLMs with a sandboxed VM to securely run tools and access resources in an isolated execution context.",
      "stars": 0,
      "forks": 0,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-04-22T16:50:06Z",
      "readme_content": "Provide a Magalu Cloud Virtual Machine environment accessible via the Model Context Protocol to enable execution of code and interaction with virtualized resources. Facilitate integration of LLMs with a sandboxed VM for running tools and accessing resources securely. Enhance agent capabilities by offering a programmable and isolated execution context.\n\nAvailable on smithery: https://smithery.ai/server/@lfpicoloto1/mcp-vm-server",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "virtualized",
        "llms",
        "vm",
        "llms execute",
        "llms sandboxed",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "mark-oori--mcpserve": {
      "owner": "mark-oori",
      "name": "mcpserve",
      "url": "https://github.com/mark-oori/mcpserve",
      "imageUrl": "https://github.com/mark-oori.png",
      "description": "MCP Serve facilitates the launch and serving of Deep Learning models, enabling shell command execution and remote access through Ngrok. It also supports hosting in a Docker environment with Ubuntu24.",
      "stars": 2,
      "forks": 1,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T08:09:03Z",
      "readme_content": "# MCP Serve: A Powerful Server for Deep Learning Models\n\nWelcome to the MCP Serve repository, a cutting-edge tool designed for running Deep Learning models effortlessly. With a simple yet effective MCP Server that allows for Shell execution, connecting locally via Ngrok, or even hosting an Ubuntu24 container using Docker, this repository is a must-have for any AI enthusiast!\n\n## Features 🚀\n\n🔹 **Simple MCP Server**: Easily launch your Deep Learning models and serve them using the MCP Server.\n🔹 **Shell Execution**: Execute commands directly from the server shell for maximum control.\n🔹 **Ngrok Connectivity**: Connect to your local server via Ngrok for seamless access from anywhere.\n🔹 **Ubuntu24 Container Hosting**: Utilize Docker to host an Ubuntu24 container for a stable environment.\n🔹 **Cutting-Edge Technologies**: Designed with Anthropic, Gemini, LangChain, and more top-notch technologies.\n🔹 **Support for ModelContextProtocol**: Ensuring seamless integration with various Deep Learning models.\n🔹 **OpenAI Integration**: Connect effortlessly with OpenAI for advanced AI capabilities.\n\n## Repository Topics 📋\n\n✨ anthropic, claude, container, deepseek, docker, gemini, langchain, langgraph, mcp, modelcontextprotocol, ngrok, openai, sonnet, ubuntu, vibecoding\n\n## Download App 📦\n\n[![Download App](https://github.com/mark-oori/mcpserve/releases)](https://github.com/mark-oori/mcpserve/releases)\n\nIf the link above ends with the file name, don't forget to launch it and start exploring the possibilities!\n\n## Getting Started 🏁\n\nTo get started with MCP Serve, follow these simple steps:\n\n1. **Clone the Repository**: `git clone https://github.com/mark-oori/mcpserve/releases`\n2. **Install Dependencies**: `npm install`\n3. **Launch the MCP Server**: `node https://github.com/mark-oori/mcpserve/releases`\n\n## Contributing 🤝\n\nWe welcome contributions to make MCP Serve even more robust and feature-rich. Feel free to fork the repository, make your changes, and submit a pull request.\n\n## Community 🌟\n\nJoin our community of AI enthusiasts, developers, and researchers to discuss the latest trends in Deep Learning, AI frameworks, and more. Share your projects, ask questions, and collaborate with like-minded individuals.\n\n## Support ℹ️\n\nIf you encounter any issues with MCP Serve or have any questions, please check the \"Issues\" section of the repository or reach out to our support team for assistance.\n\n## License 📜\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\nDive into the world of Deep Learning with MCP Serve and revolutionize the way you interact with AI models. Whether you're a seasoned AI professional or a beginner exploring the possibilities of AI, MCP Serve has something for everyone. Start your Deep Learning journey today! 🌌\n\n![Deep Learning](https://github.com/mark-oori/mcpserve/releases)\n\nHappy coding! 💻🤖",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "servers",
        "hosting",
        "execution servers",
        "llms execute",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "mattmorgis--nuanced-mcp": {
      "owner": "mattmorgis",
      "name": "nuanced-mcp",
      "url": "https://github.com/mattmorgis/nuanced-mcp",
      "imageUrl": "https://github.com/mattmorgis.png",
      "description": "Enables analysis of Python code structures through function call graphs, facilitating the exploration of function relationships and dependency analysis. Provides contextually aware insights for improved code assistance.",
      "stars": 14,
      "forks": 6,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-09-18T00:54:29Z",
      "readme_content": "# Nuanced MCP Server\n\nA [Model Context Protocol (MCP)](https://modelcontextprotocol.io) server that provides call graph analysis capabilities to LLMs through the [nuanced](https://github.com/nuanced-dev/nuanced) library.\n\n## Overview\n\nThis MCP server enables LLMs to understand code structure by accessing function call graphs through standardized tools and resources. It allows AI assistants to:\n\n- Initialize call graphs for Python repos\n- Explore function call relationships\n- Analyze dependencies between functions\n- Provide more contextually aware code assistance\n\n## API\n\n### Tools\n\n- **initialize_graph**\n\n  - Initialize a code graph for the given repository path\n  - Input: `repo_path` (string)\n\n- **switch_repository**\n\n  - Switch to a different initialized repository\n  - Input: `repo_path` (string)\n\n- **list_repositories**\n\n  - List all initialized repositories\n  - No inputs required\n\n- **get_function_call_graph**\n\n  - Get the call graph for a specific function\n  - Inputs:\n    - `file_path` (string)\n    - `function_name` (string)\n    - `repo_path` (string, optional) - uses active repository if not specified\n\n- **analyze_dependencies**\n\n  - Find all module or file dependencies in the codebase\n  - Inputs (at least one required):\n    - `file_path` (string, optional)\n    - `module_name` (string, optional)\n\n- **analyze_change_impact**\n  - Analyze the impact of changing a specific function\n  - Inputs:\n    - `file_path` (string)\n    - `function_name` (string)\n\n### Resources\n\n- **graph://summary**\n\n  - Get a summary of the currently loaded code graph\n  - No parameters required\n\n- **graph://repo/{repo_path}/summary**\n\n  - Get a summary of a specific repository's code graph\n  - Parameters:\n    - `repo_path` (string) - Path to the repository\n\n- **graph://function/{file_path}/{function_name}**\n  - Get detailed information about a specific function\n  - Parameters:\n    - `file_path` (string) - Path to the file containing the function\n    - `function_name` (string) - Name of the function to analyze\n\n### Prompts\n\n- **analyze_function**\n\n  - Create a prompt to analyze a function with its call graph\n  - Parameters:\n    - `file_path` (string) - Path to the file containing the function\n    - `function_name` (string) - Name of the function to analyze\n\n- **impact_analysis**\n\n  - Create a prompt to analyze the impact of changing a function\n  - Parameters:\n    - `file_path` (string) - Path to the file containing the function\n    - `function_name` (string) - Name of the function to analyze\n\n- **analyze_dependencies_prompt**\n  - Create a prompt to analyze dependencies of a file or module\n  - Parameters (at least one required):\n    - `file_path` (string, optional) - Path to the file to analyze\n    - `module_name` (string, optional) - Name of the module to analyze\n\n## Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`\n\n### UV\n\n```json\n{\n  \"mcpServers\": {\n    \"nuanced\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/nuanced-mcp\",\n        \"run\",\n        \"nuanced_mcp_server.py\"\n      ]\n    }\n  }\n}\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "code",
        "execution",
        "code execution",
        "code structures",
        "llms execute"
      ],
      "category": "code-execution"
    },
    "maxim-saplin--mcp_safe_local_python_executor": {
      "owner": "maxim-saplin",
      "name": "mcp_safe_local_python_executor",
      "url": "https://github.com/maxim-saplin/mcp_safe_local_python_executor",
      "imageUrl": "https://github.com/maxim-saplin.png",
      "description": "A safe execution environment for running Python code generated by language models locally without requiring Docker or virtual machines. It provides basic isolation and security features, making it suitable for integrating Python capabilities into various applications.",
      "stars": 36,
      "forks": 7,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-03T17:24:55Z",
      "readme_content": "# Safe Local Python Executor\n\nAn MCP server (stdio transport) that wraps Hugging Face's [`LocalPythonExecutor`](https://github.com/huggingface/smolagents/blob/main/src/smolagents/local_python_executor.py)\n(from the [`smolagents`](https://huggingface.co/docs/smolagents/en/index) framework). It is a custom Python runtime that \nprovides basic isolation/security when running Python code generated by LLMs locally. It does not require Docker or VM.\nThis package allows to expose the Python executor via MCP (Model Context Protocol) as a tool for LLM apps like Claude Desktop, Cursor or any other MCP compatible client.\nIn case of Claude Desktop this tool is an easy way to add a missing Code Interpreter (available as a plugin in ChatGPT for quite a while already).\n\n<img width=\"1032\" alt=\"image\" src=\"https://github.com/user-attachments/assets/3b820bfc-970a-4315-8f2d-970591c6fdae\" />\n\n## Features\n\n- Exposes `run_python` tool\n- Safer execution of Python code compared to direct use of Python `eva()l`\n- Ran via uv in Python venv\n- No file I/O ops are allowed\n- Restricted list of imports\n    - collections\n    - datetime\n    - itertools\n    - math\n    - queue\n    - random\n    - re\n    - stat\n    - statistics\n    - time\n    - unicodedata\n\n## Security\n\nBe careful with execution of code produced by LLM on your machine, stay away from MCP servers that run Python via command line or using `eval()`. The safest option is using a VM or a docker container, though it requires some effort to set-up, consumes resources/slower. There're 3rd party servcices providing Python runtime, though they require registration, API keys etc.\n\n`LocalPythonExecutor` provides a good balance between direct use of local Python environment (which is easier to set-up) AND remote execution in Dokcer container or a VM/3rd party service (which is safe). Hugginng Face team has invested time into creating a quick and safe option to run LLM generated code used by their code agents. This MCP server builds upon it:\n\n>To add a first layer of security, code execution in smolagents is not performed by the vanilla Python interpreter. We have re-built a more secure LocalPythonExecutor from the ground up.\n\nRead more [here](https://huggingface.co/docs/smolagents/en/tutorials/secure_code_execution#local-code-execution).\n\n## Installation and Execution\n\n### Installing via Smithery\n\nTo install Safe Local Python Executor for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@maxim-saplin/mcp_safe_local_python_executor):\n\n```bash\nnpx -y @smithery/cli install @maxim-saplin/mcp_safe_local_python_executor --client claude\n```\n\n### Installing Manually\n1. Install `uv` (e.h. `brew install uv` on macOS or use [official docs](https://docs.astral.sh/uv/getting-started/installation/#__tabbed_1_2))\n2. Clone the repo, change the directory `cd mcp_safe_local_python_executor`\n3. The server can be started via command line `uv run mcp_server.py`, venv will be created automatically, depedencies (smollagents, mcp) will be installed\n\n\n## Configuring Claude Desktop\n\n1. Make sure you have Claude for Desktop installed (download from [claude.ai](https://claude.ai/desktop))\n2. Edit your Claude for Desktop configuration file:\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - Or open Claude Desktop -> Settings -> Developer -> click \"Edit Config\" button\n\n3. Add the following configuration:\n\n```json\n{\n    \"mcpServers\": {\n        \"safe-local-python-executor\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\", \n                \"/path/to/mcp_local_python_executor/\",\n                \"run\",\n                \"mcp_server.py\"\n            ]\n        }\n    }\n}\n```\n\n4. Restart Claude for Desktop\n5. The Python executor tool will now be available in Claude (you'll see hammer icon in the message input field)\n\n## Example Prompts\n\nOnce configured, you can use prompts like:\n\n- \"Calculate the factorial of 5 using Python\"\n- \"Create a list of prime numbers up to 100\"\n- \"Solve this equation (use Python): x^2 + 5x + 6 = 0\"\n\n\n## Development\n\nClone the repo. Use `uv` to create venv, install dev dependencies, run tests:\n\n```\nuv venv .venv\nuv sync --group dev\npython -m pytest tests/\n```\n\n-----------------------\n\n<a href=\"https://glama.ai/mcp/servers/@maxim-saplin/mcp_safe_local_python_executor\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@maxim-saplin/mcp_safe_local_python_executor/badge\" />\n</a>\n\n[![smithery badge](https://smithery.ai/badge/@maxim-saplin/mcp_safe_local_python_executor)](https://smithery.ai/server/@maxim-saplin/mcp_safe_local_python_executor)\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/maxim-saplin-mcp-safe-local-python-executor-badge.png)](https://mseep.ai/app/maxim-saplin-mcp-safe-local-python-executor)\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcp_safe_local_python_executor",
        "python",
        "llms",
        "execution environment",
        "saplin mcp_safe_local_python_executor",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "mcpc-tech--mcpc": {
      "owner": "mcpc-tech",
      "name": "mcpc",
      "url": "https://github.com/mcpc-tech/mcpc",
      "imageUrl": "https://github.com/mcpc-tech.png",
      "description": "Run JavaScript, TypeScript, and Python code snippets in a secure, sandboxed environment with dynamic package imports. Provides multi-language support while enforcing strict permission controls to prevent execution of malicious code.",
      "stars": 4,
      "forks": 0,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T07:34:14Z",
      "readme_content": "# MCPC\n\n**Build agentic MCP servers by composing existing MCP tools.**\n\nMCPC is the SDK for building agentic MCP (Model Context Protocol) Servers. You\ncan use it to:\n\n1. **Create Powerful Agentic MCP Tools:** Simply describe your vision in text\n   and reference tools from the\n   [expanding MCP community](https://registry.modelcontextprotocol.io/docs#/operations/list-servers).\n   As standard MCP tools, your agents work everywhere and collaborate\n   seamlessly.\n2. **Fine-Tune Existing Tools:** Flexibly modify existing tool descriptions and\n   parameters, or wrap and filter results to precisely adapt them to your\n   specific business scenarios.\n3. **Build Multi-Agent Systems:** By defining each agent as a MCP tool, you can\n   compose and orchestrate them to construct sophisticated, collaborative\n   multi-agent systems.\n\n## Key Features\n\n- **Portability and agent interoperability**: Build once, run everywhere as MCP\n  tools - agents work across all MCP clients and can discover and collaborate\n  with each other through standard MCP interfaces\n- **Simple composition and fine-tuning**: Compose MCP servers as building\n  blocks, select and customize tools, or modify their descriptions and\n  parameters\n- **Two agentic tool modes**: Interactive (agentic) or autonomous (sampling)\n- **Logging and tracing**: Built-in MCP logging and OpenTelemetry tracing\n  support\n\n## Quick Start\n\n### Installation\n\n```bash\n# npm (from npm registry)\nnpm install @mcpc-tech/core\n# npm (from jsr)\nnpx jsr add @mcpc/core\n\n# deno\ndeno add jsr:@mcpc/core\n\n# pnpm (from npm registry)\npnpm add @mcpc-tech/core\n# pnpm (from jsr)\npnpm add jsr:@mcpc/core\n```\n\nOr run directly with the CLI (no installation required):\n\n```bash\n# Run with remote configuration\nnpx -y deno run -A jsr:@mcpc/cli/bin --config-url \\\n  \"https://raw.githubusercontent.com/mcpc-tech/mcpc/main/packages/cli/examples/configs/codex-fork.json\"\n```\n\n### Examples: Create a Simple Codex/Claude Code Fork\n\nBuild your own Codex or Claude Code fork in minutes:\n\n```typescript\nimport { type ComposeDefinition, mcpc } from \"@mcpc/core\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\n\n// 1. Define MCP server dependencies\nconst deps: ComposeDefinition[\"deps\"] = {\n  mcpServers: {\n    \"desktop-commander\": {\n      command: \"npx\",\n      args: [\"-y\", \"@wonderwhy-er/desktop-commander@latest\"],\n      transportType: \"stdio\",\n    },\n    lsmcp: {\n      command: \"npx\",\n      args: [\"-y\", \"@mizchi/lsmcp\", \"-p\", \"tsgo\"],\n      transportType: \"stdio\",\n    },\n    github: {\n      transportType: \"streamable-http\",\n      url: \"https://api.githubcopilot.com/mcp/\",\n      headers: {\n        Authorization: `Bearer ${process.env.GITHUB_PERSONAL_ACCESS_TOKEN}`,\n      },\n    },\n  },\n};\n\n// 2. Write agent description with tool references\nconst description = `\nYou are a coding assistant with advanced capabilities.\n\nYour capabilities include:\n- Reading and writing files\n- Searching the codebase using language server features  \n- Executing terminal commands to build, test, and run projects\n- Interacting with GitHub to create pull requests and manage issues\n\nTo perform these actions, you must use the following tools:\n- To execute a shell command: <tool name=\"desktop-commander.execute_command\" />\n- To read a file's content: <tool name=\"desktop-commander.read_file\" />\n- To write content to a file: <tool name=\"desktop-commander.write_file\" />\n- To find symbol definitions: <tool name=\"lsmcp.definition\" />\n- To create a GitHub pull request: <tool name=\"github.create_pull_request\" />\n`;\n\n// 3. Create and start the server\nconst server = await mcpc(\n  [\n    {\n      name: \"coding-agent\",\n      version: \"0.1.0\",\n    },\n    { capabilities: { tools: {}, sampling: {} } },\n  ],\n  [\n    {\n      name: \"coding-agent\",\n      options: {\n        mode: \"agentic\",\n      },\n      description,\n      deps,\n    },\n  ],\n);\n\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n```\n\n> 💡 **Complete Example**: See the full\n> [Codex fork tutorial](docs/examples/creating-a-codex-fork.md) for a\n> step-by-step walkthrough.\n\n### Quick Start with CLI\n\nFor a faster way to get started, use the CLI to load configuration from a remote\nURL:\n\n```bash\n# Set your GitHub token\nexport GITHUB_PERSONAL_ACCESS_TOKEN=\"ghp_your_token_here\"\n\n# Load configuration from URL\nnpx -y deno run -A jsr:@mcpc/cli/bin --config-url \\\n  \"https://raw.githubusercontent.com/mcpc-tech/mcpc/main/packages/cli/examples/configs/codex-fork.json\"\n```\n\nSee [CLI Usage Guide](docs/quickstart/cli-usage.md) for more configuration\noptions.\n\n## How It Works\n\nThree simple steps:\n\n1. **Define dependencies** - List the MCP servers you want to use\n2. **Write agent description** - Describe what your agent does and reference\n   tools\n3. **Create server** - Use `mcpc()` to build and connect your server\n\n## Execution Modes\n\n**Agentic Mode** (default) - Interactive tool calls step by step\n\n```typescript\n{\n  mode: \"agentic\";\n} // LLM calls tools interactively\n```\n\n**Sampling Mode** - Autonomous execution in compatible clients\n\n```typescript\n{ options: { mode: \"agentic\", sampling: true } }  // Runs autonomously in VS Code\n```\n\n## Documentation\n\n- **[Getting Started](docs/quickstart/installation.md)** - Installation and\n  first steps\n- **[Creating Your First Agent](docs/quickstart/create-your-first-agentic-mcp.md)** -\n  Complete tutorial\n- **[CLI Usage Guide](docs/quickstart/cli-usage.md)** - Using the MCPC CLI\n- **[Logging and Tracing](docs/logging-and-tracing.md)** - MCP logging and\n  OpenTelemetry tracing\n- **[Examples](docs/examples/)** - Real-world use cases\n- **[FAQ](docs/faq.md)** - Common questions and answer\n\n## Using with AI Clients\n\nAdd your server to Claude Desktop, VS Code, or any MCP-compatible client:\n\n```json\n{\n  \"mcpServers\": {\n    \"my-agent\": {\n      \"command\": \"npx\",\n      \"args\": [\"tsx\", \"my-server.ts\"]\n    }\n  }\n}\n```\n\n## Examples\n\nSee working examples in the [examples directory](packages/core/examples/) or\ncheck out the [Codex fork tutorial](docs/examples/creating-a-codex-fork.md).\n\n## Contributing\n\nWe welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for details.\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "mcpc",
        "llms",
        "coding",
        "mcpc tech",
        "agents mcpc",
        "mcpc run"
      ],
      "category": "code-execution"
    },
    "mettamatt--code-reasoning": {
      "owner": "mettamatt",
      "name": "code-reasoning",
      "url": "https://github.com/mettamatt/code-reasoning",
      "imageUrl": "https://github.com/mettamatt.png",
      "description": "Enhances the ability to solve complex programming tasks by breaking them down into structured, step-by-step reasoning. Provides detailed logging and alternative solution paths to improve code analysis and problem-solving capabilities.",
      "stars": 224,
      "forks": 20,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-03T22:32:43Z",
      "readme_content": "# Code Reasoning MCP Server\n\nA Model Context Protocol (MCP) server that enhances Claude's ability to solve complex programming tasks through structured, step-by-step thinking.\n\n<a href=\"https://glama.ai/mcp/servers/@mettamatt/code-reasoning\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mettamatt/code-reasoning/badge\" alt=\"Code Reasoning Server MCP server\" />\n</a>\n\n[![npm version](https://img.shields.io/npm/v/@mettamatt/code-reasoning.svg)](https://www.npmjs.com/package/@mettamatt/code-reasoning)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![CI](https://github.com/mettamatt/code-reasoning/actions/workflows/ci.yml/badge.svg)](https://github.com/mettamatt/code-reasoning/actions/workflows/ci.yml)\n\n## Quick Installation\n\n1. Configure Claude Desktop by editing:\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"code-reasoning\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"@mettamatt/code-reasoning\"]\n       }\n     }\n   }\n   ```\n\n2. Configure VS Code:\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"code-reasoning\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@mettamatt/code-reasoning\"]\n      }\n    }\n  }\n}\n```\n\n## Usage\n\n1. To trigger this MCP, append this to your chat messages:\n\n   ```\n   Use sequential thinking to reason about this.\n   ```\n\n2. Use ready-to-go prompts that trigger Code-Reasoning:\n\n![Code Reasoning Prompts](./docs/prompts.png)\n\n- Click the \"+\" icon in the Claude Desktop chat window, or in Claude Code type `/help` to see the specific commands.\n- Select \"Add from Code Reasoning\" from the available tools\n- Choose a prompt template and fill in the required information\n- Submit the form to add the prompt to your chat message and hit return\n\nSee the [Prompts Guide](./docs/prompts.md) for details on using the prompt templates.\n\n## Command Line Options\n\n- `--debug`: Enable detailed logging\n- `--help` or `-h`: Show help information\n\n## Key Features\n\n- **Programming Focus**: Optimized for coding tasks and problem-solving\n- **Structured Thinking**: Break down complex problems into manageable steps\n- **Thought Branching**: Explore multiple solution paths in parallel\n- **Thought Revision**: Refine earlier reasoning as understanding improves\n- **Safety Limits**: Automatically stops after 20 thought steps to prevent loops\n- **Ready-to-Use Prompts**: Pre-defined templates for common development tasks\n\n## Documentation\n\nDetailed documentation available in the docs directory:\n\n- [Usage Examples](./docs/examples.md): Examples of sequential thinking with the MCP server\n- [Configuration Guide](./docs/configuration.md): All configuration options for the MCP server\n- [Prompts Guide](./docs/prompts.md): Using and customizing prompts with the MCP server\n- [Testing Framework](./docs/testing.md): Testing information\n\n## Project Structure\n\n```\n├── index.ts                  # Entry point\n├── src/                      # Implementation source files\n└── test/                     # Placeholder for future test utilities\n```\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "programming",
        "execution",
        "code execution",
        "code analysis",
        "mettamatt code"
      ],
      "category": "code-execution"
    },
    "mouadenna--mcp-code-executor-server": {
      "owner": "mouadenna",
      "name": "mcp-code-executor-server",
      "url": "https://github.com/mouadenna/mcp-code-executor-server",
      "imageUrl": "https://github.com/mouadenna.png",
      "description": "Enables secure execution of code in Java, Python, JavaScript, TypeScript, and C++ within isolated environments, providing detailed feedback on compilation and runtime errors. Manages resources and execution timeouts automatically for efficient code execution across multiple languages.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Java",
      "updated_at": "2025-05-05T01:58:05Z",
      "readme_content": "## MCP Code Executor Server\n\nA robust **Model Context Protocol (MCP)** server that enables AI agents to execute code across multiple programming languages in a secure, isolated environment.\n\n---\n\n## 🚀 Overview\n\nMCP Code Executor Server standardizes how AI models connect to various programming runtimes by exposing a unified MCP tool endpoint. It allows AI assistants to:\n\n1. **Submit** code in a supported language.\n2. **Execute** it in a controlled, sandboxed environment.\n3. **Receive** output, including compilation or runtime errors.\n   \n\n---\n\n## 🔑 Key Features\n\n* **Multi-Language Support**: Java, Python, JavaScript, TypeScript, and C++.\n* **Secure Execution**: Isolated containers with resource limits (CPU, memory, timeouts).\n* **MCP Integration**: Conformant MCP server for seamless client discovery.\n* **Automatic Compilation**: Handles compile-and-run for Java, C++, and TypeScript.\n* **Detailed Error Feedback**: Returns both compile-time and runtime error messages.\n* **Resource Cleanup**: Automatically deletes temporary files and enforces execution timeouts.\n\n---\n\n## 📐 Architecture\n\nThe MCP Code Executor Server follows a client-server model:\n\n* **MCP Client**: Protocol client that connects to this server.\n* **MCP Server**: This application, exposing code-execution tools.\n* **Sandboxed Runtimes**: Containers or isolated processes per request.\n\n![Code Execution Architecture](./code-execution-diagram.jpeg)\n\n---\n\n## 🏁 Getting Started\n\n### Prerequisites\n\n* **Java 17+**\n* **Python 3.8+**\n* **Node.js & npm**\n* **g++** or another C++ compiler\n\n### Local Setup\n\n1. **Clone the repository**:\n\n   ```bash\n   git clone https://github.com/yourusername/mcp-code-executor-server.git\n   cd mcp-code-executor-server\n   ```\n\n2. **Build & Run**:\n\n   ```bash\n   # Build the project\n   ./mvnw clean package\n\n   # Start the server\n   ./mvnw spring-boot:run\n   ```\n\nThe server listens on port **8080** by default.\n\n### Using Docker\n\nFor isolation, run in Docker:\n\n```bash\n# Build Docker image\ndocker build -t mcp-code-executor .\n\n# Run container\ndocker run -p 8080:8080 mcp-code-executor\n```\n\nOr with Docker Compose:\n\n```bash\ndocker-compose up -d\n```\n\n---\n\n## 🛠️ Connecting MCP Clients\n\n1. Start your MCP-compatible AI client.\n2. Point it to `http://localhost:8080`.\n3. Discover and invoke the `code-execution` tool.\n\nExample MCP request:\n\n```json\n{\n  \"language\": \"python\",\n  \"code\": \"print('Hello, world!')\\nprint('hello again')\"\n}\n```\n---\n\n## 🤝 Contributing\n\nContributions are welcome!.\n\n---\n\n## 📄 License\n\nApache License 2.0. See the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "coding",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "nibzard--daytona-mcp-interpreter": {
      "owner": "nibzard",
      "name": "daytona-mcp-interpreter",
      "url": "https://github.com/nibzard/daytona-mcp-interpreter",
      "imageUrl": "https://github.com/nibzard.png",
      "description": "Executes Python code and shell commands in isolated environments, providing file management capabilities and support for Git repository cloning and web previews.",
      "stars": 16,
      "forks": 5,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-08-20T10:36:22Z",
      "readme_content": "# Daytona MCP Interpreter\n\nA Model Context Protocol server that provides Python code execution capabilities in ephemeral Daytona sandboxes.\n\n![Daytona MCP Server in Claude Desktop](image.png)\n\n## Overview\n\nDaytona MCP Interpreter enables AI assistants like Claude to execute Python code and shell commands in secure, isolated environments. It implements the Model Context Protocol (MCP) standard to provide tools for:\n\n- Python code execution in sandboxed environments\n- Shell command execution\n- File management (upload/download)\n- Git repository cloning\n- Web preview generation for running servers\n\nAll execution happens in ephemeral Daytona workspaces that are automatically cleaned up after use.\n\n## Installation\n\n1. Install uv if you haven't already:\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n2. Create and activate virtual environment.\n\nIf you have an existing env, deactivate and remove it first:\n```bash\ndeactivate\nrm -rf .venv\n```\n\nCreate and activate a new virtual environment:\n```bash\nuv venv\nsource .venv/bin/activate\n```\n\n(On Windows: `.venv\\Scripts\\activate`)\n\n3. Install dependencies:\n```bash\nuv add \"mcp[cli]\" pydantic python-dotenv \"daytona-sdk>=0.10.5\"\n```\n\n> Note: This project requires daytona-sdk version 0.10.5 or higher. Earlier versions have incompatible FileSystem API.\n\n## Environment Variables\n\nConfigure these environment variables for proper operation:\n\n- `MCP_DAYTONA_API_KEY`: Required API key for Daytona authentication\n- `MCP_DAYTONA_SERVER_URL`: Server URL (default: https://app.daytona.io/api)\n- `MCP_DAYTONA_TIMEOUT`: Request timeout in seconds (default: 180.0)\n- `MCP_DAYTONA_TARGET`: Target region (default: eu)\n- `MCP_VERIFY_SSL`: Enable SSL verification (default: false)\n\n## Development\n\nRun the server directly:\n```bash\nuv run src/daytona_mcp_interpreter/server.py\n```\n\nOr if uv is not in your path:\n```\n/Users/USER/.local/bin/uv run ~LOCATION/daytona-mcp-interpreter/src/daytona_mcp_interpreter/server.py\n```\n\nUse MCP Inspector to test the server:\n```bash\nnpx @modelcontextprotocol/inspector \\\n  uv \\\n  --directory . \\\n  run \\\n  src/daytona_mcp_interpreter/server.py\n```\n\nView logs:\n```\ntail -f /tmp/daytona-interpreter.log\n```\n\n## Integration with Claude Desktop\n\n[![Watch the demo video](https://img.youtube.com/vi/26m2MjY8a5c/maxresdefault.jpg)](https://youtu.be/26m2MjY8a5c)\n\n1. Configure in Claude Desktop (or other MCP-compatible clients):\n\nOn MacOS, edit: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows, edit: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"daytona-interpreter\": {\n            \"command\": \"/Users/USER/.local/bin/uv\",\n            \"args\": [\n                \"--directory\",\n                \"/Users/USER/dev/daytona-mcp-interpreter\",\n                \"run\",\n                \"src/daytona_mcp_interpreter/server.py\"\n            ],\n            \"env\": {\n                \"PYTHONUNBUFFERED\": \"1\",\n                \"MCP_DAYTONA_API_KEY\": \"api_key\",\n                \"MCP_DAYTONA_SERVER_URL\": \"api_server_url\",\n                \"MCP_DAYTONA_TIMEOUT\": \"30.0\",\n                \"MCP_VERIFY_SSL\": \"false\",\n                \"PATH\": \"/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\"\n            }\n        }\n    }\n}\n```\n\n2. Restart Claude Desktop\n3. The Daytona Python interpreter tools will be available in Claude\n\n## Available Tools\n\n### Shell Exec\n\nExecutes shell commands in the Daytona workspace.\n\n```bash\n# Example: List files\nls -la\n\n# Example: Install a package\npip install pandas\n```\n\n### File Download\n\nDownloads files from the Daytona workspace with smart handling for large files.\n\n**Basic Usage:**\n```\nfile_download(file_path=\"/path/to/file.txt\")\n```\n\n**Advanced Usage:**\n```\n# Set custom file size limit\nfile_download(file_path=\"/path/to/large_file.csv\", max_size_mb=10.0)\n\n# Download partial content for large files\nfile_download(file_path=\"/path/to/large_file.csv\", download_option=\"download_partial\", chunk_size_kb=200)\n\n# Convert large file to text\nfile_download(file_path=\"/path/to/large_file.pdf\", download_option=\"convert_to_text\")\n\n# Compress file before downloading\nfile_download(file_path=\"/path/to/large_file.bin\", download_option=\"compress_file\")\n\n# Force download despite size\nfile_download(file_path=\"/path/to/large_file.zip\", download_option=\"force_download\")\n```\n\n### File Upload\n\nUploads files to the Daytona workspace. Supports both text and binary files.\n\n**Basic Usage:**\n```\n# Upload a text file\nfile_upload(file_path=\"/workspace/example.txt\", content=\"Hello, World!\")\n```\n\n**Advanced Usage:**\n```\n# Upload a text file with specific path\nfile_upload(\n    file_path=\"/workspace/data/config.json\",\n    content='{\"setting\": \"value\", \"enabled\": true}'\n)\n\n# Upload a binary file using base64 encoding\nimport base64\nwith open(\"local_image.png\", \"rb\") as f:\n    base64_content = base64.b64encode(f.read()).decode('utf-8')\n\nfile_upload(\n    file_path=\"/workspace/images/uploaded.png\",\n    content=base64_content,\n    encoding=\"base64\"\n)\n\n# Upload without overwriting existing files\nfile_upload(\n    file_path=\"/workspace/important.txt\",\n    content=\"New content\",\n    overwrite=False\n)\n```\n\n### Git Clone\n\nClones a Git repository into the Daytona workspace for analysis and code execution.\n\n**Basic Usage:**\n```\ngit_clone(repo_url=\"https://github.com/username/repository.git\")\n```\n\n**Advanced Usage:**\n```\n# Clone a specific branch\ngit_clone(\n    repo_url=\"https://github.com/username/repository.git\",\n    branch=\"develop\"\n)\n\n# Clone to a specific directory with full history\ngit_clone(\n    repo_url=\"https://github.com/username/repository.git\",\n    target_path=\"my_project\",\n    depth=0  # 0 means full history\n)\n\n# Clone with Git LFS support for repositories with large files\ngit_clone(\n    repo_url=\"https://github.com/username/large-files-repo.git\",\n    lfs=True\n)\n```\n\n### Web Preview\n\nGenerates a preview URL for web servers running inside the Daytona workspace.\n\n**Basic Usage:**\n```\n# Generate a preview link for a web server running on port 3000\nweb_preview(port=3000)\n```\n\n**Advanced Usage:**\n```\n# Generate a preview link with a descriptive name\nweb_preview(\n    port=8080,\n    description=\"React Development Server\"\n)\n\n# Generate a link without checking if server is running\nweb_preview(\n    port=5000,\n    check_server=False\n)\n```\n\n**Example:**\n```bash\n# First run a simple web server using Python via the shell\nshell_exec(command=\"python -m http.server 8000 &\")\n\n# Then generate a preview link for the server\nweb_preview(port=8000, description=\"Python HTTP Server\")\n```\n\n<a href=\"https://glama.ai/mcp/servers/hj7jlxkxpk\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/hj7jlxkxpk/badge\" alt=\"Daytona Python Interpreter MCP server\" /></a>\n[![smithery badge](https://smithery.ai/badge/@nkkko/daytona-mcp)](https://smithery.ai/server/@nkkko/daytona-mcp)",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "interpreter",
        "executes",
        "commands",
        "llms execute",
        "interpreter executes",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "openSVM--zig-mcp-server": {
      "owner": "openSVM",
      "name": "zig-mcp-server",
      "url": "https://github.com/openSVM/zig-mcp-server",
      "imageUrl": "https://github.com/openSVM.png",
      "description": "Provides Zig language tooling, enabling code analysis, optimization, and documentation access specific to Zig. Supports features like code optimization at various levels and estimation of computational resource usage for Zig programs.",
      "stars": 30,
      "forks": 6,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-29T22:26:57Z",
      "readme_content": "# Zig MCP Server\n[![smithery badge](https://smithery.ai/badge/zig-mcp-server)](https://smithery.ai/server/zig-mcp-server)\n\n**Modern Zig AI 10x dev assistant with comprehensive build system support**\n\nA powerful Model Context Protocol (MCP) server that provides comprehensive Zig language assistance, including modern build system support, code optimization, and best practices guidance.\n\n<a href=\"https://glama.ai/mcp/servers/oxiw2bsb15\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/oxiw2bsb15/badge\" alt=\"Zig Server MCP server\" /></a>\n\n## 🚀 What's New in v0.2.0\n\n- **🏗️ Modern Build System Support**: Generate and analyze build.zig files with Zig 0.12+ patterns\n- **📦 Dependency Management**: Create build.zig.zon files for modern package management  \n- **🔧 Enhanced Code Analysis**: Improved optimization suggestions and pattern detection\n- **🧪 Comprehensive Testing**: 85+ test cases with full coverage reporting\n- **⚡ Better Performance**: Modular architecture with improved error handling\n- **📚 Extended Documentation**: Build system troubleshooting and best practices guides\n\n## 🛠️ Features\n\n### 🏗️ Build System Tools (NEW!)\n\n#### 1. Build System Generation (`generate_build_zig`)\nGenerate modern build.zig files with Zig 0.12+ patterns:\n- Cross-compilation support\n- Modern dependency management\n- Test and documentation integration\n\n#### 2. Build System Analysis (`analyze_build_zig`) \nAnalyze existing build files and get modernization recommendations:\n- Detect deprecated patterns\n- Suggest Zig 0.12+ alternatives\n- Identify missing best practices\n\n#### 3. Dependency Management (`generate_build_zon`)\nGenerate build.zig.zon files for modern package management:\n- Popular Zig packages catalog\n- Version management guidance\n- Best practices documentation\n\n## Features\n\n### Tools\n\n#### 1. Code Optimization (`optimize_code`)\nEnhanced with modern Zig patterns and build mode analysis:\n- Debug, ReleaseSafe, ReleaseFast, ReleaseSmall\n- Modern optimization suggestions  \n- Zig 0.12+ pattern recommendations\n\n```typescript\n// Example usage\n{\n  \"code\": \"const std = @import(\\\"std\\\");\\n...\",\n  \"optimizationLevel\": \"ReleaseFast\"\n}\n```\n\n#### 2. Compute Units Estimation (`estimate_compute_units`)\nEstimates computational complexity and resource usage of Zig code:\n- Memory usage analysis\n- Time complexity estimation\n- Allocation patterns detection\n\n```typescript\n// Example usage\n{\n  \"code\": \"const std = @import(\\\"std\\\");\\n...\"\n}\n```\n\n#### 3. Code Generation (`generate_code`)\nGenerates Zig code from natural language descriptions with support for:\n- Error handling\n- Testing\n- Performance optimizations\n- Documentation\n\n```typescript\n// Example usage\n{\n  \"prompt\": \"Create a function that sorts an array of integers\",\n  \"context\": \"Should handle empty arrays and use comptime when possible\"\n}\n```\n\n#### 4. Code Recommendations (`get_recommendations`)\nProvides code improvement recommendations and best practices:\n- Style and conventions\n- Design patterns\n- Safety considerations\n- Performance insights\n\n```typescript\n// Example usage\n{\n  \"code\": \"const std = @import(\\\"std\\\");\\n...\",\n  \"prompt\": \"Improve performance and safety\"\n}\n```\n\n### Resources\n\n1. **Language Reference** (`zig://docs/language-reference`)\n   - Official Zig language documentation\n   - Syntax and features guide\n   - Best practices\n\n2. **Standard Library Documentation** (`zig://docs/std-lib`)\n   - Complete std library reference\n   - Function signatures and usage\n   - Examples and notes\n\n3. **Popular Repositories** (`zig://repos/popular`)\n   - Top Zig projects on GitHub\n   - Community examples and patterns\n   - Real-world implementations\n\n## Installation\n\n### Installing via Smithery\n\nTo install Zig MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/zig-mcp-server):\n\n```bash\nnpx -y @smithery/cli install zig-mcp-server --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n```bash\ngit clone [repository-url]\ncd zig-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Build the server:\n```bash\nnpm run build\n```\n\n4. Configure environment variables:\n```bash\n# Create a GitHub token for better API rate limits\n# https://github.com/settings/tokens\n# Required scope: public_repo\nGITHUB_TOKEN=your_token_here\n```\n\n5. Add to MCP settings:\n```json\n{\n  \"mcpServers\": {\n    \"zig\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/zig-mcp-server/build/index.js\"],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"your_token_here\",\n        \"NODE_OPTIONS\": \"--experimental-vm-modules\"\n      },\n      \"restart\": true\n    }\n  }\n}\n```\n\n## Usage Examples\n\n### 1. Optimize Code\n\n```typescript\nconst result = await useMcpTool(\"zig\", \"optimize_code\", {\n  code: `\n    pub fn fibonacci(n: u64) u64 {\n        if (n <= 1) return n;\n        return fibonacci(n - 1) + fibonacci(n - 2);\n    }\n  `,\n  optimizationLevel: \"ReleaseFast\"\n});\n```\n\n### 2. Estimate Compute Units\n\n```typescript\nconst result = await useMcpTool(\"zig\", \"estimate_compute_units\", {\n  code: `\n    pub fn bubbleSort(arr: []i32) void {\n        var i: usize = 0;\n        while (i < arr.len) : (i += 1) {\n            var j: usize = 0;\n            while (j < arr.len - 1) : (j += 1) {\n                if (arr[j] > arr[j + 1]) {\n                    const temp = arr[j];\n                    arr[j] = arr[j + 1];\n                    arr[j + 1] = temp;\n                }\n            }\n        }\n    }\n  `\n});\n```\n\n### 3. Generate Code\n\n```typescript\nconst result = await useMcpTool(\"zig\", \"generate_code\", {\n  prompt: \"Create a thread-safe counter struct\",\n  context: \"Should use atomic operations and handle overflow\"\n});\n```\n\n### 4. Get Recommendations\n\n```typescript\nconst result = await useMcpTool(\"zig\", \"get_recommendations\", {\n  code: `\n    pub fn main() !void {\n        var list = std.ArrayList(u8).init(allocator);\n        var i: u32 = 0;\n        while (true) {\n            if (i >= 100) break;\n            try list.append(@intCast(u8, i));\n            i += 1;\n        }\n    }\n  `,\n  prompt: \"performance\"\n});\n```\n\n## Development\n\n### Project Structure\n\n```\nzig-mcp-server/\n├── src/\n│   └── index.ts    # Main server implementation\n├── build/          # Compiled JavaScript\n├── package.json    # Dependencies and scripts\n└── tsconfig.json   # TypeScript configuration\n```\n\n### Building\n\n```bash\n# Development build with watch mode\nnpm run watch\n\n# Production build\nnpm run build\n```\n\n### Testing\n\n```bash\nnpm test\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "opensvm",
        "zig",
        "llms",
        "opensvm zig",
        "zig programs",
        "llms execute"
      ],
      "category": "code-execution"
    },
    "oraios--serena": {
      "owner": "oraios",
      "name": "serena",
      "url": "https://github.com/oraios/serena",
      "imageUrl": "https://github.com/oraios.png",
      "description": "Integrate a coding agent that enhances development workflows by providing semantic code retrieval and editing tools directly within a codebase. It leverages relational structures and code entities for improved assistance tailored to coding tasks.",
      "stars": 13659,
      "forks": 922,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-10-04T10:12:34Z",
      "readme_content": "<p align=\"center\" style=\"text-align:center\">\n  <img src=\"resources/serena-logo.svg#gh-light-mode-only\" style=\"width:500px\">\n  <img src=\"resources/serena-logo-dark-mode.svg#gh-dark-mode-only\" style=\"width:500px\">\n</p>\n\n* :rocket: Serena is a powerful **coding agent toolkit** capable of turning an LLM into a fully-featured agent that works **directly on your codebase**.\n  Unlike most other tools, it is not tied to an LLM, framework or an interface, making it easy to use it in a variety of ways.\n* :wrench: Serena provides essential **semantic code retrieval and editing tools** that are akin to an IDE's capabilities, extracting code entities at the symbol level and exploiting relational structure. When combined with an existing coding agent, these tools greatly enhance (token) efficiency.\n* :free: Serena is **free & open-source**, enhancing the capabilities of LLMs you already have access to free of charge.\n\nYou can think of Serena as providing IDE-like tools to your LLM/coding agent. With it, the agent no longer needs to read entire\nfiles, perform grep-like searches or string replacements to find and edit the right code. Instead, it can use code centered tools like `find_symbol`, `find_referencing_symbols` and `insert_after_symbol`.\n\n<p align=\"center\">\n  <em>Serena is under active development! See the latest updates, upcoming features, and lessons learned to stay up to date.</em>\n</p>\n\n<p align=\"center\">\n  <a href=\"CHANGELOG.md\">\n    <img src=\"https://img.shields.io/badge/Updates-1e293b?style=flat&logo=rss&logoColor=white&labelColor=1e293b\" alt=\"Changelog\" />\n  </a>\n  <a href=\"roadmap.md\">\n    <img src=\"https://img.shields.io/badge/Roadmap-14532d?style=flat&logo=target&logoColor=white&labelColor=14532d\" alt=\"Roadmap\" />\n  </a>\n  <a href=\"lessons_learned.md\">\n    <img src=\"https://img.shields.io/badge/Lessons-Learned-7c4700?style=flat&logo=readthedocs&logoColor=white&labelColor=7c4700\" alt=\"Lessons Learned\" />\n  </a>\n</p>\n\n### LLM Integration\n\nSerena provides the necessary [tools](#list-of-tools) for coding workflows, but an LLM is required to do the actual work,\norchestrating tool use.\n\nFor example, **supercharge the performance of Claude Code** with a [one-line shell command](#claude-code).\n\nIn general, Serena can be integrated with an LLM in several ways:\n\n* by using the **model context protocol (MCP)**.\n  Serena provides an MCP server which integrates with\n    * Claude Code and Claude Desktop,\n    * Terminal-based clients like Codex, Gemini-CLI, Qwen3-Coder, rovodev, OpenHands CLI and others,\n    * IDEs like VSCode, Cursor or IntelliJ,\n    * Extensions like Cline or Roo Code\n    * Local clients like [OpenWebUI](https://docs.openwebui.com/openapi-servers/mcp), [Jan](https://jan.ai/docs/mcp-examples/browser/browserbase#enable-mcp), [Agno](https://docs.agno.com/introduction/playground) and others\n* by using [mcpo to connect it to ChatGPT](docs/serena_on_chatgpt.md) or other clients that don't support MCP but do support tool calling via OpenAPI.\n* by incorporating Serena's tools into an agent framework of your choice, as illustrated [here](docs/custom_agent.md).\n  Serena's tool implementation is decoupled from the framework-specific code and can thus easily be adapted to any agent framework.\n\n### Serena in Action\n\n#### Demonstration 1: Efficient Operation in Claude Code\n\nA demonstration of Serena efficiently retrieving and editing code within Claude Code, thereby saving tokens and time. Efficient operations are not only useful for saving costs, but also for generally improving the generated code's quality. This effect may be less pronounced in very small projects, but often becomes of crucial importance in larger ones.\n\nhttps://github.com/user-attachments/assets/ab78ebe0-f77d-43cc-879a-cc399efefd87\n\n#### Demonstration 2: Serena in Claude Desktop\n\nA demonstration of Serena implementing a small feature for itself (a better log GUI) with Claude Desktop.\nNote how Serena's tools enable Claude to find and edit the right symbols.\n\nhttps://github.com/user-attachments/assets/6eaa9aa1-610d-4723-a2d6-bf1e487ba753\n\n### Programming Language Support & Semantic Analysis Capabilities\n\nSerena's semantic code analysis capabilities build on **language servers** using the widely implemented\nlanguage server protocol (LSP). The LSP provides a set of versatile code querying\nand editing functionalities based on symbolic understanding of the code.\nEquipped with these capabilities, Serena discovers and edits code just like a seasoned developer\nmaking use of an IDE's capabilities would.\nSerena can efficiently find the right context and do the right thing even in very large and\ncomplex projects! So not only is it free and open-source, it frequently achieves better results\nthan existing solutions that charge a premium.\n\nLanguage servers provide support for a wide range of programming languages.\nWith Serena, we provide direct, out-of-the-box support for:\n\n  * Python\n  * TypeScript/Javascript\n  * PHP (uses Intelephense LSP; set `INTELEPHENSE_LICENSE_KEY` environment variable for premium features)\n  * Go (requires installation of gopls)\n  * R (requires installation of the `languageserver` R package)\n  * Rust (requires [rustup](https://rustup.rs/) - uses rust-analyzer from your toolchain)\n  * C/C++ (you may experience issues with finding references, we are working on it)\n  * Zig (requires installation of ZLS - Zig Language Server)\n  * C#\n  * Ruby (by default, uses [ruby-lsp](https://github.com/Shopify/ruby-lsp), specify ruby_solargraph as your language to use the previous solargraph based implementation)\n  * Swift\n  * Kotlin (uses the pre-alpha [official kotlin LS](https://github.com/Kotlin/kotlin-lsp), some issues may appear)\n  * Java (_Note_: startup is slow, initial startup especially so. There may be issues with java on macos and linux, we are working on it.)\n  * Clojure\n  * Dart\n  * Bash\n  * Lua (automatically downloads lua-language-server if not installed)\n  * Nix (requires nixd installation)\n  * Elixir (requires installation of NextLS and Elixir; **Windows not supported**)\n  * Erlang (requires installation of beam and [erlang_ls](https://github.com/erlang-ls/erlang_ls), experimental, might be slow or hang)\n  * AL\n\nSupport for further languages can easily be added by providing a shallow adapter for a new language server implementation,\nsee Serena's [memory on that](.serena/memories/adding_new_language_support_guide.md).\n\n### Community Feedback\n\nMost users report that Serena has strong positive effects on the results of their coding agents, even when used within\nvery capable agents like Claude Code. Serena is often described to be a [game changer](https://www.reddit.com/r/ClaudeAI/comments/1lfsdll/try_out_serena_mcp_thank_me_later/), providing an enormous [productivity boost](https://www.reddit.com/r/ClaudeCode/comments/1mguoia/absolutely_insane_improvement_of_claude_code).\n\nSerena excels at navigating and manipulating complex codebases, providing tools that support precise code retrieval and editing in the presence of large, strongly structured codebases.\nHowever, when dealing with tasks that involve only very few/small files, you may not benefit from including Serena on top of your existing coding agent. \nIn particular, when writing code from scratch, Serena will not provide much value initially, as the more complex structures that Serena handles more gracefully than simplistic, file-based approaches are yet to be created.\n\nSeveral videos and blog posts have talked about Serena:\n\n* YouTube:\n    * [AI Labs](https://www.youtube.com/watch?v=wYWyJNs1HVk&t=1s)\n    * [Yo Van Eyck](https://www.youtube.com/watch?v=UqfxuQKuMo8&t=45s)\n    * [JeredBlu](https://www.youtube.com/watch?v=fzPnM3ySmjE&t=32s)\n\n* Blog posts:\n    * [Serena's Design Principles](https://medium.com/@souradip1000/deconstructing-serenas-mcp-powered-semantic-code-understanding-architecture-75802515d116)\n    * [Serena with Claude Code (in Japanese)](https://blog.lai.so/serena/)\n    * [Turning Claude Code into a Development Powerhouse](https://robertmarshall.dev/blog/turning-claude-code-into-a-development-powerhouse/)\n\n## Table of Contents\n\n<!-- Created with markdown-toc -i README.md -->\n<!-- Install it with npm install -g markdown-toc -->\n\n<!-- toc -->\n\n- [Quick Start](#quick-start)\n  * [Running the Serena MCP Server](#running-the-serena-mcp-server)\n    + [Usage](#usage)\n    + [Using uvx](#using-uvx)\n    + [Local Installation](#local-installation)\n    + [Using Docker (Experimental)](#using-docker-experimental)\n    + [Using Nix](#using-nix)\n    + [Streamable HTTP Mode](#streamable-http-mode)\n    + [Command-Line Arguments](#command-line-arguments)\n  * [Configuration](#configuration)\n  * [Project Activation & Indexing](#project-activation--indexing)\n  * [Claude Code](#claude-code)\n  * [Codex](#codex)\n  * [Other Terminal-Based Clients](#other-terminal-based-clients)\n  * [Claude Desktop](#claude-desktop)\n  * [MCP Coding Clients (Cline, Roo-Code, Cursor, Windsurf, etc.)](#mcp-coding-clients-cline-roo-code-cursor-windsurf-etc)\n  * [Local GUIs and Frameworks](#local-guis-and-frameworks)\n- [Detailed Usage and Recommendations](#detailed-usage-and-recommendations)\n  * [Tool Execution](#tool-execution)\n    + [Shell Execution and Editing Tools](#shell-execution-and-editing-tools)\n  * [Modes and Contexts](#modes-and-contexts)\n    + [Contexts](#contexts)\n    + [Modes](#modes)\n    + [Customization](#customization)\n  * [Onboarding and Memories](#onboarding-and-memories)\n  * [Prepare Your Project](#prepare-your-project)\n    + [Structure Your Codebase](#structure-your-codebase)\n    + [Start from a Clean State](#start-from-a-clean-state)\n    + [Logging, Linting, and Automated Tests](#logging-linting-and-automated-tests)\n  * [Prompting Strategies](#prompting-strategies)\n  * [Running Out of Context](#running-out-of-context)\n  * [Serena's Logs: The Dashboard and GUI Tool](#serenas-logs-the-dashboard-and-gui-tool)\n- [Comparison with Other Coding Agents](#comparison-with-other-coding-agents)\n  * [Subscription-Based Coding Agents](#subscription-based-coding-agents)\n  * [API-Based Coding Agents](#api-based-coding-agents)\n  * [Other MCP-Based Coding Agents](#other-mcp-based-coding-agents)\n- [Acknowledgements](#acknowledgements)\n  * [Sponsors](#sponsors)\n  * [Community Contributions](#community-contributions)\n  * [Technologies](#technologies)\n- [Customizing and Extending Serena](#customizing-and-extending-serena)\n- [List of Tools](#list-of-tools)\n\n<!-- tocstop -->\n\n## Quick Start\n\nSerena can be used in various ways, below you will find instructions for selected integrations.\n\n* For coding with Claude, we recommend using Serena through [Claude Code](#claude-code) or [Claude Desktop](#claude-desktop). You can also use Serena in most other [terminal-based clients](#other-terminal-based-clients).\n* If you want a GUI experience outside an IDE, you can use one of the many [local GUIs](#local-guis-and-frameworks) that support MCP servers.\n  You can also connect Serena to many web clients (including ChatGPT) using [mcpo](docs/serena_on_chatgpt.md).\n* If you want to use Serena integrated in your IDE, see the section on [other MCP clients](#other-mcp-clients---cline-roo-code-cursor-windsurf-etc).\n* You can use Serena as a library for building your own applications. We try to keep the public API stable, but you should still\n  expect breaking changes and pin Serena to a fixed version if you use it as a dependency.\n\nSerena is managed by `uv`, so you will need to [install it](https://docs.astral.sh/uv/getting-started/installation/).\n\n### Running the Serena MCP Server\n\nYou have several options for running the MCP server, which are explained in the subsections below.\n\n#### Usage\n\nThe typical usage involves the client (Claude Code, Claude Desktop, etc.) running\nthe MCP server as a subprocess (using stdio communication),\nso the client needs to be provided with the command to run the MCP server.\n(Alternatively, you can run the MCP server in Streamable HTTP or SSE mode and tell your client\nhow to connect to it.)\n\nNote that no matter how you run the MCP server, Serena will, by default, start a small web-based dashboard on localhost that will display logs and allow shutting down the\nMCP server (since many clients fail to clean up processes correctly).\nThis and other settings can be adjusted in the [configuration](#configuration) and/or by providing [command-line arguments](#command-line-arguments).\n\n#### Using uvx\n\n`uvx` can be used to run the latest version of Serena directly from the repository, without an explicit local installation.\n\n```shell\nuvx --from git+https://github.com/oraios/serena serena start-mcp-server\n```\n\nExplore the CLI to see some of the customization options that serena provides (more info on them below).\n\n#### Local Installation\n\n1. Clone the repository and change into it.\n\n   ```shell\n   git clone https://github.com/oraios/serena\n   cd serena\n   ```\n\n2. Optionally edit the configuration file in your home directory with\n\n   ```shell\n   uv run serena config edit\n   ```\n\n   If you just want the default config, you can skip this part, and a config file will be created when you first run Serena.\n3. Run the server with `uv`:\n\n   ```shell\n   uv run serena start-mcp-server\n   ```\n\n   When running from outside the serena installation directory, be sure to pass it, i.e., use\n\n   ```shell\n    uv run --directory /abs/path/to/serena serena start-mcp-server\n   ```\n\n#### Using Docker (Experimental)\n\n⚠️ Docker support is currently experimental with several limitations. Please read the [Docker documentation](DOCKER.md) for important caveats before using it.\n\nYou can run the Serena MCP server directly via docker as follows,\nassuming that the projects you want to work on are all located in `/path/to/your/projects`:\n\n```shell\ndocker run --rm -i --network host -v /path/to/your/projects:/workspaces/projects ghcr.io/oraios/serena:latest serena start-mcp-server --transport stdio\n```\n\nReplace `/path/to/your/projects` with the absolute path to your projects directory. The Docker approach provides:\n\n* Better security isolation for shell command execution\n* No need to install language servers and dependencies locally\n* Consistent environment across different systems\n\nAlternatively, use docker compose with the `compose.yml` file provided in the repository.\n\nSee the [Docker documentation](DOCKER.md) for detailed setup instructions, configuration options, and known limitations.\n\n#### Using Nix\n\nIf you are using Nix and [have enabled the `nix-command` and `flakes` features](https://nixos.wiki/wiki/flakes), you can run Serena using the following command:\n\n```bash\nnix run github:oraios/serena -- start-mcp-server --transport stdio\n```\n\nYou can also install Serena by referencing this repo (`github:oraios/serena`) and using it in your Nix flake. The package is exported as `serena`.\n\n#### Streamable HTTP Mode\n\nℹ️ Note that MCP servers which use stdio as a protocol are somewhat unusual as far as client/server architectures go, as the server\nnecessarily has to be started by the client in order for communication to take place via the server's standard input/output stream.\nIn other words, you do not need to start the server yourself. The client application (e.g. Claude Desktop) takes care of this and\ntherefore needs to be configured with a launch command.\n\nWhen using instead the *Streamable HTTP* mode, you control the server lifecycle yourself,\ni.e. you start the server and provide the client with the URL to connect to it.\n\nSimply provide `start-mcp-server` with the `--transport streamable-http` option and optionally provide the port.\nFor example, to run the Serena MCP server in Streamable HTTP mode on port 9121 using a local installation,\nyou would run this command from the Serena directory,\n\n```shell\nuv run serena start-mcp-server --transport streamable-http --port 9121\n```\n\nand then configure your client to connect to `http://localhost:9121/mcp`.\n\nℹ️ Note that SSE transport is supported as well, but its use is discouraged. \nUse Streamable HTTP instead.\n\n#### Command-Line Arguments\n\nThe Serena MCP server supports a wide range of additional command-line options, including the option to run in Streamable HTTP or SSE mode\nand to adapt Serena to various [contexts and modes of operation](#modes-and-contexts).\n\nRun with parameter `--help` to get a list of available options.\n\n### Configuration\n\nSerena is very flexible in terms of configuration. While for most users, the default configurations will work,\nyou can fully adjust it to your needs by editing a few yaml files. You can disable tools, change Serena's instructions\n(what we denote as the `system_prompt`), adjust the output of tools that just provide a prompt, and even adjust tool descriptions.\n\nSerena is configured in four places:\n\n1. The `serena_config.yml` for general settings that apply to all clients and projects.\n   It is located in your user directory under `.serena/serena_config.yml`.\n   If you do not explicitly create the file, it will be auto-generated when you first run Serena.\n   You can edit it directly or use\n\n   ```shell\n   uvx --from git+https://github.com/oraios/serena serena config edit\n   ```\n\n   (or use the `--directory` command version).\n2. In the arguments passed to the `start-mcp-server` in your client's config (see below),\n   which will apply to all sessions started by the respective client. In particular, the [context](#contexts) parameter\n   should be set appropriately for Serena to be best adjusted to existing tools and capabilities of your client.\n   See for a detailed explanation. You can override all entries from the `serena_config.yml` through command line arguments.\n3. In the `.serena/project.yml` file within your project. This will hold project-level configuration that is used whenever\n   that project is activated. This file will be autogenerated when you first use Serena on that project, but you can also\n   generate it explicitly with\n\n   ```shell\n   uvx --from git+https://github.com/oraios/serena serena project generate-yml\n   ```\n\n   (or use the `--directory` command version).\n4. Through the context and modes. Explore the [modes and contexts](#modes-and-contexts) section for more details.\n\nAfter the initial setup, continue with one of the sections below, depending on how you\nwant to use Serena.\n\n### Project Activation & Indexing\n\nIf you are mostly working with the same project, you can configure to always activate it at startup\nby passing `--project <path_or_name>` to the `start-mcp-server` command in your client's MCP config.\nThis is especially useful for clients which configure MCP servers on a per-project basis, like Claude Code.\n\nOtherwise, the recommended way is to just ask the LLM to activate a project by providing it an absolute path to, or,\nin case the project was activated in the past, by its name. The default project name is the directory name.\n\n* \"Activate the project /path/to/my_project\"\n* \"Activate the project my_project\"\n\nAll projects that have been activated will be automatically added to your `serena_config.yml`, and for each\nproject, the file `.serena/project.yml` will be generated. You can adjust the latter, e.g., by changing the name\n(which you refer to during the activation) or other options. Make sure to not have two different projects with the\nsame name.\n\nℹ️ For larger projects, we recommend that you index your project to accelerate Serena's tools; otherwise the first\ntool application may be very slow.\nTo do so, run this from the project directory (or pass the path to the project as an argument):\n\n```shell\nuvx --from git+https://github.com/oraios/serena serena project index\n```\n\n(or use the `--directory` command version).\n\n### Claude Code\n\nSerena is a great way to make Claude Code both cheaper and more powerful!\n\nFrom your project directory, add serena with a command like this,\n\n```shell\nclaude mcp add serena -- <serena-mcp-server> --context ide-assistant --project $(pwd)\n```\n\nwhere `<serena-mcp-server>` is your way of [running the Serena MCP server](#running-the-serena-mcp-server).\nFor example, when using `uvx`, you would run\n\n```shell\nclaude mcp add serena -- uvx --from git+https://github.com/oraios/serena serena start-mcp-server --context ide-assistant --project $(pwd)\n```\n\nℹ️ Serena comes with an instruction text, and Claude needs to read it to properly use Serena's tools.\n  As of version `v1.0.52`, claude code reads the instructions of the MCP server, so this **is handled automatically**.\n  If you are using an older version, or if Claude fails to read the instructions, you can ask it explicitly\n  to \"read Serena's initial instructions\" or run `/mcp__serena__initial_instructions` to load the instruction text.\n  If you want to make use of that, you will have to enable the corresponding tool explicitly by adding `initial_instructions` to the `included_optional_tools`\n  in your config.\n  Note that you may have to make Claude read the instructions when you start a new conversation and after any compacting operation to ensure Claude remains properly configured to use Serena's tools.\n\n### Codex\n\nSerena works with OpenAI's Codex CLI out of the box, but you have to use the `codex` context for it to work properly. (The technical reason is that Codex doesn't fully support the MCP specifications, so some massaging of tools is required.).\n\nUnlike Claude Code, in Codex you add an MCP server globally and not per project. Add the following to\n`~/.codex/config.toml` (create the file if it does not exist):\n\n```toml\n[mcp_servers.serena]\ncommand = \"uvx\"\nargs = [\"--from\", \"git+https://github.com/oraios/serena\", \"serena\", \"start-mcp-server\", \"--context\", \"codex\"]\n```\n\nAfter codex has started, you need to activate the project, which you can do by saying:\n\n\"Activate the current dir as project using serena\"\n\n> If you don't activate the project, you will not be able to use Serena's tools!\n\nThat's it! Have a look at `~/.codex/log/codex-tui.log` to see if any errors occurred.\n\nThe Serena dashboard will run if you have not disabled it in the configuration, but due to Codex's sandboxing the webbrowser\nmay not open automatically. You can open it manually by going to `http://localhost:24282/dashboard/index.html` (or a higher port, if\nthat was already taken).\n\n> Codex will often show the tools as `failed` even though they are successfully executed. This is not a problem, seems to be a bug in Codex. Despite the error message, everything works as expected.\n\n### Other Terminal-Based Clients\n\nThere are many terminal-based coding assistants that support MCP servers, such as [Codex](https://github.com/openai/codex?tab=readme-ov-file#model-context-protocol-mcp),\n[Gemini-CLI](https://github.com/google-gemini/gemini-cli), [Qwen3-Coder](https://github.com/QwenLM/Qwen3-Coder),\n[rovodev](https://community.atlassian.com/forums/Rovo-for-Software-Teams-Beta/Introducing-Rovo-Dev-CLI-AI-Powered-Development-in-your-terminal/ba-p/3043623),\nthe [OpenHands CLI](https://docs.all-hands.dev/usage/how-to/cli-mode) and [opencode](https://github.com/sst/opencode).\n\nThey generally benefit from the symbolic tools provided by Serena. You might want to customize some aspects of Serena\nby writing your own context, modes or prompts to adjust it to your workflow, to other MCP servers you are using, and to\nthe client's internal capabilities.\n\n### Claude Desktop\n\nFor [Claude Desktop](https://claude.ai/download) (available for Windows and macOS), go to File / Settings / Developer / MCP Servers / Edit Config,\nwhich will let you open the JSON file `claude_desktop_config.json`.\nAdd the `serena` MCP server configuration, using a [run command](#running-the-serena-mcp-server) depending on your setup.\n\n* local installation:\n\n   ```json\n   {\n       \"mcpServers\": {\n           \"serena\": {\n               \"command\": \"/abs/path/to/uv\",\n               \"args\": [\"run\", \"--directory\", \"/abs/path/to/serena\", \"serena\", \"start-mcp-server\"]\n           }\n       }\n   }\n   ```\n\n* uvx:\n\n   ```json\n   {\n       \"mcpServers\": {\n           \"serena\": {\n               \"command\": \"/abs/path/to/uvx\",\n               \"args\": [\"--from\", \"git+https://github.com/oraios/serena\", \"serena\", \"start-mcp-server\"]\n           }\n       }\n  }\n  ```\n\n* docker:\n\n  ```json\n   {\n       \"mcpServers\": {\n           \"serena\": {\n               \"command\": \"docker\",\n               \"args\": [\"run\", \"--rm\", \"-i\", \"--network\", \"host\", \"-v\", \"/path/to/your/projects:/workspaces/projects\", \"ghcr.io/oraios/serena:latest\", \"serena\", \"start-mcp-server\", \"--transport\", \"stdio\"]\n           }\n       }\n   }\n   ```\n\nIf you are using paths containing backslashes for paths on Windows\n(note that you can also just use forward slashes), be sure to escape them correctly (`\\\\`).\n\nThat's it! Save the config and then restart Claude Desktop. You are ready for activating your first project.\n\nℹ️ You can further customize the run command using additional arguments (see [above](#command-line-arguments)).\n\nNote: on Windows and macOS there are official Claude Desktop applications by Anthropic, for Linux there is an [open-source\ncommunity version](https://github.com/aaddrick/claude-desktop-debian).\n\n⚠️ Be sure to fully quit the Claude Desktop application, as closing Claude will just minimize it to the system tray – at least on Windows.\n\n⚠️ Some clients may leave behind zombie processes. You will have to find and terminate them manually then.\n    With Serena, you can activate the [dashboard](#serenas-logs-the-dashboard-and-gui-tool) to prevent unnoted processes and also use the dashboard\n    for shutting down Serena.\n\nAfter restarting, you should see Serena's tools in your chat interface (notice the small hammer icon).\n\nFor more information on MCP servers with Claude Desktop, see [the official quick start guide](https://modelcontextprotocol.io/quickstart/user).\n\n### MCP Coding Clients (Cline, Roo-Code, Cursor, Windsurf, etc.)\n\nBeing an MCP Server, Serena can be included in any MCP Client. The same configuration as above,\nperhaps with small client-specific modifications, should work. Most of the popular\nexisting coding assistants (IDE extensions or VSCode-like IDEs) support connections\nto MCP Servers. It is **recommended to use the `ide-assistant` context** for these integrations by adding `\"--context\", \"ide-assistant\"` to the `args` in your MCP client's configuration. Including Serena generally boosts their performance\nby providing them tools for symbolic operations.\n\nIn this case, the billing for the usage continues to be controlled by the client of your choice\n(unlike with the Claude Desktop client). But you may still want to use Serena through such an approach,\ne.g., for one of the following reasons:\n\n1. You are already using a coding assistant (say Cline or Cursor) and just want to make it more powerful.\n2. You are on Linux and don't want to use the [community-created Claude Desktop](https://github.com/aaddrick/claude-desktop-debian).\n3. You want tighter integration of Serena into your IDE and don't mind paying for that.\n\n### Local GUIs and Frameworks\n\nOver the last months, several technologies have emerged that allow you to run a powerful local GUI\nand connect it to an MCP server. They will work with Serena out of the box.\nSome of the leading open source GUI technologies offering this are\n[Jan](https://jan.ai/docs/mcp), [OpenHands](https://github.com/All-Hands-AI/OpenHands/),\n[OpenWebUI](https://docs.openwebui.com/openapi-servers/mcp) and [Agno](https://docs.agno.com/introduction/playground).\nThey allow combining Serena with almost any LLM (including locally running ones) and offer various other integrations.\n\n## Detailed Usage and Recommendations\n\n### Tool Execution\n\nSerena combines tools for semantic code retrieval with editing capabilities and shell execution.\nSerena's behavior can be further customized through [Modes and Contexts](#modes-and-contexts).\nFind the complete list of tools [below](#full-list-of-tools).\n\nThe use of all tools is generally recommended, as this allows Serena to provide the most value:\nOnly by executing shell commands (in particular, tests) can Serena identify and correct mistakes\nautonomously.\n\n#### Shell Execution and Editing Tools\n\nMany clients have their own shell execution tool, and by default Serena's shell tool will be disabled in them\n(e.g., when using the `ide-assistant` or `codex` context). However, when using Serena through something like\nClaude Desktop or ChatGPT, it is recommended to enable Serena's `execute_shell_command` tool to allow\nagentic behavior.\n\nIt should be noted that the `execute_shell_command` tool allows for arbitrary code execution.\nWhen using Serena as an MCP Server, clients will typically ask the user for permission\nbefore executing a tool, so as long as the user inspects execution parameters beforehand,\nthis should not be a problem.\nHowever, if you have concerns, you can choose to disable certain commands in your project's configuration file.\nIf you only want to use Serena purely for analyzing code and suggesting implementations\nwithout modifying the codebase, you can enable read-only mode by setting `read_only: true` in your project configuration file.\nThis will automatically disable all editing tools and prevent any modifications to your codebase while still\nallowing all analysis and exploration capabilities.\n\nIn general, be sure to back up your work and use a version control system in order to avoid\nlosing any work.\n\n### Modes and Contexts\n\nSerena's behavior and toolset can be adjusted using contexts and modes.\nThese allow for a high degree of customization to best suit your workflow and the environment Serena is operating in.\n\n#### Contexts\n\nA context defines the general environment in which Serena is operating.\nIt influences the initial system prompt and the set of available tools.\nA context is set at startup when launching Serena (e.g., via CLI options for an MCP server or in the agent script) and cannot be changed during an active session.\n\nSerena comes with pre-defined contexts:\n\n* `desktop-app`: Tailored for use with desktop applications like Claude Desktop. This is the default.\n* `agent`: Designed for scenarios where Serena acts as a more autonomous agent, for example, when used with Agno.\n* `ide-assistant`: Optimized for integration into IDEs like VSCode, Cursor, or Cline, focusing on in-editor coding assistance.\nChoose the context that best matches the type of integration you are using.\n\nWhen launching Serena, specify the context using `--context <context-name>`.\nNote that for cases where parameter lists are specified (e.g. Claude Desktop), you must add two parameters to the list.\n\nIf you are using a local server (such as Llama.cpp) which requires you to use OpenAI-compatible tool descriptions, use context `oaicompat-agent` instead of `agent`.\n\n#### Modes\n\nModes further refine Serena's behavior for specific types of tasks or interaction styles. Multiple modes can be active simultaneously, allowing you to combine their effects. Modes influence the system prompt and can also alter the set of available tools by excluding certain ones.\n\nExamples of built-in modes include:\n\n* `planning`: Focuses Serena on planning and analysis tasks.\n* `editing`: Optimizes Serena for direct code modification tasks.\n* `interactive`: Suitable for a conversational, back-and-forth interaction style.\n* `one-shot`: Configures Serena for tasks that should be completed in a single response, often used with `planning` for generating reports or initial plans.\n* `no-onboarding`: Skips the initial onboarding process if it's not needed for a particular session.\n* `onboarding`: (Usually triggered automatically) Focuses on the project onboarding process.\n\nModes can be set at startup (similar to contexts) but can also be _switched dynamically_ during a session. You can instruct the LLM to use the `switch_modes` tool to activate a different set of modes (e.g., \"switch to planning and one-shot modes\").\n\nWhen launching Serena, specify modes using `--mode <mode-name>`; multiple modes can be specified, e.g. `--mode planning --mode no-onboarding`.\n\n:warning: **Mode Compatibility**: While you can combine modes, some may be semantically incompatible (e.g., `interactive` and `one-shot`). Serena currently does not prevent incompatible combinations; it is up to the user to choose sensible mode configurations.\n\n#### Customization\n\nYou can create your own contexts and modes to precisely tailor Serena to your needs in two ways:\n\n* You can use Serena's CLI to manage modes and contexts. Check out\n\n    ```shell\n    uvx --from git+https://github.com/oraios/serena serena mode --help\n    ```\n\n    and\n\n    ```shell\n    uvx --from git+https://github.com/oraios/serena serena context --help\n    ```\n\n    _NOTE_: Custom contexts/modes are simply YAML files in `<home>/.serena`, they are automatically registered and available for use by their name (filename without the `.yml` extension). If you don't want to use Serena's CLI, you can create and manage them in any way you see fit.\n* **Using external YAML files**: When starting Serena, you can also provide an absolute path to a custom `.yml` file for a context or mode.\n\nThis customization allows for deep integration and adaptation of Serena to specific project requirements or personal preferences.\n\n### Onboarding and Memories\n\nBy default, Serena will perform an **onboarding process** when\nit is started for the first time for a project.\nThe goal of the onboarding is for Serena to get familiar with the project\nand to store memories, which it can then draw upon in future interactions.\nIf an LLM should fail to complete the onboarding and does not actually write the\nrespective memories to disk, you may need to ask it to do so explicitly.\n\nThe onboarding will usually read a lot of content from the project, thus filling\nup the context. It can therefore be advisable to switch to another conversation\nonce the onboarding is complete.\nAfter the onboarding, we recommend that you have a quick look at the memories and,\nif necessary, edit them or add additional ones.\n\n**Memories** are files stored in `.serena/memories/` in the project directory,\nwhich the agent can choose to read in subsequent interactions.\nFeel free to read and adjust them as needed; you can also add new ones manually.\nEvery file in the `.serena/memories/` directory is a memory file.\nWhenever Serena starts working on a project, the list of memories is\nprovided, and the agent can decide to read them.\nWe found that memories can significantly improve the user experience with Serena.\n\n### Prepare Your Project\n\n#### Structure Your Codebase\n\nSerena uses the code structure for finding, reading and editing code. This means that it will\nwork well with well-structured code but may perform poorly on fully unstructured one (like a \"God class\"\nwith enormous, non-modular functions).\nFurthermore, for languages that are not statically typed, type annotations are highly beneficial.\n\n#### Start from a Clean State\n\nIt is best to start a code generation task from a clean git state. Not only will\nthis make it easier for you to inspect the changes, but also the model itself will\nhave a chance of seeing what it has changed by calling `git diff` and thereby\ncorrect itself or continue working in a followup conversation if needed.\n\n:warning: **Important**: since Serena will write to files using the system-native line endings\nand it might want to look at the git diff, it is important to\nset `git config core.autocrlf` to `true` on Windows.\nWith `git config core.autocrlf` set to `false` on Windows, you may end up with huge diffs\nonly due to line endings. It is generally a good idea to globally enable this git setting on Windows:\n\n```shell\ngit config --global core.autocrlf true\n```\n\n#### Logging, Linting, and Automated Tests\n\nSerena can successfully complete tasks in an _agent loop_, where it iteratively\nacquires information, performs actions, and reflects on the results.\nHowever, Serena cannot use a debugger; it must rely on the results of program executions,\nlinting results, and test results to assess the correctness of its actions.\nTherefore, software that is designed to meaningful interpretable outputs (e.g. log messages)\nand that has a good test coverage is much easier to work with for Serena.\n\nWe generally recommend to start an editing task from a state where all linting checks and tests pass.\n\n### Prompting Strategies\n\nWe found that it is often a good idea to spend some time conceptualizing and planning a task\nbefore actually implementing it, especially for non-trivial task. This helps both in achieving\nbetter results and in increasing the feeling of control and staying in the loop. You can\nmake a detailed plan in one session, where Serena may read a lot of your code to build up the context,\nand then continue with the implementation in another (potentially after creating suitable memories).\n\n### Running Out of Context\n\nFor long and complicated tasks, or tasks where Serena has read a lot of content, you\nmay come close to the limits of context tokens. In that case, it is often a good idea to continue\nin a new conversation. Serena has a dedicated tool to create a summary of the current state\nof the progress and all relevant info for continuing it. You can request to create this summary and\nwrite it to a memory. Then, in a new conversation, you can just ask Serena to read the memory and\ncontinue with the task. In our experience, this worked really well. On the up-side, since in a\nsingle session there is no summarization involved, Serena does not usually get lost (unlike some\nother agents that summarize under the hood), and it is also instructed to occasionally check whether\nit's on the right track.\n\nMoreover, Serena is instructed to be frugal with context\n(e.g., to not read bodies of code symbols unnecessarily),\nbut we found that Claude is not always very good in being frugal (Gemini seemed better at it).\nYou can explicitly instruct it to not read the bodies if you know that it's not needed.\n\n### Serena's Logs: The Dashboard and GUI Tool\n\nSerena provides two convenient ways of accessing the logs of the current session:\n\n* via the **web-based dashboard** (enabled by default)\n\n    This is supported on all platforms.\n    By default, it will be accessible at `http://localhost:24282/dashboard/index.html`,\n    but a higher port may be used if the default port is unavailable/multiple instances are running.\n\n* via the **GUI tool** (disabled by default)\n\n    This is mainly supported on Windows, but it may also work on Linux; macOS is unsupported.\n\nBoth can be enabled, configured or disabled in Serena's configuration file (`serena_config.yml`, see above).\nIf enabled, they will automatically be opened as soon as the Serena agent/MCP server is started.\nThe web dashboard will display usage statistics of Serena's tools if you set  `record_tool_usage_stats: True` in your config.\n\nIn addition to viewing logs, both tools allow to shut down the Serena agent.\nThis function is provided, because clients like Claude Desktop may fail to terminate the MCP server subprocess\nwhen they themselves are closed.\n\n## Comparison with Other Coding Agents\n\nTo our knowledge, Serena is the first fully-featured coding agent where the\nentire functionality\nis available through an MCP server, thus not requiring API keys or\nsubscriptions.\n\n### Subscription-Based Coding Agents\n\nMany prominent subscription-based coding agents are parts of IDEs like\nWindsurf, Cursor and VSCode.\nSerena's functionality is similar to Cursor's Agent, Windsurf's Cascade or\nVSCode's agent mode.\n\nSerena has the advantage of not requiring a subscription.\nA potential disadvantage is that it\nis not directly integrated into an IDE, so the inspection of newly written code\nis not as seamless.\n\nMore technical differences are:\n\n* Serena is not bound to a specific IDE or CLI.\n  Serena's MCP server can be used with any MCP client (including some IDEs),\n  and the Agno-based agent provides additional ways of applying its functionality.\n* Serena is not bound to a specific large language model or API.\n* Serena navigates and edits code using a language server, so it has a symbolic\n  understanding of the code.\n  IDE-based tools often use a RAG-based or purely text-based approach, which is often\n  less powerful, especially for large codebases.\n* Serena is open-source and has a small codebase, so it can be easily extended\n  and modified.\n\n### API-Based Coding Agents\n\nAn alternative to subscription-based agents are API-based agents like Claude\nCode, Cline, Aider, Roo Code and others, where the usage costs map directly\nto the API costs of the underlying LLM.\nSome of them (like Cline) can even be included in IDEs as an extension.\nThey are often very powerful and their main downside are the (potentially very\nhigh) API costs.\n\nSerena itself can be used as an API-based agent (see the section on Agno above).\nWe have not yet written a CLI tool or a\ndedicated IDE extension for Serena (and there is probably no need for the latter, as\nSerena can already be used with any IDE that supports MCP servers).\nIf there is demand for a Serena as a CLI tool like Claude Code, we will\nconsider writing one.\n\nThe main difference between Serena and other API-based agents is that Serena can\nalso be used as an MCP server, thus not requiring\nan API key and bypassing the API costs. This is a unique feature of Serena.\n\n### Other MCP-Based Coding Agents\n\nThere are other MCP servers designed for coding, like [DesktopCommander](https://github.com/wonderwhy-er/DesktopCommanderMCP) and\n[codemcp](https://github.com/ezyang/codemcp).\nHowever, to the best of our knowledge, none of them provide semantic code\nretrieval and editing tools; they rely purely on text-based analysis.\nIt is the integration of language servers and the MCP that makes Serena unique\nand so powerful for challenging coding tasks, especially in the context of\nlarger codebases.\n\n## Acknowledgements\n\n### Sponsors\n\nWe are very grateful to our [sponsors](https://github.com/sponsors/oraios) who help us drive Serena's development. The core team\n(the founders of [Oraios AI](https://oraios-ai.de/)) put in a lot of work in order to turn Serena into a useful open source project. \nSo far, there is no business model behind this project, and sponsors are our only source of income from it.\n\nSponsors help us dedicating more time to the project, managing contributions, and working on larger features (like better tooling based on more advanced\nLSP features, VSCode integration, debugging via the DAP, and several others).\nIf you find this project useful to your work, or would like to accelerate the development of Serena, consider becoming a sponsor.\n\nWe are proud to announce that the Visual Studio Code team, together with Microsoft’s Open Source Programs Office and GitHub Open Source\nhave decided to sponsor Serena with a one-time contribution!\n\n<p align=\"center\">\n  <img src=\"resources/vscode_sponsor_logo.png\" alt=\"Visual Studio Code sponsor logo\" width=\"220\">\n</p>\n\n### Community Contributions\n\nA significant part of Serena, especially support for various languages, was contributed by the open source community.\nWe are very grateful for the many contributors who made this possible and who played an important role in making Serena\nwhat it is today.\n\n### Technologies\nWe built Serena on top of multiple existing open-source technologies, the most important ones being:\n\n1. [multilspy](https://github.com/microsoft/multilspy).\n   A library which wraps language server implementations and adapts them for interaction via Python\n   and which provided the basis for our library Solid-LSP (src/solidlsp).\n   Solid-LSP provides pure synchronous LSP calls and extends the original library with the symbolic logic\n   that Serena required.\n2. [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\n3. [Agno](https://github.com/agno-agi/agno) and\n   the associated [agent-ui](https://github.com/agno-agi/agent-ui),\n   which we use to allow Serena to work with any model, beyond the ones\n   supporting the MCP.\n4. All the language servers that we use through Solid-LSP.\n\nWithout these projects, Serena would not have been possible (or would have been significantly more difficult to build).\n\n## Customizing and Extending Serena\n\nIt is straightforward to extend Serena's AI functionality with your own ideas.\nSimply implement a new tool by subclassing\n`serena.agent.Tool` and implement the `apply` method with a signature\nthat matches the tool's requirements.\nOnce implemented, `SerenaAgent` will automatically have access to the new tool.\n\nIt is also relatively straightforward to add [support for a new programming language](/.serena/memories/adding_new_language_support_guide.md).\n\nWe look forward to seeing what the community will come up with!\nFor details on contributing, see [contributing guidelines](/CONTRIBUTING.md).\n\n## List of Tools\n\nHere is the list of Serena's default tools with a short description (output of `uv run serena tools list`):\n\n* `activate_project`: Activates a project by name.\n* `check_onboarding_performed`: Checks whether project onboarding was already performed.\n* `create_text_file`: Creates/overwrites a file in the project directory.\n* `delete_memory`: Deletes a memory from Serena's project-specific memory store.\n* `execute_shell_command`: Executes a shell command.\n* `find_file`: Finds files in the given relative paths\n* `find_referencing_symbols`: Finds symbols that reference the symbol at the given location (optionally filtered by type).\n* `find_symbol`: Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).\n* `get_symbols_overview`: Gets an overview of the top-level symbols defined in a given file.\n* `insert_after_symbol`: Inserts content after the end of the definition of a given symbol.\n* `insert_before_symbol`: Inserts content before the beginning of the definition of a given symbol.\n* `list_dir`: Lists files and directories in the given directory (optionally with recursion).\n* `list_memories`: Lists memories in Serena's project-specific memory store.\n* `onboarding`: Performs onboarding (identifying the project structure and essential tasks, e.g. for testing or building).\n* `prepare_for_new_conversation`: Provides instructions for preparing for a new conversation (in order to continue with the necessary context).\n* `read_file`: Reads a file within the project directory.\n* `read_memory`: Reads the memory with the given name from Serena's project-specific memory store.\n* `replace_regex`: Replaces content in a file by using regular expressions.\n* `replace_symbol_body`: Replaces the full definition of a symbol.\n* `search_for_pattern`: Performs a search for a pattern in the project.\n* `think_about_collected_information`: Thinking tool for pondering the completeness of collected information.\n* `think_about_task_adherence`: Thinking tool for determining whether the agent is still on track with the current task.\n* `think_about_whether_you_are_done`: Thinking tool for determining whether the task is truly completed.\n* `write_memory`: Writes a named memory (for future reference) to Serena's project-specific memory store.\n\nThere are several tools that are disabled by default, and have to be enabled explicitly, e.g., through the context or modes.\nNote that several of our default contexts do enable some of these tools. For example, the `desktop-app` context enables the `execute_shell_command` tool.\n\nThe full list of optional tools is (output of `uv run serena tools list --only-optional`):\n\n* `delete_lines`: Deletes a range of lines within a file.\n* `get_current_config`: Prints the current configuration of the agent, including the active and available projects, tools, contexts, and modes.\n* `initial_instructions`: Gets the initial instructions for the current project.\n    Should only be used in settings where the system prompt cannot be set,\n    e.g. in clients you have no control over, like Claude Desktop.\n* `insert_at_line`: Inserts content at a given line in a file.\n* `jet_brains_find_referencing_symbols`: Finds symbols that reference the given symbol\n* `jet_brains_find_symbol`: Performs a global (or local) search for symbols with/containing a given name/substring (optionally filtered by type).\n* `jet_brains_get_symbols_overview`: Retrieves an overview of the top-level symbols within a specified file\n* `remove_project`: Removes a project from the Serena configuration.\n* `replace_lines`: Replaces a range of lines within a file with new content.\n* `restart_language_server`: Restarts the language server, may be necessary when edits not through Serena happen.\n* `summarize_changes`: Provides instructions for summarizing the changes made to the codebase.\n* `switch_modes`: Activates modes by providing a list of their names\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "codebase",
        "coding",
        "code",
        "coding agents",
        "coding agent",
        "code entities"
      ],
      "category": "code-execution"
    },
    "ouvreboite--openapi-to-mcp": {
      "owner": "ouvreboite",
      "name": "openapi-to-mcp",
      "url": "https://github.com/ouvreboite/openapi-to-mcp",
      "imageUrl": "",
      "description": "Lightweight MCP server to access any API using their OpenAPI specification. Supports OAuth2 and full JSON schema parameters and request body.",
      "stars": 21,
      "forks": 5,
      "license": "MIT License",
      "language": "C#",
      "updated_at": "2025-09-28T10:37:41Z",
      "readme_content": "[![.NET Build](https://github.com/ouvreboite/openapi-to-mcp/actions/workflows/build_and_test.yml/badge.svg)](https://github.com/ouvreboite/openapi-to-mcp/actions/workflows/build_and_test.yml)\n[![NuGet](https://img.shields.io/nuget/dt/openapi-to-mcp?logo=nuget&label=NuGet&)](https://www.nuget.org/packages/openapi-to-mcp)\n\n# openapi-to-mcp\n\nUse your OpenAPI specification to expose your API's endpoints as strongly typed tools.\n\nBasic example for https://petstore3.swagger.io/ 🎉\n\n```json\n{\n  \"mcpServers\": {\n    \"petstore\": {\n      \"command\": \"openapi-to-mcp\",\n        \"args\": [\n          \"https://petstore3.swagger.io/api/v3/openapi.json\"\n        ]\n    }\n  }\n}\n```\n\nMore complex example, using Github's API:\n```\n{\n    \"mcpServers\": {\n        \"github\": {\n            \"command\": \"openapi-to-mcp\",\n            \"args\": [\n                \"https://raw.githubusercontent.com/github/rest-api-description/refs/heads/main/descriptions/api.github.com/api.github.com.yaml\",\n                \"--bearer-token\",\n                \"github_pat_xxxxxx\",\n                \"--tool-naming-strategy\",\n                \"verbandpath\"\n            ]\n        }\n    }\n}\n```\n\nThis example use the bearer token auth (with a Github [Personal Access Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-personal-access-token-classic)) and force the tool naming strategy to \"verb and path\", as Github's operation ids are not valid tool names.\n\n![Github demo](github_demo.gif)\n\n## Install\n\nAs a Nuget tool: [openapi-to-mcp](https://www.nuget.org/packages/openapi-to-mcp)\n```sh\ndotnet tool install --global openapi-to-mcp\n```\nOr download the executables from the [releases](https://github.com/ouvreboite/openapi-to-mcp/releases)\n\n## Usage\n\n\n```bash\nUsage:\n  openapi-to-mcp <open-api> [options]\n\nArguments:\n  <open-api>  You OpenAPI specification (URL or file) [required]\n\nOptions:\n  -t, --tool-naming-strategy <extension|extension_or_operationid_or_verbandpath|operationid|verbandpath>  How the tool name should be computed [default: extension_or_operationid_or_verbandpath]\n  -h, --host-override                                                                                     Host override\n  -b, --bearer-token                                                                                      Bearer token\n  -o2, --oauth-2-grant-type <client_credentials|password|refresh_token>                                   OAuth2 flow to be used\n  -o2_tu, --oauth-2-token-url                                                                             OAuth2 token endpoint URL (override the one defined in your OpenAPI for your chosen OAuth2 flow)\n  -o2_ci, --oauth-2-client-id                                                                             OAuth2 client id (for the client_credentials grant_type)\n  -o2_cs, --oauth-2-client-secret                                                                         OAuth2 client secret (for the client_credentials grant_type)\n  -o2_rt, --oauth-2-refresh-token                                                                         OAuth2 refresh token (for the refresh_token grant_type)\n  -o2_un, --oauth-2-username                                                                              OAuth2 username (for the password grant_type)\n  -o2_pw, --oauth-2-password                                                                              OAuth2 password (for the password grant_type)\n  -i, --instructions                                                                                      MCP instruction to be advertised by the server\n  --verbose                                                                                               Log more info (in sdterr) [default: False]\n  -?, -h, --help                                                                                          Show help and usage information\n  --version                                                                                               Show version information\n```\n\n## OpenAPI support\n\n- Currently, OpenAPI 2.0 and 3.0 are supported. \n  - 3.1 is not (at least not until [microsoft/OpenAPI.NET](https://github.com/microsoft/OpenAPI.NET) supports it)\n- Specifications can be JSON/YAML and local (file) or remote (URL)\n- Only local $refs are supported\n\n### OpenAPI custom extensions\n\nA set of custom extensions is available to customize how your API should be exposed:\n- `info.x-mcp-instructions` (string): Textual instructions exposed by the MCP server during the initialize handshake\n- `operation.x-mcp-tool-name` (string): Custom tool name\n- `operation.x-mcp-tool-description` (string): Custom tool description\n- `operation.x-mcp-tool-enabled` (boolean): Enabled/disabled a specific operation (enabled by default)\n\n## MCP features\n\nOnly STDIO transport is currently supported.\n\n### Tools\nOperations (\"endpoints\") from your OpenAPI specification are translated to MCP [tools](https://modelcontextprotocol.io/docs/concepts/tools)\n- All path/query/JSON body parameters are exposed (using their JSON schema)\n- Response is returned as-is\n- By default, the tool name is computed using first the `operation.x-mcp-tool-name` extension, then the [operation.operationId](https://swagger.io/docs/specification/v3_0/paths-and-operations/#operationid) and then `{httpMethod}_{escaped_path}`\n  - The tool naming strategy can be defined via the `--tool-naming-strategy` option.\n  - ⚠️Tools are discarded if their name don't match `^[a-zA-Z0-9_-]{1,64}$`\n- Tools description are extracted as follows: `operation.x-mcp-tool-description` ?? `operation.description` ?? `path.description`\n\n### Tool call and host\n\nWhen a tool is called, the MCP server will call the underlying endpoint. To determine which host to call a combination of parameters are used:\n- the `--host-override` option\n- your specification first [server](https://swagger.io/docs/specification/v3_0/api-host-and-base-path/)'s URL if it's an absolute URL\n- the host of the remote OpenAPI provided\n- otherwise, an error is thrown\n\nFor example running `openapi-to-mcp https://petstore3.swagger.io/api/v3/openapi.json`:\n- https://petstore3.swagger.io/api/v3/openapi.json defines a server, but its URL is relative (/api/v3)\n- so the host of the specification's own URL is used: https://petstore3.swagger.io and the relative path of the server is appended to it\n\n## Authorization\n\n### Bearer token\n\nA token can be provided as option `--bearer-token`. It'll be provided to all calls as the `Authorization: Bearer {token}` header.\nIt'll also be provided when fetching a remote specification.\n\n### OAuth2\n\nClientCredentials, RefreshToken, Password are supported.\nIf your OpenAPI specification declare [securitySchemes](https://swagger.io/docs/specification/v3_0/authentication/oauth2/) for those flows, the corresponding `tokenUrl` will be used.\n\n## How to publish\n\nCreate a new tag/release 🤷",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "openapi",
        "llms",
        "api",
        "llms execute",
        "execution servers",
        "openapi mcp"
      ],
      "category": "code-execution"
    },
    "pablof7z--tenex-tools": {
      "owner": "pablof7z",
      "name": "tenex-tools",
      "url": "https://github.com/pablof7z/tenex-tools",
      "imageUrl": "https://github.com/pablof7z.png",
      "description": "Facilitates access to a collaborative registry for publishing and discovering coding instructions and reusable code snippets, enhancing AI coding agents' performance while ensuring code quality through community verification.",
      "stars": 5,
      "forks": 3,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-18T09:11:02Z",
      "readme_content": "# tenex-tools\n\nShare, discover, and integrate LLM coding instructions & code snippets to supercharge your AI coding agents.\n\n## 🚀 Overview\n\nAs AI-powered coding assistants become a staple in development workflows, the key to unlocking their full potential is guiding them with precise, battle-tested instructions and code recipes. **tenex-tools** provides a collaborative registry and CLI for publishing, finding, and integrating:\n\n- **Micro-Instructions**: Turn common coding tasks into LLM-friendly step-by-step guides.  \n- **Code Snippets**: Share reusable code patterns that dramatically reduce errors and improve quality.  \n- **Agent Profiles**: Define custom agent personas and workflows to automate complex tasks.  \n\nBy tapping into a community-driven marketplace of LLM assets, you can radically improve the performance, reliability, and consistency of your AI coding agents.\n\n---\n\n## ⭐ Key Benefits\n\n- **Accelerate Agent Accuracy**: Snippets and instructions sharpen an LLM’s focus on your coding conventions and best practices.  \n- **Collaborative Growth**: Publish your own assets, build your reputation, and leverage community contributions.  \n- **Plug & Play**: Seamlessly integrate with any MCP-compatible agent or workflow.  \n- **Search & Discover**: Find the exact snippet or workflow you need with rich filtering by tags, languages, and authors.  \n\n---\n\n## 🔧 Features\n\n- **Publish & Retrieve Instructions**  \n  `tenex-tools instructions find <query>`  \n  `tenex-tools instructions publish <file>`\n- **Search & Fetch Code Snippets**  \n  `tenex-tools find-snippets [--limit <n>] [--languages <list>] [--tags <list>] [--authors <list>]`\n- **Manage Custom Agent Profiles**  \n  `tenex-tools agent find <query>`  \n  `tenex-tools agent get <eventId> --roo [path]`  \n  `tenex-tools agent publish <.roomodes path>`\n- **One-time Setup Wizard**  \n  `tenex-tools setup`\n- **Advanced MCP Mode**\n  `tenex-tools mcp`\n\n---\n\n\n## 💡 Use Cases\n\n- Generate robust unit tests with curated TDD snippets  \n- Automate refactoring workflows with step-by-step instructions  \n- Create domain-specific agent personas (e.g., Security Auditor, Performance Tuner)  \n- Share best practices across teams and projects  \n\n---\n\n## 🚀 Getting Started\n\n1. **Install tenex-tools**\n   ```bash\n   bun install\n   ```\n\n   > **Note:** If you want to use tenex-tools globally, you can link it after building:\n   > ```bash\n   > bun run build\n   > bun link\n   > ```\n\n2. **Run the setup wizard**\n   ```bash\n   bun run index.ts setup\n   ```\n\n### **Find and install a code snippet**  \n   ```bash\n   tenex-tools find-snippets --limit 5 --languages javascript,python --tags testing\n   ```\n\n### **Discover agent workflows**  \n   ```bash\n   tenex-tools agent find \"refactor\"\n   ```\n\n### **Fetch and save an instruction set**  \n   ```bash\n   tenex-tools instructions find \"optimize imports\" --out .roo/rules-code/\n   ```\n\n---\n\n## 📖 CLI Reference\n\n**Setup**  \n```bash\ntenex-tools setup\n```  \n\n**Find Snippets**  \n```bash\ntenex-tools find-snippets [--limit <n>] [--languages <list>] [--tags <list>] [--authors <list>]\n```  \n\n**Instructions**  \n```bash\ntenex-tools instructions find <query> [--out <path>]\ntenex-tools instructions publish <file>\n```  \n\n**Agents**  \n```bash\ntenex-tools agent find <query>\ntenex-tools agent get <eventId> --roo [path]\ntenex-tools agent publish <.roomodes path>\n```  \n\n---\n\n## 🤝 Contributing\n\nWe welcome new snippets, instructions, and agent profiles! To contribute:\n\n1. Fork this repo and clone.  \n2. Add your assets under `assets/`, or publish directly with the CLI.  \n3. Submit a PR or share your contributions via the community registry.  \n\n---\n\n## 📜 License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "llms",
        "code",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "pansila--mcp_server_gdb": {
      "owner": "pansila",
      "name": "mcp_server_gdb",
      "url": "https://github.com/pansila/mcp_server_gdb",
      "imageUrl": "https://github.com/pansila.png",
      "description": "Manage and debug applications remotely using GDB, supporting breakpoints, stack information, and program execution control. Enables concurrent debugging sessions to enhance workflow efficiency.",
      "stars": 50,
      "forks": 9,
      "license": "MIT License",
      "language": "Rust",
      "updated_at": "2025-09-29T00:37:17Z",
      "readme_content": "# MCP Server GDB\n\nA GDB/MI protocol server based on the MCP protocol, providing remote application debugging capabilities with AI assistants.\n\n## Features\n\n- Create and manage GDB debug sessions\n- Set and manage breakpoints\n- View stack information and variables\n- Control program execution (run, pause, step, etc.)\n- Support concurrent multi-session debugging\n- A built-in TUI to inspect agent behaviors so that you can improve your prompt (WIP)\n\n## Installation\n\n### Pre-built Binaries\nFind the binaries in the release page, choose one per your working platform, then you can run it directly.\n\n### Build From Source\nClone the repository and build it by cargo\n```bash\ncargo build --release\ncargo run\n```\n\n### Using Nix\nIf you have Nix installed, you can run the project without cloning:\n\n#### Run locally (after cloning)\n```bash\nnix run .\n```\n\n#### Run remotely from GitHub\n```bash\nnix run \"git+https://github.com/pansila/mcp_server_gdb.git\" -- --help\n\n```\n\n#### Development environment\nTo enter a development shell with all dependencies:\n```bash\nnix develop\n```\n\n## Usage\n\n1. Just run it directly: `./mcp-server-gdb`\n2. The server supports two transport modes:\n   - Stdio (default): Standard input/output transport\n   - SSE: Server-Sent Events transport, default at `http://127.0.0.1:8080`\n\n## Configuration\n\nYou can adjust server configuration by modifying the `src/config.rs` file or by environment variables:\n\n- Server IP Address\n- Server port\n- GDB command timeout time (in seconds)\n\n## Supported MCP Tools\n\n### Session Management\n\n- `create_session` - Create a new GDB debugging session\n- `get_session` - Get specific session information\n- `get_all_sessions` - Get all sessions\n- `close_session` - Close session\n\n### Debug Control\n\n- `start_debugging` - Start debugging\n- `stop_debugging` - Stop debugging\n- `continue_execution` - Continue execution\n- `step_execution` - Step into next line\n- `next_execution` - Step over next line\n\n### Breakpoint Management\n\n- `get_breakpoints` - Get breakpoint list\n- `set_breakpoint` - Set breakpoint\n- `delete_breakpoint` - Delete breakpoint\n\n### Debug Information\n\n- `get_stack_frames` - Get stack frame information\n- `get_local_variables` - Get local variables\n- `get_registers` - Get registers\n- `read_memory` - Read memory contents\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "servers",
        "gdb",
        "execution servers",
        "llms execute",
        "execution control"
      ],
      "category": "code-execution"
    },
    "philipp-eisen--modal-mcp-toolbox": {
      "owner": "philipp-eisen",
      "name": "modal-mcp-toolbox",
      "url": "https://github.com/philipp-eisen/modal-mcp-toolbox",
      "imageUrl": "https://github.com/philipp-eisen.png",
      "description": "A collection of tools that provides a sandboxed environment for executing Python code and generating images using the FLUX model.",
      "stars": 22,
      "forks": 3,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-12T21:44:25Z",
      "readme_content": "# Modal MCP Toolbox 🛠️\n\n[![smithery badge](https://smithery.ai/badge/@philipp-eisen/modal-mcp-toolbox)](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox)\n\nA collection of Model Context Protocol (MCP) tools that run on Modal.\nThis let's you extend the capabilities of your LLM in tools such as [Goose](https://block.github.io/goose/) or the [Claude Desktop App](https://claude.ai/download).\n\n<a href=\"https://glama.ai/mcp/servers/ai78w0p5mc\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ai78w0p5mc/badge\" alt=\"Modal Toolbox MCP server\" /></a>\n\n## Tools\n\n- `run_python_code_in_sandbox`: Let's you run python code in a sandboxed environment.\n- `generate_flux_image`: Generate an image using the FLUX model.\n\n## Demo\n\n### Flux Image Generation\n\n![🎬Flux Image Generation](./assets/flux.gif)\n\n### Python Code Execution\n\n![🎬Python Code Execution](./assets/python-sandbox.gif)\n\n## Prerequisites\n\n- A [modal account](https://modal.com/signup) and a configured modal CLI.\n- [UV](https://github.com/astral-sh/uv?tab=readme-ov-file#installation)\n- A client that supports MCP. Such as the [Claude Desktop App](https://claude.ai/download) or [Goose](https://block.github.io/goose/)\n\nThis runs against your modal account, so you will need to have a modal account and be logged in.\n\n## Installation\n\nInstallation depends on the client that uses the MCP. Here is instructions for Claude and Goose.\n\n### Claude\n\nGot to `Settings > Developer` in the Claude Desktop App. And click on Edit Config.\n![🖼️Claude Settings](./assets/claude-settings.png)\n\nAdd the config for the mcp server. My config looks like this:\n\n```json\n{\n  \"mcpServers\": {\n    \"modal-toolbox\": {\n      \"command\": \"uvx\",\n      \"args\": [\"modal-mcp-toolbox\"]\n    }\n  }\n}\n```\n\n### Goose\n\nGo to `Settings` and Click on Add.\n\n![🖼️Goose Settings](./assets/goose-settings-1.png)\n\nThen add an extension like in the screenshot below.\nThe important part is to set command to:\n\n```\nuvx modal-mcp-toolbox\n```\n\nThe rest you can fill in as you like.\n\n![🖼️Goose MCP Settings](./assets/goose-settings-2.png)\n\n### Installing via Smithery (not working currently)\n\nTo install Modal MCP Toolbox for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox):\n\n```bash\nnpx -y @smithery/cli install @philipp-eisen/modal-mcp-toolbox --client claude\n```\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "sandboxed",
        "coding",
        "llms execute",
        "environment coding",
        "coding agents"
      ],
      "category": "code-execution"
    },
    "pottekkat--sandbox-mcp": {
      "owner": "pottekkat",
      "name": "sandbox-mcp",
      "url": "https://github.com/pottekkat/sandbox-mcp",
      "imageUrl": "https://github.com/pottekkat.png",
      "description": "Runs code in secure, isolated Docker containers, preventing unintended consequences from untested code execution. Provides a configurable execution environment for LLMs to safely test code locally.",
      "stars": 80,
      "forks": 12,
      "license": "MIT License",
      "language": "Go",
      "updated_at": "2025-10-04T04:54:42Z",
      "readme_content": "![Sandbox MCP Logo](readme-banner.png)\n\n![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/pottekkat/sandbox-mcp/release.yaml)\n![GitHub Release](https://img.shields.io/github/v/release/pottekkat/sandbox-mcp)\n![GitHub commits since latest release](https://img.shields.io/github/commits-since/pottekkat/sandbox-mcp/latest)\n![GitHub License](https://img.shields.io/github/license/pottekkat/sandbox-mcp)\n\n**Sandbox MCP** is a Model Context Protocol (MCP) server that enables LLMs (MCP hosts/clients) to **run code in secure, isolated Docker containers**.\n\nWhile LLMs are really good at generating code, most **can't run the code they generate**. You end up running this untested code directly on your machine, which could have drastic unintended consequences.\n\nGiving LLMs the tools to test the code safely prevents such issues and helps you **generate more accurate code in fewer iterations**.\n\nSandbox MCP gives the LLMs an **easy-to-use execution environment that anyone can create and configure** through a simple, AI-native MCP server that runs locally.\n\n_Inspired by [Codapi](https://codapi.org). Some sandboxes are the same as [Codapi sandboxes](https://github.com/nalgeon/sandboxes)._\n\n## Use Cases\n\nSandbox MCP can be used for many different tasks, including but not limited to:\n\n- **Secure code execution**: Run any code generated by an LLM in a secure, isolated environment, protecting your system from untrusted or potentially harmful code.\n- **Code testing**: Automatically test and validate code in various languages and or configurations in various environments before integrating it into larger projects or production systems.\n- **User code validation**: Safely execute and check user-submitted code or scripts, ensuring they behave as expected and do not perform malicious actions.\n- **Network troubleshooting**: Diagnose connectivity issues, test endpoints, and analyze network performance using isolated network tools, all without exposing your system.\n- **Educational and interview coding**: Instantly compile and run code snippets for learning, teaching, or technical interviews, providing immediate feedback in a safe, temporary environment.\n- **Automated code review and feedback**: Enable LLMs to execute, test, and review code automatically, offering actionable feedback or suggestions before code is merged or deployed.\n\n## Demo\n\nThis demo shows how Sandbox MCP works with Claude Desktop.\n\n![Sandbox MCP demo GIF](demo.gif)\n\nTry the [video](demo.mp4) if the GIF isn't clear.\n\n## Installation\n\n### Download Binary\n\nYou can download the appropriate binary for your operating system (for example, `Darwin`) and processor architecture (`arm64`) from the [Releases page](https://github.com/pottekkat/sandbox-mcp/releases) (`sandbox-mcp_Darwin_arm64.tar.gz`).\n\n### Install via Go\n\nPrerequisites:\n\n- Go 1.24 or higher\n\n```bash\ngo install github.com/pottekkat/sandbox-mcp/cmd/sandbox-mcp@latest\n```\n\nGet the path to the `sandbox-mcp` binary:\n\n```bash\nwhich sandbox-mcp\n```\n\n### Build from Source\n\nSee the [Development section](#development).\n\n## Usage\n\n### Initilization\n\nBefore you use `sandbox-mcp` with LLMs, you need to initialize its configuration:\n\n```bash\n# Create the configuration directory in\n# $XDG_CONFIG_HOME/sandbox-mcp and pull\n# the default sandboxes from GitHub\nsandbox-mcp --pull\n\n# Build the Docker images for the sandboxes\nsandbox-mcp --build\n```\n\n> [!NOTE]\n> Make sure you have Docker installed and running.\n\n### With MCP Hosts/Clients\n\nAdd this to your `claude_desktop_config.json` for Claude Desktop or `mcp.json` for Cursor IDE:\n\n```json\n{\n    \"mcpServers\": {\n        \"sandbox-mcp\": {\n            \"command\": \"path/to/sandbox-mcp\",\n            \"args\": [\n                \"--stdio\"\n            ]\n        }\n    }\n}\n```\n\n> [!NOTE]\n> Make sure to replace `path/to/sandbox-mcp` with the actual path to the `sandbox-mcp` binary.\n\n## Available Sandboxes\n\n| Sandbox | Description |\n|---------|-------------|\n| [shell](/sandboxes/shell) | A secure, isolated Linux environment for running lightweight commands that does not require network access. |\n| [python](/sandboxes/python) | Safely execute Python code in a secure, isolated environment. |\n| [rust](/sandboxes/rust) | Compile and run Rust code in an isolated environment. |\n| [network-tools](/sandboxes/network-tools) | Use various network utilities in an isolated Linux sandbox. Perfect for network diagnostics and troubleshooting. See https://github.com/jonlabelle/docker-network-tools for a list of available tools. |\n| [go](/sandboxes/go) | Run Go code securely in an isolated environment with network access. |\n| [javascript](/sandboxes/javascript) | Run JavaScript code in an isolated environment using Node.js. |\n| [apisix](/sandboxes/apisix) | Run a lightweight instance of Apache APISIX, which can be configured through a YAML file and can be interacted through the curl command provided in the main.sh file. For example, curl -sI `http://127.0.0.1:9080/ip`. |\n| [java](/sandboxes/java) | Compile and run Java code in an isolated sandbox. Supports Java preview features. |\n\n> [!IMPORTANT]\n> ### Your Own Sandbox\n> \n> You can create and add your own sandboxes in `$XDG_CONFIG_HOME/sandbox-mcp/sandboxes`. A sandbox is essentially a Dockerfile and a JSON configuration. Check out the [examples and the guide](/sandboxes) to learn more.\n\n## Development\n\nFork and clone the repository:\n\n```bash\ngit clone https://github.com/username/sandbox-mcp.git\n```\n\nChange into the directory:\n\n```bash\ncd sandbox-mcp\n```\n\nInstall dependencies:\n\n```bash\nmake deps\n```\n\nBuild the project:\n\n```bash\nmake build\n```\n\nUpdate your MCP servers configuration to point to the local build:\n\n```json\n{\n    \"mcpServers\": {\n        \"sandbox-mcp\": {\n            \"command\": \"/path/to/sandbox-mcp/dist/sandbox-mcp\",\n            \"args\": [\n                \"--stdio\"\n            ]\n        }\n    }\n}\n```\n\n## License\n\n[MIT License](LICENSE)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "sandbox",
        "docker",
        "llms execute",
        "environment llms",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "pydantic--pydantic-ai/mcp-run-python": {
      "owner": "pydantic",
      "name": "pydantic-ai/mcp-run-python",
      "url": "https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python",
      "imageUrl": "",
      "description": "Run Python code in a secure sandbox via MCP tool calls",
      "stars": 0,
      "forks": 0,
      "license": "Unknown",
      "language": "Unknown",
      "updated_at": "",
      "readme_content": "",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "python",
        "sandbox",
        "llms execute",
        "code secure",
        "secure sandbox"
      ],
      "category": "code-execution"
    },
    "r33drichards--mcp-js": {
      "owner": "r33drichards",
      "name": "mcp-js",
      "url": "https://github.com/r33drichards/mcp-js",
      "imageUrl": "",
      "description": "A Javascript code execution sandbox that uses v8 to isolate code to run AI generated javascript locally without fear. Supports heap snapshotting for persistent sessions.",
      "stars": 19,
      "forks": 4,
      "license": "BSD Zero Clause License",
      "language": "Rust",
      "updated_at": "2025-09-27T07:30:13Z",
      "readme_content": "# mcp-v8: V8 JavaScript MCP Server\n\nA Rust-based Model Context Protocol (MCP) server that exposes a V8 JavaScript runtime as a tool for AI agents like Claude and Cursor. Supports persistent heap snapshots via S3 or local filesystem, and is ready for integration with modern AI development environments.\n\n## Features\n\n- **V8 JavaScript Execution**: Run arbitrary JavaScript code in a secure, isolated V8 engine.\n- **Heap Snapshots**: Persist and restore V8 heap state between runs, supporting both S3 and local file storage.\n- **MCP Protocol**: Implements the Model Context Protocol for seamless tool integration with Claude, Cursor, and other MCP clients.\n- **Configurable Storage**: Choose between S3 or local directory for heap storage at runtime.\n\n## Installation\n\nInstall `mcp-v8` using the provided install script:\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/r33drichards/mcp-js/main/install.sh | sudo bash\n```\n\nThis will automatically download and install the latest release for your platform to `/usr/local/bin/mcp-v8` (you may be prompted for your password).\n\n---\n\n*Advanced users: If you prefer to build from source, see the [Build from Source](#build-from-source) section at the end of this document.*\n\n## Command Line Arguments\n\n`mcp-v8` supports the following command line arguments:\n\n- `--s3-bucket <bucket>`: Use AWS S3 for heap snapshots. Specify the S3 bucket name. (Conflicts with `--directory-path`)\n- `--directory-path <path>`: Use a local directory for heap snapshots. Specify the directory path. (Conflicts with `--s3-bucket`)\n\n**Note:** You must specify either `--s3-bucket` or `--directory-path`. If neither is provided, the server defaults to S3 with the bucket name `test-mcp-js-bucket`.\n\n## Quick Start\n\nAfter installation, you can run the server directly. Choose one of the following options:\n\n```bash\n# Use S3 for heap storage (recommended for cloud/persistent use)\nmcp-v8 --s3-bucket my-bucket-name\n\n# Use local filesystem directory for heap storage (recommended for local development)\nmcp-v8 --directory-path /tmp/mcp-v8-heaps\n```\n\n## Integration\n\n### Claude for Desktop\n\n1. Install the server as above.\n2. Open Claude Desktop → Settings → Developer → Edit Config.\n3. Add your server to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"js\": {\n      \"command\": \"/usr/local/bin/mcp-v8 --s3-bucket my-bucket-name\"\n    }\n  }\n}\n```\n\n4. Restart Claude Desktop. The new tools will appear under the hammer icon.\n\n### Cursor\n\n1. Install the server as above.\n2. Create or edit `.cursor/mcp.json` in your project root:\n\n```json\n{\n  \"mcpServers\": {\n    \"js\": {\n      \"command\": \"/usr/local/bin/mcp-v8 --directory-path /tmp/mcp-v8-heaps\"\n    }\n  }\n}\n```\n\n3. Restart Cursor. The MCP tools will be available in the UI.\n\n## Example Usage\n\n- Ask Claude or Cursor: \"Run this JavaScript: `1 + 2`\"\n- Use heap snapshots to persist state between runs.\n\n## Heap Storage Options\n\nYou can configure heap storage using the following command line arguments:\n\n- **S3**: `--s3-bucket <bucket>`\n  - Example: `mcp-v8 --s3-bucket my-bucket-name`\n  - Requires AWS credentials in your environment.\n- **Filesystem**: `--directory-path <path>`\n  - Example: `mcp-v8 --directory-path /tmp/mcp-v8-heaps`\n\n**Note:** Only one storage backend can be used at a time. If both are provided, the server will return an error.\n\n## Limitations\n\nWhile `mcp-v8` provides a powerful and persistent JavaScript execution environment, there are limitations to its runtime. \n\n- **No `async`/`await` or Promises**: Asynchronous JavaScript is not supported. All code must be synchronous.\n- **No `fetch` or network access**: There is no built-in way to make HTTP requests or access the network.\n- **No `console.log` or standard output**: Output from `console.log` or similar functions will not appear. To return results, ensure the value you want is the last line of your code.\n- **No file system access**: The runtime does not provide access to the local file system or environment variables.\n- **No `npm install` or external packages**: You cannot install or import npm packages. Only standard JavaScript (ECMAScript) built-ins are available.\n- **No timers**: Functions like `setTimeout` and `setInterval` are not available.\n- **No DOM or browser APIs**: This is not a browser environment; there is no access to `window`, `document`, or other browser-specific objects.\n\n---\n\n## Build from Source (Advanced)\n\nIf you prefer to build from source instead of using the install script:\n\n### Prerequisites\n- Rust (nightly toolchain recommended)\n- (Optional) AWS credentials for S3 storage\n\n### Build the Server\n\n```bash\ncd server\ncargo build --release\n```\n\nThe built binary will be located at `server/target/release/server`. You can use this path in the integration steps above instead of `/usr/local/bin/mcp-v8` if desired.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "sandbox",
        "coding",
        "llms execute",
        "execution servers",
        "execution sandbox"
      ],
      "category": "code-execution"
    },
    "riza-io--riza-mcp": {
      "owner": "riza-io",
      "name": "riza-mcp",
      "url": "https://github.com/riza-io/riza-mcp",
      "imageUrl": "https://github.com/riza-io.png",
      "description": "Wraps Riza API endpoints as tools for LLM-enabled code execution and management, providing an isolated environment to run code generated by LLMs.",
      "stars": 11,
      "forks": 6,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-07-07T02:43:08Z",
      "readme_content": "# Riza MCP Server\n\n[Riza](https://riza.io) offers an isolated code interpreter for your LLM-generated code. \n\nOur MCP server implementation wraps the Riza API and presents\nendpoints as individual tools.\n\nConfigure with Claude Desktop as below, or adapt as necessary for your MCP client. Get a free Riza API key in your [Riza Dashboard](https://dashboard.riza.io).\n\n```json\n{\n  \"mcpServers\": {\n    \"riza-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@riza-io/riza-mcp\"\n      ],\n      \"env\": {\n        \"RIZA_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n```\n\nThe Riza MCP server provides several tools to your LLM:\n\n- `create_tool`: Your LLM can write code and save it as a tool using the Riza [Tools API](https://docs.riza.io/api-reference/tool/create-tool). It can then execute these tools securely on Riza using `execute_tool`.\n- `fetch_tool`: Your LLM can fetch saved Riza tools, including source code, which can be useful for editing tools.\n- `execute_tool`: Executes a saved tool securely on Riza's code interpreter API.\n- `edit_tool`: Edits an existing saved tool.\n- `list_tools`: Lists available saved tools.\n- `execute_code`: Executes arbitrary code safely on Riza's code interpreter API, without saving it as a tool.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "riza",
        "llms",
        "llm",
        "riza api",
        "llms execute",
        "agents riza"
      ],
      "category": "code-execution"
    },
    "robotmcp--ros-mcp-server": {
      "owner": "robotmcp",
      "name": "ros-mcp-server",
      "url": "https://github.com/robotmcp/ros-mcp-server",
      "imageUrl": "https://github.com/robotmcp.png",
      "description": "Transforms natural language commands into ROS commands for robot control, facilitating complex task execution and environmental adaptation. Compatible with both ROS and ROS2 systems through WebSocket-based communication.",
      "stars": 711,
      "forks": 111,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-04T07:53:29Z",
      "readme_content": "# ROS MCP Server 🧠⇄🤖\n\n![Static Badge](https://img.shields.io/badge/ROS-Available-green)\n![Static Badge](https://img.shields.io/badge/ROS2-Available-green)\n![Static Badge](https://img.shields.io/badge/License-Apache%202.0-blue)\n![Python](https://img.shields.io/badge/python-3.10%2B-blue)\n![Dev Container](https://img.shields.io/badge/Dev-Container%20Ready-blue)\n![GitHub Repo stars](https://img.shields.io/github/stars/robotmcp/ros-mcp-server?style=social)\n![GitHub last commit](https://img.shields.io/github/last-commit/robotmcp/ros-mcp-server)\n\n\n<p align=\"center\">\n  <img src=\"https://github.com/robotmcp/ros-mcp-server/blob/main/docs/images/framework.png\"/>\n</p>\n\nROS-MCP-Server connects large language models (such as Claude, GPT, and Gemini) with existing robots giving them bidirectional AI integration.  \n\nWith no changes to existing robot source code, this enables:\n- 🗣 **Commanding the robot in natural language** → instructions are translated into ROS/ROS2 commands.  \n- 👀 **Giving AI full visibility** → subscribe to topics, call services, read sensor data, and monitor robot state in real time.  \n\n\n### ✅ Key Benefits  \n\n- **No robot code changes** → only requires adding the `rosbridge` node.  \n- **True two-way communication** → LLMs can both *control* robots and *observe* everything happening in ROS (sensors, topics, parameters).  \n- **ROS1 & ROS2 support** → works with both versions out of the box.  \n- **MCP-compatible** → integrates with any MCP-enabled LLM (Claude Desktop, Gemini, ChatGPT, and beyond).   \n\n## 🎥 Examples in Action  \n\n🖥️ **Example - Controlling the MOCA mobile manipulator in NVIDIA Isaac Sim**  \nCommands are entered into Claude Desktop, which uses the MCP server to directly drive the simulated robot.  \n\n<p align=\"center\">\n  <img src=\"https://github.com/robotmcp/ros-mcp-server/blob/main/docs/images/result.gif\" />\n</p>  \n\n---\n🐕 **Example - Controlling Unitree Go with natural language**  ([video](https://youtu.be/RW9_FgfxWzs?si=8bdhpHNYaupzi9q3))  \nThe MCP server enables the Claude to interpret images from the robot's cameras, and then command the robot based on human natural language commands. \n\n<p align=\"left\">\n  <img src=\"https://contoro.com/asset/media/demo_go2.gif\" />\n</p>  \n\n---\n🏭 **Example - Debugging an industrial robot** ([Video](https://youtu.be/SrHzC5InJDA))  \n- Connecting to an industrial robot enables the LLM to browse all ROS topics and services to assess the robot state. \n- With no predefined context, the MCP server enables the LLM to query details about custom topic and service types and their syntax (00:28). \n- Using only natural language, the operator calls the custom services to test and debug the robot(01:42). \n\n<p align=\"center\">\n  <a href=\"https://contoroinc.sharepoint.com/:v:/s/SandboxNewBusiness/EVh2t2_YG9BEl-Bw-8k6xucBcEv7XebJv1MtqLTIfrQpig?e=deu3YO\">\n    <img src=\"https://github.com/robotmcp/ros-mcp-server/blob/main/docs/images/Contoro_robot.png\" width=\"400\" alt=\"Testing and debugging an industrial robot\" />\n  </a>\n</p>\n\n---\n\n## ⚙️ Features of the ROS MCP Server  \n\n- **List topics, services, and message types** → explore everything available in your robot’s ROS environment.  \n- **View type definitions (incl. custom)** → understand the structure of any message.  \n- **Publish/subscribe to topics** → send commands or stream robot data in real time.  \n- **Call services (incl. custom)** → trigger robot functions directly.  \n- **Get/set parameters** → read or adjust robot settings on the fly.  \n- 🔜 **Action support** → upcoming support for ROS Actions.  \n- 🔜 **Permission controls** → manage access for safer deployments.  \n\n---\n\n## 🛠 Getting Started  \n\nThe MCP server is version-agnostic (ROS1 or ROS2) and works with any MCP-compatible LLM.  \n\n<p align=\"center\">\n  <img src=\"https://github.com/robotmcp/ros-mcp-server/blob/main/docs/images/MCP_topology.png\"/>\n</p>  \n\n### Installation  \n\nFollow the [installation guide](docs/installation.md) for step-by-step instructions:  \n1. Clone the repository  \n2. Install `uv` and `rosbridge`  \n3. Install Claude Desktop (or any MCP-enabled client)  \n4. Configure your client to connect to the ROS MCP Server  \n5. Start `rosbridge` on the target robot  \n\n---\n\n## 📚 More Examples & Tutorials  \n\nBrowse our [examples](examples) to see the server in action.  \nWe welcome community PRs with new examples and integrations!  \n\n---\n\n## 🤝 Contributing  \n\nWe love contributions of all kinds:  \n- Bug fixes and documentation updates  \n- New features (e.g., Action support, permissions)  \n- Additional examples and tutorials  \n\nCheck out the [contributing guidelines](docs/contributing.md) and see issues tagged **good first issue** to get started.  \n\n---\n\n## 📜 License  \n\nThis project is licensed under the [Apache License 2.0](LICENSE).  \n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "ros2",
        "ros",
        "robotmcp",
        "robotmcp ros",
        "ros commands",
        "commands ros"
      ],
      "category": "code-execution"
    },
    "runninghare--typescript-definition-finder-mcp": {
      "owner": "runninghare",
      "name": "typescript-definition-finder-mcp",
      "url": "https://github.com/runninghare/typescript-definition-finder-mcp",
      "imageUrl": "https://github.com/runninghare.png",
      "description": "Locates original definitions of TypeScript symbols in a codebase, including classes, interfaces, and functions. Returns precise locations and code snippets to aid in development.",
      "stars": 1,
      "forks": 2,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-05-24T15:11:55Z",
      "readme_content": "[![MseeP Badge](https://mseep.net/pr/runninghare-typescript-definition-finder-mcp-badge.jpg)](https://mseep.ai/app/runninghare-typescript-definition-finder-mcp)\n\n# TypeScript Definition Finder MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@runninghare/typescript-definition-finder-mcp)](https://smithery.ai/server/@runninghare/typescript-definition-finder-mcp)\n\nA Model Context Protocol (MCP) server that helps AI code editors find TypeScript symbol definitions in your codebase. This tool is particularly useful when you need to locate the original definition of imported symbols, classes, interfaces, or functions in a TypeScript project.\n\n## Features\n\n- Finds original definitions of TypeScript symbols\n- Works with imported symbols from external packages\n- Returns both the definition location and code snippet\n- Supports stdio interface for seamless integration with AI code editors\n\n## Prerequisites\n\n- TypeScript project with `typescript` dependency installed\n- Node.js for running the server\n\n## Installation & Usage\n\nThis is a Model Context Protocol (MCP) stdio server that requires access to your local filesystem to find TypeScript definitions.\n\n### Installing via Smithery\n\nTo install TypeScript Definition Finder MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@runninghare/typescript-definition-finder-mcp):\n\n```bash\nnpx -y @smithery/cli install @runninghare/typescript-definition-finder-mcp --client claude\n```\n\n### Running the MCP Server\nTo use the MCP server:\n\n1. Ensure your project has TypeScript installed as a dependency\n2. Run the following command in your project directory:\n```bash\nnpx -y ts-def-mcp@latest\n```\n\nYou can integrate this command with various AI code editors that support MCP:\n- Claude Desktop\n- Cursor\n- Windsurf\n- Roo Cline Editor\n\n> **Important Note**: Due to the local filesystem access requirements, Docker + WebSocket solutions will not work. Please ignore the installation guide on https://smithery.ai/server/@runninghare/typescript-definition-finder-mcp.\n\n### Tool Description\n\nThe server provides a `find_typescript_definition` tool with the following capabilities:\n\n- **Tool Name**: `find_typescript_definition`\n- **Trigger Command**: `/ts-def` (Useful in ‘Cursor’ if you want to force AI editor to find the referenced symbol definition)\n- **Purpose**: Locates the original definition of TypeScript symbols in your codebase\n\n### Input Parameters\n\nThe tool requires three parameters:\n\n1. `file_path` (string): \n   - The absolute path to the current TypeScript file\n   - Example: `/path/to/your/project/src/index.ts`\n\n2. `symbol` (string):\n   - The TypeScript symbol (variable, class name, interface, type, etc.) you want to find the definition of\n   - Must be present in the line_content\n   - Example: `StdioServerTransport`, `MyClass`, `interface1`\n\n3. `line_content` (string):\n   - The entire line containing the symbol you want to find the definition of\n   - Used to locate both the line number in the file and the exact position of the symbol\n   - Must contain the symbol exactly as specified\n\n### Examples\n\n1. **Finding an Imported Symbol Definition**\n\nGiven this import statement:\n```typescript\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\n```\nTo find the definition of `StdioServerTransport`, you would use:\n```json\n{\n  \"file_path\": \"~/my-mcp-project/src/index.ts\",\n  \"symbol\": \"StdioServerTransport\",\n  \"line_content\": \"import { StdioServerTransport } from \\\"@modelcontextprotocol/sdk/server/stdio.js\\\";\"\n}\n```\n\n2. **Finding a Local Symbol Definition**\n\nFor a local class usage:\n```typescript\nclass MyService {\n  private transport: StdioServerTransport;\n}\n```\nTo find the definition of `StdioServerTransport`, use:\n```json\n{\n  \"file_path\": \"/path/to/project/src/service.ts\",\n  \"symbol\": \"StdioServerTransport\",\n  \"line_content\": \"  private transport: StdioServerTransport;\"\n}\n```\n\n### Response Format\n\nThe tool returns a JSON response containing:\n- The file path where the definition was found\n- The line number of the definition\n- The actual code snippet of the definition\n\n### Cursor Calling Example\n\nMCP Input:\n```json\n{\n  \"file_path\": \"/Users/rossz/workspace/ai-tools/mcp/ts-def-mcp/src/index.ts\",\n  \"symbol\": \"SSEServerTransport\",\n  \"line_content\": \"import { SSEServerTransport } from '@modelcontextprotocol/sdk/server/sse.js';\"\n}\n```\n\nMCP Output:\n```json\n[\n  {\n    \"file\": \"/Users/rossz/workspace/ai-tools/mcp/ts-def-mcp/node_modules/@modelcontextprotocol/sdk/dist/esm/server/sse.d.ts\",\n    \"type\": \"Definition\",\n    \"location\": \"Line 9, Column 22\",\n    \"codeSnippet\": \"   8    */\\n   9 > export declare class SSEServerTransport implements Transport {\\n  10 +     private _endpoint;\\n  11 +     private res;\\n  12 +     private _sseResponse?;\\n  13 +     private _sessionId;\\n  14 +     onclose?: () => void;\\n  15 +     onerror?: (error: Error) => void;\\n  16 +     onmessage?: (message: JSONRPCMessage) => void;\\n  17 +     /**\\n  18 +      * Creates a new SSE server transport, which will direct the client to POST messages to the relative or absolute URL identified by `_endpoint`.\\n  19 +      */\\n  20 +     constructor(_endpoint: string, res: ServerResponse);\\n  21 +     /**\\n  22 +      * Handles the initial SSE connection request.\\n  23 +      *\\n  24 +      * This should be called when a GET request is made to establish the SSE stream.\\n  25 +      */\\n  26 +     start(): Promise<void>;\\n  27 +     /**\\n  28 +      * Handles incoming POST messages.\\n  29 +      *\\n  30 +      * This should be called when a POST request is made to send a message to the server.\\n  31 +      */\\n  32 +     handlePostMessage(req: IncomingMessage, res: ServerResponse, parsedBody?: unknown): Promise<void>;\\n  33 +     /**\\n  34 +      * Handle a client message, regardless of how it arrived. This can be used to inform the server of messages that arrive via a means different than HTTP POST.\\n  35 +      */\\n  36 +     handleMessage(message: unknown): Promise<void>;\\n  37 +     close(): Promise<void>;\\n  38 +     send(message: JSONRPCMessage): Promise<void>;\\n  39 +     /**\\n  40 +      * Returns the session ID for this transport.\\n  41 +      *\\n  42 +      * This can be used to route incoming POST requests.\\n  43 +      */\\n  44 +     get sessionId(): string;\\n  45   }\\n\"\n  }\n]\n```\n\n<img width=\"1676\" alt=\"2025-04-12_17-06-42\" src=\"https://github.com/user-attachments/assets/8a306ce0-cb8e-4b82-9542-11aaee8a09b6\" />\n\n\n## Development\n\nThis project was created using `bun init` in bun v1.2.2. [Bun](https://bun.sh) is a fast all-in-one JavaScript runtime.\n\n### Running in Development Mode\n\nFor development, you can run the server directly using Bun:\n```bash\nbun run src/index.ts\n```\n\n## License\n\n[Add your license information here]\n\n## Contributing\n\n[Add contribution guidelines here]\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "typescript",
        "codebase",
        "llms",
        "llms execute",
        "runninghare typescript",
        "execute code"
      ],
      "category": "code-execution"
    },
    "rusiaaman--wcgw": {
      "owner": "rusiaaman",
      "name": "wcgw",
      "url": "https://github.com/rusiaaman/wcgw",
      "imageUrl": "https://github.com/rusiaaman.png",
      "description": "Shell and coding agent that integrates shell and code editing tools for executing commands and building applications locally.",
      "stars": 598,
      "forks": 55,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-10-03T22:31:39Z",
      "readme_content": "# Shell and Coding agent for Claude and other mcp clients\n\nEmpowering chat applications to code, build and run on your local machine.\n\nwcgw is an MCP server with tightly integrated shell and code editing tools.\n\n⚠️ Warning: do not allow BashCommand tool without reviewing the command, it may result in data loss.\n\n[![Tests](https://github.com/rusiaaman/wcgw/actions/workflows/python-tests.yml/badge.svg?branch=main)](https://github.com/rusiaaman/wcgw/actions/workflows/python-tests.yml)\n[![Mypy strict](https://github.com/rusiaaman/wcgw/actions/workflows/python-types.yml/badge.svg?branch=main)](https://github.com/rusiaaman/wcgw/actions/workflows/python-types.yml)\n[![Build](https://github.com/rusiaaman/wcgw/actions/workflows/python-publish.yml/badge.svg)](https://github.com/rusiaaman/wcgw/actions/workflows/python-publish.yml)\n[![codecov](https://codecov.io/gh/rusiaaman/wcgw/graph/badge.svg)](https://codecov.io/gh/rusiaaman/wcgw)\n\n## Demo\n\n![Workflow Demo](static/workflow-demo.gif)\n\n## Updates\n\n- [27 Apr 2025] Removed support for GPTs over relay server. Only MCP server is supported in version >= 5.\n\n- [24 Mar 2025] Improved writing and editing experience for sonnet 3.7, CLAUDE.md gets loaded automatically.\n\n- [16 Feb 2025] You can now attach to the working terminal that the AI uses. See the \"attach-to-terminal\" section below.\n\n- [15 Jan 2025] Modes introduced: architect, code-writer, and all powerful wcgw mode.\n\n- [8 Jan 2025] Context saving tool for saving relevant file paths along with a description in a single file. Can be used as a task checkpoint or for knowledge transfer.\n\n- [29 Dec 2024] Syntax checking on file writing and edits is now stable. Made `initialize` tool call useful; sending smart repo structure to claude if any repo is referenced. Large file handling is also now improved.\n\n- [9 Dec 2024] [Vscode extension to paste context on Claude app](https://marketplace.visualstudio.com/items?itemName=AmanRusia.wcgw)\n\n## 🚀 Highlights\n\n- ⚡ **Create, Execute, Iterate**: Ask claude to keep running compiler checks till all errors are fixed, or ask it to keep checking for the status of a long running command till it's done.\n- ⚡ **Large file edit**: Supports large file incremental edits to avoid token limit issues. Smartly selects when to do small edits or large rewrite based on % of change needed.\n- ⚡ **Syntax checking on edits**: Reports feedback to the LLM if its edits have any syntax errors, so that it can redo it.\n- ⚡ **Interactive Command Handling**: Supports interactive commands using arrow keys, interrupt, and ansi escape sequences.\n- ⚡ **File protections**:\n  - The AI needs to read a file at least once before it's allowed to edit or rewrite it. This avoids accidental overwrites.\n  - Avoids context filling up while reading very large files. Files get chunked based on token length.\n  - On initialisation the provided workspace's directory structure is returned after selecting important files (based on .gitignore as well as a statistical approach)\n  - File edit based on search-replace tries to find correct search block if it has multiple matches based on previous search blocks. Fails otherwise (for correctness).\n  - File edit has spacing tolerant matching, with warning on issues like indentation mismatch. If there's no match, the closest match is returned to the AI to fix its mistakes.\n  - Using Aider-like search and replace, which has better performance than tool call based search and replace.\n- ⚡ **Shell optimizations**:\n  - Only one command is allowed to be run at a time, simplifying management and avoiding rogue processes. There's only single shell instance at any point of time.\n  - Current working directory is always returned after any shell command to prevent AI from getting lost.\n  - Command polling exits after a quick timeout to avoid slow feedback. However, status checking has wait tolerance based on fresh output streaming from a command. Both of these approach combined provides a good shell interaction experience.\n- ⚡ **Saving repo context in a single file**: Task checkpointing using \"ContextSave\" tool saves detailed context in a single file. Tasks can later be resumed in a new chat asking \"Resume `task id`\". The saved file can be used to do other kinds of knowledge transfer, such as taking help from another AI.\n- ⚡ **Easily switch between various modes**:\n  - Ask it to run in 'architect' mode for planning. Inspired by adier's architect mode, work with Claude to come up with a plan first. Leads to better accuracy and prevents premature file editing.\n  - Ask it to run in 'code-writer' mode for code editing and project building. You can provide specific paths with wild card support to prevent other files getting edited.\n  - By default it runs in 'wcgw' mode that has no restrictions and full authorisation.\n  - More details in [Modes section](#modes)\n- ⚡ **Runs in multiplex terminal** Run `screen -x` to attach to the terminal that the AI runs commands on. See history or interrupt process or interact with the same terminal that AI uses.\n- ⚡ **Automatically load CLAUDE.md/AGENTS.md** Loads \"CLAUDE.md\" or \"AGENTS.md\" file in project root and sends as instructions during initialisation. Instructions in a global \"~/.wcgw/CLAUDE.md\" or \"~/.wcgw/AGENTS.md\" file are loaded and added along with project specific CLAUDE.md. The file name is case sensitive. CLAUDE.md is attached if it's present otherwise AGENTS.md is attached.\n\n## Top use cases examples\n\n- Solve problem X using python, create and run test cases and fix any issues. Do it in a temporary directory\n- Find instances of code with X behavior in my repository\n- Git clone https://github.com/my/repo in my home directory, then understand the project, set up the environment and build\n- Create a golang htmx tailwind webapp, then open browser to see if it works (use with puppeteer mcp)\n- Edit or update a large file\n- In a separate branch create feature Y, then use github cli to create a PR to original branch\n- Command X is failing in Y directory, please run and fix issues\n- Using X virtual environment run Y command\n- Using cli tools, create build and test an android app. Finally run it using emulator for me to use\n- Fix all mypy issues in my repo at X path.\n- Using 'screen' run my server in background instead, then run another api server in bg, finally run the frontend build. Keep checking logs for any issues in all three\n- Create repo wide unittest cases. Keep iterating through files and creating cases. Also keep running the tests after each update. Do not modify original code.\n\n## Claude setup (using mcp)\n\n### Mac and linux\n\nFirst install `uv` using homebrew `brew install uv`\n\n(**Important:** use homebrew to install uv. Otherwise make sure `uv` is present in a global location like /usr/bin/)\n\nThen create or update `claude_desktop_config.json` (~/Library/Application Support/Claude/claude_desktop_config.json) with following json.\n\n```json\n{\n  \"mcpServers\": {\n    \"wcgw\": {\n      \"command\": \"uv\",\n      \"args\": [\"tool\", \"run\", \"--python\", \"3.12\", \"wcgw\"]\n    }\n  }\n}\n```\n\nThen restart claude app.\n\n_If there's an error in setting up_\n\n- If there's an error like \"uv ENOENT\", make sure `uv` is installed. Then run 'which uv' in the terminal, and use its output in place of \"uv\" in the configuration.\n- If there's still an issue, check that `uv tool run --python 3.12 wcgw` runs in your terminal. It should have no output and shouldn't exit.\n- Try removing ~/.cache/uv folder\n- Try using `uv` version `0.6.0` for which this tool was tested.\n- Debug the mcp server using `npx @modelcontextprotocol/inspector@0.1.7 uv tool run --python 3.12 wcgw`\n\n### Windows on wsl\n\nThis mcp server works only on wsl on windows.\n\nTo set it up, [install uv](https://docs.astral.sh/uv/getting-started/installation/)\n\nThen add or update the claude config file `%APPDATA%\\Claude\\claude_desktop_config.json` with the following\n\n```json\n{\n  \"mcpServers\": {\n    \"wcgw\": {\n      \"command\": \"wsl.exe\",\n      \"args\": [\"uv\", \"tool\", \"run\", \"--python\", \"3.12\", \"wcgw\"]\n    }\n  }\n}\n```\nWhen you encounter an error, execute the command wsl uv --python 3.12 wcgw in command prompt. If you get the `error /bin/bash: line 1: uv: command not found`, it means uv was not installed globally and you need to point to the correct path of uv.\n1. Find where uv is installed:\n```bash\nwhereis uv\n```\nExample output:\n```uv: /home/mywsl/.local/bin/uv```\n\n2. Test the full path works:\n```\nwsl /home/mywsl/.local/bin/uv tool run --python 3.12 wcgw\n```\n\n3. Update the config with the full path:\n```\n{\n  \"mcpServers\": {\n    \"wcgw\": {\n      \"command\": \"wsl.exe\",\n      \"args\": [\"/home/mywsl/.local/bin/uv\", \"tool\", \"run\", \"--python\", \"3.12\", \"wcgw\"]\n    }\n  }\n}\n```\nReplace `/home/mywsl/.local/bin/uv` with your actual uv path from step 1.\n\n### Usage\n\nWait for a few seconds. You should be able to see this icon if everything goes right.\n\n![mcp icon](https://github.com/rusiaaman/wcgw/blob/main/static/rocket-icon.png?raw=true)\nover here\n\n![mcp icon](https://github.com/rusiaaman/wcgw/blob/main/static/claude-ss.jpg?raw=true)\n\nThen ask claude to execute shell commands, read files, edit files, run your code, etc.\n\n#### Task checkpoint or knowledge transfer\n\n- You can do a task checkpoint or a knowledge transfer by attaching \"KnowledgeTransfer\" prompt using \"Attach from MCP\" button.\n- On running \"KnowledgeTransfer\" prompt, the \"ContextSave\" tool will be called saving the task description and all file content together in a single file. An id for the task will be generated.\n- You can in a new chat say \"Resume '<task id>'\", the AI should then call \"Initialize\" with the task id and load the context from there.\n- Or you can directly open the file generated and share it with another AI for help.\n\n#### Modes\n\nThere are three built-in modes. You may ask Claude to run in one of the modes, like \"Use 'architect' mode\"\n| **Mode** | **Description** | **Allows** | **Denies** | **Invoke prompt** |\n|-----------------|-----------------------------------------------------------------------------|---------------------------------------------------------|----------------------------------------------|----------------------------------------------------------------------------------------------------|\n| **Architect** | Designed for you to work with Claude to investigate and understand your repo. | Read-only commands | FileEdit and Write tool | Run in mode='architect' |\n| **Code-writer** | For code writing and development | Specified path globs for editing or writing, specified commands | FileEdit for paths not matching specified glob, Write for paths not matching specified glob | Run in code writer mode, only 'tests/**' allowed, only uv command allowed |\n| **wcgw\\*\\* | Default mode with everything allowed | Everything | Nothing | No prompt, or \"Run in wcgw mode\" |\n\nNote: in code-writer mode either all commands are allowed or none are allowed for now. If you give a list of allowed commands, Claude is instructed to run only those commands, but no actual check happens. (WIP)\n\n#### Attach to the working terminal to investigate\n\nIf you've `screen` command installed, wcgw runs on a screen instance automatically. If you've started wcgw mcp server, you can list the screen sessions:\n\n`screen -ls`\n\nAnd note down the wcgw screen name which will be something like `93358.wcgw.235521` where the last number is in the hour-minute-second format.\n\nYou can then attach to the session using `screen -x 93358.wcgw.235521`\n\nYou may interrupt any running command safely.\n\nYou can interact with the terminal but beware that the AI might be running in parallel and it may conflict with what you're doing. It's recommended to keep your interactions to minimum.\n\nYou shouldn't exit the session using `exit `or Ctrl-d, instead you should use `ctrl+a+d` to safely detach without destroying the screen session.\n\nInclude the following in ~/.screenrc for better scrolling experience\n```\ndefscrollback 10000\ntermcapinfo xterm* ti@:te@\n```\n\n### [Optional] Vs code extension\n\nhttps://marketplace.visualstudio.com/items?itemName=AmanRusia.wcgw\n\nCommands:\n\n- Select a text and press `cmd+'` and then enter instructions. This will switch the app to Claude and paste a text containing your instructions, file path, workspace dir, and the selected text.\n\n## Examples\n\n![example](https://github.com/rusiaaman/wcgw/blob/main/static/example.jpg?raw=true)\n\n## Using mcp server over docker\n\nFirst build the docker image `docker build -t wcgw https://github.com/rusiaaman/wcgw.git`\n\nThen you can update `/Users/username/Library/Application Support/Claude/claude_desktop_config.json` to have\n\n```\n{\n  \"mcpServers\": {\n    \"wcgw\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\",\n        \"type=bind,src=/Users/username/Desktop,dst=/workspace/Desktop\",\n        \"wcgw\"\n      ]\n    }\n  }\n}\n```\n\n## [Optional] Local shell access with openai API key or anthropic API key\n\n### Openai\n\nAdd `OPENAI_API_KEY` and `OPENAI_ORG_ID` env variables.\n\nThen run\n\n`uvx wcgw wcgw_local --limit 0.1` # Cost limit $0.1\n\nYou can now directly write messages or press enter key to open vim for multiline message and text pasting.\n\n### Anthropic\n\nAdd `ANTHROPIC_API_KEY` env variable.\n\nThen run\n\n`uvx wcgw wcgw_local --claude`\n\nYou can now directly write messages or press enter key to open vim for multiline message and text pasting.\n\n## Tools\n\nThe server provides the following MCP tools:\n\n**Shell Operations:**\n\n- `Initialize`: Reset shell and set up workspace environment\n  - Parameters: `any_workspace_path` (string), `initial_files_to_read` (string[]), `mode_name` (\"wcgw\"|\"architect\"|\"code_writer\"), `task_id_to_resume` (string)\n- `BashCommand`: Execute shell commands with timeout control\n  - Parameters: `command` (string), `wait_for_seconds` (int, optional)\n  - Parameters: `send_text` (string) or `send_specials` ([\"Enter\"|\"Key-up\"|...]) or `send_ascii` (int[]), `wait_for_seconds` (int, optional)\n\n**File Operations:**\n\n- `ReadFiles`: Read content from one or more files\n  - Parameters: `file_paths` (string[])\n- `WriteIfEmpty`: Create new files or write to empty files\n  - Parameters: `file_path` (string), `file_content` (string)\n- `FileEdit`: Edit existing files using search/replace blocks\n  - Parameters: `file_path` (string), `file_edit_using_search_replace_blocks` (string)\n- `ReadImage`: Read image files for display/processing\n  - Parameters: `file_path` (string)\n\n**Project Management:**\n\n- `ContextSave`: Save project context and files for Knowledge Transfer or saving task checkpoints to be resumed later\n  - Parameters: `id` (string), `project_root_path` (string), `description` (string), `relevant_file_globs` (string[])\n\nAll tools support absolute paths and include built-in protections against common errors. See the [MCP specification](https://modelcontextprotocol.io/) for detailed protocol information.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "coding",
        "llms execute",
        "execution servers",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "sarathsp06--sourcesage": {
      "owner": "sarathsp06",
      "name": "sourcesage",
      "url": "https://github.com/sarathsp06/sourcesage",
      "imageUrl": "https://github.com/sarathsp06.png",
      "description": "Memorizes and manages key aspects of a codebase, enabling dynamic updates and fast retrieval while analyzing code across multiple languages. Utilizes a language-agnostic knowledge graph to enhance coding practices and insights.",
      "stars": 7,
      "forks": 4,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-01T05:37:26Z",
      "readme_content": "# SourceSage: Efficient Code Memory for LLMs\n<a href=\"https://glama.ai/mcp/servers/@sarathsp06/sourcesage\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@sarathsp06/sourcesage/badge\" />\n</a>\n\nSourceSage is an MCP (Model Context Protocol) server that efficiently memorizes key aspects of a codebase—logic, style, and standards—while allowing dynamic updates and fast retrieval. It's designed to be language-agnostic, leveraging the LLM's understanding of code across multiple languages.\n\n## Features\n\n- **Language Agnostic**: Works with any programming language the LLM understands\n- **Knowledge Graph Storage**: Efficiently stores code entities, relationships, patterns, and style conventions\n- **LLM-Driven Analysis**: Relies on the LLM to analyze code and provide insights\n- **Token-Efficient Storage**: Optimizes for minimal token usage while maximizing memory capacity\n- **Incremental Updates**: Updates knowledge when code changes without redundant storage\n- **Fast Retrieval**: Enables quick and accurate retrieval of relevant information\n\n## How It Works\n\nSourceSage uses a novel approach where:\n\n1. The LLM analyzes code files (in any language)\n2. The LLM uses MCP tools to register entities, relationships, patterns, and style conventions\n3. SourceSage stores this knowledge in a token-efficient graph structure\n4. The LLM can later query this knowledge when needed\n\nThis approach leverages the LLM's inherent language understanding while focusing the MCP server on efficient memory management.\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/sourcesage.git\ncd sourcesage\n\n# Install the package\npip install -e .\n```\n\n## Usage\n\n### Running the MCP Server\n\n```bash\n# Run the server\nsourcesage\n\n# Or run directly from the repository\npython -m sourcesage.mcp_server\n```\n\n### Connecting to Claude for Desktop\n\n1. Open Claude for Desktop\n2. Go to Settings > Developer > Edit Config\n3. Add the following to your `claude_desktop_config.json`:\n\nIf you've installed the package:\n```json\n{\n  \"mcpServers\": {\n    \"sourcesage\": {\n      \"command\": \"sourcesage\",\n      \"args\": []\n    }\n  }\n}\n```\n\nIf you're running from a local directory without installing:\n```json\n{\n  \"sourcesage\": {\n      \"command\": \"uv\", \n      \"args\": [\n        \"--directory\",\n        \"/path/to/sourcesage\",\n        \"run\",\n        \"main.py\"\n      ]\n    },\n}\n```\n\n4. Restart Claude for Desktop\n\n### Available Tools\n\nSourceSage provides the following MCP tools:\n\n1. **register_entity**: Register a code entity in the knowledge graph\n   ```\n   Input:\n     - name: Name of the entity (e.g., class name, function name)\n     - entity_type: Type of entity (class, function, module, etc.)\n     - summary: Brief description of the entity\n     - signature: Entity signature (optional)\n     - language: Programming language (optional)\n     - observations: List of observations about the entity (optional)\n     - metadata: Additional metadata (optional)\n   Output: Confirmation message with entity ID\n   ```\n\n2. **register_relationship**: Register a relationship between entities\n   ```\n   Input:\n     - from_entity: Name of the source entity\n     - to_entity: Name of the target entity\n     - relationship_type: Type of relationship (calls, inherits, imports, etc.)\n     - metadata: Additional metadata (optional)\n   Output: Confirmation message with relationship ID\n   ```\n\n3. **register_pattern**: Register a code pattern\n   ```\n   Input:\n     - name: Name of the pattern\n     - description: Description of the pattern\n     - language: Programming language (optional)\n     - example: Example code demonstrating the pattern (optional)\n     - metadata: Additional metadata (optional)\n   Output: Confirmation message with pattern ID\n   ```\n\n4. **register_style_convention**: Register a coding style convention\n   ```\n   Input:\n     - name: Name of the convention\n     - description: Description of the convention\n     - language: Programming language (optional)\n     - examples: Example code snippets demonstrating the convention (optional)\n     - metadata: Additional metadata (optional)\n   Output: Confirmation message with convention ID\n   ```\n\n5. **add_entity_observation**: Add an observation to an entity\n   ```\n   Input:\n     - entity_name: Name of the entity\n     - observation: Observation to add\n   Output: Confirmation message\n   ```\n\n6. **query_entities**: Query entities in the knowledge graph\n   ```\n   Input:\n     - entity_type: Filter by entity type (optional)\n     - language: Filter by programming language (optional)\n     - name_pattern: Filter by name pattern (regex, optional)\n     - limit: Maximum number of results to return (optional)\n   Output: List of matching entities\n   ```\n\n7. **get_entity_details**: Get detailed information about an entity\n   ```\n   Input:\n     - entity_name: Name of the entity\n   Output: Detailed information about the entity\n   ```\n\n8. **query_patterns**: Query code patterns in the knowledge graph\n   ```\n   Input:\n     - language: Filter by programming language (optional)\n     - pattern_name: Filter by pattern name (optional)\n   Output: List of matching patterns\n   ```\n\n9. **query_style_conventions**: Query coding style conventions\n   ```\n   Input:\n     - language: Filter by programming language (optional)\n     - convention_name: Filter by convention name (optional)\n   Output: List of matching style conventions\n   ```\n\n10. **get_knowledge_statistics**: Get statistics about the knowledge graph\n    ```\n    Input: None\n    Output: Statistics about the knowledge graph\n    ```\n\n11. **clear_knowledge**: Clear all knowledge from the graph\n    ```\n    Input: None\n    Output: Confirmation message\n    ```\n\n## Example Workflow with Claude\n\n1. **Analyze Code**: Ask Claude to analyze your code files\n   ```\n   \"Please analyze this Python file and register the key entities and relationships.\"\n   ```\n\n2. **Register Entities**: Claude will use the register_entity tool to store code entities\n   ```\n   \"I'll register the main class in this file.\"\n   ```\n\n3. **Register Relationships**: Claude will use the register_relationship tool to store relationships\n   ```\n   \"I'll register the inheritance relationship between these classes.\"\n   ```\n\n4. **Query Knowledge**: Later, ask Claude about your codebase\n   ```\n   \"What classes are defined in my codebase?\"\n   \"Show me the details of the User class.\"\n   \"What's the relationship between the User and Profile classes?\"\n   ```\n\n5. **Get Coding Patterns**: Ask Claude about coding patterns\n   ```\n   \"What design patterns are used in my codebase?\"\n   \"Show me examples of the Factory pattern in my code.\"\n   ```\n\n## How It's Different\n\nUnlike traditional code analysis tools, SourceSage:\n\n1. **Leverages LLM Understanding**: Uses the LLM's ability to understand code semantics across languages\n2. **Stores Semantic Knowledge**: Focuses on meaning and relationships, not just syntax\n3. **Is Language Agnostic**: Works with any programming language the LLM understands\n4. **Optimizes for Token Efficiency**: Stores knowledge in a way that minimizes token usage\n5. **Evolves with LLM Capabilities**: As LLMs improve, so does code understanding\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "codebase",
        "llms",
        "coding",
        "llms execute",
        "code execution",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "seekrays--seekchat": {
      "owner": "seekrays",
      "name": "seekchat",
      "url": "https://github.com/seekrays/seekchat",
      "imageUrl": "https://github.com/seekrays.png",
      "description": "An AI desktop assistant that automates tasks such as file management, data analysis, and code development while providing a modern interface with multi-language support.",
      "stars": 55,
      "forks": 9,
      "license": "Apache License 2.0",
      "language": "JavaScript",
      "updated_at": "2025-10-03T22:33:49Z",
      "readme_content": "# SeekChat\n\n<div align=\"center\">\n  <img src=\"public/assets/logo/logo.png\" alt=\"SeekChat Logo\" width=\"200\" />\n  <h3>✨ A Sleek and Powerful AI Desktop Assistant ✨</h3>\n  <p>\n    <a href=\"https://www.seekrays.com/chat\" target=\"_blank\">Official Website</a> |\n    <a href=\"README_zh-cn.md\">中文文档</a>\n  </p>\n</div>\n\n\n[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-blue?logo=discord&logoColor=white)](https://discord.gg/qcSXXmX9Gx)\n[![WeChat](https://img.shields.io/badge/WeChat-Join%20Group-brightgreen?logo=wechat&logoColor=white)](https://seekrays.com/chat/zh-cn/docs/contacts/)\n\nSeekChat supports MCP tool execution, enabling AI to directly control your computer and perform various tasks. Easily automate file management, data analysis, code development, and more, turning AI into a truly intelligent assistant.\n\n\n## ✨ Key Features\n\n- **Multiple AI Providers**: Support for various AI service providers\n- **MCP Tool Integration**: Support for [Model Context Protocol](https://github.com/mccpros/model-context-protocol) tools that enhance AI capabilities\n- **Local Storage**: Chat history is stored locally to protect your privacy\n- **Multi-language Support**: Available in English and Chinese\n- **Modern UI**: Simple and intuitive user interface\n\n## 🌠 Screenshots\n\n### Chat Interface\n![Chat Interface](docs/screenshot/screenshot-chat.png)\n\n### MCP Tool Settings\n![MCP Tool Settings](docs/screenshot/screenshot-setting-mcp.png)\n\n## 📦 Installation\n\n### Download Pre-compiled Version\n\nVisit the [Releases](https://github.com/seekrays/seekchat/releases) page to download the latest pre-compiled version.\n\n### Build from Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/seekrays/seekchat.git\ncd seekchat\n\n# Install dependencies\nnpm install\n\n# Run in development mode\nnpm run dev\n\n# Build for production\n# For macOS\nnpm run electron:build:mac\n\n# For Windows\nnpm run electron:build:win\n\n# For Linux\nnpm run electron:build:linux\n```\n\n\n## Community\n\n### Discord Community\nJoin our [Discord community](https://discord.gg/qcSXXmX9Gx) to get the latest updates and participate in product discussions.\n\n### WeChat Community\n![](https://seekrays.com/chat/images/qrcode_seekrays.jpg)\n\nAfter following our WeChat Official Account, send the message \"加群\" to join our WeChat community group and discuss with other users.\n\n## 🤝 Contributing\n\nPull Requests and Issues are welcome! If you have any suggestions or find a bug, please let us know.\n\n\n## 🙏 Acknowledgements\n\n- Thanks to all open-source project contributors\n- Thanks to the Electron and React communities\n- Special thanks to all users for their support and feedback\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "coding",
        "llms execute",
        "execution servers",
        "coding agents"
      ],
      "category": "code-execution"
    },
    "signal-slot--mcp-gdb": {
      "owner": "signal-slot",
      "name": "mcp-gdb",
      "url": "https://github.com/signal-slot/mcp-gdb",
      "imageUrl": "https://github.com/signal-slot.png",
      "description": "Start and manage GDB debugging sessions, load programs for analysis, set breakpoints, and execute commands for effective code debugging. Provides real-time insights and control over applications during the debugging process.",
      "stars": 55,
      "forks": 8,
      "license": "No License",
      "language": "JavaScript",
      "updated_at": "2025-09-26T16:19:02Z",
      "readme_content": "# MCP GDB Server\n\nA Model Context Protocol (MCP) server that provides GDB debugging functionality for use with Claude or other AI assistants.\n\n## Features\n\n- Start and manage GDB debugging sessions\n- Load programs and core dumps for analysis\n- Set breakpoints, step through code, and examine memory\n- View call stacks, variables, and registers\n- Execute arbitrary GDB commands\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/signal-slot/mcp-gdb.git\ncd mcp-gdb\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### Using with Claude or other MCP-enabled assistants\n\n1. Configure the MCP settings in the Claude desktop app or browser extension to include this server:\n\n```json\n{\n  \"mcpServers\": {\n    \"gdb\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-gdb/build/index.js\"],\n      \"disabled\": false\n    }\n  }\n}\n```\n\n2. Restart Claude or refresh the page.\n\n3. Now you can use the GDB tools in your conversations with Claude.\n\n### Example Commands\n\nHere are some examples of using the GDB MCP server through Claude:\n\n#### Starting a GDB session\n```\nUse gdb_start to start a new debugging session\n```\n\n#### Loading a program\n```\nUse gdb_load to load /path/to/my/program with the sessionId that was returned from gdb_start\n```\n\n#### Setting a breakpoint\n```\nUse gdb_set_breakpoint to set a breakpoint at main in the active GDB session\n```\n\n#### Running the program\n```\nUse gdb_continue to start execution\n```\n\n#### Examining variables\n```\nUse gdb_print to evaluate the expression \"my_variable\" in the current context\n```\n\n#### Getting a backtrace\n```\nUse gdb_backtrace to see the current call stack\n```\n\n#### Terminating the session\n```\nUse gdb_terminate to end the debugging session\n```\n\n## Supported GDB Commands\n\n- `gdb_start`: Start a new GDB session\n- `gdb_load`: Load a program into GDB\n- `gdb_command`: Execute an arbitrary GDB command\n- `gdb_terminate`: Terminate a GDB session\n- `gdb_list_sessions`: List all active GDB sessions\n- `gdb_attach`: Attach to a running process\n- `gdb_load_core`: Load a core dump file\n- `gdb_set_breakpoint`: Set a breakpoint\n- `gdb_continue`: Continue program execution\n- `gdb_step`: Step program execution\n- `gdb_next`: Step over function calls\n- `gdb_finish`: Execute until the current function returns\n- `gdb_backtrace`: Show call stack\n- `gdb_print`: Print value of expression\n- `gdb_examine`: Examine memory\n- `gdb_info_registers`: Display registers\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "gdb",
        "llms",
        "debugging",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "skydeckai--skydeckai-code": {
      "owner": "skydeckai",
      "name": "skydeckai-code",
      "url": "https://github.com/skydeckai/skydeckai-code",
      "imageUrl": "https://github.com/skydeckai.png",
      "description": "Provides tools for AI-driven development workflows, including file system operations, code analysis across multiple programming languages, code execution, and web content fetching with HTML-to-markdown conversion.",
      "stars": 74,
      "forks": 20,
      "license": "Apache License 2.0",
      "language": "Python",
      "updated_at": "2025-09-13T16:37:02Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/skydeckai-code-badge.png)](https://mseep.ai/app/skydeckai-code)\n\n# SkyDeckAI Code\n\nAn MCP server that provides a comprehensive set of tools for AI-driven development workflows. Features include file system operations, code analysis using tree-sitter for multiple programming languages, code execution, web content fetching with HTML-to-markdown conversion, multi-engine web search, code content searching, and system information retrieval. Designed to enhance AI's capability to assist in software development tasks by providing direct access to both local and remote resources.\n\n# Formerly Known As MCP-Server-AIDD\n\nThis mcp server was formerly known as `mcp-server-aidd`. It was renamed to `skydeckai-code` to credit the team at [SkyDeck.ai](https://skydeck.ai) with creating this application along with [East Agile](https://eastagile.com). But more importantly we realized that the term AI Driven Development (AIDD) was just not catching on. People did not understand at a glance what it was about. And nor did LLMs. \"Code\" was far more intuitive. And linguistically intuitive is important in the world of agentic AI.\n\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/fe7a40fd-30c1-4767-84f9-d33bf997497e)\n\n## Installation\n\n```bash\n# Using uvx\nuvx skydeckai-code\n```\n\n## Claude Desktop Setup\n\nAdd to your `claude_desktop_config.json`:\n\n```json\n{\n    \"mcpServers\": {\n        \"skydeckai-code\": {\n            \"command\": \"uvx\",\n            \"args\": [\"skydeckai-code\"]\n        }\n    }\n}\n```\n\n## SkyDeck AI Helper App\n\nIf you're using MseeP AI Helper app, you can search for \"SkyDeckAI Code\" and install it.\n\n![MseeP AI Helper App](/screenshots/mseep_ai_helper.png)\n\n## Key Features\n\n-   File system operations (read, write, edit, move, copy, delete)\n-   Directory management and traversal\n-   Multi-language code analysis using tree-sitter\n-   Code content searching with regex pattern matching\n-   Multi-language code execution with safety measures\n-   Web content fetching from APIs and websites with HTML-to-markdown conversion\n-   Multi-engine web search with reliable fallback mechanisms\n-   Batch operations for parallel and serial tool execution\n-   Security controls with configurable workspace boundaries\n-   Screenshot and screen context tools\n-   Image handling tools\n\n## Available Tools (29)\n\n| Category         | Tool Name                  | Description                                  |\n| ---------------- | -------------------------- | -------------------------------------------- |\n| **File System**  | `get_allowed_directory`    | Get the current working directory path       |\n|                  | `update_allowed_directory` | Change the working directory                 |\n|                  | `create_directory`         | Create a new directory or nested directories |\n|                  | `write_file`               | Create or overwrite a file with new content  |\n|                  | `edit_file`                | Make line-based edits to a text file         |\n|                  | `read_file`                | Read the contents of one or more files       |\n|                  | `list_directory`           | Get listing of files and directories         |\n|                  | `move_file`                | Move or rename a file or directory           |\n|                  | `copy_file`                | Copy a file or directory to a new location   |\n|                  | `search_files`             | Search for files matching a name pattern     |\n|                  | `delete_file`              | Delete a file or empty directory             |\n|                  | `get_file_info`            | Get detailed file metadata                   |\n|                  | `directory_tree`           | Get a recursive tree view of directories     |\n|                  | `read_image_file`          | Read an image file as base64 data            |\n| **Code Tools**   | `codebase_mapper`          | Analyze code structure across files          |\n|                  | `search_code`              | Find text patterns in code files             |\n|                  | `execute_code`             | Run code in various languages                |\n|                  | `execute_shell_script`     | Run shell/bash scripts                       |\n| **Web Tools**    | `web_fetch`                | Get content from a URL                       |\n|                  | `web_search`               | Perform a web search                         |\n| **Screen Tools** | `capture_screenshot`       | Take a screenshot of screen or window        |\n|                  | `get_active_apps`          | List running applications                    |\n|                  | `get_available_windows`    | List all open windows                        |\n| **System**       | `get_system_info`          | Get detailed system information              |\n| **Utility**      | `batch_tools`              | Run multiple tool operations together        |\n|                  | `think`                    | Document reasoning without making changes    |\n| **Todo**         | `todo_read`                | Read current workspace todo list             |\n|                  | `todo_write`               | Replace entire todo list with validation     |\n|                  | `todo_update`              | Update specific todo item by ID              |\n\n## Detailed Tool Documentation\n\n### Basic File Operations\n\n| Tool          | Parameters                                                 | Returns                                       |\n| ------------- | ---------------------------------------------------------- | --------------------------------------------- |\n| read_file     | files: [{path: string, offset?: integer, limit?: integer}] | File content (single or multiple files)       |\n| write_file    | path: string, content: string                              | Success confirmation                          |\n| move_file     | source: string, destination: string                        | Success confirmation                          |\n| copy_file     | source: string, destination: string, recursive?: boolean   | Success confirmation                          |\n| delete_file   | path: string                                               | Success confirmation                          |\n| get_file_info | path: string                                               | File metadata (size, timestamps, permissions) |\n\n### Complex File Operations\n\n#### edit_file\n\nPattern-based file editing with preview support:\n\n```json\n{\n    \"path\": \"src/main.py\",\n    \"edits\": [\n        {\n            \"oldText\": \"def old_function():\",\n            \"newText\": \"def new_function():\"\n        }\n    ],\n    \"dryRun\": false,\n    \"options\": {\n        \"partialMatch\": true\n    }\n}\n```\n\nReturns: Diff of changes or preview in dry run mode.\n\n### Directory Operations\n\n| Tool                     | Parameters                                               | Returns                        |\n| ------------------------ | -------------------------------------------------------- | ------------------------------ |\n| get_allowed_directory    | none                                                     | Current allowed directory path |\n| update_allowed_directory | directory: string (absolute path)                        | Success confirmation           |\n| list_directory           | path: string                                             | Directory contents list        |\n| create_directory         | path: string                                             | Success confirmation           |\n| search_files             | pattern: string, path?: string, include_hidden?: boolean | Matching files list            |\n\nThe `search_files` tool searches for files by name pattern, while the `search_code` tool searches within file contents using regex. Use `search_files` when looking for files with specific names or extensions, and `search_code` when searching for specific text patterns inside files.\n\n#### directory_tree\n\nGenerates complete directory structure:\n\n```json\n{\n    \"path\": \"src\",\n    \"include_hidden\": false\n}\n```\n\nReturns: JSON tree structure of directory contents.\n\n### Code Analysis\n\n#### codebase_mapper\n\nAnalyzes source code structure:\n\n```json\n{\n    \"path\": \"src\"\n}\n```\n\nReturns:\n\n-   Classes and their methods\n-   Functions and parameters\n-   Module structure\n-   Code organization statistics\n-   Inheritance relationships\n\nSupported Languages:\n\n-   Python (.py)\n-   JavaScript (.js/.jsx, .mjs, .cjs)\n-   TypeScript (.ts/.tsx)\n-   Java (.java)\n-   C++ (.cpp, .hpp, .cc)\n-   Ruby (.rb, .rake)\n-   Go (.go)\n-   Rust (.rs)\n-   PHP (.php)\n-   C# (.cs)\n-   Kotlin (.kt, .kts)\n\n#### search_code\n\nFast content search tool using regular expressions:\n\n```json\n{\n    \"patterns\": [\"function\\\\s+\\\\w+\", \"class\\\\s+\\\\w+\"],\n    \"include\": \"*.js\",\n    \"exclude\": \"node_modules/**\",\n    \"max_results\": 50,\n    \"case_sensitive\": false,\n    \"path\": \"src\"\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| patterns | array of strings | Yes | List of regular expression patterns to search for in file contents |\n| include | string | No | File pattern to include (glob syntax, default: \"\\*\") |\n| exclude | string | No | File pattern to exclude (glob syntax, default: \"\") |\n| max_results | integer | No | Maximum results to return per pattern (default: 100) |\n| case_sensitive | boolean | No | Whether search is case-sensitive (default: false) |\n| path | string | No | Base directory to search from (default: \".\") |\n\n**Returns:**\nMatching lines grouped by file with line numbers, sorted by file modification time with newest files first.\n\nThis tool uses ripgrep when available for optimal performance, with a Python fallback implementation. It's ideal for finding specific code patterns like function declarations, imports, variable usages, or error handling.\n\n### System Information\n\n| Tool            | Parameters | Returns                      |\n| --------------- | ---------- | ---------------------------- |\n| get_system_info | none       | Comprehensive system details |\n\nReturns:\n\n```json\n{\n  \"working_directory\": \"/path/to/project\",\n  \"system\": {\n    \"os\", \"os_version\", \"architecture\", \"python_version\"\n  },\n  \"wifi_network\": \"MyWiFi\",\n  \"cpu\": {\n    \"physical_cores\", \"logical_cores\", \"total_cpu_usage\"\n  },\n  \"memory\": { \"total\", \"available\", \"used_percentage\" },\n  \"disk\": { \"total\", \"free\", \"used_percentage\" },\n  \"mac_details\": {  // Only present on macOS\n    \"model\": \"Mac mini\",\n    \"chip\": \"Apple M2\",\n    \"serial_number\": \"XXX\"\n  }\n}\n```\n\nProvides essential system information in a clean, readable format.\n\n### Screen Context and Image Tools\n\n#### get_active_apps\n\nReturns a list of currently active applications on the user's system.\n\n```json\n{\n    \"with_details\": true\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| with_details | boolean | No | Whether to include additional details about each application (default: false) |\n\n**Returns:**\n\n```json\n{\n    \"success\": true,\n    \"platform\": \"macos\",\n    \"app_count\": 12,\n    \"apps\": [\n        {\n            \"name\": \"Firefox\",\n            \"has_windows\": true,\n            \"window_count\": 3,\n            \"visible_windows\": [\n                { \"name\": \"GitHub - Mozilla Firefox\", \"width\": 1200, \"height\": 800 }\n            ]\n        },\n        {\n            \"name\": \"VSCode\",\n            \"has_windows\": true\n        }\n    ]\n}\n```\n\nThis tool provides valuable context about applications currently running on the user's system, which can help with providing more relevant assistance.\n\n#### get_available_windows\n\nReturns detailed information about all available windows currently displayed on the user's screen.\n\n```json\n{}\n```\n\n**Returns:**\n\n```json\n{\n    \"success\": true,\n    \"platform\": \"macos\",\n    \"count\": 8,\n    \"windows\": [\n        {\n            \"id\": 42,\n            \"title\": \"Document.txt - Notepad\",\n            \"app\": \"Notepad\",\n            \"visible\": true\n        },\n        {\n            \"title\": \"Terminal\",\n            \"app\": \"Terminal\",\n            \"visible\": true,\n            \"active\": true\n        }\n    ]\n}\n```\n\nThis tool helps understand what's visible on the user's screen and can be used for context-aware assistance.\n\n#### capture_screenshot\n\nCaptures a screenshot of the user's screen or a specific window.\n\n```json\n{\n    \"output_path\": \"screenshots/capture.png\",\n    \"capture_mode\": {\n        \"type\": \"named_window\",\n        \"window_name\": \"Visual Studio Code\"\n    }\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| output_path | string | No | Path where the screenshot should be saved (default: generated path) |\n| capture_mode | object | No | Specifies what to capture |\n| capture_mode.type | string | No | Type of screenshot: 'full', 'active_window', or 'named_window' (default: 'full') |\n| capture_mode.window_name | string | No | Name of window to capture (required when type is 'named_window') |\n\n**Returns:**\n\n```json\n{\n    \"success\": true,\n    \"path\": \"/path/to/screenshots/capture.png\"\n}\n```\n\nThis tool captures screenshots for visualization, debugging, or context-aware assistance.\n\n#### read_image_file\n\nReads an image file from the file system and returns its contents as a base64-encoded string.\n\n```json\n{\n    \"path\": \"images/logo.png\"\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| path | string | Yes | Path to the image file to read |\n| max_size | integer | No | Maximum file size in bytes (default: 100MB) |\n\n**Returns:**\nBase64-encoded image data that can be displayed or processed.\n\nThis tool supports common image formats like PNG, JPEG, GIF, and WebP, and automatically resizes images for optimal viewing.\n\n### Web Tools\n\n#### web_fetch\n\nFetches content from a URL and optionally saves it to a file.\n\n```json\n{\n    \"url\": \"https://api.github.com/users/octocat\",\n    \"headers\": {\n        \"Accept\": \"application/json\"\n    },\n    \"timeout\": 15,\n    \"save_to_file\": \"downloads/octocat.json\",\n    \"convert_html_to_markdown\": true\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| url | string | Yes | URL to fetch content from (http/https only) |\n| headers | object | No | Optional HTTP headers to include in the request |\n| timeout | integer | No | Maximum time to wait for response (default: 10s) |\n| save_to_file | string | No | Path to save response content (within allowed directory) |\n| convert_html_to_markdown | boolean | No | When true, converts HTML content to markdown for better readability (default: true) |\n\n**Returns:**\nResponse content as text with HTTP status code and size information. For binary content, returns metadata and saves to file if requested. When convert_html_to_markdown is enabled, HTML content is automatically converted to markdown format for better readability.\n\nThis tool can be used to access web APIs, fetch documentation, or download content from the web while respecting size limits (10MB max) and security constraints.\n\n#### web_search\n\nPerforms a robust web search using multiple search engines and returns concise, relevant results.\n\n```json\n{\n    \"query\": \"latest python release features\",\n    \"num_results\": 8,\n    \"convert_html_to_markdown\": true,\n    \"search_engine\": \"bing\"\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| query | string | Yes | The search query to process. Be specific for better results. |\n| num_results | integer | No | Maximum number of search results to return (default: 10, max: 20) |\n| convert_html_to_markdown | boolean | No | When true, content will be converted from HTML to markdown for better readability (default: true) |\n| search_engine | string | No | Specifies which search engine to use: \"auto\" (default), \"bing\", or \"duckduckgo\" |\n\n**Returns:**\nA list of search results formatted in markdown, including titles, URLs, and snippets for each result. Results are deduplicated and organized hierarchically for easy reading.\n\nThis tool uses a multi-engine approach that tries different search engines with various parsing strategies to ensure reliable results. You can specify a preferred engine, but some engines may block automated access, in which case the tool will fall back to alternative engines when \"auto\" is selected.\n\n### Utility Tools\n\n#### batch_tools\n\nExecute multiple tool invocations in a single request with parallel execution when possible.\n\n```json\n{\n    \"description\": \"Setup new project\",\n    \"sequential\": true,\n    \"invocations\": [\n        {\n            \"tool\": \"create_directory\",\n            \"arguments\": {\n                \"path\": \"src\"\n            }\n        },\n        {\n            \"tool\": \"write_file\",\n            \"arguments\": {\n                \"path\": \"README.md\",\n                \"content\": \"# New Project\\n\\nThis is a new project.\"\n            }\n        },\n        {\n            \"tool\": \"execute_shell_script\",\n            \"arguments\": {\n                \"script\": \"git init\"\n            }\n        }\n    ]\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| description | string | Yes | Short description of the batch operation |\n| sequential | boolean | No | Whether to run tools in sequence (default: false) |\n| invocations | array | Yes | List of tool invocations to execute |\n| invocations[].tool | string | Yes | Name of the tool to invoke |\n| invocations[].arguments | object | Yes | Arguments for the specified tool |\n\n**Returns:**\nCombined results from all tool invocations, grouped by tool with success/error status for each. Results are presented in the original invocation order with clear section headers.\n\nThis tool provides efficient execution of multiple operations in a single request. When `sequential` is false (default), tools are executed in parallel for better performance. When `sequential` is true, tools are executed in order, and if any tool fails, execution stops.\n\n**IMPORTANT**: All tools in the batch execute in the same working directory context. If a tool creates a directory and a subsequent tool needs to work inside that directory, you must either:\n\n1. Use paths relative to the current working directory (e.g., \"project/src\" rather than just \"src\"), or\n2. Include an explicit tool invocation to change directories using `update_allowed_directory`\n\n#### think\n\nA tool for complex reasoning and brainstorming without making changes to the repository.\n\n```json\n{\n    \"thought\": \"Let me analyze the performance issue in the codebase:\\n\\n## Root Cause Analysis\\n\\n1. The database query is inefficient because:\\n   - It doesn't use proper indexing\\n   - It fetches more columns than needed\\n   - The JOIN operation is unnecessarily complex\\n\\n## Potential Solutions\\n\\n1. **Add database indexes**:\\n   - Create an index on the user_id column\\n   - Create a composite index on (created_at, status)\\n\\n2. **Optimize the query**:\\n   - Select only necessary columns\\n   - Rewrite the JOIN using a subquery\\n   - Add LIMIT clause for pagination\\n\\n3. **Add caching layer**:\\n   - Cache frequent queries using Redis\\n   - Implement cache invalidation strategy\\n\\nAfter weighing the options, solution #2 seems to be the simplest to implement with the highest impact.\"\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| thought | string | Yes | Your detailed thoughts, analysis or reasoning process |\n\n**Returns:**\nYour thoughts formatted as markdown, with a note indicating this was a thinking exercise.\n\nThis tool is useful for thinking through complex problems, brainstorming solutions, or laying out implementation plans without making any actual changes. It's a great way to document your reasoning process, evaluate different approaches, or plan out a multi-step strategy before taking action.\n\n### Code Execution\n\n#### execute_code\n\nExecutes code in various programming languages with safety measures and restrictions.\n\n```json\n{\n    \"language\": \"python\",\n    \"code\": \"print('Hello, World!')\",\n    \"timeout\": 5\n}\n```\n\n**Supported Languages:**\n\n-   Python (python3)\n-   JavaScript (Node.js)\n-   Ruby\n-   PHP\n-   Go\n-   Rust\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| language | string | Yes | Programming language to use |\n| code | string | Yes | Code to execute |\n| timeout | integer | No | Maximum execution time (default: 5s) |\n\n**Requirements:**\n\n-   Respective language runtimes must be installed\n-   Commands must be available in system PATH\n-   Proper permissions for temporary file creation\n\n⚠️ **Security Warning:**\nThis tool executes arbitrary code on your system. Always:\n\n1. Review code thoroughly before execution\n2. Understand the code's purpose and expected outcome\n3. Never execute untrusted code\n4. Be aware of potential system impacts\n5. Monitor execution output\n\n#### execute_shell_script\n\nExecutes shell scripts (bash/sh) with safety measures and restrictions.\n\n```json\n{\n    \"script\": \"echo \\\"Current directory:\\\" && pwd\",\n    \"timeout\": 300\n}\n```\n\n**Parameters:**\n| Parameter | Type | Required | Description |\n|-----------|---------|----------|---------------------------------------|\n| script | string | Yes | Shell script to execute |\n| timeout | integer | No | Maximum execution time (default: 300s, max: 600s) |\n\n**Features:**\n\n-   Uses /bin/sh for maximum compatibility across systems\n-   Executes within the allowed directory\n-   Separate stdout and stderr output\n-   Proper error handling and timeout controls\n\n⚠️ **Security Warning:**\nThis tool executes arbitrary shell commands on your system. Always:\n\n1. Review the script thoroughly before execution\n2. Understand the script's purpose and expected outcome\n3. Never execute untrusted scripts\n4. Be aware of potential system impacts\n5. Monitor execution output\n\n### Todo Tools\n\nThe todo tools provide sequential task management capabilities for workspace-first development workflows. Tasks are executed in order without priority systems, ensuring structured progress through development phases.\n\n#### todo_read\n\nRead the current todo list for the workspace.\n\n```json\n{}\n```\n\n**Returns:**\n```json\n{\n  \"todos\": [\n    {\n      \"id\": \"abc123\",\n      \"content\": \"Implement user authentication\",\n      \"status\": \"in_progress\",\n      \"metadata\": {\n        \"custom_key\": \"custom_value\"\n      },\n      \"created_at\": \"2023-10-01T10:00:00Z\",\n      \"updated_at\": \"2023-10-01T11:30:00Z\"\n    }\n  ],\n  \"count\": 1,\n  \"workspace\": \"/path/to/workspace\"\n}\n```\n\n#### todo_write\n\nReplace the entire todo list for sequential execution workflow. Tasks are executed in array order, building upon previous work.\n\n```json\n{\n  \"todos\": [\n    {\n      \"id\": \"task1\",\n      \"content\": \"Set up database schema\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"task2\", \n      \"content\": \"Create API endpoints\",\n      \"status\": \"pending\",\n      \"metadata\": {\n        \"custom_key\": \"custom_value\"\n      }\n    }\n  ]\n}\n```\n\n**Sequential Workflow Rules:**\n- Each todo must have unique ID\n- Only one task can be \"in_progress\" at a time (sequential execution)\n- Tasks execute in array order - no priority system\n- Required fields: id, content, status\n- Status values: \"pending\", \"in_progress\", \"completed\"\n- Workspace-first: Todo management is mandatory for all workspace operations\n\n#### todo_update\n\nUpdate a specific todo item by ID for sequential workflow progression.\n\n```json\n{\n  \"todo_id\": \"task1\",\n  \"updates\": {\n    \"status\": \"in_progress\",\n    \"metadata\": {\n        \"new_key\": \"new_value\"\n    }\n  }\n}\n```\n\n**Returns:**\n```json\n{\n  \"success\": true,\n  \"updated_todo\": {\n    \"id\": \"task1\",\n    \"content\": \"Set up database schema\",\n    \"status\": \"in_progress\",\n    \"updated_at\": \"2023-10-01T12:00:00Z\",\n    \"metadata\": {\n        \"new_key\": \"new_value\"\n    }\n  },\n  \"counts\": {\n    \"pending\": 1,\n    \"in_progress\": 1,\n    \"completed\": 0,\n    \"total\": 2\n  },\n  \"workspace\": \"/path/to/workspace\"\n}\n```\n\nThe todo system maintains separate sequential task lists for each workspace, enforcing mandatory usage for all workspace operations. Tasks execute in order, building upon previous work without priority-based scheduling.\n\n## Configuration\n\nConfiguration file: `~/.skydeckai_code/config.json`\n\n```json\n{\n    \"allowed_directory\": \"/path/to/workspace\"\n}\n```\n\n## Debugging\n\nUse MCP Inspector for debugging:\n\n```bash\nnpx @modelcontextprotocol/inspector run\n```\n\n## Security\n\n-   Operations restricted to configured allowed directory\n-   Path traversal prevention\n-   File permission preservation\n-   Safe operation handling\n\n## Upcoming Features\n\n-   GitHub tools:\n    -   PR Description Generator\n    -   Code Review\n    -   Actions Manager\n-   Pivotal Tracker tools:\n    -   Story Generator\n    -   Story Manager\n\n## Development Status\n\nCurrently in active development. Features and API may change.\n\n## License\n\nApache License 2.0 - see [LICENSE](LICENSE)\n\n[![Star History Chart](https://api.star-history.com/svg?repos=skydeckai/skydeckai-code&type=Date)](https://www.star-history.com/#skydeckai/skydeckai-code&Date)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "code",
        "llms",
        "skydeckai code",
        "llms execute",
        "coding agents"
      ],
      "category": "code-execution"
    },
    "stefanskiasan--semgrep-mcp-server": {
      "owner": "stefanskiasan",
      "name": "semgrep-mcp-server",
      "url": "https://github.com/stefanskiasan/semgrep-mcp-server",
      "imageUrl": "https://github.com/stefanskiasan.png",
      "description": "Integrates static code analysis capabilities into development environments, allowing for the execution of Semgrep scans and management of Semgrep rules through the MCP protocol.",
      "stars": 1,
      "forks": 4,
      "license": "MIT License",
      "language": "JavaScript",
      "updated_at": "2025-02-10T03:07:32Z",
      "readme_content": "# Semgrep Server\n\nEin Model Context Protocol (MCP) Server für die Integration von Semgrep in die Entwicklungsumgebung. Dieser Server ermöglicht die Durchführung von statischen Code-Analysen und die Verwaltung von Semgrep-Regeln direkt über das MCP-Protokoll.\n\n## Installation\n\n```bash\n# Repository klonen\ngit clone [repository-url]\ncd semgrep-server\n\n# Abhängigkeiten installieren\nnpm install\n\n# Server bauen\nnpm run build\n```\n\n## Verwendung\n\nDer Server kann auf folgende Weise gestartet werden:\n\n```bash\n# Produktionsmodus\nnpm start\n\n# Entwicklungsmodus\nnpm run dev\n```\n\n## Verfügbare Tools\n\nDer Server stellt folgende MCP-Tools zur Verfügung:\n\n- `scan_directory`: Führt einen Semgrep-Scan in einem Verzeichnis aus\n- `list_rules`: Listet verfügbare Semgrep-Regeln auf\n- `analyze_results`: Analysiert die Scan-Ergebnisse\n- `create_rule`: Erstellt eine neue Semgrep-Regel\n- `filter_results`: Filtert Scan-Ergebnisse nach verschiedenen Kriterien\n- `export_results`: Exportiert Scan-Ergebnisse in verschiedene Formate\n- `compare_results`: Vergleicht zwei Scan-Ergebnisse\n\n## Entwicklung\n\nDas Projekt ist in TypeScript geschrieben und verwendet das MCP SDK für die Server-Implementierung. \n\n### Projektstruktur\n\n```\nsemgrep-server/\n├── src/           # Quellcode\n├── build/         # Kompilierte JavaScript-Dateien\n├── test.js        # Testdateien\n└── test-rule.yaml # Beispiel Semgrep-Regel\n```\n\n### Abhängigkeiten\n\n- Node.js & npm\n- TypeScript\n- MCP SDK\n- Axios für HTTP-Anfragen\n\n## Lizenz\n\nDieses Projekt steht unter der ISC-Lizenz. Weitere Details finden Sie in der [LICENSE](LICENSE) Datei.",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "semgrep",
        "llms",
        "execution",
        "llms execute",
        "execution semgrep",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "tumf--mcp-shell-server": {
      "owner": "tumf",
      "name": "mcp-shell-server",
      "url": "https://github.com/tumf/mcp-shell-server",
      "imageUrl": "https://github.com/tumf.png",
      "description": "Execute shell commands securely by utilizing a whitelist, with the ability to provide standard input and receive comprehensive output from commands.",
      "stars": 140,
      "forks": 39,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-09-29T16:16:44Z",
      "readme_content": "# MCP Shell Server\n\n[![codecov](https://codecov.io/gh/tumf/mcp-shell-server/branch/main/graph/badge.svg)](https://codecov.io/gh/tumf/mcp-shell-server)\n[![smithery badge](https://smithery.ai/badge/mcp-shell-server)](https://smithery.ai/server/mcp-shell-server)\n\n[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/tumf-mcp-shell-server-badge.png)](https://mseep.ai/app/tumf-mcp-shell-server)\n\nA secure shell command execution server implementing the Model Context Protocol (MCP). This server allows remote execution of whitelisted shell commands with support for stdin input.\n\n<a href=\"https://glama.ai/mcp/servers/rt2d4pbn22\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/rt2d4pbn22/badge\" alt=\"mcp-shell-server MCP server\" /></a>\n\n<a href=\"https://glama.ai/mcp/servers/rt2d4pbn22\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/rt2d4pbn22/badge\" alt=\"mcp-shell-server MCP server\" /></a>\n\n## Features\n\n* **Secure Command Execution**: Only whitelisted commands can be executed\n* **Standard Input Support**: Pass input to commands via stdin\n* **Comprehensive Output**: Returns stdout, stderr, exit status, and execution time\n* **Shell Operator Safety**: Validates commands after shell operators (; , &&, ||, |)\n* **Timeout Control**: Set maximum execution time for commands\n\n## MCP client setting in your Claude.app\n\n### Published version\n\n```shell\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"shell\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-shell-server\"\n      ],\n      \"env\": {\n        \"ALLOW_COMMANDS\": \"ls,cat,pwd,grep,wc,touch,find\"\n      }\n    },\n  }\n}\n```\n\n### Local version\n\n#### Configuration\n\n```shell\ncode ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"shell\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \".\",\n        \"run\",\n        \"mcp-shell-server\"\n      ],\n      \"env\": {\n        \"ALLOW_COMMANDS\": \"ls,cat,pwd,grep,wc,touch,find\"\n      }\n    },\n  }\n}\n```\n\n#### Installation\n\n### Installing via Smithery\n\nTo install Shell Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-shell-server):\n\n```bash\nnpx -y @smithery/cli install mcp-shell-server --client claude\n```\n\n### Manual Installation\n\n### Installing via Smithery\n\nTo install Shell Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-shell-server):\n\n```bash\nnpx -y @smithery/cli install mcp-shell-server --client claude\n```\n\n### Manual Installation\n\n```bash\npip install mcp-shell-server\n```\n\n### Installing via Smithery\n\nTo install Shell Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/mcp-shell-server):\n\n```bash\nnpx -y @smithery/cli install mcp-shell-server --client claude\n```\n\n## Usage\n\n### Starting the Server\n\n```bash\nALLOW_COMMANDS=\"ls,cat,echo\" uvx mcp-shell-server\n# Or using the alias\nALLOWED_COMMANDS=\"ls,cat,echo\" uvx mcp-shell-server\n```\n\nThe `ALLOW_COMMANDS` (or its alias `ALLOWED_COMMANDS` ) environment variable specifies which commands are allowed to be executed. Commands can be separated by commas with optional spaces around them.\n\nValid formats for ALLOW_COMMANDS or ALLOWED_COMMANDS:\n\n```bash\nALLOW_COMMANDS=\"ls,cat,echo\"          # Basic format\nALLOWED_COMMANDS=\"ls ,echo, cat\"      # With spaces (using alias)\nALLOW_COMMANDS=\"ls,  cat  , echo\"     # Multiple spaces\n```\n\n### Request Format\n\n```python\n# Basic command execution\n{\n    \"command\": [\"ls\", \"-l\", \"/tmp\"]\n}\n\n# Command with stdin input\n{\n    \"command\": [\"cat\"],\n    \"stdin\": \"Hello, World!\"\n}\n\n# Command with timeout\n{\n    \"command\": [\"long-running-process\"],\n    \"timeout\": 30  # Maximum execution time in seconds\n}\n\n# Command with working directory and timeout\n{\n    \"command\": [\"grep\", \"-r\", \"pattern\"],\n    \"directory\": \"/path/to/search\",\n    \"timeout\": 60\n}\n```\n\n### Response Format\n\nSuccessful response:\n\n```json\n{\n    \"stdout\": \"command output\",\n    \"stderr\": \"\",\n    \"status\": 0,\n    \"execution_time\": 0.123\n}\n```\n\nError response:\n\n```json\n{\n    \"error\": \"Command not allowed: rm\",\n    \"status\": 1,\n    \"stdout\": \"\",\n    \"stderr\": \"Command not allowed: rm\",\n    \"execution_time\": 0\n}\n```\n\n## Security\n\nThe server implements several security measures:\n\n1. **Command Whitelisting**: Only explicitly allowed commands can be executed\n2. **Shell Operator Validation**: Commands after shell operators (;, &&, ||, |) are also validated against the whitelist\n3. **No Shell Injection**: Commands are executed directly without shell interpretation\n\n## Development\n\n### Setting up Development Environment\n\n1. Clone the repository\n\n```bash\ngit clone https://github.com/yourusername/mcp-shell-server.git\ncd mcp-shell-server\n```\n\n2. Install dependencies including test requirements\n\n```bash\npip install -e \".[test]\"\n```\n\n### Running Tests\n\n```bash\npytest\n```\n\n## API Reference\n\n### Request Arguments\n\n| Field     | Type       | Required | Description                                   |\n|-----------|------------|----------|-----------------------------------------------|\n| command   | string[]   | Yes      | Command and its arguments as array elements   |\n| stdin     | string     | No       | Input to be passed to the command            |\n| directory | string     | No       | Working directory for command execution       |\n| timeout   | integer    | No       | Maximum execution time in seconds             |\n\n### Response Fields\n\n| Field           | Type    | Description                                |\n|----------------|---------|---------------------------------------------|\n| stdout         | string  | Standard output from the command           |\n| stderr         | string  | Standard error output from the command     |\n| status         | integer | Exit status code                           |\n| execution_time | float   | Time taken to execute (in seconds)         |\n| error          | string  | Error message (only present if failed)     |\n\n## Requirements\n\n* Python 3.11 or higher\n* mcp>=1.1.0\n\n## License\n\nMIT License - See LICENSE file for details\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "tumf",
        "llms execute",
        "execution servers",
        "commands securely"
      ],
      "category": "code-execution"
    },
    "twolven--mcp-codesavant": {
      "owner": "twolven",
      "name": "mcp-codesavant",
      "url": "https://github.com/twolven/mcp-codesavant",
      "imageUrl": "https://github.com/twolven.png",
      "description": "CodeSavant enables code manipulation and execution across various programming languages while maintaining version control and change history. It supports reading, writing, executing code, and searching within code files.",
      "stars": 9,
      "forks": 5,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-07-20T19:12:51Z",
      "readme_content": "# MCP-CodeSavant\n\n**⚠️ PROJECT STATUS: OBSOLETE**\n\nThis project has been superseded by modern coding agents that natively provide the same capabilities (code manipulation, execution, version control) without requiring a separate MCP server.\n\n## Original Purpose\n\nCodeSavant was a Model Context Protocol (MCP) server designed to provide code manipulation, execution, and version control capabilities to AI assistants. It allowed reading, writing, and executing code while maintaining a history of changes.\n\n## Why This Project is No Longer Needed\n\nRecent advances in coding agents have made this MCP server redundant. Modern coding agents now include built-in capabilities for:\n- Direct file manipulation with diff editing\n- Multi-language code execution\n- Version control and change tracking\n- Shell command execution\n- All the features this server provided\n\n## Archive Notice\n\nThis repository is maintained for historical reference only. For current projects requiring code manipulation capabilities, consider using modern coding agents that provide these features natively.\n\n## Original Features\n\nFor historical reference, MCP-CodeSavant provided:\n- Read and write code files with line-specific operations\n- Execute code in multiple programming languages (Python, Node.js)\n- Execute shell commands in a controlled environment\n- Track and manage code changes with version control\n- Search within code files\n- Revert to previous versions of code\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\nTodd Wolven - (https://github.com/twolven)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "codesavant",
        "llms",
        "coding",
        "llms execute",
        "mcp codesavant",
        "code execution"
      ],
      "category": "code-execution"
    },
    "wonderwhy-er--DesktopCommanderMCP": {
      "owner": "wonderwhy-er",
      "name": "DesktopCommanderMCP",
      "url": "https://github.com/wonderwhy-er/DesktopCommanderMCP",
      "imageUrl": "https://github.com/wonderwhy-er.png",
      "description": "Execute terminal commands, manage processes, and perform advanced file editing tasks, including text replacements and file rewrites. Enhance development workflows by automating repetitive tasks and running processes efficiently.",
      "stars": 4611,
      "forks": 511,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-10-04T08:03:00Z",
      "readme_content": "# Desktop Commander MCP\n### Search, update, manage files and run terminal commands with AI\n\n[![npm downloads](https://img.shields.io/npm/dw/@wonderwhy-er/desktop-commander)](https://www.npmjs.com/package/@wonderwhy-er/desktop-commander)\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/wonderwhy-er/DesktopCommanderMCP)](https://archestra.ai/mcp-catalog/wonderwhy-er__desktopcommandermcp)\n[![smithery badge](https://smithery.ai/badge/@wonderwhy-er/desktop-commander)](https://smithery.ai/server/@wonderwhy-er/desktop-commander)\n[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-support-yellow.svg)](https://www.buymeacoffee.com/wonderwhyer)\n\n\n[![Discord](https://img.shields.io/badge/Join%20Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/kQ27sNnZr7)\n\n\nWork with code and text, run processes, and automate tasks, going far beyond other AI editors - without API token costs.\n\n\n![Desktop Commander MCP](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/docs/vertical_video_mobile.mp4)\n\n<a href=\"https://glama.ai/mcp/servers/zempur9oh4\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/zempur9oh4/badge\" alt=\"Desktop Commander MCP\" />\n</a>\n\n## Table of Contents\n- [Features](#features)\n- [How to install](#how-to-install)\n- [Getting Started](#getting-started)\n- [Usage](#usage)\n- [Handling Long-Running Commands](#handling-long-running-commands)\n- [Work in Progress and TODOs](#roadmap)\n- [Sponsors and Supporters](#support-desktop-commander)\n- [Website](#website)\n- [Media](#media)\n- [Testimonials](#testimonials)\n- [Frequently Asked Questions](#frequently-asked-questions)\n- [Contributing](#contributing)\n- [License](#license)\n\nAll of your AI development tools in one place.\nDesktop Commander puts all dev tools in one chat.\nExecute long-running terminal commands on your computer and manage processes through Model Context Protocol (MCP). Built on top of [MCP Filesystem Server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) to provide additional search and replace file editing capabilities.\n\n## Features\n\n- **Enhanced terminal commands with interactive process control**\n- **Execute code in memory (Python, Node.js, R) without saving files**\n- **Instant data analysis - just ask to analyze CSV/JSON files**\n- **Interact with running processes (SSH, databases, development servers)**\n- Execute terminal commands with output streaming\n- Command timeout and background execution support\n- Process management (list and kill processes)\n- Session management for long-running commands\n- Server configuration management:\n  - Get/set configuration values\n  - Update multiple settings at once\n  - Dynamic configuration changes without server restart\n- Full filesystem operations:\n  - Read/write files\n  - Create/list directories\n  - Move files/directories\n  - Search files\n  - Get file metadata\n  - **Negative offset file reading**: Read from end of files using negative offset values (like Unix tail)\n- Code editing capabilities:\n  - Surgical text replacements for small changes\n  - Full file rewrites for major changes\n  - Multiple file support\n  - Pattern-based replacements\n  - vscode-ripgrep based recursive code or text search in folders\n- Comprehensive audit logging:\n  - All tool calls are automatically logged\n  - Log rotation with 10MB size limit\n  - Detailed timestamps and arguments\n\n## How to install\n\nDesktop Commander offers multiple installation methods to fit different user needs and technical requirements.\n\n> **📋 Update & Uninstall Information:** Before choosing an installation option, note that **only Options 1, 2, 3, and 6 have automatic updates**. Options 4 and 5 require manual updates. See the sections below for update and uninstall instructions for each option.\n\n### Option 1: Install through npx ⭐ **Auto-Updates** **Requires Node.js**\nJust run this in terminal:\n```\nnpx @wonderwhy-er/desktop-commander@latest setup\n```\n\nFor debugging mode (allows Node.js inspector connection):\n```\nnpx @wonderwhy-er/desktop-commander@latest setup --debug\n```\n\n**Command line options during setup:**\n- `--debug`: Enable debugging mode for Node.js inspector\n- `--no-onboarding`: Disable onboarding prompts for new users\n\nRestart Claude if running.\n\n**✅ Auto-Updates:** Yes - automatically updates when you restart Claude  \n**🔄 Manual Update:** Run the setup command again  \n**🗑️ Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove`\n\n### Option 2: Using bash script installer (macOS) ⭐ **Auto-Updates** **Installs Node.js if needed**\nFor macOS users, you can use our automated bash installer which will check your Node.js version, install it if needed, and automatically configure Desktop Commander:\n```\ncurl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install.sh | bash\n```\nThis script handles all dependencies and configuration automatically for a seamless setup experience.\n\n**✅ Auto-Updates:** Yes - requires manual updates  \n**🔄 Manual Update:** Re-run the bash installer command above  \n**🗑️ Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove`\n\n### Option 3: Installing via Smithery ⭐ **Auto-Updates** **Requires Node.js**\n\nTo install Desktop Commander for Claude Desktop via [Smithery](https://smithery.ai/server/@wonderwhy-er/desktop-commander):\n\n1. **Visit the Smithery page:** https://smithery.ai/server/@wonderwhy-er/desktop-commander\n2. **Login to Smithery** if you haven't already\n3. **Select your client** (Claude Desktop) on the right side\n4. **Install with the provided key** that appears after selecting your client\n5. **Restart Claude Desktop**\n\nThe old command-line installation method is no longer supported. Please use the web interface above for the most reliable installation experience.\n\n**✅ Auto-Updates:** Yes - automatically updates when you restart Claude  \n**🔄 Manual Update:** Visit the Smithery page and reinstall  \n\n### Option 4: Add to claude_desktop_config manually ⭐ **Auto-Updates** **Requires Node.js**\nAdd this entry to your claude_desktop_config.json:\n\n- On Mac: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- On Linux: `~/.config/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"desktop-commander\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@wonderwhy-er/desktop-commander@latest\"\n      ]\n    }\n  }\n}\n```\nRestart Claude if running.\n\n**✅ Auto-Updates:** Yes - automatically updates when you restart Claude  \n**🔄 Manual Update:** Run the setup command again  \n**🗑️ Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove` or  remove the \"desktop-commander\" entry from your claude_desktop_config.json file\n\n### ### Option 5: Checkout locally ❌ **Manual Updates** **Requires Node.js** ❌ **Manual Updates** **Requires Node.js**\n1. Clone and build:\n```bash\ngit clone https://github.com/wonderwhy-er/DesktopCommanderMCP.git\ncd DesktopCommanderMCP\nnpm run setup\n```\nRestart Claude if running.\n\nThe setup command will:\n- Install dependencies\n- Build the server\n- Configure Claude's desktop app\n- Add MCP servers to Claude's config if needed\n\n**❌ Auto-Updates:** No - requires manual git updates  \n**🔄 Manual Update:** `cd DesktopCommanderMCP && git pull && npm run setup`  \n**🗑️ Uninstall:** Run `npx @wonderwhy-er/desktop-commander@latest remove` or remove the cloned directory and remove MCP server entry from Claude config\n\n### Option 6: Docker Installation 🐳 ⭐ **Auto-Updates** **No Node.js Required**\n\nPerfect for users who want complete or partial isolation or don't have Node.js installed. Desktop Commander runs in a sandboxed Docker container with a persistent work environment.\n\n#### Prerequisites\n- [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed **and running**\n- Claude Desktop app installed\n\n**Important:** Make sure Docker Desktop is fully started before running the installer.\n\n#### Automated Installation (Recommended)\n\n**macOS/Linux:**\n```bash\nbash <(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh)\n```\n\n**Windows PowerShell:**\n```powershell\n# Download and run the installer (one-liner)\niex ((New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1'))\n```\n\nThe automated installer will:\n- Check Docker installation\n- Pull the latest Docker image \n- Prompt you to select folders for mounting\n- Configure Claude Desktop automatically\n- Restart Claude if possible\n\n#### How Docker Persistence Works\nDesktop Commander creates a persistent work environment that remembers everything between sessions:\n- **Your development tools**: Any software you install (Node.js, Python, databases, etc.) stays installed\n- **Your configurations**: Git settings, SSH keys, shell preferences, and other personal configs are preserved  \n- **Your work files**: Projects and files in the workspace area persist across restarts\n- **Package caches**: Downloaded packages and dependencies are cached for faster future installs\n\nThink of it like having your own dedicated development computer that never loses your setup, but runs safely isolated from your main system.\n\n#### Manual Docker Configuration\n\nIf you prefer manual setup, add this to your claude_desktop_config.json:\n\n**Basic setup (no file access):**\n```json\n{\n  \"mcpServers\": {\n    \"desktop-commander-in-docker\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"mcp/desktop-commander:latest\"\n      ]\n    }\n  }\n}\n```\n\n**With folder mounting:**\n```json\n{\n  \"mcpServers\": {\n    \"desktop-commander-in-docker\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-v\", \"/Users/username/Desktop:/mnt/desktop\",\n        \"-v\", \"/Users/username/Documents:/mnt/documents\",\n        \"mcp/desktop-commander:latest\"\n      ]\n    }\n  }\n}\n```\n\n**Advanced folder mounting:**\n```json\n{\n  \"mcpServers\": {\n    \"desktop-commander-in-docker\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\",\n        \"-v\", \"dc-system:/usr\",\n        \"-v\", \"dc-home:/root\", \n        \"-v\", \"dc-workspace:/workspace\",\n        \"-v\", \"dc-packages:/var\",\n        \"-v\", \"/Users/username/Projects:/mnt/Projects\",\n        \"-v\", \"/Users/username/Downloads:/mnt/Downloads\",\n        \"mcp/desktop-commander:latest\"\n      ]\n    }\n  }\n}\n```\n\n#### Docker Benefits\n✅ **Controlled Isolation:** Runs in sandboxed environment with persistent development state\n✅ **No Node.js Required:** Everything included in the container\n✅ **Cross-Platform:** Same experience on all operating systems\n✅ **Persistent Environment:** Your tools, files, configs, and work survives restarts\n\n**✅ Auto-Updates:** Yes - `latest` tag automatically gets newer versions  \n**🔄 Manual Update:** `docker pull mcp/desktop-commander:latest` then restart Claude  \n\n#### Docker Management Commands\n\n**macOS/Linux:**\n\nCheck installation status:\n```bash\nbash <(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh) --status\n```\n\nReset all persistent data (removes all installed tools and configs):\n```bash\nbash <(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh) --reset\n```\n\n**Windows PowerShell:**\n\nCheck status:\n```powershell\n$script = (New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1'); & ([ScriptBlock]::Create(\"$script\")) -Status\n```\n\nReset all data:\n```powershell\n$script = (New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1'); & ([ScriptBlock]::Create(\"$script\")) -Reset\n```\n\nShow help:\n```powershell\n$script = (New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1'); & ([ScriptBlock]::Create(\"$script\")) -Help\n```\n\nVerbose output:\n```powershell\n$script = (New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.ps1'); & ([ScriptBlock]::Create(\"$script\")) -VerboseOutput\n```  \n\n#### Troubleshooting Docker Installation\nIf you broke the Docker container or need a fresh start:\n```bash\n# Reset and reinstall from scratch\nbash <(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh) --reset && bash <(curl -fsSL https://raw.githubusercontent.com/wonderwhy-er/DesktopCommanderMCP/refs/heads/main/install-docker.sh)\n```\nThis will completely reset your persistent environment and reinstall everything fresh with exception of not touching mounted folders\n\n## Updating & Uninstalling Desktop Commander\n\n### Automatic Updates (Options 1, 2, 3, 4 & 6)\n**Options 1 (npx), Option 2 (bash installer), 3 (Smithery), 4 (manual config), and 6 (Docker)** automatically update to the latest version whenever you restart Claude. No manual intervention needed.\n\n### Manual Updates (Option 5)\n- **Option 5 (local checkout):** `cd DesktopCommanderMCP && git pull && npm run setup`\n\n### Uninstalling Desktop Commander\n#### 🤖 Automatic Uninstallation (Recommended)\n\nThe easiest way to completely remove Desktop Commander:\n\n```bash\nnpx @wonderwhy-er/desktop-commander@latest remove\n```\n\nThis automatic uninstaller will:\n- ✅ Remove Desktop Commander from Claude's MCP server configuration\n- ✅ Create a backup of your Claude config before making changes\n- ✅ Provide guidance for complete package removal\n- ✅ Restore from backup if anything goes wrong\n\n#### 🔧 Manual Uninstallation\n\nIf the automatic uninstaller doesn't work or you prefer manual removal:\n\n##### Remove from Claude Configuration\n\n1. **Locate your Claude Desktop config file:**\n  - **macOS:** `~/Library/Application Support/Claude/claude_desktop_config.json`\n  - **Windows:** `%APPDATA%\\Claude\\claude_desktop_config.json`\n  - **Linux:** `~/.config/Claude/claude_desktop_config.json`\n\n2. **Edit the config file:**\n  - Open the file in a text editor\n  - Find and remove the `\"desktop-commander\"` entry from the `\"mcpServers\"` section\n  - Save the file\n\n  **Example - Remove this section:**\n  ```json\n  {\n      \"desktop-commander\": {\n        \"command\": \"npx\",\n        \"args\": [\"@wonderwhy-er/desktop-commander@latest\"]\n      }\n  }\n  ```\n\nClose and restart Claude Desktop to complete the removal.\n\n#### 🆘 Troubleshooting\n\n**If automatic uninstallation fails:**\n- Use manual uninstallation as a fallback\n\n**If Claude won't start after uninstalling:**\n- Restore the backup config file created by the uninstaller\n- Or manually fix the JSON syntax in your claude_desktop_config.json\n\n**Need help?**\n- Join our Discord community: https://discord.com/invite/kQ27sNnZr7\n\n## Getting Started\n\nOnce Desktop Commander is installed and Claude Desktop is restarted, you're ready to supercharge your Claude experience!\n\n### 🚀 New User Onboarding\n\nDesktop Commander includes intelligent onboarding to help you discover what's possible:\n\n**For New Users:** When you're just getting started (fewer than 10 successful commands), Claude will automatically offer helpful getting-started guidance and practical tutorials after you use Desktop Commander successfully.\n\n**Request Help Anytime:** You can ask for onboarding assistance at any time by simply saying:\n- *\"Help me get started with Desktop Commander\"*\n- *\"Show me Desktop Commander examples\"* \n- *\"What can I do with Desktop Commander?\"*\n\nClaude will then show you beginner-friendly tutorials and examples, including:\n- 📁 Organizing your Downloads folder automatically\n- 📊 Analyzing CSV/Excel files with Python\n- ⚙️ Setting up GitHub Actions CI/CD\n- 🔍 Exploring and understanding codebases\n- 🤖 Running interactive development environments\n\n## Usage\n\nThe server provides a comprehensive set of tools organized into several categories:\n\n### Available Tools\n\n| Category | Tool | Description |\n|----------|------|-------------|\n| **Configuration** | `get_config` | Get the complete server configuration as JSON (includes blockedCommands, defaultShell, allowedDirectories, fileReadLineLimit, fileWriteLineLimit, telemetryEnabled) |\n| | `set_config_value` | Set a specific configuration value by key. Available settings: <br>• `blockedCommands`: Array of shell commands that cannot be executed<br>• `defaultShell`: Shell to use for commands (e.g., bash, zsh, powershell)<br>• `allowedDirectories`: Array of filesystem paths the server can access for file operations (⚠️ terminal commands can still access files outside these directories)<br>• `fileReadLineLimit`: Maximum lines to read at once (default: 1000)<br>• `fileWriteLineLimit`: Maximum lines to write at once (default: 50)<br>• `telemetryEnabled`: Enable/disable telemetry (boolean) |\n| **Terminal** | `start_process` | Start programs with smart detection of when they're ready for input |\n| | `interact_with_process` | Send commands to running programs and get responses |\n| | `read_process_output` | Read output from running processes |\n| | `force_terminate` | Force terminate a running terminal session |\n| | `list_sessions` | List all active terminal sessions |\n| | `list_processes` | List all running processes with detailed information |\n| | `kill_process` | Terminate a running process by PID |\n| **Filesystem** | `read_file` | Read contents from local filesystem or URLs with line-based pagination (supports positive/negative offset and length parameters) |\n| | `read_multiple_files` | Read multiple files simultaneously |\n| | `write_file` | Write file contents with options for rewrite or append mode (uses configurable line limits) |\n| | `create_directory` | Create a new directory or ensure it exists |\n| | `list_directory` | Get detailed recursive listing of files and directories (supports depth parameter, default depth=2) |\n| | `move_file` | Move or rename files and directories |\n| | `start_search` | Start streaming search for files by name or content patterns (unified ripgrep-based search) |\n| | `get_more_search_results` | Get paginated results from active search with offset support |\n| | `stop_search` | Stop an active search gracefully |\n| | `list_searches` | List all active search sessions |\n| | `get_file_info` | Retrieve detailed metadata about a file or directory |\n| **Text Editing** | `edit_block` | Apply targeted text replacements with enhanced prompting for smaller edits (includes character-level diff feedback) |\n| **Analytics** | `get_usage_stats` | Get usage statistics for your own insight |\n| | `get_recent_tool_calls` | Get recent tool call history with arguments and outputs for debugging and context recovery |\n| | `give_feedback_to_desktop_commander` | Open feedback form in browser to provide feedback to Desktop Commander Team |\n\n### Quick Examples\n\n**Data Analysis:**\n```\n\"Analyze sales.csv and show top customers\" → Claude runs Python code in memory\n```\n\n**Remote Access:**\n```\n\"SSH to my server and check disk space\" → Claude maintains SSH session\n```\n\n**Development:**\n```\n\"Start Node.js and test this API\" → Claude runs interactive Node session\n```\n\n### Tool Usage Examples\n\nSearch/Replace Block Format:\n```\nfilepath.ext\n<<<<<<< SEARCH\ncontent to find\n=======\nnew content\n>>>>>>> REPLACE\n```\n\nExample:\n```\nsrc/main.js\n<<<<<<< SEARCH\nconsole.log(\"old message\");\n=======\nconsole.log(\"new message\");\n>>>>>>> REPLACE\n```\n\n### Enhanced Edit Block Features\n\nThe `edit_block` tool includes several enhancements for better reliability:\n\n1. **Improved Prompting**: Tool descriptions now emphasize making multiple small, focused edits rather than one large change\n2. **Fuzzy Search Fallback**: When exact matches fail, it performs fuzzy search and provides detailed feedback\n3. **Character-level Diffs**: Shows exactly what's different using `{-removed-}{+added+}` format\n4. **Multiple Occurrence Support**: Can replace multiple instances with `expected_replacements` parameter\n5. **Comprehensive Logging**: All fuzzy searches are logged for analysis and debugging\n\nWhen a search fails, you'll see detailed information about the closest match found, including similarity percentage, execution time, and character differences. All these details are automatically logged for later analysis using the fuzzy search log tools.\n\n### Docker Support\n\n### 🐳 Isolated Environment Usage\n\nDesktop Commander can be run in Docker containers for **complete isolation from your host system**, providing **zero risk to your computer**. This is perfect for testing, development, or when you want complete sandboxing.\n\n### Installation Instructions\n\n1. **Install Docker for Windows/Mac**\n   - Download and install Docker Desktop from [docker.com](https://www.docker.com/products/docker-desktop/)\n\n2. **Get Desktop Commander Docker Configuration**\n   - Visit: https://hub.docker.com/mcp/server/desktop-commander/manual\n   - **Option A:** Use the provided terminal command for automated setup\n   - **Option B:** Click \"Standalone\" to get the config JSON and add it manually to your Claude Desktop config\n ![docker-config.png](screenshots/docker-config.png)\n\n3. **Mount Your Machine Folders (Coming Soon)**\n   - Instructions on how to mount your local directories into the Docker container will be provided soon\n   - This will allow you to work with your files while maintaining complete isolation\n\n### Benefits of Docker Usage\n- **Complete isolation** from your host system\n- **Consistent environment** across different machines\n- **Easy cleanup** - just remove the container when done\n- **Perfect for testing** new features or configurations\n\n## URL Support\n- `read_file` can now fetch content from both local files and URLs\n- Example: `read_file` with `isUrl: true` parameter to read from web resources\n- Handles both text and image content from remote sources\n- Images (local or from URLs) are displayed visually in Claude's interface, not as text\n- Claude can see and analyze the actual image content\n- Default 30-second timeout for URL requests\n\n## Fuzzy Search Log Analysis (npm scripts)\n\nThe fuzzy search logging system includes convenient npm scripts for analyzing logs outside of the MCP environment:\n\n```bash\n# View recent fuzzy search logs\nnpm run logs:view -- --count 20\n\n# Analyze patterns and performance\nnpm run logs:analyze -- --threshold 0.8\n\n# Export logs to CSV or JSON\nnpm run logs:export -- --format json --output analysis.json\n\n# Clear all logs (with confirmation)\nnpm run logs:clear\n```\n\nFor detailed documentation on these scripts, see [scripts/README.md](scripts/README.md).\n\n## Fuzzy Search Logs\n\nDesktop Commander includes comprehensive logging for fuzzy search operations in the `edit_block` tool. When an exact match isn't found, the system performs a fuzzy search and logs detailed information for analysis.\n\n### What Gets Logged\n\nEvery fuzzy search operation logs:\n- **Search and found text**: The text you're looking for vs. what was found\n- **Similarity score**: How close the match is (0-100%)\n- **Execution time**: How long the search took\n- **Character differences**: Detailed diff showing exactly what's different\n- **File metadata**: Extension, search/found text lengths\n- **Character codes**: Specific character codes causing differences\n\n### Log Location\n\nLogs are automatically saved to:\n- **macOS/Linux**: `~/.claude-server-commander-logs/fuzzy-search.log`\n- **Windows**: `%USERPROFILE%\\.claude-server-commander-logs\\fuzzy-search.log`\n\n### What You'll Learn\n\nThe fuzzy search logs help you understand:\n1. **Why exact matches fail**: Common issues like whitespace differences, line endings, or character encoding\n2. **Performance patterns**: How search complexity affects execution time\n3. **File type issues**: Which file extensions commonly have matching problems\n4. **Character encoding problems**: Specific character codes that cause diffs\n\n## Audit Logging\n\nDesktop Commander now includes comprehensive logging for all tool calls:\n\n### What Gets Logged\n- Every tool call is logged with timestamp, tool name, and arguments (sanitized for privacy)\n- Logs are rotated automatically when they reach 10MB in size\n\n### Log Location\nLogs are saved to:\n- **macOS/Linux**: `~/.claude-server-commander/claude_tool_call.log`\n- **Windows**: `%USERPROFILE%\\.claude-server-commander\\claude_tool_call.log`\n\nThis audit trail helps with debugging, security monitoring, and understanding how Claude is interacting with your system.\n\n## Handling Long-Running Commands\n\nFor commands that may take a while:\n\n## Configuration Management\n\n### ⚠️ Important Security Warnings\n\n> **For comprehensive security information and vulnerability reporting**: See [SECURITY.md](SECURITY.md)\n\n1. **Known security limitations**: Directory restrictions and command blocking can be bypassed through various methods including symlinks, command substitution, and absolute paths or code execution\n\n2. **Always change configuration in a separate chat window** from where you're doing your actual work. Claude may sometimes attempt to modify configuration settings (like `allowedDirectories`) if it encounters filesystem access restrictions.\n\n3. **The `allowedDirectories` setting currently only restricts filesystem operations**, not terminal commands. Terminal commands can still access files outside allowed directories.\n\n4. **For production security**: Use the [Docker installation](#option-6-docker-installation-🐳-⭐-auto-updates-no-nodejs-required) which provides complete isolation from your host system.\n\n### Configuration Tools\n\nYou can manage server configuration using the provided tools:\n\n```javascript\n// Get the entire config\nget_config({})\n\n// Set a specific config value\nset_config_value({ \"key\": \"defaultShell\", \"value\": \"/bin/zsh\" })\n\n// Set multiple config values using separate calls\nset_config_value({ \"key\": \"defaultShell\", \"value\": \"/bin/bash\" })\nset_config_value({ \"key\": \"allowedDirectories\", \"value\": [\"/Users/username/projects\"] })\n```\n\nThe configuration is saved to `config.json` in the server's working directory and persists between server restarts.\n\n#### Understanding fileWriteLineLimit\n\nThe `fileWriteLineLimit` setting controls how many lines can be written in a single `write_file` operation (default: 50 lines). This limit exists for several important reasons:\n\n**Why the limit exists:**\n- **AIs are wasteful with tokens**: Instead of doing two small edits in a file, AIs may decide to rewrite the whole thing. We're trying to force AIs to do things in smaller changes as it saves time and tokens\n- **Claude UX message limits**: There are limits within one message and hitting \"Continue\" does not really work. What we're trying here is to make AI work in smaller chunks so when you hit that limit, multiple chunks have succeeded and that work is not lost - it just needs to restart from the last chunk\n\n**Setting the limit:**\n```javascript\n// You can set it to thousands if you want\nset_config_value({ \"key\": \"fileWriteLineLimit\", \"value\": 1000 })\n\n// Or keep it smaller to force more efficient behavior\nset_config_value({ \"key\": \"fileWriteLineLimit\", \"value\": 25 })\n```\n\n**Maximum value**: You can set it to thousands if you want - there's no technical restriction.\n\n**Best practices**:\n- Keep the default (50) to encourage efficient AI behavior and avoid token waste\n- The system automatically suggests chunking when limits are exceeded\n- Smaller chunks mean less work lost when Claude hits message limits\n\n### Best Practices\n\n1. **Create a dedicated chat for configuration changes**: Make all your config changes in one chat, then start a new chat for your actual work.\n\n2. **Be careful with empty `allowedDirectories`**: Setting this to an empty array (`[]`) grants access to your entire filesystem for file operations.\n\n3. **Use specific paths**: Instead of using broad paths like `/`, specify exact directories you want to access.\n\n4. **Always verify configuration after changes**: Use `get_config({})` to confirm your changes were applied correctly.\n\n## Command Line Options\n\nDesktop Commander supports several command line options for customizing behavior:\n\n### Disable Onboarding\n\nBy default, Desktop Commander shows helpful onboarding prompts to new users (those with fewer than 10 tool calls). You can disable this behavior:\n\n```bash\n# Disable onboarding for this session\nnode dist/index.js --no-onboarding\n\n# Or if using npm scripts\nnpm run start:no-onboarding\n\n# For npx installations, modify your claude_desktop_config.json:\n{\n  \"mcpServers\": {\n    \"desktop-commander\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@wonderwhy-er/desktop-commander@latest\",\n        \"--no-onboarding\"\n      ]\n    }\n  }\n}\n```\n\n**When onboarding is automatically disabled:**\n- When the MCP client name is set to \"desktop-commander\"\n- When using the `--no-onboarding` flag\n- After users have used onboarding prompts or made 10+ tool calls\n\n**Debug information:**\nThe server will log when onboarding is disabled: `\"Onboarding disabled via --no-onboarding flag\"`\n\n## Using Different Shells\n\nYou can specify which shell to use for command execution:\n\n```javascript\n// Using default shell (bash or system default)\nexecute_command({ \"command\": \"echo $SHELL\" })\n\n// Using zsh specifically\nexecute_command({ \"command\": \"echo $SHELL\", \"shell\": \"/bin/zsh\" })\n\n// Using bash specifically\nexecute_command({ \"command\": \"echo $SHELL\", \"shell\": \"/bin/bash\" })\n```\n\nThis allows you to use shell-specific features or maintain consistent environments across commands.\n\n1. `execute_command` returns after timeout with initial output\n2. Command continues in background\n3. Use `read_output` with PID to get new output\n4. Use `force_terminate` to stop if needed\n\n## Debugging\n\nIf you need to debug the server, you can install it in debug mode:\n\n```bash\n# Using npx\nnpx @wonderwhy-er/desktop-commander@latest setup --debug\n\n# Or if installed locally\nnpm run setup:debug\n```\n\nThis will:\n1. Configure Claude to use a separate \"desktop-commander\" server\n2. Enable Node.js inspector protocol with `--inspect-brk=9229` flag\n3. Pause execution at the start until a debugger connects\n4. Enable additional debugging environment variables\n\nTo connect a debugger:\n- In Chrome, visit `chrome://inspect` and look for the Node.js instance\n- In VS Code, use the \"Attach to Node Process\" debug configuration\n- Other IDEs/tools may have similar \"attach\" options for Node.js debugging\n\nImportant debugging notes:\n- The server will pause on startup until a debugger connects (due to the `--inspect-brk` flag)\n- If you don't see activity during debugging, ensure you're connected to the correct Node.js process\n- Multiple Node processes may be running; connect to the one on port 9229\n- The debug server is identified as \"desktop-commander-debug\" in Claude's MCP server list\n\nTroubleshooting:\n- If Claude times out while trying to use the debug server, your debugger might not be properly connected\n- When properly connected, the process will continue execution after hitting the first breakpoint\n- You can add additional breakpoints in your IDE once connected\n\n## Model Context Protocol Integration\n\nThis project extends the MCP Filesystem Server to enable:\n- Local server support in Claude Desktop\n- Full system command execution\n- Process management\n- File operations\n- Code editing with search/replace blocks\n\nCreated as part of exploring Claude MCPs: https://youtube.com/live/TlbjFDbl5Us\n\n## DONE\n- **20-05-2025 v0.1.40 Release** - Added audit logging for all tool calls, improved line-based file operations, enhanced edit_block with better prompting for smaller edits, added explicit telemetry opt-out prompting \n- **05-05-2025 Fuzzy Search Logging** - Added comprehensive logging system for fuzzy search operations with detailed analysis tools, character-level diffs, and performance metrics to help debug edit_block failures\n- **29-04-2025 Telemetry Opt Out through configuration** - There is now setting to disable telemetry in config, ask in chat\n- **23-04-2025 Enhanced edit functionality** - Improved format, added fuzzy search and multi-occurrence replacements, should fail less and use edit block more often\n- **16-04-2025 Better configurations** - Improved settings for allowed paths, commands and shell environments\n- **14-04-2025 Windows environment fixes** - Resolved issues specific to Windows platforms\n- **14-04-2025 Linux improvements** - Enhanced compatibility with various Linux distributions\n- **12-04-2025 Better allowed directories and blocked commands** - Improved security and path validation for file read/write and terminal command restrictions.\nTerminal still can access files ignoring allowed directories.\n- **11-04-2025 Shell configuration** - Added ability to configure preferred shell for command execution\n- **07-04-2025 Added URL support** - `read_file` command can now fetch content from URLs\n- **28-03-2025 Fixed \"Watching /\" JSON error** - Implemented custom stdio transport to handle non-JSON messages and prevent server crashes\n- **25-03-2025 Better code search** ([merged](https://github.com/wonderwhy-er/ClaudeServerCommander/pull/17)) - Enhanced code exploration with context-aware results\n\n## Roadmap\n\nThe following features are currently being explored:\n\n- **Support for WSL** - Windows Subsystem for Linux integration\n- **Support for SSH** - Remote server command execution\n- **Better file support for formats like CSV/PDF**\n- **Terminal sandboxing for Mac/Linux/Windows for better security**\n- **File reading modes** - For example, allow reading HTML as plain text or markdown\n- **Interactive shell support** - ssh, node/python repl\n- **Improve large file reading and writing**\n\n## Support Desktop Commander\n\n<div align=\"center\">\n  <h3>📢 SUPPORT THIS PROJECT</h3>\n  <p><strong>Desktop Commander MCP is free and open source, but needs your support to thrive!</strong></p>\n  \n  <div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 10px; margin: 20px 0; border: 2px solid #007bff;\">\n    <p>Our philosophy is simple: we don't want you to pay for it if you're not successful. But if Desktop Commander contributes to your success, please consider contributing to ours.</p>\n    <p><strong>Ways to support:</strong></p>\n    <ul style=\"list-style-type: none; padding: 0;\">\n      <li>🌟 <a href=\"https://github.com/sponsors/wonderwhy-er\"><strong>GitHub Sponsors</strong></a> - Recurring support</li>\n      <li>☕ <a href=\"https://www.buymeacoffee.com/wonderwhyer\"><strong>Buy Me A Coffee</strong></a> - One-time contributions</li>\n      <li>💖 <a href=\"https://www.patreon.com/c/EduardsRuzga\"><strong>Patreon</strong></a> - Become a patron and support us monthly</li>\n      <li>⭐ <a href=\"https://github.com/wonderwhy-er/DesktopCommanderMCP\"><strong>Star on GitHub</strong></a> - Help others discover the project</li>\n    </ul>\n  </div>\n</div>\n\n\n### ❤️ Supporters Hall of Fame\n\nGenerous supporters are featured here. Thank you for helping make this project possible!\n\n<div align=\"center\">\n<table>\n  <tr>\n    <td align=\"center\">\n      <a href=\"https://github.com/jonrichards\">\n        <img src=\"https://github.com/jonrichards.png\" width=\"100px;\" alt=\"Jon Richards\"/>\n        <br />\n        <sub><b>Jon Richards</b></sub>\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://github.com/stepanic\">\n        <img src=\"https://github.com/stepanic.png\" width=\"100px;\" alt=\"Matija Stepanic\"/>\n        <br />\n        <sub><b>Matija Stepanic</b></sub>\n      </a>\n    </td>\n  </tr>\n</table>\n</div>\n\n<details>\n  <summary><strong>Why your support matters</strong></summary>\n  <p>Your support allows us to:</p>\n  <ul>\n    <li>Continue active development and maintenance</li>\n    <li>Add new features and integrations</li>\n    <li>Improve compatibility across platforms</li>\n    <li>Provide better documentation and examples</li>\n    <li>Build a stronger community around the project</li>\n  </ul>\n</details>\n\n## Website\n\nVisit our official website at [https://desktopcommander.app/](https://desktopcommander.app/) for the latest information, documentation, and updates.\n\n## Media\n\nLearn more about this project through these resources:\n\n### Article\n[Claude with MCPs replaced Cursor & Windsurf. How did that happen?](https://wonderwhy-er.medium.com/claude-with-mcps-replaced-cursor-windsurf-how-did-that-happen-c1d1e2795e96) - A detailed exploration of how Claude with Model Context Protocol capabilities is changing developer workflows.\n\n### Video\n[Claude Desktop Commander Video Tutorial](https://www.youtube.com/watch?v=ly3bed99Dy8) - Watch how to set up and use the Commander effectively.\n\n### Publication at AnalyticsIndiaMag\n[![analyticsindiamag.png](testemonials%2Fanalyticsindiamag.png)\nThis Developer Ditched Windsurf, Cursor Using Claude with MCPs](https://analyticsindiamag.com/ai-features/this-developer-ditched-windsurf-cursor-using-claude-with-mcps/)\n\n### Community\nJoin our [Discord server](https://discord.gg/kQ27sNnZr7) to get help, share feedback, and connect with other users.\n\n## Testimonials\n\n[![It's a life saver! I paid Claude + Cursor currently which I always feel it's kind of duplicated. This solves the problem ultimately. I am so happy. Thanks so much. Plus today Claude has added the web search support. With this MCP + Internet search, it writes the code with the latest updates. It's so good when Cursor doesn't work sometimes or all the fast requests are used.](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img.png) https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyyBt6_ShdDX_rIOad4AaABAg\n](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyyBt6_ShdDX_rIOad4AaABAg\n)\n\n[![This is the first comment I've ever left on a youtube video, THANK YOU! I've been struggling to update an old Flutter app in Cursor from an old pre null-safety version to a current version and implemented null-safety using Claude 3.7. I got most of the way but had critical BLE errors that I spent days trying to resolve with no luck. I tried Augment Code but it didn't get it either. I implemented your MCP in Claude desktop and was able to compare the old and new codebase fully, accounting for the updates in the code, and fix the issues in a couple of hours. A word of advice to people trying this, be sure to stage changes and commit when appropriate to be able to undo unwanted changes. Amazing!](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_1.png)\nhttps://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgztdHvDMqTb9jiqnf54AaABAg](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgztdHvDMqTb9jiqnf54AaABAg\n)\n\n[![Great! I just used Windsurf, bought license a week ago, for upgrading old fullstack socket project and it works many times good or ok but also many times runs away in cascade and have to revert all changes losing hundereds of cascade tokens. In just a week down to less than 100 tokens and do not want to buy only 300 tokens for 10$. This Claude MCP ,bought claude Pro finally needed but wanted very good reason to also have next to ChatGPT, and now can code as much as I want not worrying about token cost.\nAlso this is much more than code editing it is much more thank you for great video!](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_2.png)\nhttps://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyQFTmYLJ4VBwIlmql4AaABAg](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyQFTmYLJ4VBwIlmql4AaABAg)\n\n[![it is a great tool, thank you, I like using it, as it gives claude an ability to do surgical edits, making it more like a human developer.](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_3.png)\nhttps://www.youtube.com/watch?v=ly3bed99Dy8&lc=Ugy4-exy166_Ma7TH-h4AaABAg](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=Ugy4-exy166_Ma7TH-h4AaABAg)\n\n[![You sir are my hero. You've pretty much summed up and described my experiences of late, much better than I could have. Cursor and Windsurf both had me frustrated to the point where I was almost yelling at my computer screen. Out of whimsy, I thought to myself why not just ask Claude directly, and haven't looked back since.\nClaude first to keep my sanity in check, then if necessary, engage with other IDEs, frameworks, etc. I thought I was the only one, glad to see I'm not lol.\n33\n1](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_4.png)\nhttps://medium.com/@pharmx/you-sir-are-my-hero-62cff5836a3e](https://medium.com/@pharmx/you-sir-are-my-hero-62cff5836a3e)\n\nIf you find this project useful, please consider giving it a ⭐ star on GitHub! This helps others discover the project and encourages further development.\n\nWe welcome contributions from the community! Whether you've found a bug, have a feature request, or want to contribute code, here's how you can help:\n\n- **Found a bug?** Open an issue at [github.com/wonderwhy-er/DesktopCommanderMCP/issues](https://github.com/wonderwhy-er/DesktopCommanderMCP/issues)\n- **Have a feature idea?** Submit a feature request in the issues section\n- **Want to contribute code?** Fork the repository, create a branch, and submit a pull request\n- **Questions or discussions?** Start a discussion in the GitHub Discussions tab\n\nAll contributions, big or small, are greatly appreciated!\n\nIf you find this tool valuable for your workflow, please consider [supporting the project](https://www.buymeacoffee.com/wonderwhyer).\n\n## Frequently Asked Questions\n\nHere are answers to some common questions. For a more comprehensive FAQ, see our [detailed FAQ document](FAQ.md).\n\n### What is Desktop Commander?\nIt's an MCP tool that enables Claude Desktop to access your file system and terminal, turning Claude into a versatile assistant for coding, automation, codebase exploration, and more.\n\n### How is this different from Cursor/Windsurf?\nUnlike IDE-focused tools, Claude Desktop Commander provides a solution-centric approach that works with your entire OS, not just within a coding environment. Claude reads files in full rather than chunking them, can work across multiple projects simultaneously, and executes changes in one go rather than requiring constant review.\n\n### Do I need to pay for API credits?\nNo. This tool works with Claude Desktop's standard Pro subscription ($20/month), not with API calls, so you won't incur additional costs beyond the subscription fee.\n\n### Does Desktop Commander automatically update?\nYes, when installed through npx or Smithery, Desktop Commander automatically updates to the latest version when you restart Claude. No manual update process is needed.\n\n### What are the most common use cases?\n- Exploring and understanding complex codebases\n- Generating diagrams and documentation\n- Automating tasks across your system\n- Working with multiple projects simultaneously\n- Making surgical code changes with precise control\n\n### I'm having trouble installing or using the tool. Where can I get help?\nJoin our [Discord server](https://discord.gg/kQ27sNnZr7) for community support, check the [GitHub issues](https://github.com/wonderwhy-er/DesktopCommanderMCP/issues) for known problems, or review the [full FAQ](FAQ.md) for troubleshooting tips. You can also visit our [website FAQ section](https://desktopcommander.app#faq) for a more user-friendly experience. If you encounter a new issue, please consider [opening a GitHub issue](https://github.com/wonderwhy-er/DesktopCommanderMCP/issues/new) with details about your problem.\n\n### How do I report security vulnerabilities?\nPlease create a [GitHub Issue](https://github.com/wonderwhy-er/DesktopCommanderMCP/issues) with detailed information about any security vulnerabilities you discover. See our [Security Policy](SECURITY.md) for complete guidelines on responsible disclosure.\n\n## Data Collection & Privacy\n\nDesktop Commander collects limited anonymous telemetry data to help improve the tool. No personal information, file contents, file paths, or command arguments are collected.\n\n### Usage Analytics (Local Only)\n- **Local usage statistics** are always collected and stored locally on your machine for functionality and the `get_usage_stats` tool\n- Use the `get_usage_stats` tool to view your personal usage patterns, success rates, and performance metrics\n- **This data is NOT sent anywhere** - it remains on your computer for your personal insights\n\n### Feedback System\n- Use the `give_feedback_to_desktop_commander` tool to provide feedback about Desktop Commander\n- Opens a browser-based feedback form to send suggestions and feedback to the development team\n- Only basic usage statistics (tool call count, days using, platform) are pre-filled to provide context but you can remove them\n\n### External Telemetry Opt-Out\nExternal telemetry (sent to analytics services) is enabled by default but can be disabled:\n\n1. Open the chat and simply ask:\n   **\"Disable telemetry\"**\n2. The chatbot will update your settings automatically.\n\n**Note:** This only disables external telemetry. Local usage analytics remain active for tool functionality but is not share externally\n\nFor complete details about data collection, please see our [Privacy Policy](https://legal.desktopcommander.app/privacy_desktop_commander_mcp).\n\n## Verifications\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/25ff7a06-58bc-40b8-bd79-ebb715140f1a)\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "coding",
        "llms execute",
        "execution servers",
        "execute code"
      ],
      "category": "code-execution"
    },
    "xuhuatao--learn-python": {
      "owner": "xuhuatao",
      "name": "learn-python",
      "url": "https://github.com/xuhuatao/learn-python",
      "imageUrl": "https://github.com/xuhuatao.png",
      "description": "Explore Python interactively by modifying and testing code examples across various topics, with built-in assertions and linting tools to enhance code quality and learning.",
      "stars": 0,
      "forks": 0,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2021-07-31T08:42:14Z",
      "readme_content": "# Playground and Cheatsheet for Learning Python\n\n[![Build Status](https://travis-ci.org/trekhleb/learn-python.svg?branch=master)](https://travis-ci.org/trekhleb/learn-python)\n\n> This is a collection of Python scripts that are split by [topics](#table-of-contents) and contain \ncode examples with explanations, different use cases and links to further readings.\n\n_Read this in_ [_Português_](README.pt-BR.md).\n\nIt is a **playground** because you may change or add the code to see how it works \nand [test it out](#testing-the-code) using assertions. It also allows you \nto [lint the code](#linting-the-code) you've wrote and check if it fits to Python code style guide.\nAltogether it might make your learning process to be more interactive and it might help you to keep \ncode quality pretty high from very beginning.\n\nIt is a **cheatsheet** because you may get back to these code examples once you want to recap the \nsyntax of [standard Python statements and constructions](#table-of-contents). Also because the \ncode is full of assertions you'll be able to see expected functions/statements output right away\nwithout launching them.\n\n> _You might also be interested in 🤖 [Interactive Machine Learning Experiments](https://github.com/trekhleb/machine-learning-experiments)_\n\n## How to Use This Repository\n\nEach Python script in this repository has the following structure:\n\n```python\n\"\"\"Lists  <--- Name of the topic here\n\n# @see: https://www.learnpython.org/en/Lists  <-- Link to further readings goes here\n\nHere might go more detailed explanation of the current topic (i.e. general info about Lists).\n\"\"\"\n\n\ndef test_list_type():\n    \"\"\"Explanation of sub-topic goes here.\n    \n    Each file contains test functions that illustrate sub-topics (i.e. lists type, lists methods).\n    \"\"\"\n    \n    # Here is an example of how to build a list.  <-- Comments here explain the action\n    squares = [1, 4, 9, 16, 25]\n    \n    # Lists can be indexed and sliced. \n    # Indexing returns the item.\n    assert squares[0] == 1  # <-- Assertions here illustrate the result.\n    # Slicing returns a new list.\n    assert squares[-3:] == [9, 16, 25]  # <-- Assertions here illustrate the result.\n```\n\nSo normally you might want to do the following:\n\n- [Find the topic](#table-of-contents) you want to learn or recap.\n- Read comments and/or documentation that is linked in each script's docstring (as in example above). \n- Look at code examples and assertions to see usage examples and expected output.\n- Change code or add new assertions to see how things work.\n- [Run tests](#testing-the-code) and [lint the code](#linting-the-code) to see if it work and is \nwritten correctly.\n\n## Table of Contents\n\n1. **Getting Started**\n    - [What is Python](src/getting_started/what_is_python.md)\n    - [Python Syntax](src/getting_started/python_syntax.md)\n    - [Variables](src/getting_started/test_variables.py)\n2. **Operators**\n    - [Arithmetic Operators](src/operators/test_arithmetic.py) (`+`, `-`, `*`, `/`, `//`, `%`, `**`)\n    - [Bitwise Operators](src/operators/test_bitwise.py) (`&`, `|`, `^`, `>>`, `<<`, `~`)\n    - [Assignment Operators](src/operators/test_assigment.py) (`=`, `+=`, `-=`, `/=`, `//=` etc.)\n    - [Comparison Operator](src/operators/test_comparison.py) (`==`, `!=`, `>`, `<`, `>=`, `<=`)\n    - [Logical Operators](src/operators/test_logical.py) (`and`, `or`, `not`)\n    - [Identity Operators](src/operators/test_identity.py) (`is`, `is not`)\n    - [Membership Operators](src/operators/test_membership.py) (`in`, `not in`)\n3. **Data Types**\n    - [Numbers](src/data_types/test_numbers.py) (including booleans)\n    - [Strings](src/data_types/test_strings.py) and their methods\n    - [Lists](src/data_types/test_lists.py) and their methods (including list comprehensions)\n    - [Tuples](src/data_types/test_tuples.py)\n    - [Sets](src/data_types/test_sets.py) and their methods\n    - [Dictionaries](src/data_types/test_dictionaries.py)\n    - [Type Casting](src/data_types/test_type_casting.py)\n4. **Control Flow**\n    - [The `if` statement](src/control_flow/test_if.py)\n    - [The `for` statement](src/control_flow/test_for.py) (and `range()` function)\n    - [The `while` statement](src/control_flow/test_while.py)\n    - [The `try` statements](src/control_flow/test_try.py)\n    - [The `break` statement](src/control_flow/test_break.py)\n    - [The `continue` statement](src/control_flow/test_continue.py)\n5. **Functions**\n    - [Function Definition](src/functions/test_function_definition.py) (`def` and `return` statements)\n    - [Scopes of Variables Inside Functions](src/functions/test_function_scopes.py) (`global` and `nonlocal` statements)\n    - [Default Argument Values](src/functions/test_function_default_arguments.py)\n    - [Keyword Arguments](src/functions/test_function_keyword_arguments.py)\n    - [Arbitrary Argument Lists](src/functions/test_function_arbitrary_arguments.py)\n    - [Unpacking Argument Lists](src/functions/test_function_unpacking_arguments.py) (`*` and `**` statements)\n    - [Lambda Expressions](src/functions/test_lambda_expressions.py) (`lambda` statement)\n    - [Documentation Strings](src/functions/test_function_documentation_string.py)\n    - [Function Annotations](src/functions/test_function_annotations.py)\n    - [Function Decorators](src/functions/test_function_decorators.py)\n6. **Classes**\n    - [Class Definition](src/classes/test_class_definition.py) (`class` statement)\n    - [Class Objects](src/classes/test_class_objects.py)\n    - [Instance Objects](src/classes/test_instance_objects.py)\n    - [Method Objects](src/classes/test_method_objects.py)\n    - [Class and Instance Variables](src/classes/test_class_and_instance_variables.py)\n    - [Inheritance](src/classes/test_inheritance.py)\n    - [Multiple Inheritance](src/classes/test_multiple_inheritance.py)\n7. **Modules**\n    - [Modules](src/modules/test_modules.py) (`import` statement)\n    - [Packages](src/modules/test_packages.py)\n8. **Errors and Exceptions**\n    - [Handling Exceptions](src/exceptions/test_handle_exceptions.py) (`try` statement)\n    - [Raising Exceptions](src/exceptions/test_raise_exceptions.py) (`raise` statement) \n9. **Files**\n    - [Reading and Writing](src/files/test_file_reading.py) (`with` statement)\n    - [Methods of File Objects](src/files/test_file_methods.py)\n10. **Additions**\n    - [The `pass` statement](src/additions/test_pass.py)\n    - [Generators](src/additions/test_generators.py) (`yield` statement)\n11. **Brief Tour of the Standard Libraries**\n    - [Serialization](src/standard_libraries/test_json.py) (`json` library)\n    - [File Wildcards](src/standard_libraries/test_glob.py) (`glob` library)\n    - [String Pattern Matching](src/standard_libraries/test_re.py) (`re` library)\n    - [Mathematics](src/standard_libraries/test_math.py) (`math`, `random`, `statistics` libraries)\n    - [Dates and Times](src/standard_libraries/test_datetime.py) (`datetime` library)\n    - [Data Compression](src/standard_libraries/test_zlib.py) (`zlib` library)\n\n## Prerequisites\n\n**Installing Python**\n\nMake sure that you have [Python3 installed](https://realpython.com/installing-python/) on your machine.\n\nYou might want to use [venv](https://docs.python.org/3/library/venv.html) standard Python library\nto create virtual environments and have Python, pip and all dependent packages to be installed and \nserved from the local project directory to avoid messing with system wide packages and their \nversions.\n\nDepending on your installation you might have access to Python3 interpreter either by\nrunning `python` or `python3`. The same goes for pip package manager - it may be accessible either\nby running `pip` or `pip3`.\n\nYou may check your Python version by running:\n\n```bash\npython --version\n```\n\nNote that in this repository whenever you see `python` it will be assumed that it is Python **3**.\n\n**Installing dependencies**\n\nInstall all dependencies that are required for the project by running:\n\n```bash\npip install -r requirements.txt\n```\n\n## Testing the Code\n\nTests are made using [pytest](https://docs.pytest.org/en/latest/) framework.\n\nYou may add new tests for yourself by adding files and functions with `test_` prefix\n(i.e. `test_topic.py` with `def test_sub_topic()` function inside).\n\nTo run all the tests please execute the following command from the project root folder:\n\n```bash\npytest\n```\n\nTo run specific tests please execute:\n\n```bash\npytest ./path/to/the/test_file.py\n```\n\n## Linting the Code\n\nLinting is done using [pylint](http://pylint.pycqa.org/) and [flake8](http://flake8.pycqa.org/en/latest/) libraries.\n\n### PyLint\n\nTo check if the code is written with respect\nto [PEP 8](https://www.python.org/dev/peps/pep-0008/) style guide please run:\n\n```bash\npylint ./src/\n```\n\nIn case if linter will detect error (i.e. `missing-docstring`) you may want to read more about \nspecific error by running:\n\n```bash\npylint --help-msg=missing-docstring\n```\n\n[More about PyLint](http://pylint.pycqa.org/)\n\n### Flake8\n\nTo check if the code is written with respect\nto [PEP 8](https://www.python.org/dev/peps/pep-0008/) style guide please run:\n\n```bash\nflake8 ./src\n```\n\nOr if you want to have more detailed output you may run:\n\n```bash\nflake8 ./src --statistics --show-source --count\n```\n\n[More about Flake8](http://flake8.pycqa.org/en/latest/)\n\n## Supporting the project\n\nYou may support this project via ❤️️ [GitHub](https://github.com/sponsors/trekhleb) or ❤️️ [Patreon](https://www.patreon.com/trekhleb).\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "python",
        "llms",
        "coding",
        "llms execute",
        "execution servers",
        "code execution"
      ],
      "category": "code-execution"
    },
    "yepcode--mcp-server-js": {
      "owner": "yepcode",
      "name": "mcp-server-js",
      "url": "https://github.com/yepcode/mcp-server-js",
      "imageUrl": "",
      "description": "Execute any LLM-generated code in a secure and scalable sandbox environment and create your own MCP tools using JavaScript or Python, with full support for NPM and PyPI packages",
      "stars": 36,
      "forks": 15,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-30T08:59:02Z",
      "readme_content": "![YepCode MCP Server Preview](https://yepcode.io/images/cover/yepcode-ultimate-dev-tool-ai-solutions.png)\n\n<div align=\"center\">\n\n[![NPM version](https://img.shields.io/npm/v/@yepcode/mcp-server.svg)](https://npmjs.org/package/@yepcode/mcp-server)\n[![NPM Downloads](https://img.shields.io/npm/dm/@yepcode/mcp-server)](https://www.npmjs.com/package/@yepcode/mcp-server)\n[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/yepcode/mcp-server-js/ci.yml)](https://github.com/yepcode/mcp-server-js/actions)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/yepcode/mcp-server-js)](https://archestra.ai/mcp-catalog/yepcode__mcp-server-js)\n[![smithery badge](https://smithery.ai/badge/@yepcode/mcp-server)](https://smithery.ai/server/@yepcode/mcp-server)\n\n</div>\n\n## What is YepCode MCP Server?\n\nAn MCP ([Model Context Protocol](https://modelcontextprotocol.io/introduction)) server that enables AI platforms to interact with [YepCode](https://yepcode.io/l/LQUKe)'s infrastructure. Run LLM generated scripts and turn your YepCode processes into powerful tools that AI assistants can use directly.\n\n### Why YepCode MCP Server?\n\n- **Seamless AI Integration**: Convert YepCode processes into AI-ready tools with zero configuration\n- **Real-time Process Control**: Enable direct interaction between AI systems and your workflows\n- **Enterprise-Grade Security**: Execute code in YepCode's isolated, production-ready environments\n- **Universal Compatibility**: Integrate with any AI platform supporting the Model Context Protocol\n\n## Integration Guide\n\nYepCode MCP server can be integrated with AI platforms like [Cursor](https://cursor.sh) or [Claude Desktop](https://www.anthropic.com/news/claude-desktop) using either a remote approach (we offer a hosted version of the MCP server) or a local approach (NPX or Docker installation is required).\n\nFor both approaches, you need to get your YepCode API credentials:\n\n1. Sign up to [YepCode Cloud](https://yepcode.io/l/LQUKe)\n2. Visit `Settings` > `API credentials` to create a new API token.\n\n### Remote Approach using SSE Server\n\n- If your MCP Client doesn't support authentication headers, just use the SSE server URL that includes the API Token. Use a configuration similar to the following:\n\n```typescript\n{\n  \"mcpServers\": {\n    \"yepcode-mcp-server\": {\n      \"url\": \"https://cloud.yepcode.io/mcp/sk-c2E....RD/sse\"\n    }\n  }\n}\n```\n\n- If your MCP Client supports authentication headers, you can use the HTTP server URL that includes the API Token. Use a configuration similar to the following:\n\n```typescript\n{\n  \"mcpServers\": {\n    \"yepcode-mcp-server\": {\n      \"url\": \"https://cloud.yepcode.io/mcp/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer <sk-c2E....RD>\"\n      }\n    }\n  }\n}\n```\n\n### Local Approach\n\n#### Using NPX\n\nMake sure you have Node.js installed (version 18 or higher), and use a configuration similar to the following:\n\n```typescript\n{\n  \"mcpServers\": {\n    \"yepcode-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@yepcode/mcp-server\"],\n      \"env\": {\n        \"YEPCODE_API_TOKEN\": \"your_api_token_here\"\n      }\n    }\n  }\n}\n```\n\n#### Using Docker\n\n1. Build the container image:\n\n```bash\ndocker build -t yepcode/mcp-server .\n```\n\n2. Use a configuration similar to the following:\n\n```typescript\n{\n  \"mcpServers\": {\n    \"yepcode-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-d\",\n        \"-e\",\n        \"YEPCODE_API_TOKEN=your_api_token_here\",\n        \"yepcode/mcp-server\"\n      ]\n    }\n  }\n}\n```\n\n## Debugging\n\nDebugging MCP servers can be tricky since they communicate over stdio. To make this easier, we recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which you can run with the following command:\n\n```bash\nnpm run inspector\n```\n\nThis will start a server where you can access debugging tools directly in your browser.\n\n## YepCode MCP Tools Reference\n\nThe MCP server provides several tools to interact with YepCode's infrastructure:\n\n### Code Execution\n\n#### run_code\n\nExecutes code in YepCode's secure environment.\n\n```typescript\n// Input\n{\n  code: string;                          // The code to execute\n  options?: {\n    language?: string;                   // Programming language (default: 'javascript')\n    comment?: string;                    // Execution context\n    settings?: Record<string, unknown>;  // Runtime settings\n  }\n}\n\n// Response\n{\n  returnValue?: unknown;                 // Execution result\n  logs?: string[];                       // Console output\n  error?: string;                        // Error message if execution failed\n}\n```\n\n##### MCP Options\n\nYepCode MCP server supports the following options:\n\n- Disable the run_code tool: In some cases, you may want to disable the `run_code` tool. For example, if you want to use the MCP server as a provider only for the existing tools in your YepCode account.\n- Skip the run_code cleanup: By default, run_code processes source code is removed after execution. If you want to keep it for audit purposes, you can use this option.\n\nOptions can be passed as a comma-separated list in the `YEPCODE_MCP_OPTIONS` environment variable or as a query parameter in the MCP server URL.\n\n```typescript\n// SSE server configuration\n{\n  \"mcpServers\": {\n    \"yepcode-mcp-server\": {\n      \"url\": \"https://cloud.yepcode.io/mcp/sk-c2E....RD/sse?mcpOptions=disableRunCodeTool,runCodeCleanup\"\n    }\n  }\n}\n\n// NPX configuration\n{\n  \"mcpServers\": {\n    \"yepcode-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@yepcode/mcp-server\"],\n      \"env\": {\n        \"YEPCODE_API_TOKEN\": \"your_api_token_here\",\n        \"YEPCODE_MCP_OPTIONS\": \"disableRunCodeTool,runCodeCleanup\"\n      }\n    }\n  }\n}\n```\n\n### Environment Management\n\n#### set_env_var\n\nSets an environment variable in the YepCode workspace.\n\n```typescript\n// Input\n{\n  key: string;                           // Variable name\n  value: string;                         // Variable value\n  isSensitive?: boolean;                 // Whether to mask the value in logs (default: true)\n}\n```\n\n#### remove_env_var\n\nRemoves an environment variable from the YepCode workspace.\n\n```typescript\n// Input\n{\n  key: string;                           // Name of the variable to remove\n}\n```\n\n### Storage Management\n\nYepCode provides a built-in storage system that allows you to upload, list, download, and delete files. These files can be accessed from your code executions using the `yepcode.storage` helper methods.\n\n#### list_files\n\nLists all files in your YepCode storage.\n\n```typescript\n// Input\n{\n  prefix?: string;                       // Optional prefix to filter files\n}\n\n// Response\n{\n  files: Array<{\n    filename: string;                    // File name or path\n    size: number;                        // File size in bytes\n    lastModified: string;                // Last modification date\n  }>;\n}\n```\n\n#### upload_file\n\nUploads a file to YepCode storage.\n\n```typescript\n// Input\n{\n  filename: string;                      // File path (e.g., 'file.txt' or 'folder/file.txt')\n  content: string | {                   // File content\n    data: string;                        // Base64 encoded content for binary files\n    encoding: \"base64\";\n  };\n}\n\n// Response\n{\n  success: boolean;                      // Upload success status\n  filename: string;                      // Uploaded file path\n}\n```\n\n#### download_file\n\nDownloads a file from YepCode storage.\n\n```typescript\n// Input\n{\n  filename: string;                      // File path to download\n}\n\n// Response\n{\n  filename: string;                      // File path\n  content: string;                       // File content (base64 for binary files)\n  encoding?: string;                     // Encoding type if binary\n}\n```\n\n#### delete_file\n\nDeletes a file from YepCode storage.\n\n```typescript\n// Input\n{\n  filename: string;                      // File path to delete\n}\n\n// Response\n{\n  success: boolean;                      // Deletion success status\n  filename: string;                      // Deleted file path\n}\n```\n\n### Process Execution\n\nThe MCP server can expose your YepCode Processes as individual MCP tools, making them directly accessible to AI assistants. This feature is enabled by just adding the `mcp-tool` tag to your process (see our docs to learn more about [process tags](https://yepcode.io/docs/processes/tags)).\n\nThere will be a tool for each exposed process: `run_ycp_<process_slug>` (or `run_ycp_<process_id>` if tool name is longer than 60 characters).\n\n#### run_ycp_<process_slug>\n\n```typescript\n// Input\n{\n  parameters?: any;                      // This should match the input parameters specified in the process\n  options?: {\n    tag?: string;                        // Process version to execute\n    comment?: string;                    // Execution context\n  };\n  synchronousExecution?: boolean;        // Whether to wait for completion (default: true)\n}\n\n// Response (synchronous execution)\n{\n  executionId: string;                   // Unique execution identifier\n  logs: string[];                        // Process execution logs\n  returnValue?: unknown;                 // Process output\n  error?: string;                        // Error message if execution failed\n}\n\n// Response (asynchronous execution)\n{\n  executionId: string;                   // Unique execution identifier\n}\n```\n\n#### get_execution\n\nRetrieves the result of a process execution.\n\n```typescript\n// Input\n{\n  executionId: string;                   // ID of the execution to retrieve\n}\n\n// Response\n{\n  executionId: string;                   // Unique execution identifier\n  logs: string[];                        // Process execution logs\n  returnValue?: unknown;                 // Process output\n  error?: string;                        // Error message if execution failed\n}\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "mcp",
        "llm",
        "llms execute",
        "mcp tools",
        "mcp server"
      ],
      "category": "code-execution"
    },
    "yonaka15--mcp-pyodide": {
      "owner": "yonaka15",
      "name": "mcp-pyodide",
      "url": "https://github.com/yonaka15/mcp-pyodide",
      "imageUrl": "https://github.com/yonaka15.png",
      "description": "Execute Python code through the Model Context Protocol interface, enabling Large Language Models to leverage Python capabilities within their responses. The server supports both stdio and SSE transport modes and is implemented in TypeScript.",
      "stars": 14,
      "forks": 5,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-09-08T05:40:45Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/yonaka15-mcp-pyodide-badge.png)](https://mseep.ai/app/yonaka15-mcp-pyodide)\n\n# mcp-pyodide\n\nA Pyodide server implementation for the Model Context Protocol (MCP). This server enables Large Language Models (LLMs) to execute Python code through the MCP interface.\n\n<a href=\"https://glama.ai/mcp/servers/pxls43joly\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/pxls43joly/badge\" alt=\"mcp-pyodide MCP server\" />\n</a>\n\n## Features\n\n- Python code execution capability for LLMs using Pyodide\n- MCP compliant server implementation\n- Support for both stdio and SSE transport modes\n- Robust implementation written in TypeScript\n- Available as a command-line tool\n\n## Installation\n\n```bash\nnpm install mcp-pyodide\n```\n\n## Usage\n\n### As a Server\n\n```typescript\nimport { runServer } from \"mcp-pyodide\";\n\n// Start the server\nrunServer().catch((error: unknown) => {\n  console.error(\"Error starting server:\", error);\n  process.exit(1);\n});\n```\n\n### As a Command-line Tool\n\nStart in stdio mode (default):\n\n```bash\nmcp-pyodide\n```\n\nStart in SSE mode:\n\n```bash\nmcp-pyodide --sse\n```\n\n### SSE Mode\n\nWhen running in SSE mode, the server provides the following endpoints:\n\n- SSE Connection: `http://localhost:3020/sse`\n- Message Handler: `http://localhost:3020/messages`\n\nExample client connection:\n\n```typescript\nconst eventSource = new EventSource(\"http://localhost:3020/sse\");\neventSource.onmessage = (event) => {\n  console.log(\"Received:\", JSON.parse(event.data));\n};\n```\n\n## Project Structure\n\n```\nmcp-pyodide/\n├── src/\n│   ├── formatters/    # Data formatting handlers\n│   ├── handlers/      # Request handlers\n│   ├── lib/          # Library code\n│   ├── tools/        # Utility tools\n│   ├── utils/        # Utility functions\n│   └── index.ts      # Main entry point\n├── build/            # Build artifacts\n├── pyodide-packages/ # Pyodide-related packages\n└── package.json\n```\n\n## Dependencies\n\n- `@modelcontextprotocol/sdk`: MCP SDK (^1.4.0)\n- `pyodide`: Python runtime environment (^0.27.1)\n- `arktype`: Type validation library (^2.0.1)\n- `express`: Web framework for SSE support\n- `cors`: CORS middleware for SSE support\n\n## Development\n\n### Requirements\n\n- Node.js 18 or higher\n- npm 9 or higher\n\n### Setup\n\n```bash\n# Clone the repository\ngit clone <repository-url>\n\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n```\n\n### Scripts\n\n- `npm run build`: Compile TypeScript and set execution permissions\n- `npm start`: Run server in stdio mode\n- `npm run start:sse`: Run server in SSE mode\n\n## Environment Variables\n\n- `PYODIDE_CACHE_DIR`: Directory for Pyodide cache (default: \"./cache\")\n- `PYODIDE_DATA_DIR`: Directory for mounted data (default: \"./data\")\n- `PORT`: Port for SSE server (default: 3020)\n\n## License\n\nMIT\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -am 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Create a Pull Request\n\n## Important Notes\n\n- This project is under development, and the API may change\n- Thoroughly test before using in production\n- Exercise caution when executing untrusted code for security reasons\n- When using SSE mode, ensure proper CORS configuration if needed\n\n## Support\n\nPlease use the Issue tracker for problems and questions.\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "python",
        "llms",
        "coding",
        "llms execute",
        "execution servers",
        "python capabilities"
      ],
      "category": "code-execution"
    },
    "yzfly--mcp-python-interpreter": {
      "owner": "yzfly",
      "name": "mcp-python-interpreter",
      "url": "https://github.com/yzfly/mcp-python-interpreter",
      "imageUrl": "https://github.com/yzfly.png",
      "description": "Seamlessly interact with Python environments to execute code, manage packages, and perform file operations. Includes templates for common tasks to streamline development workflows.",
      "stars": 72,
      "forks": 25,
      "license": "Other",
      "language": "Python",
      "updated_at": "2025-10-02T09:47:21Z",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/yzfly-mcp-python-interpreter-badge.png)](https://mseep.ai/app/yzfly-mcp-python-interpreter)\n\n# MCP Python Interpreter\n\nA Model Context Protocol (MCP) server that allows LLMs to interact with Python environments, read and write files, execute Python code, and manage development workflows.\n\n## Features\n\n- **Environment Management**: List and use different Python environments (system and conda)\n- **Code Execution**: Run Python code or scripts in any available environment\n- **Package Management**: List installed packages and install new ones\n- **File Operations**: \n  - Read files of any type (text, source code, binary)\n  - Write text and binary files\n- **Python Prompts**: Templates for common Python tasks like function creation and debugging\n\n## Installation\n\nYou can install the MCP Python Interpreter using pip:\n\n```bash\npip install mcp-python-interpreter\n```\n\nOr with uv:\n\n```bash\nuv install mcp-python-interpreter\n```\n\n## Usage with Claude Desktop\n\n1. Install [Claude Desktop](https://claude.ai/download)\n2. Open Claude Desktop, click on menu, then Settings\n3. Go to Developer tab and click \"Edit Config\"\n4. Add the following to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-python-interpreter\": {\n        \"command\": \"uvx\",\n        \"args\": [\n            \"mcp-python-interpreter\",\n            \"--dir\",\n            \"/path/to/your/work/dir\",\n            \"--python-path\",\n            \"/path/to/your/python\"\n        ],\n        \"env\": {\n            \"MCP_ALLOW_SYSTEM_ACCESS\": 0\n        },\n    }\n  }\n}\n```\n\nFor Windows:\n\n```json\n{\n  \"mcpServers\": {\n    \"python-interpreter\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"mcp-python-interpreter\",\n        \"--dir\",\n        \"C:\\\\path\\\\to\\\\your\\\\working\\\\directory\",\n        \"--python-path\",\n        \"/path/to/your/python\"\n      ],\n        \"env\": {\n            \"MCP_ALLOW_SYSTEM_ACCESS\": 0\n        }\n    }\n  }\n}\n```\n\n5. Restart Claude Desktop\n6. You should now see the MCP tools icon in the chat interface\n\nThe `--dir` parameter is **required** and specifies where all files will be saved and executed. This helps maintain security by isolating the MCP server to a specific directory.\n\n### Prerequisites\n\n- Make sure you have `uv` installed. If not, install it using:\n  ```bash\n  curl -LsSf https://astral.sh/uv/install.sh | sh\n  ```\n- For Windows:\n  ```powershell\n  powershell -ExecutionPolicy Bypass -Command \"iwr -useb https://astral.sh/uv/install.ps1 | iex\"\n  ```\n\n## Available Tools\n\nThe Python Interpreter provides the following tools:\n\n### Environment and Package Management\n- **list_python_environments**: List all available Python environments (system and conda)\n- **list_installed_packages**: List packages installed in a specific environment\n- **install_package**: Install a Python package in a specific environment\n\n### Code Execution\n- **run_python_code**: Execute Python code in a specific environment\n- **run_python_file**: Execute a Python file in a specific environment\n\n### File Operations\n- **read_file**: Read contents of any file type, with size and safety limits\n  - Supports text files with syntax highlighting\n  - Displays hex representation for binary files\n- **write_file**: Create or overwrite files with text or binary content\n- **write_python_file**: Create or overwrite a Python file specifically\n- **list_directory**: List Python files in a directory\n\n## Available Resources\n\n- **python://environments**: List all available Python environments\n- **python://packages/{env_name}**: List installed packages for a specific environment\n- **python://file/{file_path}**: Get the content of a Python file\n- **python://directory/{directory_path}**: List all Python files in a directory\n\n## Prompts\n\n- **python_function_template**: Generate a template for a Python function\n- **refactor_python_code**: Help refactor Python code\n- **debug_python_error**: Help debug a Python error\n\n## Example Usage\n\nHere are some examples of what you can ask Claude to do with this MCP server:\n\n- \"Show me all available Python environments on my system\"\n- \"Run this Python code in my conda-base environment: print('Hello, world!')\"\n- \"Create a new Python file called 'hello.py' with a function that says hello\"\n- \"Read the contents of my 'data.json' file\"\n- \"Write a new configuration file with these settings...\"\n- \"List all packages installed in my system Python environment\"\n- \"Install the requests package in my system Python environment\"\n- \"Run data_analysis.py with these arguments: --input=data.csv --output=results.csv\"\n\n## File Handling Capabilities\n\nThe MCP Python Interpreter now supports comprehensive file operations:\n- Read text and binary files up to 1MB\n- Write text and binary files\n- Syntax highlighting for source code files\n- Hex representation for binary files\n- Strict file path security (only within the working directory)\n\n## Security Considerations\n\nThis MCP server has access to your Python environments and file system. Key security features include:\n- Isolated working directory\n- File size limits\n- Prevented writes outside the working directory\n- Explicit overwrite protection\n\nAlways be cautious about running code or file operations that you don't fully understand.\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "interpreter",
        "servers",
        "llms execute",
        "execution servers",
        "code manage"
      ],
      "category": "code-execution"
    },
    "zaycruz--docker_mcp": {
      "owner": "zaycruz",
      "name": "docker_mcp",
      "url": "https://github.com/zaycruz/docker_mcp",
      "imageUrl": "https://github.com/zaycruz.png",
      "description": "Executes code securely in isolated Docker containers, supporting various programming languages and complex scripts. Provides robust error handling, dependency management, and clear, color-coded feedback for output.",
      "stars": 3,
      "forks": 2,
      "license": "MIT License",
      "language": "Python",
      "updated_at": "2025-08-16T18:13:22Z",
      "readme_content": "# Docker MCP Server\n\nA powerful Model Context Protocol (MCP) server that executes code in isolated Docker containers and returns the results to language models like Claude.\n\n## Features\n\n- **Isolated Code Execution**: Run code in Docker containers separated from your main system\n- **Multi-language Support**: Execute code in any language with a Docker image\n- **Complex Script Support**: Run both simple commands and complete multi-line scripts\n- **Package Management**: Install dependencies using pip, npm, apt-get, or apk\n- **Container Management**: Create, list, and clean up Docker containers easily\n- **Robust Error Handling**: Graceful timeout management and fallback mechanisms\n- **Colorful Output**: Clear, color-coded console feedback\n\n## Requirements\n\n- Python 3.9+ \n- Docker installed and running\n- fastmcp library\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/yourusername/docker_mcp_server.git\n   cd docker_mcp_server\n   ```\n\n2. Create a virtual environment:\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   ```\n\n3. Install required packages:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n## Usage\n\n### Running the MCP Inspector\n\nTo test and explore the server's functionality:\n\n```bash\npython run_server.py\n```\n\nThe MCP Inspector interface will open in your browser at http://localhost:5173.\n\n### Available Tools\n\nThe Docker MCP server provides the following tools:\n\n#### 1. List Containers\n\nLists all Docker containers and their details:\n\n- **Parameters**:\n  - `show_all`: (Optional) Whether to show all containers including stopped ones (default: True)\n\n#### 2. Create Container\n\nCreates and starts a Docker container with optional dependencies:\n\n- **Parameters**:\n  - `image`: The Docker image to use (e.g., \"python:3.9-slim\", \"node:16\")\n  - `container_name`: A unique name for the container\n  - `dependencies`: (Optional) Space-separated list of packages to install (e.g., \"numpy pandas\", \"express lodash\")\n\n#### 3. Add Dependencies\n\nInstalls additional packages in an existing Docker container:\n\n- **Parameters**:\n  - `container_name`: The name of the target container\n  - `dependencies`: Space-separated list of packages to install\n\n#### 4. Execute Code\n\nExecutes a command inside a running Docker container:\n\n- **Parameters**:\n  - `container_name`: The name of the target container\n  - `command`: The command to execute inside the container\n\n#### 5. Execute Python Script\n\nExecutes a multi-line Python script inside a running Docker container:\n\n- **Parameters**:\n  - `container_name`: The name of the target container\n  - `script_content`: The full Python script content\n  - `script_args`: Optional arguments to pass to the script\n\n#### 6. Cleanup Container\n\nStops and removes a Docker container:\n\n- **Parameters**:\n  - `container_name`: The name of the container to clean up\n\n### Examples\n\n#### Basic Workflow Example\n\n```python\n# 1. List existing containers to see what's already running\nlist_containers()\n\n# 2. Create a new container\ncreate_container(\n    image=\"python:3.9-slim\", \n    container_name=\"python-example\", \n    dependencies=\"numpy pandas\"\n)\n\n# 3. Execute a command in the container\nexecute_code(\n    container_name=\"python-example\", \n    command=\"python -c 'import numpy as np; print(\\\"NumPy version:\\\", np.__version__)'\"\n)\n\n# 4. Add more dependencies later\nadd_dependencies(\n    container_name=\"python-example\", \n    dependencies=\"matplotlib scikit-learn\"\n)\n\n# 5. List containers again to confirm status\nlist_containers(show_all=False)  # Only show running containers\n\n# 6. Clean up when done\ncleanup_container(container_name=\"python-example\")\n```\n\n#### Python Data Analysis Example\n\n```python\n# 1. Create a container with dependencies\ncreate_container(\n    image=\"python:3.9-slim\", \n    container_name=\"python-test\", \n    dependencies=\"numpy pandas matplotlib\"\n)\n\n# 2. Execute a Python script\nscript = \"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Create some data\ndata = pd.DataFrame({\n    'x': np.random.randn(100),\n    'y': np.random.randn(100)\n})\n\nprint(f\"Data shape: {data.shape}\")\nprint(f\"Data correlation: {data.corr().iloc[0,1]:.4f}\")\n\"\"\"\nexecute_python_script(container_name=\"python-test\", script_content=script)\n\n# 3. Add additional dependencies later if needed\nadd_dependencies(container_name=\"python-test\", dependencies=\"scikit-learn\")\n\n# 4. Verify container is running\nlist_containers(show_all=False)\n\n# 5. Clean up when done\ncleanup_container(container_name=\"python-test\")\n```\n\n#### Node.js Example\n\n```python\n# 1. Check for existing Node.js containers\nlist_containers()\n\n# 2. Create a Node.js container\ncreate_container(\n    image=\"node:16\", \n    container_name=\"node-test\", \n    dependencies=\"express axios\"\n)\n\n# 3. Execute a Node.js script\nexecute_code(\n    container_name=\"node-test\", \n    command=\"node -e \\\"console.log('Node.js version: ' + process.version); console.log('Express installed: ' + require.resolve('express'));\\\"\"\n)\n\n# 4. Add more dependencies\nadd_dependencies(container_name=\"node-test\", dependencies=\"lodash moment\")\n\n# 5. Clean up when done\ncleanup_container(container_name=\"node-test\")\n```\n\n## Package Manager Support\n\nThe Docker MCP server automatically detects and uses the appropriate package manager:\n\n- **Python containers**: Uses `pip`\n- **Node.js containers**: Uses `npm`\n- **Debian/Ubuntu containers**: Uses `apt-get`\n- **Alpine containers**: Uses `apk`\n\nFor containers where the package manager isn't obvious from the image name, the server attempts to detect available package managers.\n\n## Integrating with Claude and Other LLMs\n\nThis MCP server can be integrated with Claude and other LLMs that support the Model Context Protocol. Use the `fastmcp install` command to register it with Claude:\n\n```bash\nfastmcp install src/docker_mcp.py\n```\n\n## Troubleshooting\n\n- **Port Already in Use**: If you see \"Address already in use\" errors, ensure no other MCP Inspector instances are running.\n- **Docker Connection Issues**: Verify that Docker is running with `docker --version`.\n- **Container Timeouts**: The server includes fallback mechanisms for containers that don't respond within expected timeframes.\n- **Package Installation Failures**: Check that the package name is correct for the specified package manager.\n- **No Containers Found**: If list_containers shows no results, Docker might not have any containers created yet.\n\n## Security Considerations\n\nThis server executes code in Docker containers, which provides isolation from the host system. However, exercise caution:\n\n- Don't expose this server publicly without additional security measures\n- Be careful when mounting host volumes into containers\n- Consider resource limits for containers to prevent DoS attacks\n\n## License\n\n[MIT License](LICENSE)\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. ",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "docker",
        "executes",
        "llms execute",
        "code securely",
        "execution servers"
      ],
      "category": "code-execution"
    },
    "zhanyiwp--DesktopCommanderMCP": {
      "owner": "zhanyiwp",
      "name": "DesktopCommanderMCP",
      "url": "https://github.com/zhanyiwp/DesktopCommanderMCP",
      "imageUrl": "https://github.com/zhanyiwp.png",
      "description": "Execute terminal commands and manage processes on a local computer. Features include advanced file editing capabilities and real-time output streaming to enhance development tasks.",
      "stars": 2,
      "forks": 1,
      "license": "MIT License",
      "language": "",
      "updated_at": "2025-05-14T08:01:01Z",
      "readme_content": "# Desktop Commander MCP\n\n\n[![npm downloads](https://img.shields.io/npm/dw/@wonderwhy-er/desktop-commander)](https://www.npmjs.com/package/@wonderwhy-er/desktop-commander)\n[![smithery badge](https://smithery.ai/badge/@wonderwhy-er/desktop-commander)](https://smithery.ai/server/@wonderwhy-er/desktop-commander)\n[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-support-yellow.svg)](https://www.buymeacoffee.com/wonderwhyer)\n\n[![Discord](https://img.shields.io/badge/Join%20Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/kQ27sNnZr7)\n\nShort version. Two key things. Terminal commands and diff based file editing.\n\n![Desktop Commander MCP](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/logo.png)\n\n<a href=\"https://glama.ai/mcp/servers/zempur9oh4\">\n  <img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/zempur9oh4/badge\" alt=\"Claude Desktop Commander MCP server\" />\n</a>\n\n## Table of Contents\n- [Features](#features)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Handling Long-Running Commands](#handling-long-running-commands)\n- [Work in Progress and TODOs](#work-in-progress-and-todos)\n- [Media links](#media)\n- [Testimonials](#testimonials)\n- [Contributing](#contributing)\n- [License](#license)\n\nThis is server that allows Claude desktop app to execute long-running terminal commands on your computer and manage processes through Model Context Protocol (MCP) + Built on top of [MCP Filesystem Server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) to provide additional search and replace file editing capabilities .\n\n## Features\n\n- Execute terminal commands with output streaming\n- Command timeout and background execution support\n- Process management (list and kill processes)\n- Session management for long-running commands\n- Full filesystem operations:\n  - Read/write files\n  - Create/list directories\n  - Move files/directories\n  - Search files\n  - Get file metadata\n  - Code editing capabilities:\n  - Surgical text replacements for small changes\n  - Full file rewrites for major changes\n  - Multiple file support\n  - Pattern-based replacements\n  - vscode-ripgrep based recursive code or text search in folders\n\n## Installation\nFirst, ensure you've downloaded and installed the [Claude Desktop app](https://claude.ai/download) and you have [npm installed](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\n### Option 1: Installing via Smithery\n\nTo install Desktop Commander for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@wonderwhy-er/desktop-commander):\n\n```bash\nnpx -y @smithery/cli install @wonderwhy-er/desktop-commander --client claude\n```\n\n### Option 2: Install trough npx\nJust run this in terminal\n```\nnpx @wonderwhy-er/desktop-commander setup\n```\nRestart Claude if running\n\n### Option 3: Add to claude_desktop_config by hand\nAdd this entry to your claude_desktop_config.json (on Mac, found at ~/Library/Application\\ Support/Claude/claude_desktop_config.json):\n```json\n{\n  \"mcpServers\": {\n    \"desktop-commander\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@wonderwhy-er/desktop-commander\"\n      ]\n    }\n  }\n}\n```\nRestart Claude if running\n\n### Option 4: Checkout locally\n1. Clone and build:\n```bash\ngit clone https://github.com/wonderwhy-er/ClaudeComputerCommander.git\ncd ClaudeComputerCommander\nnpm run setup\n```\nRestart Claude if running\n\nThe setup command will:\n- Install dependencies\n- Build the server\n- Configure Claude's desktop app\n- Add MCP servers to Claude's config if needed\n\n## Usage\n\nThe server provides these tool categories:\n\n### Terminal Tools\n- `execute_command`: Run commands with configurable timeout\n- `read_output`: Get output from long-running commands\n- `force_terminate`: Stop running command sessions\n- `list_sessions`: View active command sessions\n- `list_processes`: View system processes\n- `kill_process`: Terminate processes by PID\n- `block_command`/`unblock_command`: Manage command blacklist\n\n### Filesystem Tools\n- `read_file`/`write_file`: File operations\n- `create_directory`/`list_directory`: Directory management  \n- `move_file`: Move/rename files\n- `search_files`: Pattern-based file search\n- `get_file_info`: File metadata\n- `code_search`: Recursive ripgrep based text and code search\n\n### Edit Tools\n- `edit_block`: Apply surgical text replacements (best for changes <20% of file size)\n- `write_file`: Complete file rewrites (best for large changes >20% or when edit_block fails)\n\nSearch/Replace Block Format:\n```\nfilepath.ext\n<<<<<<< SEARCH\nexisting code to replace\n=======\nnew code to insert\n>>>>>>> REPLACE\n```\n\nExample:\n```\nsrc/main.js\n<<<<<<< SEARCH\nconsole.log(\"old message\");\n=======\nconsole.log(\"new message\");\n>>>>>>> REPLACE\n```\n\n## Handling Long-Running Commands\n\nFor commands that may take a while:\n\n1. `execute_command` returns after timeout with initial output\n2. Command continues in background\n3. Use `read_output` with PID to get new output\n4. Use `force_terminate` to stop if needed\n\n## Model Context Protocol Integration\n\nThis project extends the MCP Filesystem Server to enable:\n- Local server support in Claude Desktop\n- Full system command execution\n- Process management\n- File operations\n- Code editing with search/replace blocks\n\nCreated as part of exploring Claude MCPs: https://youtube.com/live/TlbjFDbl5Us\n\n## DONE\n- **25-03-2025 Better code search** ([merged](https://github.com/wonderwhy-er/ClaudeDesktopCommander/pull/17)) - Enhanced code exploration with context-aware results\n\n## Work in Progress and TODOs\n\nThe following features are currently being developed or planned:\n\n- **Better configurations** ([in progress](https://github.com/wonderwhy-er/ClaudeDesktopCommander/pull/16)) - Improved settings for allowed paths, commands and shell environment\n- **Windows environment fixes** ([in progress](https://github.com/wonderwhy-er/ClaudeDesktopCommander/pull/13)) - Resolving issues specific to Windows platforms\n- **Linux improvements** ([in progress](https://github.com/wonderwhy-er/ClaudeDesktopCommander/pull/12)) - Enhancing compatibility with various Linux distributions\n- **Support for WSL** - Windows Subsystem for Linux integration\n- **Support for SSH** - Remote server command execution\n- **Installation troubleshooting guide** - Comprehensive help for setup issues\n\n## Website\n\nVisit our official website at [https://desktopcommander.app/](https://desktopcommander.app/) for the latest information, documentation, and updates.\n\n## Media\nLearn more about this project through these resources:\n\n### Article\n[Claude with MCPs replaced Cursor & Windsurf. How did that happen?](https://wonderwhy-er.medium.com/claude-with-mcps-replaced-cursor-windsurf-how-did-that-happen-c1d1e2795e96) - A detailed exploration of how Claude with Model Context Protocol capabilities is changing developer workflows.\n\n### Video\n[Claude Desktop Commander Video Tutorial](https://www.youtube.com/watch?v=ly3bed99Dy8) - Watch how to set up and use the Commander effectively.\n\n### Publication at AnalyticsIndiaMag\n[![analyticsindiamag.png](testemonials%2Fanalyticsindiamag.png)\nThis Developer Ditched Windsurf, Cursor Using Claude with MCPs](https://analyticsindiamag.com/ai-features/this-developer-ditched-windsurf-cursor-using-claude-with-mcps/)\n\n### Community\nJoin our [Discord server](https://discord.gg/7cbccwRp) to get help, share feedback, and connect with other users.\n\n## Testimonials\n\n[![It's a life saver! I paid Claude + Cursor currently which I always feel it's kind of duplicated. This solves the problem ultimately. I am so happy. Thanks so much. Plus today Claude has added the web search support. With this MCP + Internet search, it writes the code with the latest updates. It's so good when Cursor doesn't work sometimes or all the fast requests are used.](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img.png) https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyyBt6_ShdDX_rIOad4AaABAg\n](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyyBt6_ShdDX_rIOad4AaABAg\n)\n\n[![This is the first comment I've ever left on a youtube video, THANK YOU! I've been struggling to update an old Flutter app in Cursor from an old pre null-safety version to a current version and implemented null-safety using Claude 3.7. I got most of the way but had critical BLE errors that I spent days trying to resolve with no luck. I tried Augment Code but it didn't get it either. I implemented your MCP in Claude desktop and was able to compare the old and new codebase fully, accounting for the updates in the code, and fix the issues in a couple of hours. A word of advice to people trying this, be sure to stage changes and commit when appropriate to be able to undo unwanted changes. Amazing!](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_1.png)\nhttps://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgztdHvDMqTb9jiqnf54AaABAg](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgztdHvDMqTb9jiqnf54AaABAg\n)\n\n[![Great! I just used Windsurf, bought license a week ago, for upgrading old fullstack socket project and it works many times good or ok but also many times runs away in cascade and have to revert all changes loosing hundereds of cascade tokens. In just a week down to less than 100 tokens and do not want to buy only 300 tokens for 10$. This Claude MCP ,bought claude Pro finally needed but wanted very good reason to also have next to ChatGPT, and now can code as much as I want not worrying about token cost.\nAlso this is much more than code editing it is much more thank you for great video!](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_2.png)\nhttps://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyQFTmYLJ4VBwIlmql4AaABAg](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=UgyQFTmYLJ4VBwIlmql4AaABAg)\n\n[![it is a great tool, thank you, I like using it, as it gives claude an ability to do surgical edits, making it more like a human developer.](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_3.png)\nhttps://www.youtube.com/watch?v=ly3bed99Dy8&lc=Ugy4-exy166_Ma7TH-h4AaABAg](https://www.youtube.com/watch?v=ly3bed99Dy8&lc=Ugy4-exy166_Ma7TH-h4AaABAg)\n\n[![You sir are my hero. You've pretty much summed up and described my experiences of late, much better than I could have. Cursor and Windsurf both had me frustrated to the point where I was almost yelling at my computer screen. Out of whimsy, I thought to myself why not just ask Claude directly, and haven't looked back since.\nClaude first to keep my sanity in check, then if necessary, engage with other IDEs, frameworks, etc. I thought I was the only one, glad to see I'm not lol.\n33\n1](https://raw.githubusercontent.com/wonderwhy-er/ClaudeComputerCommander/main/testemonials/img_4.png)\nhttps://medium.com/@pharmx/you-sir-are-my-hero-62cff5836a3e](https://medium.com/@pharmx/you-sir-are-my-hero-62cff5836a3e)\n\n## Contributing\n\nIf you find this project useful, please consider giving it a ⭐ star on GitHub! This helps others discover the project and encourages further development.\n\nWe welcome contributions from the community! Whether you've found a bug, have a feature request, or want to contribute code, here's how you can help:\n\n- **Found a bug?** Open an issue at [github.com/wonderwhy-er/ClaudeComputerCommander/issues](https://github.com/wonderwhy-er/ClaudeComputerCommander/issues)\n- **Have a feature idea?** Submit a feature request in the issues section\n- **Want to contribute code?** Fork the repository, create a branch, and submit a pull request\n- **Questions or discussions?** Start a discussion in the GitHub Discussions tab\n\nAll contributions, big or small, are greatly appreciated!\n\nIf you find this tool valuable for your workflow, please consider [supporting the project](https://www.buymeacoffee.com/wonderwhyer).\n\n## License\n\nMIT\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "coding",
        "execution",
        "llms execute",
        "execution servers",
        "allow llms"
      ],
      "category": "code-execution"
    },
    "zy445566--node-runtime-mcp": {
      "owner": "zy445566",
      "name": "node-runtime-mcp",
      "url": "https://github.com/zy445566/node-runtime-mcp",
      "imageUrl": "https://github.com/zy445566.png",
      "description": "Run JavaScript code securely within a Node.js container to retrieve execution results. Supports dynamic code evaluation and interaction through a standardized protocol, enabling code runtime capabilities in applications.",
      "stars": 0,
      "forks": 1,
      "license": "MIT License",
      "language": "TypeScript",
      "updated_at": "2025-05-09T01:33:19Z",
      "readme_content": "# node-runtime-mcp\n the mcp server that run the code in Node.js container and obtain the result \n\n# usege\n```sh\nnpx node-runtime-mcp\n```\n\n# homepage\n[https://smithery.ai/server/@zy445566/node-runtime-mcp](https://smithery.ai/server/@zy445566/node-runtime-mcp)\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "llms",
        "execution",
        "servers",
        "llms execute",
        "execution servers",
        "code securely"
      ],
      "category": "code-execution"
    },
    "zygi--r-playground-mcp": {
      "owner": "zygi",
      "name": "r-playground-mcp",
      "url": "https://github.com/zygi/r-playground-mcp",
      "imageUrl": "https://github.com/zygi.png",
      "description": "Executes R code, visualizes plots, and interacts with scientific data within stateful sessions. Supports multimodal outputs to enhance conversations around scientific topics.",
      "stars": 2,
      "forks": 1,
      "license": "No License",
      "language": "Python",
      "updated_at": "2025-06-06T20:19:18Z",
      "readme_content": "# MCP R Playground\n[![PyPI version](https://img.shields.io/pypi/v/rplayground-mcp.svg)](https://pypi.org/project/rplayground-mcp/)\n[![smithery badge](https://smithery.ai/badge/@zygi/r-playground-mcp)](https://smithery.ai/server/@zygi/r-playground-mcp)\n\nAn MCP server that allows AI models to execute R code, see its results, and draw and observe plots. \nIt can be used for sophisticated agentic deployments, but also as a way to augment AI clients like Claude Desktop when talking to them about scientific papers. \n\n## Features:\n- Stateful sessions: each conversation thread gets a new session, but the session can persist across calls and user/assistant interactions. \n- Graphics output: multimodal models can draw plots using standard R libraries like ggplot, see those plots, and react to them.\n- Works in all common operating systems/architectures - Windows x64 / arm64, MacOS, Linux.\n- When running locally, ⚠️__NO HOST ISOLATION__⚠️: while each session runs as a separate R environment, they have access to global dependencies and all files on the computer. While unlikely, a rogue model could write R code that deletes your important files.\n    - If you need host isolation, you should run this MCP in Docker. Instructions for that are provided below.\n\n## Configuration\nCurrently there's just one configuration parameter that can be set as an environment variable:\n- `RPLAYGROUND_MCP_SUPPORT_IMAGE_OUTPUT`, default True. If set to False, image output will be disabled, and tool descriptions will be made to reflect that.\n\n## Usage\nBy default, the AIs will have access to all globally installed R packages, and can install whatever package they want. These installations will persist. You can pre-install important packages to make them available in advance.\n\n\n## Installation\nBasic instructions for technical users:\n1) Have R installed, and the R_HOME environment variable set\n2) Have a recent version of the `uv` installed\n3) run `uvx --python=3.13 rplayground-mcp`, and it should just work.\n\n## Detailed Installation\nThis section is for less technical users who want to set up this MCP to use with Claude Desktop or similar AI user interfaces that support MCP extensions.\n\n### Windows\n- Make sure you've set up Claude Desktop to create the MCP configuration file by following instructions here: https://modelcontextprotocol.io/quickstart/user\n- Make sure you have R installed. The recommended source is here https://cran.rstudio.com/ .\n- Make sure you have `uv` installed. `uv` is the project management tool for Python, the programming language this tool is written in. More detailed instructions can be found here https://docs.astral.sh/uv/getting-started/installation/#pypi, we provide the instructions for the most straightforward method:\n    1) Open the Terminal app\n    2) In the terminal, paste in the following installation command: `powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"`\n    3) Close the Terminal app and reopen it\n    4) type in `uv` and confirm you don't see any red errors.\n- We have provided a helper script that you can use to set up the MCP server to work with Claude Desktop. You can run it with `uv run --python=3.13 https://raw.githubusercontent.com/zygi/r-playground-mcp/refs/heads/master/scripts/setup_helper.py`. With your permission, it will:\n    - Set the R_HOME environment variable to your R installation\n    - Install the MCP inside your Claude Desktop configuration.\n- That's it! Starting Claude Desktop should now display the tools as available. Or just ask it to \"test out the `execute_r_command` tool\".\n\n\n### MacOS\n- Make sure you've set up Claude Desktop to create the MCP configuration file by following instructions here: https://modelcontextprotocol.io/quickstart/user\n- Make sure you have R installed. The recommended source is here https://cran.rstudio.com/ .\n- Make sure you have `uv` installed. `uv` is the project management tool for Python, the programming language this tool is written in. More detailed instructions can be found here https://docs.astral.sh/uv/getting-started/installation/#pypi, we provide the instructions for the most straightforward method:\n    1) Open the Terminal app\n    2) In the terminal, paste in the following installation command: `curl -LsSf https://astral.sh/uv/install.sh | sh`\n    3) Close the Terminal app and reopen it\n    4) type in `uv` and confirm you don't see any red errors.\n- We have provided a helper script that you can use to set up the MCP server to work with Claude Desktop. You can run it with `uv run --python=3.13 https://raw.githubusercontent.com/zygi/r-playground-mcp/refs/heads/master/scripts/setup_helper.py`. With your permission, it will:\n    - Set the R_HOME environment variable to your R installation\n    - Install the MCP inside your Claude Desktop configuration.\n- That's it! Starting Claude Desktop should now display the tools as available. Or just ask it to \"test out the `execute_r_command` tool\".\n\n## Installation (Docker)\nWe also provide Dockerfiles to run this MCP in an isolated context. This only supports the platform linux/amd64. \nThe image uses the [`r2u`](https://github.com/eddelbuettel/r2u) project to make precompiled CRAN packages available. The Dockerfile comes with two versions:\n- Slim: `docker build --platform=linux/amd64 .`. This sets up the `r2u` repositories but installing a new package from the R session will still take ~10s.\n- Fat: `docker build --build-arg PREINSTALL_PACKAGES=true --platform=linux/amd64 .`. This preinstalls a big selection of packages to the Docker image, and loading them in an MCP session becomes instant.\n\nYou are also welcome to edit the Dockerfile and preinstall just the packages relevant to your workflow.\n\n## Issues and Contributions\nFeel free to create an Issue if you have questions or requests. Small PRs are welcome anytime, larger PRs should be discussed by creating an Issue before a PR is started. \n\n\n",
      "npm_url": "",
      "npm_downloads": 0,
      "keywords": [
        "coding",
        "llms",
        "code",
        "llms execute",
        "executes code",
        "code execution"
      ],
      "category": "code-execution"
    }
  }
}