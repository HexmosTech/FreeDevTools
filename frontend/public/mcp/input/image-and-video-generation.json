{
  "category": "image-and-video-generation",
  "categoryDisplay": "Image and Video Generation",
  "description": "",
  "repositories": {
    "13rac1--videocapture-mcp": {
      "category": "image-and-video-generation",
      "description": "The Video Still Capture MCP server allows AI models to access and control webcams to take still images and adjust camera settings using OpenCV, without streaming video.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/13rac1.webp",
      "keywords": [
        "videocapture",
        "mcp",
        "webcams",
        "videocapture mcp",
        "mcp video",
        "13rac1 videocapture"
      ],
      "language": "Python",
      "license": "No License",
      "name": "videocapture-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "13rac1",
      "readme_content": "# Video Still Capture MCP\n\n**A Model Context Protocol server for accessing and controlling webcams via OpenCV**\n\n## Overview\n\nVideo Still Capture MCP is a Python implementation of the Model Context Protocol (MCP) that provides AI assistants with the ability to access and control webcams and video sources through OpenCV. This server exposes a set of tools that allow language models to capture images, manipulate camera settings, and manage video connections. There is no video capture.\n\n## Examples\n\nHere are some examples of the Video Still Capture  MCP server in action:\n\n### Orange Example\nLeft: Claude's view of the image | Right: Actual webcam capture\n:-------------------------:|:-------------------------:\n | \n\n### Magnet Example\nLeft: Claude's view of the image | Right: Actual webcam capture\n:-------------------------:|:-------------------------:\n | \n\n## Installation\n\n### Prerequisites\n\n- Python 3.10+\n- [OpenCV](https://opencv.org/) (`opencv-python`)\n- [MCP Python SDK](https://modelcontextprotocol.io/docs/)\n- [UV](https://astral.sh/uv/) (optional)\n\n### Installation from source\n\n```bash\ngit clone https://github.com/13rac1/videocapture-mcp.git\ncd videocapture-mcp\npip install -e .\n```\n\nRun the MCP server:\n\n```bash\nmcp dev videocapture_mcp.py\n```\n\n## Integrating with Claude for Desktop\n\n### macOS/Linux\n\nEdit your Claude Desktop configuration:\n\n```bash\n# Mac\nnano ~/Library/Application\\ Support/Claude/claude_desktop_config.json\n# Linux\nnano ~/.config/Claude/claude_desktop_config.json \n```\n\nAdd this MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"VideoCapture \": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"--with\",\n        \"numpy\",\n        \"--with\",\n        \"opencv-python\",\n        \"mcp\",\n        \"run\",\n        \"/ABSOLUTE_PATH/videocapture_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\nEnsure you replace `/ABSOLUTE_PATH/videocapture-mcp` with the project's absolute path.\n\n### Windows\n\nEdit your Claude Desktop configuration:\n\n```powershell\nnano $env:AppData\\Claude\\claude_desktop_config.json\n```\n\nAdd this MCP server configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"VideoCapture\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"--with\",\n        \"numpy\",\n        \"--with\",\n        \"opencv-python\",\n        \"mcp\",\n        \"run\",\n        \"C:\\ABSOLUTE_PATH\\videocapture-mcp\\videocapture_mcp.py\"\n      ]\n    }\n  }\n}\n```\n\nEnsure you replace `C:\\ABSOLUTE_PATH\\videocapture-mcp` with the project's absolute path.\n\n### Using the Installation Command\n\nAlternatively, you can use the `mcp` CLI to install the server:\n\n```bash\nmcp install videocapture_mcp.py\n```\n\nThis will automatically configure Claude Desktop to use your videocapture MCP server.\n\nOnce integrated, Claude will be able to access your webcam or video source when requested. Simply ask Claude to take a photo or perform any webcam-related task.\n\n## Features\n\n- **Quick Image Capture**: Capture a single image from a webcam without managing connections\n- **Connection Management**: Open, manage, and close camera connections\n- **Video Properties**: Read and adjust camera settings like brightness, contrast, and resolution\n- **Image Processing**: Basic image transformations like horizontal flipping\n\n## Tools Reference\n\n### `quick_capture`\n\nQuickly open a camera, capture a single frame, and close it.\n\n```python\nquick_capture(device_index: int = 0, flip: bool = False) -\u003e Image\n```\n\n- **device_index**: Camera index (0 is usually the default webcam)\n- **flip**: Whether to horizontally flip the image\n- **Returns**: The captured frame as an Image object\n\n### `open_camera`\n\nOpen a connection to a camera device.\n\n```python\nopen_camera(device_index: int = 0, name: Optional[str] = None) -\u003e str\n```\n\n- **device_index**: Camera index (0 is usually the default webcam)\n- **name**: Optional name to identify this camera connection\n- **Returns**: Connection ID for the opened camera\n\n### `capture_frame`\n\nCapture a single frame from the specified video source.\n\n```python\ncapture_frame(connection_id: str, flip: bool = False) -\u003e Image\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **flip**: Whether to horizontally flip the image\n- **Returns**: The captured frame as an Image object\n\n### `get_video_properties`\n\nGet properties of the video source.\n\n```python\nget_video_properties(connection_id: str) -\u003e dict\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **Returns**: Dictionary of video properties (width, height, fps, etc.)\n\n### `set_video_property`\n\nSet a property of the video source.\n\n```python\nset_video_property(connection_id: str, property_name: str, value: float) -\u003e bool\n```\n\n- **connection_id**: ID of the previously opened video connection\n- **property_name**: Name of the property to set (width, height, brightness, etc.)\n- **value**: Value to set\n- **Returns**: True if successful, False otherwise\n\n### `close_connection`\n\nClose a video connection and release resources.\n\n```python\nclose_connection(connection_id: str) -\u003e bool\n```\n\n- **connection_id**: ID of the connection to close\n- **Returns**: True if successful\n\n### `list_active_connections`\n\nList all active video connections.\n\n```python\nlist_active_connections() -\u003e list\n```\n\n- **Returns**: List of active connection IDs\n\n## Example Usage\n\nHere's how an AI assistant might use the Webcam MCP server:\n\n1. **Take a quick photo**:\n   ```\n   I'll take a photo using your webcam.\n   ```\n   (The AI would call `quick_capture()` behind the scenes)\n\n2. **Open a persistent connection**:\n   ```\n   I'll open a connection to your webcam so we can take multiple photos.\n   ```\n   (The AI would call `open_camera()` and store the connection ID)\n\n3. **Adjust camera settings**:\n   ```\n   Let me increase the brightness of the webcam feed.\n   ```\n   (The AI would call `set_video_property()` with the appropriate parameters)\n\n## Advanced Usage\n\n### Resource Management\n\nThe server automatically manages camera resources, ensuring all connections are properly released when the server shuts down. For long-running applications, it's good practice to explicitly close connections when they're no longer needed.\n\n### Multiple Cameras\n\nIf your system has multiple cameras, you can specify the device index when opening a connection:\n\n```python\n# Open the second webcam (index 1)\nconnection_id = open_camera(device_index=1)\n```\n\n## Troubleshooting\n\n- **Camera Not Found**: Ensure your webcam is properly connected and not in use by another application\n- **Permission Issues**: Some systems require explicit permission to access the camera\n- **OpenCV Installation**: If you encounter issues with OpenCV, refer to the [official installation guide](https://docs.opencv.org/master/d5/de5/tutorial_py_setup_in_windows.html)\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "stars": 11,
      "updated_at": "2025-09-20T23:19:39Z",
      "url": "https://github.com/13rac1/videocapture-mcp"
    },
    "396001000--ComfyUI_StoryDiffusion": {
      "category": "image-and-video-generation",
      "description": "ComfyUI_StoryDiffusion allows users to create visually enhanced stories by integrating advanced image generation features into the ComfyUI platform. It utilizes the StoryDiffusion and MS-Diffusion models for creative storytelling through visuals.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "keywords": [
        "comfyui_storydiffusion",
        "storydiffusion",
        "comfyui",
        "comfyui_storydiffusion allows",
        "comfyui_storydiffusion comfyui_storydiffusion",
        "storytelling visuals"
      ],
      "language": "Unknown",
      "license": "Unknown",
      "name": "ComfyUI_StoryDiffusion",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "396001000",
      "readme_content": "",
      "stars": 0,
      "updated_at": "",
      "url": "https://github.com/396001000/ComfyUI_StoryDiffusion"
    },
    "8bitsats--GROK_MCP": {
      "category": "image-and-video-generation",
      "description": "Analyze Solana blockchain transactions and addresses, process images through vision capabilities, and answer general queries with contextual understanding.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "keywords": [
        "8bitsats",
        "solana",
        "blockchain",
        "solana blockchain",
        "8bitsats grok_mcp",
        "generation 8bitsats"
      ],
      "language": "Unknown",
      "license": "Unknown",
      "name": "GROK_MCP",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "8bitsats",
      "readme_content": "",
      "stars": 0,
      "updated_at": "",
      "url": "https://github.com/8bitsats/GROK_MCP"
    },
    "8bitsats--Grok-MCP": {
      "category": "image-and-video-generation",
      "description": "MCP server for generating images using Grok's AI image generation capabilities, accepting text prompts and returning images as URLs or base64-encoded data. Supports multiple image generation requests and error handling, with configuration options for API keys.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/8bitsats.webp",
      "keywords": [
        "grok",
        "mcp",
        "base64",
        "grok mcp",
        "using grok",
        "8bitsats grok"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "Grok-MCP",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "8bitsats",
      "readme_content": "Grok AI Image Generation MCP Server \n\n\nAI Image Generation MCP Server\n\nA server that connects to the xAI/Grok image generation API\nImplemented proper error handling with lazy API key initialization\nAdded support for multiple image generation (up to 10 images)\nAdded support for different response formats (URL or base64 JSON)\nDocker Support:\n\nAdded a Dockerfile to containerize the MCP server\nConfigured the Dockerfile with a dummy API key that can be overridden at runtime\nSet up proper layer caching for efficient builds\nMCP Tools Available:\n\ngenerate_image: Generate images using the Grok-2-image model\nset_api_key: Set the xAI API key at runtime if not provided via environment variable\nHow to Use\nYou can now generate images with prompts like:\n\n\"Generate an image of a cat in a space suit\"\n\"Create a picture of a futuristic city at night\"\nThe MCP server has been configured in your Claude desktop app, and the implementation handles API key management gracefully, allowing the server to start even without an API key initially set.\n\nIf you want to run the server in Docker, you can build and run it with:\n\ncd /Users/8bit/Documents/Cline/MCP/ai-image-generator\ndocker build -t grokart .\ndocker run -e XAI_API_KEY=your-api-key -p 8080:8080 grokart\n",
      "stars": 7,
      "updated_at": "2025-10-03T22:32:23Z",
      "url": "https://github.com/8bitsats/Grok-MCP"
    },
    "Antipas--4oimage-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate and edit high-quality images using text prompts. Transform existing images or create new visuals and 3D characters with real-time updates and automatic viewing in the browser.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/Antipas.webp",
      "keywords": [
        "antipas",
        "images",
        "4oimage",
        "antipas 4oimage",
        "4oimage mcp",
        "generation antipas"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "4oimage-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Antipas",
      "readme_content": "# 4o-image MCP Server\n\nAn MCP server implementation that integrates with 4o-image API, enabling LLMs and other AI systems to generate and edit images through a standardized protocol. Create high-quality art, 3D characters, and custom images using simple text prompts.\n\n\u003ca href=\"https://glama.ai/mcp/servers/@Antipas/4oimage-mcp\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@Antipas/4oimage-mcp/badge\" alt=\"mcp-4o-Image-Generator MCP server\" /\u003e\n\u003c/a\u003e\n\n[![npm version](https://img.shields.io/npm/v/4oimage-mcp.svg)](https://www.npmjs.com/package/4oimage-mcp)\n[![Node.js Version](https://img.shields.io/node/v/4oimage-mcp.svg)](https://nodejs.org)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n## Features\n\n* **Text-to-Image Generation**: Create images from text descriptions with AI\n* **Image Editing**: Transform existing images using text prompts\n* **Real-time Progress Updates**: Get feedback on generation status\n* **Browser Integration**: Automatically open generated images in your default browser\n\n\n## Tools\n\n* **generateImage**\n  * Generate images based on text prompts with optional image editing\n  * Inputs:\n    * `prompt` (string, required): Text description of the desired image\n    * `imageBase64` (string, optional): Base64-encoded image for editing or style transfer\n\n## Configuration\n\n### Getting an API Key\n\n1. Register for an account at [4o-image.app](https://4o-image.app/dashboard/)\n2. Obtain your API key from the user dashboard\n3. Set the API key as an environment variable when running the server\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"4o-image\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"4oimage-mcp\"\n      ],\n      \"env\": {\n        \"API_KEY\": \"YOUR_API_KEY_HERE\"\n      }\n    }\n  }\n}\n```\n\n## Example Usage\n\nHere's an example of using this MCP server with Claude:\n\n```\nGenerate an image of a dog running on the beach at sunset\n```\n\nClaude will use the MCP server to generate the image, which will automatically open in your default browser. You'll also get a direct link to the image in Claude's response.\n\nFor image editing, you can include a base image and prompt Claude to modify it:\n\n```\nEdit this image to make the sky more dramatic with storm clouds\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. You are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License.",
      "stars": 4,
      "updated_at": "2025-05-26T22:44:07Z",
      "url": "https://github.com/Antipas/4oimage-mcp"
    },
    "Bob-lance--grok-mcp": {
      "category": "image-and-video-generation",
      "description": "Connects to Grok AI to generate chat responses, analyze images, and invoke function calls, integrating these features directly into applications using the Model Context Protocol.",
      "forks": 7,
      "imageUrl": "/freedevtools/mcp/pfp/Bob-lance.webp",
      "keywords": [
        "grok",
        "protocol",
        "ai",
        "grok ai",
        "connects grok",
        "grok mcp"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "grok-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Bob-lance",
      "readme_content": "# Grok MCP Plugin\n\n\u003c!-- Add badges here --\u003e\n[![npm version](https://img.shields.io/npm/v/grok-mcp.svg?style=flat-square)](https://www.npmjs.com/package/grok-mcp) \u003c!-- Replace with your actual package name if different --\u003e\n[![Smithery Build Status](https://api.smithery.ai/badges/github.com/Bob-lance/grok-mcp/build-status.svg)](https://smithery.ai/Bob-lance/grok-mcp) \u003c!-- Replace with your actual repo path --\u003e\n\nA Model Context Protocol (MCP) plugin that provides seamless access to Grok AI's powerful capabilities directly from Cline.\n\n## Features\n\nThis plugin exposes three powerful tools through the MCP interface:\n\n1. **Chat Completion** - Generate text responses using Grok's language models\n2. **Image Understanding** - Analyze images with Grok's vision capabilities\n3. **Function Calling** - Use Grok to call functions based on user input\n\n## Prerequisites\n\n- Node.js (v16 or higher)\n- A Grok AI API key (obtain from [console.x.ai](https://console.x.ai/))\n- Cline with MCP support\n\n## Installation\n\n1. Clone this repository:\n   ```bash\n   git clone https://github.com/Bob-lance/grok-mcp.git\n   cd grok-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n4. Add the MCP server to your Cline MCP settings:\n\n   For VSCode Cline extension, edit the file at:\n   ```\n   ~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json\n   ```\n\n   Add the following configuration:\n   ```json\n   {\n     \"mcpServers\": {\n       \"grok-mcp\": {\n         \"command\": \"node\",\n         \"args\": [\"/path/to/grok-mcp/build/index.js\"],\n         \"env\": {\n           \"XAI_API_KEY\": \"your-grok-api-key\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n   Replace `/path/to/grok-mcp` with the actual path to your installation and `your-grok-api-key` with your Grok AI API key.\n\n## Usage\n\nOnce installed and configured, the Grok MCP plugin provides three tools that can be used in Cline:\n\n### Chat Completion\n\nGenerate text responses using Grok's language models:\n\n```javascript\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003egrok-mcp\u003c/server_name\u003e\n\u003ctool_name\u003echat_completion\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a helpful assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello, what can you tell me about Grok AI?\"\n    }\n  ],\n  \"temperature\": 0.7\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\n### Image Understanding\n\nAnalyze images with Grok's vision capabilities:\n\n```javascript\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003egrok-mcp\u003c/server_name\u003e\n\u003ctool_name\u003eimage_understanding\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"image_url\": \"https://example.com/image.jpg\",\n  \"prompt\": \"What is shown in this image?\"\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\nYou can also use base64-encoded images:\n\n```javascript\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003egrok-mcp\u003c/server_name\u003e\n\u003ctool_name\u003eimage_understanding\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"base64_image\": \"base64-encoded-image-data\",\n  \"prompt\": \"What is shown in this image?\"\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\n### Function Calling\n\nUse Grok to call functions based on user input:\n\n```javascript\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003egrok-mcp\u003c/server_name\u003e\n\u003ctool_name\u003efunction_calling\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What's the weather like in San Francisco?\"\n    }\n  ],\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state, e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"],\n              \"description\": \"The unit of temperature to use\"\n            }\n          },\n          \"required\": [\"location\"]\n        }\n      }\n    }\n  ]\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\n## API Reference\n\n### Chat Completion\n\nGenerate a response using Grok AI chat completion.\n\n**Parameters:**\n\n- `messages` (required): Array of message objects with role and content\n- `model` (optional): Grok model to use (defaults to grok-3-mini-beta)\n- `temperature` (optional): Sampling temperature (0-2, defaults to 1)\n- `max_tokens` (optional): Maximum number of tokens to generate (defaults to 16384)\n\n### Image Understanding\n\nAnalyze images using Grok AI vision capabilities.\n\n**Parameters:**\n\n- `prompt` (required): Text prompt to accompany the image\n- `image_url` (optional): URL of the image to analyze\n- `base64_image` (optional): Base64-encoded image data (without the data:image prefix)\n- `model` (optional): Grok vision model to use (defaults to grok-2-vision-latest)\n\nNote: Either `image_url` or `base64_image` must be provided.\n\n### Function Calling\n\nUse Grok AI to call functions based on user input.\n\n**Parameters:**\n\n- `messages` (required): Array of message objects with role and content\n- `tools` (required): Array of tool objects with type, function name, description, and parameters\n- `tool_choice` (optional): Tool choice mode (auto, required, none, defaults to auto)\n- `model` (optional): Grok model to use (defaults to grok-3-mini-beta)\n\n## Development\n\n### Project Structure\n\n- `src/index.ts` - Main server implementation\n- `src/grok-api-client.ts` - Grok API client implementation\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Running\n\n```bash\nXAI_API_KEY=\"your-grok-api-key\" node build/index.js\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgements\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp)\n- [Grok AI](https://x.ai/)\n",
      "stars": 15,
      "updated_at": "2025-09-13T14:48:07Z",
      "url": "https://github.com/Bob-lance/grok-mcp"
    },
    "CLOUDWERX-DEV--DiffuGen": {
      "category": "image-and-video-generation",
      "description": "Seamlessly generate AI images directly within development environments by leveraging local Stable Diffusion models and precise control over parameters. Integrate with MCP-compatible IDEs to facilitate creative development without disruption.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/CLOUDWERX-DEV.webp",
      "keywords": [
        "ai",
        "cloudwerx",
        "dev",
        "generate ai",
        "ai images",
        "generation cloudwerx"
      ],
      "language": "Shell",
      "license": "MIT License",
      "name": "DiffuGen",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "CLOUDWERX-DEV",
      "readme_content": "# DiffuGen - Advanced Local Image Generator with MCP Integration\n\n\u003cp align=\"center\"\u003e\n  \n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003cem\u003eYour AI art studio embedded directly in code. Generate, iterate, and perfect visual concepts through this powerful MCP server for Cursor, Windsurf, and other compatible IDEs, utilizing cutting-edge Flux and Stable Diffusion models without disrupting your development process.\u003c/em\u003e\n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://github.com/CLOUDWERX-DEV/diffugen/stargazers\"\u003e\u003cimg src=\"https://img.shields.io/github/stars/CLOUDWERX-DEV/diffugen\" alt=\"Stars Badge\"/\u003e\u003c/a\u003e\n  \u003ca href=\"https://github.com/CLOUDWERX-DEV/diffugen/network/members\"\u003e\u003cimg src=\"https://img.shields.io/github/forks/CLOUDWERX-DEV/diffugen\" alt=\"Forks Badge\"/\u003e\u003c/a\u003e\n  \u003ca href=\"https://github.com/CLOUDWERX-DEV/diffugen/issues\"\u003e\u003cimg src=\"https://img.shields.io/github/issues/CLOUDWERX-DEV/diffugen\" alt=\"Issues Badge\"/\u003e\u003c/a\u003e\n  \u003ca href=\"https://github.com/CLOUDWERX-DEV/diffugen/blob/master/LICENSE\"\u003e\u003cimg src=\"https://img.shields.io/github/license/CLOUDWERX-DEV/diffugen\" alt=\"License Badge\"/\u003e\u003c/a\u003e\n\u003c/p\u003e\n\n\u003e ‚≠ê **New**: Now includes OpenAPI server support and OpenWebUI OpenAPI Tools (OWUI Version 0.60.0 Required) integration for seamless image generation and display in chat interfaces! The OpenAPI is seperate from the MCP server and allowss for initigrations into your own projects!\n\n## üìÉ Table of Contents\n\n- [Introduction](#-introduction)\n- [Understanding MCP and DiffuGen](#-understanding-mcp-and-diffugen)\n- [Features](#-features)\n- [System Requirements](#-system-requirements)\n- [Installation](#-installation)\n- [IDE Setup Instructions](#-ide-setup-instructions)\n- [Usage](#-usage)\n  - [OpenAPI Server Usage](#openapi-server-usage)\n  - [Default Parameters by Model](#default-parameters-by-model)\n  - [Asking a LLM to Generate Images](#asking-a-llm-to-generate-images)\n  - [Parameter Reference](#parameter-reference)\n  - [Model-Specific Parameter Recommendations](#model-specific-parameter-recommendations)\n  - [Default Parameter Changes](#default-parameter-changes)\n  - [Command Line Usage Notes](#command-line-usage-notes)\n- [Configuration](#Ô∏è-configuration)\n  - [Configuration Approach](#configuration-approach)\n  - [Environment Variable Overrides](#environment-variable-overrides)\n  - [Setting IDE-Specific Configurations](#setting-ide-specific-configurations)\n  - [Key Configuration Elements](#key-configuration-elements)\n  - [IDE-Specific Options](#ide-specific-options)\n  - [Customizing Default Parameters](#customizing-default-parameters)\n  - [Updating Configuration Files](#updating-configuration-files)\n- [Advanced Usage](#-advanced-usage)\n  - [Using the OpenAPI Server](#using-the-openapi-server)\n- [License](#-license)\n- [Acknowledgments](#-acknowledgments)\n- [Contact](#-contact)\n\n## üöÄ Introduction\n\nDiffuGen is a powerful MCP-based image generation system that brings cutting-edge AI models directly into your development workflow. It seamlessly integrates both Flux models (Flux Schnell, Flux Dev) and Stable Diffusion variants (SDXL, SD3, SD1.5) into a unified interface, allowing you to leverage the unique strengths of each model family without switching tools. With comprehensive parameter control and multi-GPU support, DiffuGen scales from rapid concept sketches on modest hardware to production-quality visuals on high-performance systems.\n\nBuilt on top of the highly optimized [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) implementation, DiffuGen offers exceptional performance even on modest hardware while maintaining high-quality output.\n\n## üß† Understanding MCP and DiffuGen\n\n### What is MCP?\n\nMCP (Model Context Protocol) is a protocol that enables LLMs (Large Language Models) to access custom tools and services. In simple terms, an MCP client (like Cursor, Windsurf, Roo Code, or Cline) can make requests to MCP servers to access tools that they provide.\n\n### DiffuGen as an MCP Server\n\nDiffuGen functions as an MCP server that provides text-to-image generation capabilities. It implements the MCP protocol to allow compatible IDEs to send generation requests and receive generated images.\n\nThe server exposes two main tools:\n1. `generate_stable_diffusion_image`: Generate with Stable Diffusion models\n2. `generate_flux_image`: Generate with Flux models\n\n### Technical Architecture\n\nDiffuGen consists of several key components:\n\n- **setup-diffugen.sh**: The complete install utility and model downloader and manager\n- **diffugen.py**: The core Python script that implements the MCP server functionality and defines the generation tools\n- **diffugen.sh**: A shell script launcher that sets up the environment and launches the Python server\n- **diffugen.json**: Template configuration file for MCP integration with various IDEs (to be copied into IDE's MCP configuration)\n- **stable-diffusion.cpp**: The optimized C++ implementation of Stable Diffusion used for actual image generation\n\nThe system works by:\n1. Receiving prompt and parameter data from an MCP client\n2. Processing the request through the Python server\n3. Calling the stable-diffusion.cpp binary with appropriate parameters\n4. Saving the generated image to a configured output directory\n5. Returning the path and metadata of the generated image to the client\n\n### About stable-diffusion.cpp\n\n[stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) is a highly optimized C++ implementation of the Stable Diffusion algorithm. Compared to the Python reference implementation, it offers:\n\n- Significantly faster inference speed (up to 3-4x faster)\n- Lower memory usage (works on GPUs with as little as 4GB VRAM)\n- Optimized CUDA kernels for NVIDIA GPUs\n- Support for various sampling methods and model formats\n- Support for model quantization for better performance\n- No Python dependencies for the core generation process\n\nThis allows DiffuGen to provide high-quality image generation with exceptional performance, even on modest hardware setups.\n\n## ‚ú® Features\n\n- **Multiple Model Support**: Generate images using various models including Flux Schnell, Flux Dev, SDXL, SD3, and SD1.5\n- **MCP Integration**: Seamlessly integrates with IDEs that support MCP (Cursor, Windsurf, Roo Code, Cline, etc.)\n- **OpenAPI Server**: Additional REST API interface for direct HTTP access to image generation capabilities\n- **Cross-Platform**: Works on Linux, macOS, and Windows (via native or WSL)\n- **Parameter Control**: Fine-tune your generations with controls for:\n  - Image dimensions (width/height)\n  - Sampling steps\n  - CFG scale\n  - Seed values\n  - Negative prompts (for SD models only, Flux does not support negative prompts.)\n  - Sampling methods\n- **CUDA Acceleration**: Utilizes GPU acceleration for faster image generation\n- **Natural Language Interface**: Generate images using simple natural language commands\n- **Smart Error Recovery**: Robust error handling with operation-aware recovery procedures\n- **User-Friendly Setup**: Interactive setup script with improved interrupt handling\n- **Resource Tracking**: Session-aware resource management for efficient cleanup\n- **Customizable Interface**: Support for custom ANSI art logos and visual enhancements\n\n## üíª System Requirements\n\n### Minimum Requirements:\n\n- **CPU**: 4-core processor (Intel i5/AMD Ryzen 5 or equivalent)\n- **RAM**: 8GB system memory\n- **Storage**: 5GB free disk space (SSD preferred for faster model loading)\n- **Python**: 3.8 or newer\n- **GPU**: Integrated graphics or entry-level dedicated GPU (optional)\n- **Network**: Broadband connection for model downloads (5+ Mbps)\n\n### Recommended Requirements:\n\n- **CPU**: 8+ core processor (Intel i7/i9 or AMD Ryzen 7/9)\n- **RAM**: 16GB+ system memory\n- **GPU**: NVIDIA GPU with 6GB+ VRAM (RTX 2060 or better for optimal performance)\n- **Storage**: 20GB+ free SSD space\n- **Python**: 3.10 or newer (3.11 offers best performance)\n- **Network**: High-speed connection (20+ Mbps) for efficient model downloads\n\n## üì• Installation\n\n### Automatic Installation (Recommended)\n\nThe easiest way to install DiffuGen is using the provided setup script:\n\n```bash\ngit clone https://github.com/CLOUDWERX-DEV/diffugen.git\ncd DiffuGen\nchmod +x diffugen.sh\nchmod +x setup_diffugen.sh\n./setup_diffugen.sh\n```\n\nFollow the interactive prompts to complete the installation.\n\nThe setup script will:\n- Install necessary dependencies\n- Clone and build stable-diffusion.cpp\n- Set up a Python virtual environment\n- Download selected models (Note: Some models require Clip\\VAE Models as well)\n- Configure file paths for your system\n\n### Manual Installation\n\nIf you prefer to install manually, follow these steps:\n\n1. Clone the repositories:\n\n```bash\ngit clone https://github.com/CLOUDWERX-DEV/diffugen.git\ncd DiffuGen\ngit clone --recursive https://github.com/leejet/stable-diffusion.cpp\n```\n\n2. Build stable-diffusion.cpp:\n\n```bash\ncd stable-diffusion.cpp\nmkdir -p build \u0026\u0026 cd build\n```\n\nWith CUDA:\n```bash\ncmake .. -DCMAKE_BUILD_TYPE=Release -DSD_CUDA=ON\nmake -j$(nproc)\ncd ../..\n```\n\nWithout CUDA:\n```bash\ncmake .. -DCMAKE_BUILD_TYPE=Release\nmake -j$(nproc)\ncd ../..\n```\n\n3. Create and activate a Python virtual environment:\n\n```bash\npython3 -m venv diffugen_env\nsource diffugen_env/bin/activate  # On Windows: diffugen_env\\Scripts\\activate\npip install -r requirements.txt\n```\n\n4. Download required models (structure shown below):\n\n```\nstable-diffusion.cpp/models/\n‚îú‚îÄ‚îÄ ae.sft                           # VAE model\n‚îú‚îÄ‚îÄ clip_l.safetensors               # CLIP model\n‚îú‚îÄ‚îÄ flux/\n‚îÇ   ‚îú‚îÄ‚îÄ flux1-schnell-q8_0.gguf     # Flux Schnell model (default)\n‚îÇ   ‚îî‚îÄ‚îÄ flux1-dev-q8_0.gguf          # Flux Dev model\n‚îú‚îÄ‚îÄ sd3-medium.safetensors           # SD3 model\n‚îú‚îÄ‚îÄ sdxl-1.0-base.safetensors        # SDXL model\n‚îú‚îÄ‚îÄ sdxl_vae-fp16-fix.safetensors    # SDXL VAE\n‚îú‚îÄ‚îÄ t5xxl_fp16.safetensors           # T5 model\n‚îî‚îÄ‚îÄ v1-5-pruned-emaonly.safetensors  # SD1.5 model\n```\n\nYou can download the models from the following sources:\n\n```bash\n# Create model directories\nmkdir -p stable-diffusion.cpp/models/flux\n\n# Flux models\n# Flux Schnell - Fast generation model (Q8 Quantized,requires t5xxl, clip-l, vae)\ncurl -L https://huggingface.co/leejet/FLUX.1-schnell-gguf/resolve/main/flux1-schnell-q8_0.gguf -o stable-diffusion.cpp/models/flux/flux1-schnell-q8_0.gguf\n\n# Flux Dev - Development model with better quality (Q8 QUantized, requires t5xxl, clip-l, vae)\ncurl -L https://huggingface.co/leejet/FLUX.1-dev-gguf/resolve/main/flux1-dev-q8_0.gguf -o stable-diffusion.cpp/models/flux/flux1-dev-q8_0.gguf\n\n# Required models for Flux\n# T5XXL Text Encoder\ncurl -L https://huggingface.co/Sanami/flux1-dev-gguf/resolve/main/t5xxl_fp16.safetensors -o stable-diffusion.cpp/models/t5xxl_fp16.safetensors\n\n# CLIP-L Text Encoder\ncurl -L https://huggingface.co/Sanami/flux1-dev-gguf/resolve/main/clip_l.safetensors -o stable-diffusion.cpp/models/clip_l.safetensors\n\n# VAE for image decoding\ncurl -L https://huggingface.co/pretentioushorsefly/flux-models/resolve/main/models/vae/ae.safetensors -o stable-diffusion.cpp/models/ae.sft\n\n# Stable Diffusion models\n# SDXL 1.0 Base Model (requires sdxl-vae)\ncurl -L https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -o stable-diffusion.cpp/models/sd_xl_base_1.0.safetensors\n\n# SDXL VAE (required for SDXL)\ncurl -L https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae-fp16-fix.safetensors -o stable-diffusion.cpp/models/sdxl_vae-fp16-fix.safetensors\n\n# Stable Diffusion 1.5 (standalone)\ncurl -L https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors -o stable-diffusion.cpp/models/v1-5-pruned-emaonly.safetensors\n\n# Stable Diffusion 3 Medium (standalone)\ncurl -L https://huggingface.co/leo009/stable-diffusion-3-medium/resolve/main/sd3_medium_incl_clips_t5xxlfp16.safetensors -o stable-diffusion.cpp/models/sd3_medium_incl_clips_t5xxlfp16.safetensors\n```\n\nNote: Model download may take a long time depending on your internet connection. The SDXL model is approximately 6GB, SD3 is about 13GB, SD1.5 is around 4GB, and Flux models are 8-13GB each.\n\n5. Update file paths in configuration:\n\nSet shell script as Executable\n\n```\nchmod +x diffugen.sh\n```\n\n**Configuration Approach**:\nDiffuGen uses a single configuration file (`diffugen.json`) as the source of truth for all settings. The workflow is:\n\n1. Edit `diffugen.json` in the DiffuGen root directory with your desired settings\n2. Run option 5 in `setup_diffugen.sh` to automatically update paths in this file\n3. Copy the content of `diffugen.json` to your IDE's MCP configuration file\n\nThe file contains all necessary settings:\n- File paths (command, SD_CPP_PATH, models_dir, output_dir)\n- Default model parameters (steps, cfg_scale, sampling_method)\n- VRAM usage settings\n- Metadata for IDE integration\n\n```json\n{\n  \"mcpServers\": {\n    \"diffugen\": {\n      \"command\": \"/home/cloudwerxlab/Desktop/Servers/MCP/Tools/DiffuGen/diffugen.sh\",\n      \"args\": [],\n      \"env\": {\n        \"CUDA_VISIBLE_DEVICES\": \"0\",\n        \"SD_CPP_PATH\": \"path/to/stable-diffusion.cpp\",\n        \"default_model\": \"flux-schnell\"\n      },\n      \"resources\": {\n        \"models_dir\": \"path/to/stable-diffusion.cpp/models\",\n        \"output_dir\": \"path/to/outputs\",\n        \"vram_usage\": \"adaptive\"\n      },\n      \"metadata\": {\n        \"name\": \"DiffuGen\",\n        \"version\": \"1.0\",\n        \"description\": \"Your AI art studio embedded directly in code. Generate, iterate, and perfect visual concepts through this powerful MCP server for Cursor, Windsurf, and other compatible IDEs, utilizing cutting-edge Flux and Stable Diffusion models without disrupting your development process.\",\n        \"author\": \"CLOUDWERX LAB\",\n        \"homepage\": \"https://github.com/CLOUDWERX-DEV/diffugen\",\n        \"usage\": \"Generate images using two primary methods:\\n1. Standard generation: 'generate an image of [description]' with optional parameters:\\n   - model: Choose from flux-schnell (default), flux-dev, sdxl, sd3, sd15\\n   - dimensions: width and height (default: 512x512)\\n   - steps: Number of diffusion steps (default: 20, lower for faster generation)\\n   - cfg_scale: Guidance scale (default: 7.0, lower for more creative freedom)\\n   - seed: For reproducible results (-1 for random)\\n   - sampling_method: euler, euler_a (default), heun, dpm2, dpm++2s_a, dpm++2m, dpm++2mv2, lcm\\n   - negative_prompt: Specify elements to avoid in the image\\n2. Quick Flux generation: 'generate a flux image of [description]' for faster results with fewer steps (default: 4)\"\n      },\n      \"cursorOptions\": {\n        \"autoApprove\": true,\n        \"category\": \"Image Generation\",\n        \"icon\": \"üñºÔ∏è\",\n        \"displayName\": \"DiffuGen\"\n      },\n      \"windsurfOptions\": {\n        \"displayName\": \"DiffuGen\",\n        \"icon\": \"üñºÔ∏è\",\n        \"category\": \"Creative Tools\"\n      },\n      \"default_params\": {\n        \"steps\": {\n          \"flux-schnell\": 8,\n          \"flux-dev\": 20,\n          \"sdxl\": 20,\n          \"sd3\": 20,\n          \"sd15\": 20\n        },\n        \"cfg_scale\": {\n          \"flux-schnell\": 1.0,\n          \"flux-dev\": 1.0,\n          \"sdxl\": 7.0,\n          \"sd3\": 7.0, \n          \"sd15\": 7.0\n        },\n        \"sampling_method\": {\n          \"flux-schnell\": \"euler\",\n          \"flux-dev\": \"euler\",\n          \"sdxl\": \"euler\",\n          \"sd3\": \"euler\",\n          \"sd15\": \"euler\"\n        }\n      }\n    }\n  }\n}\n```\n\n## üîß IDE Setup Instructions\n\n### Setting up with Cursor\n\n1. Download and install [Cursor](https://cursor.sh)\n2. Go to Cursor Settings \u003e MCP and click \"Add new global MCP server\"\n3. **Copy the contents of your DiffuGen's `diffugen.json` file** and paste it into `~/.cursor/mcp.json`\n4. Refresh MCP Servers in Settings \u003e MCP\n5. Use DiffuGen by opening the AI chat panel (Ctrl+K or Cmd+K) and requesting image generation\n\n### Setting up with Windsurf\n\n1. Download and install [Windsurf](https://codeium.com/windsurf)\n2. Navigate to Windsurf \u003e Settings \u003e Advanced Settings or Command Palette \u003e Open Windsurf Settings Page\n3. Scroll down to the Cascade section and click \"Add Server\" \u003e \"Add custom server +\"\n4. **Copy the contents of your DiffuGen's `diffugen.json` file** and paste into `~/.codeium/windsurf/mcp_config.json`\n5. Use DiffuGen through the Cascade chat interface\n\n### Setting up with Roo Code\n\n1. Download and install [Roo Code](https://roo.ai)\n2. Locate the MCP configuration file for Roo Code\n3. **Copy the contents of your DiffuGen's `diffugen.json` file** into Roo Code's MCP configuration\n4. Use DiffuGen through the AI assistant feature\n\n### Setting up with Cline\n\n1. Download and install [Cline](https://cline.live)\n2. **Copy the contents of your DiffuGen's `diffugen.json` file** into Cline's MCP settings\n3. Use DiffuGen through the AI chat or command interface\n\n### Setting up with Claude in Anthropic Console\n\nClaude can use DiffuGen if you've set it up as an MCP server on your system. When asking Claude to generate images, be specific about using DiffuGen and provide the parameters you want to use.\n\n## üéÆ Usage\n\nTo start the DiffuGen server manually:\n\n```bash\ncd /path/to/diffugen\n./diffugen.sh\n```\n\nOr using Python directly:\n\n```bash\ncd /path/to/diffugen\npython -m diffugen\n```\n\nYou should see: `DiffuGen ready` when the server is successfully started.\n\n### OpenAPI Server Usage\n\nThe OpenAPI server provides a REST API interface for direct HTTP access to DiffuGen's image generation capabilities. This is in addition to the MCP integration and can be useful for:\n- Direct HTTP API access\n- Integration with other tools that don't support MCP\n- Custom applications that need programmatic access\n\nFor detailed setup instructions and advanced configuration options, see the [OpenAPI Integration Guide](OPENAPI_SETUP.md).\n\nTo start the OpenAPI server:\n```bash\npython diffugen_openapi.py\n```\n\nThe server can be configured to use a different host or port if needed. By default, it runs on:\n- Host: 0.0.0.0\n- Port: 8080\n\nThe server will be available at http://0.0.0.0:8080 with interactive documentation at http://0.0.0.0:8080/docs.\n\nGenerated images are saved to the `/output` directory by default. If this directory is not accessible, the server will automatically create an `output` directory in the current working directory. Images are served through the `/images` endpoint.\n\n#### OpenWebUI Integration\n\n1. Open OpenWebUI Settings (gear icon)\n2. Navigate to the \"Tools\" section\n3. Click the \"+\" button to add a new tool server\n4. Enter the following details:\n   - URL: http://0.0.0.0:5199\n   - API Key: (leave empty)\n5. Click \"Save\"\n\nOnce added, DiffuGen will appear in the available tools list when clicking the tools icon in the chat interface. The following endpoints will be available:\n- `generate_stable_image_generate_stable_post`: Generate with Stable Diffusion\n- `generate_flux_image_endpoint_generate_flux_post`: Generate with Flux Models\n- `list_models_models_get`: List Available Models\n\nExample using curl:\n```bash\ncurl -X POST \"http://0.0.0.0:5199/generate/flux\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"prompt\": \"A beautiful sunset\", \"model\": \"flux-schnell\"}'\n```\n\nExample using Python requests:\n```python\nimport requests\n\nresponse = requests.post(\n    \"http://0.0.0.0:5199/generate/flux\",\n    json={\n        \"prompt\": \"A beautiful sunset\",\n        \"model\": \"flux-schnell\"\n    }\n)\nresult = response.json()\n```\n\n### Default Parameters by Model\n\nEach model has specific default parameters optimized for best results:\n\n| Model | Default Steps | Default CFG Scale | Best For |\n|-------|--------------|-----------------|----------|\n| flux-schnell | 8 | 1.0 | Fast drafts, conceptual images |\n| flux-dev | 20 | 1.0 | Better quality flux generations |\n| sdxl | 20 | 7.0 | High-quality detailed images |\n| sd3 | 20 | 7.0 | Latest generation with good quality |\n| sd15 | 20 | 7.0 | Classic baseline model |\n\nThese default parameters can be customized by adding a `default_params` section to your IDE's MCP configuration file:\n\n```json\n\"default_params\": {\n  \"steps\": {\n    \"flux-schnell\": 12,  // Customize steps for better quality\n    \"sdxl\": 30           // Increase steps for more detailed SDXL images\n  },\n  \"cfg_scale\": {\n    \"sd15\": 9.0          // Higher cfg_scale for stronger prompt adherence\n  }\n}\n```\n\nYou only need to specify the parameters you want to override - any unspecified values will use the built-in defaults.\n\n\u003e **Note**: For model-specific command line examples and recommendations, see [Model-Specific Parameter Recommendations](#model-specific-parameter-recommendations) section.\n\n### Asking a LLM to Generate Images\n\nHere are examples of how to ask an AI assistant to generate images with DiffuGen:\n\n#### Basic Requests:\n\n```\nGenerate an image of a cat playing with yarn\n```\n\n```\nCreate a picture of a futuristic cityscape with flying cars\n```\n\n#### With Model Specification:\n\n```\nGenerate an image of a medieval castle using the sdxl model\n```\n\n```\nCreate a flux image of a sunset over mountains\n```\n\n#### With Advanced Parameters:\n\n```\nGenerate an image of a cyberpunk street scene, model=flux-dev, width=768, height=512, steps=25, cfg_scale=1.0, seed=42\n```\n\n```\nCreate an illustration of a fantasy character with model=sd15, width=512, height=768, steps=30, cfg_scale=7.5, sampling_method=dpm++2m, negative_prompt=blurry, low quality, distorted\n```\n\n### Parameter Reference\n\nDiffuGen can be used from the command line with the following basic syntax:\n\n```bash\n./diffugen.sh \"Your prompt here\" [options]\n```\n\nExample:\n```bash\n./diffugen.sh \"A futuristic cityscape with flying cars\"\n```\n\nThis command generates an image using default parameters (flux-schnell model, 512x512 resolution, etc.) and saves it to the configured output directory.\n\nBelow are the parameters that can be used with DiffuGen (applicable to both MCP interface and command line):\n\n| Parameter | Description | Default | Valid Values | Command Line Flag |\n|-----------|-------------|---------|-------------|-------------------|\n| model | The model to use for generation | flux-schnell/sd15 | flux-schnell, flux-dev, sdxl, sd3, sd15 | --model |\n| width | Image width in pixels | 512 | 256-2048 | --width |\n| height | Image height in pixels | 512 | 256-2048 | --height |\n| steps | Number of diffusion steps | model-specific | 1-100 | --steps |\n| cfg_scale | Classifier-free guidance scale | model-specific | 0.1-30.0 | --cfg-scale |\n| seed | Random seed for reproducibility | -1 (random) | -1 or any integer | --seed |\n| sampling_method | Diffusion sampling method | euler | euler, euler_a, heun, dpm2, dpm++2s_a, dpm++2m, dpm++2mv2, lcm | --sampling-method |\n| negative_prompt | Elements to avoid in the image | \"\" (empty) | Any text string | --negative-prompt |\n| output_dir | Directory to save images | Config-defined | Valid path | --output-dir |\n\nThese parameters can be specified when asking an AI assistant to generate images or when using the command line interface. Parameters are passed in different formats depending on the interface:\n\n- **In MCP/AI Assistant**: `parameter=value` (e.g., `model=sdxl, width=768, height=512`)\n- **In Command Line**: `--parameter value` (e.g., `--model sdxl --width 768 --height 512`)\n\nThe default values are chosen to provide good results out-of-the-box with minimal waiting time. For higher quality images, consider increasing steps or switching to models like sdxl.\n\n### Model-Specific Parameter Recommendations\n\n\u003e **Note**: These recommendations build on the [Default Parameters by Model](#default-parameters-by-model) section and provide practical examples.\n\nFor best results when using specific models via command line:\n\n#### Flux Models (flux-schnell, flux-dev)\n```bash\n# Flux-Schnell (fastest)\n./diffugen.sh \"Vibrant colorful abstract painting\" \\\n  --model flux-schnell \\\n  --cfg-scale 1.0 \\\n  --sampling-method euler \\\n  --steps 8\n\n# Flux-Dev (better quality)\n./diffugen.sh \"Detailed fantasy landscape with mountains and castles\" \\\n  --model flux-dev \\\n  --cfg-scale 1.0 \\\n  --sampling-method euler \\\n  --steps 20\n```\n\n#### Standard SD Models (sdxl, sd3, sd15)\n```bash\n# SDXL (highest quality)\n./diffugen.sh \"Hyperrealistic portrait of a Celtic warrior\" \\\n  --model sdxl \\\n  --cfg-scale 7.0 \\\n  --sampling-method dpm++2m \\\n  --steps 30\n\n# SD15 (classic model)\n./diffugen.sh \"Photorealistic landscape at sunset\" \\\n  --model sd15 \\\n  --cfg-scale 7.0 \\\n  --sampling-method euler_a \\\n  --steps 20\n```\n\n### Default Parameter Changes\n\nThe command-line interface of DiffuGen uses the following defaults if not otherwise specified in configuration:\n\n- Default Model: If not specified, function-appropriate models are used (flux-schnell for Flux functions, sd15 for SD functions)\n- Default Sampling Method: `euler` (best for Flux models)\n- Default CFG Scale: `1.0` for Flux models, `7.0` for standard SD models\n- Default Steps: `8` for flux-schnell, `20` for other models\n- Default Dimensions: 512x512 pixels\n\nWhen using the command line, you don't need to specify these parameters unless you want to override the defaults. If you frequently use specific parameters, consider adding them to your configuration file rather than specifying them on each command line.\n\n### Command Line Usage Notes\n\n- Generated images are saved to the configured output directory with filenames based on timestamp and parameters\n- You can generate multiple images in sequence by running the command multiple times\n- For batch processing, consider creating a shell script that calls DiffuGen with different parameters\n- To see all available command-line options, run `./diffugen.sh --help`\n- The same engine powers both the MCP interface and command-line tool, so quality and capabilities are identical\n\n## ‚öôÔ∏è Configuration\n\n### Configuration Approach\n\nDiffuGen uses a single configuration approach centered around the `diffugen.json` file:\n\n1. **Primary Configuration File**: `diffugen.json` in the DiffuGen root directory is the single source of truth for all settings\n2. **IDE Integration**: Copy the contents of `diffugen.json` to your IDE's MCP configuration file\n3. **Environment Variables**: For advanced usage, you can override settings with environment variables\n\n### Environment Variable Overrides\n\nFor advanced usage, you can override settings using environment variables:\n\n- `SD_CPP_PATH`: Override the path to stable-diffusion.cpp\n- `DIFFUGEN_OUTPUT_DIR`: Override the output directory\n- `DIFFUGEN_DEFAULT_MODEL`: Override the default model\n- `DIFFUGEN_VRAM_USAGE`: Override VRAM usage settings\n- `CUDA_VISIBLE_DEVICES`: Control which GPUs are used for generation\n\n### Setting IDE-Specific Configurations\n\nDiffuGen allows you to have different configurations for different IDEs by using environment variables in each IDE's MCP configuration. This lets you maintain a single base `diffugen.json` while customizing parameters per IDE.\n\nThe configuration priority works as follows:\n1. Environment variables (highest priority)\n2. Settings from local `diffugen.json` file (base configuration)\n\n**Example: Different Output Directories for Different IDEs**\n\nFor Cursor (in `~/.cursor/mcp.json`):\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"DIFFUGEN_OUTPUT_DIR\": \"/cursor/specific/output/directory\",\n  \"default_model\": \"flux-schnell\"\n}\n```\n\nFor Windsurf (in `~/.codeium/windsurf/mcp_config.json`):\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"DIFFUGEN_OUTPUT_DIR\": \"/windsurf/specific/output/directory\",\n  \"default_model\": \"sdxl\"\n}\n```\n\n**Example: Different Default Models and VRAM Settings**\n\n```json\n\"env\": {\n  \"CUDA_VISIBLE_DEVICES\": \"0\",\n  \"SD_CPP_PATH\": \"/path/to/stable-diffusion.cpp\",\n  \"default_model\": \"flux-dev\", \n  \"DIFFUGEN_VRAM_USAGE\": \"maximum\"\n}\n```\n\nThis approach lets you customize DiffuGen's behavior per IDE while still using the same underlying installation.\n\n### Key Configuration Elements\n\n#### Command and Arguments\n\n- **command**: Full path to the `diffugen.sh` script (must be absolute path)\n- **args**: Additional command-line arguments to pass to the script (usually left empty)\n\n#### Environment Variables\n\n- **CUDA_VISIBLE_DEVICES**: Controls which GPUs are used for generation\n  - `\"0\"`: Use only the first GPU\n  - `\"1\"`: Use only the second GPU\n  - `\"0,1\"`: Use both first and second GPUs\n  - `\"-1\"`: Disable CUDA and use CPU only\n\n- **SD_CPP_PATH**: Path to the stable-diffusion.cpp installation directory\n  - This is used to locate the stable-diffusion.cpp binary and models\n\n- **default_model**: The default model to use when none is specified\n\n#### Resource Configuration\n\n- **models_dir**: Directory containing the model files\n  - Should point to the `models` directory inside your stable-diffusion.cpp installation\n\n- **output_dir**: Directory where generated images will be saved\n  - Must be writable by the user running DiffuGen\n\n- **vram_usage**: Controls VRAM usage strategy\n  - `\"adaptive\"`: Automatically adjust memory usage based on available VRAM\n  - `\"minimal\"`: Use minimal VRAM at the cost of speed\n  - `\"balanced\"`: Balance memory usage and speed (default)\n  - `\"maximum\"`: Use maximum available VRAM for best performance\n\n### IDE-Specific Options\n\nEach IDE has specific options you can customize in the `diffugen.json` file:\n\n#### Cursor Options\n\n```json\n\"cursorOptions\": {\n  \"autoApprove\": true,\n  \"category\": \"Image Generation\",\n  \"icon\": \"üñºÔ∏è\",\n  \"displayName\": \"DiffuGen\"\n}\n```\n\n#### Windsurf Options\n\n```json\n\"windsurfOptions\": {\n  \"displayName\": \"DiffuGen\",\n  \"icon\": \"üñºÔ∏è\",\n  \"category\": \"Creative Tools\"\n}\n```\n\n### Customizing Default Parameters\n\nYou can customize default parameters for each model in the `default_params` section:\n\n```json\n\"default_params\": {\n  \"steps\": {\n    \"flux-schnell\": 12,\n    \"sdxl\": 30\n  },\n  \"cfg_scale\": {\n    \"sd15\": 9.0\n  },\n  \"sampling_method\": {\n    \"flux-schnell\": \"euler\",\n    \"sdxl\": \"dpm++2m\"\n  }\n}\n```\n\n### Updating Configuration Files\n\nWhen using the automatic setup script, a properly configured `diffugen.json` file is created with the correct paths for your system when you run option 5. To integrate DiffuGen with your IDE:\n\n1. Run option 5 in `setup_diffugen.sh` to update paths in `diffugen.json`\n2. Copy the entire contents of the generated `diffugen.json` file\n3. Paste it into your IDE's MCP configuration file (e.g., `~/.cursor/mcp.json`)\n4. Restart your IDE to apply changes\n\nThe key advantage of this approach is a single source of truth for configuration, making it easier to maintain and update your DiffuGen setup.\n\n## üìÉ Advanced Usage\n\nThe DiffuGen Python module can be imported and used programmatically in your own Python scripts:\n\n```python\nfrom diffugen import generate_image\n\n# Generate an image programmatically\nresult = generate_image(\n    prompt=\"A starry night over a quiet village\",\n    model=\"sdxl\",\n    width=1024,\n    height=768,\n    steps=30,\n    cfg_scale=7.0,\n    seed=42,\n    sampling_method=\"dpm++2m\",\n    negative_prompt=\"blurry, low quality\"\n)\n\nprint(f\"Image saved to: {result['file_path']}\")\n```\n\n### Using the OpenAPI Server\n\nYou can also use the OpenAPI server programmatically in your applications:\n\n```python\nimport requests\n\ndef generate_image_via_api(prompt, model=\"flux-schnell\", width=512, height=512):\n    response = requests.post(\n        \"http://0.0.0.0:5199/generate/flux\",\n        json={\n            \"prompt\": prompt,\n            \"model\": model,\n            \"width\": width,\n            \"height\": height\n        }\n    )\n    return response.json()\n\n# Example usage\nresult = generate_image_via_api(\n    prompt=\"A magical forest at night\",\n    model=\"flux-schnell\",\n    width=768,\n    height=512\n)\nprint(f\"Generated image: {result['file_path']}\")\n```\n\n## üîç Troubleshooting\n\n### Common Issues and Solutions\n\n1. **Missing models or incorrect paths**\n   - Ensure all model files are downloaded and placed in the correct directories\n   - Check that paths in the configuration file are correctly set\n   - Verify file permissions allow read access to model files\n\n2. **CUDA/GPU issues**\n   - Make sure your NVIDIA drivers are up-to-date\n   - Set `CUDA_VISIBLE_DEVICES` to target a specific GPU\n   - If running out of VRAM, try using a smaller model or reducing dimensions\n\n3. **Image quality issues**\n   - Increase steps for better quality (at the cost of generation time)\n   - Adjust CFG scale: higher for more prompt adherence, lower for creativity\n   - Try different sampling methods (dpm++2m often provides good results)\n   - Use more detailed prompts with specific style descriptions\n\n4. **File permission errors**\n   - Ensure the output directory is writable by the user running DiffuGen\n   - Check that all scripts have execution permissions (`chmod +x diffugen.sh`)\n\n### Getting Help\n\nIf you encounter issues not covered here, you can:\n- Check the GitHub repository for issues and solutions\n- Run with debug logging enabled: `DEBUG=1 ./diffugen.sh \"your prompt\"`\n- Contact the developers via GitHub issues\n\n## üåü Contributing\n\nContributions to DiffuGen are welcome! To contribute:\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Submit a pull request\n\nPlease ensure your code follows the project's coding standards and includes appropriate tests.\n\n## üìÑ License\n\nThis project is licensed under the Apache License - see the LICENSE file for details.\n\n* All models are licensed under their respective distribution and are not in any way licensed or provided by CLOUDWERX.DEV\n* HuggingFace.co is used to download models and is not affiliated in any way with CLOUDWERX.DEV\n\n## üôè Acknowledgments\n\n- [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) for the optimized C++ implementation\n- [Stability AI](https://stability.ai/) for Stable Diffusion models\n- [Black Forest Labs](https://blackforestlabs.ai/) for their Flux Models\n- [Hugging Face](https://huggingface.co/) for the download links\n- All contributors to the MCP protocol\n\n## üì¨ Contact\n\n- GitHub: [CLOUDWERX-DEV](https://github.com/CLOUDWERX-DEV)\n- Website: [cloudwerx.dev](http://cloudwerx.dev)\n- Mail: [sysop@cloudwerx.dev](mailto:sysop@cloudwerx.dev)\n- Discord: [Join our server](https://discord.gg/SvZFuufNTQ)\n\n```\n                   ______   __   ___   ___         _______              \n                  |   _  \\ |__|.'  _|.'  _|.--.--.|   _   |.-----.-----.\n                  |.  |   \\|  ||   _||   _||  |  ||.  |___||  -__|     |\n                  |.  |    \\__||__|  |__|  |_____||.  |   ||_____|__|__|\n                  |:  1    /                      |:  1   |             \n                  |::.. . /                       |::.. . |             \n                  `------'                        `-------'             \n```\n\n\u003cp align=\"center\"\u003e\n  Made with ‚ù§Ô∏è by CLOUDWERX LAB\n\u003c/p\u003e",
      "stars": 15,
      "updated_at": "2025-08-25T15:46:42Z",
      "url": "https://github.com/CLOUDWERX-DEV/DiffuGen"
    },
    "CLOUDWERX-DEV--gpt-image-1-mcp": {
      "category": "image-and-video-generation",
      "description": "Enables AI assistants to generate and edit images from text prompts, supporting both creation and modification of images using specified masks. Integrates with various MCP clients and provides flexible workflows for image handling, including automatic file saving and comprehensive error reporting.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/CLOUDWERX-DEV.webp",
      "keywords": [
        "cloudwerx",
        "mcp",
        "images",
        "image mcp",
        "gpt image",
        "generation cloudwerx"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "gpt-image-1-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "CLOUDWERX-DEV",
      "readme_content": "\u003cp align=\"center\"\u003e\n  \n\u003c/p\u003e\n\n\u003ch1 align=\"center\"\u003e@cloudwerxlab/gpt-image-1-mcp\u003c/h1\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"\u003e\u003cimg src=\"https://img.shields.io/npm/v/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"npm version\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"\u003e\u003cimg src=\"https://img.shields.io/npm/dm/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"npm downloads\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/blob/main/LICENSE\"\u003e\u003cimg src=\"https://img.shields.io/github/license/CLOUDWERX-DEV/gpt-image-1-mcp.svg\" alt=\"license\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://nodejs.org/\"\u003e\u003cimg src=\"https://img.shields.io/node/v/@cloudwerxlab/gpt-image-1-mcp.svg\" alt=\"node version\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://cloudwerx.dev\"\u003e\u003cimg src=\"https://img.shields.io/badge/website-cloudwerx.dev-blue\" alt=\"Website\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n  A Model Context Protocol (MCP) server for generating and editing images using the OpenAI \u003ccode\u003egpt-image-1\u003c/code\u003e model.\n\u003c/p\u003e\n\n\u003cp align=\"center\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/OpenAI-GPT--Image--1-6E46AE\" alt=\"OpenAI GPT-Image-1\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/MCP-Compatible-00A3E0\" alt=\"MCP Compatible\"\u003e\n\u003c/p\u003e\n\n## üöÄ Quick Start\n\n\u003cdiv align=\"center\"\u003e\n  \u003ca href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"\u003e\u003cimg src=\"https://img.shields.io/badge/NPX-Ready-red.svg\" alt=\"NPX Ready\"\u003e\u003c/a\u003e\n\u003c/div\u003e\n\n\u003cp align=\"center\"\u003eRun this MCP server directly using NPX without installing it. \u003ca href=\"https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp\"\u003eView on npm\u003c/a\u003e.\u003c/p\u003e\n\n```bash\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n\n\u003cp align=\"center\"\u003eThe \u003ccode\u003e-y\u003c/code\u003e flag automatically answers \"yes\" to any prompts that might appear during the installation process.\u003c/p\u003e\n\n### üìã Prerequisites\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd width=\"50%\" align=\"center\"\u003e\n      \u003cimg src=\"https://img.shields.io/badge/Node.js-v14+-339933?logo=node.js\u0026logoColor=white\" alt=\"Node.js v14+\"\u003e\n      \u003cp\u003eNode.js (v14 or higher)\u003c/p\u003e\n    \u003c/td\u003e\n    \u003ctd width=\"50%\" align=\"center\"\u003e\n      \u003cimg src=\"https://img.shields.io/badge/OpenAI-API_Key-412991?logo=openai\u0026logoColor=white\" alt=\"OpenAI API Key\"\u003e\n      \u003cp\u003eOpenAI API key with access to gpt-image-1\u003c/p\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n### üîë Environment Variables\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003cth\u003eVariable\u003c/th\u003e\n    \u003cth\u003eRequired\u003c/th\u003e\n    \u003cth\u003eDescription\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003ccode\u003eOPENAI_API_KEY\u003c/code\u003e\u003c/td\u003e\n    \u003ctd\u003e‚úÖ Yes\u003c/td\u003e\n    \u003ctd\u003eYour OpenAI API key with access to the gpt-image-1 model\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003ccode\u003eGPT_IMAGE_OUTPUT_DIR\u003c/code\u003e\u003c/td\u003e\n    \u003ctd\u003e‚ùå No\u003c/td\u003e\n    \u003ctd\u003eCustom directory for saving generated images (defaults to user's Pictures folder under \u003ccode\u003egpt-image-1\u003c/code\u003e subfolder)\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n### üíª Example Usage with NPX\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003cth\u003eOperating System\u003c/th\u003e\n    \u003cth\u003eCommand Line Example\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cstrong\u003eLinux/macOS\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd\u003e\n\n```bash\n# Set your OpenAI API key\nexport OPENAI_API_KEY=sk-your-openai-api-key\n\n# Optional: Set custom output directory\nexport GPT_IMAGE_OUTPUT_DIR=/home/username/Pictures/ai-generated-images\n\n# Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cstrong\u003eWindows (PowerShell)\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd\u003e\n\n```powershell\n# Set your OpenAI API key\n$env:OPENAI_API_KEY = \"sk-your-openai-api-key\"\n\n# Optional: Set custom output directory\n$env:GPT_IMAGE_OUTPUT_DIR = \"C:\\Users\\username\\Pictures\\ai-generated-images\"\n\n# Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cstrong\u003eWindows (Command Prompt)\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd\u003e\n\n```cmd\n:: Set your OpenAI API key\nset OPENAI_API_KEY=sk-your-openai-api-key\n\n:: Optional: Set custom output directory\nset GPT_IMAGE_OUTPUT_DIR=C:\\Users\\username\\Pictures\\ai-generated-images\n\n:: Run the server with NPX\nnpx -y @cloudwerxlab/gpt-image-1-mcp\n```\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n## üîå Integration with MCP Clients\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/VS_Code-MCP_Extension-007ACC?logo=visual-studio-code\u0026logoColor=white\" alt=\"VS Code MCP Extension\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/Roo-Compatible-FF6B6B\" alt=\"Roo Compatible\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/Cursor-Compatible-4C2889\" alt=\"Cursor Compatible\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/Augment-Compatible-6464FF\" alt=\"Augment Compatible\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/Windsurf-Compatible-00B4D8\" alt=\"Windsurf Compatible\"\u003e\n\u003c/div\u003e\n\n### üõ†Ô∏è Setting Up in an MCP Client\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      \u003ch4\u003eStep 1: Locate Settings File\u003c/h4\u003e\n      \u003cul\u003e\n        \u003cli\u003eFor \u003cstrong\u003eRoo\u003c/strong\u003e: \u003ccode\u003ec:\\Users\\\u0026lt;username\u0026gt;\\AppData\\Roaming\\Code\\User\\globalStorage\\rooveterinaryinc.roo-cline\\settings\\mcp_settings.json\u003c/code\u003e\u003c/li\u003e\n        \u003cli\u003eFor \u003cstrong\u003eVS Code MCP Extension\u003c/strong\u003e: Check your extension documentation for the settings file location\u003c/li\u003e\n        \u003cli\u003eFor \u003cstrong\u003eCursor\u003c/strong\u003e: \u003ccode\u003e~/.config/cursor/mcp_settings.json\u003c/code\u003e (Linux/macOS) or \u003ccode\u003e%APPDATA%\\Cursor\\mcp_settings.json\u003c/code\u003e (Windows)\u003c/li\u003e\n        \u003cli\u003eFor \u003cstrong\u003eAugment\u003c/strong\u003e: \u003ccode\u003e~/.config/augment/mcp_settings.json\u003c/code\u003e (Linux/macOS) or \u003ccode\u003e%APPDATA%\\Augment\\mcp_settings.json\u003c/code\u003e (Windows)\u003c/li\u003e\n        \u003cli\u003eFor \u003cstrong\u003eWindsurf\u003c/strong\u003e: \u003ccode\u003e~/.config/windsurf/mcp_settings.json\u003c/code\u003e (Linux/macOS) or \u003ccode\u003e%APPDATA%\\Windsurf\\mcp_settings.json\u003c/code\u003e (Windows)\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      \u003ch4\u003eStep 2: Add Configuration\u003c/h4\u003e\n      \u003cp\u003eAdd the following configuration to the \u003ccode\u003emcpServers\u003c/code\u003e object:\u003c/p\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@cloudwerxlab/gpt-image-1-mcp\"\n      ],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"PASTE YOUR OPEN-AI KEY HERE\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"OPTIONAL: PATH TO SAVE GENERATED IMAGES\"\n      }\n    }\n  }\n}\n```\n\n#### Example Configurations for Different Operating Systems\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003cth\u003eOperating System\u003c/th\u003e\n    \u003cth\u003eExample Configuration\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cstrong\u003eWindows\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd\u003e\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudwerxlab/gpt-image-1-mcp\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-your-openai-api-key\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"C:\\\\Users\\\\username\\\\Pictures\\\\ai-generated-images\"\n      }\n    }\n  }\n}\n```\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\u003cstrong\u003eLinux/macOS\u003c/strong\u003e\u003c/td\u003e\n    \u003ctd\u003e\n\n```json\n{\n  \"mcpServers\": {\n    \"gpt-image-1\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudwerxlab/gpt-image-1-mcp\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"sk-your-openai-api-key\",\n        \"GPT_IMAGE_OUTPUT_DIR\": \"/home/username/Pictures/ai-generated-images\"\n      }\n    }\n  }\n}\n```\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n\u003e **Note**: For Windows paths, use double backslashes (`\\\\`) to escape the backslash character in JSON. For Linux/macOS, use forward slashes (`/`).\n\n## ‚ú® Features\n\n\u003cdiv align=\"center\"\u003e\n  \u003ctable\u003e\n    \u003ctr\u003e\n      \u003ctd align=\"center\"\u003e\n        \u003ch3\u003eüé® Core Tools\u003c/h3\u003e\n        \u003cul\u003e\n          \u003cli\u003e\u003ccode\u003ecreate_image\u003c/code\u003e: Generate new images from text prompts\u003c/li\u003e\n          \u003cli\u003e\u003ccode\u003ecreate_image_edit\u003c/code\u003e: Edit existing images with text prompts and masks\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/td\u003e\n      \u003ctd align=\"center\"\u003e\n        \u003ch3\u003eüöÄ Key Benefits\u003c/h3\u003e\n        \u003cul\u003e\n          \u003cli\u003eSimple integration with MCP clients\u003c/li\u003e\n          \u003cli\u003eFull access to OpenAI's gpt-image-1 capabilities\u003c/li\u003e\n          \u003cli\u003eStreamlined workflow for AI image generation\u003c/li\u003e\n        \u003c/ul\u003e\n      \u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/table\u003e\n\u003c/div\u003e\n\n### üí° Enhanced Capabilities\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      \u003ch4\u003eüìä Output \u0026 Formatting\u003c/h4\u003e\n      \u003cul\u003e\n        \u003cli\u003e‚úÖ \u003cstrong\u003eBeautifully Formatted Output\u003c/strong\u003e: Responses include emojis and detailed information\u003c/li\u003e\n        \u003cli\u003e‚úÖ \u003cstrong\u003eAutomatic Image Saving\u003c/strong\u003e: All generated images saved to disk for easy access\u003c/li\u003e\n        \u003cli\u003e‚úÖ \u003cstrong\u003eDetailed Token Usage\u003c/strong\u003e: View token consumption for each request\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/td\u003e\n    \u003ctd\u003e\n      \u003ch4\u003e‚öôÔ∏è Configuration \u0026 Handling\u003c/h4\u003e\n      \u003cul\u003e\n        \u003cli\u003e‚úÖ \u003cstrong\u003eConfigurable Output Directory\u003c/strong\u003e: Customize where images are saved\u003c/li\u003e\n        \u003cli\u003e‚úÖ \u003cstrong\u003eFile Path Support\u003c/strong\u003e: Edit images using file paths instead of base64 encoding\u003c/li\u003e\n        \u003cli\u003e‚úÖ \u003cstrong\u003eComprehensive Error Handling\u003c/strong\u003e: Detailed error reporting with specific error codes, descriptions, and troubleshooting suggestions\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n## üîÑ How It Works\n\n\u003cdiv align=\"center\"\u003e\n  \u003ctable\u003e\n    \u003ctr\u003e\n      \u003cth align=\"center\"\u003eüñºÔ∏è Image Generation\u003c/th\u003e\n      \u003cth align=\"center\"\u003e‚úèÔ∏è Image Editing\u003c/th\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e\n        \u003col\u003e\n          \u003cli\u003eServer receives prompt and parameters\u003c/li\u003e\n          \u003cli\u003eCalls OpenAI API using gpt-image-1 model\u003c/li\u003e\n          \u003cli\u003eAPI returns base64-encoded images\u003c/li\u003e\n          \u003cli\u003eServer saves images to configured directory\u003c/li\u003e\n          \u003cli\u003eReturns formatted response with paths and metadata\u003c/li\u003e\n        \u003c/ol\u003e\n      \u003c/td\u003e\n      \u003ctd\u003e\n        \u003col\u003e\n          \u003cli\u003eServer receives image, prompt, and optional mask\u003c/li\u003e\n          \u003cli\u003eFor file paths, reads and prepares files for API\u003c/li\u003e\n          \u003cli\u003eUses direct curl command for proper MIME handling\u003c/li\u003e\n          \u003cli\u003eAPI returns base64-encoded edited images\u003c/li\u003e\n          \u003cli\u003eServer saves images to configured directory\u003c/li\u003e\n          \u003cli\u003eReturns formatted response with paths and metadata\u003c/li\u003e\n        \u003c/ol\u003e\n      \u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/table\u003e\n\u003c/div\u003e\n\n### üìÅ Output Directory Behavior\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003ctd width=\"50%\"\u003e\n      \u003ch4\u003eüìÇ Storage Location\u003c/h4\u003e\n      \u003cul\u003e\n        \u003cli\u003eüîπ \u003cstrong\u003eDefault Location\u003c/strong\u003e: User's Pictures folder under \u003ccode\u003egpt-image-1\u003c/code\u003e subfolder (e.g., \u003ccode\u003eC:\\Users\\username\\Pictures\\gpt-image-1\u003c/code\u003e on Windows)\u003c/li\u003e\n        \u003cli\u003eüîπ \u003cstrong\u003eCustom Location\u003c/strong\u003e: Set via \u003ccode\u003eGPT_IMAGE_OUTPUT_DIR\u003c/code\u003e environment variable\u003c/li\u003e\n        \u003cli\u003eüîπ \u003cstrong\u003eFallback Location\u003c/strong\u003e: \u003ccode\u003e./generated-images\u003c/code\u003e (if Pictures folder can't be determined)\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/td\u003e\n    \u003ctd width=\"50%\"\u003e\n      \u003ch4\u003eüóÇÔ∏è File Management\u003c/h4\u003e\n      \u003cul\u003e\n        \u003cli\u003eüîπ \u003cstrong\u003eDirectory Creation\u003c/strong\u003e: Automatically creates output directory if it doesn't exist\u003c/li\u003e\n        \u003cli\u003eüîπ \u003cstrong\u003eFile Naming\u003c/strong\u003e: Images saved with timestamped filenames (e.g., \u003ccode\u003eimage-2023-05-05T12-34-56-789Z.png\u003c/code\u003e)\u003c/li\u003e\n        \u003cli\u003eüîπ \u003cstrong\u003eCross-Platform\u003c/strong\u003e: Works on Windows, macOS, and Linux with appropriate Pictures folder detection\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n## Installation \u0026 Usage\n\n### NPM Package\n\nThis package is available on npm: [@cloudwerxlab/gpt-image-1-mcp](https://www.npmjs.com/package/@cloudwerxlab/gpt-image-1-mcp)\n\nYou can install it globally:\n\n```bash\nnpm install -g @cloudwerxlab/gpt-image-1-mcp\n```\n\nOr run it directly with npx as shown in the Quick Start section.\n\n### Tool: `create_image`\n\nGenerates a new image based on a text prompt.\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `prompt` | string | Yes | The text description of the image to generate (max 32,000 chars) |\n| `size` | string | No | Image size: \"1024x1024\" (default), \"1536x1024\", or \"1024x1536\" |\n| `quality` | string | No | Image quality: \"high\" (default), \"medium\", or \"low\" |\n| `n` | integer | No | Number of images to generate (1-10, default: 1) |\n| `background` | string | No | Background style: \"transparent\", \"opaque\", or \"auto\" (default) |\n| `output_format` | string | No | Output format: \"png\" (default), \"jpeg\", or \"webp\" |\n| `output_compression` | integer | No | Compression level (0-100, default: 0) |\n| `user` | string | No | User identifier for OpenAI usage tracking |\n| `moderation` | string | No | Moderation level: \"low\" or \"auto\" (default) |\n\n#### Example\n\n```xml\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003egpt-image-1\u003c/server_name\u003e\n\u003ctool_name\u003ecreate_image\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"prompt\": \"A futuristic city skyline at sunset, digital art\",\n  \"size\": \"1024x1024\",\n  \"quality\": \"high\",\n  \"n\": 1,\n  \"background\": \"auto\"\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\n#### Response\n\nThe tool returns:\n- A formatted text message with details about the generated image(s)\n- The image(s) as base64-encoded data\n- Metadata including token usage and file paths\n\n### Tool: `create_image_edit`\n\nEdits an existing image based on a text prompt and optional mask.\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `image` | string, object, or array | Yes | The image(s) to edit (base64 string or file path object) |\n| `prompt` | string | Yes | The text description of the desired edit (max 32,000 chars) |\n| `mask` | string or object | No | The mask that defines areas to edit (base64 string or file path object) |\n| `size` | string | No | Image size: \"1024x1024\" (default), \"1536x1024\", or \"1024x1536\" |\n| `quality` | string | No | Image quality: \"high\" (default), \"medium\", or \"low\" |\n| `n` | integer | No | Number of images to generate (1-10, default: 1) |\n| `background` | string | No | Background style: \"transparent\", \"opaque\", or \"auto\" (default) |\n| `user` | string | No | User identifier for OpenAI usage tracking |\n\n#### Example with Base64 Encoded Image\n\n```xml\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003egpt-image-1\u003c/server_name\u003e\n\u003ctool_name\u003ecreate_image_edit\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"image\": \"BASE64_ENCODED_IMAGE_STRING\",\n  \"prompt\": \"Add a small robot in the corner\",\n  \"mask\": \"BASE64_ENCODED_MASK_STRING\",\n  \"quality\": \"high\"\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\n#### Example with File Path\n\n```xml\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003egpt-image-1\u003c/server_name\u003e\n\u003ctool_name\u003ecreate_image_edit\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"image\": {\n    \"filePath\": \"C:/path/to/your/image.png\"\n  },\n  \"prompt\": \"Add a small robot in the corner\",\n  \"mask\": {\n    \"filePath\": \"C:/path/to/your/mask.png\"\n  },\n  \"quality\": \"high\"\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\n#### Response\n\nThe tool returns:\n- A formatted text message with details about the edited image(s)\n- The edited image(s) as base64-encoded data\n- Metadata including token usage and file paths\n\n## üîß Troubleshooting\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"https://img.shields.io/badge/Support-Available-brightgreen\" alt=\"Support Available\"\u003e\n\u003c/div\u003e\n\n### üö® Common Issues\n\n\u003ctable\u003e\n  \u003ctr\u003e\n    \u003cth align=\"center\"\u003eIssue\u003c/th\u003e\n    \u003cth align=\"center\"\u003eSolution\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      \u003ch4\u003eüñºÔ∏è MIME Type Errors\u003c/h4\u003e\n      \u003cp\u003eErrors related to image format or MIME type handling\u003c/p\u003e\n    \u003c/td\u003e\n    \u003ctd\u003e\n      \u003cp\u003eEnsure image files have the correct extension (.png, .jpg, etc.) that matches their actual format. The server uses file extensions to determine MIME types.\u003c/p\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      \u003ch4\u003eüîë API Key Issues\u003c/h4\u003e\n      \u003cp\u003eAuthentication errors with OpenAI API\u003c/p\u003e\n    \u003c/td\u003e\n    \u003ctd\u003e\n      \u003cp\u003eVerify your OpenAI API key is correct and has access to the gpt-image-1 model. Check for any spaces or special characters that might have been accidentally included.\u003c/p\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      \u003ch4\u003eüõ†Ô∏è Build Errors\u003c/h4\u003e\n      \u003cp\u003eIssues when building from source\u003c/p\u003e\n    \u003c/td\u003e\n    \u003ctd\u003e\n      \u003cp\u003eEnsure you have the correct TypeScript version installed (v5.3.3 or compatible) and that your \u003ccode\u003etsconfig.json\u003c/code\u003e is properly configured. Run \u003ccode\u003enpm install\u003c/code\u003e to ensure all dependencies are installed.\u003c/p\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      \u003ch4\u003eüìÅ Output Directory Issues\u003c/h4\u003e\n      \u003cp\u003eProblems with saving generated images\u003c/p\u003e\n    \u003c/td\u003e\n    \u003ctd\u003e\n      \u003cp\u003eCheck if the process has write permissions to the configured output directory. Try using an absolute path for \u003ccode\u003eGPT_IMAGE_OUTPUT_DIR\u003c/code\u003e if relative paths aren't working.\u003c/p\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\n### üîç Error Handling and Reporting\n\nThe MCP server includes comprehensive error handling that provides detailed information when something goes wrong. When an error occurs:\n\n1. **Error Format**: All errors are returned with:\n   - A clear error message describing what went wrong\n   - The specific error code or type\n   - Additional context about the error when available\n\n2. **AI Assistant Behavior**: When using this MCP server with AI assistants:\n   - The AI will always report the full error message to help with troubleshooting\n   - The AI will explain the likely cause of the error in plain language\n   - The AI will suggest specific steps to resolve the issue\n\n## üìÑ License\n\n\u003cdiv align=\"center\"\u003e\n  \u003ca href=\"LICENSE\"\u003e\u003cimg src=\"https://img.shields.io/badge/License-MIT-blue.svg\" alt=\"MIT License\"\u003e\u003c/a\u003e\n\u003c/div\u003e\n\n\u003cp align=\"center\"\u003e\n  This project is licensed under the MIT License - see the \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e file for details.\n\u003c/p\u003e\n\n\u003cdetails\u003e\n  \u003csummary\u003eLicense Summary\u003c/summary\u003e\n\n  \u003cp\u003eThe MIT License is a permissive license that is short and to the point. It lets people do anything with your code with proper attribution and without warranty.\u003c/p\u003e\n\n  \u003cp\u003e\u003cstrong\u003eYou are free to:\u003c/strong\u003e\u003c/p\u003e\n  \u003cul\u003e\n    \u003cli\u003eUse the software commercially\u003c/li\u003e\n    \u003cli\u003eModify the software\u003c/li\u003e\n    \u003cli\u003eDistribute the software\u003c/li\u003e\n    \u003cli\u003eUse and modify the software privately\u003c/li\u003e\n  \u003c/ul\u003e\n\n  \u003cp\u003e\u003cstrong\u003eUnder the following terms:\u003c/strong\u003e\u003c/p\u003e\n  \u003cul\u003e\n    \u003cli\u003eInclude the original copyright notice and the license notice in all copies or substantial uses of the work\u003c/li\u003e\n  \u003c/ul\u003e\n\n  \u003cp\u003e\u003cstrong\u003eLimitations:\u003c/strong\u003e\u003c/p\u003e\n  \u003cul\u003e\n    \u003cli\u003eThe authors provide no warranty with the software and are not liable for any damages\u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/details\u003e\n\n## üôè Acknowledgments\n\n\u003cdiv align=\"center\"\u003e\n  \u003ctable\u003e\n    \u003ctr\u003e\n      \u003ctd align=\"center\"\u003e\n        \u003ca href=\"https://openai.com/\"\u003e\n          \u003cimg src=\"https://img.shields.io/badge/OpenAI-412991?logo=openai\u0026logoColor=white\" alt=\"OpenAI\"\u003e\n          \u003cp\u003eFor providing the gpt-image-1 model\u003c/p\u003e\n        \u003c/a\u003e\n      \u003c/td\u003e\n      \u003ctd align=\"center\"\u003e\n        \u003ca href=\"https://github.com/model-context-protocol/mcp\"\u003e\n          \u003cimg src=\"https://img.shields.io/badge/MCP-Protocol-00A3E0\" alt=\"MCP Protocol\"\u003e\n          \u003cp\u003eFor the protocol specification\u003c/p\u003e\n        \u003c/a\u003e\n      \u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/table\u003e\n\u003c/div\u003e\n\n\u003cdiv align=\"center\"\u003e\n  \u003cp\u003e\n    \u003ca href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/issues\"\u003eReport Bug\u003c/a\u003e ‚Ä¢\n    \u003ca href=\"https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp/issues\"\u003eRequest Feature\u003c/a\u003e ‚Ä¢\n    \u003ca href=\"https://cloudwerx.dev\"\u003eVisit Our Website\u003c/a\u003e\n  \u003c/p\u003e\n\u003c/div\u003e\n\n\u003cdiv align=\"center\"\u003e\n  \u003cp\u003e\n    Developed with ‚ù§Ô∏è by \u003ca href=\"https://cloudwerx.dev\"\u003eCLOUDWERX\u003c/a\u003e\n  \u003c/p\u003e\n\u003c/div\u003e",
      "stars": 16,
      "updated_at": "2025-09-15T19:40:52Z",
      "url": "https://github.com/CLOUDWERX-DEV/gpt-image-1-mcp"
    },
    "CaullenOmdahl--pexels-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Access and retrieve photos, videos, and collections from Pexels using a standardized protocol. Supports search by various criteria and provides detailed information about media content.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/CaullenOmdahl.webp",
      "keywords": [
        "pexels",
        "photos",
        "videos",
        "pexels mcp",
        "pexels using",
        "caullenomdahl pexels"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "pexels-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "CaullenOmdahl",
      "readme_content": "# Pexels MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@CaullenOmdahl/pexels-mcp-server)](https://smithery.ai/server/@CaullenOmdahl/pexels-mcp-server)\n\nA Model Context Protocol (MCP) server that provides access to the Pexels API, allowing AI models to search for and retrieve photos, videos, and collections from Pexels.\n\n## Features\n\n- Search for photos and videos by query, orientation, size, and color\n- Access curated and popular content from Pexels\n- Browse Pexels collections\n- Get detailed information about specific photos and videos\n- Access content via tools or direct URI resources\n\n## Requirements\n\n- Node.js 18 or higher\n- A Pexels API key (get one at [https://www.pexels.com/api/](https://www.pexels.com/api/))\n\n## Local Development\n\n1. Clone the repository\n2. Install dependencies\n   ```bash\n   pnpm install\n   ```\n3. Build the project\n   ```bash\n   pnpm build\n   ```\n4. Run in development mode\n   ```bash\n   PEXELS_API_KEY=your_api_key pnpm dev\n   ```\n\n## Deploying to Smithery\n\nThis MCP server is ready to be deployed to Smithery. Follow these steps:\n\n1. Add the server to Smithery or claim an existing server\n2. Go to the Deployments tab (only visible to authenticated owners)\n3. Deploy the server\n4. When configuring the deployment, provide your Pexels API key in the configuration settings\n\n## API Usage\n\nThe server provides the following tools:\n\n### Photo Tools\n\n- `searchPhotos`: Search for photos by query (use descriptive keywords for relevant results, e.g., 'Thai hotel reception', 'red sports car driving', not just 'hotel' or 'car'; combine with parameters like `orientation`, `size`, `color`, and `locale` for refined results), with optional filters for orientation, size, color, locale (e.g., 'en-US', 'es-ES'), page, and results per page. Returns metadata including photo IDs and URLs, plus current API rate limit status.\n- `downloadPhoto`: Fetches a specific photo by its ID and desired size (optional, defaults to 'original'). Available sizes: 'original', 'large2x', 'large', 'medium', 'small', 'portrait', 'landscape', 'tiny'. Returns a direct download link for the requested image size, suggested filename (including size), and attribution information. The AI client should use its available local tools (like `curl` or PowerShell's `Invoke-WebRequest`) to download the photo using the provided link.\n- `getCuratedPhotos`: Retrieve a curated set of photos from Pexels, optionally paginated.\n- `getPhoto`: Retrieve detailed information about a specific photo by its ID.\n\n### Video Tools\n\n- `searchVideos`: Search for videos by query (use descriptive keywords for relevant results, e.g., 'drone footage beach sunset', 'time lapse city traffic', not just 'beach' or 'city'; combine with parameters like `orientation` and `size` for refined results), with optional filters for orientation, size, locale (e.g., 'en-US', 'es-ES'), page, and results per page. Returns metadata including video IDs and URLs, plus current API rate limit status.\n- `getPopularVideos`: Retrieve a list of popular videos from Pexels, with optional filters for dimensions, duration, page, and results per page.\n- `getVideo`: Retrieve detailed information about a specific video by its ID.\n- `downloadVideo`: Fetches a specific video by its ID and preferred quality (hd/sd). Returns a direct download link, suggested filename, and attribution information. The AI client should use its available local tools (like `curl` or PowerShell's `Invoke-WebRequest`) to download the video using the provided link.\n\n### Collection Tools\n\n- `getFeaturedCollections`: Retrieve a list of featured collections from Pexels, optionally paginated.\n- ~~`getMyCollections`~~: (Commented out in code) Requires OAuth 2.0 authentication, not supported by this server.\n- `getCollectionMedia`: Retrieve media items (photos or videos) from a specific collection by collection ID, with optional filters for type, sort order, page, and results per page.\n\n### Resources\n\nThe server provides the following URI-addressable resources:\n\n- `pexels-photo://{id}`: Access a specific photo by ID\n- `pexels-video://{id}`: Access a specific video by ID\n- `pexels-collection://{id}`: Access a specific collection by ID\n\n## Error Handling\n\nThe server attempts to provide informative error messages for common issues like invalid API keys, rate limits, or missing resources. Successful responses also include the current Pexels API rate limit status (remaining requests, reset time) in the output.\n\n## Attribution Requirements\n\nWhen using the Pexels API, you must follow their attribution requirements:\n\n- Always show a prominent link to Pexels (e.g., \"Photos provided by Pexels\")\n- Always credit photographers (e.g., \"Photo by John Doe on Pexels\")\n\n## License\n\nISC",
      "stars": 4,
      "updated_at": "2025-07-30T15:07:46Z",
      "url": "https://github.com/CaullenOmdahl/pexels-mcp-server"
    },
    "Dreamboat-Rachel--MCP-Server-For-Local": {
      "category": "image-and-video-generation",
      "description": "Connect AI models to real-time data and tools with features such as weather querying, Google search automation, camera control, and image generation. The server supports modular expansion and custom API integration for tailored functionalities.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/Dreamboat-Rachel.webp",
      "keywords": [
        "ai",
        "automation",
        "server",
        "connect ai",
        "automation camera",
        "ai models"
      ],
      "language": "Python",
      "license": "Apache License 2.0",
      "name": "MCP-Server-For-Local",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Dreamboat-Rachel",
      "readme_content": "# MCP Server for Local\n\n‰∏Ä‰∏™Âü∫‰∫é MCP (Multi-Component Platform) ÁöÑÊú¨Âú∞‰ª£ÁêÜÊúçÂä°Âô®ÂíåÂÆ¢Êà∑Á´ØÂÆûÁé∞ÔºåÊèê‰æõÂ§öÁßç AI Â∑•ÂÖ∑Ë∞ÉÁî®ËÉΩÂäõ„ÄÇ\n\n## ÂäüËÉΩÁâπÁÇπ\n\n### Ê†∏ÂøÉÂäüËÉΩ\n- **Â§©Ê∞îÊü•ËØ¢**ÔºöÂÆûÊó∂Ëé∑ÂèñÂÖ®ÁêÉ‰ªªÊÑè‰ΩçÁΩÆÁöÑÂ§©Ê∞î‰ø°ÊÅØÔºåÊîØÊåÅÊ∏©Â∫¶„ÄÅÊπøÂ∫¶„ÄÅÈ£éÈÄüÁ≠âËØ¶ÁªÜÊï∞ÊçÆ\n- **Ë∞∑Ê≠åÊêúÁ¥¢**ÔºöÊô∫ËÉΩÊ£ÄÁ¥¢‰∫íËÅîÁΩë‰ø°ÊÅØÔºåÊîØÊåÅÂ§öËØ≠Ë®ÄÂíåÈ´òÁ∫ßÊêúÁ¥¢ËØ≠Ê≥ï\n- **ÊëÑÂÉèÂ§¥ÊéßÂà∂**ÔºöÊîØÊåÅÊãçÁÖß„ÄÅËßÜÈ¢ëÊµÅÂíåÂæÆË°®ÊÉÖÂàÜÊûêÔºåÂèØÁî®‰∫éÊÉÖÁª™ËØÜÂà´\n- **ÂõæÁâáÁîüÊàê**ÔºöÈõÜÊàê ComfyUIÔºåÊîØÊåÅÊñáÊú¨Âà∞ÂõæÂÉèÁöÑ AI ÁîüÊàê\n- **Êô∫ËÉΩÂØπËØù**ÔºöÂü∫‰∫é DashScope ÁöÑ AI ÂØπËØùËÉΩÂäõÔºåÊîØÊåÅ‰∏ä‰∏ãÊñáÁêÜËß£ÂíåÂ§öËΩÆÂØπËØù\n\n### ÊäÄÊúØÁâπÊÄß\n- Ë∑®Âπ≥Âè∞ÊîØÊåÅÔºàWindows Âíå LinuxÔºâ\n- Ê®°ÂùóÂåñËÆæËÆ°ÔºåÊòì‰∫éÊâ©Â±ïÊñ∞ÂäüËÉΩ\n- ÂÆåÊï¥ÁöÑÊó•ÂøóÁ≥ªÁªüÔºå‰æø‰∫éË∞ÉËØïÂíåÁõëÊéß\n- ÊîØÊåÅËá™ÂÆö‰πâÂ∑•ÂÖ∑Âíå API ÈõÜÊàê\n- È´òÊÄßËÉΩÂπ∂ÂèëÂ§ÑÁêÜËÉΩÂäõ\n\n## ÁéØÂ¢ÉÈÖçÁΩÆ\n\n### Á≥ªÁªüË¶ÅÊ±Ç\n- Python 3.8+\n- Node.js (ÂèØÈÄâÔºåÁî®‰∫éËøêË°å JavaScript ÊúçÂä°Âô®)\n- Chrome ÊµèËßàÂô®ÔºàÁî®‰∫éË∞∑Ê≠åÊêúÁ¥¢ÂäüËÉΩÔºâ\n- ÊëÑÂÉèÂ§¥ÔºàÁî®‰∫éÊãçÁÖßÂäüËÉΩÔºâ\n- Ëá≥Â∞ë 4GB ÂÜÖÂ≠ò\n- ÊîØÊåÅ CUDA ÁöÑÊòæÂç°ÔºàÂèØÈÄâÔºåÁî®‰∫éÂä†ÈÄü AI ËÆ°ÁÆóÔºâ\n\n### ÂÆâË£ÖÊ≠•È™§\n\n1. ÂÖãÈöÜ‰ªìÂ∫ìÔºö\n```bash\ngit clone https://github.com/yourusername/mcp-server-for-local.git\ncd mcp-server-for-local\n```\n\n2. ÂàõÂª∫Âπ∂ÊøÄÊ¥ªËôöÊãüÁéØÂ¢ÉÔºö\n```bash\n# Windows\npython -m venv .venv\n.venv\\Scripts\\activate\n\n# Linux\npython3 -m venv .venv\nsource .venv/bin/activate\n```\n\n3. ÂÆâË£Ö‰æùËµñÔºö\n```bash\n# ‰ΩøÁî® uv ÂÆâË£Ö‰æùËµñ\nuv pip install -r requirements.txt\n\n# Â¶ÇÊûúÈÅáÂà∞ÁΩëÁªúÈóÆÈ¢òÔºåÂèØ‰ª•‰ΩøÁî®ÂõΩÂÜÖÈïúÂÉè\nuv pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n4. ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö\n```bash\n# Â§çÂà∂ÁéØÂ¢ÉÂèòÈáèÊ®°Êùø\ncp .env.example .env\n\n# ÁºñËæë .env Êñá‰ª∂ÔºåËÆæÁΩÆ‰Ω†ÁöÑÈÖçÁΩÆ\n```\n\n### ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ\nÁºñËæë `.env` Êñá‰ª∂ÔºåËÆæÁΩÆ‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n- `DASHSCOPE_API_KEY`: DashScope API ÂØÜÈí•ÔºàÂøÖÂ°´Ôºâ\n- `MODEL`: ‰ΩøÁî®ÁöÑÊ®°ÂûãÂêçÁß∞ÔºàÈªòËÆ§Ôºöqwen-maxÔºâ\n- `CONFIG_FILE`: ÊúçÂä°Âô®ÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑ\n- `GAODE_API_KEY`: È´òÂæ∑Âú∞Âõæ API ÂØÜÈí•ÔºàÁî®‰∫éÂ§©Ê∞îÊü•ËØ¢Ôºâ\n- `CHROME_PATH`: Chrome ÊµèËßàÂô®Ë∑ØÂæÑ\n- `CHROMEDRIVER_PATH`: ChromeDriver Ë∑ØÂæÑ\n- `BASE_URL`: ComfyUI ÊúçÂä°Âô®Âú∞ÂùÄ\n- `SERVERS_DIR`: ÊúçÂä°Âô®ËÑöÊú¨ÁõÆÂΩï\n- `LOG_LEVEL`: Êó•ÂøóÁ∫ßÂà´ÔºàÂèØÈÄâÔºöDEBUG, INFO, WARNING, ERRORÔºâ\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\n### Âü∫Êú¨‰ΩøÁî®\n\n1. ËøõÂÖ•È°πÁõÆÁõÆÂΩïÔºö\n```bash\ncd src/mcp\n```\n\n2. ËøêË°åÂÆ¢Êà∑Á´ØÔºö\n```bash\nuv run .\\client\\mcp_client.py .\\proxy\\proxy_server.py\n```\n\n3. Âú®ÂÆ¢Êà∑Á´Ø‰∏≠ËæìÂÖ•ÂëΩ‰ª§Ôºå‰æãÂ¶ÇÔºö\n- \"Âåó‰∫¨ÁöÑÂ§©Ê∞îÊÄé‰πàÊ†∑Ôºü\"\n- \"Âú®Ë∞∑Ê≠å‰∏äÊêúÁ¥¢ Python ÊïôÁ®ã\"\n- \"ÊãçÁÖß\"\n- \"ÁîüÊàê‰∏ÄÂº†Áå´ÁöÑÂõæÁâá\"\n\n### È´òÁ∫ßÂäüËÉΩ\n\n1. **Ëá™ÂÆö‰πâÂ∑•ÂÖ∑**Ôºö\n   - Âú® `src/mcp/tools` ÁõÆÂΩï‰∏ãÊ∑ªÂä†Êñ∞ÁöÑÂ∑•ÂÖ∑Á±ª\n   - ÂÆûÁé∞ÂøÖË¶ÅÁöÑÊé•Âè£ÊñπÊ≥ï\n   - Âú®ÈÖçÁΩÆÊñá‰ª∂‰∏≠Ê≥®ÂÜåÊñ∞Â∑•ÂÖ∑\n\n2. **API Êâ©Â±ï**Ôºö\n   - ÊîØÊåÅÊ∑ªÂä†Êñ∞ÁöÑ API ÊúçÂä°\n   - ÂèØÈÖçÁΩÆ API ÂØÜÈí•ÂíåÁ´ØÁÇπ\n   - ÊîØÊåÅËá™ÂÆö‰πâËØ∑Ê±ÇÂíåÂìçÂ∫îÂ§ÑÁêÜ\n\n3. **Êó•ÂøóÁÆ°ÁêÜ**Ôºö\n   - ÊîØÊåÅÂ§öÁ∫ßÂà´Êó•ÂøóËÆ∞ÂΩï\n   - ÂèØÈÖçÁΩÆÊó•ÂøóËæìÂá∫‰ΩçÁΩÆ\n   - ÊîØÊåÅÊó•ÂøóËΩÆËΩ¨ÂíåÂΩíÊ°£\n\n## Â∏∏ËßÅÈóÆÈ¢ò\n\n### ÂÆâË£ÖÈóÆÈ¢ò\n\n1. ‰æùËµñÂÆâË£ÖÂ§±Ë¥•Ôºö\n```bash\n# Â∞ùËØïÊ∏ÖÁêÜÁºìÂ≠òÂêéÈáçÊñ∞ÂÆâË£Ö\nuv pip cache purge\nuv pip install -r requirements.txt\n```\n\n2. ËôöÊãüÁéØÂ¢ÉÈóÆÈ¢òÔºö\n```bash\n# Â¶ÇÊûúÊøÄÊ¥ªÂ§±Ë¥•ÔºåÂ∞ùËØïÈáçÊñ∞ÂàõÂª∫ËôöÊãüÁéØÂ¢É\nrm -rf .venv\npython -m venv .venv\n```\n\n### ËøêË°åÈóÆÈ¢ò\n\n1. ÊùÉÈôêÈóÆÈ¢òÔºö\n```bash\n# Linux\nchmod +x src/mcp/proxy/proxy_server.py\nchmod +x src/mcp/client/mcp_client.py\n```\n\n2. Chrome Áõ∏ÂÖ≥ÈóÆÈ¢òÔºö\n- Á°Æ‰øù Chrome Âíå ChromeDriver ÁâàÊú¨ÂåπÈÖç\n- Ê£ÄÊü• Chrome Ë∑ØÂæÑÊòØÂê¶Ê≠£Á°Æ\n- Á°Æ‰øùÊúâË∂≥Â§üÁöÑÊùÉÈôêËøêË°å Chrome\n- Â¶ÇÊûúÈÅáÂà∞È©±Âä®ÈóÆÈ¢òÔºåÂèØ‰ª•ÊâãÂä®‰∏ãËΩΩÂØπÂ∫îÁâàÊú¨ÁöÑ ChromeDriver\n\n3. API ÂØÜÈí•ÈóÆÈ¢òÔºö\n- Ê£ÄÊü• `.env` Êñá‰ª∂‰∏≠ÁöÑ API ÂØÜÈí•ÊòØÂê¶Ê≠£Á°Æ\n- Á°Æ‰øù API ÂØÜÈí•ÊúâË∂≥Â§üÁöÑÈÖçÈ¢ù\n- Ê£ÄÊü•ÁΩëÁªúËøûÊé•ÊòØÂê¶Ê≠£Â∏∏\n\n## ÂºÄÂèëÊåáÂçó\n\n### È°πÁõÆÁªìÊûÑ\n```\nsrc/mcp/\n‚îú‚îÄ‚îÄ client/          # ÂÆ¢Êà∑Á´Ø‰ª£Á†Å\n‚îú‚îÄ‚îÄ proxy/           # ‰ª£ÁêÜÊúçÂä°Âô®‰ª£Á†Å\n‚îú‚îÄ‚îÄ tools/           # Â∑•ÂÖ∑ÂÆûÁé∞\n‚îú‚îÄ‚îÄ utils/           # Â∑•ÂÖ∑ÂáΩÊï∞\n‚îî‚îÄ‚îÄ config/          # ÈÖçÁΩÆÊñá‰ª∂\n```\n\n### Ê∑ªÂä†Êñ∞ÂäüËÉΩ\n1. Âú® `tools` ÁõÆÂΩï‰∏ãÂàõÂª∫Êñ∞ÁöÑÂ∑•ÂÖ∑Á±ª\n2. ÂÆûÁé∞ÂøÖË¶ÅÁöÑÊé•Âè£ÊñπÊ≥ï\n3. Âú®ÈÖçÁΩÆÊñá‰ª∂‰∏≠Ê≥®ÂÜåÊñ∞Â∑•ÂÖ∑\n4. ÁºñÂÜôÊµãËØïÁî®‰æã\n5. Êõ¥Êñ∞ÊñáÊ°£\n\n## Ë¥°ÁåÆÊåáÂçó\n\nÊ¨¢ËøéÊèê‰∫§ Issue Âíå Pull RequestÔºÅÂú®Êèê‰∫§‰πãÂâçÔºåËØ∑Á°Æ‰øùÔºö\n1. ‰ª£Á†ÅÁ¨¶ÂêàÈ°πÁõÆËßÑËåÉ\n2. Ê∑ªÂä†‰∫ÜÂøÖË¶ÅÁöÑÊµãËØï\n3. Êõ¥Êñ∞‰∫ÜÁõ∏ÂÖ≥ÊñáÊ°£\n4. ÈÄöËøá‰∫ÜÊâÄÊúâÊµãËØï\n\n## ËÆ∏ÂèØËØÅ\n\nMIT License\n",
      "stars": 14,
      "updated_at": "2025-09-21T02:08:22Z",
      "url": "https://github.com/Dreamboat-Rachel/MCP-Server-For-Local"
    },
    "Emmanuel97423--video_maker": {
      "category": "image-and-video-generation",
      "description": "Create and manage video projects using an intuitive interface built with Next.js, facilitating video content creation and project management through streamlined workflows and powerful features.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/Emmanuel97423.webp",
      "keywords": [
        "video_maker",
        "video",
        "projects",
        "video generation",
        "video_maker create",
        "video projects"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "video_maker",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Emmanuel97423",
      "readme_content": "pmThis is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\n\nThis project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template\u0026filter=next.js\u0026utm_source=create-next-app\u0026utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.\n",
      "stars": 0,
      "updated_at": "2025-04-01T18:44:57Z",
      "url": "https://github.com/Emmanuel97423/video_maker"
    },
    "GMKR--mcp-imagegen": {
      "category": "image-and-video-generation",
      "description": "Generate images from text prompts using advanced AI models. Supports both local and SSE endpoint configurations with specific provider requirements.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/GMKR.webp",
      "keywords": [
        "imagegen",
        "mcp",
        "images",
        "mcp imagegen",
        "generate images",
        "imagegen generate"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "mcp-imagegen",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "GMKR",
      "readme_content": "# MCP Image Generator\n\nA Model Context Protocol (MCP) server for generating images using Together AI's image generation models. This MCP Server can be run locally or using an SSE endpoint. \nThe MCP Image Generator required a provider, only \"Replicate\" and \"Together\" are supported currently. You need to set the `TOGETHER_API_KEY` or `REPLICATE_API_TOKEN` environment variables. and set the `PROVIDER` environment variable to \"replicate\" or \"together\"/\n\n## SSE Endpoint (Docker environment)\n\n### Clone the repository\n\n```bash\ngit clone https://github.com/gmkr/mcp-imagegen.git\ncd mcp-imagegen\n```\n\n### Build and run Docker container\n\n```bash\ndocker build -f Dockerfile.server -t mcp-imagegen .\ndocker run -p 3000:3000 mcp-imagegen\n```\n\n### Configuring with MCP Client\n```\n{\n  \"mcpServers\": {\n    \"imagegenerator\": {\n      \"url\": \"http://localhost:3000/sse\",\n      \"env\": {\n        \"PROVIDER\": \"replicate\",\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      }\n    }\n  }\n}\n```\nAdjust the `url` to the endpoint of the MCP server you want to use.  `provider` can be \"replicate\" or \"together\".\n\n## Running locally using stdio\n\n### Prerequisites\n\n- Node.js\n- Together AI API key or Replicate API token\n\n### Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/gmkr/mcp-imagegen.git\n   cd mcp-imagegen\n   ```\n\n2. Install dependencies:\n   ```bash\n   pnpm install\n   ```\n### Configuration\nCreate a configuration file for your MCP client. Here's an example configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"imagegenerator\": {\n      \"command\": \"pnpx\",\n      \"args\": [\n        \"-y\",\n        \"tsx\",\n        \"/path/to/mcp-imagegen/src/index.ts\"\n      ],\n      \"env\": {\n        \"PROVIDER\": \"replicate\",\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      }\n    }\n  }\n}\n```\n\nReplace `/path/to/mcp-imagegen` with the absolute path to your cloned repository and `your-replicate-api-token` with your actual Replicate API token.\n\n## Usage\n\nThe MCP Image Generator provides a tool called `generate_image` that can be used to generate images based on text prompts.\n\n### Tool: generate_image\n\nGenerates an image based on the provided prompt.\n\n**Parameters:**\n- `prompt` (string): The text prompt to generate an image for\n- `width` (number, optional): The width of the image to generate (default: 512)\n- `height` (number, optional): The height of the image to generate (default: 512)\n- `numberOfImages` (number, optional): The number of images to generate (default: 1)\n\n## Environment Variables\n- `PROVIDER`: The provider to use for image generation (default: \"replicate\")\n- `REPLICATE_API_TOKEN`: Your Replicate API token\n- `TOGETHER_API_KEY`: Your Together AI API key\n- `MODEL_NAME`: The model to use for image generation (default: \"black-forest-labs/flux-schnell\")\n\n## License\n\nMIT \n",
      "stars": 4,
      "updated_at": "2025-06-18T01:58:09Z",
      "url": "https://github.com/GMKR/mcp-imagegen"
    },
    "Garoth--dalle-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate images from text prompts using OpenAI's DALL-E API. Edit existing images and create variations of them while ensuring API key validation for secure access.",
      "forks": 8,
      "imageUrl": "/freedevtools/mcp/pfp/Garoth.webp",
      "keywords": [
        "openai",
        "images",
        "garoth",
        "generate images",
        "mcp generate",
        "images create"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "dalle-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Garoth",
      "readme_content": "# DALL-E MCP Server\n\n\n\nAn MCP (Model Context Protocol) server for generating images using OpenAI's DALL-E API.\n\n## Features\n\n- Generate images using DALL-E 2 or DALL-E 3\n- Edit existing images (DALL-E 2 only)\n- Create variations of existing images (DALL-E 2 only)\n- Validate OpenAI API key\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Garoth/dalle-mcp.git\ncd dalle-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Important Note for Cline Users\n\nWhen using this DALL-E MCP server with Cline, it's recommended to save generated images in your current workspace directory by setting the `saveDir` parameter to match your current working directory. This ensures Cline can properly locate and display the generated images in your conversation.\n\nExample usage with Cline:\n```json\n{\n  \"prompt\": \"A tropical beach at sunset\",\n  \"saveDir\": \"/path/to/current/workspace\"\n}\n```\n\n\n## Usage\n\n### Running the Server\n\n```bash\n# Run the server\nnode build/index.js\n```\n\n### Configuration for Cline\n\nAdd the dall-e server to your Cline MCP settings file inside VSCode's settings (ex. ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json):\n\n```json\n{\n  \"mcpServers\": {\n    \"dalle-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/dalle-mcp-server/build/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your-api-key-here\",\n        \"SAVE_DIR\": \"/path/to/save/directory\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\nMake sure to:\n1. Replace `/path/to/dalle-mcp-server/build/index.js` with the actual path to the built index.js file\n2. Replace `your-api-key-here` with your OpenAI API key\n\n### Available Tools\n\n#### generate_image\n\nGenerate an image using DALL-E based on a text prompt.\n\n```json\n{\n  \"prompt\": \"A futuristic city with flying cars and neon lights\",\n  \"model\": \"dall-e-3\",\n  \"size\": \"1024x1024\",\n  \"quality\": \"standard\",\n  \"style\": \"vivid\",\n  \"n\": 1,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"futuristic-city\"\n}\n```\n\nParameters:\n- `prompt` (required): Text description of the desired image\n- `model` (optional): DALL-E model to use (\"dall-e-2\" or \"dall-e-3\", default: \"dall-e-3\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n  - DALL-E 3: \"1024x1024\", \"1792x1024\", or \"1024x1792\"\n  - DALL-E 2: \"256x256\", \"512x512\", or \"1024x1024\"\n- `quality` (optional): Quality of the generated image, DALL-E 3 only (\"standard\" or \"hd\", default: \"standard\")\n- `style` (optional): Style of the generated image, DALL-E 3 only (\"vivid\" or \"natural\", default: \"vivid\")\n- `n` (optional): Number of images to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the generated images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the generated images without extension (default: \"dalle-{timestamp}\")\n\n#### edit_image\n\nEdit an existing image using DALL-E based on a text prompt.\n\n\u003e **‚ö†Ô∏è Known Issue (March 18, 2025):** The DALL-E 2 image edit API currently has a bug where it sometimes ignores the prompt and returns the original image without any edits, even when using proper RGBA format images and masks. This issue has been reported in the [OpenAI community forum](https://community.openai.com/t/dall-e-2-image-edit-issue/668376/7). If you experience this issue, try using the `create_variation` tool instead, which seems to work more reliably.\n\n```json\n{\n  \"prompt\": \"Add a red hat\",\n  \"imagePath\": \"/path/to/image.png\",\n  \"mask\": \"/path/to/mask.png\",\n  \"model\": \"dall-e-2\",\n  \"size\": \"1024x1024\",\n  \"n\": 1,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"edited-image\"\n}\n```\n\nParameters:\n- `prompt` (required): Text description of the desired edits\n- `imagePath` (required): Path to the image to edit\n- `mask` (optional): Path to the mask image (white areas will be edited, black areas preserved)\n- `model` (optional): DALL-E model to use (currently only \"dall-e-2\" supports editing, default: \"dall-e-2\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n- `n` (optional): Number of images to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the edited images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the edited images without extension (default: \"dalle-edit-{timestamp}\")\n\n#### create_variation\n\nCreate variations of an existing image using DALL-E.\n\n```json\n{\n  \"imagePath\": \"/path/to/image.png\",\n  \"model\": \"dall-e-2\",\n  \"size\": \"1024x1024\",\n  \"n\": 4,\n  \"saveDir\": \"/path/to/save/directory\",\n  \"fileName\": \"image-variation\"\n}\n```\n\nParameters:\n- `imagePath` (required): Path to the image to create variations of\n- `model` (optional): DALL-E model to use (currently only \"dall-e-2\" supports variations, default: \"dall-e-2\")\n- `size` (optional): Size of the generated image (default: \"1024x1024\")\n- `n` (optional): Number of variations to generate (1-10, default: 1)\n- `saveDir` (optional): Directory to save the variation images (default: current directory or SAVE_DIR from .env). **For Cline users:** Setting this to your current workspace directory is recommended for proper image display.\n- `fileName` (optional): Base filename for the variation images without extension (default: \"dalle-variation-{timestamp}\")\n\n#### validate_key\n\nValidate the OpenAI API key.\n\n```json\n{}\n```\n\nNo parameters required.\n\n## Development\n\n## Testing Configuration\n\n**Note: The following .env configuration is ONLY needed for running tests, not for normal operation.**\n\nIf you're developing or running tests for this project, create a `.env` file in the root directory with your OpenAI API key:\n\n```\n# Required for TESTS ONLY: OpenAI API Key\nOPENAI_API_KEY=your-api-key-here\n\n# Optional: Default save directory for test images\n# If not specified, images will be saved to the current directory\n# SAVE_DIR=/path/to/save/directory\n```\n\nFor normal operation with Cline, configure your API key in the MCP settings JSON as described in the \"Adding to MCP Settings\" section above.\n\nYou can get your API key from [OpenAI's API Keys page](https://platform.openai.com/api-keys).\n\n### Running Tests\n\n```bash\n# Run basic tests\nnpm test\n\n# Run all tests including edit and variation tests\nnpm run test:all\n\n# Run tests in watch mode\nnpm run test:watch\n\n# Run specific test by name\nnpm run test:name \"should validate API key\"\n```\n\nNote: Tests use real API calls and may incur charges on your OpenAI account.\n\n### Generating Test Images\n\nThe project includes a script to generate test images for development and testing:\n\n```bash\n# Generate a test image in the assets directory\nnpm run generate-test-image\n  ```\n\nThis will create a simple test image in the `assets` directory that can be used for testing the edit and variation features.\n\n## License\n\nMIT",
      "stars": 10,
      "updated_at": "2025-08-14T03:51:46Z",
      "url": "https://github.com/Garoth/dalle-mcp"
    },
    "GongRzhe--Image-Generation-MCP-Server": {
      "category": "image-and-video-generation",
      "description": "Generate images from text prompts using the Replicate Flux model, enabling the creation of unique visuals tailored to specific specifications.",
      "forks": 8,
      "imageUrl": "/freedevtools/mcp/pfp/GongRzhe.webp",
      "keywords": [
        "generate",
        "mcp",
        "replicate",
        "generate images",
        "image generation",
        "video generation"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "Image-Generation-MCP-Server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "GongRzhe",
      "readme_content": "# Image Generation MCP Server\n![](https://badge.mcpx.dev?type=server 'MCP Server')\n\n[![smithery badge](https://smithery.ai/badge/@GongRzhe/Image-Generation-MCP-Server)](https://smithery.ai/server/@GongRzhe/Image-Generation-MCP-Server)\n\nThis MCP server provides image generation capabilities using the Replicate Flux model.\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Generation MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@GongRzhe/Image-Generation-MCP-Server):\n\n```bash\nnpx -y @smithery/cli install @GongRzhe/Image-Generation-MCP-Server --client claude\n```\n\n### Option 1: NPX Method (No Local Setup Required)\nYou can use the package directly from npm without installing it locally:\n\n```bash\n# No installation needed - npx will handle it\n```\n\n### Option 2: Local Installation\nIf you prefer a local installation:\n\n```bash\n# Global installation\nnpm install -g @gongrzhe/image-gen-server\n\n# Or local installation\nnpm install @gongrzhe/image-gen-server\n```\n\n## Setup\n\n### Configure Claude Desktop\n\nEdit your Claude Desktop configuration file:\n\n- On MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n#### Option 1: NPX Configuration (Recommended)\nThis method runs the server directly from npm without needing local files:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"npx\",\n      \"args\": [\"@gongrzhe/image-gen-server\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\",\n        \"MODEL\": \"alternative-model-name\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n#### Option 2: Local Installation Configuration\nIf you installed the package locally:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-gen-server/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\",\n        \"MODEL\": \"alternative-model-name\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Get Your Replicate API Token\n\n1. Sign up/login at https://replicate.com\n2. Go to https://replicate.com/account/api-tokens\n3. Create a new API token\n4. Copy the token and replace `your-replicate-api-token` in the MCP settings\n\n![image](https://github.com/user-attachments/assets/583afa78-1a08-4eb5-9a37-decb95bd50c4)\n\n### Environment Variables\n\n- `REPLICATE_API_TOKEN` (required): Your Replicate API token for authentication\n- `MODEL` (optional): The Replicate model to use for image generation. Defaults to \"black-forest-labs/flux-schnell\"\n\n### Configuration Parameters\n\n- `disabled`: Controls whether the server is enabled (`false`) or disabled (`true`)\n- `autoApprove`: Array of tool names that can be executed without user confirmation. Empty array means all tool calls require confirmation.\n\n## Available Tools\n\n### generate_image\n\nGenerates images using the Flux model based on text prompts.\n\n![image](https://github.com/user-attachments/assets/766921ce-ca8e-4d68-866d-8c7b55b2e09d)\n\n![out-0 (1)](https://github.com/user-attachments/assets/83549b2e-525a-4ff9-825c-83ba74459575)\n\n#### Parameters\n\n- `prompt` (required): Text description of the image to generate\n- `seed` (optional): Random seed for reproducible generation\n- `aspect_ratio` (optional): Image aspect ratio (default: \"1:1\")\n- `output_format` (optional): Output format - \"webp\", \"jpg\", or \"png\" (default: \"webp\")\n- `num_outputs` (optional): Number of images to generate (1-4, default: 1)\n\n#### Example Usage\n\n```typescript\nconst result = await use_mcp_tool({\n  server_name: \"image-gen\",\n  tool_name: \"generate_image\",\n  arguments: {\n    prompt: \"A beautiful sunset over mountains\",\n    aspect_ratio: \"16:9\",\n    output_format: \"png\",\n    num_outputs: 1\n  }\n});\n```\n\nThe tool returns an array of URLs to the generated images.\n\n## üìú License\n\nThis project is licensed under the MIT License.\n",
      "stars": 40,
      "updated_at": "2025-09-30T20:18:52Z",
      "url": "https://github.com/GongRzhe/Image-Generation-MCP-Server"
    },
    "Hajime-Y--deep-research-mcp": {
      "category": "image-and-video-generation",
      "description": "Provides advanced web search capabilities, document analysis, and image processing. Extracts information from various sources including PDFs and YouTube transcripts efficiently.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/Hajime-Y.webp",
      "keywords": [
        "mcp",
        "hajime",
        "search",
        "mcp provides",
        "research mcp",
        "hajime deep"
      ],
      "language": "Python",
      "license": "Apache License 2.0",
      "name": "deep-research-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Hajime-Y",
      "readme_content": "# Deep Research MCP Server\n\nDeep Research is an agent-based tool that provides web search and advanced research capabilities. It leverages HuggingFace's `smolagents` and is implemented as an MCP server.\n\nThis project is based on [HuggingFace's open_deep_research example](https://github.com/huggingface/smolagents/tree/main/examples/open_deep_research).\n\n## Features\n\n- Web search and information gathering\n- PDF and document analysis\n- Image analysis and description\n- YouTube transcript retrieval\n- Archive site search\n\n## Requirements\n\n- Python 3.11 or higher\n- `uv` package manager\n- The following API keys:\n  - OpenAI API key\n  - HuggingFace token\n  - SerpAPI key\n\n## Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/Hajime-Y/deep-research-mcp.git\ncd deep-research-mcp\n```\n\n2. Create a virtual environment and install dependencies:\n\n```bash\nuv venv\nsource .venv/bin/activate # For Linux or Mac\n# .venv\\Scripts\\activate # For Windows\nuv sync\n```\n\n## Environment Variables\n\nCreate a `.env` file in the root directory of the project and set the following environment variables:\n\n```\nOPENAI_API_KEY=your_openai_api_key\nHF_TOKEN=your_huggingface_token\nSERPER_API_KEY=your_serper_api_key\n```\n\nYou can obtain a SERPER_API_KEY by signing up at [Serper.dev](https://serper.dev/signup).\n\n## Usage\n\nStart the MCP server:\n\n```bash\nuv run deep_research.py\n```\n\nThis will launch the `deep_research` agent as an MCP server.\n\n## Docker Usage\n\nYou can also run this MCP server in a Docker container:\n\n```bash\n# Build the Docker image\ndocker build -t deep-research-mcp .\n\n# Run with required API keys\ndocker run -p 8080:8080 \\\n  -e OPENAI_API_KEY=your_openai_api_key \\\n  -e HF_TOKEN=your_huggingface_token \\\n  -e SERPER_API_KEY=your_serper_api_key \\\n  deep-research-mcp\n```\n\n### Registering with MCP Clients\n\nTo register this Docker container as an MCP server in different clients:\n\n#### Claude Desktop\n\nAdd the following to your Claude Desktop configuration file (typically located at `~/.config/Claude/claude_desktop_config.json` on Linux, `~/Library/Application Support/Claude/claude_desktop_config.json` on macOS, or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Cursor IDE\n\nFor Cursor IDE, add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \n        \"-i\", \n        \"--rm\", \n        \"-e\", \"OPENAI_API_KEY=your_openai_api_key\",\n        \"-e\", \"HF_TOKEN=your_huggingface_token\", \n        \"-e\", \"SERPER_API_KEY=your_serper_api_key\",\n        \"deep-research-mcp\"\n      ]\n    }\n  }\n}\n```\n\n#### Using with Remote MCP Server\n\nIf you're running the MCP server on a remote machine or exposing it as a service, you can use the URL-based configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"deep-research-mcp\": {\n      \"url\": \"http://your-server-address:8080/mcp\",\n      \"type\": \"sse\"\n    }\n  }\n}\n```\n\n## Key Components\n\n- `deep_research.py`: Entry point for the MCP server\n- `create_agent.py`: Agent creation and configuration\n- `scripts/`: Various tools and utilities\n  - `text_web_browser.py`: Text-based web browser\n  - `text_inspector_tool.py`: File inspection tool\n  - `visual_qa.py`: Image analysis tool\n  - `mdconvert.py`: Converts various file formats to Markdown\n\n## License\n\nThis project is provided under the Apache License 2.0.\n\n## Acknowledgements\n\nThis project uses code from HuggingFace's `smolagents` and Microsoft's `autogen` projects.",
      "stars": 12,
      "updated_at": "2025-09-06T18:57:01Z",
      "url": "https://github.com/Hajime-Y/deep-research-mcp"
    },
    "Hzzy2O--flux-cloudfare-mcp": {
      "category": "image-and-video-generation",
      "description": "Provides high-quality image generation via the Flux model through a Cloudflare Worker API, enabling seamless integration into applications with customizable parameters for image output.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/Hzzy2O.webp",
      "keywords": [
        "cloudflare",
        "flux",
        "cloudfare",
        "flux cloudfare",
        "cloudfare mcp",
        "model cloudflare"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "flux-cloudfare-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Hzzy2O",
      "readme_content": "# Flux Cloudflare MCP\n\n![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue)\n![Model Context Protocol](https://img.shields.io/badge/MCP-Enabled-purple)\n\nA powerful Model Context Protocol (MCP) server that provides AI assistants with the ability to generate images using [Black Forest Labs' Flux model](https://developer.cloudflare.com/ai-gateway/models/flux-1/) via a Cloudflare Worker API.\n\n[Installation](#installation) ‚Ä¢ [Features](#features) ‚Ä¢ [Usage](#usage) ‚Ä¢ [Documentation](#documentation) ‚Ä¢ [Contributing](#contributing)\n\n---\n\n## üåü Features\n\n- **üñºÔ∏è High-Quality Image Generation**: Access to Flux, a state-of-the-art image generation model\n- **ü§ñ Seamless AI Integration**: Enable AI assistants like Claude to generate images directly\n- **üéõÔ∏è Customizable Parameters**: Control aspect ratio, inference steps, and more\n- **üîå MCP Compatible**: Works with any MCP client (Cursor, Claude Desktop, Cline, Zed, etc.)\n- **üîí Local Processing**: All requests are processed securely through the Cloudflare Worker\n- **üí¨ Chat Completions**: Get text completions using the same API\n\n## üì¶ Installation\n\n### Direct Usage with NPX\n\n```bash\nFLUX_API_TOKEN=your_token FLUX_API_URL=your_api_url npx -y flux-cloudflare-mcp\n```\n\n### From Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/Hzzy2O/flux-cloudflare-mcp.git\ncd flux-cloudflare-mcp\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## üöÄ Setting Up Your Flux API\n\nThis MCP server requires a Flux API endpoint to function. You have two options for setting up the API:\n\n### Option 1: Deploy using snakeying/flux-api-worker (Recommended)\n\n[snakeying/flux-api-worker](https://github.com/snakeying/flux-api-worker) provides a simple and efficient Cloudflare Worker for accessing the Flux model:\n\n1. Fork the [flux-api-worker repository](https://github.com/snakeying/flux-api-worker)\n2. Deploy it to Cloudflare Workers:\n   - Create a new Worker in your Cloudflare dashboard\n   - Connect it to your forked repository\n   - Set up the required environment variables:\n     - `API_KEY`: Your chosen API key for authentication\n     - `CF_ACCOUNT_ID`: Your Cloudflare account ID\n     - `CF_API_TOKEN`: Your Cloudflare API token with Workers AI access\n     - `FLUX_MODEL`: The Flux model to use (default: \"@cf/black-forest-labs/flux-1-schnell\")\n3. Once deployed, your API will be available at `https://your-worker-name.your-subdomain.workers.dev`\n4. Use this URL as your `FLUX_API_URL` and your chosen API key as `FLUX_API_TOKEN`\n\n### Option 2: Deploy using aigem/cf-flux-remix\n\nFor a more feature-rich implementation with a web UI, you can use [aigem/cf-flux-remix](https://github.com/aigem/cf-flux-remix):\n\n1. Follow the installation instructions in the [cf-flux-remix repository](https://github.com/aigem/cf-flux-remix)\n2. Once deployed, your API will be available at your deployed URL\n3. Use this URL as your `FLUX_API_URL` and your configured API key as `FLUX_API_TOKEN`\n\n## üìö Documentation\n\n### Available Tools\n\n#### `generate_image`\n\nGenerates an image based on a text prompt using the Flux model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the image to generate\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n}\n```\n\n## üîß Usage\n\n### Cursor Integration\n\n#### Method 1: Using mcp.json\n\n1. Create or edit the `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-cloudflare-mcp\": {\n      \"command\": \"env FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx\",\n      \"args\": [\"-y\", \"flux-cloudflare-mcp\"]\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Flux API token and `YOUR_API_URL` with your API URL\n3. Restart Cursor to apply the changes\n\n#### Method 2: Using Cursor MCP Settings\n\n1. Open Cursor and go to Settings\n2. Navigate to the \"MCP\" or \"Model Context Protocol\" section\n3. Click \"Add Server\" or equivalent\n4. Enter the following command in the appropriate field:\n\n```\nenv FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx -y flux-cloudflare-mcp\n```\n\n5. Replace `YOUR_TOKEN` with your actual Flux API token and `YOUR_API_URL` with your API URL\n6. Save the settings and restart Cursor if necessary\n\n### Claude Desktop Integration\nenv FLUX_API_TOKEN=YOUR_TOKEN FLUX_API_URL=YOUR_API_URL npx -y flux-cloudflare-mcp\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-cloudflare-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"flux-cloudflare-mcp\"],\n      \"env\": {\n        \"FLUX_API_TOKEN\": \"YOUR_TOKEN\",\n        \"FLUX_API_URL\": \"YOUR_API_URL\"\n      }\n    }\n  }\n}\n```\n\n## üíª Local Development\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/Hzzy2O/flux-cloudflare-mcp.git\ncd flux-cloudflare-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\n## üõ† Technical Stack\n\n* Model Context Protocol SDK - Core MCP functionality\n* Cloudflare Workers - Serverless API for image generation\n* TypeScript - Type safety and modern JavaScript features\n* Zod - Runtime type validation\n\n## ‚öôÔ∏è Configuration\n\nThe server requires the following environment variables:\n\n- `FLUX_API_TOKEN`: Your API token for authentication with the Flux API\n- `FLUX_API_URL`: The URL of your deployed Flux API (from snakeying/flux-api-worker or aigem/cf-flux-remix)\n\n## üîç Troubleshooting\n\n### Common Issues\n\n#### Authentication Error\n- Ensure your `FLUX_API_TOKEN` is correctly set in the environment\n- Verify your token is valid by testing it with the Flux API directly\n\n#### API Connection Issues\n- Check that your Flux API (Cloudflare Worker) is running and accessible\n- Ensure your network allows connections to Cloudflare Workers\n\n#### Safety Filter Triggered\n- The model has a built-in safety filter that may block certain prompts\n- Try modifying your prompt to avoid potentially problematic content\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## üîó Resources\n\n- [Model Context Protocol Documentation](https://modelcontextprotocol.io)\n- [Cloudflare Workers Documentation](https://developers.cloudflare.com/workers/)\n- [Flux Model Documentation](https://developer.cloudflare.com/ai-gateway/models/flux-1/)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n- [snakeying/flux-api-worker](https://github.com/snakeying/flux-api-worker) - Simple Flux API implementation\n- [aigem/cf-flux-remix](https://github.com/aigem/cf-flux-remix) - Feature-rich Flux API with web UI\n\n[![smithery badge](https://smithery.ai/badge/@Hzzy2O/flux-cloudfare-mcp)](https://smithery.ai/server/@Hzzy2O/flux-cloudfare-mcp)\n",
      "stars": 0,
      "updated_at": "2025-03-17T01:14:19Z",
      "url": "https://github.com/Hzzy2O/flux-cloudfare-mcp"
    },
    "IA-Programming--mcp-images": {
      "category": "image-and-video-generation",
      "description": "Fetch and process images from URLs and local file paths, handling automatic compression and MIME type retrieval. Images are returned as base64-encoded strings to facilitate integration and support parallel processing with robust error handling.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/IA-Programming.webp",
      "keywords": [
        "base64",
        "images",
        "mcp",
        "mcp images",
        "process images",
        "programming mcp"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp-images",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "IA-Programming",
      "readme_content": "# MCP Server - Image\nA Model Context Protocol (MCP) server that provides tools for fetching and processing images from URLs, local file paths, and numpy arrays. The server includes a tool called fetch_images that returns images as base64-encoded strings along with their MIME types.\n\n## Support Us\n\nIf you find this project helpful and would like to support future projects, consider buying us a coffee! Your support helps us continue building innovative AI solutions.\n\n\u003ca href=\"https://www.buymeacoffee.com/blazzmocompany\"\u003e\u003cimg alt=\"text_Buy_me_a_coffee_emoji_slug_blazzmocompany_button_colour_40DCA5_font_colour_ffffff_font_family_Cookie_outline_colour_000000_coffee_colour_FFDD00\" src=\"https://img.buymeacoffee.com/button-api/?text=Buy me a coffee\u0026emoji=\u0026slug=blazzmocompany\u0026button_colour=40DCA5\u0026font_colour=ffffff\u0026font_family=Cookie\u0026outline_colour=000000\u0026coffee_colour=FFDD00\"\u003e\u003c/a\u003e\n\nYour contributions go a long way in fueling our passion for creating intelligent and user-friendly applications.\n\n## Table of Contents\n- [Features](#features)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Running the Server](#running-the-server)\n  - [Direct Method](#1-direct-method)\n  - [Configure for Windsurf/Cursor](#2-configure-for-windsurfcursor)\n- [Available Tools](#available-tools)\n  - [Usage Examples](#usage-examples)\n- [Debugging](#debugging)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Features\n- Fetch images from URLs (http/https)\n- Load images from local file paths\n- Specialized handling for large local images\n- Automatic image compression for large images (\u003e1MB)\n- Parallel processing of multiple images\n- Proper MIME type mapping for different file extensions\n- Comprehensive error handling and logging\n## Prerequisites\n- Python 3.10+\n- uv package manager (recommended)\n## Installation\n1. Clone this repository\n2. Create and activate a virtual environment using uv:\n```bash\nuv venv\n# On Windows:\n.venv\\Scripts\\activate\n# On Unix/MacOS:\nsource .venv/bin/activate\n```\n3. Install dependencies using uv:\n```bash\nuv pip install -r requirements.txt\n```\n## Running the Server\nThere are two ways to run the MCP server:\n\n### 1. Direct Method\nTo start the MCP server directly:\n\n```bash\nuv run python mcp_image.py\n```\n### 2. Configure for Windsurf/Cursor\n#### Windsurf\nTo add this MCP server to Windsurf:\n\n1. Edit the configuration file at ~/.codeium/windsurf/mcp_config.json\n2. Add the following configuration:\n```json\n{\n  \"mcpServers\": {\n    \"image\": {\n      \"command\": \"uv\",\n        \"args\": [\"--directory\", \"/path/to/mcp-image\", \"run\", \"mcp_image.py\"]\n    }\n  }\n}\n```\n#### Cursor\nTo add this MCP server to Cursor:\n\n1. Open Cursor and go to *Settings* (Navbar ‚Üí Cursor Settings)\n2. Navigate to *Features* ‚Üí *MCP Servers*\n3. Click on + Add New MCP Server\n4. Enter the following configuration:\n```json\n{\n  \"mcpServers\": {\n    \"image\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/path/to/mcp-image\", \"run\", \"mcp_image.py\"]\n    }\n  }\n}\n```\n\n## Available Tools\nThe server provides the following tools:\n\n[fetch_images](mcp_image.py#L318): Fetch and process images from URLs or local file paths\nParameters:\nimage_sources: List of URLs or file paths to images\nReturns:\nList of processed images with base64 encoding and MIME types\n\n### Usage Examples\nYou can now use commands like:\n\n- \"Fetch these images: [list of URLs or file paths]\"\n- \"Load and process this local image: [file_path]\"\n\n#### Examples\n```\n# URL-only test\n[\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Chocolate_%28blue_background%29.jpg/400px-Chocolate_%28blue_background%29.jpg\",\n  \"https://imgs.search.brave.com/Sz7BdlhBoOmU4wZjnUkvgestdwmzOzrfc3GsiMr27Ik/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9pbWdj/ZG4uc3RhYmxlZGlm/ZnVzaW9ud2ViLmNv/bS8yMDI0LzEwLzE4/LzJmOTY3NTViLTM0/YmQtNDczNi1iNDRh/LWJlMTVmNGM5MDBm/My5qcGc\",\n  \"https://shigacare.fukushi.shiga.jp/mumeixxx/img/main.png\"\n]\n\n# Mixed URL and local file test\n[\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Chocolate_%28blue_background%29.jpg/400px-Chocolate_%28blue_background%29.jpg\",\n  \"C:\\\\Users\\\\username\\\\Pictures\\\\image1.jpg\",\n  \"https://imgs.search.brave.com/Sz7BdlhBoOmU4wZjnUkvgestdwmzOzrfc3GsiMr27Ik/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9pbWdj/ZG4uc3RhYmxlZGlm/ZnVzaW9ud2ViLmNv/bS8yMDI0LzEwLzE4/LzJmOTY3NTViLTM0/YmQtNDczNi1iNDRh/LWJlMTVmNGM5MDBm/My5qcGc\",\n  \"C:\\\\Users\\\\username\\\\Pictures\\\\image2.jpg\"\n]\n```\n\n## Debugging\nIf you encounter any issues:\n\n1. Check that all dependencies are installed correctly\n2. Verify that the server is running and listening for connections\n3. For local image loading issues, ensure the file paths are correct and accessible\n4. For \"Unsupported image type\" errors, verify the content type handling\n5. Look for any error messages in the server output\n## Contributing\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.",
      "stars": 13,
      "updated_at": "2025-09-24T05:36:12Z",
      "url": "https://github.com/IA-Programming/mcp-images"
    },
    "IncomeStreamSurfer--chatgpt-native-image-gen-mcp": {
      "category": "image-and-video-generation",
      "description": "Generates and edits images using OpenAI's advanced image generation model based on text prompts. Supports image inpainting and variations, with customizable filenames for automated saving.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/IncomeStreamSurfer.webp",
      "keywords": [
        "openai",
        "images",
        "image",
        "image generation",
        "image gen",
        "video generation"
      ],
      "language": "Python",
      "license": "Apache License 2.0",
      "name": "chatgpt-native-image-gen-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "IncomeStreamSurfer",
      "readme_content": "# OpenAI Image Generation MCP Server\n\nThis project implements an MCP (Model Context Protocol) server that provides tools for generating and editing images using OpenAI's `gpt-image-1` model via the official Python SDK.\n\n## Features\n\nThis MCP server provides the following tools:\n\n*   **`generate_image`**: Generates an image using OpenAI's `gpt-image-1` model based on a text prompt and saves it.\n    *   **Input Schema:**\n        ```json\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"prompt\": { \"type\": \"string\", \"description\": \"The text description of the desired image(s).\" },\n            \"model\": { \"type\": \"string\", \"default\": \"gpt-image-1\", \"description\": \"The model to use (currently 'gpt-image-1').\" },\n            \"n\": { \"type\": [\"integer\", \"null\"], \"default\": 1, \"description\": \"The number of images to generate (Default: 1).\" },\n            \"size\": { \"type\": [\"string\", \"null\"], \"enum\": [\"1024x1024\", \"1536x1024\", \"1024x1536\", \"auto\"], \"default\": \"auto\", \"description\": \"Image dimensions ('1024x1024', '1536x1024', '1024x1536', 'auto'). Default: 'auto'.\" },\n            \"quality\": { \"type\": [\"string\", \"null\"], \"enum\": [\"low\", \"medium\", \"high\", \"auto\"], \"default\": \"auto\", \"description\": \"Rendering quality ('low', 'medium', 'high', 'auto'). Default: 'auto'.\" },\n            \"user\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"An optional unique identifier representing your end-user.\" },\n            \"save_filename\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional filename (without extension). If None, a default name based on the prompt and timestamp is used.\" }\n          },\n          \"required\": [\"prompt\"]\n        }\n        ```\n    *   **Output:** `{\"status\": \"success\", \"saved_path\": \"path/to/image.png\"}` or error dictionary.\n\n*   **`edit_image`**: Edits an image or creates variations using OpenAI's `gpt-image-1` model and saves it. Can use multiple input images as reference or perform inpainting with a mask.\n    *   **Input Schema:**\n        ```json\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"prompt\": { \"type\": \"string\", \"description\": \"The text description of the desired final image or edit.\" },\n            \"image_paths\": { \"type\": \"array\", \"items\": { \"type\": \"string\" }, \"description\": \"A list of file paths to the input image(s). Must be PNG. \u003c 25MB.\" },\n            \"mask_path\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional file path to the mask image (PNG with alpha channel) for inpainting. Must be same size as input image(s). \u003c 25MB.\" },\n            \"model\": { \"type\": \"string\", \"default\": \"gpt-image-1\", \"description\": \"The model to use (currently 'gpt-image-1').\" },\n            \"n\": { \"type\": [\"integer\", \"null\"], \"default\": 1, \"description\": \"The number of images to generate (Default: 1).\" },\n            \"size\": { \"type\": [\"string\", \"null\"], \"enum\": [\"1024x1024\", \"1536x1024\", \"1024x1536\", \"auto\"], \"default\": \"auto\", \"description\": \"Image dimensions ('1024x1024', '1536x1024', '1024x1536', 'auto'). Default: 'auto'.\" },\n            \"quality\": { \"type\": [\"string\", \"null\"], \"enum\": [\"low\", \"medium\", \"high\", \"auto\"], \"default\": \"auto\", \"description\": \"Rendering quality ('low', 'medium', 'high', 'auto'). Default: 'auto'.\" },\n            \"user\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"An optional unique identifier representing your end-user.\" },\n            \"save_filename\": { \"type\": [\"string\", \"null\"], \"default\": null, \"description\": \"Optional filename (without extension). If None, a default name based on the prompt and timestamp is used.\" }\n          },\n          \"required\": [\"prompt\", \"image_paths\"]\n        }\n        ```\n    *   **Output:** `{\"status\": \"success\", \"saved_path\": \"path/to/image.png\"}` or error dictionary.\n\n## Prerequisites\n\n*   Python (3.8 or later recommended)\n*   pip (Python package installer)\n*   An OpenAI API Key (set directly in the script or via the `OPENAI_API_KEY` environment variable - **using environment variables is strongly recommended for security**).\n*   An MCP client environment (like the one used by Cline) capable of managing and launching MCP servers.\n\n## Installation\n\n1.  **Clone the repository:**\n    ```bash\n    git clone https://github.com/IncomeStreamSurfer/chatgpt-native-image-gen-mcp.git\n    cd chatgpt-native-image-gen-mcp\n    ```\n2.  **Set up a virtual environment (Recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n    ```\n3.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n4.  **(Optional but Recommended) Set Environment Variable:**\n    Set the `OPENAI_API_KEY` environment variable with your OpenAI key instead of hardcoding it in the script. How you set this depends on your operating system.\n\n## Configuration (for Cline MCP Client)\n\nTo make this server available to your AI assistant (like Cline), add its configuration to your MCP settings file (e.g., `cline_mcp_settings.json`).\n\nFind the `mcpServers` object in your settings file and add the following entry:\n\n```json\n{\n  \"mcpServers\": {\n    // ... other server configurations ...\n\n    \"openai-image-gen-mcp\": {\n      \"autoApprove\": [\n        \"generate_image\",\n        \"edit_image\"\n      ],\n      \"disabled\": false,\n      \"timeout\": 180, // Increased timeout for potentially long image generation\n      \"command\": \"python\", // Or path to python executable if not in PATH\n      \"args\": [\n        // IMPORTANT: Replace this path with the actual absolute path\n        // to the openai_image_mcp.py file on your system\n        \"C:/path/to/your/cloned/repo/chatgpt-native-image-gen-mcp/openai_image_mcp.py\"\n      ],\n      \"env\": {\n        // If using environment variables for the API key:\n        // \"OPENAI_API_KEY\": \"YOUR_API_KEY_HERE\"\n      },\n      \"transportType\": \"stdio\"\n    }\n\n    // ... other server configurations ...\n  }\n}\n```\n\n**Important:** Replace `C:/path/to/your/cloned/repo/` with the correct absolute path to where you cloned this repository on your machine. Ensure the path separator is correct for your operating system (e.g., use backslashes `\\` on Windows). If you set the API key via environment variable, you can remove it from the script and potentially add it to the `env` section here if your MCP client supports it.\n\n## Running the Server\n\nYou don't typically need to run the server manually. The MCP client (like Cline) will automatically start the server using the `command` and `args` specified in the configuration file when one of its tools is called for the first time.\n\nIf you want to test it manually (ensure dependencies are installed and API key is available):\n```bash\npython openai_image_mcp.py\n```\n\n## Usage\n\nThe AI assistant interacts with the server using the `generate_image` and `edit_image` tools. Images are saved within an `ai-images` subdirectory created where the `openai_image_mcp.py` script is located. The tools return the absolute path to the saved image upon success.\n",
      "stars": 15,
      "updated_at": "2025-10-03T22:33:09Z",
      "url": "https://github.com/IncomeStreamSurfer/chatgpt-native-image-gen-mcp"
    },
    "InhiblabCore--mcp-image-compression": {
      "category": "image-and-video-generation",
      "description": "Optimizes images by compressing various formats for faster loading and improved user experience, while offering features like offline usage and batch processing. Supports smart compression to balance file size and visual quality based on image content.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/InhiblabCore.webp",
      "keywords": [
        "compression",
        "compressing",
        "inhiblabcore",
        "image compression",
        "images compressing",
        "smart compression"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "mcp-image-compression",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "InhiblabCore",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/inhiblabcore-mcp-image-compression-badge.png)](https://mseep.ai/app/inhiblabcore-mcp-image-compression)\n\n# mcp-image-compression\n\n## Project Overview\n\nmcp-image-compression is a high-performance image compression microservice based on MCP (Modal Context Protocol) architecture. This service focuses on providing fast and high-quality image compression capabilities to help developers optimize image resources for websites and applications, improving loading speed and user experience.\n\n## Features\n\n- **Multi-format support**: Compress mainstream image formats including JPEG, PNG, WebP, AVIF\n- **Offline Usage**: No need to connect to the internet to use\n- **Smart compression**: Automatically select optimal compression parameters based on image content\n- **Batch processing**: Support parallel compression of multiple images for improved efficiency\n- **Quality control**: Customizable compression quality to balance file size and visual quality\n\n## TOOLS\n\n1. `image_compression`\n   - Image compression\n   - Inputs:\n     - `urls` (strings): URLs of images to compress\n     - `quality` (int): Quality of compression (0-100)\n     - `format` (string): Format of compressed image (e.g. \"jpeg\", \"png\", \"webp\", \"avif\")\n   - Returns: Compressed images url\n\n## Setup\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"Image compression\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@inhiblab-core/mcp-image-compression\"\n      ],\n      \"env\": {\n        \"IMAGE_COMPRESSION_DOWNLOAD_DIR\": \"\u003cYOUR_DIR\u003e\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Build\n\n```bash\ndocker build -t mcp-image-compression .\n```\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n\n",
      "stars": 26,
      "updated_at": "2025-08-22T03:13:54Z",
      "url": "https://github.com/InhiblabCore/mcp-image-compression"
    },
    "JeremyNixon--mcp-fetch": {
      "category": "image-and-video-generation",
      "description": "Fetches web content and processes images for integration with AI models, streamlining the retrieval and handling of online content in various applications.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/JeremyNixon.webp",
      "keywords": [
        "ai",
        "images",
        "retrieval",
        "images integration",
        "processes images",
        "ai models"
      ],
      "language": "",
      "license": "MIT License",
      "name": "mcp-fetch",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "JeremyNixon",
      "readme_content": "# MCP Fetch\n\n[![smithery badge](https://smithery.ai/badge/@kazuph/mcp-fetch)](https://smithery.ai/server/@kazuph/mcp-fetch)\n\nModel Context Protocol server for fetching web content and processing images. This allows Claude Desktop (or any MCP client) to fetch web content and handle images appropriately.\n\n## Quick Start (For Users)\n\nTo use this tool with Claude Desktop, simply add the following to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"tools\": {\n    \"fetch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-fetch\"]\n    }\n  }\n}\n```\n\nThis will automatically download and run the latest version of the tool when needed.\n\n### Required Setup\n\n1. Enable Accessibility for Claude:\n   - Open System Settings\n   - Go to Privacy \u0026 Security \u003e Accessibility\n   - Click the \"+\" button\n   - Add Claude from your Applications folder\n   - Turn ON the toggle for Claude\n\nThis accessibility setting is required for automated clipboard operations (Cmd+V) to work properly.\n\n## For Developers\n\nThe following sections are for those who want to develop or modify the tool.\n\n## Prerequisites\n\n- Node.js 18+\n- macOS (for clipboard operations)\n- Claude Desktop (install from https://claude.ai/desktop)\n- tsx (install via `npm install -g tsx`)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MCP Fetch for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@kazuph/mcp-fetch):\n\n```bash\nnpx -y @smithery/cli install @kazuph/mcp-fetch --client claude\n```\n\n### Manual Installation\n```bash\ngit clone https://github.com/kazuph/mcp-fetch.git\ncd mcp-fetch\nnpm install\nnpm run build\n```\n\n## Image Processing Specifications\n\nWhen processing images from web content, the following limits are applied:\n\n- Maximum 6 images per group\n- Maximum height of 8000 pixels per group\n- Maximum size of 30MB per group\n\nIf content exceeds these limits, images will be automatically split into multiple groups, and you'll need to paste (Cmd+V) multiple times.\n\n## Configuration\n\n1. Make sure Claude Desktop is installed and running.\n\n2. Install tsx globally if you haven't:\n```bash\nnpm install -g tsx\n# or\npnpm add -g tsx\n```\n\n3. Modify your Claude Desktop config located at:\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\nYou can easily find this through the Claude Desktop menu:\n1. Open Claude Desktop\n2. Click Claude on the Mac menu bar\n3. Click \"Settings\"\n4. Click \"Developer\"\n\nAdd the following to your MCP client's configuration:\n\n```json\n{\n  \"tools\": {\n    \"fetch\": {\n      \"args\": [\"tsx\", \"/path/to/mcp-fetch/index.ts\"]\n    }\n  }\n}\n```\n\n## Available Tools\n\n- `fetch`: Retrieves URLs from the Internet and extracts their content as markdown. Images are automatically processed and prepared for clipboard operations.\n\n## Notes\n\n- This tool is designed for macOS only due to its dependency on macOS-specific clipboard operations.\n- Images are processed using Sharp for optimal performance and quality.\n- When multiple images are found, they are merged vertically with consideration for size limits.\n- Animated GIFs are automatically handled by extracting their first frame.\n",
      "stars": 0,
      "updated_at": "2025-03-15T18:56:32Z",
      "url": "https://github.com/JeremyNixon/mcp-fetch"
    },
    "JigsawStack--jigsawstack-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generate images from text using advanced AI models. The server facilitates the integration and management of image generation tools within an MCP framework.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/JigsawStack.webp",
      "keywords": [
        "jigsawstack",
        "ai",
        "mcp",
        "generate images",
        "image generation",
        "jigsawstack mcp"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "jigsawstack-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "JigsawStack",
      "readme_content": "# JigsawStack MCP Server\n\n## Introduction\nJigsawStack MCP (Model Context Protocol) Server is a versatile platform designed to facilitate the integration and management of various tools. Each directory within the server represents a distinct tool that can be utilized for different purposes by an LLM. The server is built using Node.js and Express.js, and each tool is encapsulated within its own directory, making it easy to add, remove, or update tools without affecting the overall system.\n\nStart by obtaining your JIGSAWSTACK_API_KEY from the our website. You will need this key to access the JigsawStack services. You can get your API key by signing up for a free account at [JigsawStack](https://jigsawstack.com/dashboard).\n\nYou can also install our MCPs via [Smithery AI](https://smithery.ai/?q=jigsawstack)\n\n## Installation\n\n### Prerequisites\n- Ensure you have `git` installed on your system.\n- Ensure you have `node.js` and `npm` installed.\n- Alternatively, you can use `yarn` instead of `npm`. as a package manager.\n\n### Steps to Setup the repository:\n1. Clone the repository:\n    ```sh\n    git clone https://github.com/yourusername/jigsawstack-mcp-server.git\n    ```\n2. Navigate to the project directory:\n    ```sh\n    cd jigsawstack-mcp-server\n    ```\n3. Install the necessary dependencies:\n    ```sh\n    npm install or yarn install\n    ```\n\n## What is MCP?\nMCP stands for Model Context Protocol. It is a framework that allows users to integrate LLMs and manage various tools and components exposing external data in a modular fashion. Here each tool is encapsulated within its own directory, making it easy to add, remove, or update tools without affecting the overall system.\n\n## Using JigsawStack MCP Server\nThere are four tools available in the MCP Server. Each tool is contained within its own directory and has its own set of instructions for use.\n\n### Running a tool\nTo run a tool,\n1. cd into the tool directory and follow the instructions.\n2. Export the JIGSAWSTACK_API_KEY environment variable with your JIGSAWSTACK API key.\n    ```sh\n    export JIGSAWSTACK_API_KEY=your_api_key\n    ```\n3. Start the server:\n    ```sh\n    npm start\n    ```\n4. Access the server through your web browser at `http://localhost:3000`.\n\n### Directory Structure\n- `/ai-web-scraper`: Let AI scrape the internet for you!\n- `/ai-web-search`: Search powered by AI capable of handling complex queries.\n- `/image-generation`: Generate images using prompts, to receive a base64 string of the image.\n\n## Contact\nFor any questions or issues, please contact us at hello@jigsawstack.com.\n",
      "stars": 23,
      "updated_at": "2025-08-22T15:15:38Z",
      "url": "https://github.com/JigsawStack/jigsawstack-mcp-server"
    },
    "Kira-Pgr--PromptShopMCP": {
      "category": "image-and-video-generation",
      "description": "Transforms images based on natural language commands, enabling users to edit photos by describing desired changes such as adding accessories or modifying backgrounds.",
      "forks": 7,
      "imageUrl": "/freedevtools/mcp/pfp/Kira-Pgr.webp",
      "keywords": [
        "promptshopmcp",
        "images",
        "pgr",
        "pgr promptshopmcp",
        "promptshopmcp transforms",
        "video generation"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "PromptShopMCP",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Kira-Pgr",
      "readme_content": "# PromptShopMCP\n\n![](https://badge.mcpx.dev?type=server 'MCP Server')  \n\nEnglish | [‰∏≠Êñá](README_ZH.md)   \n\n\nA powerful MCP (Model Context Protocol) server that transforms images using simple text commands. Edit photos like a professional designer - just describe what you want in natural language!\n## Demo\nOriginal Image  \n\u003cimg alt=\"a987b4c4_3bba_4a52_a2a8_9f088868d857\" src=\"https://github.com/user-attachments/assets/a987b4c4-3bba-4a52-a2a8-9f088868d857\" width=\"300\"/\u003e  \n\nPrompt: **add a coat to the dog**  \n\u003cimg alt=\"6de3cdd1_a3b9_422b_95dd_12e2172f6f1d\" src=\"https://github.com/user-attachments/assets/6de3cdd1-a3b9-422b-95dd-12e2172f6f1d\" width=\"300\"/\u003e  \n\nPrompt: **Add a hat to it**  \n\u003cimg alt=\"047289ca_f3d0_4d16_acf7_09d5af641c68\" src=\"https://github.com/user-attachments/assets/047289ca-f3d0-4d16-acf7-09d5af641c68\" width=\"300\"/\u003e  \n \n\n##  Features\n\n- **Image Generation**: Create images from text prompts using Google's Gemini models\n- **Image Modification**: Transform existing images based on text instructions\n- **Background Removal**: Remove backgrounds from images using the remove.bg API\n- **Image Hosting**: Share generated images via FreeImage.host\n- **Resource Management**: Track and manage generated and uploaded images\n\n## Requirements\n\n- Python 3.11 or higher\n- Required API keys:\n  - Google Gemini API key [Get key](https://aistudio.google.com/apikey)\n  - FreeImage.host API key [Get key](https://freeimage.host/page/api)\n  - Remove.bg API key [Get key](https://www.remove.bg/dashboard#api-key)\n\n##  Installation\n\n1. Clone this repository:\n   ```sh\n   git https://github.com/Kira-Pgr/Image-Toolkit-MCP-Server.git\n   cd Image-Toolkit-MCP-Server\n   ```\n\n2. Install UV (if not already installed):\n   ```sh\n   # On macOS and Linux.\n   curl -LsSf https://astral.sh/uv/install.sh | sh\n   # On Windows.\n   powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n   # With pip.\n   pip install uv\n   ```\n\n3. Install dependencies using UV:\n   ```sh\n   uv venv --python=python3.11\n   source .venv/bin/activate #or .venv/Scripts/activate on Windows\n   uv pip install -r requirements.txt\n   ```\n\n##  Usage\n\n1. **Claude Desktop Integration**: Add the following configuration to your `claude_desktop_config.json` file to run the server directly from Claude Desktop:\n   ```json\n   \"PromptShopMCP\": {\n     \"command\": \"uv\",\n     \"args\": [\n       \"--directory\",\n       \"/project/dir/\",\n       \"run\",\n       \"mcp\",\n       \"run\",\n       \"/project/dir/server.py\"\n     ],\n     \"env\": {\n       \"GEMINI_API_KEY\": \"key\",\n       \"FREEIMAGE_API_KEY\": \"key\",\n       \"REMOVEBG_API_KEY\": \"key\"\n     }\n   }\n   ```\n   Note: Replace the placeholder `\"key\"` values with your actual API keys.\n2. **Cursor Integration**:    \n   **Linux/macOS**:\n  Modify the `cursor.sh` file to set your API keys and project directory.   \n  * In cursor settings, go to the \"MCP\" tab, click on `Add new MCP server`,   \n  * Name the server whatever you want, and set the command to `sh /absolute/path/to/cursor.sh`.   \n  * Wait for the server to start, and you can see the server and available tools.   \n  * Then when you use the agent, it would automatically detect whether use the tools.   \n  \u003cimg width=\"1240\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b41016fe-a0f8-4029-8f5d-82f25c606a65\" /\u003e\n  \n  **Windows**: \n  Modify the `cursor.bat` file to set your API keys and project directory.   \n  * In cursor settings, go to the \"MCP\" tab, click on `Add new MCP server`,   \n  * Name the server whatever you want, and set the command to `cmd /c C:\\absolute\\path\\to\\cursor.bat`.   \n  * Wait for the server to start, and you can see the server and available tools.   \n  * Then when you use the agent, it would automatically detect whether use the tools.   \n\n\n\n\n## Acknowledgements\n\n- [Google Gemini](https://aistudio.google.com/): For the image generation capabilities\n- [Remove.bg](https://www.remove.bg/): For background removal services\n- [FreeImage.host](https://freeimage.host/): For image hosting services\n- [MCP](https://modelcontextprotocol.io/introduction): For the Model Context Protocol\n",
      "stars": 14,
      "updated_at": "2025-10-03T20:38:19Z",
      "url": "https://github.com/Kira-Pgr/PromptShopMCP"
    },
    "Letz-AI--letzai-mcp": {
      "category": "image-and-video-generation",
      "description": "Create and upscale images based on prompts using the LetzAI MCP. This server integrates with the Claude Desktop App for seamless image generation.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/Letz-AI.webp",
      "keywords": [
        "upscale",
        "letzai",
        "images",
        "image generation",
        "upscale images",
        "video generation"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "letzai-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Letz-AI",
      "readme_content": "# LetzAI MCP Setup Guide\n\nThis guide will walk you through the process of setting up and using the LetzAI MCP (Model Context Protocol) for image generation.\n\n## Prerequisites\n\nBefore you begin, ensure that you have the following:\n\n- **Node.js** installed on your system. You can download it from [Node.js official site](https://nodejs.org/).\n- **Claude Desktop App** installed. If you don't have it, download it from [Claude Desktop App](https://claude.app).\n- **LetzAI API Key**. You can obtain it by visiting [LetzAI API](https://letz.ai/docs/api).\n\n## Setup Steps\n\n### 1. Download the Git Folder\n\nDownload the repository containing the LetzAI MCP project and place it in a location outside of your Downloads folder. For example:\n\n```\nC:\\\\Users\\\\username\\\\desktop\n```\n\nAlternatively, you can use `git clone` to clone the repository:\n\n```bash\ngit clone \u003crepository-url\u003e C:\\\\Users\\\\username\\\\desktop\n```\n\n### 2. Install Dependencies\n\nNavigate to the project folder using your terminal or command prompt:\n\n```bash\ncd C:\\\\Users\\\\username\\\\desktop\n```\n\nRun the following command to install all required dependencies:\n\n```bash\nnpm install\n```\n\n### 3. Compile the Project\n\nAfter installing the dependencies, compile the TypeScript files into JavaScript using the following command:\n\n```bash\nnpx tsc\n```\n\nThis will generate the compiled JavaScript files in the `build` folder.\n\n### 4. Restart Claude App\n\nAfter running `npx tsc`, you must **restart** the Claude Desktop App for it to recognize the updated MCP configuration and compiled files.\n\n### 5. Set Up MCP Configuration in Claude Desktop App\n\n\n\n1. **Open the Claude Desktop App**.\n2. **Click on the Menu Icon** in the top-left corner.\n3. From the dropdown, select **File**.\n4. Navigate to **Settings**.\n5. Under the **Developer** section, you will see an option for **Edit Config**.\n   \n6. Click on **Edit Config** ‚Äî this will open the configuration folder.\n7. Locate the file `claude_desktop_config.json` and edit it as needed.\n\n#### Windows Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"C:\\\\ABSOLUTE\\\\PATH\\\\TO\\\\PARENT\\\\FOLDER\\\\letzai-mcp\\\\build\\\\index.js\"\n      ],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"\u003cYour LetzAI API Key\u003e\"\n      }\n    }\n  }\n}\n```\n\n#### Ubuntu Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/PARENT/FOLDER/letzai-mcp/build/index.js\"],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"\u003cYour LetzAI API Key\u003e\"\n      }\n    }\n  }\n}\n```\n\n#### macOS Configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"letzai\": {\n      \"command\": \"node\",\n      \"args\": [\"/ABSOLUTE/PATH/TO/PARENT/FOLDER/letzai-mcp/build/index.js\"],\n      \"env\": {\n        \"LETZAI_API_KEY\": \"\u003cYour LetzAI API Key\u003e\"\n      }\n    }\n  }\n}\n```\n\n### Configuration Explanation\n\n- **command**: The command to run the application. We use `node` to run the JavaScript file generated by TypeScript.\n- **args**: This is the path to the compiled `index.js` file. Make sure the path is correct according to where your files are located after compilation. If you've placed the folder at `C:\\\\Users\\\\username\\\\desktop\\\\letzai-mcp`, the path will be:\n\n```\n\nC:\\\\Users\\\\username\\\\desktop\\\\letzai-mcp\\\\build\\\\index.js\n\n```\n\n### 6. Run the MCP Server\n\nNow that everything is set up, you can start using the LetzAI MCP in the Claude Desktop App. The server should be ready for image generation tasks once the app is running with the correct API key in the environment.\n\n**Important:** After making changes to the configuration, you **must restart Claude** for the changes to take effect.\n\n### 7. Testing the New MCP in Claude\n\n\nClick on the hammer icon to view the installed MCP tools.\n\n\nOnce you've set up the MCP in the Claude Desktop App, you can test it by running the following prompt:\n\n- **Create image with LetzAI using prompt: \"photo of @mischstrotz drinking a beer, dressed as a knight\"**\n\nThis will create the image based on the provided prompt, using the model @mischstrotz from LetzAI. Claude will open the image in your preferred browser.\n\n- **Upscale this image with strength 1: [https://letz.ai/image/d6a67077-f156-46d7-a1a2-1dc49e83dd91](https://images.letz.ai/5ed74083-f9d1-4897-b8e3-c8f1596af767/d6a67077-f156-46d7-a1a2-1dc49e83dd91/high_quality_photo_of_mischstrotz_holding_a_beer_s20250322080513.jpg)**\n\nThis will upscale the image using the strength parameter 1. You can pass entire URLs, or just the LetzAI Image IDs e.g. d6a67077-f156-46d7-a1a2-1dc49e83dd91\n\n## Troubleshooting\n\n- **Node.js not found**: Ensure that Node.js is installed and added to your system's PATH environment variable.\n- **Invalid API Key**: Double-check that you have correctly added your API key under the `LETZAI_API_KEY` variable in the Claude Desktop App settings.\n- **File Path Issues**: Make sure that the path to the `index.js` file is correct. If you're unsure about the path, use the absolute path to the file.\n\nFor more detailed documentation and support, visit [LetzAI Docs](https://letz.ai/docs/api).",
      "stars": 1,
      "updated_at": "2025-03-25T17:46:55Z",
      "url": "https://github.com/Letz-AI/letzai-mcp"
    },
    "LoganLxb--LoganLxb": {
      "category": "image-and-video-generation",
      "description": "Logan provides tools and applications aimed at enhancing user interaction in mixed reality environments through augmented and virtual reality technologies. It focuses on facilitating the development of immersive digital experiences and applications.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/LoganLxb.webp",
      "keywords": [
        "loganlxb",
        "immersive",
        "logan",
        "virtual reality",
        "augmented virtual",
        "generation loganlxb"
      ],
      "language": "",
      "license": "No License",
      "name": "LoganLxb",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "LoganLxb",
      "readme_content": "\u003ch2 align=\"center\"\u003eHi there üëã\u003c/h2\u003e\n\u003c!--\n**LoganLxb/LoganLxb** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.\n--\u003e\n\n## üñ•Ô∏è Logan\n\nI'm a developers experienced in creating and developing the future thanks to AR,VR and Mixed reality.\n\n- üî≠ I‚Äôm currently working on democratizing mixed reality with Glassear\n- üå± I‚Äôm currently learning computer vision, python and c#\n\n## üí¨ Ask me about ...\n* Unity development\n* Mobile / headmounted Augmented Reality\n* Virtual Reality\n* Image detection\n\n##  üëÄ Find me\n- üì´ How to reach me: logan@xrexp.io\n\n[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=LoganLxb\u0026layout=compact\u0026theme=gruvbox)](https://github.com/LoganLxb/github-readme-stats)\n",
      "stars": 0,
      "updated_at": "2024-10-08T18:42:17Z",
      "url": "https://github.com/LoganLxb/LoganLxb"
    },
    "Lucker631--mcp-templateio": {
      "category": "image-and-video-generation",
      "description": "Generates customized visuals by creating images based on templates using the Templated.io API. Supports dynamic graphics creation through user-provided text and image URLs.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/Lucker631.webp",
      "keywords": [
        "templateio",
        "templated",
        "templates",
        "mcp templateio",
        "templateio generates",
        "graphics creation"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "mcp-templateio",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Lucker631",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/lucker631-mcp-templateio-badge.png)](https://mseep.ai/app/lucker631-mcp-templateio)\n\n# MCP TemplateIO - Image Generation Tool\n\nA Model Context Protocol (MCP) server built with mcp-framework that provides an image generation tool using Templated.io.\n\n## Overview\n\nThis template provides a starting point for building MCP servers with custom tools. It includes an example tool and instructions on how to add more tools, develop them, and publish them to npm. This README will guide you through the process of setting up, developing, and deploying your own MCP server.\n\n## Quick Start\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Project Structure\n\n```\nmcp-templateio/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ tools/        # MCP Tools\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ExampleTool.ts\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TemplatedImageTool.ts # Image generation tool\n‚îÇ   ‚îî‚îÄ‚îÄ index.ts      # Server entry point\n‚îú‚îÄ‚îÄ package.json\n‚îî‚îÄ‚îÄ tsconfig.json\n```\n\n## Available Tools\n\n### Templated Image Generator\n\nThis tool generates an image based on a template, given text and image URLs, using the Templated.io API.\n\n**Input Parameters:**\n\n- `templateId`: ID of the Templated.io template to use\n- `photoBgImageUrl`: URL for the image to place in the \"photo-bg\" layer.\n- `bgYellowImageUrl`: URL for the image to place in the \"bg-yellow\" layer.\n- `buildText`: Text content for the \"build\" text layer.\n\n## Tool Development\n\nExample tool structure:\n\n```typescript\nimport { MCPTool } from \"mcp-framework\";\nimport { z } from \"zod\";\n\ninterface MyToolInput {\n  message: string;\n}\n\nclass MyTool extends MCPTool\u003cMyToolInput\u003e {\n  name = \"my_tool\";\n  description = \"Describes what your tool does\";\n\n  schema = {\n    message: {\n      type: z.string(),\n      description: \"Description of this input parameter\",\n    },\n  };\n\n  async execute(input: MyToolInput) {\n    // Your tool logic here\n    return `Processed: ${input.message}`;\n  }\n}\n\nexport default MyTool;\n```\n\n## Adding Components\n\nThe project comes with an example tool in `src/tools/ExampleTool.ts` and the `TemplatedImageTool.ts`. You can add more tools using the CLI:\n\n```bash\n# Add a new tool\nmcp add tool my-tool\n\n# Example tools you might create:\nmcp add tool data-processor\nmcp add tool api-client\nmcp add tool file-handler\n```\n\n## Publishing to npm\n\n1. Update your package.json:\n\n   - Ensure `name` is unique and follows npm naming conventions\n   - Set appropriate `version`\n   - Add `description`, `author`, `license`, etc.\n   - Check `bin` points to the correct entry file\n\n2. Build and test locally:\n\n   ```bash\n   npm run build\n   npm link\n   mcp-templateio  # Test your CLI locally\n   ```\n\n3. Login to npm (create account if necessary):\n\n   ```bash\n   npm login\n   ```\n\n4. Publish your package:\n   ```bash\n   npm publish\n   ```\n\nAfter publishing, users can add it to their claude desktop client (read below) or run it with npx\n\n## Using with Claude Desktop\n\n### Local Development\n\nAdd this configuration to your Claude Desktop config file:\n\n**MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n**Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-templateio\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp-templateio/dist/index.js\"]\n    }\n  }\n}\n```\n\n### After Publishing\n\nGET YOUR API KEY HERE: https://app.templated.io/api-integration?template=4ae9a86b-4ecd-44ee-aebd-7c5a49c16969\n\nAdd this configuration to your Claude Desktop config file:\n\n**MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n**Windows**: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-templateio\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"C:\\\\Users\\\\alex0\\\\Documents\\\\AA_CodeAndScripts\\\\modelcontextprotocol\\\\mcp-templateio\\\\dist\\\\index.js\"\n      ],\n      \"env\": {\"TEMPLATED_API_KEY\":\"YOUR-API-KEY-HERE\"}\n    },\n  }\n}\n```\n\n## Building and Testing\n\n1. Make changes to your tools\n2. Run `npm run build` to compile\n3. The server will automatically load your tools on startup\n\n## Learn More\n\n- [MCP Framework Github](https://github.com/QuantGeekDev/mcp-framework)\n- [MCP Framework Docs](https://mcp-framework.com)\n",
      "stars": 0,
      "updated_at": "2025-07-10T15:36:42Z",
      "url": "https://github.com/Lucker631/mcp-templateio"
    },
    "MichaelYangjson--mcp-ghibli-video": {
      "category": "image-and-video-generation",
      "description": "Transforms static images into animated videos using AI technology. Users can manage video generation tasks and check API credits through a straightforward interface.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/MichaelYangjson.webp",
      "keywords": [
        "animated",
        "ghibli",
        "videos",
        "animated videos",
        "video generation",
        "ghibli video"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "mcp-ghibli-video",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "MichaelYangjson",
      "readme_content": "# mcp-server-ghibli MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@MichaelYangjson/mcp-ghibli-video)](https://smithery.ai/server/@MichaelYangjson/mcp-ghibli-video)\n\nA TypeScript-based MCP server that provides AI image and video generation capabilities through a simple interface.\n\n\u003e **Note**: This server requires an API key from [GPT4O Image Generator](https://www.gpt4oimg.com/). Please visit the website to obtain your API key before using this service.\n\n## Features\n\n### Tools\n\n#### 1. Image to Video Conversion\n\n- `image_to_video` - Convert static images into animated videos\n  - Required parameters:\n    - `image`: Base64 encoded image or image URL\n    - `api_key`: Authentication key\n  - Optional parameters:\n    - `prompt`: Text prompt to guide video generation (default: \"in the style of ghibli\")\n    - `aspect_ratio`: Output video aspect ratio (default: \"9:16\")\n    - `negative_prompt`: Negative prompt to guide generation (default: \"bad prompt\")\n\n#### 2. Points Management\n\n- `get_points` - Check remaining API credits\n  - Required parameters:\n    - `api_key`: Authentication key\n\n#### 3. Task Management\n\n- `get_task_result` - Check the status of a video generation task\n  - Required parameters:\n    - `taskId`: Task ID returned from image_to_video\n    - `api_key`: Authentication key\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm install\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-ghibli-video\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@openmcprouter/mcp-server-ghibli-video\"],\n      \"env\": {\n        \"Ghibli_API_URL\": \"https://www.gpt4oimg.com\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install mcp-server-ghibli MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MichaelYangjson/mcp-ghibli-video):\n\n```bash\nnpx -y @smithery/cli install @MichaelYangjson/mcp-ghibli-video --client claude\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "stars": 4,
      "updated_at": "2025-09-29T13:57:06Z",
      "url": "https://github.com/MichaelYangjson/mcp-ghibli-video"
    },
    "MiniMax-AI--MiniMax-MCP-JS": {
      "category": "image-and-video-generation",
      "description": "Integrates with MiniMax's AI capabilities to facilitate interaction with multimedia generation tools, including image generation, video generation, text-to-speech, and voice cloning. Supports a flexible and configurable JavaScript/TypeScript framework for versatile deployment scenarios.",
      "forks": 29,
      "imageUrl": "/freedevtools/mcp/pfp/MiniMax-AI.webp",
      "keywords": [
        "minimax",
        "multimedia",
        "javascript",
        "minimax ai",
        "ai minimax",
        "mcp js"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "MiniMax-MCP-JS",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "MiniMax-AI",
      "readme_content": "![export](https://github.com/MiniMax-AI/MiniMax-01/raw/main/figures/MiniMaxLogo-Light.png)\n\n\u003cdiv align=\"center\"\u003e\n\n# MiniMax MCP JS\n\nJavaScript/TypeScript implementation of MiniMax MCP, providing image generation, video generation, text-to-speech, and more.\n\n\u003cdiv style=\"line-height: 1.5;\"\u003e\n  \u003ca href=\"https://www.minimax.io\" target=\"_blank\" style=\"margin: 2px; color: var(--fgColor-default);\"\u003e\n    \u003cimg alt=\"Homepage\" src=\"https://img.shields.io/badge/_Homepage-MiniMax-FF4040?style=flat-square\u0026labelColor=2C3E50\u0026logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+\u0026logoWidth=20\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://arxiv.org/abs/2501.08313\" target=\"_blank\" style=\"margin: 2px;\"\u003e\n    \u003cimg alt=\"Paper\" src=\"https://img.shields.io/badge/üìñ_Paper-MiniMax--01-FF4040?style=flat-square\u0026labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://chat.minimax.io/\" target=\"_blank\" style=\"margin: 2px;\"\u003e\n    \u003cimg alt=\"Chat\" src=\"https://img.shields.io/badge/_MiniMax_Chat-FF4040?style=flat-square\u0026labelColor=2C3E50\u0026logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+\u0026logoWidth=20\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://www.minimax.io/platform\" style=\"margin: 2px;\"\u003e\n    \u003cimg alt=\"API\" src=\"https://img.shields.io/badge/‚ö°_API-Platform-FF4040?style=flat-square\u0026labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n\u003c/div\u003e\n\n\u003cdiv style=\"line-height: 1.5;\"\u003e\n  \u003ca href=\"https://huggingface.co/MiniMaxAI\" target=\"_blank\" style=\"margin: 2px;\"\u003e\n    \u003cimg alt=\"Hugging Face\" src=\"https://img.shields.io/badge/ü§ó_Hugging_Face-MiniMax-FF4040?style=flat-square\u0026labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://github.com/MiniMax-AI/MiniMax-AI.github.io/blob/main/images/wechat-qrcode.jpeg\" target=\"_blank\" style=\"margin: 2px;\"\u003e\n    \u003cimg alt=\"WeChat\" src=\"https://img.shields.io/badge/_WeChat-MiniMax-FF4040?style=flat-square\u0026labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://www.modelscope.cn/organization/MiniMax\" target=\"_blank\" style=\"margin: 2px;\"\u003e\n    \u003cimg alt=\"ModelScope\" src=\"https://img.shields.io/badge/_ModelScope-MiniMax-FF4040?style=flat-square\u0026labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n\u003c/div\u003e\n\n\u003cdiv style=\"line-height: 1.5;\"\u003e\n  \u003ca href=\"https://github.com/MiniMax-AI/MiniMax-MCP-JS/blob/main/LICENSE\" style=\"margin: 2px;\"\u003e\n    \u003cimg alt=\"Code License\" src=\"https://img.shields.io/badge/_Code_License-MIT-FF4040?style=flat-square\u0026labelColor=2C3E50\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://smithery.ai/server/@MiniMax-AI/MiniMax-MCP-JS\"\u003e\u003cimg alt=\"Smithery Badge\" src=\"https://smithery.ai/badge/@MiniMax-AI/MiniMax-MCP-JS\"\u003e\u003c/a\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e\n\n## Documentation\n\n- [‰∏≠ÊñáÊñáÊ°£](README.zh-CN.md)\n- [Python Version](https://github.com/MiniMax-AI/MiniMax-MCP) - Official Python implementation of MiniMax MCP\n\n## Release Notes\n\n### July 22, 2025\n\n#### üîß Fixes \u0026 Improvements\n- **TTS Tool Fixes**: Fixed parameter handling for `languageBoost` and `subtitleEnable` in the `text_to_audio` tool\n- **API Response Enhancement**: TTS API can return both audio file and subtitle file, providing a more complete speech-to-text experience\n\n### July 7, 2025\n\n#### üÜï What's New\n- **Voice Design**: New `voice_design` tool - create custom voices from descriptive prompts with preview audio\n- **Video Enhancement**: Added `MiniMax-Hailuo-02` model with ultra-clear quality and duration/resolution controls  \n- **Music Generation**: Enhanced `music_generation` tool powered by `music-1.5` model\n\n#### üìà Enhanced Tools\n- `voice_design` - Generate personalized voices from text descriptions\n- `generate_video` - Now supports MiniMax-Hailuo-02 with 6s/10s duration and 768P/1080P resolution options\n- `music_generation` - High-quality music creation with music-1.5 model\n\n## Features\n\n- Text-to-Speech (TTS)\n- Image Generation\n- Video Generation\n- Voice Cloning\n- Music Generation\n- Voice Design\n- Dynamic configuration (supports both environment variables and request parameters)\n- Compatible with MCP platform hosting (ModelScope and other MCP platforms)\n\n## Installation\n\n### Installing via Smithery\n\nTo install MiniMax MCP JS for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@MiniMax-AI/MiniMax-MCP-JS):\n\n```bash\nnpx -y @smithery/cli install @MiniMax-AI/MiniMax-MCP-JS --client claude\n```\n\n### Installing manually\n```bash\n# Install with pnpm (recommended)\npnpm add minimax-mcp-js\n```\n\n## Quick Start\n\nMiniMax MCP JS implements the [Model Context Protocol (MCP)](https://github.com/anthropics/model-context-protocol) specification and can be used as a server to interact with MCP-compatible clients (such as Claude AI).\n\n### Quickstart with MCP Client\n\n1. Get your API key from [MiniMax International Platform](https://www.minimax.io/platform/user-center/basic-information/interface-key).\n2. Make sure that you already installed [Node.js and npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\n3. **Important: API HOST\u0026KEY are different in different region**, they must match, otherwise you will receive an `Invalid API key` error.\n\n|Region| Global  | Mainland  |\n|:--|:-----|:-----|\n|MINIMAX_API_KEY| go get from [MiniMax Global](https://www.minimax.io/platform/user-center/basic-information/interface-key) | go get from [MiniMax](https://platform.minimaxi.com/user-center/basic-information/interface-key) |\n|MINIMAX_API_HOST| ‚Äãhttps://api.minimaxi.chat (note the extra **\"i\"**) | ‚Äãhttps://api.minimax.chat |\n\n\n### Using with MCP Clients (Recommended)\n\nConfigure your MCP client:\n\n#### Claude Desktop\n\nGo to `Claude \u003e Settings \u003e Developer \u003e Edit Config \u003e claude_desktop_config.json` to include:\n\n```json\n{\n  \"mcpServers\": {\n    \"minimax-mcp-js\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"minimax-mcp-js\"\n      ],\n      \"env\": {\n        \"MINIMAX_API_HOST\": \"\u003chttps://api.minimaxi.chat|https://api.minimax.chat\u003e\",\n        \"MINIMAX_API_KEY\": \"\u003cyour-api-key-here\u003e\",\n        \"MINIMAX_MCP_BASE_PATH\": \"\u003clocal-output-dir-path, such as /User/xxx/Desktop\u003e\",\n        \"MINIMAX_RESOURCE_MODE\": \"\u003coptional, [url|local], url is default, audio/image/video are downloaded locally or provided in URL format\u003e\"\n      }\n    }\n  }\n}\n```\n\n#### Cursor\n\nGo to `Cursor ‚Üí Preferences ‚Üí Cursor Settings ‚Üí MCP ‚Üí Add new global MCP Server` to add the above config.\n\n‚ö†Ô∏è **Note**: If you encounter a \"No tools found\" error when using MiniMax MCP JS with Cursor, please update your Cursor to the latest version. For more information, see this [discussion thread](https://forum.cursor.com/t/mcp-servers-no-tools-found/49094/23).\n\nThat's it. Your MCP client can now interact with MiniMax through these tools.\n\n**For local development**: \nWhen developing locally, you can use `npm link` to test your changes:\n```bash\n# In your project directory\nnpm link\n```\n\nThen configure Claude Desktop or Cursor to use npx as shown above. This will automatically use your linked version.\n\n‚ö†Ô∏è **Note**: The API key needs to match the host address. Different hosts are used for global and mainland China versions:\n- Global Host: `https://api.minimaxi.chat` (note the extra \"i\")\n- Mainland China Host: `https://api.minimaxi.chat`\n\n## Transport Modes\n\nMiniMax MCP JS supports three transport modes:\n\n| Feature | stdio (default) | REST | SSE |\n|:-----|:-----|:-----|:-----|\n| Environment | Local only | Local or cloud deployment | Local or cloud deployment |\n| Communication | Via `standard I/O` | Via `HTTP requests` | Via `server-sent events` |\n| Use Cases | Local MCP client integration | API services, cross-language calls | Applications requiring server push |\n| Input Restrictions | Supports `local files` or `URL` resources | When deployed in cloud, `URL` input recommended | When deployed in cloud, `URL` input recommended |\n\n## Configuration\n\nMiniMax-MCP-JS provides multiple flexible configuration methods to adapt to different use cases. The configuration priority from highest to lowest is as follows:\n\n### 1. Request Parameter Configuration (Highest Priority)\n\nIn platform hosting environments (like ModelScope or other MCP platforms), you can provide an independent configuration for each request via the `meta.auth` object in the request parameters:\n\n```json\n{\n  \"params\": {\n    \"meta\": {\n      \"auth\": {\n        \"api_key\": \"your_api_key_here\",\n        \"api_host\": \"\u003chttps://api.minimaxi.chat|https://api.minimaxi.chat\u003e\",\n        \"base_path\": \"/path/to/output\",\n        \"resource_mode\": \"url\"\n      }\n    }\n  }\n}\n```\n\nThis method enables multi-tenant usage, where each request can use different API keys and configurations.\n\n### 2. API Configuration\n\nWhen used as a module in other projects, you can pass configuration through the `startMiniMaxMCP` function:\n\n```javascript\nimport { startMiniMaxMCP } from 'minimax-mcp-js';\n\nawait startMiniMaxMCP({\n  apiKey: 'your_api_key_here',\n  apiHost: 'https://api.minimaxi.chat', // Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat\n  basePath: '/path/to/output',\n  resourceMode: 'url'\n});\n```\n\n### 3. Command Line Arguments\n\n1. Install the CLI tool globally:\n```bash\n# Install globally\npnpm install -g minimax-mcp-js\n```\n\n2. When used as a CLI tool, you can provide configuration via command line arguments:\n\n```bash\nminimax-mcp-js --api-key your_api_key_here --api-host https://api.minimaxi.chat --base-path /path/to/output --resource-mode url\n```\n\n### 4. Environment Variables (Lowest Priority)\n\nThe most basic configuration method is through environment variables:\n\n```bash\n# MiniMax API Key (required)\nMINIMAX_API_KEY=your_api_key_here\n\n# Base path for output files (optional, defaults to user's desktop)\nMINIMAX_MCP_BASE_PATH=~/Desktop\n\n# MiniMax API Host (optional, defaults to https://api.minimaxi.chat, Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat)\nMINIMAX_API_HOST=https://api.minimaxi.chat\n\n# Resource mode (optional, defaults to 'url')\n# Options: 'url' (return URLs), 'local' (save files locally)\nMINIMAX_RESOURCE_MODE=url\n```\n\n### Configuration Priority\n\nWhen multiple configuration methods are used, the following priority order applies (from highest to lowest):\n\n1. **Request-level configuration** (via `meta.auth` in each API request)\n2. **Command line arguments**\n3. **Environment variables**\n4. **Configuration file**\n5. **Default values**\n\nThis prioritization ensures flexibility across different deployment scenarios while maintaining per-request configuration capabilities for multi-tenant environments.\n\n### Configuration Parameters\n\n| Parameter | Description | Default Value |\n|-----------|-------------|---------------|\n| apiKey | MiniMax API Key | None (Required) |\n| apiHost | MiniMax API Host | Global Host - https://api.minimaxi.chat, Mainland Host - https://api.minimax.chat |\n| basePath | Base path for output files | User's desktop |\n| resourceMode | Resource handling mode, 'url' or 'local' | url |\n\n‚ö†Ô∏è **Note**: The API key needs to match the host address. Different hosts are used for global and mainland China versions:\n- Global Host: `https://api.minimaxi.chat` (note the extra \"i\")\n- Mainland China Host: `https://api.minimax.chat`\n\n## Example usage\n\n‚ö†Ô∏è Warning: Using these tools may incur costs.\n\n### 1. broadcast a segment of the evening news\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_20-07-53.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n\n### 2. clone a voice\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-45-13.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n\n### 3. generate a video\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-58-52.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-59-43.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle; \"/\u003e\n\n### 4. generate images\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image1.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle; \"/\u003e\n\n### 5. generate music\n\u003cimg alt=\"format_webp\" src=\"https://filecdn.minimax.chat/public/5675b3dc-6789-4ceb-9505-8ef39ae4224f.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n\n### 6. voice design\n\u003cimg alt=\"format_webp\" src=\"https://filecdn.minimax.chat/public/5654f5df-0642-477f-9c5d-b853d185b8b0.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n\n## Available Tools\n\n### Text to Audio\n\nConvert text to speech audio file.\n\nTool Name: `text_to_audio`\n\nParameters:\n- `text`: Text to convert (required)\n- `model`: Model version, options are 'speech-02-hd', 'speech-02-turbo', 'speech-01-hd', 'speech-01-turbo', 'speech-01-240228', 'speech-01-turbo-240228', default is 'speech-02-hd'\n- `voiceId`: Voice ID, default is 'male-qn-qingse'\n- `speed`: Speech speed, range 0.5-2.0, default is 1.0\n- `vol`: Volume, range 0.1-10.0, default is 1.0\n- `pitch`: Pitch, range -12 to 12, default is 0\n- `emotion`: Emotion, options are 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised', 'neutral', default is 'happy'. Note: This parameter only works with 'speech-02-hd', 'speech-02-turbo', 'speech-01-turbo', 'speech-01-hd' models\n- `format`: Audio format, options are 'mp3', 'pcm', 'flac', 'wav', default is 'mp3'\n- `sampleRate`: Sample rate (Hz), options are 8000, 16000, 22050, 24000, 32000, 44100, default is 32000\n- `bitrate`: Bitrate (bps), options are 64000, 96000, 128000, 160000, 192000, 224000, 256000, 320000, default is 128000\n- `channel`: Audio channels, options are 1 or 2, default is 1\n- `languageBoost`: Enhance the ability to recognize specified languages and dialects.\nSupported values include:\n'Chinese', 'Chinese,Yue', 'English', 'Arabic', 'Russian', 'Spanish', 'French', 'Portuguese', 'German', 'Turkish', 'Dutch', 'Ukrainian', 'Vietnamese', 'Indonesian', 'Japanese', 'Italian', 'Korean', 'Thai', 'Polish', 'Romanian', 'Greek', 'Czech', 'Finnish', 'Hindi', 'auto', default is 'auto'\n- `stream`: Enable streaming output\n- `subtitleEnable`: The parameter controls whether the subtitle service is enabled. The model must be 'speech-01-turbo' or 'speech-01-hd'. If this parameter is not provided, the default value is false\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n\n### Play Audio\n\nPlay an audio file. Supports WAV and MP3 formats. Does not support video.\n\nTool Name: `play_audio`\n\nParameters:\n- `inputFilePath`: Path to the audio file to play (required)\n- `isUrl`: Whether the audio file is a URL, default is false\n\n### Voice Clone\n\nClone a voice from an audio file.\n\nTool Name: `voice_clone`\n\nParameters:\n- `audioFile`: Path to audio file (required)\n- `voiceId`: Voice ID (required)\n- `text`: Text for demo audio (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n### Text to Image\n\nGenerate images based on text prompts.\n\nTool Name: `text_to_image`\n\nParameters:\n- `prompt`: Image description (required)\n- `model`: Model version, default is 'image-01'\n- `aspectRatio`: Aspect ratio, default is '1:1', options are '1:1', '16:9','4:3', '3:2', '2:3', '3:4', '9:16', '21:9'\n- `n`: Number of images to generate, range 1-9, default is 1\n- `promptOptimizer`: Whether to optimize the prompt, default is true\n- `subjectReference`: Path to local image file or public URL for character reference (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n- `asyncMode`: Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result. (optional)\n\n### Generate Video\n\nGenerate videos based on text prompts.\n\nTool Name: `generate_video`\n\nParameters:\n- `prompt`: Video description (required)\n- `model`: Model version, options are 'T2V-01', 'T2V-01-Director', 'I2V-01', 'I2V-01-Director', 'I2V-01-live', 'S2V-01', 'MiniMax-Hailuo-02', default is 'MiniMax-Hailuo-02'\n- `firstFrameImage`: Path to first frame image (optional)\n- `duration`: The duration of the video. The model must be \"MiniMax-Hailuo-02\". Values can be 6 and 10. (optional)\n- `resolution`: The resolution of the video. The model must be \"MiniMax-Hailuo-02\". Values range [\"768P\", \"1080P\"]. (optional)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n- `outputFile`: Path to save the output file (optional, auto-generated if not provided)\n- `asyncMode`: Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result. (optional)\n\n### Query Video Generation Status\n\nQuery the status of a video generation task.\n\nTool Name: `query_video_generation`\n\nParameters:\n- `taskId`: The Task ID to query. Should be the task_id returned by `generate_video` tool if `async_mode` is True. (required)\n- `outputDirectory`: Directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n### Generate Music\n\nGenerate music from prompt and lyrics.\n\nTool Name: `music_generation`\n\nParameters:\n- `prompt`: Music creation inspiration describing style, mood, scene, etc. Example: \"Pop music, sad, suitable for rainy nights\". Character range: [10, 300]. (required)\n- `lyrics`: Song lyrics for music generation. Use newline (\\\\n) to separate each line of lyrics. Supports lyric structure tags [Intro] [Verse] [Chorus] [Bridge] [Outro] to enhance musicality. Character range: [10, 600] (each Chinese character, punctuation, and letter counts as 1 character). (required)\n- `sampleRate`: Sample rate of generated music. Values: [16000, 24000, 32000, 44100], default is 32000. (optional)\n- `bitrate`: Bitrate of generated music. Values: [32000, 64000, 128000, 256000], default is 128000. (optional)\n- `format`: Format of generated music. Values: [\"mp3\", \"wav\", \"pcm\"], default is 'mp3'. (optional)\n- `outputDirectory`: The directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n\n### Voice Design\n\nGenerate a voice based on description prompts.\n\nTool Name: `voice_design`\n\nParameters:\n- `prompt`: The prompt to generate the voice from. (required)\n- `previewText`: The text to preview the voice. (required)\n- `voiceId`: The id of the voice to use. For example, \"male-qn-qingse\"/\"audiobook_female_1\"/\"cute_boy\"/\"Charming_Lady\"... (optional)\n- `outputDirectory`: The directory to save the output file. `outputDirectory` is relative to `MINIMAX_MCP_BASE_PATH` (or `basePath` in config). The final save path is `${basePath}/${outputDirectory}`. For example, if `MINIMAX_MCP_BASE_PATH=~/Desktop` and `outputDirectory=workspace`, the output will be saved to `~/Desktop/workspace/`. (optional)\n\n## FAQ\n\n### 1. How to use `generate_video` in async-mode\nDefine completion rules before starting:\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_rule2.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\nAlternatively, these rules can be configured in your IDE settings (e.g., Cursor):\n\u003cimg alt=\"format_webp\" src=\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_video_rule.png?x-oss-process=image/resize,p_50/format,webp\" style=\"display: inline-block; vertical-align: middle;\"/\u003e\n\n## Development\n\n### Setup\n\n```bash\n# Clone the repository\ngit clone https://github.com/MiniMax-AI/MiniMax-MCP-JS.git\ncd minimax-mcp-js\n\n# Install dependencies\npnpm install\n```\n\n### Build\n\n```bash\n# Build the project\npnpm run build\n```\n\n### Run\n\n```bash\n# Run the MCP server\npnpm start\n```\n\n## License\n\nMIT\n",
      "stars": 84,
      "updated_at": "2025-09-28T15:24:03Z",
      "url": "https://github.com/MiniMax-AI/MiniMax-MCP-JS"
    },
    "Momo707577045--tinypng-script-with-cache": {
      "category": "image-and-video-generation",
      "description": "Compress images without dependencies, automatically skip already compressed images, and replace source files, while maintaining quality. The server utilizes multiple API keys for compression and generates compression reports while ensuring no redundant files are created during the process.",
      "forks": 8,
      "imageUrl": "/freedevtools/mcp/pfp/Momo707577045.webp",
      "keywords": [
        "tinypng",
        "compression",
        "compressed",
        "momo707577045 tinypng",
        "compress images",
        "compressed images"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "tinypng-script-with-cache",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Momo707577045",
      "readme_content": "# Êó†‰æùËµñÁöÑ tinypng node ËÑöÊú¨\n## ÁâπÁÇπ\n- „ÄêÊó†‰æùËµñÔºåÁ∫ØËÑöÊú¨„Äë\n  - ‰∏ãËΩΩËÑöÊú¨‰ª£Á†ÅÔºåÁõ¥Êé•‰ΩøÁî® node ÂëΩ‰ª§Âç≥ÂèØËøêË°å„ÄÇ\n  - Â∞Ü‰ΩøÁî®Èó®ÊßõÈôçÂà∞ÊúÄ‰Ωé„ÄÇ\n- „ÄêËøáÊª§ÈáçÂ§çÂéãÁº©„Äë\n  - Ëá™Âä®ËÆ∞ÂΩïÂ∑≤Ë¢´ÂéãÁº©ËøáÁöÑÂõæÁâáÔºåË∑≥ËøáÂéãÁº©ÔºåÂä†Âø´ËøõÂ∫¶„ÄÇ\n  - ËÆ∞ÂΩïÂõæÁâáÂéãÁº©ÂêéÁöÑ md5 ÂÄºÔºåÂÜçÊ¨°ËøêË°åÂéãÁº©ËÑöÊú¨Êó∂ÔºåË∑≥ËøáÂéãÁº©„ÄÇ\n  - ÈÄöËøá md5 ÂÄºÊØîËæÉÊñá‰ª∂ÂèòÊõ¥ÔºåÂç≥‰Ωø„ÄåÊñá‰ª∂ËøÅÁßª„Äç‰πüËÉΩËá™Âä®ËøáÊª§„ÄÇ\n  - ÈÄöËøá md5 ÂÄºÊØîËæÉÊñá‰ª∂ÂèòÊõ¥ÔºåÂç≥‰Ωø„Äå‰ΩøÁî®ÂêåÂêçÊñá‰ª∂ÊõøÊç¢„Äç‰πüËÉΩËá™Âä®ËØÜÂà´ÔºåÂπ∂ÂéãÁº©ÔºåÊ≤°ÊúâÊºèÁΩë‰πãÈ±º„ÄÇ\n- „ÄêÊõøÊç¢Ê∫êÊñá‰ª∂„Äë\n  - ÂéãÁº©ÊàêÂäüÔºåÁõ¥Êé•ÊõøÊç¢Ê∫êÊñá‰ª∂Ôºå‰∏çÁîüÊàêÂÜó‰ΩôÊñá‰ª∂Ôºå‰∏çÈúÄË¶ÅÂ§çÂà∂Á≤òË¥¥ÔºåÁßªÂä®ÂõæÁâá„ÄÇ\n  - ÈùôÈªòÂéãÁº©ÔºåÂØπÈ°πÁõÆÊó†ÊÑüÁü•ÔºåÊó†‰ªª‰ΩïÂΩ±Âìç„ÄÇ\n- „ÄêËá™Âä®ÂàáÊç¢ api key„Äë\n  - tinypng Áî≥ËØ∑ÁöÑ [api key](https://tinypng.com/developers) ÊØèÊúàÂè™Êúâ 500 Ê¨°ÂÖçË¥πÂéãÁº©È¢ùÂ∫¶„ÄÇ\n  - ÂèØËÆæÁΩÆÂ§ö‰∏™ api keyÔºåÂΩìÊüê key Ë∂ÖËøá‰ΩøÁî®Ê¨°Êï∞Êó∂ÔºåËá™Âä®ÂàáÊç¢‰∏ã‰∏Ä‰∏™ key ËøõË°åÂéãÁº©„ÄÇ\n- „ÄêÂéãÁº©Êä•Âëä„Äë\n  - ËÆ∞ÂΩïÊØè‰∏™ÂõæÁâáÁöÑÂéãÁº©Êï∞ÊçÆÔºåÂπ∂ÁîüÊàêÊ±áÊÄª‰ø°ÊÅØ„ÄÇ\n- „ÄêÂéãÁº©ÂÆâÂÖ®ËæπÁïå„Äë\n  - ÂéãÁº©ÂÆâÂÖ®Á∫øÔºåÂΩìÂéãÁº©ÊØî‰æã‰Ωé‰∫éËØ•ÁôæÂàÜÊØîÂÄºÊó∂Ôºå‰øùÊåÅÊ∫êÊñá‰ª∂ÔºåÈÅøÂÖçËøáÂàÜÂéãÁº©ÔºåÊçü‰º§ÂõæÁâáË¥®Èáè„ÄÇ\n- „ÄêÊ∫êÁ†ÅÊê∫Â∏¶ËØ¶ÁªÜÂ§áÊ≥®ÔºåËá™Â∏¶ÊµãËØïÂõæÁâá„Äë\n  - Èôç‰ΩéÊ∫êÁ†ÅÈòÖËØªÈó®ÊßõÔºåÈôç‰ΩéÊµãËØïÈó®ÊßõÔºåÂáè‰Ωé‰ΩøÁî®Èó®Êßõ„ÄÇ\n  - Êé®ËçêÈòÖËØªÊ∫êÁ†ÅÔºåÊâìÁ†¥ÊÅêÊÉßÔºå‰æø‰∫éÂÆöÂà∂‰∏™ÊÄßÂåñÈúÄÊ±Ç„ÄÇ\n\n\n## ‰∏ì‰∏∫Â∞èÂûãÈ°πÁõÆÂÆöÂà∂\n- Á∫ØËÑöÊú¨Ôºå‰∏ç‰æùËµñ gulpÔºå‰∏ç‰æùËµñ webpackÔºåÊó†ÈúÄÊê≠Âª∫ËÑöÊâãÊû∂ÁéØÂ¢É\n- Â∞èÂûãÈ°πÁõÆÔºåÊàñËÄÖÂè™ÊúâÂá†‰∏™ÈùôÊÄÅÈ°µÈù¢ÔºåÊê≠Âª∫ËÑöÊâãÊû∂ÁöÑÊàêÊú¨ËøáÈ´ò„ÄÇÊú¨ËÑöËß£ÂÜ≥ÁöÑÂç≥ÊòØËÑöÊâãÊû∂‰æùËµñÁöÑÈóÆÈ¢ò„ÄÇ\n- ÂΩìÁÑ∂Ôºå‰∏≠Â§ßÂûãÈ°πÁõÆ‰πüÂèØ‰ª•Áî®ÔºåÂè™ÊòØÂÖ∂„ÄåÊó†‰æùËµñ„ÄçÁöÑÁâπÁÇπÂú®ÈáåÈù¢Ê≤°ÈÇ£‰πàÁ™ÅÂá∫„ÄÇ‰∏≠Â§ßÂûãÈ°πÁõÆÊé®Ëçê‰ΩøÁî®ÂÖ∂ [gulp ÁâàÊú¨](https://segmentfault.com/a/1190000023895556)ÔºåÂÆûÁé∞Êõ¥ÁÅµÊ¥ªÁöÑÈÖçÁΩÆ„ÄÇ\n\n\n## ÂçïÊñá‰ª∂‰ΩøÁî®ÊñπÂºè\n- Á¨¨‰∏ÄÊ≠•ÔºåÁÇπÂáª[‰∏ãËΩΩÊ∫êÁ†Å](http://upyun.luckly-mjw.cn/lib/mtp.js)\n- Á¨¨‰∫åÊ≠•ÔºåÂú®ËÑöÊú¨Êñá‰ª∂Â§¥ÈÉ®Ê∑ªÂä† tinypng ÁöÑ [api key](https://tinypng.com/developers)\n  ```\n  global.tinypngConf = {\n    apiKeyList: [\n      // 'XgNgkoyWbdIZd8OizINMjX2TpxAd_Gp3', // Êó†Êïà key\n      // 'IAl6s3ekmONUVMEqWZdIp1nV2ItJL1PC', // Êó†Êïà key\n      'IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC', // ÊúâÊïà key\n    ]\n  }\n  ```\n  ![ÈÖçÁΩÆÂõæ](http://upyun.luckly-mjw.cn/Assets/tinypng/004.png)\n- Á¨¨‰∏âÊ≠•ÔºåËµã‰∫àËÑöÊú¨Êñá‰ª∂„ÄåÂèØÊâßË°å„ÄçÊùÉÈôêÔºå```chmod +x ./mtp.js```\n- Á¨¨ÂõõÊ≠•ÔºåÂ∞ÜËÑöÊú¨Êñá‰ª∂ÊîæÁΩÆÂà∞È°πÁõÆÊâÄÂú®ÁõÆÂΩï\n  ![ËøêË°åÊïàÊûú](http://upyun.luckly-mjw.cn/Assets/tinypng/007.jpeg)\n- Á¨¨‰∫îÊ≠•ÔºåÂú®È°πÁõÆÊâÄÂú®ÁõÆÂΩïËøêË°åËÑöÊú¨```node ./mtp.js```\n  ![ËøêË°åÊïàÊûú](http://upyun.luckly-mjw.cn/Assets/tinypng/006.jpeg)\n- ÂêéÁª≠‰ΩøÁî®Ôºå‰ªÖÈúÄÊúÄÂêé‰∏§Ê≠•„ÄåÁ¨¨ÂõõÊ≠•„Äç„ÄåÁ¨¨‰∫îÊ≠•„Äç\n\n\n## ÂÖ®Â±ÄÈÖçÁΩÆ‰ΩøÁî®ÊñπÂºè\n- Á¨¨‰∏ÄÊ≠•ÔºåÂÖ®Â±ÄÂÆâË£Ö```npm install -g tinypng-script-with-cache```\n- Á¨¨‰∫åÊ≠•ÔºåÂÖ®Â±ÄÈÖçÁΩÆ api key\n  ```mtp setKey XgNgkoyWbdIZd8OizINMjX2TpxAd_Gp3,IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC```\n- Á¨¨‰∏âÊ≠•ÔºåÂú®È°πÁõÆÊâÄÂú®ÁõÆÂΩïËøêË°åËÑöÊú¨```mtp```\n- ÂêéÁª≠‰ΩøÁî®ÔºåÊó†ÈúÄÈÖçÁΩÆÔºåÁõ¥Êé•Âú®ÁõÆÊ†áÁõÆÂΩïËøêË°å```mtp```\n\n  ![ËøêË°åÊïàÊûú](http://upyun.luckly-mjw.cn/Assets/tinypng/008.png)\n\n## ÂèÇÊï∞‰º†ÈÄíÊñπÂºè\n#### ÈªòËÆ§ÈÖçÁΩÆ\n- ÈªòËÆ§ÂéãÁº©„ÄåËøêË°åÂëΩ‰ª§ÊâÄÂú®Êñá‰ª∂Â§π„Äç‰∏ãÁöÑÂõæÁâá\n- „ÄåÂëΩ‰ª§‰º†ÂèÇ„Äç‰ºòÂÖàÁ∫ßÈ´ò‰∫é„Äå‰øÆÊîπÊ∫êÊñá‰ª∂ËÆæÁΩÆ„Äç\n\n\n#### ‰øÆÊîπÊ∫êÊñá‰ª∂ËÆæÁΩÆ\n- Âú®Ê∫êÊñá‰ª∂Â§¥ÈÉ®ÔºåÂÜôÂÖ•ÂÖ®Â±ÄÂèÇÊï∞ÔºåÁ®ãÂ∫èËøêË°åÊó∂Ëá™Âä®Ëé∑Âèñ\n- ÂÖ®ÈÉ®ÂèÇËÄÉÈÖçÁΩÆÂ¶Ç‰∏ã\n  ```\n  global.tinypngConf = {\n     basePath: '/Users/mjw/Desktop/git/tinypng-script-with-cache/test-img', // ÂéãÁº©Ë∑ØÂæÑ\n     createMd5FormOrigin: false, // ‰∏çËøõË°åÂéãÁº©Êìç‰ΩúÔºåÂè™ÁîüÊàêÁé∞ÊúâÂõæÁâáÁöÑ md5 ‰ø°ÊÅØÔºåÂπ∂‰Ωú‰∏∫ÁºìÂ≠ò„ÄÇÁî®‰∫é„ÄåÂàùÊ¨°È°πÁõÆÊé•ÂÖ•„ÄçÂèäÊâãÂä®Ê∏ÖÁêÜÂÜó‰ΩôÁöÑ„ÄåÂõæÁâámd5‰ø°ÊÅØ„Äç\n     apiKeyList: [ // tiny png ÁöÑ api key Êï∞ÁªÑÔºåÂΩìÂÖ∂‰∏≠‰∏Ä‰∏™‰∏çÂèØÁî®ÊàñË∂ÖËøá‰ΩøÁî®Ê¨°Êï∞Êó∂ÔºåËá™Âä®ÂàáÊç¢‰∏ã‰∏Ä‰∏™ key Ë∞ÉÁî®\n       'IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC', // ÊúâÊïà key\n     ]\n   }\n  ```\n  ![ÈÖçÁΩÆÂõæ](http://upyun.luckly-mjw.cn/Assets/tinypng/004.png)\n\n#### ÂëΩ‰ª§‰º†ÂèÇ\n- ÂèÇÊï∞ÈÄöËøáÁ©∫Ê†ºÂå∫ÂàÜ\n- ÂèÇÊï∞‰∏ÄÔºöÂéãÁº©Ë∑ØÂæÑ\n- ÂèÇÊï∞‰∫åÔºöÊòØÂê¶‰∏çËøõË°åÂéãÁº©Êìç‰ΩúÔºåÂè™ÁîüÊàêÁé∞ÊúâÂõæÁâáÁöÑ md5 ‰ø°ÊÅØ„ÄÇÈô§Á©∫Â≠óÁ¨¶‰∏≤```''```Â§ñÔºåÂÖ∂‰ΩôÂÄºÂùá‰∏∫ true\n- ÂèÇÊï∞‰∏âÔºöapiKeyListÔºå‰ª•ÈÄóÂè∑Âå∫ÂàÜ```,```\n- ‰º†ÂèÇÂèÇËÄÉ\n  ```\n  node ./mtp.js /Users/mjw/Desktop/git/tinypng-script-with-cache/test-img '' IAl6s3ekmONUVMEqWZdIp1nV2ItJLyPC\n  ```\n  ![ËøêË°åÊïàÊûú](http://upyun.luckly-mjw.cn/Assets/tinypng/005.jpeg)\n\n#### ÈÖçÁΩÆÂêàÂπ∂‰ºòÂÖàÁ∫ßÊ∫êÁ†Å\n```\nconst vfs = require('vinyl-fs');\nlet tinypng = require('./tinypng-with-cache')\n\nlet apiKeyList = [] // Êé•Âè£ key ÈªòËÆ§‰∏∫Á©∫\nlet basePath = process.cwd() // ÈªòËÆ§ËøêË°åËÑöÊú¨ÊâÄÂú®ÁõÆÂΩï\nlet createMd5FormOrigin = false // ‰∏çËøõË°åÂéãÁº©Êìç‰ΩúÔºåÂè™ÁîüÊàêÁé∞ÊúâÂõæÁâáÁöÑ md5 ‰ø°ÊÅØÔºåÂπ∂‰Ωú‰∏∫ÁºìÂ≠ò„ÄÇÁî®‰∫é„ÄåÂàùÊ¨°È°πÁõÆÊé•ÂÖ•„ÄçÂèäÊâãÂä®Ê∏ÖÁêÜÂÜó‰ΩôÁöÑ„ÄåÂõæÁâámd5‰ø°ÊÅØ„Äç\n\n// Â¶ÇÊûúÊúâÂÖ®Â±Ä‰º†ÂÄº\nif (global.tinypngConf) {\n  basePath = tinypngConf.basePath || basePath\n  apiKeyList = tinypngConf.apiKeyList || apiKeyList\n  createMd5FormOrigin = tinypngConf.createMd5FormOrigin || createMd5FormOrigin\n}\n\n// Âä®ÊÄÅÂèÇÊï∞‰º†ÂÄº\nbasePath = process.argv[2] || basePath\ncreateMd5FormOrigin = process.argv[3] || createMd5FormOrigin\napiKeyList = process.argv[4] ? process.argv[4].split(',') : apiKeyList\n\nlet fileFilter = tinypngConf.fileFilter || [\n  basePath + '/**/*.png',\n  basePath + '/**/*.jpg',\n  basePath + '/**/*.jpeg',\n  `!${basePath}/**/node_modules/**`, // ÂøΩÁï•Êó†ÈúÄÈÅçÂéÜÁöÑÊñá‰ª∂ÔºåË∑ØÂæÑÂåπÈÖçËØ≠Ê≥ïÂèÇËÄÉÔºöhttps://www.gulpjs.com.cn/docs/getting-started/explaining-globs/\n  `!${basePath}/**/dist/**`,\n]\n\nconsole.log({\n  basePath,\n  apiKeyList,\n  fileFilter,\n  createMd5FormOrigin,\n})\n\nif (!apiKeyList.length) {\n  return console.error('tinypng-script-with-cache', 'tinypny key ÂàóË°®‰∏çËÉΩ‰∏∫Á©∫!')\n}\n\nvfs.src(fileFilter, {\n  base: './', // ÂØπÊñá‰ª∂‰ΩøÁî®Áõ∏Ë∑ØÂæÑÔºå‰∏∫‰∫ÜÂêéÈù¢Ë¶ÜÁõñÊ∫êÊñá‰ª∂\n  nodir: true, // ÂøΩÁï•Êñá‰ª∂Â§π\n})\n.pipe(tinypng({\n  apiKeyList,\n  reportFilePath: basePath + '/tinypngReport.json', // ‰∏çËÆæÁΩÆÔºåÂàô‰∏çËøõË°åÊó•ÂøóËÆ∞ÂΩï\n  md5RecordFilePath: basePath + '/tinypngMd5Record.json', // ‰∏çËÆæÁΩÆÔºåÂàô‰∏çËøõË°åÁºìÂ≠òËøáÊª§\n  minCompressPercentLimit: 10, // ÈªòËÆ§ÂÄº‰∏∫Èõ∂ÔºåÊúÄÂ∞èÂéãÁº©ÁôæÂàÜÊØîÈôêÂà∂Ôºå‰∏∫‰øùËØÅÂõæÁâáË¥®ÈáèÔºåÂΩìÂéãÁº©ÊØî‰æã‰Ωé‰∫éËØ•ÂÄºÊó∂Ôºå‰øùÊåÅÊ∫êÊñá‰ª∂ÔºåÈÅøÂÖçËøáÂàÜÂéãÁº©ÔºåÊçü‰º§ÂõæÁâáË¥®Èáè\n  createMd5FormOrigin, // ‰∏çËøõË°åÂéãÁº©Êìç‰ΩúÔºåÂè™ÁîüÊàêÁé∞ÊúâÂõæÁâáÁöÑ md5 ‰ø°ÊÅØÔºåÂπ∂‰Ωú‰∏∫ÁºìÂ≠ò„ÄÇÁî®‰∫é„ÄåÂàùÊ¨°È°πÁõÆÊé•ÂÖ•„ÄçÂèäÊâãÂä®Ê∏ÖÁêÜÂÜó‰ΩôÁöÑ„ÄåÂõæÁâámd5‰ø°ÊÅØ„Äç\n}))\n.pipe(vfs.dest('./', { overwrite: true })) // Ë¶ÜÂÜôÂéüÊñá‰ª∂\n```\n\n## [È°πÁõÆÂú∞ÂùÄ](https://github.com/Momo707577045/tinypng-script-with-cache)\n\n## ‰∫åÊ¨°ÂºÄÂèëÔºåÁîüÊàêËá™ÂÆö‰πâËÑöÊú¨\n- git clone ‰∏ãËΩΩÈ°πÁõÆ\n- npm install ÂÆâË£Ö‰æùËµñ\n- ‰øÆÊîπ„Äåtinypng-mjw.js„Äç‰∏é„Äåtinypng-with-cache.js„ÄçÊ∫êÊñá‰ª∂\n- ÊâßË°å```npx webpack --config webpack.config.js```ÂëΩ‰ª§ÔºåËøõË°åÊâìÂåÖ\n- ÁîüÊàêÁõÆÊ†áÊñá‰ª∂```dist/mtp.js```\n\n\n## ÊµãËØïËµÑÊ∫ê\n- test-imgÔºöÂõæÁâáÂéãÁº©ÊµãËØïÁõÆÂΩï\n- test-img-originÔºöÊµãËØïÂõæÁâáÂ§á‰ªΩÁõÆÂΩïÔºåÁî®‰∫éÊÅ¢Â§çÊµãËØï\n\n\n## ËøêË°åÊïàÊûú\n![ËøêË°åÊïàÊûú](http://upyun.luckly-mjw.cn/Assets/tinypng/006.jpeg)\n\n## ÂéãÁº©Êä•Âëä\n![ÂéãÁº©Êä•Âëä](http://upyun.luckly-mjw.cn/Assets/tinypng/002.png)\n\n## md5 ËÆ∞ÂΩï\n![md5 ËÆ∞ÂΩï](http://upyun.luckly-mjw.cn/Assets/tinypng/003.png)\n\n## gulp ÁâàÊú¨ËØ∑ÂèÇËÄÉ[ËøôÈáå](https://segmentfault.com/a/1190000023895556)",
      "stars": 23,
      "updated_at": "2025-06-24T13:15:05Z",
      "url": "https://github.com/Momo707577045/tinypng-script-with-cache"
    },
    "MubarakHAlketbi--game-asset-mcp": {
      "category": "image-and-video-generation",
      "description": "Generates 2D and 3D game assets from text prompts using AI models. Integrates with Hugging Face Spaces for asset generation, facilitating rapid prototyping for game developers.",
      "forks": 20,
      "imageUrl": "/freedevtools/mcp/pfp/MubarakHAlketbi.webp",
      "keywords": [
        "mcp",
        "prototyping",
        "3d",
        "game assets",
        "game asset",
        "prototyping game"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "game-asset-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "MubarakHAlketbi",
      "readme_content": "# Game Asset Generator using MCP and Hugging Face Spaces\n\nThis project is an innovative tool that simplifies game asset creation by leveraging AI-powered generation. Whether you're a game developer seeking rapid prototypes or an AI enthusiast exploring generative models, this tool enables you to create **2D** and **3D game assets** from text prompts effortlessly. It integrates AI models from **Hugging Face Spaces**‚Äîpowered by `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"`, `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"`, and one of three 3D model generation spaces (`InstantMesh`, `Hunyuan3D-2`, or `Hunyuan3D-2mini-Turbo`, which you must duplicate to your account)‚Äîand uses the **Model Context Protocol (MCP)** for seamless interaction with AI assistants like **Claude Desktop**.\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://pay.ziina.com/MubarakHAlketbi\"\u003e\n    \u003cimg src=\"https://img.shields.io/badge/Support_Me-Donate-9626ff?style=for-the-badge\u0026logo=https%3A%2F%2Fimgur.com%2FvwC39JY\" alt=\"Support Me - Donate\"\u003e\n  \u003c/a\u003e\n  \u003ca href=\"https://github.com/RooVetGit/Roo-Code\"\u003e\n    \u003cimg src=\"https://img.shields.io/badge/Built_With-Roo_Code-412894?style=for-the-badge\" alt=\"Built With - Roo Code\"\u003e\n  \u003c/a\u003e\n  \u003cbr\u003e\n  \u003ca href=\"https://glama.ai/mcp/servers/@MubarakHAlketbi/game-asset-mcp\"\u003e\n    \u003cimg alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@MubarakHAlketbi/game-asset-mcp/badge\" /\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\n---\n\n## Table of Contents\n\n1. [Project Overview](#project-overview)\n2. [Features](#features)\n3. [How It Works](#how-it-works)\n4. [Prerequisites](#prerequisites)\n5. [Installation](#installation)\n6. [Usage](#usage)\n7. [Configuration](#configuration)\n8. [File Management](#file-management)\n9. [MCP Integration](#mcp-integration)\n10. [Troubleshooting](#troubleshooting)\n11. [Advanced](#advanced)\n12. [Contributing](#contributing)\n13. [License](#license)\n\n---\n\n## Project Overview\n\nThe **Game Asset Generator** (version **0.3.0**) harnesses AI to streamline the creation of game assets. It supports generating **2D assets** (e.g., pixel art sprites) and **3D assets** (e.g., OBJ and GLB models) from text prompts, integrating with **Hugging Face Spaces** and the **Model Context Protocol (MCP)**. This release introduces support for multiple 3D model generation spaces‚Äî`InstantMesh`, `Hunyuan3D-2`, and `Hunyuan3D-2mini-Turbo`‚Äîoffering flexibility and enhanced performance. Built with **Node.js** and the **MCP TypeScript SDK (v1.7.0)**, it provides a robust, cross-platform solution for asset generation.\n\n---\n\n## Features\n\n- **2D Asset Generation**: Create pixel art, sprites, or other 2D assets from text prompts (e.g., \"pixel art sword\").\n- **3D Asset Generation**: Generate 3D models (OBJ and GLB formats) from text descriptions, with automatic image-to-model conversion.\n- **Multiple 3D Model Spaces**: Supports `InstantMesh`, `Hunyuan3D-2`, and `Hunyuan3D-2mini-Turbo` for varied 3D generation workflows.\n- **MCP Integration**: Seamlessly interact with the tool via MCP-compatible clients like **Claude Desktop**.\n- **File Management**: Automatically saves and organizes assets in a local `assets` directory with resource URIs (e.g., `asset://{type}/{id}`).\n- **Robust Input Validation**: Uses **Zod** for secure and reliable input processing.\n- **Multi-Client Support**: Handles multiple simultaneous connections via **SSE transport**.\n- **Secure Remote Access**: Optional **HTTPS** support for safe remote communication.\n- **Extensible Backend**: Modular design for easy integration of new models or features.\n- **Cross-Platform**: Compatible with Windows, macOS, and Linux using **Node.js**.\n- **Configurable 3D Generation**: Customize parameters like inference steps, guidance scale, and turbo mode via environment variables.\n\n---\n\n## How It Works\n\nThe Game Asset Generator transforms text prompts into game-ready assets through an automated pipeline:\n\n1. **User Input**: Submit a text prompt (e.g., \"pixel art sword\" or \"isometric 3D castle\").\n2. **MCP Server**: Routes the prompt to the appropriate tool (`generate_2d_asset` or `generate_3d_asset`).\n3. **AI Model Interaction**:\n   - **2D Assets**: Utilizes the **Hugging Face Inference API** with `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"` (50 steps).\n   - **3D Assets**:\n     - Generates an initial image using `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"` (30 steps).\n     - Converts the image to a 3D model using one of:\n       - **InstantMesh**: Multi-step process (`/preprocess`, `/generate_mvs`, `/make3d`).\n       - **Hunyuan3D-2**: Single-step process (`/generation_all`).\n       - **Hunyuan3D-2mini-Turbo**: Single-step process (`/generation_all`) with configurable turbo modes.\n4. **File Output**: Saves assets (PNG for 2D, OBJ/GLB for 3D) in the `assets` directory.\n5. **Response**: Returns resource URIs (e.g., `asset://3d_model/filename.glb`) for immediate use.\n\n### Workflow Diagram\n```\nUser Prompt ‚Üí MCP Server ‚Üí AI Model(s) ‚Üí Local File ‚Üí Resource URI Response\n```\n\nPrompts are automatically enhanced with \"high detailed, complete object, not cut off, white solid background\" for optimal quality.\n\n---\n\n## Prerequisites\n\n- **Node.js**: Version 16+ (includes `npm`).\n- **Git**: For cloning the repository.\n- **Internet Access**: Required for Hugging Face API connectivity.\n- **Hugging Face Account**: Needed for API access; obtain your token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).\n- **NPM Packages**:\n  - `@gradio/client`: Interacts with Hugging Face Spaces.\n  - `@huggingface/inference`: For direct model inference.\n  - `@modelcontextprotocol/sdk`: Implements the MCP server.\n  - `dotenv`: Loads environment variables.\n  - `express`: Enables SSE transport.\n  - `zod`: Ensures input validation.\n  - `sharp`: Handles image processing.\n- **Optional**: **Claude Desktop** (or another MCP client) for enhanced interaction.\n\n---\n\n## Installation\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/yourusername/game-asset-mcp.git\n   cd game-asset-mcp\n   ```\n\n2. **Install Dependencies**:\n   ```bash\n   npm install\n   ```\n\n3. **Configure Environment**:\n   - Copy the example `.env` file:\n     ```bash\n     cp .env.example .env\n     ```\n   - Edit `.env` with your **Hugging Face API token** and duplicated **MODEL_SPACE**. See [Configuration](#configuration) for details.\n\n4. **Run the Server**:\n   - **Local (stdio transport)**:\n     ```bash\n     npm start\n     ```\n   - **Custom Working Directory**:\n     ```bash\n     node src/index.js /path/to/directory\n     ```\n   - **Remote (SSE transport)**:\n     ```bash\n     node src/index.js --sse\n     ```\n   - **Remote with HTTPS**:\n     ```bash\n     node src/index.js --sse --https\n     ```\n     Requires `ssl/key.pem` and `ssl/cert.pem` (see [ssl/README.md](ssl/README.md)).\n\n\u003e **Note**: Uses ES modules (`\"type\": \"module\"` in `package.json`). Ensure Node.js 16+ is installed (`node --version`).\n\n---\n\n## Usage\n\nInteract with the server via an **MCP client** (e.g., Claude Desktop) or programmatically:\n\n- **Generate a 2D Asset**:\n  - **Command**: `generate_2d_asset prompt:\"pixel art sword\"`\n  - **Output**: Saves a PNG file (e.g., `2d_asset_generate_2d_asset_1698765432.png`) and returns its URI.\n\n- **Generate a 3D Asset**:\n  - **Command**: `generate_3d_asset prompt:\"isometric 3D castle\"`\n  - **Output**: Saves OBJ/GLB files and intermediate images, returning their URIs. Provides an operation ID for long-running tasks.\n\n### Prompt Examples\n- **Natural Interaction**:\n  - `generate_2d_sprite prompt:\"pixel art sword\"`\n  - `generate_3d_model prompt:\"isometric 3D castle\"`\n\n### With Claude Desktop\nAfter configuring (see [Configuration](#configuration)), type commands directly in the interface.\n\n---\n\n## Configuration\n\nCustomize the server via the `.env` file:\n\n### Required Settings\n- **HF_TOKEN**: Hugging Face API token.\n  ```plaintext\n  HF_TOKEN=your_hf_token\n  ```\n- **MODEL_SPACE**: Your duplicated 3D model space (e.g., `your-username/InstantMesh`).\n  - Duplicate one of:\n    - [InstantMesh](https://huggingface.co/spaces/tencentARC/InstantMesh)\n    - [Hunyuan3D-2](https://huggingface.co/spaces/tencent/Hunyuan3D-2)\n    - [Hunyuan3D-2mini-Turbo](https://huggingface.co/spaces/tencent/Hunyuan3D-2mini-Turbo)\n  ```plaintext\n  MODEL_SPACE=your-username/InstantMesh\n  ```\n\n### Optional 3D Model Settings\n| Variable                  | Description                                   | Valid Range/Default       |\n|---------------------------|-----------------------------------------------|---------------------------|\n| `MODEL_3D_STEPS`         | Inference steps                              | Varies by space (see below) |\n| `MODEL_3D_GUIDANCE_SCALE`| How closely the model follows the prompt     | 0.0-100.0 (default: 5.0-5.5) |\n| `MODEL_3D_OCTREE_RESOLUTION` | Detail level of the 3D model            | Varies by space (see below) |\n| `MODEL_3D_SEED`          | Randomness control                          | 0-10000000 (default: varies) |\n| `MODEL_3D_REMOVE_BACKGROUND` | Remove image background                | `true`/`false` (default: `true`) |\n| `MODEL_3D_TURBO_MODE`    | Generation mode (Hunyuan3D-2mini-Turbo only) | `Turbo`, `Fast`, `Standard` (default: `Turbo`) |\n| `MODEL_SPACE_TYPE`       | Override space type detection               | `instantmesh`, `hunyuan3d`, `hunyuan3d_mini_turbo` |\n\n#### Space-Specific Defaults\n- **InstantMesh**:\n  - Steps: 30-75 (default: 75)\n  - Seed: Default 42\n- **Hunyuan3D-2**:\n  - Steps: 20-50 (default: 20)\n  - Guidance Scale: Default 5.5\n  - Octree Resolution: `256`, `384`, `512` (default: `256`)\n  - Seed: Default 1234\n- **Hunyuan3D-2mini-Turbo**:\n  - Steps: 1-100 (default: 5 for `Turbo`, 10 for `Fast`, 20 for `Standard`)\n  - Guidance Scale: Default 5.0\n  - Octree Resolution: 16-512 (default: 256)\n  - Seed: Default 1234\n\n### Transport Settings\n- **PORT**: SSE transport port (default: 3000).\n  ```plaintext\n  PORT=3000\n  ```\n\n### Claude Desktop Setup\nEdit the config file:\n- **MacOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n```json\n{\n  \"mcpServers\": {\n    \"game-asset-generator\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/game-asset-mcp/src/index.js\"]\n    }\n  }\n}\n```\nRestart Claude Desktop after editing.\n\n---\n\n## File Management\n\n- **Storage Location**: Assets are saved in `./assets` within the working directory.\n- **Naming Convention**: Files use a prefix, tool name, timestamp, and unique ID (e.g., `2d_asset_generate_2d_asset_1698765432_abcd1234.png`).\n- **Customization**: Set a custom directory:\n  ```bash\n  node src/index.js /path/to/custom/directory\n  ```\n- **Resource Access**: Use MCP URIs (e.g., `asset://2d_asset/filename.png`) to list or read assets.\n\n---\n\n## MCP Integration\n\nThe **Model Context Protocol (MCP)** enables this tool to serve AI clients securely:\n- **Tools**: `generate_2d_asset`, `generate_3d_asset`.\n- **Resources**: Managed via `asset://` URIs.\n- **Prompts**: `generate_2d_sprite`, `generate_3d_model`.\n- **Compatibility**: Works with **Claude Desktop** and other MCP clients.\n\n---\n\n## Troubleshooting\n\n- **API Errors**: Check network connectivity or rate limits; review `./logs/server.log`.\n- **Authentication Issues**: Verify `HF_TOKEN` and `MODEL_SPACE` in `.env`.\n- **ES Modules Error**: Ensure Node.js 16+ (`node --version`).\n- **Logs**: Inspect detailed logs:\n  ```bash\n  tail -f ./logs/server.log\n  ```\n\n---\n\n## Advanced\n\n### API Endpoints and Integration\n- **2D Asset Generation**: Uses `\"gokaygokay/Flux-2D-Game-Assets-LoRA\"` (50 steps).\n- **3D Asset Image Generation**: Uses `\"gokaygokay/Flux-Game-Assets-LoRA-v2\"` (30 steps).\n- **3D Model Conversion**:\n  - **InstantMesh**: Multi-step (`/check_input_image`, `/preprocess`, `/generate_mvs`, `/make3d`).\n  - **Hunyuan3D-2**: Single-step (`/generation_all`).\n  - **Hunyuan3D-2mini-Turbo**: Single-step (`/generation_all`) with turbo modes.\n\n### Versioning\n- **Current Version**: 0.3.0 (Added Hunyuan3D-2mini-Turbo support).\n- **MCP SDK Version**: 1.7.0.\n- **Format**: MAJOR.MINOR.PATCH (SemVer).\n\n### Backend Architecture\n- **Core File**: `src/index.js`.\n- **Dependencies**: See `package.json`.\n- **Security**: Zod validation, path traversal prevention, HTTPS support, rate limiting.\n- **Performance**: Async processing, retry with backoff, GPU quota handling.\n\n---\n\n## Contributing\n\nWe welcome contributions! To participate:\n1. **Fork the Repository**: Create your copy on GitHub.\n2. **Make Changes**: Add features, fix bugs, or enhance docs.\n3. **Submit a Pull Request**: Detail your changes.\n4. **Open Issues**: Report bugs or suggest improvements.\n\nFollow standard coding conventions and include tests where applicable.\n\n---\n\n## License\n\nLicensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.",
      "stars": 85,
      "updated_at": "2025-09-21T17:45:58Z",
      "url": "https://github.com/MubarakHAlketbi/game-asset-mcp"
    },
    "NON906--omniparser-autogui-mcp": {
      "category": "image-and-video-generation",
      "description": "Analyzes the screen using OmniParser to automatically operate graphical user interfaces. It provides capabilities for interpreting visual content and executing GUI actions based on analysis.",
      "forks": 10,
      "imageUrl": "/freedevtools/mcp/pfp/NON906.webp",
      "keywords": [
        "omniparser",
        "gui",
        "autogui",
        "omniparser autogui",
        "omniparser automatically",
        "using omniparser"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "omniparser-autogui-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "NON906",
      "readme_content": "# omniparser-autogui-mcp\n\nÔºà[Êó•Êú¨Ë™ûÁâà„ÅØ„Åì„Å°„Çâ](README_ja.md)Ôºâ\n\nThis is an [MCP server](https://modelcontextprotocol.io/introduction) that analyzes the screen with [OmniParser](https://github.com/microsoft/OmniParser) and automatically operates the GUI.  \nConfirmed on Windows.\n\n## License notes\n\nThis is MIT license, but Excluding submodules and sub packages.  \nOmniParser's repository is CC-BY-4.0.  \nEach OmniParser model has a different license ([reference](https://github.com/microsoft/OmniParser?tab=readme-ov-file#model-weights-license)).\n\n## Installation\n\n1. Please do the following:\n\n```\ngit clone --recursive https://github.com/NON906/omniparser-autogui-mcp.git\ncd omniparser-autogui-mcp\nuv sync\nset OCR_LANG=en\nuv run download_models.py\n```\n\n(Other than Windows, use ``export`` instead of ``set``.)  \n(If you want ``langchain_example.py`` to work, ``uv sync --extra langchain`` instead.)\n\n2. Add this to your ``claude_desktop_config.json``:\n\n```claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"omniparser_autogui_mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp\",\n        \"run\",\n        \"omniparser-autogui-mcp\"\n      ],\n      \"env\": {\n        \"PYTHONIOENCODING\": \"utf-8\",\n        \"OCR_LANG\": \"en\"\n      }\n    }\n  }\n}\n```\n\n(Replace ``D:\\\\CLONED_PATH\\\\omniparser-autogui-mcp`` with the directory you cloned.)\n\n``env`` allows for the following additional configurations:\n\n- ``OMNI_PARSER_BACKEND_LOAD``  \nIf it does not work with other clients (such as [LibreChat](https://github.com/danny-avila/LibreChat)), specify ``1``.\n\n- ``TARGET_WINDOW_NAME``  \nIf you want to specify the window to operate, please specify the window name.  \nIf not specified, operates on the entire screen.\n\n- ``OMNI_PARSER_SERVER``  \nIf you want OmniParser processing to be done on another device, specify the server's address and port, such as ``127.0.0.1:8000``.  \nThe server can be started with ``uv run omniparserserver``.\n\n- ``SSE_HOST``, ``SSE_PORT``  \nIf specified, communication will be done via SSE instead of stdio.\n\n- ``SOM_MODEL_PATH``, ``CAPTION_MODEL_NAME``, ``CAPTION_MODEL_PATH``, ``OMNI_PARSER_DEVICE``, ``BOX_TRESHOLD``  \nThese are for OmniParser configuration.  \nUsually, they are not necessary.\n\n## Usage Examples\n\n- Search for \"MCP server\" in the on-screen browser.\n\netc.",
      "stars": 55,
      "updated_at": "2025-10-02T00:52:32Z",
      "url": "https://github.com/NON906/omniparser-autogui-mcp"
    },
    "NightTrek--moondream-mcp": {
      "category": "image-and-video-generation",
      "description": "Advanced image analysis capabilities including captioning, object detection, and visual question answering for applications requiring sophisticated computer vision tasks.",
      "forks": 9,
      "imageUrl": "/freedevtools/mcp/pfp/NightTrek.webp",
      "keywords": [
        "nighttrek",
        "vision",
        "captioning",
        "nighttrek moondream",
        "moondream mcp",
        "advanced image"
      ],
      "language": "JavaScript",
      "license": "Apache License 2.0",
      "name": "moondream-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "NightTrek",
      "readme_content": "# üåô Moondream MCP Server\n\nA powerful Model Context Protocol (MCP) server that brings advanced image analysis capabilities to your applications using the Moondream vision model. This server seamlessly integrates with Claude and Cline, providing a bridge between AI assistants and sophisticated computer vision tasks.\n\nThis IS NOT an offical Moondream package. All credit to [moondream.ai](https://github.com/vikhyat/moondream) for making the best open source vision model that you can run on consumer hardware.\n\n\u003cdiv align=\"center\" style=\"height: 150px; overflow: hidden; display: flex; align-items: center; margin: 20px 0;\"\u003e\n  \u003cimg src=\"https://github.com/user-attachments/assets/e999ada0-9dfa-4f3d-a489-e4ce58434ecb\" alt=\"Moondream MCP Banner\" style=\"width: 100%; object-fit: cover;\"\u003e\n\u003c/div\u003e\n\n\n## ‚ú® Features\n\n- üñºÔ∏è **Image Captioning**: Generate natural language descriptions of images\n- üîç **Object Detection**: Identify and locate specific objects within images\n- üí≠ **Visual Question Answering**: Ask questions about image content and receive intelligent responses\n- üöÄ **High Performance**: Uses quantized 8-bit models for efficient inference\n- üîÑ **Automatic Setup**: Handles model downloading and environment setup\n- üõ†Ô∏è **MCP Integration**: Standardized protocol for seamless tool usage\n\n## üéØ Use Cases\n\n- **Content Analysis**: Automatically generate descriptions for image content\n- **Accessibility**: Create alt text for visually impaired users\n- **Data Extraction**: Extract specific information from images through targeted questions\n- **Object Verification**: Confirm the presence of specific objects in images\n- **Scene Understanding**: Analyze complex scenes and their components\n\n## üöÄ Quick Start\n\n### Prerequisites\n\n- Node.js v18 or higher\n- Python 3.8+\n- UV package manager (automatically installed if not present)\n\n### Installation\n\n1. **Clone and Setup**\n```bash\ngit clone \u003crepository-url\u003e\ncd moondream-server\npnpm install\n```\n\n2. **Build the Server**\n```bash\npnpm run build\n```\n\nThe server handles the rest automatically:\n- Creates Python virtual environment\n- Installs UV if not present\n- Downloads and sets up the Moondream model\n- Manages the model server process\n\n### Integration with Claude/Cline\n\nAdd to your MCP settings file (`claude_desktop_config.json` or `cline_mcp_settings.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"moondream\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/moondream-server/build/index.js\"]\n    }\n  }\n}\n```\n\n## üõ†Ô∏è Available Tools\n\n### analyze_image\n\nPowerful image analysis tool with multiple modes:\n\n```typescript\n{\n  \"name\": \"analyze_image\",\n  \"arguments\": {\n    \"image_path\": string,  // Path to image file\n    \"prompt\": string       // Analysis command\n  }\n}\n```\n\n**Prompt Types:**\n- `\"generate caption\"` - Creates natural language description\n- `\"detect: [object]\"` - Finds specific objects (e.g., \"detect: car\")\n- `\"[question]\"` - Answers questions about the image\n\n**Examples:**\n\n```javascript\n// Image Captioning\n{\n  \"image_path\": \"photo.jpg\",\n  \"prompt\": \"generate caption\"\n}\n\n// Object Detection\n{\n  \"image_path\": \"scene.jpg\",\n  \"prompt\": \"detect: person\"\n}\n\n// Visual Q\u0026A\n{\n  \"image_path\": \"painting.jpg\",\n  \"prompt\": \"What colors are used in this painting?\"\n}\n```\n\n## üîß Technical Details\n\n### Architecture\n\nThe server operates as a dual-component system:\n\n1. **MCP Interface Layer**\n   - Handles protocol communication\n   - Manages tool interfaces\n   - Processes requests/responses\n\n2. **Moondream Model Server**\n   - Runs the vision model\n   - Processes image analysis\n   - Provides HTTP API endpoints\n\n### Model Information\n\nUses the Moondream quantized model:\n- Default: `moondream-2b-int8.mf.gz`\n- Efficient 8-bit quantization\n- Automatic download from Hugging Face\n- ~500MB model size\n\n### Performance\n\n- Fast startup with automatic caching\n- Efficient memory usage through quantization\n- Responsive API endpoints\n- Concurrent request handling\n\n## üîç Debugging\n\nCommon issues and solutions:\n\n1. **Model Download Issues**\n   ```bash\n   # Manual model download\n   wget https://huggingface.co/vikhyatk/moondream2/resolve/main/moondream-0_5b-int4.mf.gz\n   ```\n\n2. **Server Port Conflicts**\n   - Default port: 3475\n   - Check for process using: `lsof -i :3475`\n\n3. **Python Environment**\n   - UV manages dependencies\n   - Check logs in temp directory\n   - Virtual env in system temp folder\n\n## ü§ù Contributing\n\nContributions welcome! Areas of interest:\n\n- Additional model support\n- Performance optimizations\n- New analysis capabilities\n- Documentation improvements\n\n## üìÑ License\n\n[Add your license information here]\n\n## üôè Acknowledgments\n\n- [Moondream Model Team](https://github.com/vikhyat/moondream)\n- Model Context Protocol (MCP) Community\n- Contributors and maintainers\n\n---\n\n\u003cp align=\"center\"\u003e\nMade with ‚ù§Ô∏è by Nighttrek\n\u003c/p\u003e\n",
      "stars": 18,
      "updated_at": "2025-08-09T18:23:23Z",
      "url": "https://github.com/NightTrek/moondream-mcp"
    },
    "PawNzZi--image-server": {
      "category": "image-and-video-generation",
      "description": "Transform text prompts into images using advanced AI techniques, creating unique visuals tailored to user descriptions.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/PawNzZi.webp",
      "keywords": [
        "ai",
        "text",
        "prompts",
        "prompts images",
        "pawnzzi image",
        "advanced ai"
      ],
      "language": "Python",
      "license": "No License",
      "name": "image-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "PawNzZi",
      "readme_content": "[![smithery badge](https://smithery.ai/badge/@PawNzZi/image-server)](https://smithery.ai/server/@PawNzZi/image-server)\n\n### Installing via Smithery\n\nTo install text2image for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@PawNzZi/image-server):\n\n```bash\nnpx -y @smithery/cli install @PawNzZi/image-server --client claude\n```\n",
      "stars": 1,
      "updated_at": "2025-04-17T12:56:27Z",
      "url": "https://github.com/PawNzZi/image-server"
    },
    "Sheshiyer--jina-ai-mcp-multimodal-search": {
      "category": "image-and-video-generation",
      "description": "Seamless integration with Jina AI's neural search capabilities enables semantic, image, and cross-modal searches through a simple interface. Perform searches based on natural language queries, visual similarities, and text-to-image or image-to-text conversions.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/Sheshiyer.webp",
      "keywords": [
        "multimodal",
        "search",
        "searches",
        "multimodal search",
        "mcp multimodal",
        "modal searches"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "jina-ai-mcp-multimodal-search",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Sheshiyer",
      "readme_content": "# Jina AI MCP Server\n\nA Model Context Protocol (MCP) server that provides seamless integration with Jina AI's neural search capabilities. This server enables semantic search, image search, and cross-modal search functionalities through a simple interface.\n\n## üöÄ Features\n\n- **Semantic Search**: Find semantically similar documents using natural language queries\n- **Image Search**: Search for visually similar images using image URLs\n- **Cross-Modal Search**: Perform text-to-image or image-to-text searches\n\n## üìã Prerequisites\n\n- Node.js 16 or higher\n- A Jina AI account and API key ([Get one here](https://cloud.jina.ai/))\n- MCP-compatible environment (e.g., Cline)\n\n## üõ†Ô∏è Installation\n\n1. Clone the repository:\n```bash\ngit clone \u003crepository-url\u003e\ncd jina-ai-mcp\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Create a `.env` file with your Jina AI API key:\n```bash\nJINA_API_KEY=your_api_key_here\n```\n\n4. Build the server:\n```bash\nnpm run build\n```\n\n## ‚öôÔ∏è Configuration\n\nAdd the following configuration to your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"jina-ai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/jina-ai-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"JINA_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n## üîç Available Tools\n\n### 1. Semantic Search\nPerform semantic/neural search on text documents.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"semantic_search\",\n  arguments: {\n    query: \"search query text\",\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n### 2. Image Search\nSearch for similar images using an image URL.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"image_search\",\n  arguments: {\n    imageUrl: \"https://example.com/image.jpg\",\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n### 3. Cross-Modal Search\nPerform text-to-image or image-to-text search.\n\n```typescript\nuse_mcp_tool({\n  server_name: \"jina-ai\",\n  tool_name: \"cross_modal_search\",\n  arguments: {\n    query: \"a beautiful sunset\", // or image URL for image2text\n    mode: \"text2image\", // or \"image2text\"\n    collection: \"your-collection-name\",\n    limit: 10 // optional, defaults to 10\n  }\n})\n```\n\n## üìù Response Format\n\nAll search tools return results in the following format:\n\n```typescript\n{\n  content: [\n    {\n      type: \"text\",\n      text: JSON.stringify({\n        results: [\n          {\n            id: string,\n            score: number,\n            data: Record\u003cstring, any\u003e\n          }\n        ]\n      }, null, 2)\n    }\n  ]\n}\n```\n\n## üîê Error Handling\n\nThe server handles various error cases:\n- Invalid API key\n- Missing or invalid parameters\n- API rate limits\n- Network errors\n- Invalid collection names\n\nAll errors are properly formatted and returned with appropriate error codes and messages.\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## üôè Acknowledgments\n\n- [Jina AI](https://jina.ai/) for their excellent neural search platform\n- [Model Context Protocol](https://github.com/modelcontextprotocol/protocol) for the MCP specification\n",
      "stars": 4,
      "updated_at": "2025-08-19T08:35:51Z",
      "url": "https://github.com/Sheshiyer/jina-ai-mcp-multimodal-search"
    },
    "Siddhant-K-code--memory-journal-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Search and analyze photos in a library using various intuitive tools, including location-based searches to easily find images taken in specific places.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/Siddhant-K-code.webp",
      "keywords": [
        "photos",
        "images",
        "searches",
        "photos library",
        "analyze photos",
        "easily images"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "memory-journal-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Siddhant-K-code",
      "readme_content": "# üì∏ Smart Photo Journal MCP Server\n\n**Smart Photo Journal** is an MCP server designed to help you search and analyze your photo library with powerful, intuitive tools. Whether you're reminiscing about family moments or looking for a specific photo with friends, this server has got you covered! üéâ\n\n\u003e **Inspired by:** [burningion/video-editing-mcp](https://github.com/burningion/video-editing-mcp)\n\u003e A huge shoutout to [@burningion](https://x.com/burningion) for the innovative idea of using MCP for creative media management!\n\n\u003ca href=\"https://glama.ai/mcp/servers/51jiworg5k\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/51jiworg5k/badge\" alt=\"Smart Photo Journal Server MCP server\" /\u003e\u003c/a\u003e\n\n## üéØ Features\n\n- **Location Search:** Find photos from specific places with ease. üåç\n- **Label Search:** Search photos by keywords or labels like \"Birthday,\" \"Beach,\" or \"Vacation.\" üéâ\n- **People Search:** Quickly locate photos featuring specific people. üë•\n- **Photo Analysis:** Discover fun insights like the most popular times and days for your photo shoots. üï∞Ô∏è\n- **Fuzzy Matching:** Not sure of the exact name? Don't worry! The server supports fuzzy matching for flexibility. üîç\n\n## üöÄ Getting started\n\n### Prerequisites\n\n1. Ensure you have macOS with a Photos library.\n2. Install [uv](https://docs.astral.sh/uv/) to manage dependencies and run the server.\n\n### Installation\n\n1. Clone the repository:\n\n   ```bash\n   git clone https://github.com/Siddhant-K-code/memory-journal-mcp-server.git\n   cd memory-journal-mcp-server\n   ```\n\n2. Install dependencies using `uv`:\n\n   ```bash\n   uv sync\n   ```\n\n3. Configure the MCP server. Update your `claude_desktop_config.json` with the following configuration:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"smart-photo-journal\": {\n         \"command\": \"/Users/\u003cYOUR_DEVICE_USERNAME\u003e/.local/bin/uv\",\n         \"args\": [\n           \"--directory\",\n           \"/Users/\u003cPATH_TO_CLONED_DIR\u003e/memory-journal-mcp-server\",\n           \"run\",\n           \"server.py\"\n         ]\n       }\n     }\n   }\n   ```\n\n4. Start the server with following command or just open Claude Desktop:\n   ```bash\n   uv run server.py\n   ```\n\n\u003e **Note:** Replace `\u003cYOUR_DEVICE_USERNAME\u003e` and `\u003cPATH_TO_CLONED_DIR\u003e` with your actual device username and the path to the cloned directory.\n\u003e You will get a popup to authorize the server to access your photos. It will be in local only, and no data will be shared with anyone except Claude services.\n\n### MCP Server Initialization\n\nWhen the server starts, you'll see:\n\n```\nStarting Smart Photo Journal MCP server.\n```\n\nIt's now ready to process your photo queries! üéâ\n\n---\n\n## üõ†Ô∏è Usage\n\n### Available Tools\n\n1. **Location Search**\n\n   - Description: Find photos taken in a specific location.\n   - Input Example:\n     ```json\n     {\n       \"location\": \"Udaipur\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Found 5 photos from Udaipur:\n     üì∑ IMG_1234.jpg\n     ...\n     ```\n\n2. **Label Search**\n\n   - Description: Search for photos by labels or keywords.\n   - Input Example:\n     ```json\n     {\n       \"label\": \"Birthday\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Photos labeled as 'Birthday' (3 found):\n     üì∑ IMG_5678.jpg\n     ...\n     ```\n\n3. **People Search**\n\n   - Description: Find photos containing specific people.\n   - Input Example:\n     ```json\n     {\n       \"person\": \"Maa\"\n     }\n     ```\n   - Expected Output:\n     ```\n     Photos with Maa (10 found):\n     üì∑ IMG_9101.jpg\n     ...\n     ```\n\n4. **Photo Analysis**\n   - Description: Analyze patterns in your photo library, such as the most common times or days for photo shoots.\n   - Input Example:\n     ```json\n     {}\n     ```\n   - Expected Output:\n     ```\n     üì∏ Photo Taking Patterns:\n     Total Photos: 200\n     ...\n     ```\n\n---\n\n## üìö Example Use-Cases\n\n### 1. **Family \u0026 Friends Album Organizer**\n\nWant to gather all your family moments in one place? Use the `people-search` tool with names like \"Papa\" or \"Mom\" or \"Any Friend\" to find photos with specific people.\n\n### 2. **Vacation Highlights**\n\nSearch for photos from your vacation destination using the `location-search` tool.\n\n### 3. **Throwback Fun**\n\nCurious about your past birthday photos? Use `label-search` with \"Birthday\" and relive the fun!\n\n### 4. **Understand Your Photography Habits**\n\nUse the `photo-analysis` tool to understand when and where you take most of your photos. Plan your next shoot accordingly!\n\n---\n\n## ‚ö° Tips for Best Results\n\n- Ensure your Photos library is loaded in macOS.\n- Be as specific as possible with search queries for more accurate results.\n- Use fuzzy matching for flexibility when you're unsure of the exact name.\n",
      "stars": 21,
      "updated_at": "2025-07-28T18:59:40Z",
      "url": "https://github.com/Siddhant-K-code/memory-journal-mcp-server"
    },
    "Sunwood-ai-labs--ideagram-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generate images based on prompts with customizable parameters like aspect ratio and style using the Ideogram API.",
      "forks": 7,
      "imageUrl": "/freedevtools/mcp/pfp/Sunwood-ai-labs.webp",
      "keywords": [
        "ideagram",
        "ideogram",
        "images",
        "generate images",
        "ideagram mcp",
        "ideogram api"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "ideagram-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Sunwood-ai-labs",
      "readme_content": "\u003cdiv align=\"center\"\u003e\n\n\n\n  \u003ch1\u003eüé® Ideogram MCP Server\u003c/h1\u003e\n\n  \u003cp\u003e\n    \u003cimg alt=\"GitHub\" src=\"https://img.shields.io/github/license/sunwood-ai-labs/ideagram-mcp-server\"\u003e\n    \u003cimg alt=\"GitHub package.json version\" src=\"https://img.shields.io/github/package-json/v/sunwood-ai-labs/ideagram-mcp-server\"\u003e\n    \u003cimg alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/sunwood-ai-labs/ideagram-mcp-server\"\u003e\n    \u003cimg alt=\"GitHub pull requests\" src=\"https://img.shields.io/github/issues-pr/sunwood-ai-labs/ideagram-mcp-server\"\u003e\n    \u003cimg alt=\"npm\" src=\"https://img.shields.io/npm/v/@sunwood-ai-labs/ideagram-mcp-server\"\u003e\n    \u003cimg alt=\"npm\" src=\"https://img.shields.io/npm/dt/@sunwood-ai-labs/ideagram-mcp-server\"\u003e\n  \u003c/p\u003e\n\n  \u003cp\u003e\n    Ideogram API„Çí‰Ωø„Å£„Å¶ÁîªÂÉèÁîüÊàê„ÇíÊèê‰æõ„Åô„ÇãModel Context Protocol (MCP) „Çµ„Éº„Éê„Éº„Å†„ÇàÔºÅ\u003cbr\u003e\n    \u003cb\u003eIdeogram 3.0\u003c/b\u003eÂØæÂøú„Åß„ÄÅClaude Desktop„ÇÑMCP„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åã„ÇâÁàÜÈÄüÈÄ£Êê∫„Åß„Åç„Çã„ÅÆ„ÅåÁ•û‚ú®\n  \u003c/p\u003e\n\u003c/div\u003e\n\n---\n\n## üì¶ „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊ¶ÇË¶Å\n\n- Ideogram API (v3.0) „ÇíMCP„Çµ„Éº„Éê„ÉºÁµåÁî±„Åß‰Ωø„Åà„ÇãTypeScriptË£Ω„ÉÑ„Éº„É´\n- ÁîªÂÉèÁîüÊàê„Éª„Çπ„Çø„Ç§„É´ÂèÇÁÖß„Éª„Éû„Ç∏„ÉÉ„ÇØ„Éó„É≠„É≥„Éó„Éà„Éª„Ç¢„Çπ„Éö„ÇØ„ÉàÊØî„Éª„É¢„Éá„É´ÈÅ∏Êäû„Å™„Å©Â§öÊ©üËÉΩ\n- Claude Desktop„ÇÑ‰ªñMCP„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åã„ÇâÂç≥Âà©Áî®OK\n\n---\n\n\n## ‚ö°Ô∏è „ÇØ„Ç§„ÉÉ„ÇØ„Çπ„Çø„Éº„Éà\n\nClaude Desktop„ÇÑ‰ªñMCP„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÅßÁàÜÈÄüÈÄ£Êê∫„Åó„Åü„ÅÑ„Å™„Çâ„ÄÅ  \n‰∏ãË®òJSON„Çπ„Éã„Éö„ÉÉ„Éà„ÇíË®≠ÂÆö„Éï„Ç°„Ç§„É´„Å´„Ç≥„Éî„Éö„ÅßOKÔºÅ‚ú®\n\n```json\n{\n  \"mcpServers\": {\n    \"ideogram\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@sunwood-ai-labs/ideagram-mcp-server\"\n      ],\n      \"env\": {\n        \"IDEOGRAM_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n\n---\n\n## üõ†Ô∏è MCP„ÉÑ„Éº„É´‰ªïÊßò\n\n### generate_image\n\n#### „Éë„É©„É°„Éº„Çø‰∏ÄË¶ßÔºàÊúÄÊñ∞ÁâàÔºâ\n\n| „Éë„É©„É°„Éº„Çø         | Âûã         | Ë™¨Êòé                                                                                 | ÂøÖÈ†à/‰ªªÊÑè | ÂÇôËÄÉ                      |\n|--------------------|------------|--------------------------------------------------------------------------------------|-----------|---------------------------|\n| prompt             | string     | ÁîªÂÉèÁîüÊàê„Éó„É≠„É≥„Éó„ÉàÔºàËã±Ë™ûÊé®Â•®Ôºâ                                                        | ÂøÖÈ†à      |                           |\n| aspect_ratio       | string     | „Ç¢„Çπ„Éö„ÇØ„ÉàÊØîÔºà‰æã: \"1x1\", \"16x9\", \"4x3\" „Å™„Å©Ôºâ                                        | ‰ªªÊÑè      | 15Á®ÆÈ°û                    |\n| resolution         | string     | Ëß£ÂÉèÂ∫¶ÔºàÂÖ¨Âºè„Éâ„Ç≠„É•„É°„É≥„ÉàÂèÇÁÖß„ÄÅÂÖ®69Á®ÆÔºâ                                               | ‰ªªÊÑè      |                           |\n| seed               | integer    | ‰π±Êï∞„Ç∑„Éº„ÉâÔºàÂÜçÁèæÊÄßÊãÖ‰øùÁî®Ôºâ                                                            | ‰ªªÊÑè      | 0ÔΩû2147483647             |\n| magic_prompt       | string     | „Éû„Ç∏„ÉÉ„ÇØ„Éó„É≠„É≥„Éó„ÉàÔºà\"AUTO\"|\"ON\"|\"OFF\"Ôºâ                                               | ‰ªªÊÑè      | „Éá„Éï„Ç©„É´„Éà\"AUTO\"          |\n| rendering_speed    | string     | v3Áî®„É¨„É≥„ÉÄ„É™„É≥„Ç∞ÈÄüÂ∫¶Ôºà\"TURBO\"|\"DEFAULT\"|\"QUALITY\"Ôºâ                                  | ‰ªªÊÑè      |                           |\n| style_codes        | string[]   | 8ÊñáÂ≠ó„ÅÆ„Çπ„Çø„Ç§„É´„Ç≥„Éº„ÉâÈÖçÂàó                                                             | ‰ªªÊÑè      |                           |\n| style_type         | string     | „Çπ„Çø„Ç§„É´„Çø„Ç§„ÉóÔºà\"AUTO\"|\"GENERAL\"|\"REALISTIC\"|\"DESIGN\"Ôºâ                              | ‰ªªÊÑè      |                           |\n| negative_prompt    | string     | Èô§Â§ñË¶ÅÁ¥†ÔºàËã±Ë™ûÊé®Â•®Ôºâ                                                                  | ‰ªªÊÑè      |                           |\n| num_images         | number     | ÁîüÊàêÁîªÂÉèÊï∞Ôºà1ÔΩû8Ôºâ                                                                    | ‰ªªÊÑè      |                           |\n| style_reference    | object     | „Çπ„Çø„Ç§„É´ÂèÇÁÖßÔºàIdeogram 3.0Êñ∞Ê©üËÉΩÔºâ                                                   | ‰ªªÊÑè      | ‰∏ãË®òË©≥Á¥∞                   |\n| ‚îî urls             | string[]   | ÂèÇÁÖßÁîªÂÉèURLÈÖçÂàóÔºàÊúÄÂ§ß3„Å§Ôºâ                                                            | ‰ªªÊÑè      |                           |\n| ‚îî style_code       | string     | „Çπ„Çø„Ç§„É´„Ç≥„Éº„Éâ                                                                        | ‰ªªÊÑè      |                           |\n| ‚îî random_style     | boolean    | „É©„É≥„ÉÄ„É†„Çπ„Çø„Ç§„É´‰ΩøÁî®                                                                  | ‰ªªÊÑè      |                           |\n| output_dir         | string     | ÁîªÂÉè‰øùÂ≠ò„Éá„Ç£„É¨„ÇØ„Éà„É™Ôºà„Éá„Éï„Ç©„É´„Éà: \"docs\"Ôºâ                                            | ‰ªªÊÑè      |                           |\n| base_filename      | string     | ‰øùÂ≠ò„Éï„Ç°„Ç§„É´Âêç„ÅÆ„Éô„Éº„ÇπÔºà„Éá„Éï„Ç©„É´„Éà: \"ideogram-image\"Ôºâ                                | ‰ªªÊÑè      | „Çø„Ç§„É†„Çπ„Çø„É≥„Éó„ÉªID‰ªò‰∏é     |\n| blur_mask          | boolean    | ÁîªÂÉè„ÅÆÁ∏Å„Çí„Åº„Åã„ÅôÔºàtrue„Åß„Éû„Çπ„ÇØÂêàÊàêÔºâ                                                  | ‰ªªÊÑè      | „Éá„Éï„Ç©„É´„Éà: false          |\n\n#### üìù ‰ΩøÁî®‰æã\n\n```typescript\nconst result = await use_mcp_tool({\n  server_name: \"ideagram-mcp-server\",\n  tool_name: \"generate_image\",\n  arguments: {\n    prompt: \"A beautiful sunset over mountains\",\n    aspect_ratio: \"16x9\",\n    rendering_speed: \"QUALITY\",\n    num_images: 2,\n    style_reference: {\n      urls: [\n        \"https://example.com/ref1.jpg\",\n        \"https://example.com/ref2.jpg\"\n      ],\n      random_style: false\n    },\n    blur_mask: true\n  }\n});\n```\n\n---\n\n## üßë‚Äçüíª ÈñãÁô∫„Éª„Éì„É´„Éâ„Éª„ÉÜ„Çπ„Éà\n\n- `npm run build` ... TypeScript„Éì„É´„Éâ\n- `npm run watch` ... ÈñãÁô∫„É¢„Éº„ÉâÔºàËá™Âãï„Éì„É´„ÉâÔºâ\n- `npm run lint` ... „Ç≥„Éº„Éâ„É™„É≥„Éà\n- `npm test` ... „ÉÜ„Çπ„ÉàÂÆüË°å\n\n---\n\n## üóÇÔ∏è „Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÊàê\n\n```bash\nideagram-mcp-server/\n‚îú‚îÄ‚îÄ assets/\n‚îú‚îÄ‚îÄ docs/\n‚îÇ   ‚îî‚îÄ‚îÄ ideogram-image_2025-05-18T06-31-45-777Z.png\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ tools/\n‚îÇ   ‚îú‚îÄ‚îÄ types/\n‚îÇ   ‚îú‚îÄ‚îÄ utils/\n‚îÇ   ‚îú‚îÄ‚îÄ ideogram-client.ts\n‚îÇ   ‚îú‚îÄ‚îÄ index.ts\n‚îÇ   ‚îú‚îÄ‚îÄ server.ts\n‚îÇ   ‚îî‚îÄ‚îÄ test.ts\n‚îú‚îÄ‚îÄ .env.example\n‚îú‚îÄ‚îÄ package.json\n‚îú‚îÄ‚îÄ tsconfig.json\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ ...ÔºàÁúÅÁï•Ôºâ\n```\n\n---\n\n## üìù „Ç≥„É≥„Éà„É™„Éì„É•„Éº„Ç∑„Éß„É≥\n\n1. „Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„Çí„Éï„Ç©„Éº„ÇØ\n2. Êñ∞„Éñ„É©„É≥„ÉÅ‰ΩúÊàê (`git checkout -b feature/awesome`)\n3. Â§âÊõ¥„Ç≥„Éü„ÉÉ„ÉàÔºà„Ç≥„Éü„ÉÉ„Éà„É°„ÉÉ„Çª„Éº„Ç∏„ÅØÊó•Êú¨Ë™ûÔºãÁµµÊñáÂ≠óÊé®Â•®ÔºÅÔºâ\n4. „Éó„ÉÉ„Ç∑„É•ÔºÜ„Éó„É´„É™„ÇØ‰ΩúÊàê\n\n---\n\n## üöÄ „Éá„Éó„É≠„Ç§ \u0026 „É™„É™„Éº„Çπ\n\n- GitHub Actions„ÅßËá™ÂãïnpmÂÖ¨Èñã\n- „Éê„Éº„Ç∏„Éß„É≥Êõ¥Êñ∞‚Üí„Çø„Ç∞push„ÅßËá™Âãï„Éá„Éó„É≠„Ç§\n\n```bash\nnpm version patch|minor|major\ngit push --follow-tags\n```\n\nË©≥Á¥∞„ÅØ [docs/npm-deploy.md](docs/npm-deploy.md) „ÇíÂèÇÁÖßÔºÅ\n\n---\n\n## üìÑ „É©„Ç§„Çª„É≥„Çπ\n\nMIT\n\n---\n\n\u003cdiv align=\"center\"\u003e\n\n\n\n\u003c/div\u003e",
      "stars": 5,
      "updated_at": "2025-08-20T21:40:42Z",
      "url": "https://github.com/Sunwood-ai-labs/ideagram-mcp-server"
    },
    "SureScaleAI--openai-gpt-image-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate and edit images using the latest OpenAI GPT-4o and gpt-image-1 models with advanced prompt control. Outputs can be saved to disk or received in base64 format for integration with MCP-compatible clients.",
      "forks": 23,
      "imageUrl": "/freedevtools/mcp/pfp/SureScaleAI.webp",
      "keywords": [
        "openai",
        "gpt",
        "mcp",
        "openai gpt",
        "gpt image",
        "image mcp"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "openai-gpt-image-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "SureScaleAI",
      "readme_content": "# openai-gpt-image-mcp\n\n\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://www.npmjs.com/package/@modelcontextprotocol/sdk\"\u003e\u003cimg src=\"https://img.shields.io/npm/v/@modelcontextprotocol/sdk?label=MCP%20SDK\u0026color=blue\" alt=\"MCP SDK\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://www.npmjs.com/package/openai\"\u003e\u003cimg src=\"https://img.shields.io/npm/v/openai?label=OpenAI%20SDK\u0026color=blueviolet\" alt=\"OpenAI SDK\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/blob/main/LICENSE\"\u003e\u003cimg src=\"https://img.shields.io/github/license/SureScaleAI/openai-gpt-image-mcp?color=brightgreen\" alt=\"License\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/stargazers\"\u003e\u003cimg src=\"https://img.shields.io/github/stars/SureScaleAI/openai-gpt-image-mcp?style=social\" alt=\"GitHub stars\"\u003e\u003c/a\u003e\n  \u003ca href=\"https://github.com/SureScaleAI/openai-gpt-image-mcp/actions\"\u003e\u003cimg src=\"https://img.shields.io/github/actions/workflow/status/SureScaleAI/openai-gpt-image-mcp/main.yml?label=build\u0026logo=github\" alt=\"Build Status\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\n---\n\nA Model Context Protocol (MCP) tool server for OpenAI's GPT-4o/gpt-image-1 image generation and editing APIs.\n\n- **Generate images** from text prompts using OpenAI's latest models.\n- **Edit images** (inpainting, outpainting, compositing) with advanced prompt control.\n- **Supports**: Claude Desktop, Cursor, VSCode, Windsurf, and any MCP-compatible client.\n\n---\n\n## ‚ú® Features\n\n- **create-image**: Generate images from a prompt, with advanced options (size, quality, background, etc).\n- **edit-image**: Edit or extend images using a prompt and optional mask, supporting both file paths and base64 input.\n- **File output**: Save generated images directly to disk, or receive as base64.\n\n---\n\n## üöÄ Installation\n\n```sh\ngit clone https://github.com/SureScaleAI/openai-gpt-image-mcp.git\ncd openai-gpt-image-mcp\nyarn install\nyarn build\n```\n\n---\n\n## üîë Configuration\n\nAdd to Claude Desktop or VSCode (including Cursor/Windsurf) config:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\"],\n      \"env\": { \"OPENAI_API_KEY\": \"sk-...\" }\n    }\n  }\n}\n```\n\nAlso supports Azure deployments:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\"],\n      \"env\": { \n        \"AZURE_OPENAI_API_KEY\": \"sk-...\",\n        \"AZURE_OPENAI_ENDPOINT\": \"my.endpoint.com\",\n        \"OPENAI_API_VERSION\": \"2024-12-01-preview\"\n      }\n    }\n  }\n}\n```\n\nAlso supports supplying an environment files:\n\n```json\n{\n  \"mcpServers\": {\n    \"openai-gpt-image-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/dist/index.js\", \"--env-file\", \"./deployment/.env\"]\n    }\n  }\n}\n```\n\n---\n\n## ‚ö° Advanced\n\n- For `create-image`, set `n` to generate up to 10 images at once.\n- For `edit-image`, provide a mask image (file path or base64) to control where edits are applied.\n- Provide an environment file with `--env-file path/to/file/.env`\n- See `src/index.ts` for all options.\n\n---\n\n## üßë‚Äçüíª Development\n\n- TypeScript source: `src/index.ts`\n- Build: `yarn build`\n- Run: `node dist/index.js`\n\n---\n\n## üìù License\n\nMIT\n\n---\n\n## ü©∫ Troubleshooting\n\n- Make sure your `OPENAI_API_KEY` is valid and has image API access.\n- You must have a [verified OpenAI organization](https://platform.openai.com/account/organization). After verifying, it can take 15‚Äì20 minutes for image API access to activate.\n- File paths must be absolute.\n  - **Unix/macOS/Linux**: Starting with `/` (e.g., `/path/to/image.png`)\n  - **Windows**: Drive letter followed by `:` (e.g., `C:/path/to/image.png` or `C:\\path\\to\\image.png`)\n- For file output, ensure the directory is writable.\n- If you see errors about file types, check your image file extensions and formats.\n\n---\n\n## ‚ö†Ô∏è Limitations \u0026 Large File Handling\n\n- **1MB Payload Limit:** MCP clients (including Claude Desktop) have a hard 1MB limit for tool responses. Large images (especially high-res or multiple images) can easily exceed this limit if returned as base64.\n- **Auto-Switch to File Output:** If the total image size exceeds 1MB, the tool will automatically save images to disk and return the file path(s) instead of base64. This ensures compatibility and prevents errors like `result exceeds maximum length of 1048576`.\n- **Default File Location:** If you do not specify a `file_output` path, images will be saved to `/tmp` (or the directory set by the `MCP_HF_WORK_DIR` environment variable) with a unique filename.\n- **Environment Variable:**\n  - `MCP_HF_WORK_DIR`: Set this to control where large images and file outputs are saved. Example: `export MCP_HF_WORK_DIR=/your/desired/dir`\n- **Best Practice:** For large or production images, always use file output and ensure your client is configured to handle file paths.\n\n---\n\n## üìö References\n\n- [OpenAI Images API Documentation](https://platform.openai.com/docs/api-reference/images)\n\n---\n\n## üôè Credits\n\n- Built with [@modelcontextprotocol/sdk](https://www.npmjs.com/package/@modelcontextprotocol/sdk)\n- Uses [openai](https://www.npmjs.com/package/openai) Node.js SDK \n- Built by [SureScale.ai](https://surescale.ai)\n- Contributions from [Axle Research and Technology](https://axleinfo.com/)",
      "stars": 74,
      "updated_at": "2025-10-03T22:32:34Z",
      "url": "https://github.com/SureScaleAI/openai-gpt-image-mcp"
    },
    "Tencent--cos-mcp": {
      "category": "image-and-video-generation",
      "description": "Integrate large language models with Tencent Cloud Object Storage (COS) and Data Insight (CI), enabling file management, automated cloud data handling, and various image and video processing tasks. Supports natural language-based metadata search and efficient backup workflows.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/Tencent.webp",
      "keywords": [
        "cloud",
        "storage",
        "metadata",
        "tencent cloud",
        "automated cloud",
        "storage cos"
      ],
      "language": "TypeScript",
      "license": "Other",
      "name": "cos-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "Tencent",
      "readme_content": "‰∏≠Êñá | [English](README.en.md)\n\n# ËÖæËÆØ‰∫ë COS MCP Server üöÄüöÄüöÄ\n ![](https://badge.mcpx.dev?type=server 'MCP Server') [![npm Version](https://img.shields.io/npm/v/cos-mcp)](https://www.npmjs.com/package/cos-mcp) [![license](http://img.shields.io/badge/license-BSD3-brightgreen.svg?style=flat)](License.txt)\n\n\u003cp align=\"center\"\u003e\n  \u003cimg alt=\"logo\" src=\"https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/logo.png\"/\u003e\n\u003c/p\u003e\n\nÂü∫‰∫é MCP ÂçèËÆÆÁöÑËÖæËÆØ‰∫ë COS MCP ServerÔºåÊó†ÈúÄÁºñÁ†ÅÂç≥ÂèØËÆ©Â§ßÊ®°ÂûãÂø´ÈÄüÊé•ÂÖ•ËÖæËÆØ‰∫ëÂ≠òÂÇ® (COS) ÂíåÊï∞ÊçÆ‰∏áË±° (CI) ËÉΩÂäõ„ÄÇ\n\n---\n\n## ‚ú® Ê†∏ÂøÉÂäüËÉΩ\n\n### ‰∫ëÁ´ØÂ≠òÂÇ®ËÉΩÂäõ\n- ‚¨ÜÔ∏è Êñá‰ª∂‰∏ä‰º†Âà∞‰∫ëÁ´Ø\n- ‚¨áÔ∏è Êñá‰ª∂‰ªé‰∫ëÁ´Ø‰∏ãËΩΩ\n- üìã Ëé∑Âèñ‰∫ëÁ´ØÊñá‰ª∂ÂàóË°®\n\n### ‰∫ëÁ´ØÂ§ÑÁêÜËÉΩÂäõ\n- üñºÔ∏è Ëé∑ÂèñÂõæÁâá‰ø°ÊÅØ\n- üîç ÂõæÁâáË∂ÖÂàÜËæ®Áéá\n- ‚úÇÔ∏è ÂõæÁâáË£ÅÂâ™\n- üì≤ ‰∫åÁª¥Á†ÅËØÜÂà´\n- üèÜ ÂõæÁâáË¥®ÈáèËØÑ‰º∞\n- üÖ∞Ô∏è ÊñáÂ≠óÊ∞¥Âç∞\n- üé¨ ÂÖÉÊï∞ÊçÆ/Ëá™ÁÑ∂ËØ≠Ë®ÄÊ£ÄÁ¥¢ (MateInsight)\n- üìÑ ÊñáÊ°£ËΩ¨ PDF\n- üé• ËßÜÈ¢ëÂ∞ÅÈù¢\n\n---\n\n## üí° ÂÖ∏ÂûãÂ∫îÁî®Âú∫ÊôØ\n\n- ‰ΩøÁî®ÂÖ∂‰ªñ MCP ËÉΩÂäõËé∑ÂèñÁöÑÊñáÊú¨/ÂõæÁâá/ËßÜÈ¢ë/Èü≥È¢ëÁ≠âÊï∞ÊçÆÔºåÂèØÁõ¥Êé•‰∏ä‰º†Âà∞ COS ‰∫ëÁ´ØÂ≠òÂÇ®„ÄÇ\n- Êú¨Âú∞Êï∞ÊçÆÂø´ÈÄüÈÄöËøáÂ§ßÊ®°ÂûãËΩ¨Â≠òÂà∞ COS ‰∫ëÁ´ØÂ≠òÂÇ®/Â§á‰ªΩ„ÄÇ\n- ÈÄöËøáÂ§ßÊ®°ÂûãÂÆûÁé∞Ëá™Âä®ÂåñÔºöÂ∞ÜÁΩëÈ°µÈáåÁöÑËßÜÈ¢ë/ÂõæÁâá/Èü≥È¢ë/ÊñáÊú¨Á≠âÊï∞ÊçÆÊâπÈáèËΩ¨Â≠òÂà∞ COS ‰∫ëÁ´ØÂ≠òÂÇ®„ÄÇ\n- Ëá™Âä®ÂåñÂ∞ÜËßÜÈ¢ë/ÂõæÁâá/Èü≥È¢ë/ÊñáÊú¨Á≠âÊï∞ÊçÆÂú®‰∫ëÁ´ØÂ§ÑÁêÜÔºåÂπ∂ËΩ¨Â≠òÂà∞ COS ‰∫ëÁ´ØÂ≠òÂÇ®„ÄÇ\n\n---\n\n## üåü ÂäüËÉΩÁ§∫‰æã\n\n1. ‰∏ä‰º†Êñá‰ª∂Âà∞ COS  \n   ![eg1](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg1.png)\n2. ÂõæÁâáË¥®ÈáèËØÑ‰º∞  \n   ![eg3](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg3.png)\n3. Ëá™ÁÑ∂ËØ≠Ë®ÄÊ£ÄÁ¥¢ÂõæÁâá  \n   ![eg2](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg2.png)\n4. ËßÜÈ¢ëÊà™Â∏ß  \n   ![eg15](https://raw.githubusercontent.com/Tencent/cos-mcp/master/src/img/eg15.png)\n\n---\n\n# üîß ÂÆâË£Ö‰ΩøÁî®\n\n## ÂèÇÊï∞ËØ¥Êòé\n\n‰∏∫‰∫Ü‰øùÊä§ÊÇ®ÁöÑÊï∞ÊçÆÁßÅÂØÜÊÄßÔºåËØ∑ÂáÜÂ§á‰ª•‰∏ãÂèÇÊï∞Ôºö\n\n### 1. **SecretId / SecretKey**\n- **ËØ¥Êòé**: ËÖæËÆØ‰∫ë COS ÁöÑÂØÜÈí•ÔºåÁî®‰∫éË∫´‰ªΩËÆ§ËØÅÔºåËØ∑Â¶•ÂñÑ‰øùÁÆ°ÔºåÂàáÂãøÊ≥ÑÈú≤„ÄÇ\n- **Ëé∑ÂèñÊñπÂºè**: \n  1. ËÆøÈóÆ [ËÖæËÆØ‰∫ëÂØÜÈí•ÁÆ°ÁêÜ](https://console.cloud.tencent.com/cam/capi)„ÄÇ\n  2. Êñ∞Âª∫ÂØÜÈí•Âπ∂Â§çÂà∂ÁîüÊàêÁöÑ **SecretId** Âíå **SecretKey**„ÄÇ\n\n### 2. **Bucket**\n- **Á§∫‰æã**: `mybucket-123456`\n- **ËØ¥Êòé**: Â≠òÂÇ®Ê°∂ÂêçÁß∞ÔºåÁî®‰∫éÂ≠òÊîæÊï∞ÊçÆÔºåÁõ∏ÂΩì‰∫éÊÇ®ÁöÑ‰∏™‰∫∫Â≠òÂÇ®Á©∫Èó¥„ÄÇ\n- **Ëé∑ÂèñÊñπÂºè**: \n  1. ËÆøÈóÆ [Â≠òÂÇ®Ê°∂ÂàóË°®](https://console.cloud.tencent.com/cos/bucket)„ÄÇ\n  2. Â§çÂà∂Â≠òÂÇ®Ê°∂ÂêçÁß∞„ÄÇÂ¶ÇÊûúÊ≤°ÊúâÂ≠òÂÇ®Ê°∂ÔºåÂèØÁÇπÂáª‚ÄúÂàõÂª∫Â≠òÂÇ®Ê°∂‚ÄùÔºå‰∏ÄËà¨ÈÄâÊã©ÈªòËÆ§ÈÖçÁΩÆÂç≥ÂèØÂø´ÈÄüÂÆåÊàêÂàõÂª∫„ÄÇ\n\n### 3. **Region**\n- **Á§∫‰æã**: `ap-beijing`\n- **ËØ¥Êòé**: Â≠òÂÇ®Ê°∂ÊâÄÂú®ÁöÑÂú∞Âüü„ÄÇ\n- **Ëé∑ÂèñÊñπÂºè**: \n  1. Âú® [Â≠òÂÇ®Ê°∂ÂàóË°®](https://console.cloud.tencent.com/cos/bucket) ‰∏≠ÊâæÂà∞Â≠òÂÇ®Ê°∂„ÄÇ\n  2. Âú®Â≠òÂÇ®Ê°∂ÂêçÁß∞‰∏ÄË°åÊü•ÁúãÊâÄÂ±ûÂú∞ÂüüÂπ∂Â§çÂà∂Ôºå‰æãÂ¶ÇÔºö`ap-beijing`„ÄÇ\n\n### 4. **DatasetName**\n- **ËØ¥Êòé**: ÈùûÂøÖÂ°´ÂèÇÊï∞ÔºåÊï∞ÊçÆÊô∫ËÉΩÊ£ÄÁ¥¢Êìç‰ΩúÈúÄË¶ÅÊ≠§ÂèÇÊï∞„ÄÇ\n- **Ëé∑ÂèñÊñπÂºè**: \n  1. ËÆøÈóÆ [Êï∞ÊçÆÈõÜÁÆ°ÁêÜ](https://console.cloud.tencent.com/cos/metaInsight/dataManage)„ÄÇ\n  2. ÂàõÂª∫Êï∞ÊçÆÈõÜÂπ∂Á≠âÂæÖÁ¥¢ÂºïÂª∫Á´ãÂÆåÊàêÂêéÔºåÂ§çÂà∂Êï∞ÊçÆÈõÜÂêçÁß∞„ÄÇ\n\n### 5. **connectType**\n- **ËØ¥Êòé**: ÈùûÂøÖÂ°´ÂèÇÊï∞ÔºåÊåáÂÆöËøûÊé•ÊñπÂºèÔºåÂèØÈÄâÂÄº‰∏∫ `stdio`ÔºàÊú¨Âú∞ÔºâÊàñ `sse`ÔºàËøúÁ®ãÔºâ„ÄÇ\n- **ÈªòËÆ§ÂÄº**: `stdio`\n\n### 6. **port**\n- **ËØ¥Êòé**: ÈùûÂøÖÂ°´ÂèÇÊï∞ÔºåÂΩìËøûÊé•ÊñπÂºè‰∏∫ `sse` Êó∂ÔºåÂèØËá™Áî±ËÆæÁΩÆÁ´ØÂè£„ÄÇ\n- **ÈªòËÆ§ÂÄº**: `3001`\n\n---\n\n## ‰ªé npx ÂêØÂä®\n\nÂú®Â§ßÊ®°ÂûãÂÜÖ‰ΩøÁî®Êó∂Ôºà‰æãÂ¶Ç: cursorÔºâÔºåÈúÄË¶ÅÂú® `mcp.json` ‰∏≠ÈÖçÁΩÆÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--Region=yourRegion\",\n        \"--Bucket=yourBucket\",\n        \"--SecretId=yourSecretId\",\n        \"--SecretKey=yourSecretKey\",\n        \"--DatasetName=yourDatasetname\"\n      ]\n    }\n  }\n}\n```\n\n‰πüÂèØ‰ª•ÈÄöËøá JSON ÈÖçÁΩÆÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"cos-mcp\",\n        \"--cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"yourBucket\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"yourDatasetname\\\"}'\"\n      ]\n    }\n  }\n}\n```\n\n---\n\n## ‰ΩøÁî® npm ÂÆâË£Ö\n\n```bash\n# ÂÆâË£Ö\nnpm install -g cos-mcp@latest\n\n# ËøêË°åÂºÄÂêØ SSE Ê®°Âºè\ncos-mcp --Region=yourRegion --Bucket=yourBucket --SecretId=yourSecretId --SecretKey=yourSecretKey --DatasetName=yourDatasetname --port=3001 --connectType=sse\n\n# ÊàñÈÄöËøá JSON ÈÖçÁΩÆ\ncos-mcp --cos-config='{\"Region\":\"yourRegion\",\"Bucket\":\"BucketName-APPID\",\"SecretId\":\"yourSecretId\",\"SecretKey\":\"yourSecretKey\",\"DatasetName\":\"datasetName\"}' --port=3001 --connectType=sse\n```\n\nÂú®Â§ßÊ®°ÂûãÂÜÖ‰ΩøÁî® SSE Ê®°ÂºèÊó∂Ôºà‰æãÂ¶Ç: cursorÔºâÔºåÈúÄË¶ÅÂú® `mcp.json` ‰∏≠ÈÖçÁΩÆÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n---\n\n## ‰ΩøÁî®Ê∫êÁ†ÅÂÆâË£Ö\n\n### Ê≠•È™§ 1: ÂÖãÈöÜÈ°πÁõÆ‰ª£Á†Å\n\n```bash\ngit clone https://github.com/Tencent/cos-mcp.git\ncd cos-mcp\n```\n\n### Ê≠•È™§ 2: ÂÆâË£Ö‰æùËµñ\n\n```bash\nnpm install\n```\n\n### Ê≠•È™§ 3: ÂêØÂä®ÊúçÂä°\n\n#### 3.1 ÈÖçÁΩÆÊú¨Âú∞ÁéØÂ¢ÉÂèòÈáè\n\nÂàõÂª∫ `.env` Êñá‰ª∂ÔºåÂπ∂ÈÖçÁΩÆ‰ª•‰∏ãÁéØÂ¢ÉÂèòÈáèÔºö\n\n```env\nRegion='yourRegion'\nBucket='yourBucket'\nSecretId='yourSecretId'\nSecretKey='yourSecretKey'\nDatasetName=\"yourDatasetName\"\n```\n\n#### 3.2 Êú¨Âú∞ SSE Ê®°ÂºèÂêØÂä®ÔºàÊñπÂºè‰∏ÄÔºâ\n\n```bash\nnpm run start:sse\n```\n\n#### 3.3 Êú¨Âú∞ÊûÑÂª∫Âêé‰ΩøÁî® STDIO Ê®°ÂºèÔºàÊñπÂºè‰∫åÔºâ\n\n```bash\nnpm run build\n```\n\nÊûÑÂª∫‰∫ßÁâ©‰Ωç‰∫é `dist/index.js`„ÄÇ\n\n---\n\n### Ê≠•È™§ 4: Âú®Â§ßÊ®°ÂûãÂÜÖ‰ΩøÁî®\n\n#### SSE Ê®°ÂºèÈÖçÁΩÆ\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\n#### STDIO Ê®°ÂºèÈÖçÁΩÆ\n\n```json\n{\n  \"mcpServers\": {\n    \"cos-mcp\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"${your work space}/dist/index.js\"\n      ]\n    }\n  }\n}\n```\n\nÂÆåÊàê‰ª•‰∏äÊ≠•È™§ÂêéÔºåÂç≥ÂèØÈÄöËøáÊ∫êÁ†ÅËøêË°å COS MCP Server„ÄÇ\n\n---\n\n## ‚ö†Ô∏è Ê≥®ÊÑè‰∫ãÈ°π\n\n1. Â¶ÇÊûúÂÆâË£Ö‰∫ÜÊóßÁâàÊú¨ÁöÑÂåÖÔºåÂèØ‰ª•Â∞Ü‰∏äËø∞ÂÜÖÂÆπÂÜÖ `cos-mcp` Êîπ‰∏∫ `cos-mcp@latest` ÂÆâË£ÖÊúÄÊñ∞ÁâàÂåÖ„ÄÇ\n2. Â¶ÇÊûúÂÖ®Â±ÄÂÆâË£ÖÂêéÁõ¥Êé•‰ΩøÁî® `cos-mcp` ‰∏çË°åÔºåÂèØËÉΩÊòØÂÖ®Â±ÄÂèòÈáèÊúâÈóÆÈ¢òÔºåÂèØ‰ª•‰ΩøÁî®ÊãÜÂàÜÂèòÈáèÊàñ `npx` ÁöÑÊñπÂºèÂêØÂä®Ôºö\n   ```bash\n   npm install -g cos-mcp@latest\n   cos-mcp --cos-config=xxx --port=3001 --connectType=sse\n   ```\n   ‰∏äËø∞ÂëΩ‰ª§ÊïàÊûúÁ≠âÂêå‰∫éÔºö\n   ```bash\n   npx cos-mcp@latest --cos-config=xxx --port=3001 --connectType=sse\n   ```\n3. Â¶ÇÊûúÂá∫Áé∞Ëß£ÊûêÈóÆÈ¢òÔºåÂèØËÉΩÊòØÁªàÁ´ØÂØπÂèåÂºïÂè∑ÊïèÊÑüÔºåÂèØ‰ª•Â∞ÜÈÖçÁΩÆÂèÇÊï∞Êîπ‰∏∫‰ª•‰∏ãÊ†ºÂºèÂÜçÂ∞ùËØïÔºö\n   ```bash\n   --cos-config='{\\\"Region\\\":\\\"yourRegion\\\",\\\"Bucket\\\":\\\"BucketName-APPID\\\",\\\"SecretId\\\":\\\"yourSecretId\\\",\\\"SecretKey\\\":\\\"yourSecretKey\\\",\\\"DatasetName\\\":\\\"datasetName\\\"}' --port=3001 --connectType=sse\n   ```\n\n",
      "stars": 15,
      "updated_at": "2025-10-02T12:48:08Z",
      "url": "https://github.com/Tencent/cos-mcp"
    },
    "agan2023416--workers": {
      "category": "image-and-video-generation",
      "description": "An MCP server for image generation that interfaces with a Cloudflare Worker to enable asynchronous image creation, real-time status updates, and error handling. It supports type-safe API calls for generating images based on given prompts.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/agan2023416.webp",
      "keywords": [
        "cloudflare",
        "mcp",
        "images",
        "server image",
        "generating images",
        "video generation"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "workers",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "agan2023416",
      "readme_content": "# Cloudflare Workers Collection\n\nThis repository contains a collection of specialized Cloudflare Workers and related tools, each designed to provide specific functionality and services.\n\n## Available Projects\n\n### [replicate-2-r2](./replicate-2-r2)\nA worker that integrates Replicate's AI image generation with Cloudflare R2 storage. This worker:\n- Generates images using Replicate's API\n- Stores generated images in Cloudflare R2\n- Provides immediate URL generation\n- Supports webhook notifications\n- Includes MCP server integration for seamless AI tooling\n\nüëâ [Learn more about replicate-2-r2](./replicate-2-r2)\n\n### [generate-image](./mcps/generate-image)\nA Model Context Protocol (MCP) server that provides a simple interface to the replicate-2-r2 worker. This server:\n- Interfaces with replicate-2-r2 worker\n- Provides type-safe API calls\n- Handles asynchronous image generation\n- Supports real-time status updates\n\nüëâ [Learn more about generate-image](./mcps/generate-image)\n\n### [n8n-image-generator](./mcps/n8n-image-generator) ‚≠ê NEW\nA specialized MCP server designed specifically for n8n integration with SSE protocol support. This server:\n- **Perfect n8n Integration**: Works seamlessly with n8n's MCP Client Tool\n- **SSE Protocol Support**: Real-time communication using Server-Sent Events\n- **Multi-Model Support**: Supports Flux, Stable Diffusion, and more AI models\n- **Production Ready**: Built with error handling and monitoring\n- **Zero Worker Changes**: Uses existing replicate-2-r2 worker without modifications\n\nüëâ [Learn more about n8n-image-generator](./mcps/n8n-image-generator)\n\n## üöÄ Quick Start for n8n Users\n\nIf you want to use AI image generation in n8n workflows, follow these steps:\n\n### 1. Deploy the Worker\n```bash\ncd replicate-2-r2\nnpm install\nnpm run deploy\n```\n\n### 2. Set up the MCP Server\n```bash\ncd mcps/n8n-image-generator\nnpm install\nnpm run build\n```\n\n### 3. Configure Environment\n```bash\nexport CLOUDFLARE_WORKERS_URL=https://your-worker.workers.dev\nexport WORKER_API_TOKEN=your-api-token\nnpm start\n```\n\n### 4. Add to n8n\nIn your n8n workflow:\n1. Add **MCP Client Tool** node\n2. Configure connection to your MCP server\n3. Use `generate_image` tool with your prompt\n\n## Architecture Overview\n\n```mermaid\ngraph TB\n    A[n8n Workflow] --\u003e|SSE/MCP| B[n8n-image-generator MCP Server]\n    B --\u003e|HTTP API| C[replicate-2-r2 Worker]\n    C --\u003e|AI Generation| D[Replicate API]\n    C --\u003e|Storage| E[Cloudflare R2]\n    C --\u003e|Webhook| C\n    \n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#e8f5e8\n    style D fill:#fff3e0\n    style E fill:#fce4ec\n```\n\n## Getting Started\n\nEach project is contained in its own directory with its own documentation. To get started:\n\n1. Choose the project you want to use\n2. Navigate to its directory\n3. Follow the setup instructions in its README.md\n\n## Repository Structure\n\n```\ncloudflare-workers/\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ replicate-2-r2/         # Replicate integration worker\n‚îÇ   ‚îú‚îÄ‚îÄ README.md           # Worker-specific documentation\n‚îÇ   ‚îú‚îÄ‚îÄ src/                # Source code\n‚îÇ   ‚îî‚îÄ‚îÄ ...                 # Other worker files\n‚îî‚îÄ‚îÄ mcps/                   # MCP servers\n    ‚îú‚îÄ‚îÄ generate-image/     # Original MCP server\n    ‚îÇ   ‚îú‚îÄ‚îÄ README.md       # Server documentation\n    ‚îÇ   ‚îú‚îÄ‚îÄ src/           # Source code\n    ‚îÇ   ‚îî‚îÄ‚îÄ ...            # Other server files\n    ‚îî‚îÄ‚îÄ n8n-image-generator/ # ‚≠ê NEW: n8n-specific MCP server\n        ‚îú‚îÄ‚îÄ README.md       # Detailed setup guide\n        ‚îú‚îÄ‚îÄ src/           # TypeScript source\n        ‚îî‚îÄ‚îÄ ...            # Configuration files\n```\n\n## üîÑ Migration from generate-image to n8n-image-generator\n\nIf you're currently using the original `generate-image` MCP server, consider migrating to `n8n-image-generator` for better n8n integration:\n\n### Benefits of n8n-image-generator:\n- ‚úÖ **Better SSE Support**: Designed specifically for n8n's MCP Client Tool\n- ‚úÖ **Enhanced Error Handling**: More robust error messages and logging\n- ‚úÖ **Improved Performance**: Optimized for n8n workflow patterns\n- ‚úÖ **Better Documentation**: Comprehensive setup and usage guides\n- ‚úÖ **Active Development**: Focused on n8n use cases\n\n### Migration Steps:\n1. Install the new MCP server: `cd mcps/n8n-image-generator \u0026\u0026 npm install`\n2. Update your n8n MCP Client Tool configuration\n3. Test your workflows with the new server\n4. Enjoy improved reliability and performance!\n\nMore projects will be added to this collection in the future. Stay tuned for updates!",
      "stars": 0,
      "updated_at": "2025-09-14T00:28:04Z",
      "url": "https://github.com/agan2023416/workers"
    },
    "aigc17--Al-StoryLab": {
      "category": "image-and-video-generation",
      "description": "AI-StoryLab generates interactive stories with accompanying audio effects and provides illustration prompts. It leverages AI services for story creation, voice synthesis, sound effect generation, and suggests relevant audio placements.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/aigc17.webp",
      "keywords": [
        "storylab",
        "audio",
        "interactive",
        "ai storylab",
        "storylab ai",
        "storylab generates"
      ],
      "language": "",
      "license": "No License",
      "name": "Al-StoryLab",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "aigc17",
      "readme_content": "# AI-StoryLab\n\nAI-StoryLab ÊòØ‰∏Ä‰∏™Âü∫‰∫é Next.js ÂºÄÂèëÁöÑÊô∫ËÉΩÊïÖ‰∫ãÂàõ‰ΩúÂπ≥Âè∞ÔºåÂÆÉËÉΩÂ§üÂ∏ÆÂä©Áî®Êà∑ÁîüÊàêÊïÖ‰∫ãÂπ∂Ê∑ªÂä†Èü≥È¢ëÊïàÊûúÔºåËÆ©ÊïÖ‰∫ãÊõ¥Âä†ÁîüÂä®ÊúâË∂£„ÄÇÂêåÊó∂ÊîØÊåÅÁîüÊàêÈÖçÂ•óÁöÑÁªòÂõæÊèêÁ§∫ËØçÔºåÊñπ‰æøÁî®Êà∑‰ΩøÁî® Midjourney„ÄÅRecraft Á≠â AI ÁªòÂõæÂ∑•ÂÖ∑ÂàõÂª∫ÊèíÂõæ„ÄÇ\n\n## ‰∏ªË¶ÅÂäüËÉΩ\n\n- **ÊïÖ‰∫ãÁîüÊàê**ÔºöÊ†πÊçÆ‰∏ªÈ¢òËá™Âä®ÁîüÊàêÊïÖ‰∫ãÂÜÖÂÆπ\n- **ËØ≠Èü≥ÂêàÊàê**ÔºöÊîØÊåÅ‰∏≠Ëã±ÊñáËØ≠Èü≥ÁîüÊàê\n  - ‰∏≠ÊñáÔºö‰ΩøÁî® Êµ∑Ëû∫ MiniMax ËØ≠Èü≥ÊúçÂä°\n  - Ëã±ÊñáÔºö‰ΩøÁî® Replicate Kokoro ËØ≠Èü≥ÊúçÂä°\n- **Èü≥ÊïàÁîüÊàê**Ôºö‰ΩøÁî® ElevenLabs ÁîüÊàêÈÄºÁúüÁöÑÈü≥Êïà\n- **Êô∫ËÉΩÂª∫ËÆÆ**ÔºöËá™Âä®Êé®ËçêÂêàÈÄÇÁöÑÈü≥Êïà‰ΩçÁΩÆ\n- **ÁªòÂõæÊèêÁ§∫ËØç**Ôºö‰∏∫ÊïÖ‰∫ãÂú∫ÊôØËá™Âä®ÁîüÊàê AI ÁªòÂõæÊèêÁ§∫ËØç\n- **ÂØºÂá∫ÂäüËÉΩ**Ôºö\n  - ÂØºÂá∫Èü≥Êïà‰ΩçÁΩÆÊåáÂçó\n  - ÂØºÂá∫ÁªòÂõæÊèêÁ§∫ËØç\n\n## ÊäÄÊúØÊ†à\n\n- **Ê°ÜÊû∂**ÔºöNext.js 14\n- **ËØ≠Ë®Ä**ÔºöTypeScript\n- **Ê†∑Âºè**ÔºöTailwind CSS\n- **UIÁªÑ‰ª∂**Ôºöshadcn/ui (Âü∫‰∫é Radix UI ÁöÑÁªÑ‰ª∂Â∫ì)\n- **AIÊúçÂä°**Ôºö\n  - DeepSeekÔºöÊïÖ‰∫ãÁîüÊàêÂíåÁªòÂõæÊèêÁ§∫ËØçÁîüÊàê\n  - MiniMaxÔºö‰∏≠ÊñáËØ≠Èü≥\n  - KokoroÔºöËã±ÊñáËØ≠Èü≥\n  - ElevenLabsÔºöÈü≥ÊïàÁîüÊàê\n\n## ÂºÄÂßã‰ΩøÁî®\n\n1. ÂÖãÈöÜÈ°πÁõÆ\n```bash\ngit clone https://github.com/nicekate/Al-StoryLab.git\ncd Al-StoryLab\n```\n\n2. ÂÆâË£Ö‰æùËµñ\n```bash\nnpm install\n```\n\n3. ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè\nÂ§çÂà∂ `.env.example` Êñá‰ª∂Âπ∂ÈáçÂëΩÂêç‰∏∫ `.env.local`ÔºåÂ°´ÂÖ•ÂøÖË¶ÅÁöÑ API ÂØÜÈí•Ôºö\n\nÈúÄË¶ÅÂú®‰ª•‰∏ãÂπ≥Âè∞Ê≥®ÂÜåÂπ∂Ëé∑Âèñ API ÂØÜÈí•Ôºö\n- DeepSeek API Key ([Ëé∑ÂèñÂú∞ÂùÄ](https://api-docs.deepseek.com/zh-cn/))\n- MiniMax API Key Âíå Group ID ([Ëé∑ÂèñÂú∞ÂùÄ](https://platform.minimaxi.com/))\n- ElevenLabs API Key ([Ëé∑ÂèñÂú∞ÂùÄ](https://elevenlabs.io))\n- Replicate API Token ([Ëé∑ÂèñÂú∞ÂùÄ](https://replicate.com/))\n\nÂ∞ÜËé∑ÂèñÁöÑÂØÜÈí•Â°´ÂÖ• `.env.local`Ôºö\n- DEEPSEEK_API_KEY\n- MINIMAX_API_KEY\n- MINIMAX_GROUP_ID\n- ELEVENLABS_API_KEY\n- REPLICATE_API_TOKEN\n\n4. ÂêØÂä®ÂºÄÂèëÊúçÂä°Âô®\n```bash\nnpm run dev\n```\n\n5. ËÆøÈóÆ [http://localhost:3000](http://localhost:3000) ÂºÄÂßã‰ΩøÁî®\n\n## ‰ΩøÁî®ÊåáÂçó\n\n### ÁîüÊàêÊïÖ‰∫ã\n1. ËæìÂÖ•ÊïÖ‰∫ã‰∏ªÈ¢òÊàñ‰ΩøÁî®Ëá™Âä®ÁîüÊàêÁöÑÊèêÁ§∫\n2. ÈÄâÊã©ËØ≠Ë®ÄÔºà‰∏≠Êñá/Ëã±ÊñáÔºâ\n3. ÁÇπÂáªÁîüÊàêÊåâÈíÆ\n\n### Ê∑ªÂä†Èü≥Êïà\n1. ‰ΩøÁî®Êô∫ËÉΩÂª∫ËÆÆÁîüÊàêÈü≥ÊïàÊèêÁ§∫ËØç\n2. ÈÄâÊã©ÂêàÈÄÇÁöÑÈü≥Êïà‰ΩçÁΩÆ\n3. ÁÇπÂáªÁîüÊàêÈü≥Êïà\n\n### ÁîüÊàêÁªòÂõæÊèêÁ§∫ËØç\n1. Âú®ÊïÖ‰∫ãÁîüÊàêÂêéÔºåÁÇπÂáª\"ÁîüÊàêÁªòÂõæÊèêÁ§∫ËØç\"\n2. Á≥ªÁªü‰ºö‰∏∫ÊØè‰∏™ÂÖ≥ÈîÆÂú∫ÊôØÁîüÊàê AI ÁªòÂõæÊèêÁ§∫ËØç\n3. ÂèØ‰ª•Áõ¥Êé•Â§çÂà∂‰ΩøÁî®ÊàñÂØºÂá∫‰øùÂ≠ò\n\n## ËÆ∏ÂèØËØÅ\n\nMIT",
      "stars": 0,
      "updated_at": "2025-01-21T02:57:12Z",
      "url": "https://github.com/aigc17/Al-StoryLab"
    },
    "aiyogg--tinypng-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Compress images using the TinyPNG API to reduce file size while maintaining quality. Integrate image optimization into various projects seamlessly.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/aiyogg.webp",
      "keywords": [
        "tinypng",
        "compress",
        "images",
        "tinypng mcp",
        "compress images",
        "using tinypng"
      ],
      "language": "TypeScript",
      "license": "Apache License 2.0",
      "name": "tinypng-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "aiyogg",
      "readme_content": "## MCP server for TinyPNG\n[![smithery badge](https://smithery.ai/badge/@aiyogg/tinypng-mcp-server)](https://smithery.ai/server/@aiyogg/tinypng-mcp-server) [![MseeP.ai Security Assessment Badge](https://mseep.net/mseep-audited.png)](https://mseep.ai/app/aiyogg-tinypng-mcp-server)\n\n### Usage\n\n### Use `bun` or `node` to run the server\n\n1. Install dependencies and build\n\n```bash\npnpm i\npnpm build\n```\n\n2. Edit the `mcp.json` file\n\n```json\n{\n  \"mcpServers\": {\n    \"tinypng\": {\n      \"command\": \"bun\", // or \"node\"\n      \"args\": [\"/path/to/tinypng-mcp-server/src/index.ts\"], // or \"dist/index.js\"\n      \"env\": {\n        \"TINYPNG_API_KEY\": \"your-tinypng-api-key\"\n      }\n    }\n  }\n}\n```\n\n### Installing via Smithery\n\nTo install TinyPNG MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@aiyogg/tinypng-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @aiyogg/tinypng-mcp-server --client claude\n```\n\n### Tools\n\n1. Compress local image\n\n```js\n{\n  name: 'compress_local_image',\n  description: 'Compress a local image file',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imagePath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to the image file to compress',\n        example: '/Users/user/Downloads/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imagePath'],\n  },\n}\n```\n\n2. Compress remote image\n\n```js\n{\n  name: 'compress_remote_image',\n  description: 'Compress a remote image file by giving the URL of the image',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imageUrl: {\n        type: 'string',\n        description: 'The URL of the image file to compress',\n        example: 'https://example.com/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imageUrl'],\n  },\n}\n```\n",
      "stars": 4,
      "updated_at": "2025-04-28T10:03:48Z",
      "url": "https://github.com/aiyogg/tinypng-mcp-server"
    },
    "apinetwork--piapi-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Integrates with PiAPI's API to facilitate media content generation using various services like Midjourney, Flux, and more. It connects AI models with tools for seamless content creation directly from applications that support the Model Context Protocol.",
      "forks": 22,
      "imageUrl": "/freedevtools/mcp/pfp/apinetwork.webp",
      "keywords": [
        "apinetwork",
        "piapi",
        "api",
        "piapi api",
        "apinetwork piapi",
        "video generation"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "piapi-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "apinetwork",
      "readme_content": "# piapi-mcp-server\n\n[![Website](https://img.shields.io/badge/Website-piapi.ai-blue?style=flat-square\u0026logo=internet-explorer)](https://piapi.ai)\n[![Documentation](https://img.shields.io/badge/Documentation-docs-green?style=flat-square\u0026logo=bookstack)](https://piapi.ai/docs)\n[![Discord](https://img.shields.io/badge/Discord-Join%20chat-7289da?style=flat-square\u0026logo=discord)](https://discord.gg/qRRvcGa7Wb)\n\n[![smithery badge](https://smithery.ai/badge/piapi-mcp-server)](https://smithery.ai/server/piapi-mcp-server)\n\nA TypeScript implementation of a Model Context Protocol (MCP) server that integrates with PiAPI's API. PiAPI makes user able to generate media content with Midjourney/Flux/Kling/LumaLabs/Udio/Chrip/Trellis directly from Claude or any other MCP-compatible apps.\n\n\u003ca href=\"https://glama.ai/mcp/servers/ywvke8xruo\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ywvke8xruo/badge\" alt=\"PiAPI-Server MCP server\" /\u003e\u003c/a\u003e\n\n## Features (more coming soon)\n\nNote: Time-consuming tools like video generation may not complete due to Claude's timeout limitations\n\n- [x] Base Image toolkit\n- [x] Base Video toolkit\n- [x] Flux Image generation from text/image prompt\n- [x] Hunyuan Video generation from text/image prompt\n- [x] Skyreels Video generation from image prompt\n- [x] Wan Video generation from text/image prompt\n- [x] MMAudio Music generation from video\n- [x] TTS Zero-Shot voice generation\n- [ ] Midjourney Image generation\n  - [x] imagine\n  - [ ] other\n- [x] Kling Video and Effects generation\n- [x] Luma Dream Machine video generation\n- [x] Suno Music generation\n- [ ] Suno Lyrics generation\n- [ ] Udio Music and Lyrics generation\n- [x] Trellis 3D model generation from image\n- [ ] Workflow planning inside LLMs\n\n## Working with Claude Desktop Example\n\n\n\n## Prerequisites\n\n- Node.js 16.x or higher\n- npm or yarn\n- A PiAPI API key (get one at [piapi.ai](https://piapi.ai/workspace/key))\n\n## Installation\n\n### Installing via Smithery\n\nTo install PiAPI MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/piapi-mcp-server):\n\n```bash\nnpx -y @smithery/cli install piapi-mcp-server --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/apinetwork/piapi-mcp-server\ncd piapi-mcp-server\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Build the project:\n\n```bash\nnpm run build\n```\n\nAfter building, a `dist/index.js` file will be generated. You can then configure this file with Claude Desktop and other applications. For detailed configuration instructions, please refer to the Usage section.\n\n4. (Optional) Test server with MCP Inspector:\n\nFirst, create a `.env` file in the project root directory with your API key:\n\n```bash\nPIAPI_API_KEY=your_api_key_here\n```\n\nThen run the following command to start the MCP Inspector:\n\n```bash\nnpm run inspect\n```\n\nAfter running the command, MCP Inspector will be available at http://localhost:5173 (default port: 5173). Open this URL in your browser to start testing. The default timeout for inspector operations is 10000ms (10 seconds), which may not be sufficient for image generation tasks. It's recommended to increase the timeout when testing image generation or other time-consuming operations. You can adjust the timeout by adding a timeout parameter to the URL, for example: http://localhost:5173?timeout=60000 (sets timeout to 60 seconds)\n\nThe MCP Inspector is a powerful development tool that helps you test and debug your MCP server implementation. Key features include:\n\n- **Interactive Testing**: Test your server's functions directly through a web interface\n- **Real-time Feedback**: See immediate results of your function calls and any errors that occur\n- **Request/Response Inspection**: View detailed information about requests and responses\n- **Function Documentation**: Browse available functions and their parameters\n- **Custom Parameters**: Set custom timeout values and other configuration options\n- **History Tracking**: Keep track of your previous function calls and their results\n\nFor detailed information about using the MCP Inspector and its features, visit the [official MCP documentation](https://modelcontextprotocol.io/docs/tools/inspector).\n\n## Usage\n\n### Connecting to Claude Desktop\n\nAdd this to your Claude Desktop configuration file (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS or `%APPDATA%\\Claude\\claude_desktop_config.json` on Windows):\n\n```json\n{\n  \"mcpServers\": {\n    \"piapi\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/piapi-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"PIAPI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\nAfter updating your configuration file, you need to restart Claude for Desktop. Upon restarting, you should see a hammer icon in the bottom right corner of the input box.\nFor more detailed information, visit the [official MCP documentation](https://modelcontextprotocol.io/quickstart/user)\n\n### Connecting to Cursor\n\nNote: Following guide is based on Cursor 0.47.5. Features and behaviors may vary in different versions.\n\nTo configure the MCP server:\n\n1. Navigate to: File \u003e Preferences \u003e Cursor Settings, or use the shortcut key `Ctrl+Shift+J`\n2. Select \"MCP\" tab on the left panel\n3. Click \"Add new global MCP server\" button in the top right\n4. Add your configuration in the opened mcp.json file\n\n```json\n{\n  \"mcpServers\": {\n    \"piapi\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/piapi-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"PIAPI_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n5. After configuration, you'll see a \"piapi\" entry in MCP Servers page\n6. Click the Refresh button on the entry or restart Cursor to connect to the piapi server\n\nTo test the piapi image generation:\n\n1. Open and select \"Agent mode\" in Cursor Chat, or use the shortcut key `Ctrl+I`\n2. Enter a test prompt, for example: \"generate image of a dog\"\n3. The image will be generated based on your prompt using piapi server\n\nTo disable the piapi server:\n\n1. Navigate to the MCP Servers page in Cursor Settings\n2. Find the \"piapi\" entry in the server list\n3. Click the \"Enabled\" toggle button to switch it to \"Disabled\"\n\n## Development\n\n### Project Structure\n\n```\npiapi-mcp-server/\n‚îú‚îÄ‚îÄ assets/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ index.ts        # Main server entry point\n‚îú‚îÄ‚îÄ package.json\n‚îú‚îÄ‚îÄ tsconfig.json\n‚îî‚îÄ‚îÄ .env.example\n```\n\n## License\n\nMIT",
      "stars": 61,
      "updated_at": "2025-09-27T21:10:22Z",
      "url": "https://github.com/apinetwork/piapi-mcp-server"
    },
    "attarmau--StyleCLIP": {
      "category": "image-and-video-generation",
      "description": "A CLIP-based fashion recommendation system that enables users to upload clothing images and receive similar clothing tag recommendations through an interactive web interface. It utilizes YOLO for clothing detection and integrates seamlessly with an MCP framework.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/attarmau.webp",
      "keywords": [
        "styleclip",
        "fashion",
        "clothing",
        "clothing images",
        "upload clothing",
        "clothing tag"
      ],
      "language": "Python",
      "license": "Apache License 2.0",
      "name": "StyleCLIP",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "attarmau",
      "readme_content": "# FastMCP_RecSys\nThis is a CLIP-Based Fashion Recommender with MCP. \n\n### üìå Sample Components for UI\n1. Image upload\n2. Submit button\n3. Display clothing tags + recommendations\n\n# Mockup\nA user uploads a clothing image ‚Üí YOLO detects clothing ‚Üí CLIP encodes ‚Üí Recommend similar\n\n\u003cimg width=\"463\" alt=\"Screenshot 2025-04-26 at 10 26 13‚ÄØAM\" src=\"https://github.com/user-attachments/assets/93c0a75b-4ed1-4fa1-b25d-5137b8eb6af0\" /\u003e\n\n\n# Folder Structure\n```\n/project-root\n‚îÇ\n‚îú‚îÄ‚îÄ /backend\n‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile            \n‚îÇ   ‚îú‚îÄ‚îÄ /app\n‚îÇ   ‚îú‚îÄ‚îÄ /aws\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rekognition_wrapper.py         # AWS Rekognition logic\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /utils\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image_utils.py                 # Bounding box crop utils\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /controllers\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clothing_detector.py           # Coordinates Rekognition + cropping\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /tests\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_rekognition_wrapper.py\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_clothing_tagging.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.py                    # FastAPI app code\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /routes\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clothing_routes.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /controllers\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clothing_controller.py\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clothing_tagging.py\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tag_extractor.py         # Pending: define core CLIP functionality\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clothing_schemas.py\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tag_list_en.py           $ Tool for mapping: https://jsoncrack.com/editor\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py       \n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.py       \n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api_keys.py     \n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt      \n‚îÇ   ‚îî‚îÄ‚îÄ .env                      \n‚îÇ                      \n‚îú‚îÄ‚îÄ /frontend \n‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile        \n‚îÇ   ‚îú‚îÄ‚îÄ package.json              \n‚îÇ   ‚îú‚îÄ‚îÄ package-lock.json         \n‚îÇ   ‚îú‚îÄ‚îÄ /public\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html            \n‚îÇ   ‚îú‚îÄ‚îÄ /src\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /components            \n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ImageUpload.jsx    \n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DetectedTags.jsx   \n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Recommendations.jsx \n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ /utils\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js             \n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.js                    # Main React component\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.js\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.css            \n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js        \n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ postcss.config.js                    \n‚îÇ   ‚îî‚îÄ‚îÄ .env                                \n‚îú‚îÄ‚îÄ docker-compose.yml                     \n‚îî‚îÄ‚îÄ README.md \n```\n\n## Quick Start Guide\n### Step 1: Clone the GitHub Project\n### Step 2: Set Up the Python Environment\n```\npython -m venv venv\nsource venv/bin/activate  # On macOS or Linux\nvenv\\Scripts\\activate     # On Windows\n```\n### Step 3: Install Dependencies\n```\npip install -r requirements.txt\n```\n### Step 4: Start the FastAPI Server (Backend)\n```\nuvicorn backend.app.server:app --reload\n```\nOnce the server is running and the database is connected, you should see the following message in the console:\n```\nDatabase connected\nINFO:     Application startup complete.\n```\n\u003cimg width=\"750\" alt=\"Screenshot 2025-04-25 at 1 15 45‚ÄØAM\" src=\"https://github.com/user-attachments/assets/7f3fc403-fb33-4107-a00c-61796a48ecec\" /\u003e\n\n### Step 5: Install Dependencies\nDatabase connected\nINFO:     Application startup complete.\n```\nnpm install\n```\n### Step 6: Start the Development Server (Frontend)\n```\nnpm start\n```\nOnce running, the server logs a confirmation and opens the app in your browser: [http://localhost:3000/](http://localhost:3000/)\n\n\u003cimg width=\"372\" alt=\"Screenshot 2025-04-25 at 9 08 50‚ÄØPM\" src=\"https://github.com/user-attachments/assets/794a6dba-9fbb-40f1-9e57-c5c2e2af1013\" /\u003e\n\n# What‚Äôs completed so far:\n1. FastAPI server is up and running (24 Apr)\n2. Database connection is set up (24 Apr)\n3. Backend architecture is functional (24 Apr)\n4. Basic front-end UI for uploading picture (25 Apr)\n## 5. Mock Testing for AWS Rekognition -\u003e bounding box (15 May)\n```\nPYTHONPATH=. pytest backend/app/tests/test_rekognition_wrapper.py\n```\n\u003cimg width=\"1067\" alt=\"Screenshot 2025-05-20 at 4 58 14‚ÄØPM\" src=\"https://github.com/user-attachments/assets/7a25a92d-2aca-42a8-abdd-194dd9d2e8a5\" /\u003e\n\n- Tested Rekognition integration logic independently using a mock ‚Üí verified it correctly extracts bounding boxes only when labels match the garment set\n- Confirmed the folder structure and PYTHONPATH=. works smoothly with pytest from root\n\n## 6. Mock Testing for AWS Rekognition -\u003e CLIP (20 May)\n```\nPYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py\n```\n\u003cimg width=\"1062\" alt=\"Screenshot 2025-05-21 at 9 25 33‚ÄØAM\" src=\"https://github.com/user-attachments/assets/6c64b658-3414-4115-9e20-520132605cab\" /\u003e\n\n- Detecting garments using AWS Rekognition \n\n- Cropping the image around detected bounding boxes\n\n- Tagging the cropped image using CLIP\n\n## 7. Mock Testing for full image tagging pipeline (Image bytes ‚Üí AWS Rekognition (detect garments) ‚Üí Crop images ‚Üí CLIP (predict tags) + Error Handling (25 May)\n| **Negative Test Case**         | **Description**                                                                 |\n| -------------------------------| ------------------------------------------------------------------------------- |\n| No Detection Result            | AWS doesn't detect any garments ‚Äî should return an empty list.                  |\n| Image Not Clothing             | CLIP returns vague or empty tags ‚Äî verify fallback behavior.                    |\n| AWS Returns Exception          | Simulate `rekognition.detect_labels` throwing an error ‚Äî check `try-except`.    |\n| Corrupted Image File           | Simulate a broken (non-JPEG) image ‚Äî verify it raises an error or gives a hint. |\n\n```\nPYTHONPATH=. pytest backend/app/tests/test_clothing_tagging.py\n```\n\u003cimg width=\"1072\" alt=\"Screenshot 2025-05-21 at 11 19 47‚ÄØAM\" src=\"https://github.com/user-attachments/assets/b41f07f4-7926-44a3-8b64-34fe3c6ef049\" /\u003e\n\n- detect_garments: simulates AWS Rekognition returning one bounding box: {\"Left\": 0.1, \"Top\": 0.1, \"Width\": 0.5, \"Height\": 0.5}\n- crop_by_bounding_box: simulates the cropping step returning a dummy \"cropped_image\" object\n- get_tags_from_clip: simulates CLIP returning a list of tags: [\"T-shirt\", \"Cotton\", \"Casual\"]\n\n## 8. Run Testing for CLIP Output (30 May)\n```\npython3 -m venv venv\npip install -r requirements.txt\npip install git+https://github.com/openai/CLIP.git\npython -m backend.app.tests.test_tag_extractor\n```\n\u003cimg width=\"1111\" alt=\"Screenshot 2025-06-06 at 5 12 13‚ÄØPM\" src=\"https://github.com/user-attachments/assets/d0b3b288-20f8-482f-9d39-dcccf9a775ee\" /\u003e\n\nNext Step:\n1. Evaluate CLIP‚Äôs tagging accuracy on sample clothing images\n2. Fine-tune the tagging system for better recommendations\n3. Test the backend integration with real-time user data\n4. Set up monitoring for model performance\n5. Front-end demo\n",
      "stars": 0,
      "updated_at": "2025-09-19T08:44:33Z",
      "url": "https://github.com/attarmau/StyleCLIP"
    },
    "awkoy--replicate-flux-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate images from text prompts using advanced AI models. Customize parameters for tailored outputs with secure and local processing.",
      "forks": 11,
      "imageUrl": "/freedevtools/mcp/pfp/awkoy.webp",
      "keywords": [
        "ai",
        "mcp",
        "prompts",
        "mcp generate",
        "generate images",
        "awkoy replicate"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "replicate-flux-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "awkoy",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/awkoy-replicate-flux-mcp-badge.png)](https://mseep.ai/app/awkoy-replicate-flux-mcp)\n\n# Replicate Flux MCP\n\n![MCP Compatible](https://img.shields.io/badge/MCP-Compatible-blue)\n![License](https://img.shields.io/badge/license-MIT-green)\n![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-blue)\n![Model Context Protocol](https://img.shields.io/badge/MCP-Enabled-purple)\n[![smithery badge](https://smithery.ai/badge/@awkoy/replicate-flux-mcp)](https://smithery.ai/server/@awkoy/replicate-flux-mcp)\n![NPM Downloads](https://img.shields.io/npm/dw/replicate-flux-mcp)\n![Stars](https://img.shields.io/github/stars/awkoy/replicate-flux-mcp)\n\n\u003ca href=\"https://glama.ai/mcp/servers/ss8n1knen8\"\u003e\n  \u003cimg alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ss8n1knen8/badge\" /\u003e\n\u003c/a\u003e\n\n**Replicate Flux MCP** is an advanced Model Context Protocol (MCP) server that empowers AI assistants to generate high-quality images and vector graphics. Leveraging [Black Forest Labs' Flux Schnell model](https://replicate.com/black-forest-labs/flux-schnell) for raster images and [Recraft's V3 SVG model](https://replicate.com/recraft-ai/recraft-v3-svg) for vector graphics via the Replicate API.\n\n## üìë Table of Contents\n\n- [Getting Started \u0026 Integration](#-getting-started--integration)\n  - [Setup Process](#setup-process)\n  - [Cursor Integration](#cursor-integration)\n  - [Claude Desktop Integration](#claude-desktop-integration)\n  - [Smithery Integration](#smithery-integration)\n  - [Glama.ai Integration](#glamaai-integration)\n- [Features](#-features)\n- [Documentation](#-documentation)\n  - [Available Tools](#available-tools)\n  - [Available Resources](#available-resources)\n- [Development](#-development)\n- [Technical Details](#-technical-details)\n- [Troubleshooting](#-troubleshooting)\n- [Contributing](#-contributing)\n- [License](#-license)\n- [Resources](#-resources)\n- [Examples](#-examples)\n\n## üöÄ Getting Started \u0026 Integration\n\n### Setup Process\n\n1. **Obtain a Replicate API Token**\n   - Sign up at [Replicate](https://replicate.com/)\n   - Create an API token in your account settings\n\n2. **Choose Your Integration Method**\n   - Follow one of the integration options below based on your preferred MCP client\n\n3. **Ask Your AI Assistant to Generate an Image**\n   - Simply ask naturally: \"Can you generate an image of a serene mountain landscape at sunset?\"\n   - Or be more specific: \"Please create an image showing a peaceful mountain scene with a lake reflecting the sunset colors in the foreground\"\n\n4. **Explore Advanced Features**\n   - Try different parameter settings for customized results\n   - Experiment with SVG generation using `generate_svg`\n   - Use batch image generation or variant generation features\n\n### Cursor Integration\n\n#### Method 1: Using mcp.json\n\n1. Create or edit the `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate-flux-mcp\": {\n      \"command\": \"env REPLICATE_API_TOKEN=YOUR_TOKEN npx\",\n      \"args\": [\"-y\", \"replicate-flux-mcp\"]\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Replicate API token\n3. Restart Cursor to apply the changes\n\n#### Method 2: Manual Mode\n\n1. Open Cursor and go to Settings\n2. Navigate to the \"MCP\" or \"Model Context Protocol\" section\n3. Click \"Add Server\" or equivalent\n4. Enter the following command in the appropriate field:\n\n```\nenv REPLICATE_API_TOKEN=YOUR_TOKEN npx -y replicate-flux-mcp\n```\n\n5. Replace `YOUR_TOKEN` with your actual Replicate API token\n6. Save the settings and restart Cursor if necessary\n\n### Claude Desktop Integration\n\n1. Create or edit the `mcp.json` file in your configuration directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate-flux-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"replicate-flux-mcp\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"YOUR TOKEN\"\n      }\n    }\n  }\n}\n```\n\n2. Replace `YOUR_TOKEN` with your actual Replicate API token\n3. Restart Claude Desktop to apply the changes\n\n### Smithery Integration\n\nThis MCP server is available as a hosted service on Smithery, allowing you to use it without setting up your own server.\n\n1. Visit [Smithery](https://smithery.ai/) and create an account if you don't have one\n2. Navigate to the [Replicate Flux MCP server page](https://smithery.ai/server/@awkoy/replicate-flux-mcp)\n3. Click \"Add to Workspace\" to add the server to your Smithery workspace\n4. Configure your MCP client (Cursor, Claude Desktop, etc.) to use your Smithery workspace URL\n\nFor more information on using Smithery with your MCP clients, visit the [Smithery documentation](https://smithery.ai/docs).\n\n### Glama.ai Integration\n\nThis MCP server is also available as a hosted service on Glama.ai, providing another option to use it without local setup.\n\n1. Visit [Glama.ai](https://glama.ai/) and create an account if you don't have one\n2. Go to the [Replicate Flux MCP server page](https://glama.ai/mcp/servers/ss8n1knen8)\n3. Click \"Install Server\" to add the server to your workspace\n4. Configure your MCP client to use your Glama.ai workspace\n\nFor more information, visit the [Glama.ai MCP servers documentation](https://glama.ai/mcp/servers).\n\n## üåü Features\n\n- **üñºÔ∏è High-Quality Image Generation** - Create stunning images using Flux Schnell, a state-of-the-art AI model\n- **üé® Vector Graphics Support** - Generate professional SVG vector graphics with Recraft V3 SVG model\n- **ü§ñ AI Assistant Integration** - Seamlessly enable AI assistants like Claude to generate visual content\n- **üéõÔ∏è Advanced Customization** - Fine-tune generation with controls for aspect ratio, quality, resolution, and more\n- **üîå Universal MCP Compatibility** - Works with all MCP clients including Cursor, Claude Desktop, Cline, and Zed\n- **üîí Secure Local Processing** - All requests are processed locally for enhanced privacy and security\n- **üîç Comprehensive History Management** - Track, view, and retrieve your complete generation history\n- **üìä Batch Processing** - Generate multiple images from different prompts in a single request\n- **üîÑ Variant Exploration** - Create and compare multiple interpretations of the same concept\n- **‚úèÔ∏è Prompt Engineering** - Fine-tune image variations with specialized prompt modifications\n\n## üìö Documentation\n\n### Available Tools\n\n#### `generate_image`\n\nGenerates an image based on a text prompt using the Flux Schnell model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the image to generate\n  seed?: number;                 // Optional: Random seed for reproducible generation\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  num_outputs?: number;          // Optional: Number of images to generate (1-4) (default: 1)\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_multiple_images`\n\nGenerates multiple images based on an array of prompts using the Flux Schnell model.\n\n```typescript\n{\n  prompts: string[];             // Required: Array of text descriptions for images to generate (1-10 prompts)\n  seed?: number;                 // Optional: Random seed for reproducible generation\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_image_variants`\n\nGenerates multiple variants of the same image from a single prompt.\n\n```typescript\n{\n  prompt: string;                // Required: Text description for the image to generate variants of\n  num_variants: number;          // Required: Number of image variants to generate (2-10, default: 4)\n  prompt_variations?: string[];  // Optional: List of prompt modifiers to apply to variants (e.g., [\"in watercolor style\", \"in oil painting style\"])\n  variation_mode?: \"append\" | \"replace\"; // Optional: How to apply variations - 'append' adds to base prompt, 'replace' uses variations directly (default: \"append\")\n  seed?: number;                 // Optional: Base random seed. Each variant will use seed+variant_index\n  go_fast?: boolean;             // Optional: Run faster predictions with optimized model (default: true)\n  megapixels?: \"1\" | \"0.25\";     // Optional: Image resolution (default: \"1\")\n  aspect_ratio?: string;         // Optional: Aspect ratio (e.g., \"16:9\", \"4:3\") (default: \"1:1\")\n  output_format?: string;        // Optional: Output format (\"webp\", \"jpg\", \"png\") (default: \"webp\")\n  output_quality?: number;       // Optional: Image quality (0-100) (default: 80)\n  num_inference_steps?: number;  // Optional: Number of denoising steps (1-4) (default: 4)\n  disable_safety_checker?: boolean; // Optional: Disable safety filter (default: false)\n}\n```\n\n#### `generate_svg`\n\nGenerates an SVG vector image based on a text prompt using the Recraft V3 SVG model.\n\n```typescript\n{\n  prompt: string;                // Required: Text description of the SVG to generate\n  size?: string;                 // Optional: Size of the generated SVG (default: \"1024x1024\")\n  style?: string;                // Optional: Style of the generated image (default: \"any\")\n                                // Options: \"any\", \"engraving\", \"line_art\", \"line_circuit\", \"linocut\"\n}\n```\n\n#### `prediction_list`\n\nRetrieves a list of your recent predictions from Replicate.\n\n```typescript\n{\n  limit?: number;  // Optional: Maximum number of predictions to return (1-100) (default: 50)\n}\n```\n\n#### `get_prediction`\n\nGets detailed information about a specific prediction.\n\n```typescript\n{\n  predictionId: string;  // Required: ID of the prediction to retrieve\n}\n```\n\n### Available Resources\n\n#### `imagelist`\n\nBrowse your history of generated images created with the Flux Schnell model.\n\n#### `svglist`\n\nBrowse your history of generated SVG images created with the Recraft V3 SVG model.\n\n#### `predictionlist`\n\nBrowse all your Replicate predictions history.\n\n## üíª Development\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/awkoy/replicate-flux-mcp.git\ncd replicate-flux-mcp\n```\n\n2. Install dependencies:\n\n```bash\nnpm install\n```\n\n3. Start development mode:\n\n```bash\nnpm run dev\n```\n\n4. Build the project:\n\n```bash\nnpm run build\n```\n\n5. Connect to Client:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-generation-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"/Users/{USERNAME}/{PATH_TO}/replicate-flux-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"YOUR REPLICATE API TOKEN\"\n      }\n    }\n  }\n}\n```\n\n## ‚öôÔ∏è Technical Details\n\n### Stack\n\n- **Model Context Protocol SDK** - Core MCP functionality for tool and resource management\n- **Replicate API** - Provides access to state-of-the-art AI image generation models\n- **TypeScript** - Ensures type safety and leverages modern JavaScript features\n- **Zod** - Implements runtime type validation for robust API interactions\n\n### Configuration\n\nThe server can be configured by modifying the `CONFIG` object in `src/config/index.ts`:\n\n```javascript\nconst CONFIG = {\n  serverName: \"replicate-flux-mcp\",\n  serverVersion: \"0.1.2\",\n  imageModelId: \"black-forest-labs/flux-schnell\",\n  svgModelId: \"recraft-ai/recraft-v3-svg\",\n  pollingAttempts: 25,\n  pollingInterval: 2000, // ms\n};\n```\n\n## üîç Troubleshooting\n\n### Common Issues\n\n#### Authentication Error\n- Ensure your `REPLICATE_API_TOKEN` is correctly set in the environment\n- Verify your token is valid by testing it with the Replicate API directly\n\n#### Safety Filter Triggered\n- The model has a built-in safety filter that may block certain prompts\n- Try modifying your prompt to avoid potentially problematic content\n\n#### Timeout Error\n- For larger images or busy servers, you might need to increase `pollingAttempts` or `pollingInterval` in the configuration\n- Default settings should work for most use cases\n\n## ü§ù Contributing\n\nContributions are welcome! Please follow these steps to contribute:\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nFor feature requests or bug reports, please create a GitHub issue. If you like this project, consider starring the repository!\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## üîó Resources\n\n- [Model Context Protocol Documentation](https://modelcontextprotocol.io)\n- [Replicate API Documentation](https://replicate.com/docs)\n- [Flux Schnell Model](https://replicate.com/black-forest-labs/flux-schnell)\n- [Recraft V3 SVG Model](https://replicate.com/recraft-ai/recraft-v3-svg)\n- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n- [Smithery Documentation](https://smithery.ai/docs)\n- [Glama.ai MCP Servers](https://glama.ai/mcp/servers)\n\n## üé® Examples\n\n![Demo](https://github.com/user-attachments/assets/ad6db606-ae3a-48db-a1cc-e1f88847769e)\n\n| Multiple Prompts | Prompt Variants |\n|-----------------|-----------------|\n| ![Multiple prompts example: \"A serene mountain lake at sunset\", \"A bustling city street at night\", \"A peaceful garden in spring\"](https://github.com/user-attachments/assets/e5ac56d2-bfbb-4f33-938c-a3d7bffeee60) | ![Variants example: Base prompt \"A majestic castle\" with modifiers \"in watercolor style\", \"as an oil painting\", \"with gothic architecture\"](https://github.com/user-attachments/assets/8ebe5992-4803-4bf3-a82a-251135b0698a) |\n\nHere are some examples of how to use the tools:\n\n### Batch Image Generation with `generate_multiple_images`\n\nCreate multiple distinct images at once with different prompts:\n\n```json\n{\n  \"prompts\": [\n    \"A red sports car on a mountain road\", \n    \"A blue sports car on a beach\", \n    \"A vintage sports car in a city street\"\n  ]\n}\n```\n\n### Image Variants with `generate_image_variants`\n\nCreate different interpretations of the same concept using seeds:\n\n```json\n{\n  \"prompt\": \"A futuristic city skyline at night\",\n  \"num_variants\": 4,\n  \"seed\": 42\n}\n```\n\nOr explore style variations with prompt modifiers:\n\n```json\n{\n  \"prompt\": \"A character portrait\",\n  \"prompt_variations\": [\n    \"in anime style\", \n    \"in watercolor style\", \n    \"in oil painting style\", \n    \"as a 3D render\"\n  ]\n}\n```\n\n---\n\nMade with ‚ù§Ô∏è by Yaroslav Boiko\n\n",
      "stars": 50,
      "updated_at": "2025-09-14T19:36:15Z",
      "url": "https://github.com/awkoy/replicate-flux-mcp"
    },
    "awslabs--mcp": {
      "category": "image-and-video-generation",
      "description": "A specialized generative AI tool for creating visual media from textual descriptions. It integrates capabilities similar to modern text-to-image models, which utilize deep neural networks to transform language into photorealistic or artistic visuals. This implementation uniquely incorporates specified color palettes as a critical constraint during the image synthesis process, offering precise chromatic control over the output media.",
      "forks": 942,
      "imageUrl": "/freedevtools/mcp/pfp/awslabs.webp",
      "keywords": [
        "awslabs",
        "images",
        "mcp",
        "awslabs mcp",
        "generates images",
        "generation awslabs"
      ],
      "language": "Python",
      "license": "Apache License 2.0",
      "name": "Visual Synthesis Engine with Palette Guidance",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "awslabs",
      "readme_content": "## **Introduction**\n\nThis system functions as an advanced visual synthesis utility, drawing inspiration from the evolving field of text-to-image models. These models, often based on latent diffusion architectures, effectively bridge natural language understanding with image generation capabilities. Our tool extends this by accepting user-defined color constraints, allowing for detailed chromatic direction alongside standard descriptive prompts. This permits outputs to align not just with semantic content, but also with a required visual theme or palette, a feature enhancing creative control in media generation workflows.\n\n## **Core Generation Mechanism**\n\nThis engine processes natural language requests, mapping them into an internal representation that guides the visual creation phase. A key differentiator is the integration of user-supplied color schemes. The model conditions its output generation based on both the text prompt and the required palette. It supports the simultaneous creation of several images per single instructional input, optimizing batch processing for specific visual tasks.\n\n## **Configuration Details**\n\nControlling the output dimensions and the level of synthesis fidelity requires specific parameters. Adjust these settings to balance generation speed against final image quality.\n\n**Image Parameters:**\n\n*   `dimensions`: Specify the output aspect ratio and resolution.\n*   `quality_setting`: Adjust the computational effort applied during sampling.\n*   `palette_input`: Define the required color array or reference for chromatic guidance.\n\n## **Usage**\n\nTo invoke the generator, supply a descriptive text string and the desired color constraints. Successful operation yields a set of generated visual assets.\n\nExample request structure:\n\n```json\n{\n  \"prompt\": \"A serene mountain lake at sunrise, reflective surface.\",\n  \"palette\": [\"#000080\", \"#FFD700\", \"#A9A9A9\"], \n  \"count\": 4,\n  \"output_size\": \"1024x1024\"\n}\n```\n\n## **API**\n\nFor programmatic access, communication adheres strictly to the Model Context Protocol (MCP) standards. Clients must maintain appropriate connections to invoke the server's generative endpoint. Responses will contain the resulting image data or references to stored assets, depending on the configuration.\n\n## **Security**\n\nAccess to the generative model should be secured via standard authentication mechanisms expected by the MCP framework. Pay special attention to data transmission security, as high-resolution media assets are being transferred.\n\n## **Setup**\n\nInstallation involves deploying the server component and ensuring appropriate dependencies, including necessary deep learning frameworks, are present on the host system. Configure AWS credentials if the server relies on cloud-backed resources for storage or model serving.\n\n## **Integration**\n\nThis tool integrates seamlessly with other MCP-enabled applications, such as coding assistants or media pipeline processors. Its structured input requirements make it suitable for automation scripts requiring controlled visual assets.\n\n## **Related Topics**\n\n*   Latent Diffusion Models\n*   Deep Neural Networks for Image Synthesis\n*   Generative Adversarial Networks (GANs)\n*   Color Theory in Digital Imaging\n*   Model Context Protocol (MCP) Specification\n\n## **Extra Details**\n\nWhile highly effective models often rely on massive, web-scraped training datasets, our specific focus on palette conditioning allows for fine-grained stylistic control not always available in general-purpose models. When using custom palettes, ensure the specified colors are represented accurately within the model's learned color space for optimal adherence.\n\n## **Conclusion**\n\nThis engine offers a targeted solution for generating visual content, specifically enhancing traditional text-to-image capabilities with mandatory color palette guidance. By integrating this contextual control, users gain a powerful instrument for creating media that meets rigorous pre-defined visual specifications, advancing automated image and video generation tasks.",
      "stars": 6585,
      "updated_at": "2025-10-04T06:19:32Z",
      "url": "https://github.com/awslabs/mcp"
    },
    "bendusy--pollinations-mcp": {
      "category": "image-and-video-generation",
      "description": "Connects AI models to Pollinations.ai's services for generating images and text via the MCP protocol. Facilitates seamless interaction with Pollinations.ai's API for image generation, downloading images, and text generation.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/bendusy.webp",
      "keywords": [
        "ai",
        "pollinations",
        "images",
        "pollinations ai",
        "generating images",
        "ai api"
      ],
      "language": "JavaScript",
      "license": "Apache License 2.0",
      "name": "pollinations-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "bendusy",
      "readme_content": "# Pollinations MCP ÊúçÂä°Âô®\n\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\nËøôÊòØ‰∏Ä‰∏™Âü∫‰∫é[Model Context Protocol (MCP)](https://github.com/microsoft/modelcontextprotocol)ÁöÑÊúçÂä°Âô®ÂÆûÁé∞ÔºåÁî®‰∫éËøûÊé•[Pollinations.ai](https://pollinations.ai)ÊúçÂä°ÁöÑAPIÊé•Âè£„ÄÇËØ•ÊúçÂä°Âô®ÂÖÅËÆ∏AIÊ®°ÂûãÈÄöËøáMCPÂçèËÆÆË∞ÉÁî®Pollinations.aiÁöÑÂõæÂÉèÂíåÊñáÊú¨ÁîüÊàêÂäüËÉΩ„ÄÇ\n\n## ÂäüËÉΩÁâπÁÇπ\n\n- ÊîØÊåÅÈÄöËøáMCPÂçèËÆÆ‰∏éPollinations.aiÊúçÂä°‰∫§‰∫í\n- Êèê‰æõ‰∏â‰∏™‰∏ªË¶ÅÂ∑•ÂÖ∑Ôºö\n  - `generate_image`: ‰ΩøÁî®Pollinations.aiÁîüÊàêÂõæÂÉèÂπ∂ËøîÂõûURLÔºàÈªòËÆ§Êó†Ê∞¥Âç∞Ôºâ\n  - `download_image`: ‰∏ãËΩΩÁîüÊàêÁöÑÂõæÂÉèÂà∞Êú¨Âú∞Êñá‰ª∂\n  - `generate_text`: ‰ΩøÁî®Pollinations.aiÁîüÊàêÊñáÊú¨\n- Âü∫‰∫éTypeScriptÂÆûÁé∞ÔºåÊîØÊåÅÁ±ªÂûãÂÆâÂÖ®\n- ‰ΩøÁî®stdio‰º†ËæìÊú∫Âà∂Ôºå‰æø‰∫é‰∏éAIÊ®°ÂûãÈõÜÊàê\n\n## ÂÆâË£Ö\n\n1. ÂÖãÈöÜ‰ªìÂ∫ìÔºö\n\n```bash\ngit clone https://github.com/bendusy/pollinations-mcp.git\ncd pollinations-mcp\n```\n\n2. ÂÆâË£Ö‰æùËµñÔºö\n\n```bash\nnpm install\n```\n\n3. ÊûÑÂª∫È°πÁõÆÔºö\n\n```bash\nnpm run build\n```\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\n### ‰Ωú‰∏∫MCPÊúçÂä°Âô®ËøêË°å\n\n```bash\nnpm start\n```\n\nÊúçÂä°Âô®Â∞ÜÈÄöËøáÊ†áÂáÜËæìÂÖ•/ËæìÂá∫(stdio)ÂêØÂä®ÔºåÁ≠âÂæÖMCPÂÆ¢Êà∑Á´ØËøûÊé•„ÄÇ\n\n### Âú®Cursor‰∏≠‰ΩøÁî®ÔºàÂΩìÂâçÂèØËÉΩÊó†Ê≥ïÊ≠£Â∏∏Â∑•‰ΩúÔºâ\n\n**Ê≥®ÊÑèÔºö** ÁõÆÂâçÂú®Cursor‰∏≠ÈÖçÁΩÆÊ≠§ÊúçÂä°Âô®ÂèØËÉΩ‰∏ç‰ºöÊàêÂäü„ÄÇÂ¶ÇÊûúÊÇ®ÈúÄË¶Å‰ΩøÁî®Ê≠§ÂäüËÉΩÔºåÂª∫ËÆÆ‰ΩøÁî®ClineÔºàËßÅ‰∏ãÊñáÔºâ„ÄÇ\n\n### Âú®Cline‰∏≠‰ΩøÁî®ÔºàÊé®ËçêÔºâ\n\n[Cline](https://cline.app)ÊòØ‰∏Ä‰∏™ÊîØÊåÅMCPÂçèËÆÆÁöÑAIÁªàÁ´ØÔºåÂèØ‰ª•ÊàêÂäü‰ΩøÁî®Êú¨ÊúçÂä°Âô®Êèê‰æõÁöÑÂõæÂÉèÁîüÊàêÂäüËÉΩ„ÄÇËÆæÁΩÆÊ≠•È™§Â¶Ç‰∏ãÔºö\n\n1. ÂÆâË£ÖÂπ∂ÂêØÂä®Cline\n2. ÊâìÂºÄClineÁöÑËÆæÁΩÆÊñá‰ª∂ÔºåÈÄöÂ∏∏‰Ωç‰∫éÔºö\n   - Windows: `%APPDATA%\\Cline\\config.json`\n   - Mac: `~/Library/Application Support/Cline/config.json`\n   - Linux: `~/.config/Cline/config.json`\n\n3. Âú®ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÊâæÂà∞ÊàñÊ∑ªÂä†`mcpServers`ÈÉ®ÂàÜÔºåÁÑ∂ÂêéÊ∑ªÂä†‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n```json\n\"mcpServers\": {\n  \"pollinations-mcp\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"ÂÆåÊï¥Ë∑ØÂæÑ/Âà∞ÊÇ®ÁöÑ/pollinations-mcp/dist/index.js\"\n    ],\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"download_image\",\n      \"generate_image\",\n      \"generate_text\"\n    ]\n  }\n}\n```\n\n‰æãÂ¶ÇÔºåWindowsÁ≥ªÁªü‰∏äÁöÑÂÆåÊï¥ÈÖçÁΩÆÂèØËÉΩÂ¶Ç‰∏ãÔºö\n\n```json\n\"mcpServers\": {\n  \"pollinations-mcp\": {\n    \"command\": \"node\",\n    \"args\": [\n      \"C:\\\\Users\\\\Áî®Êà∑Âêç\\\\Ë∑ØÂæÑ\\\\Âà∞\\\\pollinations-mcp\\\\dist\\\\index.js\"\n    ],\n    \"disabled\": false,\n    \"autoApprove\": [\n      \"download_image\",\n      \"generate_image\",\n      \"generate_text\"\n    ]\n  }\n}\n```\n\n4. ‰øùÂ≠òÈÖçÁΩÆÊñá‰ª∂Âπ∂ÈáçÂêØCline\n5. Áé∞Âú®ÊÇ®ÂèØ‰ª•Âú®Cline‰∏≠‰ΩøÁî®PollinationsÂõæÂÉèÁîüÊàêÂäüËÉΩ‰∫ÜÔºå‰æãÂ¶ÇÔºö\n\n```\n‰ΩøÁî®PollinationsÁîüÊàêÂõæÂÉèÔºöbeautiful sunset over ocean with palm trees\n```\n\n### ‰∏éAIÊ®°ÂûãÈõÜÊàê\n\nÊú¨ÊúçÂä°Âô®ËÆæËÆ°Áî®‰∫é‰∏éÊîØÊåÅMCPÂçèËÆÆÁöÑAIÊ®°ÂûãÈõÜÊàêÔºå‰ΩøÂÖ∂ËÉΩÂ§üÁîüÊàêÂõæÂÉè„ÄÇ\n\n### ÊîØÊåÅÁöÑÂ∑•ÂÖ∑\n\n#### generate_image\n\n‰ΩøÁî®Pollinations.aiÁîüÊàêÂõæÂÉèÂπ∂ËøîÂõûURL„ÄÇ\n\nÂèÇÊï∞Ôºö\n- `prompt` (ÂøÖÈúÄ): ÂõæÂÉèÊèèËø∞ÊèêÁ§∫ËØç\n- `width` (ÂèØÈÄâ): ÂõæÂÉèÂÆΩÂ∫¶ÔºàÂÉèÁ¥†ÔºâÔºåÈªòËÆ§‰∏∫1024\n- `height` (ÂèØÈÄâ): ÂõæÂÉèÈ´òÂ∫¶ÔºàÂÉèÁ¥†ÔºâÔºåÈªòËÆ§‰∏∫1024\n- `seed` (ÂèØÈÄâ): ÈöèÊú∫ÁßçÂ≠êÂÄºÔºàÁî®‰∫éÁîüÊàê‰∏ÄËá¥ÁöÑÂõæÂÉèÔºâ\n- `model` (ÂèØÈÄâ): Ë¶Å‰ΩøÁî®ÁöÑÊ®°ÂûãÔºåÈªòËÆ§‰∏∫'flux'\n- `nologo` (ÂèØÈÄâ): ËÆæÁΩÆ‰∏∫trueÂèØÂéªÈô§Ê∞¥Âç∞ÔºåÈªòËÆ§‰∏∫true\n- `enhance` (ÂèØÈÄâ): ÊèêÈ´òÂõæÂÉèË¥®ÈáèÔºàÂ∫îÁî®Â¢ûÂº∫Êª§ÈïúÔºâÔºåÈªòËÆ§‰∏∫false\n- `safe` (ÂèØÈÄâ): ÂêØÁî®ÂÆâÂÖ®ËøáÊª§ÔºàËøáÊª§‰∏çÈÄÇÂÜÖÂÆπÔºâÔºåÈªòËÆ§‰∏∫false\n- `private` (ÂèØÈÄâ): ËÆæÁΩÆ‰∏∫trueÂèØ‰ΩøÂõæÂÉèÁßÅÊúâÔºà‰∏çÂú®ÂÖ¨ÂÖ±feed‰∏≠ÊòæÁ§∫ÔºâÔºåÈªòËÆ§‰∏∫false\n\n**ÊèêÁ§∫ËØçÊúÄ‰Ω≥ÂÆûË∑µÔºö**\n- Â∞ΩÈáè‰ΩøÁî®Ëã±ÊñáÁºñÂÜôÊèêÁ§∫ËØçÔºåPollinations.aiÂØπËã±ÊñáÁöÑÁêÜËß£Êõ¥Â•Ω\n- ‰øùÊåÅÊèêÁ§∫ËØçÁÆÄÁü≠Á≤æÁ°ÆÔºåÈÅøÂÖçËøáÈïøÊàñÊ®°Á≥äÁöÑÊèèËø∞\n- ‰ΩøÁî®ÂÖ∑‰ΩìÁöÑÂΩ¢ÂÆπËØçÂíåÂêçËØçÔºåËÄåÈùûÊäΩË±°Ê¶ÇÂøµ\n- ‰æãÂ¶ÇÔºö\"beautiful sunset over ocean with palm trees\"ÊØî\"‰∏ÄÂº†Êó•ËêΩÁöÑÂõæÁâá\"ÊïàÊûúÊõ¥Â•Ω\n\n#### download_image\n\n‰∏ãËΩΩPollinations.aiÁîüÊàêÁöÑÂõæÂÉèÂà∞Êú¨Âú∞Êñá‰ª∂„ÄÇ\n\nÂèÇÊï∞Ôºö\n- `url` (ÂøÖÈúÄ): Ë¶Å‰∏ãËΩΩÁöÑÂõæÂÉèURL\n- `output_path` (ÂèØÈÄâ): ‰øùÂ≠òÂõæÂÉèÁöÑË∑ØÂæÑÔºàÂåÖÊã¨Êñá‰ª∂ÂêçÔºâÔºåÈªòËÆ§‰∏∫'image.jpg'\n\n#### generate_text\n\n‰ΩøÁî®Pollinations.aiÁîüÊàêÊñáÊú¨„ÄÇ\n\nÂèÇÊï∞Ôºö\n- `prompt` (ÂøÖÈúÄ): ÊñáÊú¨ÊèêÁ§∫ËØç\n- `model` (ÂèØÈÄâ): Ë¶Å‰ΩøÁî®ÁöÑÊ®°ÂûãÔºàÂ¶Çopenai„ÄÅmistralÁ≠âÔºâÔºåÈªòËÆ§‰∏∫'openai'\n- `seed` (ÂèØÈÄâ): ÈöèÊú∫ÁßçÂ≠êÂÄºÔºàÁî®‰∫éÁîüÊàê‰∏ÄËá¥ÁöÑÁªìÊûúÔºâ\n- `system` (ÂèØÈÄâ): Á≥ªÁªüÊèêÁ§∫ËØçÔºàËÆæÁΩÆAIË°å‰∏∫Ôºâ\n- `json` (ÂèØÈÄâ): ÊòØÂê¶ËøîÂõûJSONÊ†ºÂºèÁöÑÂìçÂ∫îÔºåÈªòËÆ§‰∏∫false\n- `private` (ÂèØÈÄâ): ËÆæÁΩÆ‰∏∫trueÂèØ‰ΩøÂìçÂ∫îÁßÅÊúâÔºåÈªòËÆ§‰∏∫false\n\n## APIÂèÇËÄÉ\n\nÊú¨È°πÁõÆ‰ΩøÁî®Pollinations.aiÁöÑÂÆòÊñπAPI„ÄÇÂÆåÊï¥ÁöÑAPIÊñáÊ°£ËØ∑ÂèÇËÄÉÔºö[Pollinations APIÊñáÊ°£](https://github.com/pollinations/pollinations/blob/master/APIDOCS.md)\n\n### ÂõæÂÉèÁîüÊàêAPI\n\nÂü∫Êú¨Ê†ºÂºèÔºö`https://image.pollinations.ai/prompt/{prompt}?{ÂèÇÊï∞}`\n\nÁ§∫‰æãÔºö\n```\nhttps://image.pollinations.ai/prompt/beautiful%20sunset?width=1024\u0026height=1024\u0026nologo=true\n```\n\n### ÂèØÁî®ÁöÑÂõæÂÉèÊ®°Âûã\n\n- `flux` (ÈªòËÆ§): ‰∏ªÊµÅÊñáÁîüÂõæÊ®°ÂûãÔºåÂäüËÉΩÂÖ®Èù¢\n- `variation`: ÂõæÂÉèÂèò‰ΩìÁîüÊàê\n- `dreamshaper`: Ê¢¶ÂπªÈ£éÊ†º\n- `anything`: Âä®Êº´È£éÊ†ºÂõæÂÉè\n- `pixart`: È´òË¥®ÈáèÊèíÂõæÈ£éÊ†º\n\n### ÊñáÊú¨ÁîüÊàêAPI\n\nÂü∫Êú¨Ê†ºÂºèÔºö`https://text.pollinations.ai/{prompt}?{ÂèÇÊï∞}`\n\nÁ§∫‰æãÔºö\n```\nhttps://text.pollinations.ai/Tell%20me%20about%20artificial%20intelligence?model=openai\n```\n\n### ÂèØÁî®ÁöÑÊñáÊú¨Ê®°Âûã\n\n- `openai` (ÈªòËÆ§): OpenAIÊ®°Âûã\n- `mistral`: MistralÊ®°Âûã\n- `gemini`: Google GeminiÊ®°Âûã\n\n## ÂºÄÂèë\n\n### È°πÁõÆÁªìÊûÑ\n\n- `src/index.ts`: ‰∏ªÊúçÂä°Âô®ÂÆûÁé∞\n- `dist/`: ÁºñËØëÂêéÁöÑJavaScriptÊñá‰ª∂\n- `package.json`: È°πÁõÆÈÖçÁΩÆÂíå‰æùËµñ\n\n### ‰æùËµñ\n\n- `@modelcontextprotocol/sdk`: MCPÂçèËÆÆSDK\n- `axios`: HTTPÂÆ¢Êà∑Á´ØÔºåÁî®‰∫é‰∏ãËΩΩÂõæÂÉè\n- `typescript`: TypeScriptÁºñËØëÂô®\n\n## ËÆ∏ÂèØ\n\nÊú¨È°πÁõÆÈááÁî®ISCËÆ∏ÂèØËØÅ„ÄÇËØ¶ÊÉÖËØ∑ÂèÇÈòÖ[LICENSE](LICENSE)Êñá‰ª∂„ÄÇ\n\n## Áõ∏ÂÖ≥ÈìæÊé•\n\n- [Pollinations.ai](https://pollinations.ai)\n- [Model Context Protocol](https://github.com/microsoft/modelcontextprotocol)",
      "stars": 8,
      "updated_at": "2025-09-04T11:40:45Z",
      "url": "https://github.com/bendusy/pollinations-mcp"
    },
    "beordle--tinypng-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Compress images efficiently using the TinyPNG API. Supports both local and remote image compression with minimal setup required.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/beordle.webp",
      "keywords": [
        "tinypng",
        "compression",
        "compress",
        "compress images",
        "tinypng mcp",
        "beordle tinypng"
      ],
      "language": "",
      "license": "Apache License 2.0",
      "name": "tinypng-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "beordle",
      "readme_content": "## MCP server for TinyPNG\n\n### Usage\n\n### Use `bun` or `node` to run the server\n\n1. Install dependencies and build\n\n```bash\npnpm i\npnpm build\n```\n\n2. Edit the `mcp.json` file\n\n```json\n{\n  \"mcpServers\": {\n    \"tinypng\": {\n      \"command\": \"bun\", // or \"node\"\n      \"args\": [\"/path/to/tinypng-mcp-server/src/index.ts\"], // or \"dist/index.js\"\n      \"env\": {\n        \"TINYPNG_API_KEY\": \"your-tinypng-api-key\"\n      }\n    }\n  }\n}\n```\n\n### Tools\n\n1. Compress local image\n\n```js\n{\n  name: 'compress_local_image',\n  description: 'Compress a local image file',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imagePath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to the image file to compress',\n        example: '/Users/user/Downloads/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imagePath'],\n  },\n}\n```\n\n2. Compress remote image\n\n```js\n{\n  name: 'compress_remote_image',\n  description: 'Compress a remote image file by giving the URL of the image',\n  inputSchema: {\n    type: 'object',\n    properties: {\n      imageUrl: {\n        type: 'string',\n        description: 'The URL of the image file to compress',\n        example: 'https://example.com/image.jpg',\n      },\n      outputPath: {\n        type: 'string',\n        description: 'The ABSOLUTE path to save the compressed image file',\n        example: '/Users/user/Downloads/image_compressed.jpg',\n      },\n      outputFormat: {\n        type: 'string',\n        description: 'The format to save the compressed image file',\n        enum: SUPPORTED_IMAGE_TYPES,\n        example: 'image/jpeg',\n      },\n    },\n    required: ['imageUrl'],\n  },\n}\n```\n",
      "stars": 0,
      "updated_at": "2025-03-31T16:01:05Z",
      "url": "https://github.com/beordle/tinypng-mcp-server"
    },
    "bitscorp-mcp--mcp-ffmpeg": {
      "category": "image-and-video-generation",
      "description": "Manipulate video files by resizing them to various resolutions and extracting audio in multiple formats. Interact with video processing capabilities using natural language requests via API calls.",
      "forks": 13,
      "imageUrl": "/freedevtools/mcp/pfp/bitscorp-mcp.webp",
      "keywords": [
        "ffmpeg",
        "audio",
        "formats",
        "mcp ffmpeg",
        "video generation",
        "video processing"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "mcp-ffmpeg",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "bitscorp-mcp",
      "readme_content": "# MCP FFmpeg Video Processor\n[![smithery badge](https://smithery.ai/badge/@bitscorp-mcp/mcp-ffmpeg)](https://smithery.ai/server/@bitscorp-mcp/mcp-ffmpeg)\n\nA Node.js server that uses FFmpeg to manipulate video files. This server provides APIs to:\n\n- Resize videos to different resolutions (360p, 480p, 720p, 1080p)\n- Extract audio from videos in various formats (MP3, AAC, WAV, OGG)\n\n## Prerequisites\n\nBefore running this application, you need to have the following installed:\n\n1. **Node.js** (v14 or higher)\n2. **FFmpeg** - This is required for video processing\n\n### Installing FFmpeg\n\n#### On macOS:\n```bash\nbrew install ffmpeg\n```\n\n#### On Ubuntu/Debian:\n```bash\nsudo apt update\nsudo apt install ffmpeg\n```\n\n#### On Windows:\n1. Download FFmpeg from the [official website](https://ffmpeg.org/download.html)\n2. Extract the files to a folder (e.g., `C:\\ffmpeg`)\n3. Add the `bin` folder to your PATH environment variable\n\n## Installation\n\n1. Clone this repository:\n```bash\ngit clone https://github.com/bitscorp-mcp/mcp-ffmpeg.git\ncd mcp-ffmpeg\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n### Installing via Smithery\n\nTo install mcp-ffmpeg for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@bitscorp-mcp/mcp-ffmpeg):\n\n```bash\nnpx -y @smithery/cli install @bitscorp-mcp/mcp-ffmpeg --client claude\n```\n\n## Running the Server\n\nStart the server with:\n\n```bash\nnpm start\n```\n\nFor development with auto-restart on file changes:\n\n```bash\nnpm run dev\n```\n\n### Installing via Smithery\n\nTo install mcp-ffmpeg for Claude Desktop automatically via [Smithery](https://smithery.ai/server/bitscorp-mcp/mcp-ffmpeg):\n\n```bash\nnpx -y @smithery/cli install @bitscorp-mcp/mcp-ffmpeg --client claude\n```\n\nTo install mcp-ffmpeg for Cursor, go to Settings -\u003e Cursor Settings -\u003e Features -\u003e MCP Servers -\u003e + Add\n\nSelect Type: command and paste the below, using your API key from Adjust\n```\nnpx -y @smithery/cli@latest run @bitscorp/mcp-ffmpeg\n```\n\n## Using with Claude Desktop\n\nThis MCP FFmpeg server can be integrated with Claude Desktop to process videos through natural language requests.\n\n### Running with npx\n\nYou can run the server directly with npx:\n\n```bash\nnpx /path/to/mcp-ffmpeg\n```\n\nOr if you've published the package to npm:\n\n```bash\nnpx mcp-ffmpeg\n```\n\n### Configuring Claude Desktop\n\nTo add this server to Claude Desktop, update your Claude Desktop configuration file:\n\n1. Locate your Claude Desktop config file:\n   - macOS: `~/.config/claude-desktop/config.json` or `~/Library/Application Support/Claude Desktop/config.json`\n   - Windows: `%APPDATA%\\Claude Desktop\\config.json`\n   - Linux: `~/.config/claude-desktop/config.json`\n\n2. Add the FFmpeg MCP server to the `mcpServers` section:\n\n```json\n{\n    \"mcpServers\": {\n        \"ffmpeg\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"--yes\",\n                \"/absolute/path/to/mcp-ffmpeg\"\n            ]\n        }\n    }\n}\n```\n\nIf you've published the package to npm:\n\n```json\n{\n    \"mcpServers\": {\n        \"ffmpeg\": {\n            \"command\": \"npx\",\n            \"args\": [\n                \"--yes\",\n                \"mcp-ffmpeg\"\n            ]\n        }\n    }\n}\n```\n\n3. Restart Claude Desktop for the changes to take effect.\n\n### Example Prompts for Claude\n\nOnce configured, you can use prompts like:\n\n```\nUsing the ffmpeg MCP server, please resize the video at /path/to/video.mp4 to 720p resolution.\n```\n\n## Notes\n\n- Uploaded videos are stored temporarily in the `uploads` directory\n- Processed videos and audio files are stored in the `output` directory\n- The server has a file size limit of 500MB for uploads\n\n## License\n\nMIT\n",
      "stars": 35,
      "updated_at": "2025-09-28T04:42:34Z",
      "url": "https://github.com/bitscorp-mcp/mcp-ffmpeg"
    },
    "bobtista--luma-ai-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Integrates with Luma AI's Dream Machine API to facilitate the generation and manipulation of AI-generated videos and images. Offers tools for text-to-video generation, image processing, and audio integration to enhance creative projects.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/bobtista.webp",
      "keywords": [
        "luma",
        "ai",
        "bobtista",
        "ai dream",
        "dream machine",
        "luma ai"
      ],
      "language": "Python",
      "license": "No License",
      "name": "luma-ai-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "bobtista",
      "readme_content": "# Luma AI MCP Server üé•\n\nA Model Context Protocol server for Luma AI's Dream Machine API.\n\n## Overview\n\nThis MCP server integrates with Luma AI's Dream Machine API (v1) to provide tools for generating, managing, and manipulating AI-generated videos and images via Large Language Models. It implements the Model Context Protocol (MCP) to enable seamless interaction between AI assistants and Luma's creative tools.\n\n## Features ‚ú®\n\n- Text-to-video generation\n- Advanced video generation with keyframes\n- Image-to-video conversion\n- Video extension and interpolation\n- Image generation with reference images\n- Audio addition to videos\n- Video upscaling\n- Credit management\n- Generation tracking and status checking\n\n## Tools üõ†Ô∏è\n\n1. `ping`\n\n   - Check if the Luma API is running\n   - No parameters required\n\n2. `create_generation`\n\n   - Creates a new video generation\n   - Input:\n     - `prompt` (string, required): Text description of the video to generate\n     - `model` (string, optional): Model to use (default: \"ray-2\")\n       - Available models: \"ray-1-6\", \"ray-2\", \"ray-flash-2\"\n     - `resolution` (string, optional): Video resolution (choices: \"540p\", \"720p\", \"1080p\", \"4k\")\n     - `duration` (string, optional): Video duration (only \"5s\" and \"9s\" are currently supported)\n     - `aspect_ratio` (string, optional): Video aspect ratio (e.g., \"16:9\", \"1:1\", \"9:16\", \"4:3\", \"3:4\", \"21:9\", \"9:21\")\n     - `loop` (boolean, optional): Whether to make the video loop\n     - `keyframes` (object, optional): Start and end frames for advanced video generation:\n       - `frame0` and/or `frame1` with either:\n         - `{\"type\": \"image\", \"url\": \"image_url\"}` for image keyframes\n         - `{\"type\": \"generation\", \"id\": \"generation_id\"}` for video keyframes\n\n3. `get_generation`\n\n   - Gets the status of a generation\n   - Input:\n     - `generation_id` (string, required): ID of the generation to check\n   - Output includes:\n     - Generation ID\n     - State (queued, dreaming, completed, failed)\n     - Failure reason (if failed)\n     - Video URL (if completed)\n\n4. `list_generations`\n\n   - Lists all generations\n   - Input:\n     - `limit` (number, optional): Maximum number of generations to return (default: 10)\n     - `offset` (number, optional): Number of generations to skip\n\n5. `delete_generation`\n\n   - Deletes a generation\n   - Input:\n     - `generation_id` (string, required): ID of the generation to delete\n\n6. `upscale_generation`\n\n   - Upscales a video generation to higher resolution\n   - Input:\n     - `generation_id` (string, required): ID of the generation to upscale\n     - `resolution` (string, required): Target resolution for the upscaled video (one of \"540p\", \"720p\", \"1080p\", or \"4k\")\n   - Note:\n     - The generation must be in a completed state to be upscaled\n     - The target resolution must be higher than the original generation's resolution\n     - Each generation can only be upscaled once\n\n7. `add_audio`\n\n   - Adds AI-generated audio to a video generation\n   - Input:\n     - `generation_id` (required): The ID of the generation to add audio to\n     - `prompt` (required): The prompt for the audio generation\n     - `negative_prompt` (optional): The negative prompt for the audio generation\n     - `callback_url` (optional): URL to notify when the audio processing is complete\n\n8. `generate_image`\n\n   - Generates an image from a text prompt with optional reference images\n   - Input:\n     - `prompt` (string, required): Text description of the image to generate\n     - `model` (string, optional): Model to use for image generation (default: \"photon-1\")\n       - Available models: \"photon-1\", \"photon-flash-1\"\n     - `aspect_ratio` (string, optional): Image aspect ratio (same options as video)\n     - `image_ref` (array, optional): Reference images to guide generation\n       - Each ref: `{\"url\": \"image_url\", \"weight\": optional_float}`\n     - `style_ref` (array, optional): Style reference images\n       - Each ref: `{\"url\": \"image_url\", \"weight\": optional_float}`\n     - `character_ref` (object, optional): Character reference images\n       - Format: `{\"identity_name\": {\"images\": [\"url1\", \"url2\", ...]}}`\n     - `modify_image_ref` (object, optional): Image to modify\n       - Format: `{\"url\": \"image_url\", \"weight\": optional_float}`\n\n9. `get_credits`\n\n   - Gets credit information for the current user\n   - No parameters required\n   - Returns available credit balance in USD cents\n\n10. `get_camera_motions`\n    - Gets all supported camera motions\n    - No parameters required\n    - Returns: List of available camera motion strings\n\n## Setup for Claude Desktop üñ•Ô∏è\n\n1. Get your Luma API key from [Luma AI](https://lumalabs.ai) (sign up or log in to get your API key)\n\n2. Add this to your Claude Desktop configuration file:\n\n   - On macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - On Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"luma\": {\n         \"command\": \"uv\",\n         \"args\": [\n           \"run\",\n           \"--project\",\n           \"/path/to/your/luma-ai-mcp-server\",\n           \"-m\",\n           \"luma_ai_mcp_server\"\n         ],\n         \"env\": {\n           \"LUMA_API_KEY\": \"your-luma-api-key-here\"\n         }\n       }\n     }\n   }\n   ```\n\n   Replace:\n\n   - `/path/to/your/luma-ai-mcp-server` with the actual path to your server directory\n   - `your-luma-api-key-here` with your actual Luma API key\n\n3. Restart Claude Desktop\n\n4. That's it! You can now use Luma AI tools directly in Claude Desktop conversations.\n\n## Quick Troubleshooting üõ†Ô∏è\n\nIf you're having issues:\n\n1. Check your API key is correct\n2. Make sure the path to the server is correct\n3. View logs with: `tail -n 20 -f ~/Library/Logs/Claude/mcp*.log`\n\n## Advanced Video Generation Types üé¨\n\nThe Luma API supports various types of advanced video generation through keyframes:\n\n1. **Starting from an image**: Provide `frame0` with `type: \"image\"` and an image URL\n2. **Ending with an image**: Provide `frame1` with `type: \"image\"` and an image URL\n3. **Extending a video**: Provide `frame0` with `type: \"generation\"` and a generation ID\n4. **Reverse extending a video**: Provide `frame1` with `type: \"generation\"` and a generation ID\n5. **Interpolating between videos**: Provide both `frame0` and `frame1` with `type: \"generation\"` and generation IDs\n\n## API Limitations and Notes üìù\n\n- **Duration**: Currently, the API only supports durations of \"5s\" or \"9s\"\n- **Resolution**: Valid values are \"540p\", \"720p\", \"1080p\", and \"4k\"\n- **Models**:\n  - Video generation:\n    - \"ray-2\" (default) - Best quality, slower\n    - \"ray-flash-2\" - Faster generation\n    - \"ray-1-6\" - Legacy model\n  - Image generation:\n    - \"photon-1\" (default) - Best quality, slower\n    - \"photon-flash-1\" - Faster generation\n- **Generation types**: Video, image, and advanced (with keyframes)\n- **Aspect Ratios**: \"1:1\" (square), \"16:9\" (landscape), \"9:16\" (portrait), \"4:3\" (standard), \"3:4\" (standard portrait), \"21:9\" (ultrawide), \"9:21\" (ultrawide portrait)\n- **States**: \"queued\", \"dreaming\", \"completed\", \"failed\"\n- **Upscaling**:\n  - Video generations can only be upscaled when they're in a \"complete\" state\n  - Target resolution must be higher than the original generation's resolution\n  - Each generation can only be upscaled once\n- **API Key**: Required in environment variables\n- **API Version**: Uses Dream Machine API v1\n\n## License üìÑ\n\nMIT\n",
      "stars": 3,
      "updated_at": "2025-07-23T00:09:33Z",
      "url": "https://github.com/bobtista/luma-ai-mcp-server"
    },
    "breezedeus--CnOCR": {
      "category": "image-and-video-generation",
      "description": "A comprehensive Python toolkit engineered for robust Optical Character Recognition (OCR) across Chinese scripts, the Latin alphabet, and numerical sequences. It facilitates utilization of pre-trained recognition systems or supports user-defined model calibration, delivering advanced text extraction capabilities for diverse computational vision pipelines.",
      "forks": 528,
      "imageUrl": "/freedevtools/mcp/pfp/breezedeus.webp",
      "keywords": [
        "cnocr",
        "recognition",
        "text",
        "character recognition",
        "text recognition",
        "recognition chinese"
      ],
      "language": "Python",
      "license": "Apache License 2.0",
      "name": "CnOCR-TextExtractor",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "breezedeus",
      "readme_content": "\u003cdiv align=\"center\"\u003e\n  \n  \u003cdiv\u003e\u0026nbsp;\u003c/div\u003e\n\n[![Discord](https://img.shields.io/discord/1200765964434821260?label=Discord)](https://discord.gg/GgD87WM8Tf) \n[![Downloads](https://static.pepy.tech/personalized-badge/cnocr?period=total\u0026units=international_system\u0026left_color=grey\u0026right_color=orange\u0026left_text=Downloads)](https://pepy.tech/project/cnocr) \n[](https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2Fbreezedeus%2FCnOCR) \n[![license](https://img.shields.io/github/license/breezedeus/cnocr)](./LICENSE) \n[![Docs](https://readthedocs.org/projects/cnocr/badge/?version=latest)](https://cnocr.readthedocs.io/zh-cn/stable/?badge=latest) \n[![PyPI version](https://badge.fury.io/py/cnocr.svg)](https://badge.fury.io/py/cnocr) \n[![forks](https://img.shields.io/github/forks/breezedeus/cnocr)](https://github.com/breezedeus/cnocr) \n[![stars](https://img.shields.io/github/stars/breezedeus/cnocr)](https://github.com/breezedeus/cnocr) \n![last-releast](https://img.shields.io/github/release-date/breezedeus/cnocr) \n![last-commit](https://img.shields.io/github/last-commit/breezedeus/cnocr) \n[![Twitter](https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fbreezedeus)](https://twitter.com/breezedeus)\n\n[üìñ ÂèÇÈòÖÊñáÊ°£](https://cnocr.readthedocs.io/zh-cn/stable/) | \n[üõ†Ô∏è ÂÆâË£ÖÊåáÂçó](https://cnocr.readthedocs.io/zh-cn/stable/install/) | \n[üß≥ ÂèØÁî®Ê®°ÂûãÊ∏ÖÂçï](https://cnocr.readthedocs.io/zh-cn/stable/models/) | \n[üïπ Ê®°ÂûãËÆ≠ÁªÉÊµÅÁ®ã](https://cnocr.readthedocs.io/zh-cn/stable/train/) | \n[üõÄüèª Âú®Á∫øÊºîÁ§∫Á©∫Èó¥](https://huggingface.co/spaces/breezedeus/CnOCR-Demo) | \n[üí¨ ‰∫§ÊµÅÁ§æÂå∫](https://www.breezedeus.com/article/join-group)\n\n\u003c/div\u003e\n\n\u003cdiv align=\"center\"\u003e\n\n[English Documentation](./README_en.md) | ‰∏≠Êñá\n\n\u003c/div\u003e\n\n# CnOCR - Character Recognition Toolkit\n\n\u003cdiv align=\"center\"\u003e\n\u003cstrong\u003eÊäÄÊúØÂ∫îÊúçÂä°‰∫éÂ§ß‰ºóÔºåËÄåÈùûÊùüÁºö‰πãÔºÅ\u003c/strong\u003e\n\u003cbr\u003e\n\u003cstrong\u003e‰∏•Á¶ÅÊª•Áî®Êú¨È°πÁõÆ‰∫éÂÜÖÂÆπÂÆ°Êü•ÁõÆÁöÑÔºÅ\u003c/strong\u003e\n\u003cbr\u003e\n---\n\u003c/div\u003e\n\n### 2025.06.26 ÁâàÊú¨Êõ¥Êñ∞ÔºöÂèëÂ∏É V2.3.2\n\nÂÖ≥ÈîÆËø≠‰ª£ÂÜÖÂÆπÔºö\n\n* Êï¥Âêà‰∫ÜÊúÄÊñ∞ÁöÑ PPOCRv5 ËØÜÂà´ÂºïÊìé\n  * Êñ∞Â¢û‰∫ÜÂØπ PP-OCRv5 ËØÜÂà´Ê®°ÂûãÁöÑÂÖºÂÆπÊÄßÊîØÊåÅÔºö`ch_PP-OCRv5` Âíå `ch_PP-OCRv5_server` Ê®°ÂûãÁöÑÂºïÂÖ•\n\n\n### [2024.11.30 ÁâàÊú¨Êõ¥Êñ∞]ÔºöÂèëÂ∏É V2.3.1\n\n‰∏ªË¶ÅÂèëÂ∏ÉËØ¥ÊòéÔºö\n\n* ÂÄüÁî± RapidOCR Ê°ÜÊû∂ÔºåÊï¥Âêà‰∫ÜÂΩì‰∏ãÊúÄÊñ∞ÁöÑ PPOCRv4 ËØÜÂà´ÂºïÊìéÔºåÊûÅÂ§ßÂú∞ÊãìÂÆΩ‰∫ÜÊ®°ÂûãÈÄâÊã©ËåÉÂõ¥\n  * ÂºïÂÖ•‰∫ÜÂØπ PP-OCRv4 ËØÜÂà´Ê®°ÂûãÁöÑÊîØÊåÅÔºåÂåÖÂê´Ê†áÂáÜÁâà‰∏éÊúçÂä°Âô®ÈÉ®ÁΩ≤ÁâàÊú¨\n* ‰ºòÂåñ‰∫ÜÊñá‰ª∂ËØªÂèñÈÄªËæëÔºåÁé∞Â∑≤ÂÆåÂÖ®ÂÖºÂÆπ Windows Á≥ªÁªü‰∏ãÁöÑ‰∏≠ÊñáÊñá‰ª∂Ë∑ØÂæÑËÆøÈóÆ\n* Áº∫Èô∑‰øÆÂ§çÔºöËß£ÂÜ≥‰∫ÜÂ§öËøõÁ®ãÁéØÂ¢É‰∏ã `transform_func` Êó†Ê≥ïËøõË°åÂ∫èÂàóÂåñÊìç‰ΩúÁöÑÈóÆÈ¢ò\n* Áº∫Èô∑‰øÆÂ§çÔºöÁ°Æ‰øù‰∫Ü‰∏é `albumentations=1.4.*` Â∫ìÁâàÊú¨ÁöÑËâØÂ•Ω‰∫íÊìç‰ΩúÊÄß\n\n\n### [2023.12.24 ÁâàÊú¨Êõ¥Êñ∞]ÔºöÂèëÂ∏É V2.3\n\nÊ†∏ÂøÉÂèòÂä®ÊëòË¶ÅÔºö\n\n* ÂÖ®Á≥ªÂàóÊ®°ÂûãÂùáÁªèËøáÈáçÊñ∞ËÆ≠ÁªÉ‰∏éÂæÆË∞ÉÔºåÊòæËëóÊèêÂçá‰∫ÜËØÜÂà´Á≤æÂ∫¶„ÄÇ\n* Ê†πÊçÆ‰∏çÂêåÁöÑÂ∫îÁî®Âú∫ÊôØÂØπÊ®°ÂûãËøõË°å‰∫ÜÁ≥ªÁªüÂåñÁöÑÂàÜÁ±ªÔºàËØ¶ËßÅ [ÂèØ‰ΩøÁî®ÁöÑËØÜÂà´Ê®°Âûã](#ÂèØ‰ΩøÁî®ÁöÑËØÜÂà´Ê®°Âûã) Á´†ËäÇÔºâÔºö\n  * `scene`ÔºöÈÄÇÁî®‰∫éËá™ÁÑ∂Âú∫ÊôØÂõæÂÉèÁöÑÊñáÊú¨ÊèêÂèñÔºåÊ®°ÂûãÂêçÁß∞ÈÄöÂ∏∏‰ª• `scene-` ‰∏∫ÂâçÁºÄÔºå‰æãÂ¶Ç `scene-densenet_lite_136-gru`„ÄÇ\n  * `doc`Ôºö‰∏ì‰∏∫ÁªìÊûÑÂåñÊñáÊ°£Êà™ÂõæÊàñÈ´òË¥®ÈáèÊâ´Êèè‰ª∂ËÆæËÆ°ÔºåÊ®°ÂûãÂêçÁß∞ÈÄöÂ∏∏‰ª• `doc-` ‰∏∫ÂâçÁºÄÔºå‰æãÂ¶Ç `doc-densenet_lite_136-gru`„ÄÇ\n  * `number`Ôºö**‰∏ìËÅåÊï∞Â≠óËØÜÂà´**Ôºà‰ªÖÈôê `0` Âà∞ `9`ÔºâÔºåÈÄÇÁî®‰∫éÈì∂Ë°åË¥¶Âè∑„ÄÅËØÅ‰ª∂Âè∑Á†ÅÁ≠âÁ≤æÁ°ÆÊï∞Â≠óÊèêÂèñÂú∫ÊôØ„ÄÇÊ®°ÂûãÂêçÁß∞ÈÄöÂ∏∏‰ª• `number-` ‰∏∫ÂâçÁºÄÔºå‰æãÂ¶Ç `number-densenet_lite_136-gru`„ÄÇ\n  * `general`: ÂØπÂ∫îÊó†ÊòéÊòæÂÄæÂêëÊÄßÁöÑÈÄöÁî®Âú∫ÊôØÔºåÊ®°ÂûãÂëΩÂêçÊ≤øË¢≠ÊóßÊúâËßÑËåÉÔºåÊó†ÁâπÂÆöÂâçÁºÄÔºå‰æãÂ¶Ç `densenet_lite_136-gru`„ÄÇ\n  \u003e ‚ö†Ô∏è ÁâπÂà´ÊèêÁ§∫Ôºö‰∏äËø∞Âú∫ÊôØÂàíÂàÜ‰ªÖ‰æõÂàùÊ≠•ÂèÇËÄÉÔºåÊúÄÁªàÊ®°ÂûãÈÄâÊã©Â∫î‰ª•Âú®ÁõÆÊ†áÂõæÂÉè‰∏äÁöÑÂÆûÈôÖËØÜÂà´Ë°®Áé∞‰∏∫ÂáÜ„ÄÇ\n* Êñ∞Â¢û‰∫Ü‰∏§ÁªÑÊõ¥Â§ßÂèÇÊï∞ÈáèÁöÑÊ®°ÂûãÁ≥ªÂàó‰ª•‰æõÈÄâÁî®Ôºö\n  * `*-densenet_lite_246-gru_base`ÔºöÂàùÊúü‰ªÖÂØπÁü•ËØÜÊòüÁêÉ [**CnOCR/CnSTDÁßÅ‰∫´Áæ§**](https://t.zsxq.com/FEYZRJQ) ËÆ¢ÈòÖËÄÖÂºÄÊîæÔºåÈ¢ÑËÆ°‰∏Ä‰∏™ÊúàÂêéÂ∞ÜÂÖ¨ÂºÄÂèëÂ∏É„ÄÇ\n  * `*-densenet_lite_666-gru_large`ÔºöPro Á≠âÁ∫ßÊ®°ÂûãÔºåÈúÄ‰ªòË¥πËß£ÈîÅ‰ΩøÁî®ÊùÉÈôê„ÄÇ\n  \nÊõ¥Â§öÊäÄÊúØÁªÜËäÇËØ∑Êü•ÈòÖÔºö[CnOCR V2.3 Ê≠£ÂºèÂèëÂ∏ÉÔºöÊ®°Âûã‰ºòÂåñ„ÄÅÂìÅÁ±ªÊâ©Â±ï„ÄÅÊÄßËÉΩÂçáÁ∫ß | Breezedeus.com](https://www.breezedeus.com/article/cnocr-v2.3-better-more)„ÄÇ\n\n\n\n[**CnOCR**](https://github.com/breezedeus/cnocr) ÊòØ‰∏Ä‰∏™Âü∫‰∫é **Python 3** ÁéØÂ¢ÉÁöÑÂÖàËøõ**ÊñáÊú¨ËØÜÂà´**Ôºà**Optical Character Recognition**ÔºåÁÆÄÁß∞**OCR**ÔºâËΩØ‰ª∂ÂåÖ„ÄÇÂÆÉÂéüÁîüÊîØÊåÅÂØπ**ÁÆÄ‰Ωì‰∏≠Êñá**„ÄÅ**ÈÉ®ÂàÜÁπÅ‰Ωì‰∏≠Êñá**„ÄÅ**Ëã±ÊñáÂ≠óÁ¨¶**Âèä**ÈòøÊãâ‰ºØÊï∞Â≠ó**ÁöÑÂ∏∏ËßÅÂ≠óÁ¨¶ËØÜÂà´ÔºåÂπ∂ÂÖ∑Â§áÂ§ÑÁêÜ**ÂûÇÁõ¥ÊéíÂàóÊñáÊú¨**ÁöÑËÉΩÂäõ„ÄÇÂ∑•ÂÖ∑ÂåÖÂÜÖÁΩÆ‰∫Ü**Ë∂ÖËøá20Áßç** [Â∑≤ËÆ≠ÁªÉÊ®°Âûã](https://cnocr.readthedocs.io/zh-cn/stable/models/)ÔºåÂºÄÁÆ±Âç≥Áî®ÔºåË¶ÜÁõñÂ§öÁßçÂ∫îÁî®ÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåCnOCR ‰πü‰∏∫Áî®Êà∑Êèê‰æõ‰∫ÜÁÆÄ‰æøÁöÑ[Ê®°ÂûãËÆ≠ÁªÉÊé•Âè£](https://cnocr.readthedocs.io/zh-cn/stable/train/)‰ª•ÂÆöÂà∂‰∏ìÂ±ûÊ®°Âûã„ÄÇÊ¨¢ËøéÊâ´Êèè‰∏ãÊñπ‰∫åÁª¥Á†ÅÊ∑ªÂä†Â∞èÂä©ÊâãÂæÆ‰ø°ÔºåËØ∑Â§áÊ≥® `ocr`ÔºåÂä©ÊâãÂ∞ÜÂÆöÊúüÈõÜ‰∏≠ÈÇÄËØ∑Âä†ÂÖ•‰∫§ÊµÅÁ§æÂå∫Ôºö\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"https://huggingface.co/datasets/breezedeus/cnocr-wx-qr-code/resolve/main/wx-qr-code.JPG\" alt=\"ÂæÆ‰ø°Áæ§‰∫åÁª¥Á†Å\" width=\"300px\"/\u003e\n\u003c/div\u003e\n\n\n‰ΩúËÄÖÂêåÊó∂ËøêËê•Áü•ËØÜÊòüÁêÉ [**CnOCR/CnSTDÁßÅ‰∫´Áæ§**](https://t.zsxq.com/FEYZRJQ)ÔºåÂú®Ê≠§Áæ§ÁªÑÂÜÖÊèêÈóÆÂèØ‰ª•Ëé∑Âæó‰ΩúËÄÖÊõ¥Âç≥Êó∂ÁöÑÂèçÈ¶àÂíåÊîØÊåÅÔºåËØöÈÇÄÊÇ®Âä†ÂÖ•„ÄÇ**Áü•ËØÜÊòüÁêÉ‰ºöÂëò** ‰∏ì‰∫´ÁâπÊùÉÂåÖÊã¨Ôºö\n\n- ÂÖçË¥πËé∑ÂèñÈÉ®ÂàÜ**Â∞öÊú™ÂÖ¨ÂºÄÁöÑ‰ªòË¥πÊ®°Âûã**ÁöÑ‰∏ãËΩΩÊùÉÈôêÔºõ\n- Ë¥≠‰π∞ÊâÄÊúâÂÖ∂‰ªñ‰ªòË¥πÊ®°ÂûãÁöÑ**ÂÖ´Êäò‰ºòÊÉ†**Ôºõ\n- ‰ΩúËÄÖÂØπ‰ΩøÁî®‰∏≠ÈÅáÂà∞ÁöÑÂõ∞ÈöæÊèê‰æõÂø´ÈÄüÂìçÂ∫îÊîØÊåÅÔºõ\n- ‰ΩúËÄÖÊØèÊúàÊèê‰æõ‰∏§Ê¨°ÈíàÂØπÁî®Êà∑ÁâπÂÆöÊï∞ÊçÆÁöÑ**ÂÖçË¥πÊ®°ÂûãËÆ≠ÁªÉÊúçÂä°**„ÄÇ\n- Áæ§ÂÜÖÂ∞ÜÊåÅÁª≠ÂàÜ‰∫´CnOCR/CnSTDÁõ∏ÂÖ≥ÁöÑÁã¨ÂÆ∂ÂÜÖÈÉ®ËµÑÊñôÔºõ\n- Áæ§ÂÜÖÂ∞ÜÊåÅÁª≠ÂèëÂ∏É OCR/STD/CV Á≠âÈ¢ÜÂüüÁöÑÊúÄÊñ∞ÂâçÊ≤øÁ†îÁ©∂ËµÑÊñô„ÄÇ\n\n\n\n## Ê∑±Â∫¶ÊäÄÊúØÊñáÊ°£\n\nÂèÇÈòÖ [CnOCR Âú®Á∫øÊñáÊ°£](https://cnocr.readthedocs.io/) ‰ª•Ëé∑ÂèñÂÆåÊï¥‰ø°ÊÅØ„ÄÇ\n\n## Êìç‰ΩúÊåáÂçó\n\nËá™ **V2.2** ÁâàÊú¨ÂèëÂ∏É‰ª•Êù•Ôºå**CnOCR** ÂÜÖÈÉ®Â∑≤Êó†ÁºùÈõÜÊàêÊñáÊú¨Ê£ÄÊµãÂºïÊìé **[CnSTD](https://github.com/breezedeus/cnstd)** ËøõË°åÂ≠óÁ¨¶ÁöÑÂÆö‰Ωç‰∏éÊ£ÄÊµã„ÄÇÂõ†Ê≠§Ôºå**CnOCR** V2.2 ÂèäÊõ¥È´òÁâàÊú¨‰∏ç‰ªÖËÉΩÂ§ÑÁêÜÁâàÈù¢ËßÑÊï¥ÁöÑÂç∞Âà∑‰ΩìÂõæÂÉèÔºàÂ¶ÇËΩØ‰ª∂Êà™Âõæ„ÄÅÊ∏ÖÊô∞Êâ´Êèè‰ª∂ÔºâÔºåËøòËÉΩÊúâÊïàËØÜÂà´**Ëá™ÁÑ∂Âú∫ÊôØÂõæÂÉè‰∏≠ÁöÑÊñáÊú¨**„ÄÇ\n\n‰ª•‰∏ãÊòØÈíàÂØπ‰∏çÂêåÂ∫îÁî®Âú∫ÊôØÁöÑË∞ÉÁî®Á§∫‰æã„ÄÇ\n\n\n\n## Âú∫ÊôØÂåñË∞ÉÁî®Á§∫‰æã\n\n### Â∏∏ËßÅÂõæÂÉèÊñáÊú¨ÊèêÂèñ\n\nÂàùÂßãÈò∂ÊÆµÔºåÊâÄÊúâÈÖçÁΩÆÂèÇÊï∞ÂùáÈááÁî®ÈªòËÆ§ÂÄºÂç≥ÂèØ„ÄÇËã•ËØÜÂà´Á≤æÂ∫¶‰∏çÂ∞Ω‰∫∫ÊÑèÔºåÂª∫ËÆÆÂ∞ùËØïË∞ÉÊï¥ÂêÑÈ°πÂèÇÊï∞ÔºåÈÄöÂ∏∏ËÉΩÊâæÂà∞ÊèêÂçáÁ≤æÂ∫¶ÁöÑÁêÜÊÉ≥ÈÖçÁΩÆ„ÄÇ\n\npython\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/huochepiao.jpeg'\noc = CnOcr()  # ÂÆû‰æãÂåñÊó∂‰ΩøÁî®ÊâÄÊúâÈªòËÆ§ÂèÇÊï∞\nout = oc.ocr(img_fp)\n\nprint(out)\n\n\nËØÜÂà´ËæìÂá∫Á§∫‰æãÔºö\n\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n\n### ÈíàÂØπÁâàÈù¢ÁÆÄÂçïÁöÑÂç∞Âà∑‰ΩìÊà™ÂõæÂõæÂÉèËØÜÂà´\n\nËã•Â§ÑÁêÜÁöÑÂõæÂÉèÊòØ**ÁâàÈù¢ÁªìÊûÑÁÆÄÂçïÁöÑÂç∞Âà∑‰ΩìÊñáÂ≠ó**Ôºà‰æãÂ¶ÇËΩØ‰ª∂Êà™Âõæ„ÄÅÊñáÊ°£Êâ´Êèè‰ª∂ÔºâÔºåÂèØ‰ª•ÈÄöËøáËÆæÁΩÆÂèÇÊï∞ `det_model_name='naive_det'` Êù•Á¶ÅÁî®Ê∑±Â∫¶ÊñáÊú¨Ê£ÄÊµãÊ®°ÂûãÔºåËΩ¨ËÄåÈááÁî®ÁÆÄÂåñÁöÑÂü∫‰∫éËßÑÂàôÁöÑË°åÂàÜÂâ≤Á≠ñÁï•„ÄÇ\n\n\u003e **Ê≥®ÊÑè**\n\u003e \n\u003e `det_model_name='naive_det'` ÁöÑËøêË°åÊïàÊûúÁ≠âÂêå‰∫é `V2.2` ‰πãÂâçÁöÑ CnOCR ÁâàÊú¨ÔºàÂç≥ `V2.0.*`, `V2.1.*`Ôºâ„ÄÇ\n\n‰ΩøÁî® `det_model_name='naive_det'` ÁöÑ‰∏ªË¶Å‰ºòÂäøÂú®‰∫é**ÊâßË°åÈÄüÂ∫¶ÊûÅÂø´**Ôºå‰ΩÜÁº∫ÁÇπÊòØÂØπËæìÂÖ•ÂõæÂÉèÁöÑ**ÈÄÇÂ∫îÊÄßËæÉÂ∑Æ**„ÄÇÂà§Êñ≠ÊòØÂê¶Â∫îÈááÁî®Ê≠§Ê£ÄÊµãÊ®°ÂºèÁöÑÊúÄÁÆÄÂçïÊñπÊ≥ïÊòØÔºöÁî®ÁõÆÊ†áÂõæÂÉèËøõË°åÊµãËØïÔºåËã•ÊïàÊûúÊª°ÊÑèÂàôÈááÁî®ÔºåÂê¶ÂàôÂ∫îÂàáÊç¢ÂõûÊõ¥Âº∫Â§ßÁöÑÊ£ÄÊµãÊ®°Âûã„ÄÇ\n\npython\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/multi-line_cn1.png'\noc = CnOcr(det_model_name='naive_det') \nout = oc.ocr(img_fp)\n\nprint(out)\n\n\nËØÜÂà´ÁªìÊûúÂ±ïÁ§∫Ôºö\n\n\u003cdiv align=\"center\"\u003e\n\n| ÂéüÂßãÂõæÂÉè                                                                      | OCR ÊèêÂèñÁªìÊûú                                                                                                                         | \n| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n|  | ÁΩëÁªúÊîØ‰ªòÂπ∂Êó†Êú¨Ë¥®ÁöÑÂå∫Âà´ÔºåÂõ†‰∏∫\u003cbr /\u003eÊØè‰∏Ä‰∏™ÊâãÊú∫Âè∑Á†ÅÂíåÈÇÆ‰ª∂Âú∞ÂùÄËÉåÂêé\u003cbr /\u003eÈÉΩ‰ºöÂØπÂ∫îÁùÄ‰∏Ä‰∏™Ë¥¶Êà∑--Ëøô‰∏™Ë¥¶\u003cbr /\u003eÊà∑ÂèØ‰ª•ÊòØ‰ø°Áî®Âç°Ë¥¶Êà∑„ÄÅÂÄüËÆ∞Âç°Ë¥¶\u003cbr /\u003eÊà∑Ôºå‰πüÂåÖÊã¨ÈÇÆÂ±ÄÊ±áÊ¨æ„ÄÅÊâãÊú∫‰ª£\u003cbr /\u003eÊî∂„ÄÅÁîµËØù‰ª£Êî∂„ÄÅÈ¢Ñ‰ªòË¥πÂç°ÂíåÁÇπÂç°\u003cbr /\u003eÁ≠âÂ§öÁßçÂΩ¢Âºè„ÄÇ |\n\n\u003c/div\u003e\n\n\n### ÂûÇÁõ¥ÊñáÊú¨ËØÜÂà´\n\nÂª∫ËÆÆÈááÁî®Ê∫êËá™ [**PaddleOCR**](https://github.com/PaddlePaddle/PaddleOCR)ÔºàÂêéÁª≠ÁÆÄÁß∞ **ppocr**ÔºâÁöÑ‰∏≠ÊñáËØÜÂà´Ê®°Âûã `rec_model_name='ch_PP-OCRv3'` Êù•Â§ÑÁêÜÁ´ñÊéíÊñáÊú¨„ÄÇ\n\npython\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/shupai.png'\noc = CnOcr(rec_model_name='ch_PP-OCRv3')\nout = oc.ocr(img_fp)\n\nprint(out)\n\n\nËØÜÂà´ÁªìÊûúÔºö\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n\n### Á∫ØËã±ÊñáÂÜÖÂÆπËØÜÂà´\n\nÂ∞ΩÁÆ°‰∏≠ÊñáÂ≠óÁ¨¶ÁöÑÊ£ÄÊµã‰∏éËØÜÂà´Ê®°Âûã‰πüËÉΩÂ§ÑÁêÜËã±ÊñáÂÜÖÂÆπÔºå‰ΩÜ**‰∏ìÈó®‰∏∫Ëã±ÊñáÊñáÊú¨ËÆ≠ÁªÉÁöÑÊ£ÄÊµãÂô®ÂíåËØÜÂà´Âô®ÈÄöÂ∏∏ËÉΩËææÂà∞Êõ¥È´òÁöÑÁ≤æÂ∫¶**„ÄÇÂØπ‰∫éÁ∫ØËã±ÊñáÁöÑÂ∫îÁî®Âú∫ÊôØÔºåÊé®ËçêÈÄâÁî® **ppocr** Êèê‰æõÁöÑËã±ÊñáÊ£ÄÊµãÊ®°Âûã `det_model_name='en_PP-OCRv3_det'` ÂíåËã±ÊñáËØÜÂà´Ê®°Âûã `rec_model_name='en_PP-OCRv3'`„ÄÇ\n\npython\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/en_book1.jpeg'\noc = CnOcr(det_model_name='en_PP-OCRv3_det', rec_model_name='en_PP-OCRv3')\nout = oc.ocr(img_fp)\n\nprint(out)\n\n\nËØÜÂà´ÁªìÊûúÊ¶ÇËßàÔºö\n\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n\n### ‰º†ÁªüÁπÅ‰Ωì‰∏≠ÊñáËØÜÂà´\n\nËØ∑ÈÄâÁî®Ê∫êËá™ ppocr ÁöÑÁπÅ‰Ωì‰∏≠ÊñáËØÜÂà´Ê®°Âûã `rec_model_name='chinese_cht_PP-OCRv3'` ËøõË°åÂ§ÑÁêÜ„ÄÇ\n\npython\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/fanti.jpg'\noc = CnOcr(rec_model_name='chinese_cht_PP-OCRv3')  # ÈÄâÁî®ÁπÅ‰ΩìËØÜÂà´‰∏ìÁî®Ê®°Âûã\nout = oc.ocr(img_fp)\n\nprint(out)\n\n\n‰ΩøÁî®ËØ•ÁπÅ‰ΩìÊ®°ÂûãÊó∂ÈúÄÁïôÊÑè‰ª•‰∏ãÈôêÂà∂Ôºö\n\n* ÂÖ∂ËØÜÂà´ÁöÑÊÄª‰ΩìÂáÜÁ°ÆÁéáÁõ∏ÂØπÊúâÈôêÔºåË°®Áé∞‰∏≠Á≠âÔºõ\n\n* Èô§‰∫ÜÁπÅ‰ΩìÊ±âÂ≠óÂ§ñÔºåÂØπÊ†áÁÇπÁ¨¶Âè∑„ÄÅËã±ÊñáÂ≠óÊØçÂíåÊï∞Â≠óÁöÑËØÜÂà´ÊïàÊûúÂùá‰∏çÁêÜÊÉ≥Ôºõ\n\n* Ê≠§ÁâπÂÆöÊ®°Âûã**‰∏çÊîØÊåÅÁ´ñÂêëÊñáÊú¨ÁöÑËØÜÂà´**„ÄÇ\n\nËØÜÂà´ÁªìÊûúÂõæÁ§∫Ôºö\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n\n### ÈíàÂØπÂçïË°åÊñáÊú¨ÂõæÂÉèÁöÑÂø´ÈÄüËØÜÂà´\n\nÂΩìÊÇ®Á°ÆÂÆöÂæÖÂ§ÑÁêÜÁöÑÂõæÂÉè‰ªÖÂåÖÂê´**ÂçïË°åÊñáÂ≠ó**ÔºàÂèÇËÄÉ‰∏ãÂõæÔºâÔºåÂèØ‰ª•‰ΩøÁî®Á±ªÊñπÊ≥ï `CnOcr.ocr_for_single_line()`„ÄÇÊ≠§ÊñπÊ≥ï‰ºöÁõ¥Êé•Ë∑≥ËøáËÄóÊó∂ÁöÑÊñáÂ≠óÊ£ÄÊµãÊ≠•È™§ÔºåËØÜÂà´ÈÄüÂ∫¶ÂèØÊèêÂçá‰∏ÄÂÄç‰ª•‰∏ä„ÄÇ\n\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\nË∞ÉÁî®‰ª£Á†ÅÂ¶Ç‰∏ãÊâÄÁ§∫Ôºö\n\npython\nfrom cnocr import CnOcr\n\nimg_fp = './docs/examples/helloworld.jpg'\noc = CnOcr()\nout = oc.ocr_for_single_line(img_fp)\nprint(out)\n\n\n\n\n### Êõ¥Â§öÂ∫îÁî®Âú∫ÊôØÊºîÁ§∫\n\n* **Ê†∏ÈÖ∏Ê£ÄÊµã/Áñ´ËãóÊé•ÁßçÂá≠ËØÅÊà™ÂõæËØÜÂà´**\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n* **Ë∫´‰ªΩËØÅ‰ª∂‰ø°ÊÅØÊèêÂèñ**\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n* **È§êÈ•ÆÂ∞èÁ•®/Êî∂ÊçÆËØÜÂà´**\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n  \n\n  \n\n## ÂÆâË£ÖÈÉ®ÁΩ≤\n\nÁêÜÊÉ≥ÊÉÖÂÜµ‰∏ãÔºåÂü∫Á°ÄÂÆâË£Ö‰ªÖÈúÄÊâßË°å‰∏ÄÊù°ÂëΩ‰ª§Ë°åÊåá‰ª§Âç≥ÂèØÂÆåÊàê„ÄÇ\n\nbash\n$ pip install cnocr[ort-cpu]\n\n\nÂ¶ÇÊûúÊÇ®‰ΩøÁî®ÁöÑÊòØ **GPU** ÁéØÂ¢ÉÂπ∂ËÆ°ÂàíÂà©Áî® ONNX Ê®°ÂûãËøõË°åÂä†ÈÄüÔºåËØ∑ÈááÁî®‰ª•‰∏ãÂëΩ‰ª§ËøõË°åÂÆâË£ÖÔºö\n\nbash\n$ pip install cnocr[ort-gpu]\n\n\n\n\nÂ¶ÇÊûúÊÇ®ËÆ°ÂàíËá™Ë°åËÆ≠ÁªÉÊàñÂæÆË∞ÉÊ®°ÂûãÔºåÂèØ‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£ÖÂºÄÂèë‰æùËµñÔºö\n\nbash\n$ pip install cnocr[dev]\n\n\n\n\nËã•Ê†áÂáÜÂÆâË£ÖÊ∫ê‰∏ãËΩΩÈÄüÂ∫¶ËæÉÊÖ¢ÔºåÂª∫ËÆÆÂàáÊç¢Ëá≥ÂõΩÂÜÖÈïúÂÉèÊ∫êÔºå‰æãÂ¶ÇÈòøÈáå‰∫ëÁöÑÂä†ÈÄüÊ∫êÔºö\n\nbash\n$ pip install cnocr[ort-cpu] -i https://mirrors.aliyun.com/pypi/simple\n\n\n\u003e **ÁéØÂ¢ÉÊèêÁ§∫** \n\u003e \n\u003e ËØ∑Âä°ÂøÖ‰ΩøÁî® **Python3** ÁéØÂ¢ÉÔºàÁâàÊú¨ËåÉÂõ¥ 3.7.* Ëá≥ 3.10.* ÈÄöÂ∏∏ÂÖºÂÆπËâØÂ•ΩÔºâÔºåPython 2 ÁéØÂ¢ÉÊú™ËøõË°åÂÖºÂÆπÊÄßÊµãËØï„ÄÇ\n\nÊõ¥Â§öËØ¶ÁªÜÁöÑÂÆâË£ÖËØ¥ÊòéËØ∑ÂèÇËÄÉ [ÂÆâË£ÖÊñáÊ°£](https://cnocr.readthedocs.io/zh-cn/stable/install/)„ÄÇ\n\n\u003e **ÈáçË¶ÅË≠¶Âëä** \n\u003e \n\u003e Â¶ÇÊûúÊÇ®ÁöÑÁ≥ªÁªüÂ∞öÊú™ÂÆâË£Ö `PyTorch` Êàñ `OpenCV-python` Â∫ìÔºåÈ¶ñÊ¨°ÂÆâË£ÖÂèØËÉΩ‰ºöÈÅáÂà∞‰æùËµñÂÜ≤Á™ÅÊàñÁºñËØëÈóÆÈ¢ò„ÄÇËøô‰∫õÈÄöÂ∏∏ÊòØÂ∏∏ËßÅÁöÑÁéØÂ¢ÉÈÖçÁΩÆÈóÆÈ¢òÔºåÂª∫ËÆÆÈÄöËøáÊêúÁ¥¢ÂºïÊìéÔºàÁôæÂ∫¶/GoogleÔºâÊü•ÊâæÂØπÂ∫îËß£ÂÜ≥ÊñπÊ°à„ÄÇ\n\n\n\n### Docker ÂÆπÂô®ÂåñÈÉ®ÁΩ≤\n\nÊÇ®ÂèØÁõ¥Êé•‰ªé [Docker Hub](https://hub.docker.com/u/breezedeus) ÊãâÂèñÈ¢ÑÂÖàÈÖçÁΩÆÂ•Ω CnOCR ÁéØÂ¢ÉÁöÑÂÆòÊñπÈïúÂÉèÔºåÂÆûÁé∞Âø´ÈÄüÂêØÂä®„ÄÇ\n\nbash\n$ docker pull breezedeus/cnocr:latest\n\n\nÊõ¥Â§öÂÖ≥‰∫é Docker ÁöÑÈÉ®ÁΩ≤ÁªÜËäÇËØ∑ÂèÇËÄÉ [ÂÆâË£ÖÊñáÊ°£](https://cnocr.readthedocs.io/zh-cn/stable/install/)„ÄÇ\n\n\n\n## ÈÉ®ÁΩ≤‰∏∫ HTTP ÊúçÂä°\n\nCnOCR Âú® **V2.2.1** ÁâàÊú¨‰∏≠Âä†ÂÖ•‰∫ÜÂü∫‰∫é FastAPI Ê°ÜÊû∂ÊûÑÂª∫ÁöÑ Web ÊúçÂä°Êé•Âè£„ÄÇÂêØÁî®ËØ•ÊúçÂä°ÈúÄË¶ÅÂÆâË£ÖÈ¢ùÂ§ñÁöÑ‰æùËµñÂåÖÔºåËØ∑‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£ÖÔºö\n\nbash\npip install cnocr[serve]\n\n\n\n\nÂÆâË£ÖÂÆåÊØïÂêéÔºåÂèØÈÄöËøáÂ¶Ç‰∏ãÂëΩ‰ª§ÂêØÂä® HTTP ÁõëÂê¨ÊúçÂä°Ôºà`-p` ÂêéÈù¢ÁöÑÊï∞Â≠óÊòØ**ÊúçÂä°Á´ØÂè£Âè∑**ÔºåÂèØÊ†πÊçÆÂÆûÈôÖÈúÄÊ±Ç‰øÆÊîπÔºâÔºö\n\nbash\ncnocr serve -p 8501\n\n\n\n\nÊúçÂä°ÂêØÂä®ÂêéÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÊñπÂºèÈÄöËøáÁΩëÁªúËØ∑Ê±ÇË∞ÉÁî®ËØ•ÊúçÂä°„ÄÇ\n\n### ÂëΩ‰ª§Ë°åË∞ÉÁî®ÔºàcURLÔºâ\n\nÂÅáËÆæÂæÖËØÜÂà´Êñá‰ª∂Ë∑ØÂæÑ‰∏∫ `docs/examples/huochepiao.jpeg`ÔºåÂèØ‰ΩøÁî® curl ÂëΩ‰ª§ËøõË°å POST ËØ∑Ê±ÇÔºö\n\nbash\n\u003e curl -F image=@docs/examples/huochepiao.jpeg http://0.0.0.0:8501/ocr\n\n\n\n### Python ÂÆ¢Êà∑Á´ØË∞ÉÁî®\n\n‰ΩøÁî® Python ÁöÑ `requests` Â∫ìËøõË°åÊúçÂä°Ë∞ÉÁî®ÁöÑÁ§∫‰æã‰ª£Á†ÅÂ¶Ç‰∏ãÔºö\n\npython\nimport requests\n\nimage_fp = 'docs/examples/huochepiao.jpeg'\nr = requests.post(\n    'http://0.0.0.0:8501/ocr', files={'image': (image_fp, open(image_fp, 'rb'), 'image/png')},\n)\nocr_out = r.json()['results']\nprint(ocr_out)\n\n\n\n\nÊõ¥ËØ¶ÁªÜÁöÑÈõÜÊàêÁ§∫‰æãÂèØÂèÇËÄÉÈ°πÁõÆÂÜÖÁöÑÊñá‰ª∂ [scripts/screenshot_daemon_with_server.py](scripts/screenshot_daemon_with_server.py) „ÄÇ \n\n\n### ÂÖ∂‰ªñÁºñÁ®ãËØ≠Ë®Ä\n\nÂÖ∂‰ªñËØ≠Ë®ÄÁöÑÂÆ¢Êà∑Á´ØÂÆûÁé∞Â∫îÂèÇËÄÉ‰∏äËø∞ curl ËØ∑Ê±ÇÁöÑÊñπÂºèËá™Ë°åÊûÑÂª∫„ÄÇ\n\n\n\n## ÂèØÁî®Ê®°ÂûãËµÑÊ∫êÂàóË°®\n\n### ÂèØÈÄâÁî®ÁöÑÊñáÊú¨Ê£ÄÊµãÊ®°Âûã\n\nËØ¶ÁªÜÁöÑÊ£ÄÊµãÊ®°Âûã‰ø°ÊÅØËØ∑ÂèÇÈòÖ [CnSTD È°πÁõÆÁöÑ‰∏ãËΩΩËØ¥Êòé](https://github.com/breezedeus/CnSTD?tab=readme-ov-file#%E5%B7%B2%E6%9C%89std%E6%A8%A1%E5%9E%8B)„ÄÇ\n\n| `det_model_name`                                             | PyTorch ÊîØÊåÅ | ONNX ÊîØÊåÅ | Ê®°ÂûãÊù•Ê∫ê | Ê®°ÂûãÊñá‰ª∂ËßÑÊ®° | ÊîØÊåÅËØ≠Ë®ÄÁ±ªÂûã                       | ÊòØÂê¶ÈÄÇÈÖçÂûÇÁõ¥ÊñáÊú¨ | \n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ------------------------------ | -------------------- | \n| db_shufflenet_v2                                             | ‚àö            | X         | cnocr        | 18 M         | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| **db_shufflenet_v2_small**                                   | ‚àö            | X         | cnocr        | 12 M         | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| db_mobilenet_v3                                              | ‚àö            | X         | cnocr        | 16 M         | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| db_mobilenet_v3_small                                        | ‚àö            | X         | cnocr        | 7.9 M        | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| db_resnet34                                                  | ‚àö            | X         | cnocr        | 86 M         | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| db_resnet18                                                  | ‚àö            | X         | cnocr        | 47 M         | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| ch_PP-OCRv5_det                                              | X            | ‚àö         | ppocr        | 4.6 M        | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| ch_PP-OCRv5_det_server                                       | X            | ‚àö         | ppocr        | 84 M        | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| ch_PP-OCRv4_det                                              | X            | ‚àö         | ppocr        | 4.5 M        | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| ch_PP-OCRv4_det_server                                       | X            | ‚àö         | ppocr        | 108 M        | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| ch_PP-OCRv3_det                                              | X            | ‚àö         | ppocr        | 2.3 M        | ÁÆÄ‰Ωì/ÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó | ‚àö                    | \n| **en_PP-OCRv3_det**                                          | X            | ‚àö         | ppocr        | 2.3 M        | **Ëã±Êñá**„ÄÅÊï∞Â≠ó                 | ‚àö                    | \n\n\n\n### ÂèØÈÄâÁî®ÁöÑÊñáÊú¨ËØÜÂà´Ê®°Âûã\n\n‰∏é CnOCR V2.2.* ÁâàÊú¨ÂØπÊØîÔºå**V2.3** ÁâàÊú¨‰∏≠Â§ßÂ§öÊï∞Ê®°ÂûãÈÉΩÁªèËøá‰∫ÜÈáçÊñ∞ËÆ≠ÁªÉÂíåÁ≤æË∞ÉËøáÁ®ãÔºå‰ªéËÄåÂ∏¶Êù•‰∫ÜÊõ¥È´òÁöÑËØÜÂà´Á≤æÂ∫¶„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨Êñ∞Â¢û‰∫Ü‰∏§ÁªÑÂèÇÊï∞ËßÑÊ®°Êõ¥Â§ßÁöÑÊ®°ÂûãÁ≥ªÂàó‰æõÈ´òÁ∫ßÁî®Êà∑ÈÄâÊã©Ôºö\n\n  * `*-densenet_lite_246-gru_base`ÔºöÂàùÊúü‰∏ì‰æõ **Áü•ËØÜÊòüÁêÉ** [**CnOCR/CnSTDÁßÅ‰∫´Áæ§**](https://t.zsxq.com/FEYZRJQ) ËÆ¢ÈòÖËÄÖ‰ºòÂÖà‰ΩøÁî®ÔºåÈöèÂêéÂ∞ÜÂÖçË¥πÂºÄÊ∫ê„ÄÇ\n  * `*-densenet_lite_666-gru_large`Ôºö‰ªòË¥π **Pro Ê®°Âûã**ÔºåÈúÄÈÄöËøáÊåáÂÆöÈìæÊé•Ë¥≠‰π∞ÂêéÊñπÂèØÂêØÁî®„ÄÇ\n\n**V2.3** ÁâàÊú¨‰∏≠ÁöÑÊ®°ÂûãÊ†πÊçÆÂÖ∂‰ºòÂåñÁöÑÂ∫îÁî®Âú∫ÊôØÔºåÂèØË¢´ÂàíÂàÜ‰∏∫‰ª•‰∏ã‰∏ªË¶ÅÁ±ªÂà´Ôºö\n\n* `scene`ÔºöÈù¢ÂêëÂú∫ÊôØÂõæÂÉèÔºåÈÄÇÁî®‰∫éËá™ÁÑ∂ÊãçÊëÑÁÖßÁâá‰∏≠ÁöÑÊñáÊú¨ÊèêÂèñ„ÄÇËøôÁ±ªÊ®°ÂûãÂêçÁß∞ÂâçÁºÄ‰∏∫ `scene-`Ôºå‰æãÂ¶ÇÊ®°Âûã `scene-densenet_lite_136-gru`„ÄÇ\n* `doc`ÔºöÈù¢ÂêëÊñáÊ°£ÂõæÂÉèÔºåÈÄÇÁî®‰∫éËØÜÂà´ÊéíÁâàÂ∑•Êï¥ÁöÑÊà™ÂõæÊàñÊâ´Êèè‰ª∂Á≠â„ÄÇËøôÁ±ªÊ®°ÂûãÂêçÁß∞ÂâçÁºÄ‰∏∫ `doc-`Ôºå‰æãÂ¶ÇÊ®°Âûã `doc-densenet_lite_136-gru`„ÄÇ\n* `number`Ôºö**‰ªÖÊîØÊåÅÊï∞Â≠óËØÜÂà´**Ôºà‰ªÖÈôê `0` Âà∞ `9` ÂçÅ‰∏™ÈòøÊãâ‰ºØÊï∞Â≠óÔºâÔºå‰∏ì‰∏∫Èì∂Ë°åÂç°Âè∑„ÄÅËØÅ‰ª∂Âè∑Á†ÅÁ≠âÂú∫ÊôØ‰ºòÂåñ„ÄÇËøôÁ±ªÊ®°ÂûãÂêçÁß∞ÂâçÁºÄ‰∏∫ `number-`Ôºå‰æãÂ¶ÇÊ®°Âûã `number-densenet_lite_136-gru`„ÄÇ\n* `general`: ÈÄÇÁî®‰∫éÊó†ÊòéÊòæÈ£éÊ†ºÂÄæÂêëÁöÑÈÄöÁî®ÂõæÂÉè„ÄÇËøôÁ±ªÊ®°ÂûãÊ≤øÁî®ÊóßÁâàÂëΩÂêçËßÑÂàôÔºåÊó†ÁâπÂÆöÂâçÁºÄÔºå‰æãÂ¶ÇÊ®°Âûã `densenet_lite_136-gru`„ÄÇ\n\n\u003e Ê≥®ÊÑè ‚ö†Ô∏èÔºö‰∏äËø∞Âú∫ÊôØÊèèËø∞‰ªÖ‰æõÂèÇËÄÉÔºåÁî®Êà∑Âú®ÂÆûÈôÖÈÉ®ÁΩ≤Êó∂ÔºåÂä°ÂøÖ‰ª•Ê®°ÂûãÂú®ÁõÆÊ†áÊï∞ÊçÆ‰∏äÁöÑÂÆûÊµãÊÄßËÉΩ‰∏∫ÊúÄÁªàÈÄâÊã©‰æùÊçÆ„ÄÇ\n\nÊõ¥Â§öÊ®°ÂûãÁªÜËäÇËØ∑ÂèÇËÄÉÔºö[ÂèØÁî®Ê®°ÂûãËµÑÊ∫ê](https://cnocr.readthedocs.io/zh-cn/stable/models/)„ÄÇ\n\n| `rec_model_name`                                             | PyTorch ÊîØÊåÅ | ONNX ÊîØÊåÅ | Ê®°ÂûãÊù•Ê∫ê | Ê®°ÂûãÊñá‰ª∂ËßÑÊ®° | ÊîØÊåÅËØ≠Ë®ÄÈõÜ                            | ÊòØÂê¶ÈÄÇÈÖçÂûÇÁõ¥ÊñáÊú¨ | \n| ------------------------------------------------------------ | ------------ | --------- | ------------ | ------------ | ----------------------------------- | -------------------- | \n| **densenet_lite_136-gru** üÜï                                  | ‚àö            | ‚àö         | cnocr        | 12 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **scene-densenet_lite_136-gru** üÜï                            | ‚àö            | ‚àö         | cnocr        | 12 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **doc-densenet_lite_136-gru** üÜï                              | ‚àö            | ‚àö         | cnocr        | 12 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **densenet_lite_246-gru_base** üÜï \u003cbr /\u003e ([ÊòüÁêÉ‰ºöÂëò](https://t.zsxq.com/FEYZRJQ)‰∏ì‰∫´) | ‚àö            | ‚àö         | cnocr        | 25 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **scene-densenet_lite_246-gru_base** üÜï \u003cbr /\u003e ([ÊòüÁêÉ‰ºöÂëò](https://t.zsxq.com/FEYZRJQ)‰∏ì‰∫´) | ‚àö            | ‚àö         | cnocr        | 25 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **doc-densenet_lite_246-gru_base** üÜï \u003cbr /\u003e ([ÊòüÁêÉ‰ºöÂëò](https://t.zsxq.com/FEYZRJQ)‰∏ì‰∫´) | ‚àö            | ‚àö         | cnocr        | 25 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **densenet_lite_666-gru_large** üÜï \u003cbr /\u003eÔºàË¥≠‰π∞ÈìæÊé•Ôºö[BÁ´ô](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1\u0026page=detailuniversal_detail\u0026saleType=10\u0026itemsId=11884138\u0026loadingShow=1\u0026noTitleBar=1\u0026msource=merchant_share)„ÄÅ[Lemon Squeezy](https://ocr.lemonsqueezy.com/)Ôºâ | ‚àö            | ‚àö         | cnocr        | 82 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **scene-densenet_lite_666-gru_large** üÜï \u003cbr /\u003eÔºàË¥≠‰π∞ÈìæÊé•Ôºö[BÁ´ô](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1\u0026page=detailuniversal_detail\u0026saleType=10\u0026itemsId=11883935\u0026loadingShow=1\u0026noTitleBar=1\u0026msource=merchant_share)„ÄÅ[Lemon Squeezy](https://ocr.lemonsqueezy.com/)Ôºâ | ‚àö            | ‚àö         | cnocr        | 82 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **doc-densenet_lite_666-gru_large** üÜï \u003cbr /\u003eÔºàË¥≠‰π∞ÈìæÊé•Ôºö[BÁ´ô](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1\u0026page=detailuniversal_detail\u0026saleType=10\u0026itemsId=11883965\u0026loadingShow=1\u0026noTitleBar=1\u0026msource=merchant_share)„ÄÅ[Lemon Squeezy](https://ocr.lemonsqueezy.com/)Ôºâ | ‚àö            | ‚àö         | cnocr        | 82 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | X                    | \n| **number-densenet_lite_136-fc** üÜï                            | ‚àö            | ‚àö         | cnocr        | 2.7 M        | **Á∫ØÊï∞Â≠ó**Ôºà‰ªÖÂê´ `0~9`Ôºâ | X                    | \n| **number-densenet_lite_136-gru**  üÜï \u003cbr /\u003e ([ÊòüÁêÉ‰ºöÂëò](https://t.zsxq.com/FEYZRJQ)‰∏ì‰∫´) | ‚àö            | ‚àö         | cnocr        | 5.5 M        | **Á∫ØÊï∞Â≠ó**Ôºà‰ªÖÂê´ `0~9`Ôºâ | X                    | \n| **number-densenet_lite_666-gru_large** üÜï \u003cbr /\u003eÔºàË¥≠‰π∞ÈìæÊé•Ôºö[BÁ´ô](https://mall.bilibili.com/neul-next/detailuniversal/detail.html?isMerchant=1\u0026page=detailuniversal_detail\u0026saleType=10\u0026itemsId=11884155\u0026loadingShow=1\u0026noTitleBar=1\u0026msource=merchant_share)„ÄÅ[Lemon Squeezy](https://ocr.lemonsqueezy.com/)Ôºâ | ‚àö            | ‚àö         | cnocr        | 55 M         | **Á∫ØÊï∞Â≠ó**Ôºà‰ªÖÂê´ `0~9`Ôºâ | X                    | \n| ch_PP-OCRv5                                                  | X            | ‚àö         | ppocr        | 16 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| ch_PP-OCRv5_server                                           | X            | ‚àö         | ppocr        | 81 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| ch_PP-OCRv4                                                  | X            | ‚àö         | ppocr        | 10 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| ch_PP-OCRv4_server                                           | X            | ‚àö         | ppocr        | 86 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| ch_PP-OCRv3                                                  | X            | ‚àö         | ppocr        | 10 M         | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| ch_ppocr_mobile_v2.0                                         | X            | ‚àö         | ppocr        | 4.2 M        | ÁÆÄ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| en_PP-OCRv4                                                  | X            | ‚àö         | ppocr        | 8.6 M        | **Ëã±Êñá**„ÄÅÊï∞Â≠ó                      | ‚àö                    | \n| en_PP-OCRv3                                                  | X            | ‚àö         | ppocr        | 8.5 M        | **Ëã±Êñá**„ÄÅÊï∞Â≠ó                      | ‚àö                    | \n| en_number_mobile_v2.0                                        | X            | ‚àö         | ppocr        | 1.8 M        | **Ëã±Êñá**„ÄÅÊï∞Â≠ó                      | ‚àö                    | \n| chinese_cht_PP-OCRv3                                         | X            | ‚àö         | ppocr        | 11 M         | **ÁπÅ‰Ωì‰∏≠Êñá**„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó            | X                    | \n| japan_PP-OCRv3                                               | X            | ‚àö         | ppocr        | 9.6 M         | **Êó•Êñá**„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| korean_PP-OCRv3                                              | X            | ‚àö         | ppocr        | 9.4 M         | **Èü©Êñá**„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó                | ‚àö                    | \n| latin_PP-OCRv3                                               | X            | ‚àö         | ppocr        | 8.6 M         | **Êãâ‰∏ÅÊñá**„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó              | ‚àö                    | \n| arabic_PP-OCRv3                                              | X            | ‚àö         | ppocr        | 8.6 M         | **ÈòøÊãâ‰ºØÊñá**„ÄÅËã±Êñá„ÄÅÊï∞Â≠ó            | ‚àö                    | \n\n\n\n## ÂâçËøõË∑ØÁ∫øÂõæ\n\n* [x] ÂÆûÁé∞ÂØπÂ§öË°åÊñáÊú¨ÂõæÂÉèÁöÑÂáÜÁ°ÆËØÜÂà´ (`Â∑≤ÂÆåÊàê`)\n* [x] CRNN Ê®°ÂûãÊîØÊåÅÂèòÈïøÂ∫èÂàóÈ¢ÑÊµãÔºåÂ¢ûÂº∫Â§ÑÁêÜÁÅµÊ¥ªÊÄß (Ëá™ `V1.0.0` Ëµ∑)\n* [x] ÂÆåÂñÑÂçïÂÖÉÊµãËØïÁî®‰æã (`ËøõË°å‰∏≠`)\n* [x] ‰øÆÂ§çÂ∑≤Áü•ËΩØ‰ª∂Áº∫Èô∑ÔºàÂΩìÂâç‰ª£Á†ÅÁªìÊûÑÁõ∏ÂØπÂ§çÊùÇ„ÄÇ„ÄÇÔºâ (`ËøõË°å‰∏≠`)\n* [x] ÊîØÊåÅËØÜÂà´ÊñáÊú¨‰∏≠ÁöÑ`Á©∫Ê†º`Â≠óÁ¨¶ (Ëá™ `V1.1.0` Ëµ∑)\n* [x] Êé¢Á¥¢Âπ∂ÈõÜÊàêÊñ∞ÂûãÊ®°ÂûãÔºåÂ¶Ç DenseNet Êû∂ÊûÑÔºå‰ª•ÊúüÊèêÂçáËØÜÂà´Á≤æÂ∫¶ (Ëá™ `V1.1.0` Ëµ∑)\n* [x] Êï∞ÊçÆÈõÜÊ∏ÖÊ¥ó‰∏é‰ºòÂåñÔºåÂéªÈô§‰ΩéË¥®ÈáèÊ†∑Êú¨ÔºõÂú®Ê≠§Âü∫Á°Ä‰∏äÔºåÂØπÊâÄÊúâÊ®°ÂûãËøõË°åÈáçËÆ≠ÁªÉ\n* [x] ÊäÄÊúØÊ†àËøÅÁßªÔºö‰ªé MXNet Êû∂ÊûÑÂàáÊç¢Ëá≥ PyTorch Ê°ÜÊû∂ (Ëá™ `V2.0.0` Ëµ∑)\n* [x] Âü∫‰∫é PyTorch Âπ≥Âè∞ËÆ≠ÁªÉÂá∫Êõ¥È´òÊÄßËÉΩÁöÑÊ®°Âûã\n* [x] ÊîØÊåÅÂØπÂàóÂºèÔºàÂûÇÁõ¥ÔºâÂ∏ÉÂ±ÄÊñáÊú¨ÁöÑËØÜÂà´ËÉΩÂäõ\n* [x] ÂÆûÁé∞‰∏é [CnSTD](https://github.com/breezedeus/cnstd) ÊñáÊú¨Ê£ÄÊµãÊ®°ÂùóÁöÑÈõ∂Êë©Êì¶ÈõÜÊàê (Ëá™ `V2.2` Ëµ∑)\n* [ ] ÊåÅÁª≠Êé®ËøõÊ®°ÂûãËØÜÂà´Á≤æÂ∫¶ÁöÑËæπÁïåÁ™ÅÁ†¥\n* [ ] Êâ©Â±ïÂØπÊõ¥Â§öÁâπÂÆöÂ∫îÁî®Âú∫ÊôØÁöÑ‰ºòÂåñÊîØÊåÅ\n\n\n\n## ÈºìÂä±‰ΩúËÄÖÔºàËØ∑ÂñùÊùØÂíñÂï°Ôºâ\n\nÂºÄÊ∫êÁª¥Êä§‰∏çÊòìÔºåËã•Êú¨Â∑•ÂÖ∑ÂåÖÂØπÊÇ®ÁöÑÂ∑•‰ΩúÊúâÊâÄÂä©ÁõäÔºåÊÅ≥ËØ∑ÊÇ®ËÄÉËôë [‰∏∫‰ΩúËÄÖÊ∑ªÁ†ñÂä†Áì¶ü•§ÔºåÁªô‰∫àÁ≤æÁ•ûÊîØÊåÅüí™üèª](https://cnocr.readthedocs.io/zh-cn/stable/buymeacoffee/) „ÄÇ\n\n---\n\nÂÆòÊñπ‰ª£Á†Å‰ªìÂ∫ìÂú∞ÂùÄÔºö[https://github.com/breezedeus/cnocr](https://github.com/breezedeus/cnocr)„ÄÇ\nWIKIPEDIA ÂºïÁî®ÔºöA text-to-image model (T2I or TTI model) is a machine learning model which takes an input natural language prompt and produces an image matching that description. \nText-to-image models began to be developed in the mid-2010s during the beginnings of the AI boom, as a result of advances in deep neural networks. In 2022, the output of state-of-the-art text-to-image models‚Äîsuch as OpenAI's DALL-E 2, Google Brain's Imagen, Recraft, Stability AI's Stable Diffusion, Midjourney, and Runway's Gen-4‚Äîbegan to be considered to approach the quality of real photographs and human-drawn art.\nText-to-image models are generally latent diffusion models, which combine a language model, which transforms the input text into a latent representation, and a generative image model, which produces an image conditioned on that representation. The most effective models have generally been trained on massive amounts of image and text data scraped from the web.\n\n\n== History ==\nBefore the rise of deep learning, attempts to build text-to-image models were limited to collages by arranging existing component images, such as from a database of clip art. \nThe inverse task, image captioning, was more tractable, and a number of image captioning deep learning models came prior to the first text-to-image models.\n\nThe first modern text-to-image model, alignDRAW, was introduced in 2015 by researchers from the University of Toronto. alignDRAW extended the previously-introduced DRAW architecture (which used a recurrent variational autoencoder with an attention mechanism) to be conditioned on text sequences. Images generated by alignDRAW were in small resolution (32√ó32 pixels, attained from resizing) and were considered to be 'low in diversity'. The model was able to generalize to objects not represented in the training data (such as a red school bus) and appropriately handled novel prompts such as \"a stop sign is flying in blue skies\", exhibiting output that it was not merely \"memorizing\" data from the training set.\nIn 2016, Reed, Akata, Yan et al. became the first to use generative adversarial networks for the text-to-image task. With models trained on narrow, domain-specific datasets, they were able to generate \"visually plausible\" images of birds and flowers from text captions like \"an all black bird with a distinct thick, rounded bill\". A model trained on the more diverse COCO (Common Objects in Context) dataset produced images which were \"from a distance... encouraging\", but which lacked coherence in their details. Later systems include VQGAN-CLIP, XMC-GAN, and GauGAN2. \nOne of the first text-to-image models to capture widespread public attention was OpenAI's DALL-E, a transformer system announced in January 2021. A successor capable of generating more complex and realistic images, DALL-E 2, was unveiled in April 2022, followed by Stable Diffusion that was publicly released in August 2022. In August 2022, text-to-image personalization allows to teach the model a new concept using a ",
      "stars": 3659,
      "updated_at": "2025-10-03T14:15:19Z",
      "url": "https://github.com/breezedeus/CnOCR"
    },
    "burningion--video-editing-mcp": {
      "category": "image-and-video-generation",
      "description": "Upload, edit, search, and generate videos using large language models and Video Jungle's tools. The server enables interaction with videos through a custom URI scheme for managing individual videos and projects.",
      "forks": 29,
      "imageUrl": "/freedevtools/mcp/pfp/burningion.webp",
      "keywords": [
        "videos",
        "editing",
        "upload",
        "video generation",
        "generate videos",
        "video editing"
      ],
      "language": "Python",
      "license": "No License",
      "name": "video-editing-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "burningion",
      "readme_content": "# Video Editor MCP server\n\n[](https://www.video-jungle.com)\n\nSee a demo here: [https://www.youtube.com/watch?v=KG6TMLD8GmA](https://www.youtube.com/watch?v=KG6TMLD8GmA)\n\nUpload, edit, search, and generate videos from everyone's favorite LLM and [Video Jungle](https://www.video-jungle.com/).\n\nYou'll need to sign up for an account at [Video Jungle](https://app.video-jungle.com/register) in order to use this tool, and add your API key.\n\n[![PyPI version](https://badge.fury.io/py/video-editor-mcp.svg)](https://badge.fury.io/py/video-editor-mcp)\n\n## Components\n\n### Resources\n\nThe server implements an interface to upload, generate, and edit videos with:\n- Custom vj:// URI scheme for accessing individual videos and projects\n- Each project resource has a name, description\n- Search results are returned with metadata about what is in the video, and when, allowing for edit generation directly\n\n### Prompts\n\nComing soon.\n\n### Tools\n\nThe server implements a few tools:\n- add-video\n  - Add a Video File for analysis from a URL. Returns an vj:// URI to reference the Video file\n- create-videojungle-project\n  - Creates a Video Jungle project to contain generative scripts, analyzed videos, and images for video edit generation\n- edit-locally\n  - Creates an OpenTimelineIO project and downloads it to your machine to open in a Davinci Resolve Studio instance (Resolve Studio _must_ already be running before calling this tool.) \n- generate-edit-from-videos\n  - Generates a rendered video edit from a set of video files\n- generate-edit-from-single-video\n  - Generate an edit from a single input video file\n- get-project-assets\n  - Get assets within a project for video edit generation.\n- search-videos\n  - Returns video matches based upon embeddings and keywords\n- update-video-edit\n  - Live update a video edit's information. If Video Jungle is open, edit will be updated in real time.\n\n### Using Tools in Practice\n\nIn order to use the tools, you'll need to sign up for Video Jungle and add your API key.\n\n**add-video**\n\nHere's an example prompt to invoke the `add-video` tool:\n\n```\ncan you download the video at https://www.youtube.com/shorts/RumgYaH5XYw and name it fly traps?\n```\n\nThis will download a video from a URL, add it to your library, and analyze it for retrieval later. Analysis is multi-modal, so both audio and visual components can be queried against.\n\n**search-videos**\n\nOnce you've got a video downloaded and analyzed, you can then do queries on it using the `search-videos` tool:\n\n```\ncan you search my videos for fly traps?\n```\n\nSearch results contain relevant metadata for generating a video edit according to details discovered in the initial analysis.\n\n**search-local-videos**\n\nYou must set the environment variable `LOAD_PHOTOS_DB=1` in order to use this tool, as it will make Claude prompt to access your files on your local machine.\n\nOnce that's done, you can search through your Photos app for videos that exist on your phone, using Apple's tags.\n\nIn my case, when I search for \"Skateboard\", I get 1903 video files.\n\n```\ncan you search my local video files for Skateboard?\n```\n\n**generate-edit-from-videos**\n\nFinally, you can use these search results to generate an edit:\n\n```\ncan you create an edit of all the times the video says \"fly trap\"?\n```\n\n(Currently), the video edits tool relies on the context within the current chat. \n\n**generate-edit-from-single-video**\n\nFinally, you can cut down an edit from a single, existing video:\n\n```\ncan you create an edit of all the times this video says the word \"fly trap\"?\n```\n\n## Configuration\n\nYou must login to [Video Jungle settings](https://app.video-jungle.com/profile/settings), and get your [API key](https://app.video-jungle.com/profile/settings). Then, use this to start Video Jungle MCP:\n\n```bash\n$ uv run video-editor-mcp YOURAPIKEY\n```\n\nTo allow this MCP server to search your Photos app on MacOS:\n\n```\n$ LOAD_PHOTOS_DB=1 uv run video-editor-mcp YOURAPIKEY\n```\n## Quickstart\n\n### Install\n\n#### Installing via Smithery\n\nTo install Video Editor for Claude Desktop automatically via [Smithery](https://smithery.ai/server/video-editor-mcp):\n\n```bash\nnpx -y @smithery/cli install video-editor-mcp --client claude\n```\n\n#### Claude Desktop\n\nYou'll need to adjust your `claude_desktop_config.json` manually:\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n\u003cdetails\u003e\n\u003cdetails\u003e\n  \u003csummary\u003ePublished Server Configuration\u003c/summary\u003e\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n\u003c/details\u003e\n  \u003csummary\u003eDevelopment/Unpublished Servers Configuration\u003c/summary\u003e\n  \n ```json\n  \"mcpServers\": {\n    \"video-editor-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/YOURDIRECTORY/video-editor-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"YOURAPIKEY\"\n      ]\n    }\n  }\n  ```\n\n  With local Photos app access enabled (search your Photos app):\n\n  ```json\n    \"video-jungle-mcp\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/\u003cPATH_TO\u003e/video-jungle-mcp\",\n        \"run\",\n        \"video-editor-mcp\",\n        \"\u003cYOURAPIKEY\u003e\"\n      ],\n     \"env\": {\n\t      \"LOAD_PHOTOS_DB\": \"1\"\n      }\n    },\n  ```\n\n\u003c/details\u003e\n\nBe sure to replace the directories with the directories you've placed the repository in on **your** computer.\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### MCP Server Registry\n\n```\nmcp-name: io.github.burningion/video-editing-mcp\n```\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n(Be sure to replace `YOURDIRECTORY` and `YOURAPIKEY` with the directory this repo is in, and your Video Jungle API key, found in the settings page.)\n\n```bash\nnpx @modelcontextprotocol/inspector uv run --directory /Users/YOURDIRECTORY/video-editor-mcp video-editor-mcp YOURAPIKEY\n```\n\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.\n\nAdditionally, I've added logging to `app.log` in the project directory. You can add logging to diagnose API calls via a:\n\n```\nlogging.info(\"this is a test log\")\n```\n\nA reasonable way to follow along as you're workin on the project is to open a terminal session and do a:\n\n```bash\n$ tail -n 90 -f app.log\n```",
      "stars": 214,
      "updated_at": "2025-09-25T07:41:40Z",
      "url": "https://github.com/burningion/video-editing-mcp"
    },
    "bytefer--mcp-flux-schnell": {
      "category": "image-and-video-generation",
      "description": "Generate images from text descriptions using the Flux Schnell model through an MCP interface. This server connects with Cloudflare's Flux Schnell worker API to deliver image generation capabilities.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/bytefer.webp",
      "keywords": [
        "flux",
        "images",
        "bytefer",
        "flux schnell",
        "mcp flux",
        "image generation"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp-flux-schnell",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "bytefer",
      "readme_content": "# mcp-flux-schnell MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@bytefer/mcp-flux-schnell)](https://smithery.ai/server/@bytefer/mcp-flux-schnell)\n\nA TypeScript-based MCP server that implements a text-to-image generation tool using the Flux Schnell model. This server integrates with Cloudflare's Flux Schnell worker API to provide image generation capabilities through MCP.\n\n- [Creating your own Flux Schnell MCP Server is so easy! ‚Äî Part 1](https://medium.com/@bytefer/creating-your-own-flux-schnell-mcp-server-is-so-easy-part-1-4b9a5b3fb14f)\n- [Creating your own Flux Schnell MCP Server is so easy! ‚Äî Part 2](https://medium.com/@bytefer/creating-your-own-flux-schnell-mcp-server-is-so-easy-part-2-bd711836a493)\n\n## Features\n\n### Tools\n- `generate_image` - Generate images from text descriptions\n  - Takes a text prompt as input (1-2048 characters)\n  - Returns the path to the generated image file\n\n## Environment Variables\n\nThe following environment variables must be configured:\n\n- `FLUX_API_URL` - The URL of the Flux Schnell API endpoint\n- `FLUX_API_TOKEN` - Your authentication token for the Flux Schnell API\n- `WORKING_DIR` (optional) - Directory where generated images will be saved (defaults to current working directory)\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n# or\npnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n# or\npnpm build\n```\n\n## Installation\n\n### Installing via Smithery\n\nTo install Flux Schnell Image Generator for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@bytefer/mcp-flux-schnell):\n\n```bash\nnpx -y @smithery/cli install @bytefer/mcp-flux-schnell --client claude\n```\n\n### Cursor Configuration\n\nThere are two ways to configure the MCP server in Cursor:\n\n#### Project Configuration\n\nFor tools specific to a project, create a `.cursor/mcp.json` file in your project directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-flux-schnell/build/index.js\"],\n      \"env\": {\n        \"FLUX_API_URL\": \"your flux api url\",\n        \"FLUX_API_TOKEN\": \"your flux api token\",\n        \"WORKING_DIR\": \"your working directory\"\n      }\n    }\n  }\n}\n```\n\nThis configuration will only be available within the specific project.\n\n#### Global Configuration\n\nFor tools that you want to use across all projects, create a `~/.cursor/mcp.json` file in your home directory with the same configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-flux-schnell/build/index.js\"],\n      \"env\": {\n        \"FLUX_API_URL\": \"your flux api url\",\n        \"FLUX_API_TOKEN\": \"your flux api token\",\n        \"WORKING_DIR\": \"your working directory\"\n      }\n    }\n  }\n}\n```\n\nThis makes the MCP server available in all your Cursor workspaces.\n",
      "stars": 5,
      "updated_at": "2025-04-20T04:32:23Z",
      "url": "https://github.com/bytefer/mcp-flux-schnell"
    },
    "c-rick--jimeng-mcp": {
      "category": "image-and-video-generation",
      "description": "Integrates with the Jimeng AI service to generate images from text prompts. Supports customization of image parameters such as size, quality, and negative prompts without the need for third-party APIs.",
      "forks": 12,
      "imageUrl": "/freedevtools/mcp/pfp/c-rick.webp",
      "keywords": [
        "jimeng",
        "mcp",
        "images",
        "generate images",
        "jimeng mcp",
        "jimeng ai"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "jimeng-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "c-rick",
      "readme_content": "# Jimeng MCP ÊúçÂä°Âô®\n\n\n‰ΩøÁî®TypeScriptÂÆûÁé∞ÁöÑModel Context Protocol (MCP) ÊúçÂä°Âô®È°πÁõÆÔºåÈõÜÊàê‰∫ÜÂç≥Ê¢¶AIÂõæÂÉèÁîüÊàêÊúçÂä°ÔºåÈÄöËøáÈÄÜÂêëÂ∑•Á®ãÁõ¥Êé•Ë∞ÉÁî®Âç≥Ê¢¶ÂÆòÊñπAPI„ÄÇ\n\n\n## ÂäüËÉΩ\n\n- Âü∫‰∫éTypeScriptÊûÑÂª∫\n- ‰ΩøÁî®tsup‰Ωú‰∏∫ÊûÑÂª∫Â∑•ÂÖ∑\n- ÂÆûÁé∞‰∫ÜMCPÂçèËÆÆÔºåÊîØÊåÅÊ†áÂáÜÁöÑstdioÈÄö‰ø°\n- Áõ¥Êé•Ë∞ÉÁî®Âç≥Ê¢¶AIÂõæÂÉèÁîüÊàêÊúçÂä°ÔºåÊó†ÈúÄÁ¨¨‰∏âÊñπAPI\n- Êèê‰æõÂ§öÁßçÂç≥Ê¢¶Ê®°ÂûãÁöÑÂõæÂÉèÁîüÊàêÂ∑•ÂÖ∑\n- ÊîØÊåÅÂ§öÁßçÂõæÂÉèÂèÇÊï∞Ë∞ÉÊï¥ÔºåÂ¶ÇÂ∞∫ÂØ∏„ÄÅÁ≤æÁªÜÂ∫¶„ÄÅË¥üÈù¢ÊèêÁ§∫ËØçÁ≠â\n- ÊîØÊåÅÂõæÁâáÊ∑∑Âêà/ÂèÇËÄÉÂõæÁîüÊàêÔºàÈÄöËøáfilePathÂèÇÊï∞ÔºåÊîØÊåÅÊú¨Âú∞ÂõæÁâáÂíåÁΩëÁªúÂõæÁâáÔºâ\n- ÊîØÊåÅËßÜÈ¢ëÁîüÊàêÔºåÊîØÊåÅÊ∑ªÂä†ÂèÇËÄÉÂõæÁâáÔºàÈ¶ñÂ∞æÂ∏ßÈÄöËøáfilePathÂèÇÊï∞ËÆæÁΩÆÔºâ\n\n## ÂÆâË£Ö\n\n### ÈÄöËøáSmitheryÂÆâË£Ö\n\nË¶ÅÈÄöËøá [Smithery](https://smithery.ai/server/@c-rick/jimeng-mcp) Ëá™Âä®‰∏∫Claude DesktopÂÆâË£Öjimeng-mcpÔºåËØ∑ÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö\n\n```bash\nnpx -y @smithery/cli install @c-rick/jimeng-mcp --client claude\n```\n\n### ÊâãÂä®ÂÆâË£Ö\n```bash\n# ‰ΩøÁî®yarnÂÆâË£Ö‰æùËµñ\nyarn install\n\n# Êàñ‰ΩøÁî®npmÂÆâË£Ö‰æùËµñ\nnpm install\n```\n\n## ÁéØÂ¢ÉÈÖçÁΩÆ\n\nÂú®MCPÂÆ¢Êà∑Á´ØÈÖçÁΩÆÔºàÂ¶ÇClaude DesktopÔºâ‰∏≠ËÆæÁΩÆ‰ª•‰∏ãÁéØÂ¢ÉÂèòÈáèÔºö\n\nËøõÂÖ•[SmitheryÊâòÁÆ°È°πÁõÆ](https://smithery.ai/server/@c-rick/jimeng-mcp)ÔºåÁÇπÂáªjson, Â°´ÂÖ•JIMENG_API_TOKENÔºå ÁÇπÂáªconnect, ÁîüÊàê‰∏ãÈù¢mcpServers config json\n\n```json\n{\n  \"mcpServers\": {\n    \"jimeng-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@smithery/cli@latest\",\n        \"run\",\n        \"@c-rick/jimeng-mcp\",\n        \"--key\",\n        \"[SmitheryÁîüÊàê]\",\n        \"--profile\",\n        \"[SmitheryÁîüÊàê]\"\n      ]\n    }\n  }\n}\n```\n\n### Ëé∑ÂèñJIMENG_API_TOKEN\n\n1. ËÆøÈóÆ [Âç≥Ê¢¶AIÂÆòÁΩë](https://jimeng.jianying.com) Âπ∂ÁôªÂΩïË¥¶Âè∑\n2. ÊåâF12ÊâìÂºÄÊµèËßàÂô®ÂºÄÂèëËÄÖÂ∑•ÂÖ∑\n3. Âú®Application \u003e Cookies‰∏≠ÊâæÂà∞`sessionid`ÁöÑÂÄº\n4. Â∞ÜÊâæÂà∞ÁöÑsessionidÂÄºÈÖçÁΩÆ‰∏∫JIMENG_API_TOKENÁéØÂ¢ÉÂèòÈáè\n\n## ÂºÄÂèë\n\n```bash\n# ÂºÄÂèëÊ®°ÂºèËøêË°å\nyarn dev\n\n# ‰ΩøÁî®nodemonÂºÄÂèëÂπ∂Ëá™Âä®ÈáçÂêØ\nyarn start:dev\n```\n\n## ÊûÑÂª∫\n\n```bash\n# ÊûÑÂª∫È°πÁõÆ\nyarn build\n```\n\n## ËøêË°å\n\n```bash\n# ÂêØÂä®ÊúçÂä°Âô®\nyarn start\n\n# ÊµãËØïMCPÊúçÂä°Âô®\nyarn test\n```\n\n## Claude Desktop ÈÖçÁΩÆÁ§∫‰æã\n\n‰ª•‰∏ãÊòØÂú®Claude Desktop‰∏≠ÈÖçÁΩÆÊ≠§MCPÊúçÂä°Âô®ÁöÑÂÆåÊï¥Á§∫‰æã:\n\n```json\n{\n  \"mcpServers\": {\n    \"jimeng\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/jimeng-mcp/lib/index.js\"],\n      \"env\": {\n        \"JIMENG_API_TOKEN\": \"your_jimeng_session_id_here\"\n      }\n    }\n  }\n}\n```\n\n## Âç≥Ê¢¶AIÂõæÂÉèÁîüÊàê\n\nÊú¨MCPÊúçÂä°Âô®Áõ¥Êé•Ë∞ÉÁî®Âç≥Ê¢¶AIÂõæÂÉèÁîüÊàêAPIÔºåÊèê‰æõÂõæÂÉèÁîüÊàêÂ∑•ÂÖ∑Ôºö\n\n`generateImage` - Êèê‰∫§ÂõæÂÉèÁîüÊàêËØ∑Ê±ÇÂπ∂ËøîÂõûÂõæÂÉèURLÂàóË°®\n- ÂèÇÊï∞Ôºö\n  - `prompt`ÔºöÁîüÊàêÂõæÂÉèÁöÑÊñáÊú¨ÊèèËø∞ÔºàÂøÖÂ°´Ôºâ\n  - `filePath`ÔºöÊú¨Âú∞ÂõæÁâáË∑ØÂæÑÊàñÂõæÁâáURLÔºàÂèØÈÄâÔºåËã•Â°´ÂÜôÂàô‰∏∫ÂõæÁâáÊ∑∑Âêà/ÂèÇËÄÉÂõæÁîüÊàêÂäüËÉΩÔºâ\n  - `model`ÔºöÊ®°ÂûãÂêçÁß∞ÔºåÂèØÈÄâÂÄº: jimeng-3.0, jimeng-2.1, jimeng-2.0-pro, jimeng-2.0, jimeng-1.4, jimeng-xl-proÔºàÂèØÈÄâÔºåÈªòËÆ§‰∏∫jimeng-2.1ÔºåÂõæÁâáÊ∑∑ÂêàÊó∂Ëá™Âä®ÂàáÊç¢‰∏∫jimeng-2.0-proÔºâ\n  - `width`ÔºöÂõæÂÉèÂÆΩÂ∫¶ÔºåÈªòËÆ§ÂÄºÔºö1024ÔºàÂèØÈÄâÔºâ\n  - `height`ÔºöÂõæÂÉèÈ´òÂ∫¶ÔºåÈªòËÆ§ÂÄºÔºö1024ÔºàÂèØÈÄâÔºâ\n  - `sample_strength`ÔºöÁ≤æÁªÜÂ∫¶ÔºåÈªòËÆ§ÂÄºÔºö0.5ÔºåËåÉÂõ¥0-1ÔºàÂèØÈÄâÔºâ\n  - `negative_prompt`ÔºöÂèçÂêëÊèêÁ§∫ËØçÔºåÂëäËØâÊ®°Âûã‰∏çË¶ÅÁîüÊàê‰ªÄ‰πàÂÜÖÂÆπÔºàÂèØÈÄâÔºâ\n\n\u003e **Ê≥®ÊÑèÔºö**\n\u003e - `filePath` ÊîØÊåÅÊú¨Âú∞ÁªùÂØπ/Áõ∏ÂØπË∑ØÂæÑÂíåÂõæÁâáURL„ÄÇ\n\u003e - Ëã•ÊåáÂÆö `filePath`ÔºåÂ∞ÜËá™Âä®ËøõÂÖ•ÂõæÁâáÊ∑∑Âêà/ÂèÇËÄÉÂõæÁîüÊàêÊ®°ÂºèÔºåÂ∫ïÂ±ÇÊ®°ÂûãËá™Âä®ÂàáÊç¢‰∏∫ `jimeng-2.0-pro`„ÄÇ\n\u003e - ÁΩëÁªúÂõæÁâáÈúÄ‰øùËØÅÂèØÂÖ¨ÂºÄËÆøÈóÆ„ÄÇ\n\n### ÂõæÁâáÊ∑∑Âêà/ÂèÇËÄÉÂõæÁîüÊàêÂäüËÉΩ\n\nÂ¶ÇÈúÄÂü∫‰∫éÂõæÁâáËøõË°åÊ∑∑ÂêàÁîüÊàêÔºåÂè™ÈúÄ‰º†ÂÖ•`filePath`ÂèÇÊï∞ÔºàÊîØÊåÅÊú¨Âú∞Ë∑ØÂæÑÊàñÂõæÁâáURLÔºâÔºåÂç≥ÂèØÂÆûÁé∞ÂõæÁâáÈ£éÊ†ºËûçÂêà„ÄÅÂèÇËÄÉÂõæÁîüÊàêÁ≠âÈ´òÁ∫ßÁé©Ê≥ï„ÄÇ\n\n#### Á§∫‰æãÔºö\n\n```javascript\n// ÂèÇËÄÉÂõæÁâáÊ∑∑ÂêàÁîüÊàê\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"Ê¢µÈ´òÈ£éÊ†ºÁöÑÁå´\",\n    filePath: \"./test.png\", // Êú¨Âú∞ÂõæÁâáË∑ØÂæÑ\n    sample_strength: 0.6\n  }\n});\n```\n\nÊàñ\n\n```javascript\n// ‰ΩøÁî®ÁΩëÁªúÂõæÁâá‰Ωú‰∏∫ÂèÇËÄÉ\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"Êú™Êù•ÂüéÂ∏Ç\",\n    filePath: \"https://example.com/your-image.png\"\n  }\n});\n```\n\n### ÊîØÊåÅÁöÑÊ®°Âûã\n\nÊúçÂä°Âô®ÊîØÊåÅ‰ª•‰∏ãÂç≥Ê¢¶AIÊ®°ÂûãÔºö\n\n- ÂõæÁâáÊ®°Âûã\n- `jimeng-3.1`ÔºöÂç≥Ê¢¶Á¨¨‰∏â‰ª£Ê®°ÂûãÔºå‰∏∞ÂØåÁöÑÁæéÂ≠¶Â§öÊ†∑ÊÄßÔºåÁîªÈù¢Êõ¥È≤úÊòéÁîüÂä® ÔºàÈªòËÆ§Ôºâ\n- `jimeng-3.0`ÔºöÂç≥Ê¢¶Á¨¨‰∏â‰ª£Ê®°ÂûãÔºåÊïàÊûúÊõ¥Â•ΩÔºåÊîØÊåÅÊõ¥Âº∫ÁöÑÂõæÂÉèÁîüÊàêËÉΩÂäõ\n- `jimeng-2.1`ÔºöÂç≥Ê¢¶2.1ÁâàÊú¨Ê®°ÂûãÔºåÈªòËÆ§Ê®°Âûã\n- `jimeng-2.0-pro`ÔºöÂç≥Ê¢¶2.0 ProÁâàÊú¨\n- `jimeng-2.0`ÔºöÂç≥Ê¢¶2.0Ê†áÂáÜÁâàÊú¨\n- `jimeng-1.4`ÔºöÂç≥Ê¢¶1.4ÁâàÊú¨\n- `jimeng-xl-pro`ÔºöÂç≥Ê¢¶XL ProÁâπÊÆäÁâàÊú¨\n- ËßÜÈ¢ëÊ®°Âûã\n- `jimeng-video-3.0-pro`ÔºöÂç≥Ê¢¶ËßÜÈ¢ë3.0 ProÊ®°ÂûãÔºåÈÄÇÂêàÈ´òË¥®ÈáèËßÜÈ¢ëÁîüÊàê\n- `jimeng-video-3.0`ÔºöÂç≥Ê¢¶ËßÜÈ¢ë3.0Ê†áÂáÜÊ®°ÂûãÔºå‰∏ªÂäõËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÔºàÈªòËÆ§Ôºâ\n- `jimeng-video-2.0-pro`ÔºöÂç≥Ê¢¶ËßÜÈ¢ë2.0 ProÊ®°ÂûãÔºåÂÖºÂÆπÊÄßÂ•ΩÔºåÈÄÇÂêàÂ§öÂú∫ÊôØ\n- `jimeng-video-2.0`ÔºöÂç≥Ê¢¶ËßÜÈ¢ë2.0Ê†áÂáÜÊ®°ÂûãÔºåÈÄÇÂêàÂü∫Á°ÄËßÜÈ¢ëÁîüÊàê\n\n### ÊäÄÊúØÂÆûÁé∞\n\n- Áõ¥Êé•Ë∞ÉÁî®Âç≥Ê¢¶ÂÆòÊñπAPIÔºåÊó†ÈúÄÁ¨¨‰∏âÊñπÊúçÂä°\n- ÈÄÜÂêëÂ∑•Á®ãAPIË∞ÉÁî®ÊµÅÁ®ãÔºåÂÆûÁé∞ÂÆåÊï¥ÁöÑÂõæÂÉèÁîüÊàêËøáÁ®ã\n- ÊîØÊåÅÁßØÂàÜËá™Âä®È¢ÜÂèñÂíå‰ΩøÁî®\n- Âü∫‰∫éÈù¢ÂêëÂØπË±°ËÆæËÆ°ÔºåÂ∞ÜAPIÂÆûÁé∞Â∞ÅË£Ö‰∏∫Á±ª\n- ËøîÂõûÈ´òË¥®ÈáèÂõæÂÉèURLÂàóË°®\n- ÊîØÊåÅÂõæÁâá‰∏ä‰º†ÔºåËá™Âä®Â§ÑÁêÜÊú¨Âú∞/ÁΩëÁªúÂõæÁâáÔºåËá™Âä®ÂàáÊç¢Ê∑∑ÂêàÊ®°Âûã\n- ÂõæÁâáÊ∑∑ÂêàÊó∂Ëá™Âä®‰∏ä‰º†ÂõæÁâáÂà∞Âç≥Ê¢¶‰∫ëÁ´ØÔºåÊµÅÁ®ãÂÖ®Ëá™Âä®\n\n### ‰ΩøÁî®Á§∫‰æã\n\nÈÄöËøáMCPÂçèËÆÆË∞ÉÁî®ÂõæÂÉèÁîüÊàêÂäüËÉΩÔºö\n\n```javascript\n// ÁîüÊàêÂõæÂÉèÔºàÊñáÊú¨ÁîüÊàêÔºâ\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"‰∏ÄÂè™ÂèØÁà±ÁöÑÁå´Âí™Âú®ËçâÂú∞‰∏ä\",\n    model: \"jimeng-3.0\",\n    width: 1024,\n    height: 1024,\n    sample_strength: 0.7,\n    negative_prompt: \"Ê®°Á≥äÔºåÊâ≠Êõ≤Ôºå‰ΩéË¥®Èáè\"\n  }\n});\n\n// ÁîüÊàêÂõæÂÉèÔºàÂõæÁâáÊ∑∑Âêà/ÂèÇËÄÉÂõæÁîüÊàêÔºâ\nclient.callTool({\n  name: \"generateImage\",\n  arguments: {\n    prompt: \"Êú™Êù•ÂüéÂ∏Ç\",\n    filePath: \"https://example.com/your-image.png\"\n  }\n});\n```\n\n## ÂìçÂ∫îÊ†ºÂºè\n\nAPIÂ∞ÜËøîÂõûÁîüÊàêÁöÑÂõæÂÉèURLÊï∞ÁªÑÔºåÂèØ‰ª•Áõ¥Êé•Âú®ÂêÑÁ±ªÂÆ¢Êà∑Á´Ø‰∏≠ÊòæÁ§∫Ôºö\n\n```javascript\n[\n  \"https://example.com/generated-image-1.jpg\",\n  \"https://example.com/generated-image-2.jpg\",\n  \"https://example.com/generated-image-3.jpg\",\n  \"https://example.com/generated-image-4.jpg\"\n]\n```\n\n## ËµÑÊ∫ê\n\nÊúçÂä°Âô®ËøòÊèê‰æõ‰∫Ü‰ª•‰∏ã‰ø°ÊÅØËµÑÊ∫êÔºö\n\n- `greeting://{name}` - Êèê‰æõ‰∏™ÊÄßÂåñÈóÆÂÄô\n- `info://server` - Êèê‰æõÊúçÂä°Âô®Âü∫Êú¨‰ø°ÊÅØ\n- `jimeng-ai://info` - Êèê‰æõÂç≥Ê¢¶AIÂõæÂÉèÁîüÊàêÊúçÂä°ÁöÑ‰ΩøÁî®ËØ¥Êòé\n\n## CursorÊàñClaude‰ΩøÁî®ÊèêÁ§∫\n\nÂú®CursorÊàñClaude‰∏≠Ôºå‰Ω†ÂèØ‰ª•ËøôÊ†∑‰ΩøÁî®JimengÂõæÂÉèÁîüÊàêÊúçÂä°Ôºö\n\n1. Á°Æ‰øùÂ∑≤ÁªèÈÖçÁΩÆ‰∫ÜMCPÊúçÂä°Âô®\n2. ÊèêÁ§∫Claude/CursorÁîüÊàêÂõæÂÉèÔºå‰æãÂ¶ÇÔºö\n   ```\n   ËØ∑ÁîüÊàê‰∏ÄÂº†ÂÜôÂÆûÈ£éÊ†ºÁöÑÊó•ËêΩ‰∏ãÁöÑÂ±±ËÑâÂõæÁâá\n   ```\n3. Claude/Cursor‰ºöË∞ÉÁî®Jimeng MCPÊúçÂä°Âô®ÁîüÊàêÂõæÂÉèÂπ∂ÊòæÁ§∫\n\n## Â∏∏ËßÅÈóÆÈ¢ò\n\n1. **ÂõæÂÉèÁîüÊàêÂ§±Ë¥•**\n   - Ê£ÄÊü•JIMENG_API_TOKENÊòØÂê¶Ê≠£Á°ÆÈÖçÁΩÆ\n   - ÁôªÂΩïÂç≥Ê¢¶ÂÆòÁΩëÊ£ÄÊü•Ë¥¶Âè∑ÁßØÂàÜÊòØÂê¶ÂÖÖË∂≥\n   - Â∞ùËØïÊõ¥Êç¢ÊèêÁ§∫ËØçÔºåÈÅøÂÖçÊïèÊÑüÂÜÖÂÆπ\n   - Ëã•‰∏∫ÂõæÁâáÊ∑∑ÂêàÔºåÊ£ÄÊü•filePathË∑ØÂæÑ/URLÊòØÂê¶ÊúâÊïà„ÄÅÂõæÁâáÊòØÂê¶ÂèØËÆøÈóÆ\n   - ÁΩëÁªúÂõæÁâáÂª∫ËÆÆ‰ΩøÁî®httpsÁõ¥ÈìæÔºåÈÅøÂÖçÈò≤ÁõóÈìæ/ÊùÉÈôêÈóÆÈ¢ò\n\n2. **ÊúçÂä°Âô®Êó†Ê≥ïÂêØÂä®**\n   - Á°Æ‰øùÂ∑≤ÂÆâË£ÖÊâÄÊúâ‰æùËµñ\n   - Á°Æ‰øùÁéØÂ¢ÉÂèòÈáèÊ≠£Á°ÆËÆæÁΩÆ\n   - Ê£ÄÊü•Node.jsÁâàÊú¨ÊòØÂê¶‰∏∫14.0ÊàñÊõ¥È´ò\n\n## ËÆ∏ÂèØËØÅ\n\nMIT \n\n## Âç≥Ê¢¶AIËßÜÈ¢ëÁîüÊàê\n\nÊú¨MCPÊúçÂä°Âô®ÈõÜÊàê‰∫ÜÂç≥Ê¢¶AIËßÜÈ¢ëÁîüÊàêAPIÔºåÊèê‰æõËßÜÈ¢ëÁîüÊàêÂ∑•ÂÖ∑Ôºö\n\n`generateVideo` - Êèê‰∫§ËßÜÈ¢ëÁîüÊàêËØ∑Ê±ÇÂπ∂ËøîÂõûËßÜÈ¢ëURL\n- ÂèÇÊï∞Ôºö\n  - `prompt`ÔºöÁîüÊàêËßÜÈ¢ëÁöÑÊñáÊú¨ÊèèËø∞ÔºàÂøÖÂ°´Ôºâ\n  - `filePath`ÔºöÈ¶ñÂ∏ßÂíåÂ∞æÂ∏ßÂõæÁâáË∑ØÂæÑÔºåÊîØÊåÅÊï∞ÁªÑÔºåÊúÄÂ§ö2‰∏™ÂÖÉÁ¥†ÔºåÂàÜÂà´‰∏∫È¶ñÂ∏ßÂíåÂ∞æÂ∏ßÔºàÂèØÈÄâÔºâ\n  - `model`ÔºöÊ®°ÂûãÂêçÁß∞ÔºåÈªòËÆ§jimeng-video-3.0ÔºàÂèØÈÄâÔºâ\n  - `resolution`ÔºöÂàÜËæ®ÁéáÔºåÂèØÈÄâ720pÊàñ1080pÔºåÈªòËÆ§720pÔºàÂèØÈÄâÔºâ\n  - `width`ÔºöËßÜÈ¢ëÂÆΩÂ∫¶ÔºåÈªòËÆ§ÂÄºÔºö1024ÔºàÂèØÈÄâÔºâ\n  - `height`ÔºöËßÜÈ¢ëÈ´òÂ∫¶ÔºåÈªòËÆ§ÂÄºÔºö1024ÔºàÂèØÈÄâÔºâ\n  - `refresh_token`ÔºöÂç≥Ê¢¶API‰ª§ÁâåÔºàÂèØÈÄâÔºåÈÄöÂ∏∏‰ªéÁéØÂ¢ÉÂèòÈáèËØªÂèñÔºâ\n  - `req_key`ÔºöËá™ÂÆö‰πâÂèÇÊï∞ÔºåÂÖºÂÆπÊóßÊé•Âè£ÔºàÂèØÈÄâÔºâ\n\n\u003e **Ê≥®ÊÑèÔºö**\n\u003e - `filePath` ÊîØÊåÅÊú¨Âú∞ÁªùÂØπ/Áõ∏ÂØπË∑ØÂæÑÂíåÂõæÁâáURL„ÄÇ\n\u003e - Ëã•ÊåáÂÆö `filePath`ÔºåÂèØÂÆûÁé∞È¶ñÂ∏ß/Â∞æÂ∏ßÂÆöÂà∂ÁöÑËßÜÈ¢ëÁîüÊàê„ÄÇ\n\u003e - ÁΩëÁªúÂõæÁâáÈúÄ‰øùËØÅÂèØÂÖ¨ÂºÄËÆøÈóÆ„ÄÇ\n\n### ‰ΩøÁî®Á§∫‰æã\n\nÈÄöËøáMCPÂçèËÆÆË∞ÉÁî®ËßÜÈ¢ëÁîüÊàêÂäüËÉΩÔºö\n\n```javascript\n// ÁîüÊàêËßÜÈ¢ëÔºàÊñáÊú¨ÁîüÊàêÔºâ\nclient.callTool({\n  name: \"generateVideo\",\n  arguments: {\n    prompt: \"‰∏ÄÂè™Â∞èÁãóÂú®ËçâÂú∞‰∏äÂ•îË∑ëÔºåÈò≥ÂÖâÊòéÂ™öÔºåÈ´òÊ∏Ö\",\n    model: \"jimeng-video-3.0\",\n    resolution: \"720p\",\n    width: 1024,\n    height: 1024\n  }\n});\n\n// ÁîüÊàêËßÜÈ¢ëÔºàÈ¶ñÂ∏ß/Â∞æÂ∏ßÂÆöÂà∂Ôºâ\nclient.callTool({\n  name: \"generateVideo\",\n  arguments: {\n    prompt: \"ÂüéÂ∏ÇÂ§úÊôØÂª∂Êó∂ÊëÑÂΩ±\",\n    filePath: [\"./first.png\", \"./last.png\"],\n    resolution: \"1080p\"\n  }\n});\n```\n\n## ËßÜÈ¢ëÂìçÂ∫îÊ†ºÂºè\n\nAPIÂ∞ÜËøîÂõûÁîüÊàêÁöÑËßÜÈ¢ëURLÂ≠óÁ¨¶‰∏≤ÔºåÂèØ‰ª•Áõ¥Êé•Âú®ÂêÑÁ±ªÂÆ¢Êà∑Á´Ø‰∏≠Êí≠ÊîæÔºö\n\n```javascript\n\"https://example.com/generated-video.mp4\"\n``` \n\n\n## ÊîØÊåÅapiÊúçÂä°ÂêØÂä®\n\nÂ¶ÇÈúÄ‰ª•APIÊúçÂä°ÊñπÂºèÂêØÂä®ÔºàÈÄÇÂêàHTTPÊé•Âè£Ë∞ÉÁî®ÔºâÔºö\n\n```bash\ncp .env.example .env   # Â§çÂà∂ÁéØÂ¢ÉÂèòÈáèÊ®°Êùø\n# Ê†πÊçÆÈúÄË¶ÅÁºñËæë.envÔºåÂ°´ÂÜôJIMENG_API_TOKENÁ≠âÈÖçÁΩÆ\n\n# ÂêØÂä®APIÊúçÂä°\nyarn start:api\n```\n\nAPIÊúçÂä°ÂêØÂä®ÂêéÂ∞ÜÁõëÂê¨ÈÖçÁΩÆÁ´ØÂè£ÔºåÊîØÊåÅÈÄöËøáHTTPÊé•Âè£Ë∞ÉÁî®Âç≥Ê¢¶AIÂõæÂÉèÂíåËßÜÈ¢ëÁîüÊàêÂäüËÉΩ„ÄÇ \n",
      "stars": 40,
      "updated_at": "2025-09-18T10:20:11Z",
      "url": "https://github.com/c-rick/jimeng-mcp"
    },
    "catalystneuro--mcp_read_images": {
      "category": "image-and-video-generation",
      "description": "Analyze images using OpenRouter vision models like Claude-3.5-sonnet and Claude-3-opus through a simple API interface.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/catalystneuro.webp",
      "keywords": [
        "mcp_read_images",
        "catalystneuro",
        "vision",
        "catalystneuro mcp_read_images",
        "mcp_read_images analyze",
        "analyze images"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp_read_images",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "catalystneuro",
      "readme_content": "# MCP Read Images\n\nAn MCP server for analyzing images using OpenRouter vision models. This server provides a simple interface to analyze images using various vision models like Claude-3.5-sonnet and Claude-3-opus through the OpenRouter API.\n\n## Installation\n\n```bash\nnpm install @catalystneuro/mcp_read_images\n```\n\n## Configuration\n\nThe server requires an OpenRouter API key. You can get one from [OpenRouter](https://openrouter.ai/keys).\n\nAdd the server to your MCP settings file (usually located at `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json` for VSCode):\n\n```json\n{\n  \"mcpServers\": {\n    \"read_images\": {\n      \"command\": \"read_images\",\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"OPENROUTER_MODEL\": \"anthropic/claude-3.5-sonnet\"  // optional, defaults to claude-3.5-sonnet\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides a single tool `analyze_image` that can be used to analyze images:\n\n```typescript\n// Basic usage with default model\nuse_mcp_tool({\n  server_name: \"read_images\",\n  tool_name: \"analyze_image\",\n  arguments: {\n    image_path: \"/path/to/image.jpg\",\n    question: \"What do you see in this image?\"  // optional\n  }\n});\n\n// Using a specific model for this call\nuse_mcp_tool({\n  server_name: \"read_images\",\n  tool_name: \"analyze_image\",\n  arguments: {\n    image_path: \"/path/to/image.jpg\",\n    question: \"What do you see in this image?\",\n    model: \"anthropic/claude-3-opus-20240229\"  // overrides default and settings\n  }\n});\n```\n\n### Model Selection\n\nThe model is selected in the following order of precedence:\n1. Model specified in the tool call (`model` argument)\n2. Model specified in MCP settings (`OPENROUTER_MODEL` environment variable)\n3. Default model (anthropic/claude-3.5-sonnet)\n\n### Supported Models\n\nThe following OpenRouter models have been tested:\n- anthropic/claude-3.5-sonnet\n- anthropic/claude-3-opus-20240229\n\n## Features\n\n- Automatic image resizing and optimization\n- Configurable model selection\n- Support for custom questions about images\n- Detailed error messages\n- Automatic JPEG conversion and quality optimization\n\n## Error Handling\n\nThe server handles various error cases:\n- Invalid image paths\n- Missing API keys\n- Network errors\n- Invalid model selections\n- Image processing errors\n\nEach error will return a descriptive message to help diagnose the issue.\n\n## Development\n\nTo build from source:\n\n```bash\ngit clone https://github.com/catalystneuro/mcp_read_images.git\ncd mcp_read_images\nnpm install\nnpm run build\n```\n\n## License\n\nMIT License. See [LICENSE](LICENSE) for details.\n",
      "stars": 8,
      "updated_at": "2025-07-14T12:27:13Z",
      "url": "https://github.com/catalystneuro/mcp_read_images"
    },
    "champierre--image-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Analyzes images by accepting URLs or local file paths, providing detailed insights through advanced image recognition powered by the GPT-4o-mini model. Validates image URLs and supports loading images from local files and Base64 encoding.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/champierre.webp",
      "keywords": [
        "images",
        "image",
        "encoding",
        "image mcp",
        "image urls",
        "analyzes images"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "image-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "champierre",
      "readme_content": "# image-mcp-server\n\n[Êó•Êú¨Ë™û„ÅÆ README](README.ja.md)\n\n\u003ca href=\"https://glama.ai/mcp/servers/@champierre/image-mcp-server\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@champierre/image-mcp-server/badge\" alt=\"Image Analysis MCP Server\" /\u003e\n\u003c/a\u003e\n\n[![smithery badge](https://smithery.ai/badge/@champierre/image-mcp-server)](https://smithery.ai/server/@champierre/image-mcp-server)\nAn MCP server that receives image URLs or local file paths and analyzes image content using the GPT-4o-mini model.\n\n## Features\n\n- Receives image URLs or local file paths as input and provides detailed analysis of the image content\n- High-precision image recognition and description using the GPT-4o-mini model\n- Image URL validity checking\n- Image loading from local files and Base64 encoding\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Analysis Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@champierre/image-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @champierre/image-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/champierre/image-mcp-server.git # or your forked repository\ncd image-mcp-server\n\n# Install dependencies\nnpm install\n\n# Compile TypeScript\nnpm run build\n```\n\n## Configuration\n\nTo use this server, you need an OpenAI API key. Set the following environment variable:\n\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n## MCP Server Configuration\n\nTo use with tools like Cline, add the following settings to your MCP server configuration file:\n\n### For Cline\n\nAdd the following to `cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-analysis\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your_openai_api_key\"\n      }\n    }\n  }\n}\n```\n\n### For Claude Desktop App\n\nAdd the following to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-analysis\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"OPENAI_API_KEY\": \"your_openai_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nOnce the MCP server is configured, the following tools become available:\n\n- `analyze_image`: Receives an image URL and analyzes its content.\n- `analyze_image_from_path`: Receives a local file path and analyzes its content.\n\n### Usage Examples\n\n**Analyzing from URL:**\n\n```\nPlease analyze this image URL: https://example.com/image.jpg\n```\n\n**Analyzing from local file path:**\n\n```\nPlease analyze this image: /path/to/your/image.jpg\n```\n\n### Note: Specifying Local File Paths\n\nWhen using the `analyze_image_from_path` tool, the AI assistant (client) must specify a **valid file path in the environment where this server is running**.\n\n- **If the server is running on WSL:**\n  - If the AI assistant has a Windows path (e.g., `C:\\...`), it needs to convert it to a WSL path (e.g., `/mnt/c/...`) before passing it to the tool.\n  - If the AI assistant has a WSL path, it can pass it as is.\n- **If the server is running on Windows:**\n  - If the AI assistant has a WSL path (e.g., `/home/user/...`), it needs to convert it to a UNC path (e.g., `\\\\wsl$\\Distro\\...`) before passing it to the tool.\n  - If the AI assistant has a Windows path, it can pass it as is.\n\n**Path conversion is the responsibility of the AI assistant (or its execution environment).** The server will try to interpret the received path as is.\n\n### Note: Type Errors During Build\n\nWhen running `npm run build`, you may see an error (TS7016) about missing TypeScript type definitions for the `mime-types` module.\n\n```\nsrc/index.ts:16:23 - error TS7016: Could not find a declaration file for module 'mime-types'. ...\n```\n\nThis is a type checking error, and since the JavaScript compilation itself succeeds, it **does not affect the server's execution**. If you want to resolve this error, install the type definition file as a development dependency.\n\n```bash\nnpm install --save-dev @types/mime-types\n# or\nyarn add --dev @types/mime-types\n```\n\n## Development\n\n```bash\n# Run in development mode\nnpm run dev\n```\n\n## License\n\nMIT\n",
      "stars": 6,
      "updated_at": "2025-08-09T18:23:14Z",
      "url": "https://github.com/champierre/image-mcp-server"
    },
    "chenyeju295--mcp_generate_images": {
      "category": "image-and-video-generation",
      "description": "An image generation service that integrates with Cursor IDE, offering features such as customizable image aspect ratios, high-quality image generation, and batch processing capabilities.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/chenyeju295.webp",
      "keywords": [
        "mcp_generate_images",
        "image",
        "cursor",
        "chenyeju295 mcp_generate_images",
        "mcp_generate_images image",
        "image generation"
      ],
      "language": "Python",
      "license": "No License",
      "name": "mcp_generate_images",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "chenyeju295",
      "readme_content": "# AI ÂõæÂÉèÁîüÊàêÊúçÂä°\n\nÂü∫‰∫éÁÅ´Â±±ÂºïÊìéÔºàÊäñÈü≥Ë±ÜÂåÖÔºâÁöÑÂõæÂÉèÁîüÊàêÊúçÂä°Ôºå‰∏ìÈó®ËÆæËÆ°Áî®‰∫é‰∏é Cursor MCP ÊúçÂä°ÈõÜÊàê„ÄÇÊîØÊåÅËá™ÂÆö‰πâÂõæÁâáÂÆΩÈ´òÊØî„ÄÅ‰øùÂ≠òË∑ØÂæÑÁ≠âÂäüËÉΩÔºåÊèê‰æõÈ´òË¥®ÈáèÂõæÂÉèÁîüÊàêËÉΩÂäõ„ÄÇ\n\n## ÂäüËÉΩÁâπÁÇπ\n\n- ÊîØÊåÅÈ´òË¥®ÈáèÂõæÂÉèÁîüÊàê\n- Â§öÁßçÂ∏∏ËßÅÂÆΩÈ´òÊØîÊîØÊåÅÔºà1:1„ÄÅ4:3„ÄÅ16:9„ÄÅ3:4„ÄÅ9:16Ôºâ\n- ÁÅ´Â±±ÂºïÊìéË±ÜÂåÖÊ®°ÂûãÔºàdoubao-seedream-3-0-t2i-250415Ôºâ\n- Ëá™Âä®ÈáçËØïÂíåËØ¶ÁªÜÈîôËØØÂ§ÑÁêÜ\n- ÂÆåÊï¥ÁöÑË∑ØÂæÑÂíåÊùÉÈôêÈ™åËØÅ\n- ËØ¶ÁªÜÁöÑÈîôËØØÊèêÁ§∫ÂíåÊó•Âøó\n- ÂºÇÊ≠•Â§ÑÁêÜÊîØÊåÅ\n\n## ÁéØÂ¢ÉÂáÜÂ§á\n\n### 1. Python ÁéØÂ¢É\n\n- Python 3.10+\n- ‰∏ãËΩΩÂú∞ÂùÄÔºö \u003chttps://www.python.org/downloads/\u003e\n\n- Êé®Ëçê‰ΩøÁî® pyenv ÁÆ°ÁêÜ Python ÁâàÊú¨Ôºö\n\n```bash\n# macOS ÂÆâË£Ö pyenv\nbrew install pyenv\n\n# ÂÆâË£Ö Python\npyenv install 3.13.2\npyenv global 3.13.2\n```\n\n### 2. Nodejs ÁéØÂ¢É\n\n- ‰∏ãËΩΩÂú∞ÂùÄÔºö \u003chttps://nodejs.org/zh-cn\u003e  \n\n### 3. uv ÂåÖÁÆ°ÁêÜÂ∑•ÂÖ∑\n\nuv ÊòØ‰∏Ä‰∏™Âø´ÈÄüÁöÑ Python ÂåÖÁÆ°ÁêÜÂô®ÔºåÈúÄË¶ÅÂÖàÂÆâË£ÖÔºö\n\n```bash\n# macOS ÂÆâË£Ö uv\nbrew install uv\n\n# ÊàñËÄÖ‰ΩøÁî® pip ÂÆâË£Ö\npip install uv\n```\n\n### 4. ÁÅ´Â±±ÂºïÊìé API ÂØÜÈí•\n\n1. ËÆøÈóÆ [ÁÅ´Â±±ÂºïÊìéÊñπËàüÂ§ßÊ®°ÂûãÊúçÂä°](https://console.volcengine.com/ark)\n2. Ê≥®ÂÜå/ÁôªÂΩïË¥¶Âè∑\n3. ÂàõÂª∫Êñ∞ÁöÑ API ÂØÜÈí•\n4. Â§çÂà∂ÂØÜÈí•Âπ∂‰øùÂ≠òÔºåÊ†ºÂºèÂ¶ÇÔºö`YOUR_API_KEY`\n\n### 5. Cursor\n\n- ‰∏ãËΩΩÂπ∂ÂÆâË£Ö [Cursor IDE](https://cursor.sh/)\n- Á°Æ‰øù Cursor Â∑≤Ê≠£Á°ÆÈÖçÁΩÆ Python ÁéØÂ¢É\n\n## ÂÆâË£ÖÈÖçÁΩÆ\n\n### 1. ÂÖãÈöÜÈ°πÁõÆ\n\n```bash\ngit clone https://github.com/chenyeju295/mcp_generate_images.git\ncd mcp_generate_images\n```\n\n### 2. ÂÆâË£Ö‰æùËµñ(cd Âà∞mcp_generate_images ÂÆâË£Ö)\n \n```bash\npython3 -m pip install fastmcp requests 'volcengine-python-sdk[ark]'\n```\n\nÊàñËÄÖ‰ΩøÁî®requirements.txtÊñá‰ª∂Ôºö\n\n```bash\npip install -r requirements.txt\n```\n\nÂá∫Áé∞ËØÅ‰π¶ÈóÆÈ¢òÂèØ‰ª•‰ΩøÁî®Ôºö\n\n```bash\npython3 -m pip install fastmcp requests 'volcengine-python-sdk[ark]' --trusted-host pypi.org --trusted-host files.pythonhosted.org --upgrade --force-reinstall --no-cache-dir\n```\n\ntips: ÈúÄÁ°Æ‰øùÂÆâË£ÖÊàêÂäüÔºåÂê¶ÂàôÈÖçÁΩÆMCP ÊúçÂä°‰ºöÊä•Á∫¢„ÄÇ\n\n### 3. ÈÖçÁΩÆ API ÂØÜÈí•\n\nËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàÊé®ËçêÊñπÂºèÔºâÔºö\n\n```bash\nexport ARK_API_KEY=your_api_key_here\n```\n\nÊàñËÄÖÂú® ~/.bashrc Êàñ ~/.zshrc ‰∏≠Ê∑ªÂä†Ôºö\n\n```bash\necho 'export ARK_API_KEY=your_api_key_here' \u003e\u003e ~/.zshrc\nsource ~/.zshrc\n```\n\nÈ™åËØÅÁéØÂ¢ÉÂèòÈáèÂ∑≤ËÆæÁΩÆÔºö\n\n```bash\necho $ARK_API_KEY\n```\n\n### 4. ÈÖçÁΩÆÊúçÂä°\n\nÂú® `mcp_server.py` ‰∏≠ÂèØ‰ª•‰øÆÊîπ‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n```python\nCONFIG = {\n    \"api\": {\n        \"base_url\": \"https://ark.cn-beijing.volces.com/api/v3\",\n        \"model\": \"doubao-seedream-3-0-t2i-250415\",\n        \"timeout\": 120,\n        \"max_retries\": 3,\n        \"retry_delay\": 5\n    },\n    \"image\": {\n        \"max_width\": 1024,   \n        \"max_height\": 1024, \n        \"default_width\": 1024,\n        \"default_height\": 1024,\n        \"max_batch_size\": 1\n    },\n    \"output\": {\n        \"base_folder\": \"‰Ω†ÁöÑÈªòËÆ§‰øùÂ≠òË∑ØÂæÑ\",\n        \"allowed_extensions\": [\".png\", \".jpg\", \".jpeg\"],\n        \"default_extension\": \".png\"\n    }\n}\n```\n\n## ËøêË°åÊúçÂä°\n\nÂºÄÂèëÊ®°ÂºèËøêË°åÔºàÂ∏¶Ë∞ÉËØïÁïåÈù¢ÔºâÔºö\n\n```bash\nuv run --with fastmcp fastmcp dev /Users/username/Documents/mcp_generate_images/mcp_server.py\n```\n\n## Âú® Cursor ‰∏≠‰ΩøÁî®\n \n### 1. Âú® Cursor ‰∏≠ÂºïÂÖ• MCP ÊúçÂä°\n\nÂú® Cursor ÁöÑ MCP ÈÖçÁΩÆ‰∏≠Ê∑ªÂä†Ôºö\n\n```json\n{\n  \"mcpServers\": {\n    \"generate_images\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"fastmcp\",\n        \"fastmcp\",\n        \"run\",\n        \"/Users/chenyeju/Documents/github/mcp_generate_images/mcp_server.py\"\n      ]\n    } \n  }\n}\n```\n\n### 3. ÊúçÂä°ËøêË°åÊàêÂäüÁ§∫‰æã\n\n\n\n### 4. Âú® Cursor Composer ÁöÑ agent Ê®°Âºè‰∏ã‰ΩøÁî®\n\n\n\n## ÂèÇÊï∞ËØ¥Êòé\n\nÂõæÂÉèÁîüÊàêÂ∑•ÂÖ∑ÊîØÊåÅ‰ª•‰∏ãÂèÇÊï∞Ôºö\n\n| ÂèÇÊï∞Âêç | Á±ªÂûã | ÂøÖÂ°´ | ËØ¥Êòé |\n|-------|------|------|------|\n| prompt | Â≠óÁ¨¶‰∏≤ | ÊòØ | ÂõæÁâáÁîüÊàêÊèêÁ§∫ËØçÔºåÂª∫ËÆÆ‰∏çË∂ÖËøá500Â≠óÁ¨¶ |\n| file_name | Â≠óÁ¨¶‰∏≤ | ÊòØ | ‰øùÂ≠òÁöÑÊñá‰ª∂Âêç(‰∏çÂê´Ë∑ØÂæÑÔºåÂ¶ÇÊûúÊ≤°ÊúâÂêéÁºÄÂàôÈªòËÆ§‰ΩøÁî®.png) |\n| save_folder | Â≠óÁ¨¶‰∏≤ | ÊòØ | ‰øùÂ≠òÁõÆÂΩïÁöÑÁªùÂØπË∑ØÂæÑ |\n| aspect_ratio | Â≠óÁ¨¶‰∏≤ | Âê¶ | ÂõæÁâáÁöÑÂÆΩÈ´òÊØîÔºåÊîØÊåÅ '1:1', '4:3', '16:9', '3:4', '9:16'„ÄÇÈªòËÆ§‰∏∫'1:1' |\n\n\n## ‰ΩøÁî®Á§∫‰æã\n\n```\nÁîüÊàê‰∏ÄÂº†ÂÆΩÈ´òÊØî‰∏∫16:9ÁöÑÈ£éÊôØÂõæÁâáÔºö\n\ngenerate_image(\n  prompt=\"A beautiful mountain landscape with sunset\", \n  file_name=\"landscape.png\", \n  save_folder=\"/Users/username/Documents/images\", \n  aspect_ratio=\"16:9\"\n)\n```\n\n## ‰ΩøÁî®Ê≥®ÊÑè‰∫ãÈ°π\n\n1. **Ê®°Âûã**Ôºö‰ΩøÁî®ÁÅ´Â±±ÂºïÊìéË±ÜÂåÖÊ®°ÂûãÔºàdoubao-seedream-3-0-t2i-250415ÔºâÔºåÊîØÊåÅÊúÄÂ§ß1024x1024ÁöÑÂ∞∫ÂØ∏„ÄÇ\n2. **ÈïøÂÆΩÊØî**ÔºöÂª∫ËÆÆ‰ΩøÁî®1:1ÁöÑÂÆΩÈ´òÊØîÔºàÊ≠£ÊñπÂΩ¢ÂõæÁâáÔºâÔºå‰æãÂ¶Ç512x512Êàñ1024x1024Ôºå‰ª•Ëé∑ÂæóÊúÄ‰Ω≥ÊïàÊûúÂíåÁîüÊàêÈÄüÂ∫¶„ÄÇ\n3. **ÊèêÁ§∫ËØç**ÔºöÁÆÄÊ¥ÅÊòé‰∫ÜÁöÑÊèêÁ§∫ËØçÈÄöÂ∏∏ËÉΩËé∑ÂæóÊõ¥Â•ΩÁöÑÁªìÊûúÔºåÂ∞ΩÈáè‰∏çË∂ÖËøá500Â≠óÁ¨¶„ÄÇÊîØÊåÅ‰∏≠ÊñáÊèêÁ§∫ËØç„ÄÇ\n4. **Ë∂ÖÊó∂ÈóÆÈ¢ò**ÔºöÂØπ‰∫éÂ§çÊùÇÊèêÁ§∫ËØçÊàñÈùûÊ≠£ÊñπÂΩ¢ÂõæÁâáÔºåÁîüÊàêÂèØËÉΩÈúÄË¶ÅÊõ¥ÈïøÊó∂Èó¥ÔºåÊúâÊó∂‰ºöÂØºËá¥Ë∂ÖÊó∂ÈîôËØØ„ÄÇ\n5. **APIÈôêÂà∂**ÔºöÁÅ´Â±±ÂºïÊìéAPIÊØèÊ¨°Âè™ÁîüÊàê‰∏ÄÂº†ÂõæÁâáÔºåÁõ∏ÊØî‰πãÂâçÁöÑÊâπÈáèÁîüÊàêÊúâÊâÄ‰∏çÂêå„ÄÇ\n\n## ÈîôËØØÊéíÊü•\n\nÂ¶ÇÊûúÈÅáÂà∞ÈóÆÈ¢òÔºåËØ∑Ê£ÄÊü•Ôºö\n\n1. ÊúçÂä°ÊòØÂê¶Ê≠£Â∏∏ËøêË°å\n2. ‰øùÂ≠òË∑ØÂæÑÊòØÂê¶Ê≠£Á°ÆÔºàÂøÖÈ°ªÊòØÁªùÂØπË∑ØÂæÑÔºâ\n3. ÁõÆÂΩïÊùÉÈôêÊòØÂê¶Ê≠£Á°Æ\n4. ÁΩëÁªúËøûÊé•ÊòØÂê¶Ê≠£Â∏∏\n5. API ÂØÜÈí•ÊòØÂê¶ÊúâÊïà\n6. Python ÁéØÂ¢ÉÊòØÂê¶Ê≠£Á°ÆÈÖçÁΩÆ\n7. uv ÊòØÂê¶Ê≠£Á°ÆÂÆâË£Ö\n8. ‰æùËµñÂåÖÊòØÂê¶ÂÆåÊï¥ÂÆâË£Ö\n\n## Â∏∏ËßÅÈîôËØØÂèäËß£ÂÜ≥ÊñπÊ°à\n\n| ÈîôËØØ‰ø°ÊÅØ | ÂèØËÉΩÂéüÂõ† | Ëß£ÂÜ≥ÊñπÊ°à |\n|---------|---------|---------|\n| \"Êú™ËÉΩÁîüÊàêÂõæÁâá: API ËØ∑Ê±ÇË∂ÖÊó∂\" | ÁΩëÁªúÈóÆÈ¢òÊàñËØ∑Ê±ÇËÄóÊó∂ËøáÈïø | ‰ΩøÁî®Êõ¥ÁÆÄÂçïÁöÑÊèêÁ§∫ËØçÔºåÊ£ÄÊü•ÁΩëÁªúËøûÊé• |\n| \"Êú™ËÉΩÁîüÊàêÂõæÁâá: API Ë∞ÉÁî®È¢ëÁéáÂèóÈôê\" | ÁÅ´Â±±ÂºïÊìéAPIÈ¢ëÁéáÈôêÂà∂ | Á≠âÂæÖÂá†ÂàÜÈíüÂêéÂÜçËØï |\n| \"Êú™ËÉΩÁîüÊàêÂõæÁâá: API ËÆ§ËØÅÂ§±Ë¥•\" | APIÂØÜÈí•Êó†Êïà | Ê£ÄÊü•Âπ∂Êõ¥Êñ∞ÁÅ´Â±±ÂºïÊìéAPIÂØÜÈí• |\n| \"Ê≤°ÊúâÊùÉÈôê‰øùÂ≠òÂõæÁâáÂà∞...\" | ÁõÆÂΩïÊùÉÈôêÈóÆÈ¢ò | Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®‰∏îÊúâÂÜôÂÖ•ÊùÉÈôê |\n| \"‰∏çÊîØÊåÅÁöÑÂÆΩÈ´òÊØî\" | ‰ΩøÁî®‰∫Ü‰∏çÊîØÊåÅÁöÑÂÆΩÈ´òÊØî | ‰ΩøÁî®ÊîØÊåÅÁöÑÂÆΩÈ´òÊØîÔºö'1:1', '4:3', '16:9', '3:4', '9:16' |\n| \"Failed to download generated images\" | ÂõæÁâá‰∏ãËΩΩÂ§±Ë¥• | Ê£ÄÊü•ÁΩëÁªúËøûÊé•ÔºåÁ°Æ‰øùËÉΩËÆøÈóÆÁÅ´Â±±ÂºïÊìéÁöÑÂõæÁâáURL |",
      "stars": 21,
      "updated_at": "2025-08-29T07:27:23Z",
      "url": "https://github.com/chenyeju295/mcp_generate_images"
    },
    "ckz--flux-img-mcp": {
      "category": "image-and-video-generation",
      "description": "Utilize advanced AI models to generate images from textual prompts, enabling users to convert their ideas into visual art. This server facilitates effortless image creation through simple command inputs.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/ckz.webp",
      "keywords": [
        "ai",
        "images",
        "img",
        "generate images",
        "image creation",
        "video generation"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "flux-img-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "ckz",
      "readme_content": "# Flux Image MCP Server\n\nThis MCP server provides image generation capabilities using the Flux Schnell model on Replicate.\n\n## Installation\n\n0. Install the MCP SDK globally:\n```bash\nnpm install -g @modelcontextprotocol/sdk@latest\n```\n\n1. Clone this repository to your MCP servers directory:\n```bash\ncd ~/Documents/Cline/MCP\ngit clone https://github.com/yourusername/flux-img-mcp.git\ncd flux-img-mcp\nnpm install\n```\n\n\n\n2. Build the server:\n```bash\nnpm run build\n```\n\n3. Add the server configuration to your MCP settings file (either global or workspace):\n\n```json\n{\n  \"mcpServers\": {\n    \"flux-img\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/flux-img-mcp/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n## Configuration\n\nThe server requires the following environment variable:\n\n- `REPLICATE_API_TOKEN`: Your Replicate API token. You can get this from your [Replicate account settings](https://replicate.com/account).\n\n## Usage\n\nOnce installed and configured, the server provides the following tool:\n\n### generate_image\n\nGenerates an image using the Flux Schnell model based on a text prompt.\n\nParameters:\n- `prompt` (string, required): Text description of the desired image\n\nExample usage:\n```typescript\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003eflux-img\u003c/server_name\u003e\n\u003ctool_name\u003egenerate_image\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"prompt\": \"A beautiful sunset over mountains\"\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\nThe tool will return a JSON response containing:\n- `status`: The status of the generation request\n- `output`: The URL of the generated image (if successful)\n- `error`: Any error message (if failed)\n\n## Development\n\nTo make changes to the server:\n\n1. Modify the source code in `src/index.ts`\n2. Rebuild the server: `npm run build`\n3. Restart the MCP server for changes to take effect\n\n## Error Handling\n\nThe server includes comprehensive error handling for:\n- Missing API token\n- Invalid parameters\n- API request failures\n- Network issues\n\n## Security\n\n- Never commit your Replicate API token to version control\n- Always provide the token through environment variables\n- The server validates all input parameters before making API requests\n",
      "stars": 1,
      "updated_at": "2025-03-12T05:08:24Z",
      "url": "https://github.com/ckz/flux-img-mcp"
    },
    "ckz--flux-schnell-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate images from text prompts using the Replicate API, enabling users to create customized visuals based on detailed descriptions. The server manages the communication with the API and handles errors effectively.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/ckz.webp",
      "keywords": [
        "replicate",
        "generate",
        "visuals",
        "generate images",
        "video generation",
        "ckz flux"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "flux-schnell-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "ckz",
      "readme_content": "# Flux Schnell MCP Server\n\n‰∏Ä‰∏™Âü∫‰∫éMCPÔºàModel Context ProtocolÔºâÁöÑÊúçÂä°Âô®ÔºåÁî®‰∫éÈÄöËøáReplicate APIË∞ÉÁî®Flux SchnellÊ®°ÂûãÁîüÊàêÂõæÁâá„ÄÇ\n\n## ÂäüËÉΩÁâπÁÇπ\n\n- Êèê‰æõ`generate_image`Â∑•ÂÖ∑Áî®‰∫éÁîüÊàêÂõæÁâá\n- ÊîØÊåÅËá™ÂÆö‰πâÊñáÊú¨ÊèêÁ§∫ËØç\n- Ëá™Âä®Â§ÑÁêÜ‰∏éReplicate APIÁöÑÈÄö‰ø°\n- ÂÆåÊï¥ÁöÑÈîôËØØÂ§ÑÁêÜÂíåÂìçÂ∫î\n\n## ÂâçÁΩÆË¶ÅÊ±Ç\n\n1. Node.js (v14ÊàñÊõ¥È´òÁâàÊú¨)\n2. Replicate API Token\n3. MCPÂÖºÂÆπÁöÑÁéØÂ¢ÉÔºàÂ¶ÇClaude DesktopÔºâ\n\n## Ëé∑ÂèñReplicate API Token\n\n1. ËÆøÈóÆ [ReplicateÂÆòÁΩë](https://replicate.com/) Âπ∂Ê≥®ÂÜåË¥¶Âè∑\n2. ÁôªÂΩïÂêéËÆøÈóÆ [API TokensÈ°µÈù¢](https://replicate.com/account/api-tokens)\n3. ÁÇπÂáª\"Create API token\"ÂàõÂª∫Êñ∞ÁöÑtoken\n4. Â§çÂà∂ÁîüÊàêÁöÑtokenÔºàÊ†ºÂºèÂ¶ÇÔºör8_xxxxxxÔºâ\n\n## ÂÆâË£Ö\n\n1. ÂÖãÈöÜÈ°πÁõÆÂπ∂ÂÆâË£Ö‰æùËµñÔºö\n```bash\ngit clone [repository-url]\ncd flux-schnell-mcp\nnpm install\n```\n\n2. ÊûÑÂª∫ÊúçÂä°Âô®Ôºö\n```bash\nnpm run build\n```\n\n## ÈÖçÁΩÆ\n\n### Claude DesktopÈÖçÁΩÆ\n\n1. ÊâìÂºÄÈÖçÁΩÆÊñá‰ª∂Ôºö\n   - MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n2. Ê∑ªÂä†ÊúçÂä°Âô®ÈÖçÁΩÆÔºö\n```json\n{\n  \"mcpServers\": {\n    \"flux-schnell\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/flux-schnell-mcp/build/index.js\"],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your-replicate-api-token\"\n      },\n      \"disabled\": false,\n      \"alwaysAllow\": []\n    }\n  }\n}\n```\n\n### VSCode RooÈÖçÁΩÆ\n\n1. ÊâìÂºÄÈÖçÁΩÆÊñá‰ª∂Ôºö\n   - Linux: `~/.vscode-remote/data/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n   - MacOS: `~/Library/Application Support/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n   - Windows: `%APPDATA%/Code/User/globalStorage/rooveterinaryinc.roo-cline/settings/cline_mcp_settings.json`\n\n2. Ê∑ªÂä†‰∏é‰∏äËø∞Áõ∏ÂêåÁöÑÊúçÂä°Âô®ÈÖçÁΩÆ„ÄÇ\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\nÊúçÂä°Âô®Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫`generate_image`ÁöÑÂ∑•ÂÖ∑ÔºåÂèØ‰ª•ÈÄöËøáMCPË∞ÉÁî®Ôºö\n\n```typescript\n\u003cuse_mcp_tool\u003e\n\u003cserver_name\u003eflux-schnell\u003c/server_name\u003e\n\u003ctool_name\u003egenerate_image\u003c/tool_name\u003e\n\u003carguments\u003e\n{\n  \"prompt\": \"a beautiful sunset over the ocean, digital art style\"\n}\n\u003c/arguments\u003e\n\u003c/use_mcp_tool\u003e\n```\n\n### ÂèÇÊï∞ËØ¥Êòé\n\n- `prompt`: Áî®‰∫éÁîüÊàêÂõæÁâáÁöÑÊñáÊú¨ÊèèËø∞ÔºàÂøÖÂ°´Ôºâ\n  - Âª∫ËÆÆ‰ΩøÁî®ËØ¶ÁªÜÁöÑÊèèËø∞Êù•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÁîüÊàêÁªìÊûú\n  - ÂèØ‰ª•ÂåÖÂê´È£éÊ†º„ÄÅÂú∫ÊôØ„ÄÅÁªÜËäÇÁ≠â‰ø°ÊÅØ\n\n### ÂìçÂ∫îÊ†ºÂºè\n\nÊúçÂä°Âô®Â∞ÜËøîÂõûReplicate APIÁöÑÂÆåÊï¥ÂìçÂ∫îÔºåÂåÖÂê´ÁîüÊàêÁöÑÂõæÁâáURLÂíåÂÖ∂‰ªñÂÖÉÊï∞ÊçÆ„ÄÇ\n\n## Ë∞ÉËØï\n\nÁî±‰∫éMCPÊúçÂä°Âô®ÈÄöËøástdioÈÄö‰ø°ÔºåË∞ÉËØïÂèØËÉΩÊØîËæÉÂõ∞Èöæ„ÄÇÊé®Ëçê‰ΩøÁî®[MCP Inspector](https://github.com/modelcontextprotocol/inspector)Ôºö\n\n```bash\nnpm run inspector\n```\n\nInspectorÂ∞ÜÊèê‰æõ‰∏Ä‰∏™URLÔºåÂèØ‰ª•Âú®ÊµèËßàÂô®‰∏≠ËÆøÈóÆË∞ÉËØïÂ∑•ÂÖ∑„ÄÇ\n\n## Ê≥®ÊÑè‰∫ãÈ°π\n\n1. ËØ∑Â¶•ÂñÑ‰øùÁÆ°ÊÇ®ÁöÑReplicate API TokenÔºå‰∏çË¶ÅÂ∞ÜÂÖ∂ÂàÜ‰∫´Áªô‰ªñ‰∫∫\n2. Á°Æ‰øùÂú®ÈÖçÁΩÆÊñá‰ª∂‰∏≠‰ΩøÁî®Ê≠£Á°ÆÁöÑÊñá‰ª∂Ë∑ØÂæÑ\n3. ÁîüÊàêÂõæÁâáÂèØËÉΩÈúÄË¶Å‰∏Ä‰∫õÊó∂Èó¥ÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖÂìçÂ∫î\n4. Â¶ÇÈÅáÂà∞ÈîôËØØÔºåËØ∑Ê£ÄÊü•API TokenÊòØÂê¶Ê≠£Á°ÆÔºå‰ª•ÂèäÁΩëÁªúËøûÊé•ÊòØÂê¶Ê≠£Â∏∏\n",
      "stars": 3,
      "updated_at": "2025-04-12T09:44:48Z",
      "url": "https://github.com/ckz/flux-schnell-mcp"
    },
    "coderjun--shaka-packager-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Supports advanced video transcoding, packaging, and analysis using Shaka Packager. Facilitates format conversion, DRM application, and content preparation for streaming, featuring intelligent path handling and error management.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/coderjun.webp",
      "keywords": [
        "packager",
        "coderjun",
        "streaming",
        "shaka packager",
        "video transcoding",
        "packager mcp"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "shaka-packager-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "coderjun",
      "readme_content": "# Shaka Packager MCP Server\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/downloads/)\n[![Status: Alpha](https://img.shields.io/badge/Status-Alpha%20%7C%20Experimental-red)](https://github.com/coderjun/shaka-packager-mcp)\n\n\u003e **‚ö†Ô∏è EXPERIMENTAL STATUS DISCLAIMER**\n\u003e \n\u003e This project is in early alpha stage and is highly experimental. It is not recommended for production use. It is also likely **MESSY!**\n\u003e \n\u003e **Current limitations:**\n\u003e - You may run into inconsistent behavior\n\u003e - Advanced features (packaging, conversion, etc.) are still under active development\n\u003e - Path translation between Docker and host environments may require manual configuration\n\u003e - Expect frequent breaking changes and potential instability\n\u003e\n\u003e Please report any issues you encounter to help improve the project.\n\nAn MCP (Model Context Protocol) server that integrates [Shaka Packager](https://shaka-project.github.io/shaka-packager/) with Claude AI applications for video transcoding, packaging, and analysis.\n\nThis server works with the [Filesystem MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) to enable Claude Desktop to access and process video files on your computer, turning Claude into a powerful assistant for media processing tasks.\n\n## Features\n\n- **Video Analysis**: Analyze video files to extract detailed stream information, codecs, bitrates, and more\n- **Media Packaging**: Convert videos for streaming in HLS and DASH formats with support for VOD and live streaming\n- **Advanced Options**: \n  - Apply DRM encryption (Widevine, PlayReady, FairPlay)\n  - Configure ad insertion markers\n  - Convert between formats (MP4, TS, etc.)\n- **Intelligent Path Handling**: Automatically translates paths between Docker and host environments\n- **Robust Error Management**: Provides meaningful error analysis with suggestions for resolution\n- **Command Assistance**: Helps correctly format Shaka Packager commands for optimal results\n- **Interactive Documentation**: Built-in help and examples to guide users through complex operations\n- **Detailed Outputs**: Comprehensive summaries and execution details for all operations\n\n## Prerequisites\n\n- Python 3.10 or higher\n- Shaka Packager installed and available in your PATH\n  - [Download from GitHub](https://github.com/shaka-project/shaka-packager/releases)\n  - Or build from source following [these instructions](https://shaka-project.github.io/shaka-packager/html/build_instructions.html)\n- An MCP-compatible client (like Claude Desktop)\n\n## Installation\n\n### Using pip or uv (coming soon)\n\nInstall the package with pip:\n\n```bash\npip install shaka-packager-mcp\n```\n\nOr with uv:\n\n```bash\nuv pip install shaka-packager-mcp\n```\n\n### From source (recommended)\n\n```bash\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\npip install -e .\n```\n\nOr with uv:\n\n```bash\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\nuv pip install -e .\n```\n\n## Claude Desktop Integration\n\nSince Claude Desktop doesn't directly support uploading video files, we'll use a two-server approach:\n1. A simplified **filesystem MCP server** to access video files on your computer\n2. The **Shaka Packager MCP server** to analyze and process those videos\n\n### Step 1: Set Up the MCP Filesystem Server\n\nUse the official MCP filesystem server to allow Claude to access your video files:\n\n1. Install the official filesystem server with Docker:\n   ```bash\n   docker pull mcp/filesystem\n   ```\n\n2. Alternatively, you can build it from source following the instructions in the [Filesystem MCP Server repository](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem)\n\n### Step 2: Find the Configuration File\n\nLocate your Claude Desktop configuration file:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\nIf the file doesn't exist, create it.\n\n### Step 3: Add Both Servers to the Configuration\n\nAdd the following configuration, making sure to use absolute paths:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/PATH/TO/VIDEOS/DIRECTORY,dst=/projects/video-drop\",\n        \"mcp/filesystem\",\n        \"/projects\"\n      ]\n    },\n    \"shaka-packager\": {\n      \"command\": \"/ABSOLUTE/PATH/TO/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"/ABSOLUTE/PATH/TO/shaka_packager_mcp.py\"\n      ],\n      \"env\": {\n        \"VIDEO_PATH\": \"/PATH/TO/VIDEOS/DIRECTORY\",\n        \"SHAKA_PACKAGER_PATH\": \"/PATH/TO/PACKAGER\"\n      }\n    }\n  }\n}\n```\n\nReplace:\n- `/PATH/TO/VIDEOS/DIRECTORY` with the path to the directory containing your video files\n- `/ABSOLUTE/PATH/TO/uv` with the full path to your uv executable\n- `/ABSOLUTE/PATH/TO/shaka_packager_mcp.py` with the full path to the script file\n- `/PATH/TO/PACKAGER` with the full path to your Shaka Packager executable\n\nFor example:\n\n```json\n{\n  \"mcpServers\": {\n    \"filesystem\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--mount\", \"type=bind,src=/Users/username/Videos,dst=/projects/video-drop\",\n        \"mcp/filesystem\",\n        \"/projects\"\n      ]\n    },\n    \"shaka-packager\": {\n      \"command\": \"/Users/username/.local/bin/uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"/Users/username/Development/shaka-packager-mcp/shaka_packager_mcp.py\"\n      ],\n      \"env\": {\n        \"VIDEO_PATH\": \"/Users/username/Videos\",\n        \"SHAKA_PACKAGER_PATH\": \"/Users/username/.shaka/packager\"\n      }\n    }\n  }\n}\n```\n\n### Step 4: Restart Claude Desktop\n\nAfter editing the configuration file, restart Claude Desktop to apply the changes.\n\n### How to Use the Two-Server Approach\n\n1. First, browse your video files using the simplified filesystem server:\n   - Ask Claude to \"List the files in my video directory\"\n   - Navigate to the video file you want to analyze or process\n\n2. Once you've found your video file, use its path with the Shaka Packager tools:\n   - For analysis: \"Please analyze this video: /Users/username/Videos/example.mp4\"\n   - For processing: \"Please package this video for HLS: /Users/username/Videos/example.mp4\"\n\n### Troubleshooting\n\nIf you encounter any issues:\n\n1. Make sure both servers are properly configured with absolute paths\n2. Verify that Shaka Packager is installed and accessible\n3. Ensure the directory specified for the filesystem server exists and contains videos\n4. Check Claude Desktop logs for errors at:\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n## Usage\n\nOnce both the Filesystem MCP server and the Shaka Packager MCP server are running in Claude Desktop:\n\n1. **Access your video files**:\n   ```\n   Please show me the files in my Videos directory\n   ```\n\n2. **Navigate to your video file**:\n   ```\n   Please show me the files in the Movies subdirectory\n   ```\n\n3. **Copy the file:// URI path of the video** you want to process\n\n4. **Use the Shaka Packager tools with the file path**:\n   ```\n   Please analyze this video: file:///Users/username/Videos/my_video.mp4\n   ```\n   or\n   ```\n   Please package this video for HLS and DASH streaming: file:///Users/username/Videos/my_video.mp4\n   ```\n\n5. The server will execute the appropriate Shaka Packager command and provide a detailed summary of the results\n\nYou can also use direct file paths if you know the exact location of your video files:\n```\nPlease analyze this video: /Users/username/Videos/my_video.mp4\n```\n\n## Tools\n\nThe server provides these tools:\n\n1. **analyze_video**: Examines a video file and provides detailed stream information with intelligent error handling\n2. **run_shaka_packager**: Executes any Shaka Packager command with custom arguments and proper path handling\n3. **get_shaka_options**: Retrieves available command options and version information\n4. **get_shaka_documentation**: Provides comprehensive documentation and examples for using Shaka Packager\n\n## Prompts\n\nThe server includes these prompt templates:\n\n- MP4 to TS conversion\n- VOD packaging in HLS and DASH\n- Live streaming packaging\n- Content encryption\n- Ad insertion preparation\n- Video analysis\n- Command format reminder\n- Error interpretation guidance\n\n## Configuration\n\nThe server can be configured using environment variables:\n\n- `SHAKA_PACKAGER_PATH`: Path to the Shaka Packager executable (highly recommended for Claude Desktop)\n- `VIDEO_PATH`: Path to your local video directory (used for translating paths between Docker and host)\n- `DOCKER_PATH`: Docker container mount path (default: \"/projects/video-drop\")\n- `TEMP_DIR`: Custom temporary directory for file uploads\n- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n- `COMMAND_TIMEOUT`: Timeout in seconds for Shaka Packager commands (default: 300)\n\nYou can set these in:\n1. Your Claude Desktop configuration file (preferred for `SHAKA_PACKAGER_PATH` and `VIDEO_PATH`)\n2. Your environment variables\n3. A `.env` file in the same directory as the script\n\nExample `.env` file:\n```\nSHAKA_PACKAGER_PATH=/usr/local/bin/packager\nVIDEO_PATH=/Users/yourusername/Videos\nLOG_LEVEL=DEBUG\n```\n\n## Development\n\n### Setting up a development environment\n\n```bash\n# Clone the repository\ngit clone https://github.com/coderjun/shaka-packager-mcp.git\ncd shaka-packager-mcp\n\n# Install development dependencies with pip\npip install -e \".[dev]\"\n\n# Or with uv\nuv pip install -e \".[dev]\"\n```\n\n### Running tests\n\n```bash\npytest\n```\n\n### Code formatting\n\n```bash\nblack .\nisort .\n```\n\n### Understanding the Code Structure\n\nThe main components of the Shaka Packager MCP server are:\n\n- `shaka_packager_mcp.py`: Main server implementation with MCP tools and prompts\n- `tests/`: Test suite for verifying functionality\n\nThis server is designed to work with the official MCP filesystem server for accessing video files.\n\n### Key Features in the Implementation\n\n- **Robust path handling**: Automatically translates paths between Docker and host environments\n- **Smart error handling**: Provides meaningful error messages and suggestions\n- **Command syntax assistance**: Helps correctly format Shaka Packager commands\n- **Documentation integration**: Provides comprehensive documentation and examples\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Getting Help\n\nFeel free to use an AI code copilot, the author does.\n\nIf you encounter any issues or have questions:\n\n1. Check the troubleshooting section in this README\n2. Review the [Shaka Packager documentation](https://shaka-project.github.io/shaka-packager/html/index.html)\n3. Use the `get_shaka_documentation` tool for interactive help within Claude\n4. [Open an issue](https://github.com/coderjun/shaka-packager-mcp/issues) on GitHub\n\n## Acknowledgements\n\n- [Shaka Packager](https://github.com/shaka-project/shaka-packager) for the powerful video processing capabilities\n- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) for the communication framework\n- [Claude](https://claude.ai) for the AI assistant capabilities\n- [Anthropic](https://www.anthropic.com/) for developing Claude and the MCP standard",
      "stars": 3,
      "updated_at": "2025-06-19T18:32:59Z",
      "url": "https://github.com/coderjun/shaka-packager-mcp-server"
    },
    "dangtanloc--ComfyUI": {
      "category": "image-and-video-generation",
      "description": "A visual graph-based interface for designing and executing advanced stable diffusion pipelines, enabling users to create complex workflows without coding. It features smart memory management and asynchronous processing, supporting both GPU and CPU usage for offline functionality.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/dangtanloc.webp",
      "keywords": [
        "visual",
        "processing",
        "pipelines",
        "diffusion pipelines",
        "visual graph",
        "comfyui visual"
      ],
      "language": "",
      "license": "GNU General Public License v3.0",
      "name": "ComfyUI",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "dangtanloc",
      "readme_content": "\u003cdiv align=\"center\"\u003e\n\n# ComfyUI\n**The most powerful and modular diffusion model GUI and backend.**\n\n\n[![Website][website-shield]][website-url]\n[![Dynamic JSON Badge][discord-shield]][discord-url]\n[![Matrix][matrix-shield]][matrix-url]\n\u003cbr\u003e\n[![][github-release-shield]][github-release-link]\n[![][github-release-date-shield]][github-release-link]\n[![][github-downloads-shield]][github-downloads-link]\n[![][github-downloads-latest-shield]][github-downloads-link]\n\n[matrix-shield]: https://img.shields.io/badge/Matrix-000000?style=flat\u0026logo=matrix\u0026logoColor=white\n[matrix-url]: https://app.element.io/#/room/%23comfyui_space%3Amatrix.org\n[website-shield]: https://img.shields.io/badge/ComfyOrg-4285F4?style=flat\n[website-url]: https://www.comfy.org/\n\u003c!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 --\u003e\n[discord-shield]: https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue\u0026query=%24.approximate_member_count\u0026logo=discord\u0026logoColor=white\u0026label=Discord\u0026color=green\u0026suffix=%20total\n[discord-url]: https://www.comfy.org/discord\n\n[github-release-shield]: https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat\u0026sort=semver\n[github-release-link]: https://github.com/comfyanonymous/ComfyUI/releases\n[github-release-date-shield]: https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat\n[github-downloads-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat\n[github-downloads-latest-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat\u0026label=downloads%40latest\n[github-downloads-link]: https://github.com/comfyanonymous/ComfyUI/releases\n\n\n\u003c/div\u003e\n\nThis ui will let you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. For some workflow examples and see what ComfyUI can do you can check out:\n### [ComfyUI Examples](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n### [Installing ComfyUI](#installing)\n\n## Features\n- Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.\n- Fully supports SD1.x, SD2.x, [SDXL](https://comfyanonymous.github.io/ComfyUI_examples/sdxl/), [Stable Video Diffusion](https://comfyanonymous.github.io/ComfyUI_examples/video/), [Stable Cascade](https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/), [SD3](https://comfyanonymous.github.io/ComfyUI_examples/sd3/) and [Stable Audio](https://comfyanonymous.github.io/ComfyUI_examples/audio/)\n- [Flux](https://comfyanonymous.github.io/ComfyUI_examples/flux/)\n- Asynchronous Queue system\n- Many optimizations: Only re-executes the parts of the workflow that changes between executions.\n- Smart memory management: can automatically run models on GPUs with as low as 1GB vram.\n- Works even if you don't have a GPU with: ```--cpu``` (slow)\n- Can load ckpt, safetensors and diffusers models/checkpoints. Standalone VAEs and CLIP models.\n- Embeddings/Textual inversion\n- [Loras (regular, locon and loha)](https://comfyanonymous.github.io/ComfyUI_examples/lora/)\n- [Hypernetworks](https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/)\n- Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.\n- Saving/Loading workflows as Json files.\n- Nodes interface can be used to create complex workflows like one for [Hires fix](https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/) or much more advanced ones.\n- [Area Composition](https://comfyanonymous.github.io/ComfyUI_examples/area_composition/)\n- [Inpainting](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/) with both regular and inpainting models.\n- [ControlNet and T2I-Adapter](https://comfyanonymous.github.io/ComfyUI_examples/controlnet/)\n- [Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)](https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/)\n- [unCLIP Models](https://comfyanonymous.github.io/ComfyUI_examples/unclip/)\n- [GLIGEN](https://comfyanonymous.github.io/ComfyUI_examples/gligen/)\n- [Model Merging](https://comfyanonymous.github.io/ComfyUI_examples/model_merging/)\n- [LCM models and Loras](https://comfyanonymous.github.io/ComfyUI_examples/lcm/)\n- [SDXL Turbo](https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/)\n- [AuraFlow](https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/)\n- [HunyuanDiT](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/)\n- Latent previews with [TAESD](#how-to-show-high-quality-previews)\n- Starts up very fast.\n- Works fully offline: will never download anything.\n- [Config file](extra_model_paths.yaml.example) to set the search paths for models.\n\nWorkflow examples can be found on the [Examples page](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n## Shortcuts\n\n| Keybind                            | Explanation                                                                                                        |\n|------------------------------------|--------------------------------------------------------------------------------------------------------------------|\n| Ctrl + Enter                       | Queue up current graph for generation                                                                              |\n| Ctrl + Shift + Enter               | Queue up current graph as first for generation                                                                     |\n| Ctrl + Alt + Enter                 | Cancel current generation                                                                                          |\n| Ctrl + Z/Ctrl + Y                  | Undo/Redo                                                                                                          |\n| Ctrl + S                           | Save workflow                                                                                                      |\n| Ctrl + O                           | Load workflow                                                                                                      |\n| Ctrl + A                           | Select all nodes                                                                                                   |\n| Alt + C                            | Collapse/uncollapse selected nodes                                                                                 |\n| Ctrl + M                           | Mute/unmute selected nodes                                                                                         |\n| Ctrl + B                           | Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)            |\n| Delete/Backspace                   | Delete selected nodes                                                                                              |\n| Ctrl + Backspace                   | Delete the current graph                                                                                           |\n| Space                              | Move the canvas around when held and moving the cursor                                                             |\n| Ctrl/Shift + Click                 | Add clicked node to selection                                                                                      |\n| Ctrl + C/Ctrl + V                  | Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)                     |\n| Ctrl + C/Ctrl + Shift + V          | Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes) |\n| Shift + Drag                       | Move multiple selected nodes at the same time                                                                      |\n| Ctrl + D                           | Load default graph                                                                                                 |\n| Alt + `+`                          | Canvas Zoom in                                                                                                     |\n| Alt + `-`                          | Canvas Zoom out                                                                                                    |\n| Ctrl + Shift + LMB + Vertical drag | Canvas Zoom in/out                                                                                                 |\n| P                                  | Pin/Unpin selected nodes                                                                                           |\n| Ctrl + G                           | Group selected nodes                                                                                               |\n| Q                                  | Toggle visibility of the queue                                                                                     |\n| H                                  | Toggle visibility of history                                                                                       |\n| R                                  | Refresh graph                                                                                                      |\n| Double-Click LMB                   | Open node quick search palette                                                                                     |\n| Shift + Drag                       | Move multiple wires at once                                                                                        |\n| Ctrl + Alt + LMB                   | Disconnect all wires from clicked slot                                                                             |\n\nCtrl can also be replaced with Cmd instead for macOS users\n\n# Installing\n\n## Windows\n\nThere is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the [releases page](https://github.com/comfyanonymous/ComfyUI/releases).\n\n### [Direct link to download](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z)\n\nSimply download, extract with [7-Zip](https://7-zip.org) and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\\models\\checkpoints\n\nIf you have trouble extracting it, right click the file -\u003e properties -\u003e unblock\n\n#### How do I share models between another UI and ComfyUI?\n\nSee the [Config file](extra_model_paths.yaml.example) to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.\n\n## Jupyter Notebook\n\nTo run it on services like paperspace, kaggle or colab you can use my [Jupyter Notebook](notebooks/comfyui_colab.ipynb)\n\n## Manual Install (Windows, Linux)\n\nGit clone this repo.\n\nPut your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints\n\nPut your VAE in: models/vae\n\n\n### AMD GPUs (Linux only)\nAMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:\n\n```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1```\n\nThis is the command to install the nightly with ROCm 6.2 which might have some performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.2```\n\n### NVIDIA\n\nNvidia users should install stable pytorch using this command:\n\n```pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124```\n\nThis is the command to install pytorch nightly instead which might have performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu124```\n\n#### Troubleshooting\n\nIf you get the \"Torch not compiled with CUDA enabled\" error, uninstall torch with:\n\n```pip uninstall torch```\n\nAnd install it again with the command above.\n\n### Dependencies\n\nInstall the dependencies by opening your terminal inside the ComfyUI folder and:\n\n```pip install -r requirements.txt```\n\nAfter this you should have everything installed and can proceed to running ComfyUI.\n\n### Others:\n\n#### Intel GPUs\n\nIntel GPU support is available for all Intel GPUs supported by Intel's Extension for Pytorch (IPEX) with the support requirements listed in the [Installation](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu) page. Choose your platform and method of install and follow the instructions. The steps are as follows:\n\n1. Start by installing the drivers or kernel listed or newer in the Installation page of IPEX linked above for Windows and Linux if needed.\n1. Follow the instructions to install [Intel's oneAPI Basekit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html) for your platform.\n1. Install the packages for IPEX using the instructions provided in the Installation page for your platform.\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux and run ComfyUI normally as described above after everything is installed.\n\nAdditional discussion and help can be found [here](https://github.com/comfyanonymous/ComfyUI/discussions/476).\n\n#### Apple Mac silicon\n\nYou can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.\n\n1. Install pytorch nightly. For instructions, read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide (make sure to install the latest pytorch nightly).\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux.\n1. Install the ComfyUI [dependencies](#dependencies). If you have another Stable Diffusion UI [you might be able to reuse the dependencies](#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies).\n1. Launch ComfyUI by running `python main.py`\n\n\u003e **Note**: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in [ComfyUI manual installation](#manual-install-windows-linux).\n\n#### DirectML (AMD Cards on Windows)\n\n```pip install torch-directml``` Then you can launch ComfyUI with: ```python main.py --directml```\n\n# Running\n\n```python main.py```\n\n### For AMD cards not officially supported by ROCm\n\nTry running it with this command if you have issues:\n\nFor 6700, 6600 and maybe other RDNA2 or older: ```HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py```\n\nFor AMD 7600 and maybe other RDNA3 cards: ```HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py```\n\n# Notes\n\nOnly parts of the graph that have an output with all the correct inputs will be executed.\n\nOnly parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.\n\nDragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.\n\nYou can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \\\\( or \\\\).\n\nYou can use {day|night}, for wildcard/dynamic prompts. With this syntax \"{wild|card|test}\" will be randomly replaced by either \"wild\", \"card\" or \"test\" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \\\\{ or \\\\}.\n\nDynamic prompts also support C-style comments, like `// comment` or `/* comment */`.\n\nTo use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):\n\n```embedding:embedding_filename.pt```\n\n\n## How to show high-quality previews?\n\nUse ```--preview-method auto``` to enable previews.\n\nThe default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with [TAESD](https://github.com/madebyollin/taesd), download the [taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth](https://github.com/madebyollin/taesd/) and place them in the `models/vae_approx` folder. Once they're installed, restart ComfyUI and launch it with `--preview-method taesd` to enable high-quality previews.\n\n## How to use TLS/SSL?\nGenerate a self-signed certificate (not appropriate for shared/production use) and key by running the command: `openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj \"/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname\"`\n\nUse `--tls-keyfile key.pem --tls-certfile cert.pem` to enable TLS/SSL, the app will now be accessible with `https://...` instead of `http://...`.\n\n\u003e Note: Windows users can use [alexisrolland/docker-openssl](https://github.com/alexisrolland/docker-openssl) or one of the [3rd party binary distributions](https://wiki.openssl.org/index.php/Binaries) to run the command example above. \n\u003cbr/\u003e\u003cbr/\u003eIf you use a container, note that the volume mount `-v` can be a relative path so `... -v \".\\:/openssl-certs\" ...` would create the key \u0026 cert files in the current directory of your command prompt or powershell terminal.\n\n## Support and dev channel\n\n[Matrix space: #comfyui_space:matrix.org](https://app.element.io/#/room/%23comfyui_space%3Amatrix.org) (it's like discord but open source).\n\nSee also: [https://www.comfy.org/](https://www.comfy.org/)\n\n## Frontend Development\n\nAs of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: [ComfyUI Frontend](https://github.com/Comfy-Org/ComfyUI_frontend). This repository now hosts the compiled JS (from TS/Vue) under the `web/` directory.\n\n### Reporting Issues and Requesting Features\n\nFor any bugs, issues, or feature requests related to the frontend, please use the [ComfyUI Frontend repository](https://github.com/Comfy-Org/ComfyUI_frontend). This will help us manage and address frontend-specific concerns more efficiently.\n\n### Using the Latest Frontend\n\nThe new frontend is now the default for ComfyUI. However, please note:\n\n1. The frontend in the main ComfyUI repository is updated weekly.\n2. Daily releases are available in the separate frontend repository.\n\nTo use the most up-to-date frontend version:\n\n1. For the latest daily release, launch ComfyUI with this command line argument:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@latest\n   ```\n\n2. For a specific version, replace `latest` with the desired version number:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@1.2.2\n   ```\n\nThis approach allows you to easily switch between the stable weekly release and the cutting-edge daily updates, or even specific versions for testing purposes.\n\n### Accessing the Legacy Frontend\n\nIf you need to use the legacy frontend for any reason, you can access it using the following command line argument:\n\n```\n--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest\n```\n\nThis will use a snapshot of the legacy frontend preserved in the [ComfyUI Legacy Frontend repository](https://github.com/Comfy-Org/ComfyUI_legacy_frontend).\n\n# QA\n\n### Which GPU should I buy for this?\n\n[See this page for some recommendations](https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI)",
      "stars": 0,
      "updated_at": "2024-10-10T06:48:42Z",
      "url": "https://github.com/dangtanloc/ComfyUI"
    },
    "dasheck0--face-generator": {
      "category": "image-and-video-generation",
      "description": "Generate realistic human face images with customizable shapes, sizes, and backgrounds. Supports batch generation for multiple images and offers transparent backgrounds for non-square outputs.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/dasheck0.webp",
      "keywords": [
        "generate",
        "dasheck0",
        "backgrounds",
        "face generator",
        "face images",
        "dasheck0 face"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "face-generator",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "dasheck0",
      "readme_content": "# Face Generator MCP Server: Generate Human Faces with Ease\n\n[![Smithery badge](https://smithery.ai/badge/@dasheck0/face-generator)](https://smithery.ai/server/@dasheck0/face-generator)\n\n\u003ca href=\"https://glama.ai/mcp/servers/0v6oomxing\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/0v6oomxing/badge\" alt=\"Face Generator Server MCP server\" /\u003e\n\u003c/a\u003e\n\n## Features\nThis project provides a Model Context Protocol (MCP) server for generating human face images using https://thispersondoesnotexist.com. Think of it as a tool that lets other applications, like Cline, generate realistic-looking faces on demand.\n\nThis guide is designed for beginners, so we'll walk through everything step-by-step. We'll cover:\n\n1.  **Prerequisites:** What you need before you start.\n2.  **Installation and Setup:** Getting everything up and running.\n3.  **Running the Server:** Starting the server.\n4.  **Integrating with Cline:** Connecting this server to the Cline VS Code extension.\n5.  **Troubleshooting:** Common problems and solutions.\n6.  **Tool Parameters:** A list of the parameters you can use with the `generate_face` tool.\n\n## 1. Prerequisites\n\nBefore you begin, you'll need a few things:\n\n*   **Node.js and npm:** Node.js is a JavaScript runtime that lets you run JavaScript code outside of a web browser. npm (Node Package Manager) is included with Node.js and is used to install packages (libraries of code).\n    *   [Download Node.js](https://nodejs.org/en/download/). **Choose the LTS (Long Term Support) version.** This is the most stable version. Follow the installation instructions for your operating system. Make sure to include npm in the installation (it's usually included by default).\n    *   **Verify Installation:** After installing Node.js, open a new terminal (command prompt on Windows, Terminal on macOS/Linux) and type:\n        ```bash\n        node -v\n        npm -v\n        ```\n        You should see version numbers for both Node.js and npm. If you see an error, Node.js might not be installed correctly, or it might not be in your system's PATH. (See Troubleshooting below).\n\n## 2. Installation and Setup\n\nLet's get the project code and set it up:\n\n1.  **Clone the Repository:**\n    *   **Using Git (command line):**\n        1.  Open a terminal (command prompt or Terminal).\n        2.  Navigate to the directory where you want to store the project. For example, to put it on your Desktop:\n            ```bash\n            cd Desktop\n            ```\n        3.  Clone the repository:\n            ```bash\n            git clone https://github.com/Moe/mcp-face-generator\n            ```\n        4.  Change into the project directory:\n            ```bash\n            cd mcp-face-generator\n            ```\n    *   **Using GitHub Desktop:**\n        1.  Open GitHub Desktop.\n        2.  Click \"File\" -\u003e \"Clone Repository...\".\n        3.  In the \"URL\" tab, paste the repository URL.\n        4.  Choose a local path (where you want to save the project on your computer).\n        5.  Click \"Clone\".\n\n2.  **Install Dependencies:** This downloads all the necessary libraries the project needs. In the terminal, inside the project directory, run:\n    ```bash\n    npm install\n    ```\n    This might take a few minutes.\n\n3.  **Build the Project:** This compiles the code into an executable format.\n    ```bash\n    npm run build\n    ```\n\n## 3. Running the Server\n\nYou can run the server in two main ways:\n\n*   **Standalone Mode:** This runs the server directly, and it will output messages to the terminal.\n*   **Development/Debug Mode:** This runs the server with the MCP Inspector. You can open the URL that it outputs in your browser and start playing around.\n\n### 3.1 Standalone Mode\n\nTo run the server in standalone mode, use the following command in the terminal (from the project directory):\n\n```bash\nnpm run start\n```\n\nYou should see messages in the terminal indicating that the server is running. It will listen for connections from MCP clients. The server will keep running until you stop it (usually with Ctrl+C).\n\n### 3.2 Development/Debug Mode (with Inspector)\n\nThis mode is useful for debugging.\n\n1.  **Start the server in debug mode:**\n    ```bash\n    npm run dev\n    ```\n    This will start the server and output a message like: `üîç MCP Inspector is up and running at http://localhost:5173 üöÄ`. This is the URL you'll use to open the MCP inspector in your Browser.\n\n## 4. Integrating with Cline\n\nCline is a VS Code extension that uses MCP servers to provide language support. Here's how to connect this face generator server to Cline:\n\n1.  **Install Cline:** If you haven't already, install the \"Cline\" extension in VS Code.\n\n2.  **Open Cline Settings:**\n    *   Open the VS Code settings (File -\u003e Preferences -\u003e Settings, or Ctrl+,).\n    *   Search for \"Cline MCP Settings\".\n    *   Click \"Edit in settings.json\". This will open the `cline_mcp_settings.json` file.\n\n3.  **Add the Server Configuration:** You'll need to add an entry to the `servers` array in the `cline_mcp_settings.json` file. Here's an example:\n\n    ```json\n    {\n      \"mcpServers\": {\n        \"face-generator\": {\n          \"command\": \"node\",\n          \"args\": [\n            \"C:/PATH_TO/mcp-face-generator/build/index.js\"\n          ],\n          \"disabled\": false,\n          \"autoApprove\": []\n        }\n      }\n    }\n    ```\n    *   Replace `\"C:/PATH_TO/mcp-face-generator/build/index.js\"` with the actual path to the `index.js` file in your project directory.  Use forward slashes (/) or double backslashes (\\\\\\\\) for the path on Windows.\n\n4.  **Test the Connection:**\n    *   Cline should automatically connect to the server. You will see the Server appear in the \"MCP Servers\" Panel (in the Cline extension, you'll find different buttons on the top.)\n    *   Ask Cline to generate a face and it should mention the MCP Server and should try to use the corresponding tools\n\n## 5. Troubleshooting\n\n*   **`node -v` or `npm -v` gives an error:**\n    *   Make sure Node.js is installed correctly. Try reinstalling it.\n    *   Ensure that the Node.js installation directory is in your system's PATH environment variable. On Windows, you can edit environment variables through the System Properties (search for \"environment variables\" in the Start Menu).\n*   **`npm install` fails:**\n    *   Make sure you have an internet connection.\n    *   Try deleting the `node_modules` folder and running `npm install` again.\n    *   If you're behind a proxy, you might need to configure npm to use the proxy. Search online for \"npm proxy settings\".\n*   **Cline doesn't connect to the server:**\n    *   Double-check the settings in `cline_mcp_settings.json`. It *must* be the correct path to the `index.js` file.\n    *   Make sure the server is running (use `npm run start` to check).\n    *   Restart VS Code.\n\n## 6. Tool Parameters\n\nThe `generate_face` tool accepts the following parameters:\n\n*   `outputDir`: (required) Directory to save the images\n*   `fileName`: Optional file name (defaults to timestamp)\n*   `count`: Number of images to generate (default: 1)\n*   `width`: Image width in pixels (default: 256)\n*   `height`: Image height in pixels (default: 256)\n*   `shape`: Image shape (square|circle|rounded, default: square)\n*   `borderRadius`: Border radius for rounded shape (default: 32)\n*   `returnImageContent`: Return image as base64 encoded content instead of file path (default: false)\n\n## Example\n\n```json\n{\n  \"outputDir\": \"./output\",\n  \"count\": 3,\n  \"width\": 512,\n  \"height\": 512,\n  \"shape\": \"circle\",\n  \"returnImageContent\": true\n}\n```\n\n## License\n\nMIT\n",
      "stars": 5,
      "updated_at": "2025-10-03T22:32:05Z",
      "url": "https://github.com/dasheck0/face-generator"
    },
    "deepfates--mcp-replicate": {
      "category": "image-and-video-generation",
      "description": "Access Replicate models to run predictions through a tool-based interface, facilitating interactions with various AI models hosted on Replicate's platform.",
      "forks": 19,
      "imageUrl": "/freedevtools/mcp/pfp/deepfates.webp",
      "keywords": [
        "replicate",
        "deepfates",
        "ai",
        "mcp replicate",
        "deepfates mcp",
        "generation deepfates"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "mcp-replicate",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "deepfates",
      "readme_content": "# Replicate MCP Server\n\nA [Model Context Protocol](https://github.com/mcp-sdk/mcp) server implementation for Replicate. Run Replicate models through a simple tool-based interface.\n\n## NOT IN ACTIVE DEVELOPMENT\n\nThis repo was an experiment in MCP tooling for Replicate. The company now offers an [official MCP server](https://replicate.com/docs/reference/mcp). This repo will stay up for those who find it useful or want to fork it, but it's not in active development and issues won't be addressed. Contributions might be folded in but no promises. Enjoy at your own risk.\n\n## Quickstart\n\n1. Install the server:\n\n```bash\nnpm install -g mcp-replicate\n```\n\n2. Get your Replicate API token:\n\n   - Go to [Replicate API tokens page](https://replicate.com/account/api-tokens)\n   - Create a new token if you don't have one\n   - Copy the token for the next step\n\n3. Configure Claude Desktop:\n   - Open Claude Desktop Settings (\u003ckbd\u003e‚åò\u003c/kbd\u003e\u003ckbd\u003e,\u003c/kbd\u003e)\n   - Select the \"Developer\" section in the sidebar\n   - Click \"Edit Config\" to open the configuration file\n   - Add the following configuration, replacing `your_token_here` with your actual Replicate API token:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate\": {\n      \"command\": \"mcp-replicate\",\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_token_here\"\n      }\n    }\n  }\n}\n```\n\n4. Start Claude Desktop. You should see a üî® hammer icon in the bottom right corner of new chat windows, indicating the tools are available.\n\n(You can also use any other MCP client, such as Cursor, Cline, or Continue.)\n\n## Alternative Installation Methods\n\n### Install from source\n\n```bash\ngit clone https://github.com/deepfates/mcp-replicate\ncd mcp-replicate\nnpm install\nnpm run build\nnpm start\n```\n\n### Run with npx\n\n```bash\nnpx mcp-replicate\n```\n\n## Features\n\n### Models\n\n- Search models using semantic search\n- Browse models and collections\n- Get detailed model information and versions\n\n### Predictions\n\n- Create predictions with text or structured input\n- Track prediction status\n- Cancel running predictions\n- List your recent predictions\n\n### Image Handling\n\n- View generated images in your browser\n- Manage image cache for better performance\n\n## Configuration\n\nThe server needs a Replicate API token to work. You can get one at [Replicate](https://replicate.com/account/api-tokens).\n\nThere are two ways to provide the token:\n\n### 1. In Claude Desktop Config (Recommended)\n\nAdd it to your Claude Desktop configuration as shown in the Quickstart section:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicate\": {\n      \"command\": \"mcp-replicate\",\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_token_here\"\n      }\n    }\n  }\n}\n```\n\n### 2. As Environment Variable\n\nAlternatively, you can set it as an environment variable if you're using another MCP client:\n\n```bash\nexport REPLICATE_API_TOKEN=your_token_here\n```\n\n## Available Tools\n\n### Model Tools\n\n- `search_models`: Find models using semantic search\n- `list_models`: Browse available models\n- `get_model`: Get details about a specific model\n- `list_collections`: Browse model collections\n- `get_collection`: Get details about a specific collection\n\n### Prediction Tools\n\n- `create_prediction`: Run a model with your inputs\n- `create_and_poll_prediction`: Run a model with your inputs and wait until it's completed\n- `get_prediction`: Check a prediction's status\n- `cancel_prediction`: Stop a running prediction\n- `list_predictions`: See your recent predictions\n\n### Image Tools\n\n- `view_image`: Open an image in your browser\n- `clear_image_cache`: Clean up cached images\n- `get_image_cache_stats`: Check cache usage\n\n## Troubleshooting\n\n### Server is running but tools aren't showing up\n\n1. Check that Claude Desktop is properly configured with the MCP server settings\n2. Ensure your Replicate API token is set correctly\n3. Try restarting both the server and Claude Desktop\n4. Check the server logs for any error messages\n\n### Tools are visible but not working\n\n1. Verify your Replicate API token is valid\n2. Check your internet connection\n3. Look for any error messages in the server output\n\n## Development\n\n1. Install dependencies:\n\n```bash\nnpm install\n```\n\n2. Start development server (with auto-reload):\n\n```bash\nnpm run dev\n```\n\n3. Check code style:\n\n```bash\nnpm run lint\n```\n\n4. Format code:\n\n```bash\nnpm run format\n```\n\n## Requirements\n\n- Node.js \u003e= 18.0.0\n- TypeScript \u003e= 5.0.0\n- [Claude Desktop](https://claude.ai/download) for using the tools\n\n## License\n\nMIT\n",
      "stars": 84,
      "updated_at": "2025-09-24T19:15:13Z",
      "url": "https://github.com/deepfates/mcp-replicate"
    },
    "douglarek--unsplash-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Access a vast library of high-quality images from Unsplash through a simplified API integration. Fetch stunning images on demand to enhance visual content in applications.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/douglarek.webp",
      "keywords": [
        "unsplash",
        "images",
        "mcp",
        "stunning images",
        "images unsplash",
        "unsplash mcp"
      ],
      "language": "Go",
      "license": "MIT License",
      "name": "unsplash-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "douglarek",
      "readme_content": "# Unsplash MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@douglarek/unsplash-mcp-server)](https://smithery.ai/server/@douglarek/unsplash-mcp-server)\n\nA rewrite of the [Unsplash MCP Server](https://github.com/hellokaton/unsplash-mcp-server) using the [mark3labs/mcp-go](https://github.com/mark3labs/mcp-go) library.\n\n## Usage\n\nBefore building, you must install go 1.24+ first.\n\n```bash\ngit clone https://github.com/douglarek/unsplash-mcp-server.git\ncd unsplash-mcp-server\nmake build\n```\n\n### Cursor Editor Integration\n\nTo use this server in Cursor, you can add the following to your `mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"unsplash\": {\n      \"command\": \"\u003csource_dir\u003e/cmd/server/unsplash-mcp-server\",\n      \"args\": [],\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"\u003cyour_unsplash_access_key\u003e\"\n      }\n    }\n  }\n}\n```\n",
      "stars": 10,
      "updated_at": "2025-08-25T02:26:41Z",
      "url": "https://github.com/douglarek/unsplash-mcp-server"
    },
    "drumnation--unsplash-smart-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Connects AI models to Unsplash for searching and delivering stock photos with context-aware selection and automatic attribution management.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/drumnation.webp",
      "keywords": [
        "ai",
        "mcp",
        "attribution",
        "smart mcp",
        "automatic attribution",
        "photos context"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "unsplash-smart-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "drumnation",
      "readme_content": "# üñºÔ∏è Unsplash Smart MCP Server\n\n\u003e **Empower your AI agents with stunning visuals, zero hassle.**\n\nA powerful FastMCP server that enables AI agents to seamlessly search, recommend, and deliver professional stock photos from Unsplash with intelligent context awareness and automated attribution management.\n\n![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)\n![Node.js Version](https://img.shields.io/badge/node-%3E%3D18.x-brightgreen)\n![TypeScript Ready](https://img.shields.io/badge/TypeScript-Ready-blue)\n[![smithery badge](https://smithery.ai/badge/@drumnation/unsplash-smart-mcp-server)](https://smithery.ai/server/@drumnation/unsplash-smart-mcp-server)\n[![npm version](https://img.shields.io/npm/v/@drumnation/unsplash-smart-mcp-server.svg)](https://www.npmjs.com/package/@drumnation/unsplash-smart-mcp-server)\n\n## üöÄ Why Choose This Unsplash Integration\n\nIn the landscape of visual content integration, our Unsplash Smart MCP Server stands out as the **definitive solution** for AI-powered image acquisition:\n\n- **üß† AI-Agent Optimized**: Purpose-built for AI agents like Claude in Cursor, streamlining image requests with natural language\n- **üîç Context-Aware Image Selection**: Interprets vague requests intelligently, delivering relevant images even from abstract prompts\n- **‚ö° Single Tool Efficiency**: Eliminates tool spam with a unified `stock_photo` tool that handles the entire image workflow\n- **üìä Resource Optimization**: URL-first approach conserves bandwidth and storage while maintaining flexibility\n- **‚úÖ Automatic Attribution**: Built-in compliance with Unsplash's Terms of Service with zero developer effort\n- **üìÅ Project-Aware Organization**: Intelligently organizes images based on your project structure (Next.js, React, Vue, etc.)\n- **üß© Seamless Integration**: Designed for minimal setup and maximum compatibility with your existing workflow\n\n## ‚ú® Features Beyond Comparison\n\n### For AI Agent Developers\n\n- **Smart Contextual Search**: Find the perfect image through natural language requests\n- **Automatic Subject Selection**: AI determines optimal image subjects from your purpose description\n- **Intent-Driven Results**: Get images that match not just keywords, but the underlying intent\n- **Seamless Agent Integration**: Works out-of-the-box with Claude in Cursor and other MCP-compatible agents\n\n### For Project Efficiency\n\n- **Two-Step Workflow**: Get URLs for controlled downloads, avoiding permission issues and unnecessary storage\n- **Project-Aware File Management**: Auto-organizes images based on framework conventions\n- **Intelligent Directory Creation**: Creates appropriate folder structures based on your project type\n- **Progressive Enhancement**: Works with any project size, from quick prototypes to enterprise applications\n\n### For Compliance Peace of Mind\n\n- **Complete Attribution Management**:\n  - Local attribution database tracks all image usage\n  - Automatic embedding of photographer metadata in images (EXIF, IPTC, XMP)\n  - One-click generation of attribution pages in multiple formats\n  - Comprehensive API for attribution data\n\n## üõ†Ô∏è Installation\n\n### Prerequisites\n\n- Node.js 18.x or higher\n- An Unsplash API access key ([get one here](https://unsplash.com/developers))\n\n### Local Installation (Recommended)\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure your Cursor MCP settings:\n   - macOS: Edit `~/.cursor/mcp.json`\n   - Windows: Edit `%USERPROFILE%\\.cursor\\mcp.json`\n   - Linux: Edit `~/.cursor/mcp.json`\n\n4. Add the following configuration:\n```json\n{\n  \"servers\": {\n    \"unsplash\": {\n      \"command\": \"npx\",\n      \"args\": [\"tsx\", \"src/server.ts\"],\n      \"cwd\": \"/absolute/path/to/unsplash-smart-mcp-server\",\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n5. Replace:\n   - `/absolute/path/to/unsplash-smart-mcp-server` with the actual path where you cloned the repo\n   - `your_api_key_here` with your Unsplash API key\n\n6. Save the file and restart Cursor.\n\n\u003e **Important:** Unlike many MCP servers, this server requires direct process piping and cannot be accessed via TCP ports or through npm directly due to how it handles FastMCP's I/O interactions. The local installation method is the most reliable approach.\n\n### Cursor CLI Alternative\n\nIf you prefer using Cursor's CLI:\n\n```bash\nclaude mcp add unsplash npx tsx /path/to/unsplash-smart-mcp-server/src/server.ts --cwd /path/to/unsplash-smart-mcp-server\nclaude mcp config set unsplash UNSPLASH_ACCESS_KEY=your_api_key_here\n```\n\nReplace the paths and API key with your actual values.\n\n### Via Docker (Most Reliable Method)\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n```\n\n2. Create a `docker-compose.yml` file:\n```yaml\nservices:\n  unsplash-mcp:\n    build: .\n    image: unsplash-mcp-server\n    restart: always\n    stdin_open: true\n    tty: true\n    environment:\n      - UNSPLASH_ACCESS_KEY=your_api_key_here\n```\n\n3. Build and start the container:\n```bash\ndocker-compose up -d\n```\n\n4. Configure your Cursor MCP settings:\n   - macOS: Edit `~/.cursor/mcp.json`\n   - Windows: Edit `%USERPROFILE%\\.cursor\\mcp.json`\n   - Linux: Edit `~/.cursor/mcp.json`\n\n5. Add the following configuration:\n```json\n{\n  \"servers\": {\n    \"unsplash\": {\n      \"command\": \"docker\",\n      \"args\": [\"exec\", \"-i\", \"unsplash-mcp-unsplash-mcp-1\", \"tsx\", \"src/server.ts\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\n6. Save the file and restart Cursor.\n\nThis setup will:\n- Start the server automatically when Docker starts\n- Restart the server if it crashes\n- Run in the background without terminal windows\n- Provide a reliable connection to Cursor\n\n### Via Smithery (Cloud Deployment)\n\nIf you prefer cloud deployment, you can use Smithery:\n\n1. Install the server in Cursor via Smithery:\n\n```bash\nnpx @smithery/cli install @drumnation/unsplash-smart-mcp-server --client cursor --key your_api_key_here\n```\n\n2. Alternatively, you can log in to [Smithery.ai](https://smithery.ai) and deploy it through their web interface.\n\n\u003e **Note for Windows users:** Smithery deployment includes special handling for Windows compatibility.\n\nFor detailed instructions and troubleshooting, see the [Smithery Deployment Guide](./docs/smithery-deployment.md).\n\n## üß© Integration with AI Agents\n\n### Step-by-Step Guide for Claude in Cursor\n\nOur Unsplash Smart MCP Server is designed to make image acquisition through AI agents effortless and intuitive:\n\n1. **Initiate a request**: Simply ask Claude for an image in natural language\n2. **AI interpretation**: Claude understands your needs and calls the `stock_photo` tool with optimized parameters\n3. **Smart image selection**: The server interprets context and finds the most relevant images\n4. **Presentation of options**: Claude presents you with the best matches and download commands\n5. **Seamless download**: Execute the suggested commands to place images exactly where you need them\n6. **Automatic attribution**: All attribution data is stored and can be accessed whenever needed\n\nThis process eliminates the traditional workflow of:\n1. ~~Searching Unsplash manually~~\n2. ~~Scrolling through hundreds of results~~\n3. ~~Downloading images to random locations~~\n4. ~~Moving files to the correct project folders~~\n5. ~~Manually tracking attribution data~~\n6. ~~Creating attribution pages~~\n\n### Example Prompts for AI Agents\n\nAsk Claude in Cursor for images using natural language prompts like these:\n\n```\n\"Find a professional image for a tech startup landing page hero section\"\n```\n\n## ü™ü Windows Compatibility\n\nIf you're using Windows and experiencing the \"Client closed\" error when running the MCP server in Cursor, follow these special configuration steps:\n\n### Windows-specific MCP Configuration\n\nCreate a file named `mcp.json` in your `.cursor` directory (typically at `%USERPROFILE%\\.cursor\\mcp.json`) with one of these configurations:\n\n#### Option 1: Direct Node Execution (Recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"stock_photo\": {\n      \"command\": \"node\",\n      \"args\": [\"./node_modules/.bin/tsx\", \"path/to/unsplash-mcp/src/server.ts\"],\n      \"disabled\": false,\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      },\n      \"shell\": false\n    }\n  }\n}\n```\n\n#### Option 2: PowerShell Approach\n\n```json\n{\n  \"mcpServers\": {\n    \"stock_photo\": {\n      \"command\": \"powershell\",\n      \"args\": [\"-Command\", \"npx tsx path/to/unsplash-mcp/src/server.ts\"],\n      \"disabled\": false,\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\nFor complete documentation on Windows compatibility, see [Windows Compatibility Guide](./docs/windows-compatibility.md).\n\n## üõ†Ô∏è API Reference\n\n### URL-First Approach: The Smart Choice\n\nOur architecture uses a URL-first approach rather than direct image embedding for several critical reasons:\n\n1. **Storage Efficiency**: Prevents AI agents from unnecessarily storing large binary data in their context\n2. **Bandwidth Conservation**: Reduces data transfer between services, improving response times\n3. **Placement Flexibility**: Allows developers to download images exactly where they're needed\n4. **Permission Management**: Avoids filesystem permission issues in restricted environments\n5. **Workflow Integration**: Seamlessly integrates with existing development pipelines\n\nThis strategy enables AI agents to intelligently suggest the optimal download location based on project context, without being constrained by their own environment limitations.\n\n### Minimizing Tool Spam and API Calls\n\nUnlike other solutions that require multiple tool calls for searching, filtering, downloading, and attributing images, our server:\n\n- **Unifies the entire image workflow** into a single `stock_photo` tool\n- **Optimizes result retrieval** by requesting more images upfront to enable better filtering\n- **Eliminates ping-pong interactions** between the agent and services\n- **Reduces agent token usage** by streamlining request and response formats\n\nThis design significantly reduces the number of API calls and tool invocations, leading to faster results and lower operational costs.\n\n## üîÑ Automatic Attribution and Compliance\n\n### Unsplash Terms of Service: Effortless Compliance\n\nUsing images from Unsplash requires adherence to their [Terms of Service](https://unsplash.com/license). Our server handles this automatically:\n\n1. **Attribution Data Capture**: Every image download automatically stores photographer information\n2. **Metadata Embedding**: Photographer details are embedded directly into image files\n3. **Attribution Database**: A local database maintains a record of all image usage\n4. **Attribution Generators**: Built-in tools create HTML and React attribution components\n5. **API Access**: Simple endpoints to retrieve attribution data for any project\n\nBy using our Unsplash Smart MCP Server, you are automatically compliant with Unsplash's requirements without any additional effort.\n\n### Attribution Management System\n\nThe server includes a comprehensive attribution management system:\n\n```javascript\n// Retrieve attribution data for your project\nconst attributions = await fetch('http://localhost:3000/api/unsplash', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    method: 'get_attributions',\n    params: {\n      format: 'json',  // Options: json, html, react\n      projectPath: '/path/to/your/project'\n    }\n  })\n}).then(res =\u003e res.json());\n\n// attributions contains complete data about every image used\n```\n\nThe API can generate three types of attribution files:\n\n1. **JSON**: Structured data for custom implementations\n2. **HTML**: Ready-to-use HTML page for website footer or credits section\n3. **React**: Drop-in React component for modern web applications\n\n## üíº Developer Workflow Integration\n\n### Real-World Use Cases\n\nOur Unsplash Smart MCP Server seamlessly integrates into your development workflow:\n\n#### UI Development\n- Instantly populate mockups with relevant placeholder images\n- Maintain consistent image dimensions across components\n- Organize images logically within your project structure\n\n#### Documentation\n- Enhance technical documentation with explanatory visuals\n- Create visually appealing tutorials and guides\n- Maintain proper attribution for all visual assets\n\n#### Content Creation\n- Quickly find images for blog posts and articles\n- Generate visuals for social media content\n- Access consistent imagery for product marketing\n\n#### Application Development\n- Populate e-commerce sites with product imagery\n- Create visually rich user experiences\n- Maintain separate image collections for different sections\n\n### Framework-Specific Organization\n\nImages are automatically organized based on your project type:\n\n| Framework | Default Image Path | Alternate Paths |\n|-----------|-------------------|----------------|\n| Next.js   | `/public/images/` | `/public/assets/images/` |\n| React     | `/src/assets/images/` | `/assets/images/` |\n| Vue       | `/src/assets/images/` | `/public/images/` |\n| Angular   | `/src/assets/images/` | `/assets/images/` |\n| Generic   | `/assets/images/` | `~/Downloads/stock-photos/` |\n\n## ü•á Competitive Differentiation\n\n### Why Choose Our Unsplash Integration?\n\n| Feature | Unsplash Smart MCP Server | Alternatives |\n|---------|--------------|--------------|\n| **AI Agent Integration** | ‚úÖ Purpose-built for AI agent workflow | ‚ùå Typically requires manual parameter setting |\n| **Context Awareness** | ‚úÖ Interprets vague requests intelligently | ‚ùå Relies on exact keyword matching |\n| **Tool Efficiency** | ‚úÖ Single tool handles entire workflow | ‚ùå Often requires multiple separate tools |\n| **Attribution Management** | ‚úÖ Comprehensive system with multiple formats | ‚ùå Manual tracking or basic text output |\n| **Project Organization** | ‚úÖ Framework-aware folder structures | ‚ùå Generic downloads to a single location |\n| **Installation Complexity** | ‚úÖ Simple one-line command | ‚ùå Often requires multiple configuration steps |\n| **Response Format** | ‚úÖ AI-optimized with relevant context | ‚ùå Generic JSON requiring further processing |\n| **Download Flexibility** | ‚úÖ URL-first with intelligent suggestions | ‚ùå Either direct downloads or just URLs |\n\n## ‚öôÔ∏è Configuration\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `UNSPLASH_ACCESS_KEY` | Your Unsplash API access key | - |\n| `PORT` | Port for the server to listen on | `3000` |\n| `HOST` | Host for the server | `localhost` |\n| `ATTRIBUTION_DB_PATH` | Path to store attribution database | `~/.unsplash-mcp` |\n\n### Tool Parameters\n\n#### stock_photo\n\n| Parameter | Type | Description | Default |\n|-----------|------|-------------|---------|\n| `query` | string | What to search for (AI will choose if not specified) | - |\n| `purpose` | string | Where the image will be used (e.g., hero, background) | - |\n| `count` | number | Number of images to return | `1` |\n| `orientation` | string | Preferred orientation (any, landscape, portrait, square) | `any` |\n| `width` | number | Target width in pixels | - |\n| `height` | number | Target height in pixels | - |\n| `minWidth` | number | Minimum width for filtering results | - |\n| `minHeight` | number | Minimum height for filtering results | - |\n| `outputDir` | string | Directory to save photos | `~/Downloads/stock-photos` |\n| `projectType` | string | Project type for folder structure (next, react, vue, angular) | - |\n| `category` | string | Category for organizing images (e.g., heroes, backgrounds) | - |\n| `downloadMode` | string | Whether to download images or return URLs | `urls_only` |\n\n#### get_attributions\n\n| Parameter | Type | Description | Default |\n|-----------|------|-------------|---------|\n| `format` | string | Output format (json, html, react) | `json` |\n| `projectPath` | string | Filter attributions to a specific project path | - |\n| `outputPath` | string | Where to save attribution files | - |\n\n## üîß Troubleshooting\n\n### Common Issues and Solutions\n\n| Issue | Solution |\n|-------|----------|\n| **Connection Refused** | Ensure the server is running on the configured port |\n| **Authentication Error** | Verify your Unsplash API key is correctly set |\n| **No Images Found** | Try broader search terms or check your search query |\n| **Download Permission Issues** | Use `downloadMode: 'urls_only'` and manual download commands |\n| **Docker Container Exits Prematurely** | Ensure you're using `CMD [\"npm\", \"start\"]` in your Dockerfile instead of directly running the TypeScript file with tsx. This ensures the server stays running in a Docker environment. |\n| **Timeout Errors** | The default MCP timeout is 60 seconds, which may be insufficient for downloading larger images or processing multiple images. For image-heavy operations: 1) Process fewer images per request, 2) Use smaller image dimensions, 3) Consider using `urls_only` mode instead of auto-download, 4) Check network connectivity |\n| **Attribution Not Found** | Verify the image was downloaded through the MCP server |\n| **Unhandled MCP Errors** | If you see `\"McpError: MCP error -32001: Request timed out\"` errors, your request is likely taking too long. Break it into smaller operations or use the URLs-only approach |\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n### Development Workflow\n\n1. Clone the repository\n2. Install dependencies with `npm install`\n3. Create a `.env` file with your Unsplash API key\n4. Run in development mode with `npm run dev`\n5. Run tests with `npm test`\n\n## üó∫Ô∏è Roadmap\n\nHere's what we're planning for future releases:\n\n- **Image Editing Capabilities**: Basic resizing, cropping, and adjustment tools\n- **Advanced Search Filters**: More granular control over image selection\n- **Batch Processing**: Handle multiple image requests efficiently\n- **Custom Collections**: Save and manage groups of images for projects\n- **Team Collaboration**: Share attribution and image collections\n- **Usage Analytics**: Track image usage across projects\n- **Additional Image Sources**: Integration with other stock photo providers\n- **Improved Timeout Handling**: Enhanced timeout configuration and recovery mechanisms\n\n## üìÑ License\n\nMIT License\n\n## üìö Attribution Requirements\n\nWhen using images from Unsplash, you must comply with the [Unsplash License](https://unsplash.com/license):\n\n- Attribution is not required but appreciated\n- You cannot sell unaltered copies of the photos\n- You cannot compile photos from Unsplash to create a competing service\n\nOur server's attribution system makes it easy to provide proper credit to photographers.\n\n## üìû Contact\n\nFor issues or questions, please [open an issue](https://github.com/drumnation/unsplash-smart-mcp-server/issues) on GitHub.\n\n## üß∞ Development and Testing\n\n### Running the Server Locally\n\n```bash\n# Clone the repository\ngit clone https://github.com/drumnation/unsplash-smart-mcp-server.git\ncd unsplash-smart-mcp-server\n\n# Install dependencies\nnpm install\n\n# Set up your environment variables\ncp .env.example .env\n# Edit .env to add your UNSPLASH_ACCESS_KEY\n\n# Start the development server\nnpm run dev\n```\n\n### Testing\n\nThe package includes a comprehensive test suite:\n\n```bash\n# Run core tests\nnpm test\n\n# Run all tests and get a summary report\nnpm run test:all\n```\n\nThe test suite includes:\n- Unit and integration tests\n- Manual tool testing\n- Docker container tests\n- Smithery.ai integration tests\n\nFor detailed information about testing, see [docs/testing.md](docs/testing.md).\n\n---\n\n\u003cp align=\"center\"\u003e\n  \u003cstrong\u003eEmpower your AI agents with the perfect images, every time.\u003c/strong\u003e\u003cbr\u003e\n  Built with ‚ù§Ô∏è for developers and AI enthusiasts.\n\u003c/p\u003e\n",
      "stars": 47,
      "updated_at": "2025-10-02T20:15:22Z",
      "url": "https://github.com/drumnation/unsplash-smart-mcp-server"
    },
    "dvejsada--mcp_media_generator": {
      "category": "image-and-video-generation",
      "description": "Create images using the Amazon Nova Canvas model and videos using the Amazon Nova Reel model. Connects to existing tools for media generation and storage.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/dvejsada.webp",
      "keywords": [
        "mcp_media_generator",
        "dvejsada",
        "videos",
        "dvejsada mcp_media_generator",
        "video generation",
        "generation dvejsada"
      ],
      "language": "Python",
      "license": "No License",
      "name": "mcp_media_generator",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "dvejsada",
      "readme_content": "# What is it?\n\nA [Model Context Protocol](https://modelcontextprotocol.io/) Server running over SSE\n\n# What it offers?\n\nTools to create images using Amazon Nova Canvas model and videos using Amazon Nova Reel model.\n\n# What do I need?\n\n- Amazon Bedrock account with access to Amazon Nova Canvas and Amazon Nova Reel models.\n- Amazon S3 bucket to store the video\n- MCP Client, such is Claude Desktop or [LibreChat](https://github.com/danny-avila/LibreChat)\n\n# How to run this?\n\nUsing Docker with precompiled image as per docker-compose.yml. App is listening on port 8961.\n\n## How to add to LibreChat\n\nIn your librechat.yaml file, add the following section:\n\n```yaml\nmcpServers:\n  media-creator:\n    type: sse # type can optionally be omitted\n    url: URL of your docker container # e.g. http://localhost:8961/sse\n```\n\n## How to use in LibreChat\n\nAfter the server is added to LibreChat as per above, restart LibreChat to connect to MCP server and discover tools. Then, create an agent and add the respective tools to agent.\n\nWhen the agent is created, you may ask the agent to create image or video which should invoke the provided tools.\n",
      "stars": 3,
      "updated_at": "2025-09-16T11:26:11Z",
      "url": "https://github.com/dvejsada/mcp_media_generator"
    },
    "el-el-san--vidu-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generate videos from static images using advanced AI models, while monitoring the status of video generation tasks and uploading images for processing.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/el-el-san.webp",
      "keywords": [
        "ai",
        "videos",
        "vidu",
        "generate videos",
        "video generation",
        "image video"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "vidu-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "el-el-san",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/el-el-san-vidu-mcp-server-badge.png)](https://mseep.ai/app/el-el-san-vidu-mcp-server)\n\n# Vidu MCP Server\n[![smithery badge](https://smithery.ai/badge/@el-el-san/vidu-mcp-server)](https://smithery.ai/server/@el-el-san/vidu-mcp-server)\n\nViduÂãïÁîªÁîüÊàêAPI„Å®ÈÄ£Êê∫„Åô„Çã„Åü„ÇÅ„ÅÆModel Context Protocol (MCP) „Çµ„Éº„Éê„Éº„Åß„Åô„ÄÇVidu„ÅÆÂº∑Âäõ„Å™AI„É¢„Éá„É´„Çí‰ΩøÁî®„Åó„Å¶„ÄÅÁîªÂÉè„Åã„ÇâÂãïÁîª„ÇíÁîüÊàê„Åô„Çã„ÉÑ„Éº„É´„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ\n\n## Ê©üËÉΩ\n\n- **ÁîªÂÉè„Åã„ÇâÂãïÁîª„Å∏„ÅÆÂ§âÊèõ**: „Ç´„Çπ„Çø„Éû„Ç§„Ç∫ÂèØËÉΩ„Å™Ë®≠ÂÆö„ÅßÈùôÊ≠¢Áîª„Åã„ÇâÂãïÁîª„ÇíÁîüÊàê\n  - Ë§áÊï∞„É¢„Éá„É´ÂØæÂøú: viduq1„ÄÅvidu1.5„ÄÅvidu2.0\n  - „É¢„Éá„É´Âõ∫Êúâ„ÅÆÊôÇÈñì„ÉªËß£ÂÉèÂ∫¶Âà∂Á¥Ñ\n  - 4ÁßíÂãïÁîªÂêë„Åë„ÅÆBGMÂØæÂøú\n  - ÈùûÂêåÊúüÈÄöÁü•Áî®„ÅÆ„Ç≥„Éº„É´„Éê„ÉÉ„ÇØURLÂØæÂøú\n- **ÁîüÊàêÁä∂Ê≥Å„ÅÆÁ¢∫Ë™ç**: „ÇØ„É¨„Ç∏„ÉÉ„Éà‰ΩøÁî®ÈáèÊÉÖÂ†±‰ªò„Åç„ÅßÂãïÁîªÁîüÊàê„Çø„Çπ„ÇØ„ÅÆÈÄ≤Êçó„ÇíÁõ£Ë¶ñ\n- **ÁîªÂÉè„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ**: Vidu API„Åß‰ΩøÁî®„Åô„ÇãÁîªÂÉè„ÇíÁ∞°Âçò„Å´„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÔºàÊúÄÂ§ß10MBÔºâ\n\n## ÂâçÊèêÊù°‰ª∂\n\n- Node.js (v14‰ª•‰∏ä)\n- Vidu API„Ç≠„ÉºÔºà[Vidu„Ç¶„Çß„Éñ„Çµ„Ç§„Éà](https://vidu.com)„Åã„ÇâÂèñÂæóÂèØËÉΩÔºâ\n- TypeScriptÔºàÈñãÁô∫Áî®Ôºâ\n\n## „Ç§„É≥„Çπ„Éà„Éº„É´\n\n### SmitheryÁµåÁî±„Åß„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n\n[Smithery](https://smithery.ai/server/@el-el-san/vidu-mcp-server)„Çí‰ΩøÁî®„Åó„Å¶Claude DesktopÁî®„ÅÆVidu Video Generation Server„ÇíËá™Âãï„Ç§„É≥„Çπ„Éà„Éº„É´:\n\n```bash\nnpx -y @smithery/cli install @el-el-san/vidu-mcp-server --client claude\n```\n\n### Gemini CLIË®≠ÂÆö\n\nGemini CLI„Åß‰ΩøÁî®„Åô„Çã„Å´„ÅØ„ÄÅ`~/.gemini/settings.json`„Å´„Çµ„Éº„Éê„ÉºË®≠ÂÆö„ÇíËøΩÂä†„Åó„Å¶„Åè„Å†„Åï„ÅÑ:\n\n```json\n{\n  \"mcpServers\": {\n    \"vidu\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"your_path/vidu-mcp-server/build/index.js\"\n      ],\n      \"env\": {\n        \"VIDU_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n**Ê≥®ÊÑè**: `your_path`„ÇíÂÆüÈöõ„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆ„Éë„Çπ„Å´„ÄÅ`your_api_key_here`„Çí„ÅÇ„Å™„Åü„ÅÆVidu API„Ç≠„Éº„Å´ÁΩÆ„ÅçÊèõ„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n\n### ÊâãÂãï„Ç§„É≥„Çπ„Éà„Éº„É´\n1. „Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„Çí„ÇØ„É≠„Éº„É≥:\n```bash\ngit clone https://github.com/el-el-san/vidu-mcp-server.git\ncd vidu-mcp-server\n```\n\n2. ‰æùÂ≠òÈñ¢‰øÇ„Çí„Ç§„É≥„Çπ„Éà„Éº„É´:\n```bash\nnpm install\n```\n\n3. `.env.template`„ÇíÂü∫„Å´`.env`„Éï„Ç°„Ç§„É´„Çí‰ΩúÊàê„Åó„ÄÅVidu API„Ç≠„Éº„ÇíËøΩÂä†:\n```\nVIDU_API_KEY=your_api_key_here\n```\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\n### Gemini CLIÁî®\n\n1. TypeScript„Ç≥„Éº„Éâ„Çí„Éì„É´„Éâ:\n```bash\nnpm run build\n```\n\n2. Gemini CLIË®≠ÂÆö„ÅßË®≠ÂÆöÔºà‰∏äË®ò„ÅÆGemini CLIË®≠ÂÆö„Çª„ÇØ„Ç∑„Éß„É≥„ÇíÂèÇÁÖßÔºâ\n\n3. Gemini CLI„ÇíÂÜçËµ∑Âãï„Åó„Å¶MCP„ÇíË™≠„ÅøËæº„Åø\n\n## „ÉÑ„Éº„É´\n\n### 1. ÁîªÂÉè„Åã„ÇâÂãïÁîª„Å∏„ÅÆÂ§âÊèõ\n\n„Ç´„Çπ„Çø„Éû„Ç§„Ç∫ÂèØËÉΩ„Å™„Éë„É©„É°„Éº„Çø„ÅßÈùôÊ≠¢Áîª„ÇíÂãïÁîª„Å´Â§âÊèõ„Åó„Åæ„Åô„ÄÇ\n\n„Éë„É©„É°„Éº„Çø:\n- `image_url` (ÂøÖÈ†à): ÂãïÁîª„Å´Â§âÊèõ„Åô„ÇãÁîªÂÉè„ÅÆURL\n- `prompt` („Ç™„Éó„Ç∑„Éß„É≥): ÂãïÁîªÁîüÊàêÁî®„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„Éó„É≠„É≥„Éó„ÉàÔºàÊúÄÂ§ß1500ÊñáÂ≠óÔºâ\n- `duration` („Ç™„Éó„Ç∑„Éß„É≥): Âá∫ÂäõÂãïÁîª„ÅÆÊôÇÈñìÔºàÁßíÔºâÔºà„É¢„Éá„É´Âõ∫ÊúâÔºâ\n  - **viduq1**: 5Áßí„ÅÆ„Åø\n  - **vidu1.5/vidu2.0**: 4Áßí„Åæ„Åü„ÅØ8ÁßíÔºà„Éá„Éï„Ç©„É´„Éà4ÁßíÔºâ\n- `model` („Ç™„Éó„Ç∑„Éß„É≥): ÁîüÊàêÁî®„É¢„Éá„É´ÂêçÔºà\"viduq1\", \"vidu1.5\", \"vidu2.0\", „Éá„Éï„Ç©„É´„Éà \"vidu2.0\"Ôºâ\n- `resolution` („Ç™„Éó„Ç∑„Éß„É≥): Âá∫ÂäõÂãïÁîª„ÅÆËß£ÂÉèÂ∫¶Ôºà„É¢„Éá„É´/ÊôÇÈñìÂõ∫ÊúâÔºâ\n  - **viduq1 (5s)**: 1080p„ÅÆ„Åø\n  - **vidu1.5/vidu2.0 (4s)**: \"360p\", \"720p\", \"1080p\"Ôºà„Éá„Éï„Ç©„É´„Éà \"360p\"Ôºâ\n  - **vidu1.5/vidu2.0 (8s)**: \"720p\"„ÅÆ„Åø\n- `movement_amplitude` („Ç™„Éó„Ç∑„Éß„É≥): „Éï„É¨„Éº„É†ÂÜÖ„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÅÆÂãï„Åç„ÅÆÊåØÂπÖÔºà\"auto\", \"small\", \"medium\", \"large\", „Éá„Éï„Ç©„É´„Éà \"auto\"Ôºâ\n- `seed` („Ç™„Éó„Ç∑„Éß„É≥): ÂÜçÁèæÊÄß„ÅÆ„Åü„ÇÅ„ÅÆ„É©„É≥„ÉÄ„É†„Ç∑„Éº„Éâ\n- `bgm` („Ç™„Éó„Ç∑„Éß„É≥): ÂãïÁîª„Å´BGM„ÇíËøΩÂä†Ôºàboolean, „Éá„Éï„Ç©„É´„Éà false, 4ÁßíÂãïÁîª„ÅÆ„ÅøÔºâ\n- `callback_url` („Ç™„Éó„Ç∑„Éß„É≥): ÁîüÊàêÁä∂Ê≥ÅÂ§âÊõ¥ÊôÇ„ÅÆÈùûÂêåÊúüÈÄöÁü•Áî®URL\n\n„É™„ÇØ„Ç®„Çπ„Éà‰æã:\n```json\n{\n  \"image_url\": \"https://example.com/image.jpg\",\n  \"prompt\": \"Â±±„ÇíËÉåÊôØ„Å´„Åó„ÅüÈùô„Åã„Å™Êπñ\",\n  \"duration\": 8,\n  \"model\": \"vidu2.0\",\n  \"resolution\": \"720p\",\n  \"movement_amplitude\": \"medium\",\n  \"seed\": 12345,\n  \"bgm\": false\n}\n```\n\n### 2. ÁîüÊàêÁä∂Ê≥Å„ÅÆÁ¢∫Ë™ç\n\nÂÆüË°å‰∏≠„ÅÆÂãïÁîªÁîüÊàê„Çø„Çπ„ÇØ„ÅÆÁä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åó„Åæ„Åô„ÄÇ\n\n„Éë„É©„É°„Éº„Çø:\n- `task_id` (ÂøÖÈ†à): ÁîªÂÉè„Åã„ÇâÂãïÁîª„Å∏„ÅÆÂ§âÊèõ„ÉÑ„Éº„É´„ÅßËøî„Åï„Çå„Åü„Çø„Çπ„ÇØID\n\n„É™„ÇØ„Ç®„Çπ„Éà‰æã:\n```json\n{\n  \"task_id\": \"12345abcde\"\n}\n```\n\n### 3. ÁîªÂÉè„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ\n\nVidu API„Åß‰ΩøÁî®„Åô„ÇãÁîªÂÉè„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Åæ„Åô„ÄÇ\n\n„Éë„É©„É°„Éº„Çø:\n- `image_path` (ÂøÖÈ†à): ÁîªÂÉè„Éï„Ç°„Ç§„É´„ÅÆ„É≠„Éº„Ç´„É´„Éë„Çπ\n- `image_type` (ÂøÖÈ†à): ÁîªÂÉè„Éï„Ç°„Ç§„É´„Çø„Ç§„ÉóÔºà\"png\", \"webp\", \"jpeg\", \"jpg\"Ôºâ\n\n„É™„ÇØ„Ç®„Çπ„Éà‰æã:\n```json\n{\n  \"image_path\": \"/path/to/your/image.jpg\",\n  \"image_type\": \"jpg\"\n}\n```\n\n## „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞\n\n- **API„Ç≠„Éº„ÅÆÂïèÈ°å**: Vidu API„Ç≠„Éº„Åå`.env`„Éï„Ç°„Ç§„É´ÔºàÊâãÂãïË®≠ÂÆö„ÅÆÂ†¥ÂêàÔºâ„Åæ„Åü„ÅØGemini CLIË®≠ÂÆöÔºàGemini CLIË®≠ÂÆö„ÅÆÂ†¥ÂêàÔºâ„ÅßÊ≠£„Åó„ÅèË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n- **„Éï„Ç°„Ç§„É´„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Ç®„É©„Éº**: ÁîªÂÉè„Éï„Ç°„Ç§„É´„ÅåÊúâÂäπ„Åß„ÄÅ„Çµ„Ç§„Ç∫Âà∂ÈôêÂÜÖÔºàupload-image„ÉÑ„Éº„É´„ÅØ10MB„ÄÅÁõ¥Êé•URLÁîªÂÉè„ÅØÊúÄÂ§ß50MBÔºâ„Åß„ÅÇ„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n- **Êé•Á∂öÂïèÈ°å**: „Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„Ç¢„ÇØ„Çª„Çπ„Åå„ÅÇ„Çä„ÄÅVidu API„Çµ„Éº„Éê„Éº„Å´Âà∞ÈÅî„Åß„Åç„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n- **Gemini CLI„ÅÆÂïèÈ°å**: \n  - Gemini CLI„ÅßË®≠ÂÆö„Åô„ÇãÂâç„Å´„Çµ„Éº„Éê„Éº„Åå„Éì„É´„Éâ„Åï„Çå„Å¶„ÅÑ„ÇãÔºà`npm run build`Ôºâ„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n  - settings.json„ÅÆ„Éë„Çπ„ÅåÊ≠£„Åó„ÅÑ`build/index.js`„Éï„Ç°„Ç§„É´„ÇíÊåá„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n  - Ë®≠ÂÆöÂ§âÊõ¥Âæå„Å´Gemini CLI„ÇíÂÜçËµ∑Âãï„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n  - „Çµ„Éº„Éê„ÉºË®≠ÂÆö„Åß`\"disabled\": false`„Å´Ë®≠ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n\n\n\n",
      "stars": 3,
      "updated_at": "2025-09-09T11:11:26Z",
      "url": "https://github.com/el-el-san/vidu-mcp-server"
    },
    "evalstate--mcp-hfspace": {
      "category": "image-and-video-generation",
      "description": "Connects to Hugging Face Spaces to access various AI models for tasks including image generation, text-to-speech, speech-to-text, and chat functionalities, requiring minimal setup.",
      "forks": 57,
      "imageUrl": "/freedevtools/mcp/pfp/evalstate.webp",
      "keywords": [
        "hfspace",
        "ai",
        "mcp",
        "mcp hfspace",
        "face spaces",
        "image generation"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "mcp-hfspace",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "evalstate",
      "readme_content": "# mcp-hfspace MCP Server ü§ó\n\n\u003e [!TIP]\n\u003e\n\u003e You can access and configure Hugging Face MCP services directly at https://hf.co/mcp, including Gradio spaces.\n\u003e\n\u003e This project has been superceded by the official [Hugging Face MCP Server](https://github.com/evalstate/hf-mcp-server) and [Gradio MCP Endpoints](https://huggingface.co/blog/gradio-mcp).\n\u003e \n\u003e Alternatively you can run hf-mcp-server locally as a STDIO Server, or with robust support for SSE, Streaming HTTP and Streaming HTTP JSON Mode. This also runs a local UI for selecting tools and endpoints and supports `ToolListChangedNotifications` too.\n\n## hf.co/mcp\n\n![image](https://github.com/user-attachments/assets/9cbf407b-2330-4330-8274-e47305a555b9)\n\n## mcp-hfspace\n\nRead the introduction here [llmindset.co.uk/resources/mcp-hfspace/](https://llmindset.co.uk/resources/mcp-hfspace/)\n\nConnect to [Hugging Face Spaces](https://huggingface.co/spaces) with minimal setup needed - simply add your spaces and go!\n\nBy default, it connects to `black-forest-labs/FLUX.1-schnell` providing Image Generation capabilities to Claude Desktop.\n\n\n\n\n\n\n\n## Gradio MCP Support\n\n\u003e [!TIP]\n\u003e Gradio 5.28 now has integrated MCP Support via SSE: https://huggingface.co/blog/gradio-mcp. Check out whether your target Space is MCP Enabled!\n\n## Installation\n\nNPM Package is `@llmindset/mcp-hfspace`.\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform, then add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\"\n      ]\n    }\n```\n\nPlease make sure you are using Claude Desktop 0.78 or greater.\n\nThis will get you started with an Image Generator.\n\n### Basic setup\n\nSupply a list of HuggingFace spaces in the arguments. mcp-hfspace will find the most appropriate endpoint and automatically configure it for usage. An example `claude_desktop_config.json` is supplied [below](#installation).\n\nBy default the current working directory is used for file upload/download. On Windows this is a read/write folder at `\\users\\\u003cusername\u003e\\AppData\\Roaming\\Claude\\\u003cversion.number\\`, and on MacOS it is the is the read-only root: `/`.\n\nIt is recommended to override this and set a Working Directory for handling the upload and download of images and other file-based content. Specify either the `--work-dir=/your_directory` argument or `MCP_HF_WORK_DIR` environment variable.\n\nAn example configuration for using a modern image generator, vision model and text to speech, with a working directory set is below:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=/Users/evalstate/mcp-store\",\n        \"shuttleai/shuttle-jaguar\",\n        \"styletts2/styletts2\",\n        \"Qwen/QVQ-72B-preview\"\n      ]\n    }\n```\n\nTo use private spaces, supply your Hugging Face Token with either the `--hf-token=hf_...` argument or `HF_TOKEN` environment variable.\n\nIt's possible to run multiple server instances to use different working directories and tokens if needed.\n\n## File Handling and Claude Desktop Mode\n\nBy default, the Server operates in _Claude Desktop Mode_. In this mode, Images are returned in the tool responses, while other files are saved in the working folder, their file path is returned as a message. This will usually give the best experience if using Claude Desktop as the client.\n\nURLs can also be supplied as inputs: the content gets passed to the Space.\n\nThere is an \"Available Resources\" prompt that gives Claude the available files and mime types from your working directory. This is currently the best way to manage files.\n\n### Example 1 - Image Generation (Download Image / Claude Vision)\n\nWe'll use Claude to compare images created by `shuttleai/shuttle-3.1-aesthetic` and `FLUX.1-schnell`. The images gets saved to the Work Directory, as well as included in Claude's context window - so Claude can use its vision capabilities.\n\n\n\n### Example 2 - Vision Model (Upload Image)\n\nWe'll use `merve/paligemma2-vqav2` [space link](https://huggingface.co/spaces/merve/paligemma2-vqav2) to query an image. In this case, we specify the filename which is available in the Working Directory: we don't want to upload the Image directly to Claude's context window. So, we can prompt Claude:\n\n`use paligemma to find out who is in \"test_gemma.jpg\"` -\u003e `Text Output: david bowie`\n\n\n_If you are uploading something to Claude's context use the Paperclip Attachment button, otherwise specify the filename for the Server to send directly._\n\nWe can also supply a URL. For example : `use paligemma to detect humans in https://e3.365dm.com/24/12/1600x900/skynews-taylor-swift-eras-tour_6771083.jpg?20241209000914` -\u003e `One person is detected in the image - Taylor Swift on stage.`\n\n### Example 3 - Text-to-Speech (Download Audio)\n\nIn _Claude Desktop Mode_, the audio file is saved in the WORK_DIR, and Claude is notified of the creation. If not in desktop mode, the file is returned as a base64 encoded resource to the Client (useful if it supports embedded Audio attachments).\n\n\n\n### Example 4 - Speech-to-Text (Upload Audio)\n\nHere, we use `hf-audio/whisper-large-v3-turbo` to transcribe some audio, and make it available to Claude.\n\n\n\n### Example 5 - Image-to-Image\n\nIn this example, we specify the filename for `microsoft/OmniParser` to use, and get returned an annotated Image and 2 separate pieces of text: descriptions and coordinates. The prompt used was `use omniparser to analyse ./screenshot.png` and `use the analysis to produce an artifact that reproduces that screen`. `DawnC/Pawmatch` is also good at this.\n\n\n\n### Example 6 - Chat\n\nIn this example, Claude sets a number of reasoning puzzles for Qwen, and asks follow-up questions for clarification.\n\n\n\n### Specifying API Endpoint\n\nIf you need, you can specify a specific API Endpoint by adding it to the spacename. So rather than passing in `Qwen/Qwen2.5-72B-Instruct` you would use `Qwen/Qwen2.5-72B-Instruct/model_chat`.\n\n### Claude Desktop Mode\n\nThis can be disabled with the option --desktop-mode=false or the environment variable CLAUDE_DESKTOP_MODE=false. In this case, content as returned as an embedded Base64 encoded Resource.\n\n## Recommended Spaces\n\nSome recommended spaces to try:\n\n### Image Generation\n\n- shuttleai/shuttle-3.1-aesthetic\n- black-forest-labs/FLUX.1-schnell\n- yanze/PuLID-FLUX\n- gokaygokay/Inspyrenet-Rembg (Background Removal)\n- diyism/Datou1111-shou_xin - [Beautiful Pencil Drawings](https://x.com/ClementDelangue/status/1867318931502895358)\n\n### Chat\n\n- Qwen/Qwen2.5-72B-Instruct\n- prithivMLmods/Mistral-7B-Instruct-v0.3\n\n### Text-to-speech / Audio Generation\n\n- fantaxy/Sound-AI-SFX\n- parler-tts/parler_tts\n\n### Speech-to-text\n\n- hf-audio/whisper-large-v3-turbo\n- (the openai models use unnamed parameters so will not work)\n\n### Text-to-music\n\n- haoheliu/audioldm2-text2audio-text2music\n\n### Vision Tasks\n\n- microsoft/OmniParser\n- merve/paligemma2-vqav2\n- merve/paligemma-doc\n- DawnC/PawMatchAI\n- DawnC/PawMatchAI/on_find_match_click - for interactive dog recommendations\n\n## Other Features\n\n### Prompts\n\nPrompts for each Space are generated, and provide an opportunity to input. Bear in mind that often Spaces aren't configured with particularly helpful labels etc. Claude is actually very good at figuring this out, and the Tool description is quite rich (but not visible in Claude Desktop).\n\n### Resources\n\nA list of files in the WORK_DIR is returned, and as a convenience returns the name as \"Use the file...\" text. If you want to add something to Claude's context, use the paperclip - otherwise specify the filename for the MCP Server. Claude does not support transmitting resources from within Context.\n\n### Private Spaces\n\nPrivate Spaces are supported with a HuggingFace token. The Token is used to download and save generated content.\n\n### Using Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-hfspace\": {\n      \"command\": \"npx\"\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=~/mcp-files/ or x:/temp/mcp-files/\",\n        \"--HF_TOKEN=HF_{optional token}\"\n        \"Qwen/Qwen2-72B-Instruct\",\n        \"black-forest-labs/FLUX.1-schnell\",\n        \"space/example/specific-endpint\"\n        (... and so on)\n        ]\n    }\n  }\n}\n```\n\n## Known Issues and Limitations\n\n### mcp-hfspace\n\n- Endpoints with unnamed parameters are unsupported for the moment.\n- Full translation from some complex Python types to suitable MCP formats.\n\n### Claude Desktop\n\n- Claude Desktop 0.75 doesn't seem to respond to errors from the MCP Server, timing out instead. For persistent issues, use the MCP Inspector to get a better look at diagnosing what's going wrong. If something suddenly stops working, it's probably due to exhausting your HuggingFace ZeroGPU quota - try again after a short period, or set up your own Space for hosting.\n- Claude Desktop seems to use a hard timeout value of 60s, and doesn't appear to use Progress Notifications to manage UX or keep-alive. If you are using ZeroGPU spaces, large/heavy jobs may timeout. Check the WORK_DIR for results though; the MCP Server will still capture and save the result if it was produced.\n- Claude Desktops reporting of Server Status, logging etc. isn't great - use [@modelcontextprotocol/inspector](https://github.com/modelcontextprotocol/inspector) to help diagnose issues.\n\n### HuggingFace Spaces\n\n- If ZeroGPU quotas or queues are too long, try duplicating the space. If your job takes less than sixty seconds, you can usually change the function decorator `@spaces.GPU(duration=20)` in `app.py` to request less quota when running the job.\n- Passing HF_TOKEN will make ZeroGPU quotas apply to your (Pro) HF account\n- If you have a private space, and dedicated hardware your HF_TOKEN will give you direct access to that - no quota's apply. I recommend this if you are using for any kind of Production task.\n\n## Third Party MCP Services\n\n\u003ca href=\"https://glama.ai/mcp/servers/s57c80wvgq\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/s57c80wvgq/badge\" alt=\"mcp-hfspace MCP server\" /\u003e\u003c/a\u003e",
      "stars": 360,
      "updated_at": "2025-10-03T22:31:58Z",
      "url": "https://github.com/evalstate/mcp-hfspace"
    },
    "evalstate--mcp-webcam": {
      "category": "image-and-video-generation",
      "description": "Streams live images from a webcam to an MCP Client, supporting both capturing frames and taking screenshots.",
      "forks": 10,
      "imageUrl": "/freedevtools/mcp/pfp/evalstate.webp",
      "keywords": [
        "webcam",
        "mcp",
        "capturing",
        "mcp webcam",
        "webcam mcp",
        "images webcam"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "mcp-webcam",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "evalstate",
      "readme_content": "# ‚≠ê‚≠ê mcp-webcam 0.2.0 - the 50 Star Update ‚≠ê‚≠ê \n\nIn celebration of getting 52 GitHub stars, `mcp-webcam 0.2.0` is here! Now supports streamable-http!! No installation required! - try it now at [`https://webcam.fast-agent.ai/`](https://webcam.fast-agent.ai/). You can specify your own UserID by adding `?user=\u003cYOUR_USER_ID\u003e` after the URL. Note this shared instance is for fun, not security - see below for instructions how to run your own copy locally.\n\nIn streamable-http mode multiple clients can connect simultaneously, and you can choose which is used for Sampling.\n\n![mcp_webcam_020_thumb](https://github.com/user-attachments/assets/041e3091-71e5-4aa1-9170-ee20177485ef)\n\nIf we get to 100 stars I'll add another feature üòä.\n\n## Multi-user Mode\n\nWhen run in Streaming mode, if you set an MCP_HOST environment variable the host name is used as a prefix in URL construction, and 5 character UserIDs are automatically generated when the User lands on the webpage. \n\n![image](https://github.com/user-attachments/assets/30d06cc2-59b6-485b-989d-7030b39c287d)\n\n\n## mcp-webcam\n\nMCP Server that provides access to your WebCam. Provides `capture` and `screenshot` tools to take an image from the Webcam, or take a screenshot. The current image is also available as a Resource.\n\n### MCP Sampling\n\n`mcp-webcam` supports \"sampling\"! Press the \"Sample\" button to send a sampling request to the Client along with your entered message. \n\n\u003e [!TIP]\n\u003e Claude Desktop does not currently support Sampling. If you want a Client that can handle multi-modal sampling request, try https://github.com/evalstate/fast-agent/ or VSCode (more details below).\n\n## Installation and Running\n\n### NPX\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform. The NPM package is `@llmindset/mcp-webcam`. \n\nTo start in **STDIO** mode: `npx @llmindset/mcp-webcam`. This starts the `mcp-webcam` UI on port 3333. Point your browser at `http://localhost:3333` to get started.\n\nTo change the port: `npx @llmindset/mcp-webcam 9999`. This starts `mcp-webcam` the UI on port 9999.\n\nFor **Streaming HTTP** mode: `npx @llmindset/mcp-webcam --streaming`. This will make the UI available at `http://localhost:3333` and the MCP Server available at `http://localhost:3333/mcp`.\n\n### Docker\n\nYou can run `mcp-webcam` using Docker. By default, it starts in **streaming mode**:\n\n```bash\ndocker run -p 3333:3333 ghcr.io/evalstate/mcp-webcam:latest\n```\n\n#### Environment Variables\n\n- `MCP_TRANSPORT_MODE` - Set to `stdio` for STDIO mode, defaults to `streaming`\n- `PORT` - The port to run on (default: `3333`)\n- `BIND_HOST` - Network interface to bind the server to (default: `localhost`)\n- `MCP_HOST` - Public-facing URL for user instructions and MCP client connections (default: `http://localhost:3333`)\n\n#### Examples\n\n```bash\n# STDIO mode\ndocker run -p 3333:3333 -e MCP_TRANSPORT_MODE=stdio ghcr.io/evalstate/mcp-webcam:latest\n\n# Custom port\ndocker run -p 8080:8080 -e PORT=8080 ghcr.io/evalstate/mcp-webcam:latest\n\n# For cloud deployments with custom domain (e.g., Hugging Face Spaces)\ndocker run -p 3333:3333 -e MCP_HOST=https://evalstate-mcp-webcam.hf.space ghcr.io/evalstate/mcp-webcam:latest\n\n# Complete cloud deployment example\ndocker run -p 3333:3333 -e MCP_HOST=https://your-domain.com ghcr.io/evalstate/mcp-webcam:latest\n```\n\n## Clients\n\nIf you want a Client that supports sampling try:\n\n### fast-agent\n\nStart the `mcp-webcam` in streaming mode, install [`uv`](https://docs.astral.sh/uv/) and connect with:\n\n`uvx fast-agent-mcp go --url http://localhost:3333/mcp`\n\n`fast-agent` currently uses Haiku as its default model, so set an `ANTHROPIC_API_KEY`. If you want to use a different model, you can add `--model` on the command line. More instructions for installation and configuration are available here: https://fast-agent.ai/models/.\n\nTo start the server in STDIO mode, add the following to your `fastagent.config.yaml`\n\n```yaml\nwebcam_local:\n   command: \"npx\"\n   args: [\"@llmindset/mcp-webcam\"]\n```\n\n### VSCode\n\nVSCode versions 1.101.0 and above support MCP Sampling. Simply start `mcp-webcam` in streaming mode, and add `http://localhost:3333/mcp` as an MCP Server to get started.\n\n### Claude Desktop\n\nClaude Desktop does **NOT** support Sampling. To run `mcp-webcam` from Claude Desktop, add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"webcam\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-webcam\"\n      ]\n    }\n```\n\nStart Claude Desktop, and connect to `http://localhost:3333`. You can then ask Claude to `get the latest picture from my webcam`, or `Claude, take a look at what I'm holding` or `what colour top am i wearing?`. You can \"freeze\" the current image and that will be returned to Claude rather than a live capture. \n\nYou can ask for Screenshots - navigate to the browser so that you can guide the capture area when the request comes in. Screenshots are automatically resized to be manageable for Claude (useful if you have a 4K Screen). The button is there to allow testing of your platform specific Screenshot UX - it doesn't do anything other than prepare you for a Claude intiated request. NB this does not **not** work on Safari as it requires human initiation.\n\n## Other notes\n\nThat's it really. \n\nThis MCP Server was built to demonstrate exposing a User Interface on an MCP Server, and serving live resources back to Claude Desktop.\n\nThis project might prove useful if you want to build a local, interactive MCP Server.\n\nThanks to  https://github.com/tadasant for help with testing and setup. \n\nPlease read the article at [https://llmindset.co.uk/posts/2025/01/resouce-handling-mcp](https://llmindset.co.uk/posts/2025/01/mcp-files-resources-part1/) for more details about handling files and resources in LLM / MCP Chat Applications, and why you might want to do this.\n",
      "stars": 90,
      "updated_at": "2025-10-03T23:37:10Z",
      "url": "https://github.com/evalstate/mcp-webcam"
    },
    "falahgs--MCP-Storybook-Image-Generator": {
      "category": "image-and-video-generation",
      "description": "Generates high-quality storybook images and matching children's stories using Google's Gemini AI, offering multiple art styles such as 3D cartoon, watercolor, and pixel art. It allows instant previewing of creations and saves them locally in an organized manner.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "keywords": [
        "storybook",
        "images",
        "image",
        "storybook images",
        "storybook image",
        "image generator"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "MCP-Storybook-Image-Generator",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "falahgs",
      "readme_content": "# MCP Storybook Image Generator\n\nA professional-grade server that generates beautiful storybook images with matching children's stories using Google's Gemini AI.\n\n## üé¨ Demo\n\n\n\n## üåü Features\n\n- **Storybook Image Generation**: Creates high-quality images in various art styles for children's stories\n- **Automatic Story Creation**: Generates engaging children's stories to match the images\n- **Multiple Art Styles**: Choose from 3D cartoon, watercolor, pixel art, hand drawn, or claymation styles\n- **Instant Preview**: Automatically opens generated images and stories in your browser\n- **Local Storage**: Saves images and stories in an organized output directory\n\n## üõ†Ô∏è Technical Stack\n\n- **Core Framework**: Model Context Protocol (MCP) SDK\n- **AI Integration**: Google Generative AI (Gemini)\n- **Runtime**: Node.js v14+\n- **Language**: TypeScript\n- **Package Manager**: npm\n\n## üìã Prerequisites\n\n- Node.js (v14 or higher)\n- Google Gemini API key\n- TypeScript\n\n## ‚öôÔ∏è Installation\n\n1. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure environment:\nCreate a `.env` file in the root directory:\n```env\nGEMINI_API_KEY=your_api_key_here\n```\n\n4. Build the project:\n```bash\nnpm run build\n```\n\n## üöÄ Using the CLI\n\nYou can use the storybook generator directly from the command line:\n\n```bash\n# Using npx (after publishing to npm)\nnpx mcp-storybook-image-generator --api-key your_api_key_here --save-to-desktop\n\n# Or run locally\nnode build/cli.js --api-key your_api_key_here --save-to-desktop\n```\n\n### Command Line Options\n\n| Option | Description |\n|--------|-------------|\n| `--api-key \u003ckey\u003e` | Set your Gemini API key |\n| `--save-to-desktop` | Save generated files to desktop |\n| `--debug` | Enable debug logging |\n| `--help` | Show help information |\n\n## üîß Configuring Claude Desktop with MCP Server\n\nTo integrate this server with Claude Desktop:\n\n1. Locate the Claude Desktop Configuration File:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"storybook-generator\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-storybook-image-generator@latest\",\n        \"--api-key\",\n        \"your_gemini_api_key_here\"\n      ],\n      \"env\": {\n        \"SAVE_TO_DESKTOP\": \"true\",\n        \"DEBUG\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## üöÄ Available Tool\n\n### Storybook Image Generator Tool\n\n```json\n{\n  \"name\": \"generate_storybook_image\",\n  \"description\": \"Generates a 3D style cartoon image with a children's story based on the given prompt\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"prompt\": {\n        \"type\": \"string\",\n        \"description\": \"The prompt describing the storybook scene to generate\"\n      },\n      \"fileName\": {\n        \"type\": \"string\",\n        \"description\": \"Base name for the output files (without extension)\"\n      },\n      \"artStyle\": {\n        \"type\": \"string\",\n        \"description\": \"The art style for the image (default: '3d cartoon')\",\n        \"enum\": [\"3d cartoon\", \"watercolor\", \"pixel art\", \"hand drawn\", \"claymation\"]\n      }\n    },\n    \"required\": [\"prompt\", \"fileName\"]\n  }\n}\n```\n\n## üìÑ Example Usage\n\n### Storybook Generation Examples\n\n```javascript\n// Generate a storybook with a 3D cartoon style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A friendly dragon teaching kids how to fly\",\n    \"fileName\": \"dragon_flight_lesson\",\n    \"artStyle\": \"3d cartoon\"\n  }\n}\n\n// Generate a storybook with a watercolor style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A rabbit and turtle having a tea party in the forest\",\n    \"fileName\": \"forest_tea_party\",\n    \"artStyle\": \"watercolor\"\n  }\n}\n\n// Generate a storybook with pixel art style\n{\n  \"name\": \"generate_storybook_image\",\n  \"arguments\": {\n    \"prompt\": \"A space adventure with a kid astronaut meeting friendly aliens\",\n    \"fileName\": \"space_adventure\",\n    \"artStyle\": \"pixel art\"\n  }\n}\n```\n\n## ‚öôÔ∏è Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GEMINI_API_KEY` | Google Gemini API key for AI generation | (Required) |\n| `SAVE_TO_DESKTOP` | Force saving to desktop directory | false |\n| `DEBUG` | Enable verbose debug logging | false |\n\n## üìù Output Files\n\nFor each storybook generation request, the server produces:\n\n1. **PNG Image**: The generated illustration matching your prompt in the requested art style\n2. **Text File**: The matching children's story in plain text format\n3. **HTML Preview**: A combined view showing both the image and story together\n\nThese files are saved to either:\n- Your desktop in a folder called \"storybook-images\" (if `SAVE_TO_DESKTOP=true`)\n- The server's directory in a folder called \"storybook-images\"\n\n## ü§ù Contributing\n\nContributions, issues, and feature requests are welcome! Feel free to check issues page.\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.",
      "stars": 3,
      "updated_at": "2025-08-12T03:16:03Z",
      "url": "https://github.com/falahgs/MCP-Storybook-Image-Generator"
    },
    "falahgs--flux-imagegen-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generates and manipulates images using advanced AI models, offering functionalities such as image URL generation, direct image creation from text prompts, and management of multiple image generation models.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "keywords": [
        "imagegen",
        "images",
        "ai",
        "image generation",
        "image creation",
        "imagegen mcp"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "flux-imagegen-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "falahgs",
      "readme_content": "# Flux ImageGen MCP Server\r\n\r\nA specialized Model Context Protocol (MCP) server for image generation and manipulation, powered by Pollinations AI.\r\n\r\n## Developer\r\n- **Author**: Falah.G.Salieh\r\n- **Copyright**: ¬© 2025 All rights reserved\r\n\r\n## Overview\r\n\r\nImageGen MCP Server is a streamlined server implementation that provides powerful image generation capabilities through the Model Context Protocol (MCP). This server specializes in three core functionalities:\r\n\r\n1. Image URL Generation\r\n2. Direct Image Generation\r\n3. Model Listing and Management\r\n\r\n## Features\r\n\r\n- üñºÔ∏è **Image Generation**: Create stunning images from text prompts\r\n- üé® **Multiple Models**: Support for various image generation models\r\n- üîß **Flexible Configuration**: Easy to set up and customize\r\n- üöÄ **High Performance**: Optimized for quick response times\r\n- üîÑ **MCP Compatible**: Fully compliant with Model Context Protocol\r\n\r\n## Installation\r\n\r\n```bash\r\n# Clone the repository\r\ngit clone https://github.com/yourusername/flux-imagegen-mcp-server.git\r\n\r\n# Install dependencies\r\nnpm install\r\n```\r\n\r\n## Configuration\r\n\r\n### Claude Desktop Configuration\r\n\r\nTo use this server with Claude Desktop, update your configuration file at:\r\n`C:\\Users\\[YourUsername]\\AppData\\Roaming\\Claude\\claude_desktop_config.json`\r\n\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"mcpollinations\": {\r\n      \"command\": \"cmd\",\r\n      \"args\": [\r\n        \"/c\",\r\n        \"node\",\r\n        \"PATH_TO_YOUR_SERVER\\\\server.js\"\r\n      ],\r\n      \"tools\": [\r\n        \"generateImageUrl\",\r\n        \"generateImage\",\r\n        \"listImageModels\"\r\n      ]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nReplace `PATH_TO_YOUR_SERVER` with your actual server path.\r\n\r\n## Available Tools\r\n\r\n### 1. Generate Image URL (`generateImageUrl`)\r\nGenerates a URL for an image based on a text prompt.\r\n\r\n```javascript\r\n{\r\n  \"prompt\": \"A beautiful sunset over mountains\",\r\n  \"model\": \"flux\",  // optional, defaults to 'flux'\r\n  \"width\": 1024,    // optional\r\n  \"height\": 1024,   // optional\r\n  \"enhance\": true,  // optional\r\n  \"safe\": false     // optional\r\n}\r\n```\r\n\r\n### 2. Generate Image (`generateImage`)\r\nGenerates and saves an image directly from a text prompt.\r\n\r\n```javascript\r\n{\r\n  \"prompt\": \"A serene lake reflecting mountains\",\r\n  \"model\": \"flux\",\r\n  \"width\": 1024,\r\n  \"height\": 1024,\r\n  \"enhance\": true,\r\n  \"safe\": false,\r\n  \"outputPath\": \"./output\",\r\n  \"fileName\": \"mountain_lake\",\r\n  \"format\": \"png\"\r\n}\r\n```\r\n\r\n### 3. List Image Models (`listImageModels`)\r\nReturns a list of available image generation models.\r\n\r\n```javascript\r\n// Example response:\r\n{\r\n  \"models\": [\r\n    {\r\n      \"id\": \"flux\",\r\n      \"name\": \"Flux\",\r\n      \"description\": \"Default image generation model\"\r\n    },\r\n    // ... other models\r\n  ]\r\n}\r\n```\r\n## Running the Server\r\n\r\n```bash\r\n# Start the server\r\nnode server.js\r\n```\r\n\r\n## Environment Requirements\r\n\r\n- Node.js \u003e= 16.0.0\r\n- NPM \u003e= 7.0.0\r\n- Windows/Linux/MacOS compatible\r\n\r\n## Development\r\n\r\nTo contribute or modify the server:\r\n\r\n1. Fork the repository\r\n2. Create your feature branch\r\n3. Make your changes\r\n4. Submit a pull request\r\n\r\n## Error Handling\r\n\r\nThe server provides detailed error messages for common issues:\r\n\r\n```javascript\r\n{\r\n  \"error\": {\r\n    \"code\": \"ERROR_CODE\",\r\n    \"message\": \"Human-readable error message\",\r\n    \"details\": { /* Additional error details */ }\r\n  }\r\n}\r\n```\r\n\r\n## Examples\r\n\r\n### Basic Image Generation\r\n```javascript\r\n// Generate an image URL\r\nconst response = await generateImageUrl({\r\n  prompt: \"A futuristic city at night\",\r\n  model: \"flux\",\r\n  width: 1024,\r\n  height: 1024\r\n});\r\n\r\n// Generate and save an image\r\nconst image = await generateImage({\r\n  prompt: \"A peaceful garden with butterflies\",\r\n  outputPath: \"./images\",\r\n  fileName: \"garden_scene\"\r\n});\r\n```\r\n\r\n### Download Image Example\r\n```javascript\r\n// Download an image from URL\r\nconst downloadResult = await downloadImage({\r\n  imageUrl: \"https://example.com/image.jpg\",\r\n  fileName: \"downloaded-image\",\r\n  format: \"png\"\r\n});\r\n```\r\n\r\n## Support\r\n\r\nFor issues and feature requests, please create an issue in the repository or contact the developer:\r\n- Email: [Your contact email]\r\n- GitHub: [Your GitHub profile]\r\n\r\n## License\r\n\r\nThis project is licensed under the MIT License - see the LICENSE file for details.\r\n\r\n---\r\nMade with ‚ù§Ô∏è by Falah.G.Salieh\r\n¬© 2025 All rights reserved\r\n\r\n",
      "stars": 3,
      "updated_at": "2025-09-18T19:58:34Z",
      "url": "https://github.com/falahgs/flux-imagegen-mcp-server"
    },
    "falahgs--imagen-3.0-generate-google-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generates high-quality images using Google's Imagen 3.0 model via the Gemini API, manages image files with intelligent naming, and creates HTML previews for local viewing. Integrates seamlessly with MCP-compatible hosts for enhanced AI capabilities.",
      "forks": 8,
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "keywords": [
        "imagen",
        "images",
        "mcp",
        "imagen generate",
        "google imagen",
        "imagen model"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "imagen-3.0-generate-google-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "falahgs",
      "readme_content": "# Gemini Imagen 3.0 MCP Server\r\n\r\n![License](https://img.shields.io/badge/license-MIT-blue.svg)\r\n![Node](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen)\r\n![TypeScript](https://img.shields.io/badge/typescript-%5E5.3.3-blue)\r\n\r\nA professional Model Context Protocol (MCP) server implementation that harnesses Google's Imagen 3.0 model through the Gemini API for high-quality image generation. Built with TypeScript and designed for seamless integration with Claude Desktop and other MCP-compatible hosts.\r\n\r\n## üåü Features\r\n\r\n- Leverage Google's state-of-the-art Imagen 3.0 model via Gemini API\r\n- Generate up to 4 high-quality images per request\r\n- Automatic file management with intelligent naming\r\n- HTML preview generation with file:// protocol support\r\n- Built on MCP protocol for AI agent compatibility\r\n- TypeScript implementation with robust error handling\r\n\r\n## üöÄ Quick Start\r\n\r\n### Prerequisites\r\n\r\n- Node.js 18 or higher\r\n- Google Gemini API key\r\n- Claude Desktop or another MCP-compatible host\r\n\r\n### Installation\r\n\r\n1. Clone the repository:\r\n```bash\r\ngit clone https://github.com/yourusername/gemini-imagen-mcp-server.git\r\ncd gemini-imagen-mcp-server\r\n```\r\n\r\n2. Install dependencies:\r\n```bash\r\nnpm install\r\n```\r\n\r\n3. Build the TypeScript code:\r\n```bash\r\nnpm run build\r\n```\r\n\r\n## ‚öôÔ∏è Configuration\r\n\r\n1. Configure Claude Desktop by adding to `claude_desktop_config.json`:\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"gemini-image-gen\": {\r\n      \"command\": \"node\",\r\n      \"args\": [\"./build/index.js\"],\r\n      \"cwd\": \"\u003cpath-to-project-directory\u003e\",\r\n      \"env\": {\r\n        \"GEMINI_API_KEY\": \"your-gemini-api-key\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n2. Replace placeholders:\r\n   - `\u003cpath-to-project-directory\u003e`: Your project path\r\n   - `your-gemini-api-key`: Your Gemini API key\r\n\r\n## üõ†Ô∏è Available Tools\r\n\r\n### 1. generate_images\r\nGenerates images using Google's Imagen 3.0 model.\r\n\r\nParameters:\r\n- `prompt` (required): Text description of the image to generate\r\n- `numberOfImages` (optional): Number of images (1-4, default: 1)\r\n\r\nFile Management:\r\n- Images are automatically saved in `G:\\image-gen3-google-mcp-server\\images`\r\n- Filenames follow the pattern: `{sanitized-prompt}-{timestamp}-{index}.png`\r\n- Timestamps ensure unique filenames\r\n- Prompts are sanitized for safe filesystem usage\r\n\r\nExample:\r\n```\r\nGenerate an image of a futuristic city at night\r\n```\r\n\r\n### 2. create_image_html\r\nCreates HTML preview tags for generated images.\r\n\r\nParameters:\r\n- `imagePaths` (required): Array of image file paths\r\n- `width` (optional): Image width in pixels (default: 512)\r\n- `height` (optional): Image height in pixels (default: 512)\r\n\r\nReturns HTML tags with absolute file:// URLs for local viewing.\r\n\r\nExample:\r\n```\r\nCreate HTML tags for the generated images with width=400\r\n```\r\n\r\n## üîß Development\r\n\r\n```bash\r\n# Install dependencies\r\nnpm install\r\n\r\n# Build TypeScript\r\nnpm run build\r\n\r\n# Run tests (when available)\r\nnpm test\r\n```\r\n\r\n## ü§ù Contributing\r\n\r\nContributions are welcome! Please feel free to submit a Pull Request. For major changes:\r\n\r\n1. Fork the repository\r\n2. Create your feature branch (`git checkout -b feature/AmazingFeature`)\r\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\r\n4. Push to the branch (`git push origin feature/AmazingFeature`)\r\n5. Open a Pull Request\r\n\r\n## üìù Error Handling\r\n\r\nThe server implements two main error codes:\r\n- `tool_not_found` (1): When the requested tool is not available\r\n- `execution_error` (2): When image generation or HTML creation fails\r\n\r\n## üìÑ License\r\n\r\nMIT License - see the [LICENSE](LICENSE) file for details.\r\n\r\n## ‚ú® Author\r\n\r\n**Falah G. Salieh**\r\n- Copyright ¬© 2025\r\n- GitHub: [@yourgithubhandle](https://github.com/yourgithubhandle)\r\n- Email: [your.email@example.com](mailto:your.email@example.com)\r\n\r\n## üôè Acknowledgments\r\n\r\n- Google Gemini API and Imagen 3.0 model\r\n- Model Context Protocol (MCP) by Anthropic\r\n- Claude Desktop team for MCP host implementation\r\n\r\n## üìå Tags\r\n\r\n`#MCP` `#Gemini` `#Imagen3` `#AI` `#ImageGeneration` `#TypeScript` `#NodeJS` `#GoogleAI` `#ClaudeDesktop`\r\n\r\n---\r\nMade with ‚ù§Ô∏è by Falah G. Salieh ",
      "stars": 3,
      "updated_at": "2025-08-10T13:44:15Z",
      "url": "https://github.com/falahgs/imagen-3.0-generate-google-mcp-server"
    },
    "falahgs--mcp-3d-style-cartoon-gen-server": {
      "category": "image-and-video-generation",
      "description": "Generates high-quality 3D-style cartoon images from text prompts using Google's Gemini AI, with child-friendly designs for engaging visuals. Offers secure file system operations for managing files, including reading and writing capabilities.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/falahgs.webp",
      "keywords": [
        "mcp",
        "images",
        "cartoon",
        "mcp 3d",
        "cartoon images",
        "cartoon gen"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "mcp-3d-style-cartoon-gen-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "falahgs",
      "readme_content": "# MCP Combined Server: 3D Cartoon Generator \u0026 File System Tools\n\nA professional-grade server that provides two major capabilities: \n1. High-quality 3D-style cartoon image generation using Google's Gemini AI\n2. Secure file system operations for reading, writing, and managing files\n\n\n\n## üåü Features\n\n### Image Generation\n- **3D Cartoon Generation**: Creates high-quality 3D-style cartoon images\n- **Child-Friendly Design**: Focuses on colorful, playful, and engaging visuals\n- **Instant Preview**: Automatically opens generated images in your default browser\n- **Local Storage**: Saves images and previews in an organized output directory\n\n### File System Operations\n- **Secure File Access**: Path validation and security checks\n- **Read/Write Files**: Read and write text file contents\n- **Directory Operations**: List, create, and navigate directories\n- **File Search**: Find files matching patterns\n\n### System Features\n- **Professional Configuration**: Robust error handling and controlled logging\n- **Cross-Platform Support**: Intelligent file path handling for Windows, macOS, and Linux\n- **Smart OS Detection**: Automatically finds the best save location for each operating system\n- **Security Controls**: Restricted directory access through configuration\n\n## üõ†Ô∏è Technical Stack\n\n- **Core Framework**: Model Context Protocol (MCP) SDK\n- **AI Integration**: Google Generative AI (Gemini)\n- **Runtime**: Node.js v14+\n- **Language**: TypeScript\n- **Package Manager**: npm\n\n## üìã Prerequisites\n\n- Node.js (v14 or higher)\n- Google Gemini API key\n- TypeScript\n\n## ‚öôÔ∏è Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/falahgs/mcp-3d-style-cartoon-gen-server.git\ncd mcp-3d-style-cartoon-gen-server\n```\n\n2. Install dependencies:\n```bash\nnpm install\n```\n\n3. Configure environment:\nCreate a `.env` file in the root directory:\n```env\nGEMINI_API_KEY=your_api_key_here\nALLOWED_DIRECTORIES=/path/to/allowed/dir1,/path/to/allowed/dir2\n```\n\n4. Build the project:\n```bash\nnpm run build\n```\n\n## üîß Configuring Claude Desktop with MCP Server\n\nTo integrate this combined server with Claude Desktop:\n\n1. Locate the Configuration File:\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Linux: `~/.config/Claude/claude_desktop_config.json`\n\n2. Add the following configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-3d-cartoon-generator\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"path/to/your/build/index.js\"\n      ],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key_here\",\n        \"IS_REMOTE\": \"true\",\n        \"SAVE_TO_DESKTOP\": \"true\",\n        \"DETECT_OS_PATHS\": \"true\",\n        \"ALLOWED_DIRECTORIES\": \"C:\\\\Users\\\\YourUsername\\\\Desktop,C:\\\\Users\\\\YourUsername\\\\Documents\",\n        \"DEBUG\": \"false\"\n      }\n    }\n  }\n}\n```\n\n### Windows PowerShell Helper Script\n\nFor Windows users, you can use the included `fix_claude_config.ps1` script to automatically configure Claude Desktop:\n\n1. Edit the script to update the path to your server build and your Gemini API key\n2. Run the script in PowerShell:\n```powershell\npowershell -ExecutionPolicy Bypass -File .\\fix_claude_config.ps1\n```\n\nThis will create or update the configuration file with proper encoding and settings.\n\n## üöÄ Available Tools\n\n### 1. Image Generation Tool\n\n```json\n{\n  \"name\": \"generate_3d_cartoon\",\n  \"description\": \"Generates a 3D style cartoon image for kids based on the given prompt\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"prompt\": {\n        \"type\": \"string\",\n        \"description\": \"The prompt describing the 3D cartoon image to generate\"\n      },\n      \"fileName\": {\n        \"type\": \"string\",\n        \"description\": \"The name of the output file (without extension)\"\n      }\n    },\n    \"required\": [\"prompt\", \"fileName\"]\n  }\n}\n```\n\n### 2. File System Tools\n\n#### Read File\n```json\n{\n  \"name\": \"read_file\",\n  \"description\": \"Read the contents of a file\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the file to read\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Write File\n```json\n{\n  \"name\": \"write_file\",\n  \"description\": \"Write content to a file\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the file to write\"\n      },\n      \"content\": {\n        \"type\": \"string\",\n        \"description\": \"Content to write to the file\"\n      }\n    },\n    \"required\": [\"path\", \"content\"]\n  }\n}\n```\n\n#### List Directory\n```json\n{\n  \"name\": \"list_directory\",\n  \"description\": \"List the contents of a directory\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the directory to list\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Create Directory\n```json\n{\n  \"name\": \"create_directory\",\n  \"description\": \"Create a new directory\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Path to the directory to create\"\n      }\n    },\n    \"required\": [\"path\"]\n  }\n}\n```\n\n#### Search Files\n```json\n{\n  \"name\": \"search_files\",\n  \"description\": \"Search for files matching a pattern\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"path\": {\n        \"type\": \"string\",\n        \"description\": \"Base directory to search from\"\n      },\n      \"pattern\": {\n        \"type\": \"string\",\n        \"description\": \"Search pattern (glob format)\"\n      },\n      \"excludePatterns\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\"\n        },\n        \"description\": \"Patterns to exclude from search (glob format)\"\n      }\n    },\n    \"required\": [\"path\", \"pattern\"]\n  }\n}\n```\n\n## üìÑ Example Usage\n\n### Image Generation Examples\n\n```javascript\n// Generate a 3D cartoon\n{\n  \"name\": \"generate_3d_cartoon\",\n  \"arguments\": {\n    \"prompt\": \"A friendly robot playing with a cat\",\n    \"fileName\": \"robot_cat_play\"\n  }\n}\n```\n\n### File System Examples\n\n```javascript\n// Read a file\n{\n  \"name\": \"read_file\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/example.txt\"\n  }\n}\n\n// Write a file\n{\n  \"name\": \"write_file\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/new-file.txt\",\n    \"content\": \"This is the content of the file.\"\n  }\n}\n\n// List directory contents\n{\n  \"name\": \"list_directory\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents\"\n  }\n}\n\n// Create a directory\n{\n  \"name\": \"create_directory\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents/new-folder\"\n  }\n}\n\n// Search for files\n{\n  \"name\": \"search_files\",\n  \"arguments\": {\n    \"path\": \"C:/Users/YourUsername/Documents\",\n    \"pattern\": \"*.txt\",\n    \"excludePatterns\": [\"temp*\", \"*.tmp\"]\n  }\n}\n```\n\n## üîí Security Features\n\nThe server implements several security measures:\n\n1. **Path Validation**: All file paths are validated to ensure they are within allowed directories.\n2. **Allowed Directories**: Only directories explicitly set in the `ALLOWED_DIRECTORIES` environment variable can be accessed.\n3. **Symlink Protection**: Prevents access to directories outside the allowed scope via symlinks.\n4. **Controlled Logging**: Debug logs are disabled by default to prevent information leakage.\n\n## ‚öôÔ∏è Configuration Options\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GEMINI_API_KEY` | Google Gemini API key for image generation | (Required) |\n| `ALLOWED_DIRECTORIES` | Comma-separated list of allowed file system paths | User's home dir, current dir |\n| `IS_REMOTE` | Run in remote mode without browser opening | false |\n| `SAVE_TO_DESKTOP` | Force saving to desktop directory | false |\n| `DETECT_OS_PATHS` | Enable OS-specific path detection | true |\n| `DEBUG` | Enable verbose debug logging | false |\n\n## üõ†Ô∏è Troubleshooting\n\n### Common Issues:\n\n1. **JSON Parsing Errors in Claude**:\n   - Ensure `DEBUG` is set to \"false\" to prevent logs from interfering with JSON communication\n   - Check for proper JSON formatting in the Claude configuration\n\n2. **File Access Denied**:\n   - Verify that the paths you're trying to access are included in `ALLOWED_DIRECTORIES`\n   - Check file permissions on the target files/directories\n\n3. **Images Not Saving**:\n   - Set `SAVE_TO_DESKTOP` to \"true\" to ensure images save to the desktop\n   - Check desktop path detection in the server logs (enable DEBUG temporarily)\n\n## üìÑ License\n\n[MIT License](LICENSE)\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "stars": 3,
      "updated_at": "2025-09-11T21:40:56Z",
      "url": "https://github.com/falahgs/mcp-3d-style-cartoon-gen-server"
    },
    "felores--cloudinary-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Upload images and videos to Cloudinary via MCP clients. Integrates with Claude Desktop for media management.",
      "forks": 8,
      "imageUrl": "/freedevtools/mcp/pfp/felores.webp",
      "keywords": [
        "cloudinary",
        "upload",
        "mcp",
        "cloudinary mcp",
        "videos cloudinary",
        "mcp server"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "cloudinary-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "felores",
      "readme_content": "# Cloudinary MCP Server\n\nThis MCP server provides tools for uploading images and videos to Cloudinary through Claude Desktop and compatible MCP clients.\n\n\u003ca href=\"https://glama.ai/mcp/servers/zjiw1ry8ly\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/zjiw1ry8ly/badge\" alt=\"Cloudinary Server MCP server\" /\u003e\u003c/a\u003e\n\n## Installation\n\n### Requirements: Node.js\n\n1. Install Node.js (version 18 or higher) and npm from [nodejs.org](https://nodejs.org/)\n2. Verify installation:\n   ```bash\n   node --version\n   npm --version\n   ```\n\n### Install using npx (Recommended)\n1. Navigate to the Claude configuration directory:\n\n   - Windows: `C:\\Users\\NAME\\AppData\\Roaming\\Claude`\n   - macOS: `~/Library/Application Support/Claude/`\n   \n   You can also find these directories inside the Claude Desktop app: Claude Desktop \u003e Settings \u003e Developer \u003e Edit Config\n\n2. Add the following configuration to your MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"npx\",\n      \"args\": [\"@felores/cloudinary-mcp-server@latest\"],\n      \"env\": {\n        \"CLOUDINARY_CLOUD_NAME\": \"your_cloud_name\",\n        \"CLOUDINARY_API_KEY\": \"your_api_key\",\n        \"CLOUDINARY_API_SECRET\": \"your_api_secret\"\n      }\n    }\n  }\n}\n```\n\n3. Make sure to replace the environment variables with your Cloudinary credentials from the [Cloudinary Console](https://console.cloudinary.com/settings/api-keys).\n\n### Developer Installation\nIf you want to modify the server or contribute to development:\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/felores/cloudinary-mcp-server.git\ncd cloudinary-mcp-server\n```\n\n2. Install dependencies and build:\n```bash\nnpm install\nnpm run build\n```\n\n## Setup Instructions\n\n1. First, ensure you have a Cloudinary account and get your credentials from the [Cloudinary Console](https://console.cloudinary.com/settings/api-keys):\n   - Cloud Name\n   - API Key\n   - API Secret\n\n2. Add the server configuration to your Claude/Cline MCP settings file:\n\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"node\",\n      \"args\": [\"c:/path/to/cloudinary-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"CLOUDINARY_CLOUD_NAME\": \"your_cloud_name\",\n        \"CLOUDINARY_API_KEY\": \"your_api_key\",\n        \"CLOUDINARY_API_SECRET\": \"your_api_secret\"\n      }\n    }\n  }\n}\n```\n\nFor Claude desktop app, edit the configuration file at the appropriate location for your OS.\n\n3. Install dependencies and build the server:\n```bash\nnpm install\nnpm run build\n```\n\n## Available Tools\n\n### upload\n\nUpload images and videos to Cloudinary.\n\nParameters:\n- `file` (required): Path to file, URL, or base64 data URI to upload\n- `resource_type` (optional): Type of resource ('image', 'video', or 'raw')\n- `public_id` (optional): Custom public ID for the uploaded asset\n- `overwrite` (optional): Whether to overwrite existing assets with the same public ID\n- `tags` (optional): Array of tags to assign to the uploaded asset\n\nExample usage in Claude/Cline:\n```typescript\nuse_mcp_tool({\n  server_name: \"cloudinary\",\n  tool_name: \"upload\",\n  arguments: {\n    file: \"path/to/image.jpg\",\n    resource_type: \"image\",\n    public_id: \"my-custom-id\"\n  }\n});\n",
      "stars": 9,
      "updated_at": "2025-09-12T10:23:47Z",
      "url": "https://github.com/felores/cloudinary-mcp-server"
    },
    "felores--placid-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Integrates with Placid.app to list available templates and generate images and videos using dynamic content. Provides secure API token management and robust error handling.",
      "forks": 7,
      "imageUrl": "/freedevtools/mcp/pfp/felores.webp",
      "keywords": [
        "placid",
        "mcp",
        "server",
        "placid app",
        "placid mcp",
        "mcp server"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "placid-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "felores",
      "readme_content": "# Placid.app MCP Server\n[![smithery badge](https://smithery.ai/badge/@felores/placid-mcp-server)](https://smithery.ai/server/@felores/placid-mcp-server)\n\nAn MCP server implementation for integrating with Placid.app's API. This server provides tools for listing templates and generating images and videos through the Model Context Protocol.\n\n\u003ca href=\"https://glama.ai/mcp/servers/xeklsydon0\"\u003e\n  \u003cimg alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/xeklsydon0/badge\" /\u003e\n\u003c/a\u003e\n\n## Features\n\n- List available Placid templates with filtering options\n- Generate images and videos using templates and dynamic content\n- Secure API token management\n- Error handling and validation\n- Type-safe implementation\n\n## Requirements: Node.js\n\n1. Install Node.js (version 18 or higher) and npm from [nodejs.org](https://nodejs.org/)\n2. Verify installation:\n   ```bash\n   node --version\n   npm --version\n   ```\n\n## Installation\n\n### Quick Start (Recommended)\n\nThe easiest way to get started is using Smithery, which will automatically configure everything for you:\n\n```bash\nnpx -y @smithery/cli install @felores/placid-mcp-server --client claude\n```\n\n### Manual Configuration\n\nIf you prefer to configure manually, add this to your Claude Desktop or Cline settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"placid\": {\n      \"command\": \"npx\",\n      \"args\": [\"@felores/placid-mcp-server\"],\n      \"env\": {\n        \"PLACID_API_TOKEN\": \"your-api-token\"\n      }\n    }\n  }\n}\n```\n\n## Getting Your Placid API Token\n\n1. Log in to your [Placid.app](https://placid.app/) account\n2. Go to Settings \u003e API\n3. Click on \"Create API Token\"\n4. Give your token a name (e.g., \"MCP Server\")\n5. Copy the generated token\n6. Add the token to your configuration as shown above\n\n## Development\n\n```bash\n# Run in development mode with hot reload\nnpm run dev\n\n# Run tests\nnpm test\n```\n\n## Tools\n\n### placid_list_templates\nLists available Placid templates with filtering options. Each template includes its title, ID, preview image URL, available layers, and tags.\n\n#### Parameters\n- `collection_id` (optional): Filter templates by collection ID\n- `custom_data` (optional): Filter by custom reference data\n- `tags` (optional): Array of tags to filter templates by\n\n#### Response\nReturns an array of templates, each containing:\n- `uuid`: Unique identifier for the template\n- `title`: Template name\n- `thumbnail`: Preview image URL (if available)\n- `layers`: Array of available layers with their names and types\n- `tags`: Array of template tags\n\n### placid_generate_video\nGenerate videos by combining Placid templates with dynamic content like videos, images, and text. For longer videos (\u003e60 seconds processing time), you'll receive a job ID to check status in your Placid dashboard.\n\n#### Parameters\n- `template_id` (required): UUID of the template to use\n- `layers` (required): Object containing dynamic content for template layers\n  - For video layers: `{ \"layerName\": { \"video\": \"https://video-url.com\" } }`\n  - For image layers: `{ \"layerName\": { \"image\": \"https://image-url.com\" } }`\n  - For text layers: `{ \"layerName\": { \"text\": \"Your content\" } }`\n- `audio` (optional): URL to an mp3 audio file\n- `audio_duration` (optional): Set to 'auto' to trim audio to video length\n- `audio_trim_start` (optional): Timestamp of trim start point (e.g. '00:00:45' or '00:00:45.25')\n- `audio_trim_end` (optional): Timestamp of trim end point (e.g. '00:00:55' or '00:00:55.25')\n\n#### Response\nReturns an object containing:\n- `status`: Current status (\"finished\", \"queued\", or \"error\")\n- `video_url`: URL to download the generated video (when status is \"finished\")\n- `job_id`: ID for checking status in Placid dashboard (for longer videos)\n\n#### Example Usage for LLM models\n```json\n{\n  \"template_id\": \"template-uuid\",\n  \"layers\": {\n    \"MEDIA\": { \"video\": \"https://example.com/video.mp4\" },\n    \"PHOTO\": { \"image\": \"https://example.com/photo.jpg\" },\n    \"LOGO\": { \"image\": \"https://example.com/logo.png\" },\n    \"HEADLINE\": { \"text\": \"My Video Title\" }\n  },\n  \"audio\": \"https://example.com/background.mp3\",\n  \"audio_duration\": \"auto\"\n}\n```\n\n### placid_generate_image\nGenerate static images by combining Placid templates with dynamic content like text and images.\n\n#### Parameters\n- `template_id` (required): UUID of the template to use\n- `layers` (required): Object containing dynamic content for template layers\n  - For text layers: `{ \"layerName\": { \"text\": \"Your content\" } }`\n  - For image layers: `{ \"layerName\": { \"image\": \"https://image-url.com\" } }`\n\n#### Response\nReturns an object containing:\n- `status`: \"finished\" when complete\n- `image_url`: URL to download the generated image\n\n#### Example Usage for LLM models\n```json\n{\n  \"template_id\": \"template-uuid\",\n  \"layers\": {\n    \"headline\": { \"text\": \"Welcome to My App\" },\n    \"background\": { \"image\": \"https://example.com/bg.jpg\" }\n  }\n}\n```\n\n## Documentation\n\nFor more detailed information about the Placid API, visit the [Placid API Documentation](https://placid.app/docs/api/).\n\n## License\n\nMIT\n",
      "stars": 14,
      "updated_at": "2025-09-02T13:59:52Z",
      "url": "https://github.com/felores/placid-mcp-server"
    },
    "fengin--image-gen-server": {
      "category": "image-and-video-generation",
      "description": "Generate images from text descriptions and save them, seamlessly integrated with Cursor IDE. Users can create multiple image outputs simultaneously and specify custom save paths.",
      "forks": 25,
      "imageUrl": "/freedevtools/mcp/pfp/fengin.webp",
      "keywords": [
        "fengin",
        "generate",
        "images",
        "generate images",
        "image gen",
        "fengin image"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "image-gen-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "fengin",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/fengin-image-gen-server-badge.png)](https://mseep.ai/app/fengin-image-gen-server)\n\n# Image-Gen-Server\n\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n[![smithery badge](https://smithery.ai/badge/@fengin/image-gen-server)](https://smithery.ai/server/@fengin/image-gen-server)\n\nÂü∫‰∫éÂç≥Ê¢¶AIÁöÑÂõæÂÉèÁîüÊàêÊúçÂä°Ôºå‰∏ìÈó®ËÆæËÆ°Áî®‰∫é‰∏éCursor IDEÈõÜÊàê„ÄÇÂÆÉÊé•Êî∂Êù•Ëá™CursorÁöÑÊñáÊú¨ÊèèËø∞ÔºåÁîüÊàêÁõ∏Â∫îÁöÑÂõæÂÉèÔºåÂπ∂Êèê‰æõÂõæÁâá‰∏ãËΩΩÂíå‰øùÂ≠òÂäüËÉΩ„ÄÇ\n\nÊ≠§Êèí‰ª∂ÁöÑÂºÄÂèëËøáÁ®ãÂèØ‰ª•ÁúãÊàëÁöÑÁΩëÁ´ôÔºö[ÂºÄÂèë‰∏Ä‰∏™MCP Server‰∏éCursorÈõÜÊàêÔºåÁªôCursorÊèí‰∏äÁøÖËÜÄÔºÅ](https://aibook.ren/archives/mcp-server-for-cursor)\n\nÊõ¥Â§öAIÁü•ËØÜÔºåËßÅAIÂÖ®‰π¶(https://aibook.ren)\n\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n## ÁâπÊÄß\n\n- ‰∏éCursor IDEÂÆåÁæéÈõÜÊàê\n- ÊîØÊåÅÊñáÊú¨Âà∞ÂõæÂÉèÁöÑÁîüÊàê\n- Ëá™Âä®‰øùÂ≠òÁîüÊàêÁöÑÂõæÂÉè\n- ÊîØÊåÅËá™ÂÆö‰πâ‰øùÂ≠òË∑ØÂæÑ\n- ‰∏ÄÊ¨°ÁîüÊàêÂõõÂº†ÂõæÔºå‰æõÊõ¥Â§öÈÄâÊã©\n\n## ÂÆâË£Ö\n\n### Installing via Smithery\n\nTo install Image-Gen-Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@fengin/image-gen-server):\n\n```bash\nnpx -y @smithery/cli install @fengin/image-gen-server --client claude\n```\n\n1. ÁéØÂ¢ÉÂáÜÂ§áÔºåMCPÊØîËæÉÊñ∞ÁöÑ‰∏úË•øÔºå‰æùËµñÁéØÂ¢ÉÁâàÊú¨ÈÉΩÊØîËæÉÊñ∞\n- python 3.10+\n\n- ÂÆâË£Önpm\n\n- ÂÆâË£ÖnodejsÔºàÂÆûÊµãv15 v16ÈÉΩ‰∏çË°åÔºåÂºÄÂèëÁéØÂ¢ÉÈ™åËØÅv20ÂèØ‰ª•ÔºåÂÖ∂‰ªñÊú™È™åËØÅÔºâ\n\n- ÂÆâË£Ö pip install uv\n\n- Â¶ÇÊûúË¶ÅË∞ÉËØïÔºåËøòÈúÄË¶ÅÂÆâË£ÖËøô‰∏™Ôºönpm install -g @modelcontextprotocol/inspector@0.4.0\n2. ÂÖãÈöÜÈ°πÁõÆ\n   \n   ```bash\n   git clone https://github.com/fengin/image-gen-server.git\n   cd image-gen-server\n   ```\n\n3. ÂÆâË£Ö‰æùËµñ\n   \n   ```bash\n   pip install -r requirements.txt\n   pip install uv\n   ```\n\n4. ËÆæÁΩÆÂç≥Ê¢¶TokenÂíåÂõæÁâáÈªòËÆ§‰øùÂ≠òÂú∞ÂùÄ\n   ‰øÆÊîπserver.pyÊñá‰ª∂ÈáåÈù¢Ëøô‰∏§‰∏™ÈÖçÁΩÆ\n   \n   ```bash\n   # APIÈÖçÁΩÆ\n   JIMENG_API_TOKEN = \"057f7addf85dxxxxxxxxxxxxx\" # ‰Ω†ÁôªÂΩïÂç≥Ê¢¶Ëé∑ÂæóÁöÑsession_idÔºåÊîØÊåÅÂ§ö‰∏™ÔºåÂú®ÂêéÈù¢Áî®ÈÄóÂè∑ÂàÜÈöî   \n   IMG_SAVA_FOLDER = \"D:/code/image-gen-server/images\" # ÂõæÁâáÈªòËÆ§‰øùÂ≠òË∑ØÂæÑ\n   ```\n\n¬†¬†¬†¬†\n\n## CursorÈõÜÊàê\n\n\u003cdiv align=\"center\"\u003e\n  \n\u003c/div\u003e\n\n1. ÊâìÂºÄCursorËÆæÁΩÆ\n   \n   - ÁÇπÂáªÂ∑¶‰∏ãËßíÁöÑËÆæÁΩÆÂõæÊ†á\n   - ÈÄâÊã© Features \u003e MCP Servers\n   - ÁÇπÂáª \"Add new MCP server\"\n\n2. Â°´ÂÜôÊúçÂä°Âô®ÈÖçÁΩÆ\n   \n   - Name: `image-gen-server`ÔºàÊàñÂÖ∂‰ªñ‰Ω†ÂñúÊ¨¢ÁöÑÂêçÁß∞Ôºâ\n   \n   - Type: `command`\n   \n   - Command: \n     \n     ```bash\n     uv run --with fastmcp fastmcp run D:\\code\\image-gen-service\\server.py\n     ```\n     \n     Ê≥®ÊÑèÔºöÂ∞ÜË∑ØÂæÑÊõøÊç¢‰∏∫‰Ω†ÁöÑÂÆûÈôÖÈ°πÁõÆË∑ØÂæÑ\n     \n     - WindowsÁ§∫‰æã: ` uv run --with fastmcp fastmcp run D:/code/image-gen-service/server.py`\n     - macOS/LinuxÁ§∫‰æã: ` uv run --with fastmcp fastmcp run /Users/username/code/image-gen-server/server.py`\n     \n     windowsË∑ØÂæÑÈóÆÈ¢òÊØîËæÉÂ§öÔºåD:/code/image-gen-server/server.py ÂêÑÁßçÊñúÊù†ÈÉΩËØï‰∏ã\n     \n     Â°´ÂÜôÂÆåÂêéÔºå‰ºöÂºπÂá∫‰∏Ä‰∏™ÈªëÁ™óÂè£ÔºåÁÑ∂Âêé‰Ω†Â∞±ÂèØ‰ª•Âè´CursorÁªô‰Ω†ÁîüÊàêÈúÄË¶ÅÁöÑÂõæÁâá‰∫ÜÔºåÁõÆÂâçÈªëÁ™óÂè£‰ºö‰∏ÄÁõ¥ËøêË°åÔºåÁõÆÂâçËøòÊ≤°ÂäûÊ≥ïËß£ÂÜ≥ÂºπÂá∫Ëøô‰∏™ÁöÑÈóÆÈ¢ò\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\nÂú®Cursor‰∏≠Ôºå‰Ω†Ë¶ÅËÆ©cursorÁîüÊàêÂõæÁâáÔºåÂú®agentÊ®°Âºè‰∏ãÔºå‰Ω†ÊèêÁ§∫ÂÆÉ‰∫ÜËß£‰∏ãÂõæÁâáÂ∑•ÂÖ∑‰ΩøÁî®ÊñπÊ≥ïÔºåÁÑ∂ÂêéÁõ¥Êé•Êèê‰Ω†Ë¶ÅÁîüÊàêÁöÑÂõæÁâáË¶ÅÊ±ÇÔºå‰øùÂ≠ò‰ΩçÁΩÆÂ∞±Ë°å‰∫Ü\n\n## Ëé∑ÂèñÂç≥Ê¢¶Token\n\n1. ËÆøÈóÆ [Âç≥Ê¢¶](https://jimeng.jianying.com/)\n2. ÁôªÂΩïË¥¶Âè∑\n3. ÊåâF12ÊâìÂºÄÂºÄÂèëËÄÖÂ∑•ÂÖ∑\n4. Âú®Application \u003e Cookies‰∏≠ÊâæÂà∞`sessionid`\n5. Â∞ÜÊâæÂà∞ÁöÑsessionidËÆæÁΩÆÂà∞server.pyÁöÑJIMENG_API_TOKEN‰∏≠\n\n## Â∑•ÂÖ∑ÂáΩÊï∞ËØ¥Êòé\n\n### generate_image\n\n```python\nasync def generate_image(prompt: str, file_name: str, save_folder: str = None, sample_strength: float = 0.5, width: int = 1024, height: int = 1024) -\u003e list[types.TextContent | types.ImageContent | types.EmbeddedResource]:\n    \"\"\"Ê†πÊçÆÊñáÊú¨ÊèèËø∞ÁîüÊàêÂõæÁâá\n\n    Args:\n        prompt: ÂõæÁâáÁöÑÊñáÊú¨promptÊèèËø∞\n        file_name: ÁîüÊàêÂõæÁâáÁöÑÊñá‰ª∂Âêç(‰∏çÂê´Ë∑ØÂæÑÔºåÂ¶ÇÊûúÊ≤°ÊúâÂêéÁºÄÂàôÈªòËÆ§‰ΩøÁî®.jpg)\n        save_folder: ÂõæÁâá‰øùÂ≠òÁªùÂØπÂú∞ÂùÄÁõÆÂΩï(ÂèØÈÄâ,ÈªòËÆ§‰ΩøÁî®IMG_SAVA_FOLDER)\n        sample_strength: ÁîüÊàêÂõæÁâáÁöÑÁ≤æÁªÜÂ∫¶(ÂèØÈÄâ,ËåÉÂõ¥0-1,ÈªòËÆ§0.5)\n        width: ÁîüÊàêÂõæÁâáÁöÑÂÆΩÂ∫¶(ÂèØÈÄâ,ÈªòËÆ§1024)\n        height: ÁîüÊàêÂõæÁâáÁöÑÈ´òÂ∫¶(ÂèØÈÄâ,ÈªòËÆ§1024)\n\n    Returns:\n        List: ÂåÖÂê´ÁîüÊàêÁªìÊûúÁöÑJSONÂ≠óÁ¨¶‰∏≤\n    \"\"\"\n```\n\n### ÊäÄÊúØÂÆûÁé∞\n\n1. server.pyÈááÁî®‰∫ÜfastmcpÂÆûÁé∞‰∫Ümcp severÁöÑËÉΩÂäõÔºåÊèê‰æõÁªôcursor/claude‰ΩøÁî®\n\n   2.sever.pyË∞ÉÁî®‰∫Üproxy.jimengÊ®°ÂùóÈÄÜÂêë‰∏éÂç≥Ê¢¶AIËøõË°å‰∫§‰∫í„ÄÇ\nproxy.jimengÈÄÜÂêëÊ®°Âùó‰πüÂèØ‰ª•ÂçïÁã¨install‰ΩøÁî®Ôºå‰∏ªË¶ÅÊèê‰æõ‰∫Ü‰ª•‰∏ã‰∏ªË¶ÅÂäüËÉΩÔºö\n\n- ÂõæÂÉèÁîüÊàêÔºàgenerate_imagesÔºâ\n- ÂêåÊ≠•ÂØπËØùË°•ÂÖ®Ôºàcreate_completionÔºâ\n- ÊµÅÂºèÂØπËØùË°•ÂÖ®Ôºàcreate_completion_streamÔºâ\n- Â§öË¥¶Âè∑tokenÊîØÊåÅ\n- ÂÆåÊï¥ÁöÑÈîôËØØÂ§ÑÁêÜ\n\nÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØËØ∑ÂèÇËÄÉ`proxy/jimeng/README.md`„ÄÇ\n\n### ‰ΩøÁî®Á§∫‰æã\n\n```cmd\n# cursor agentÊ®°Âºè‰∏ã\n#‰æãÂ≠ê‰∏Ä\nÊ†πÊçÆÊèê‰æõËøá‰Ω†ÁöÑÈ°πÁõÆÈúÄÊ±ÇÔºåÂ∏ÆÊàëÁîüÊàê‰∏ÄÂº†‰∫ßÂìÅlogoÔºåÊîæÂú®È°πÁõÆÁõÆÂΩïimages‰∏ãÈù¢\n\n#‰æãÂ≠ê‰∫å\nÊ†πÊçÆÈ°πÁõÆÈúÄÊ±ÇÔºåÂ∏ÆÊàëÂà∂‰ΩúÁΩëÁ´ôÁöÑÈ¶ñÈ°µÔºåÂ§¥ÈÉ®ÈúÄË¶ÅÊúâbannerÂõæÁâá„ÄÇ\n```\n\n## ËÆ∏ÂèØËØÅ\n\nMIT License \n‰ΩúËÄÖÔºöÂáåÂ∞Å\n\n## ÊïÖÈöúÊéíÈô§\n\n1.ÈÖçÁΩÆÂÆåÂêéË∑≥Âá∫ÈªëÁ™óÂè£ÔºåÂæàÂø´Ê∂àÂ§±ÔºåÂ∑•ÂÖ∑Áä∂ÊÄÅÂèòÊàêNo tools found\n\n  ÂéüÂõ†ÔºöÊ≤°ÊúâÊ≠£Â∏∏ÂêØÂä®Ôºå‰∏ÄËà¨Êúâ‰ª•‰∏ãÂéüÂõ†\n\n- ÈÖçÁΩÆÂëΩ‰ª§‰∏çÂØπÔºåÊ£ÄÊü•ÂëΩ‰ª§ÊòØÂê¶Ê≠£Á°ÆÔºå‰∏ÄËà¨ÊòØserver.pyË∑ØÂæÑ‰∏çÂØπÔºåÊàñËÄÖË∑ØÂæÑ‰∏≠ÂåÖÂê´‰∏≠ÊñáÔºåÊàñËÄÖÊ≠£ÂèçÊñúÊù†‰∏çÂØπ\n- ‰æùËµñÁöÑÁéØÂ¢ÉÊ≤°ÂáÜÂ§áÂ•Ω\n- ‰æùËµñËøêË°åÁöÑÁªàÁ´Ø‰∏çÂØπÔºåÂÉèÊàëwindowsÁöÑÔºåÁªàÁ´ØÊúâgit bashÔºåcmdÔºåpowershellÔºåwslÁ≠âÔºåËøô‰∫õÁªàÁ´ØÈÉΩËØï‰∏ãÔºåcursorÈÖçÁΩÆÊàëËøôÈªòËÆ§ÁªàÁ´ØÊòØcmdÔºåÂ¶ÇÊûú‰Ω†Âú®ËøôÂØπÂ∫îÁªàÁ´ØËøêË°åÊä•ÈîôÔºå‰∏ÄËà¨ÊòØÁéØÂ¢ÉÊ≤°Ë£ÖÂ•ΩÔºåÂÆâË£ÖÁéØÂ¢ÉÂ∞±ÂèØ‰ª•\n\n2.Ê≠£Â∏∏ËøêË°åÂêéÔºåÊÉ≥ÁúãË∞ÉÁî®Êó•ÂøóÔºåÊàñËÄÖË∞ÉËØïÊÄé‰πàÂºÑ\n\n  ÂëΩ‰ª§ÊîπÊàê‰ª•‰∏ãÔºö\n\n```\nuv run --with fastmcp fastmcp dev D:/code/image-gen-service/server.py\n```\n\n\n  Âç≥ÊääÊúÄÂêé‰∏Ä‰∏™run ÊîπÊàê dev„ÄÇ\n\n  ÊàñËÄÖÊâæ‰∏™ÁªàÁ´ØËøêË°å‰ª•‰∏ãÂëΩ‰ª§ËøõÂÖ•Ë∞ÉËØïÊ®°ÂºèÔºö\n\n```\nfastmcp dev D:/code/image-gen-service/server.py\n```\n\n‰ºöÊúâ‰∏Ä‰∏™Ë∞ÉËØïÂú∞ÂùÄËæìÂá∫Ôºöhttp://localhost:5173/Ôºå‰Ω†ÂèØ‰ª•ÊµèËßàÂô®ÊâìÂºÄËøôÂú∞ÂùÄMCP InspectorËøõË°åË∞ÉËØïÔºåÂÖ∑‰ΩìMCP InspectorÊÄé‰πà‰ΩøÁî®ÔºåÂèØ‰ª•ÁúãÂÆòÊñπÊñáÊ°£",
      "stars": 205,
      "updated_at": "2025-09-28T14:14:49Z",
      "url": "https://github.com/fengin/image-gen-server"
    },
    "hamflx--imagen3-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate high-quality images using Google's Imagen 3.0 model through an MCP interface, facilitating integration with tools like Cherry Studio or Cursor. Supports configurable deployment options using a Google Gemini API key.",
      "forks": 7,
      "imageUrl": "/freedevtools/mcp/pfp/hamflx.webp",
      "keywords": [
        "imagen3",
        "imagen",
        "hamflx",
        "imagen3 mcp",
        "hamflx imagen3",
        "google imagen"
      ],
      "language": "Rust",
      "license": "No License",
      "name": "imagen3-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "hamflx",
      "readme_content": "# Imagen3-MCP\n\n[English Version](#imagen3-mcp-english)\n\nÂü∫‰∫é Google ÁöÑ Imagen 3.0 ÁöÑÂõæÂÉèÁîüÊàêÂ∑•ÂÖ∑ÔºåÈÄöËøá MCPÔºàModel Control ProtocolÔºâÊèê‰æõÊúçÂä°„ÄÇ\n\n## ÊïàÊûú\n\nÁîª‰∏ÄÂè™Â•îË∑ëÁöÑÊù∞ÂÖãÁΩóÁ¥†Áä¨ÔºåÈïøÁÑ¶ÈïúÂ§¥ÔºåÈò≥ÂÖâÈÄèËøáÁãóÁãóÁöÑÊØõÂèëÔºåÁÖßÁâáÁ∫ßÁîªË¥®\n\n\n\nÁîª‰∏Ä‰∏™ÁßëÊäÄÊÑüÂçÅË∂≥ÁöÑËãπÊûú\n\n\n\n## ÂÆâË£ÖË¶ÅÊ±Ç\n\n- ÊúâÊïàÁöÑ [Google Gemini API ÂØÜÈí•](https://aistudio.google.com/apikey)\n\n## ÂÆâË£ÖÊ≠•È™§‚Äî‚ÄîCherry Studio\n\n1. ‰ªé [GitHub Releases](https://github.com/hamflx/imagen3-mcp/releases) ‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨ÁöÑÂèØÊâßË°åÊñá‰ª∂\n2. Â∞Ü‰∏ãËΩΩÁöÑÂèØÊâßË°åÊñá‰ª∂ÊîæÁΩÆÂú®Á≥ªÁªü‰∏≠ÁöÑ‰ªªÊÑè‰ΩçÁΩÆÔºå‰æãÂ¶Ç `C:\\bin\\imagen3-mcp.exe`\n3. Âú® Cherry Studio ‰∏≠ÈÖçÁΩÆÔºö\n   - Command Â≠óÊÆµÂ°´ÂÜôÂèØÊâßË°åÊñá‰ª∂Ë∑ØÂæÑÔºå‰æãÂ¶Ç `C:\\bin\\imagen3-mcp.exe`\n   - ÁéØÂ¢ÉÂèòÈáè `GEMINI_API_KEY` ‰∏≠Â°´ÂÜô‰Ω†ÁöÑ Gemini API ÂØÜÈí•\n   - [ÂèØÈÄâ] ÁéØÂ¢ÉÂèòÈáè `BASE_URL` ‰∏≠Â°´ÂÜô‰ª£ÁêÜÂú∞ÂùÄÔºå‰æãÂ¶Ç `https://lingxi-proxy.hamflx.dev/api/provider/google`ÔºàËøô‰∏™Âú∞ÂùÄÂèØ‰ª•Ëß£ÂÜ≥ GFW ÁöÑÈóÆÈ¢òÔºå‰ΩÜÊòØËß£ÂÜ≥‰∏ç‰∫Ü Google ÂØπ IP ÁöÑÈôêÂà∂ÈóÆÈ¢òÔºåÂõ†Ê≠§ËøòÊòØÂæóÊåÇÊ¢ØÂ≠êÔºâ„ÄÇ\n   - [ÂèØÈÄâ] ÁéØÂ¢ÉÂèòÈáè `SERVER_LISTEN_ADDR`ÔºöËÆæÁΩÆÊúçÂä°Âô®ÁõëÂê¨ÁöÑ IP Âú∞ÂùÄÔºàÈªòËÆ§‰∏∫ `127.0.0.1`Ôºâ„ÄÇ\n   - [ÂèØÈÄâ] ÁéØÂ¢ÉÂèòÈáè `SERVER_PORT`ÔºöËÆæÁΩÆÊúçÂä°Âô®ÁõëÂê¨ÁöÑÁ´ØÂè£ÂíåÂõæÁâá URL ‰ΩøÁî®ÁöÑÁ´ØÂè£ÔºàÈªòËÆ§‰∏∫ `9981`Ôºâ„ÄÇ\n   - [ÂèØÈÄâ] ÁéØÂ¢ÉÂèòÈáè `IMAGE_RESOURCE_SERVER_ADDR`ÔºöËÆæÁΩÆÂõæÁâá URL ‰∏≠‰ΩøÁî®ÁöÑÊúçÂä°Âô®Âú∞ÂùÄÔºàÈªòËÆ§‰∏∫ `127.0.0.1`Ôºâ„ÄÇËøôÂú®ÊúçÂä°Âô®ËøêË°åÂú®ÂÆπÂô®ÊàñËøúÁ®ãÊú∫Âô®‰∏äÊó∂ÂæàÊúâÁî®„ÄÇ\n\n\n\n## ÂÆâË£ÖÊ≠•È™§‚Äî‚ÄîCursor\n\n```json\n{\n  \"mcpServers\": {\n    \"imagen3\": {\n      \"command\": \"C:\\\\bin\\\\imagen3-mcp.exe\",\n      \"env\": {\n        \"GEMINI_API_KEY\": \"\u003cGEMINI_API_KEY\u003e\"\n        // Optional environment variables:\n        // \"BASE_URL\": \"\u003cPROXY_URL\u003e\",\n        // \"SERVER_LISTEN_ADDR\": \"0.0.0.0\", // Example: Listen on all interfaces\n        // \"SERVER_PORT\": \"9981\",\n        // \"IMAGE_RESOURCE_SERVER_ADDR\": \"your.domain.com\" // Example: Use a domain name for image URLs\n      }\n    }\n  }\n}\n```\n\n## ËÆ∏ÂèØËØÅ\n\nMIT\n\n---\n\n# Imagen3-MCP (English)\n\nAn image generation tool based on Google's Imagen 3.0, providing services through MCP (Model Control Protocol).\n\n## Examples\n\nA running Jack Russell Terrier, telephoto lens, sunlight filtering through the dog's fur, photorealistic quality\n\n\n\nA high-tech apple\n\n\n\n## Requirements\n\n- Valid [Google Gemini API key](https://aistudio.google.com/apikey)\n\n## Installation Steps‚ÄîCherry Studio\n\n1. Download the latest executable from [GitHub Releases](https://github.com/hamflx/imagen3-mcp/releases)\n2. Place the downloaded executable anywhere in your system, e.g., `C:\\bin\\imagen3-mcp.exe`\n3. Configure in Cherry Studio:\n   - Fill in the Command field with the executable path, e.g., `C:\\bin\\imagen3-mcp.exe`\n   - Enter your Gemini API key in the `GEMINI_API_KEY` environment variable\n   - [Optional] Enter a proxy URL in the `BASE_URL` environment variable, e.g., `https://your-proxy.com`.\n   - [Optional] Set the `SERVER_LISTEN_ADDR` environment variable: The IP address the server listens on (defaults to `127.0.0.1`).\n   - [Optional] Set the `SERVER_PORT` environment variable: The port the server listens on and uses for image URLs (defaults to `9981`).\n   - [Optional] Set the `IMAGE_RESOURCE_SERVER_ADDR` environment variable: The server address used in the image URLs (defaults to `127.0.0.1`). Useful if the server runs in a container or remote machine.\n\n\n\n## Installation Steps‚ÄîCursor\n\n```json\n{\n  \"mcpServers\": {\n    \"imagen3\": {\n      \"command\": \"C:\\\\bin\\\\imagen3-mcp.exe\",\n      \"env\": {\n        \"GEMINI_API_KEY\": \"\u003cGEMINI_API_KEY\u003e\"\n        // Optional environment variables:\n        // \"BASE_URL\": \"\u003cPROXY_URL\u003e\",\n        // \"SERVER_LISTEN_ADDR\": \"0.0.0.0\", // Example: Listen on all interfaces\n        // \"SERVER_PORT\": \"9981\",\n        // \"IMAGE_RESOURCE_SERVER_ADDR\": \"your.domain.com\" // Example: Use a domain name for image URLs\n      }\n    }\n  }\n}\n```\n\n## License\n\nMIT",
      "stars": 43,
      "updated_at": "2025-09-20T19:36:59Z",
      "url": "https://github.com/hamflx/imagen3-mcp"
    },
    "hellokaton--unsplash-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Connects to Unsplash's image library to perform advanced searches and apply filters on keywords for rich, high-quality image retrieval.",
      "forks": 19,
      "imageUrl": "/freedevtools/mcp/pfp/hellokaton.webp",
      "keywords": [
        "unsplash",
        "mcp",
        "image",
        "unsplash image",
        "unsplash mcp",
        "image retrieval"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "unsplash-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "hellokaton",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/hellokaton-unsplash-mcp-server-badge.png)](https://mseep.ai/app/hellokaton-unsplash-mcp-server)\n\n# Unsplash MCP Server\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh.md)\n\n\u003e A simple MCP server for seamless Unsplash image integration and search capabilities.\n\n[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![smithery badge](https://smithery.ai/badge/@hellokaton/unsplash-mcp-server)](https://smithery.ai/server/@hellokaton/unsplash-mcp-server)\n\n## üìã Overview\n\nUnsplash MCP Server is used for searching rich, high-quality images. It's ideal for developers who want to integrate Unsplash functionality into their own applications.\n\n## ‚ú® Features\n\n- **Advanced Image Search**: Search Unsplash's extensive photo library with filters for:\n  - Keyword relevance\n  - Color schemes\n  - Orientation options\n  - Custom sorting and pagination\n\n## üîë Obtaining Unsplash Access Key\n\nBefore installing this server, you'll need to obtain an Unsplash API Access Key:\n\n1. Create a developer account at [Unsplash](https://unsplash.com/developers)\n2. Register a new application\n3. Get your Access Key from the application details page\n4. Use this key in the configuration steps below\n\nFor more details, refer to the [official Unsplash API documentation](https://unsplash.com/documentation).\n\n## üöÄ Installation\n\nTo install Unsplash Image Integration Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@hellokaton/unsplash-mcp-server):\n\n### IDE Setup\n\n**Cursor IDE**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client cursor --key 7558c683-****-****\n```\n\n**Windsurf**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client windsurf --key 7558c683-****-****\n```\n\n**Cline**\n\n```bash\nnpx -y @smithery/cli@latest install @hellokaton/unsplash-mcp-server --client cline --key 7558c683-****-****\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/hellokaton/unsplash-mcp-server.git\n\n# Navigate to project directory\ncd unsplash-mcp-server\n\n# Create virtual environment\nuv venv\n\n# Install dependencies\nuv pip install .\n```\n\n**Cursor Editor Integration**\n\nAdd the following configuration to your Cursor editor's `settings.json`:\n\n‚ö†Ô∏è **Note:** Please adjust the following configuration according to your actual installation:\n\n- If `uv` is not in your system PATH, use an absolute path (e.g., `/path/to/uv`)\n- `./server.py` should be modified to the actual location of your server script (can use absolute path or path relative to workspace)\n\n\n\n```json\n{\n  \"mcpServers\": {\n    \"unsplash\": {\n      \"command\": \"uv\",\n      \"args\": [\"run\", \"--with\", \"fastmcp\", \"fastmcp\", \"run\", \"./server.py\"],\n      \"env\": {\n        \"UNSPLASH_ACCESS_KEY\": \"${YOUR_ACCESS_KEY}\"\n      }\n    }\n  }\n}\n```\n\n### Using in Cursor\n\n\n\n## üõ†Ô∏è Available Tools\n\n### Search Photos\n\n```json\n{\n  \"tool\": \"search_photos\",\n  \"query\": \"mountain\",\n  \"per_page\": 5,\n  \"orientation\": \"landscape\"\n}\n```\n\n## üîÑ Other Implementations\n\n- Golang: [unsplash-mcp-server](https://github.com/douglarek/unsplash-mcp-server)\n- Java: [unsplash-mcp-server](https://github.com/JavaProgrammerLB/unsplash-mcp-server)\n\n## üìÑ License\n\n[MIT License](LICENSE)\n\n## üì¨ Contact\n\n- [Twitter/X](https://x.com/hellokaton)\n- [GitHub Issues](https://github.com/hellokaton/unsplash-mcp-server/issues)",
      "stars": 174,
      "updated_at": "2025-10-03T22:30:58Z",
      "url": "https://github.com/hellokaton/unsplash-mcp-server"
    },
    "htessaro--mcp-test-deploy-2": {
      "category": "image-and-video-generation",
      "description": "Access a wide array of cat images and detailed breed information through a TypeScript SDK, enabling image uploads, retrieval of breed data, and user interactions such as favoriting or voting on images.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/htessaro.webp",
      "keywords": [
        "htessaro",
        "breed",
        "images",
        "htessaro mcp",
        "cat images",
        "breed information"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "mcp-test-deploy-2",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "htessaro",
      "readme_content": "",
      "stars": 0,
      "updated_at": "2025-04-28T17:24:43Z",
      "url": "https://github.com/htessaro/mcp-test-deploy-2"
    },
    "huangmiuXyz--jimeng-mcp": {
      "category": "image-and-video-generation",
      "description": "Integrate AI-powered image generation capabilities into applications using the Jimeng AI model. Generate high-quality images through a simple MCP interface for advanced AI image synthesis.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/huangmiuXyz.webp",
      "keywords": [
        "ai",
        "jimeng",
        "generate",
        "image generation",
        "image synthesis",
        "ai image"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "jimeng-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "huangmiuXyz",
      "readme_content": "{\n  \"mcpServers\": {\n    \"jimeng\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"jimeng\",\n        \"-y\"\n      ],\n      \"env\": {\n        \"VOLCENGINE_ACCESS_KEY\": \"your_access_key_here\",\n        \"VOLCENGINE_SECRET_KEY\": \"your_secret_key_here\"\n      }\n    }\n  }\n}\n\nhttps://console.volcengine.com/iam/keymanage/ Ëé∑ÂèñAccess Key IDÂíåSecret Access Key\n",
      "stars": 2,
      "updated_at": "2025-06-20T02:13:23Z",
      "url": "https://github.com/huangmiuXyz/jimeng-mcp"
    },
    "husniadil--mcp-image-placeholder": {
      "category": "image-and-video-generation",
      "description": "Generates placeholder images from multiple providers, supporting both simple and real images as placeholders. Validates input parameters and returns image URLs for immediate use.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/husniadil.webp",
      "keywords": [
        "placeholder",
        "images",
        "mcp",
        "placeholder images",
        "image placeholder",
        "mcp image"
      ],
      "language": "HTML",
      "license": "MIT License",
      "name": "mcp-image-placeholder",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "husniadil",
      "readme_content": "# MCP Image Placeholder Server\n\nThis is a Model Context Protocol (MCP) server that provides a tool for generating placeholder images from different providers.\n\n## Features\n\n- Generates placeholder images from supported providers\n- Supports two image providers:\n  - [`placehold`](https://placehold.co/): Provides simple placeholder images\n  - [`lorem-picsum`](https://picsum.photos/): Provides real images as placeholder images\n- Validates input parameters\n- Returns image URLs for immediate use\n\n## Requirements\n\n- Python 3.9+\n- `uv` package manager\n\n## Installation\n\n1. Clone this repository\n2. [Set up the configuration for MCP server](#configuration)\n\n## Usage\n\nThe server exposes one tool:\n\n### `image_placeholder`\n\nGenerate a placeholder image URL based on specified parameters.\n\n**Parameters:**\n- `provider`: The image provider to use (`placehold` or `lorem-picsum`)\n- `width`: The width of the image (1-10000)\n- `height`: The height of the image (1-10000)\n\n**Returns:**\n- URL string of the generated image\n\n**Example Usage:**\n```python\n# Generate a 300x200 placeholder image\nurl = image_placeholder(provider=\"placehold\", width=300, height=200)\n\n# Generate a 500px square lorem-picsum image\nurl = image_placeholder(provider=\"lorem-picsum\", width=500)\n```\n\n## Configuration\n\n### To connect this server to Claude for Desktop:\n\n1. Add the following to your `claude_desktop_config.json`:\n   ```json\n   {\n       \"mcpServers\": {\n           \"image-placeholder\": {\n               \"command\": \"uv\",\n               \"args\": [\n                   \"--directory\",\n                   \"/ABSOLUTE/PATH/TO/PROJECT\",\n                   \"run\",\n                   \"main.py\"\n               ]\n           }\n       }\n   }\n   ```\n2. Restart Claude for Desktop\n\n### To connect this server to Cursor:\n\n1. Open Cursor Settings\n2. Head to the `Features` section\n3. Scroll down to the `MCP Servers` section\n4. Click on the `Add new MCP server` button\n5. Enter the following information:\n   - Name: `image-placeholder`\n   - Type: `command`\n   - Server URL: `uv --directory /ABSOLUTE/PATH/TO/PROJECT run main.py`\n6. Click on the `Add ‚Üµ` button\n\n\n## Troubleshooting\n\nIf the tool is not detected, use absolute path of the `uv` command, e.g.\n```\n/ABSOLUTE/PATH/TO/uv --directory /ABSOLUTE/PATH/TO/PROJECT run main.py\n```\n\n## Example Usage and Output (Cursor)\n\nPrompt:\n```\nCreate a new directory named \"example\" and a file named output.html.\n\nThen create a single modern looking page using tailwindcss: https://unpkg.com/@tailwindcss/browser@4\n\nShow a nice header, content, and footer, showing a photo gallery.\n\nSave this into output.html\n```\n\n\n\nOutput:\n[Example Output (Cursor)](example/output.html)\n\n## License\n\n[MIT License](LICENSE)",
      "stars": 8,
      "updated_at": "2025-06-17T08:32:20Z",
      "url": "https://github.com/husniadil/mcp-image-placeholder"
    },
    "ifmelate--mcp-image-extractor": {
      "category": "image-and-video-generation",
      "description": "Extracts images from local files and URLs, processing them into base64 format for analysis by large language models (LLMs). Suitable for analyzing image-based data, such as screenshots from tests.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/ifmelate.webp",
      "keywords": [
        "images",
        "base64",
        "image",
        "image extractor",
        "mcp image",
        "extracts images"
      ],
      "language": "HTML",
      "license": "MIT License",
      "name": "mcp-image-extractor",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "ifmelate",
      "readme_content": "# MCP Image Extractor\n\nMCP server for extracting and converting images to base64 for LLM analysis.\n\nThis MCP server provides tools for AI assistants to:\n- Extract images from local files\n- Extract images from URLs\n- Process base64-encoded images\n\n\u003ca href=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@ifmelate/mcp-image-extractor/badge\" alt=\"Image Extractor MCP server\" /\u003e\n\u003c/a\u003e\n\nHow it looks in Cursor:\n\n\u003cimg width=\"687\" alt=\"image\" src=\"https://github.com/user-attachments/assets/8954dbbd-7e7a-4f27-82a7-b251bd3c5af2\" /\u003e\n\nSuitable cases:\n- analyze playwright test results: screenshots\n\n## Installation\n\n### Recommended: Using npx in mcp.json (Easiest)\n\nThe recommended way to install this MCP server is using npx directly in your `.cursor/mcp.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-image-extractor\"\n      ]\n    }\n  }\n}\n```\n\nThis approach:\n- Automatically installs the latest version\n- Does not require global installation\n- Works reliably across different environments\n\n### Alternative: Local Path Installation\n\nIf you prefer to use a local installation of the package, you can clone the repository and point to the built files:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/mcp-image-extractor/dist/index.js\"],\n      \"disabled\": false\n    }\n  }\n}\n```\n\n### Manual Installation\n\n```bash\n# Clone and install \ngit clone https://github.com/ifmelate/mcp-image-extractor.git\ncd mcp-image-extractor\nnpm install\nnpm run build\nnpm link\n```\n\nThis will make the `mcp-image-extractor` command available globally.\n\nThen configure in `.cursor/mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-extractor\": {\n      \"command\": \"mcp-image-extractor\",\n      \"disabled\": false\n    }\n  }\n}\n```\n\n\u003e **Troubleshooting for Cursor Users**: If you see \"Failed to create client\" error, try the local path installation method above or ensure you're using the correct path to the executable.\n\n## Available Tools\n\n### extract_image_from_file\n\nExtracts an image from a local file and converts it to base64.\n\nParameters:\n- `file_path` (required): Path to the local image file\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_url\n\nExtracts an image from a URL and converts it to base64.\n\nParameters:\n- `url` (required): URL of the image to extract\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n### extract_image_from_base64\n\nProcesses a base64-encoded image for LLM analysis.\n\nParameters:\n- `base64` (required): Base64-encoded image data\n- `mime_type` (optional, default: \"image/png\"): MIME type of the image\n\n**Note:** All images are automatically resized to optimal dimensions (max 512x512) for LLM analysis to limit the size of the base64 output and optimize context window usage.\n\n## Example Usage\n\nHere's an example of how to use the tools from Claude:\n\n```\nPlease extract the image from this local file: images/photo.jpg\n```\n\nClaude will automatically use the `extract_image_from_file` tool to load and analyze the image content.\n\n```\nPlease extract the image from this URL: https://example.com/image.jpg\n```\n\nClaude will automatically use the `extract_image_from_url` tool to fetch and analyze the image content.\n\n## Docker\n\nBuild and run with Docker:\n\n```bash\ndocker build -t mcp-image-extractor .\ndocker run -p 8000:8000 mcp-image-extractor\n```\n\n## License\n\nMIT",
      "stars": 14,
      "updated_at": "2025-09-21T00:31:03Z",
      "url": "https://github.com/ifmelate/mcp-image-extractor"
    },
    "jaokuohsuan--draw-things-mcp-cursor": {
      "category": "image-and-video-generation",
      "description": "Generates images based on text prompts using AI, integrating seamlessly within workflows. The server utilizes the Draw Things API to transform user-defined prompts into visual creations.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/jaokuohsuan.webp",
      "keywords": [
        "visual",
        "cursor",
        "draw",
        "visual creations",
        "generates images",
        "utilizes draw"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "draw-things-mcp-cursor",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "jaokuohsuan",
      "readme_content": "# Draw Things MCP\n\nDraw Things API integration for Cursor using Model Context Protocol (MCP).\n\n## Prerequisites\n\n- Node.js \u003e= 14.0.0\n- Draw Things API running on http://127.0.0.1:7888\n\n## Installation\n\n```bash\n# Install globally\nnpm install -g draw-things-mcp-cursor\n\n# Or run directly\nnpx draw-things-mcp-cursor\n```\n\n## Cursor Integration\n\nTo set up this tool in Cursor, see the detailed guide in [cursor-setup.md](./cursor-setup.md).\n\nQuick setup:\n\n1. Create or edit `~/.cursor/claude_desktop_config.json`:\n```json\n{\n  \"mcpServers\": {\n    \"draw-things\": {\n      \"command\": \"draw-things-mcp-cursor\",\n      \"args\": []\n    }\n  }\n}\n```\n\n2. Restart Cursor\n3. Use in Cursor: `generateImage({\"prompt\": \"a cute cat\"})`\n\n## CLI Usage\n\n### Generate Image\n\n```bash\necho '{\"prompt\": \"your prompt here\"}' | npx draw-things-mcp-cursor\n```\n\n### Parameters\n\n- `prompt`: The text prompt for image generation (required)\n- `negative_prompt`: The negative prompt for image generation\n- `width`: Image width (default: 360)\n- `height`: Image height (default: 360)\n- `steps`: Number of steps for generation (default: 8)\n- `model`: Model to use for generation (default: \"flux_1_schnell_q5p.ckpt\")\n- `sampler`: Sampling method (default: \"DPM++ 2M AYS\")\n\nExample:\n\n```bash\necho '{\n  \"prompt\": \"a happy smiling dog, professional photography\",\n  \"negative_prompt\": \"ugly, deformed, blurry\",\n  \"width\": 360,\n  \"height\": 360,\n  \"steps\": 4\n}' | npx draw-things-mcp-cursor\n```\n\n### MCP Tool Integration\n\nWhen used as an MCP tool in Cursor, the tool will be registered as `generateImage` with the following parameters:\n\n```typescript\n{\n  prompt: string;       // Required - The prompt to generate the image from\n  negative_prompt?: string;  // Optional - The negative prompt\n  width?: number;       // Optional - Image width (default: 360)\n  height?: number;      // Optional - Image height (default: 360)\n  model?: string;       // Optional - Model name\n  steps?: number;       // Optional - Number of steps (default: 8)\n}\n```\n\nThe generated images will be saved in the `images` directory with a filename format of:\n`\u003csanitized_prompt\u003e_\u003ctimestamp\u003e.png`\n\n## Response Format\n\nSuccess:\n```json\n{\n  \"type\": \"success\",\n  \"content\": [{\n    \"type\": \"image\",\n    \"data\": \"base64 encoded image data\",\n    \"mimeType\": \"image/png\"\n  }],\n  \"metadata\": {\n    \"parameters\": { ... }\n  }\n}\n```\n\nError:\n```json\n{\n  \"type\": \"error\",\n  \"error\": \"error message\",\n  \"code\": 500\n}\n```\n\n## Troubleshooting\n\nIf you encounter issues:\n\n- Ensure Draw Things API is running at http://127.0.0.1:7888\n- Check log files in `~/.cursor/logs` if using with Cursor\n- Make sure src/index.js has execution permissions: `chmod +x src/index.js`\n\n## License\n\nMIT ",
      "stars": 12,
      "updated_at": "2025-08-16T06:00:20Z",
      "url": "https://github.com/jaokuohsuan/draw-things-mcp-cursor"
    },
    "jbrower95--mcp-asset-gen": {
      "category": "image-and-video-generation",
      "description": "Generate high-quality image assets for game or web development by providing descriptive prompts. Streamline asset creation workflows with automated image generation through AI.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/jbrower95.webp",
      "keywords": [
        "mcp",
        "generate",
        "image",
        "image generation",
        "video generation",
        "image assets"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp-asset-gen",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "jbrower95",
      "readme_content": "# mcp-asset-gen\n[![npm version](https://badge.fury.io/js/mcp-asset-gen.svg)](https://badge.fury.io/js/mcp-asset-gen)\n\n\nThis tool allows Claude to speak to OpenAI, and use `gpt-image-1` to generate image assets. This can be pretty useful for game or web development, when you need to print individual assets.\n\n# Requirements\n\n- Node \n- An OpenAI [API Key](https://platform.openai.com/settings/organization/api-keys)\n    - Note that this requires an organization, with ID verification at the moment.\n\n# Installation\n\n1. Get an API KEY from the [OpenAI website](https://platform.openai.com/settings/organization/api-keys).\n\n2. Export it in your shell as API_KEY.\n\n```bash\nexport API_KEY=sk-proj-....\n```\n\n3. Then, paste this into that same shell:\n\n```bash\njq --arg apiKey \"$API_KEY\" \\\n'.mcpServers = (.mcpServers // {}) | \n .mcpServers[\"mcp-asset-gen\"] = {\n   type: \"stdio\",\n   command: \"npx\",\n   args: [\"mcp-asset-gen\"],\n   env: { API_KEY: $apiKey }\n }' ~/.claude.json \u003e ~/.claude.tmp \u0026\u0026 mv ~/.claude.tmp ~/.claude.json\n```\n\n4. You're done! Ask Claude to generate you an image for something, and you'll see\n\n```\n\u003e generate a small logo image that i could use for my arcade game\n\n I'll generate a logo for your arcade game. Please provide a more specific description of what you'd like to see in the logo (colors, style,\n  game theme, etc.) for better results.\n\n\u003e It should look like an old school pacman machine (liek a wooden arcade machine)\n\n‚è∫ mcp-asset-gen:generateImag(outputPathAbsolute: \"/Users/jbrower/projects/mcp-asset-gen/arcade-logo.png\", prompt: \"An old school wooden arcade‚Ä¶\n   (MCP)                    machine logo in the style of Pacman, with retro colors and pixelated elements, top-down view of the cabinet,\n                            nostalgic arcade gaming feel, vibrant colors against dark background\", quality: \"high\", size: \"1024x1024\")\n¬†¬†‚éø ¬†The image is now available at /Users/jbrower/projects/mcp-asset-gen/arcade-logo.png.\n\n‚è∫ Generated arcade logo saved to /Users/jbrower/projects/mcp-asset-gen/arcade-logo.png\n```\n\n",
      "stars": 3,
      "updated_at": "2025-08-05T20:41:33Z",
      "url": "https://github.com/jbrower95/mcp-asset-gen"
    },
    "jezweb--openai-mcp": {
      "category": "image-and-video-generation",
      "description": "Connect to OpenAI's DALL-E API for image generation with support for various options, enabling seamless integration into MCP-compatible AI assistants like Roo Code.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/jezweb.webp",
      "keywords": [
        "openai",
        "mcp",
        "ai",
        "openai mcp",
        "image generation",
        "video generation"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "openai-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "jezweb",
      "readme_content": "# OpenAI MCP - DALL-E API Integration for Roo Code\n\nThis project provides a Model Context Protocol (MCP) server for connecting to OpenAI's DALL-E API for image generation with full support for all available options. It's specifically designed to work with Roo Code and other MCP-compatible AI assistants.\n\n## Overview\n\nThis MCP server provides a tool for DALL-E image generation with comprehensive support for all DALL-E API options. It allows AI assistants like Roo Code to generate images through the Model Context Protocol (MCP) with fine-grained control over the generation process.\n\n## Project Structure\n\n- `src/` - Source code for the MCP server\n  - `dalle.ts` - Implementation of the DALL-E API integration with all options\n  - `index.ts` - Main server file with the DALL-E tool and input schema\n  - `install.ts` - Installation script for Roo Code and Claude Desktop\n- `build/` - Compiled JavaScript files\n- `dalle-test.html` - HTML page to display the generated image and document available options\n- `test-dalle.js` - Direct test script for the DALL-E API with examples of different options\n\n## Setup Instructions for Roo Code\n\n### Installation\n\n1. Install the package globally:\n   ```\n   npm install -g openai-mcp\n   ```\n\n2. Run the setup command to configure Roo Code:\n   ```\n   openai-mcp install\n   ```\n\n3. Set your OpenAI API key in Roo Code settings:\n   - Open Roo Code\n   - Go to Settings\n   - Add the following environment variable to the MCP server configuration:\n     ```json\n     \"openai-mcp\": {\n       \"env\": {\n         \"OPENAI_API_KEY\": \"your-openai-api-key\"\n       }\n     }\n     ```\n\n4. Restart Roo Code",
      "stars": 1,
      "updated_at": "2025-04-24T08:28:31Z",
      "url": "https://github.com/jezweb/openai-mcp"
    },
    "jhacksman--OpenSCAD-MCP-Server": {
      "category": "image-and-video-generation",
      "description": "Generates 3D models from text descriptions or images, focusing on parametric model creation through multi-view reconstruction and integration with OpenSCAD. Facilitates remote processing and includes an image approval workflow for model generation.",
      "forks": 17,
      "imageUrl": "/freedevtools/mcp/pfp/jhacksman.webp",
      "keywords": [
        "openscad",
        "3d",
        "mcp",
        "openscad mcp",
        "openscad facilitates",
        "jhacksman openscad"
      ],
      "language": "Python",
      "license": "No License",
      "name": "OpenSCAD-MCP-Server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "jhacksman",
      "readme_content": "# OpenSCAD MCP Server\n\nA Model Context Protocol (MCP) server that enables users to generate 3D models from text descriptions or images, with a focus on creating parametric 3D models using multi-view reconstruction and OpenSCAD.\n\n## Features\n\n- **AI Image Generation**: Generate images from text descriptions using Google Gemini or Venice.ai APIs\n- **Multi-View Image Generation**: Create multiple views of the same 3D object for reconstruction\n- **Image Approval Workflow**: Review and approve/deny generated images before reconstruction\n- **3D Reconstruction**: Convert approved multi-view images into 3D models using CUDA Multi-View Stereo\n- **Remote Processing**: Process computationally intensive tasks on remote servers within your LAN\n- **OpenSCAD Integration**: Generate parametric 3D models using OpenSCAD\n- **Parametric Export**: Export models in formats that preserve parametric properties (CSG, AMF, 3MF, SCAD)\n- **3D Printer Discovery**: Optional network printer discovery and direct printing\n\n## Architecture\n\nThe server is built using the Python MCP SDK and follows a modular architecture:\n\n```\nopenscad-mcp-server/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Main application\n‚îÇ   ‚îú‚îÄ‚îÄ main_remote.py           # Remote CUDA MVS server\n‚îÇ   ‚îú‚îÄ‚îÄ ai/                      # AI integrations\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_api.py        # Google Gemini API for image generation\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ venice_api.py        # Venice.ai API for image generation (optional)\n‚îÇ   ‚îú‚îÄ‚îÄ models/                  # 3D model generation\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cuda_mvs.py          # CUDA Multi-View Stereo integration\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ code_generator.py    # OpenSCAD code generation\n‚îÇ   ‚îú‚îÄ‚îÄ workflow/                # Workflow components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_approval.py    # Image approval mechanism\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ multi_view_to_model_pipeline.py  # Complete pipeline\n‚îÇ   ‚îú‚îÄ‚îÄ remote/                  # Remote processing\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cuda_mvs_client.py   # Client for remote CUDA MVS processing\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cuda_mvs_server.py   # Server for remote CUDA MVS processing\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection_manager.py # Remote connection management\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ error_handling.py    # Error handling for remote processing\n‚îÇ   ‚îú‚îÄ‚îÄ openscad_wrapper/        # OpenSCAD CLI wrapper\n‚îÇ   ‚îú‚îÄ‚îÄ visualization/           # Preview generation and web interface\n‚îÇ   ‚îú‚îÄ‚îÄ utils/                   # Utility functions\n‚îÇ   ‚îî‚îÄ‚îÄ printer_discovery/       # 3D printer discovery\n‚îú‚îÄ‚îÄ scad/                        # Generated OpenSCAD files\n‚îú‚îÄ‚îÄ output/                      # Output files (models, previews)\n‚îÇ   ‚îú‚îÄ‚îÄ images/                  # Generated images\n‚îÇ   ‚îú‚îÄ‚îÄ multi_view/              # Multi-view images\n‚îÇ   ‚îú‚îÄ‚îÄ approved_images/         # Approved images for reconstruction\n‚îÇ   ‚îî‚îÄ‚îÄ models/                  # Generated 3D models\n‚îú‚îÄ‚îÄ templates/                   # Web interface templates\n‚îî‚îÄ‚îÄ static/                      # Static files for web interface\n```\n\n## Installation\n\n1. Clone the repository:\n   ```\n   git clone https://github.com/jhacksman/OpenSCAD-MCP-Server.git\n   cd OpenSCAD-MCP-Server\n   ```\n\n2. Create a virtual environment:\n   ```\n   python -m venv venv\n   source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n   ```\n\n3. Install dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n\n4. Install OpenSCAD:\n   - Ubuntu/Debian: `sudo apt-get install openscad`\n   - macOS: `brew install openscad`\n   - Windows: Download from [openscad.org](https://openscad.org/downloads.html)\n\n5. Install CUDA Multi-View Stereo:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build \u0026\u0026 cd build\n   cmake ..\n   make\n   ```\n\n6. Set up API keys:\n   - Create a `.env` file in the root directory\n   - Add your API keys:\n     ```\n     GEMINI_API_KEY=your-gemini-api-key\n     VENICE_API_KEY=your-venice-api-key  # Optional\n     REMOTE_CUDA_MVS_API_KEY=your-remote-api-key  # For remote processing\n     ```\n\n## Remote Processing Setup\n\nThe server supports remote processing of computationally intensive tasks, particularly CUDA Multi-View Stereo reconstruction. This allows you to offload processing to more powerful machines within your LAN.\n\n### Server Setup (on the machine with CUDA GPU)\n\n1. Install CUDA Multi-View Stereo on the server machine:\n   ```\n   git clone https://github.com/fixstars/cuda-multi-view-stereo.git\n   cd cuda-multi-view-stereo\n   mkdir build \u0026\u0026 cd build\n   cmake ..\n   make\n   ```\n\n2. Start the remote CUDA MVS server:\n   ```\n   python src/main_remote.py\n   ```\n\n3. The server will automatically advertise itself on the local network using Zeroconf.\n\n### Client Configuration\n\n1. Configure remote processing in your `.env` file:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=True\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n2. Alternatively, you can specify a server URL directly:\n   ```\n   REMOTE_CUDA_MVS_ENABLED=True\n   REMOTE_CUDA_MVS_USE_LAN_DISCOVERY=False\n   REMOTE_CUDA_MVS_SERVER_URL=http://server-ip:8765\n   REMOTE_CUDA_MVS_API_KEY=your-shared-secret-key\n   ```\n\n### Remote Processing Features\n\n- **Automatic Server Discovery**: Find CUDA MVS servers on your local network\n- **Job Management**: Upload images, track job status, and download results\n- **Fault Tolerance**: Automatic retries, circuit breaker pattern, and error tracking\n- **Authentication**: Secure API key authentication for all remote operations\n- **Health Monitoring**: Continuous server health checks and status reporting\n\n## Usage\n\n1. Start the server:\n   ```\n   python src/main.py\n   ```\n\n2. The server will start on http://localhost:8000\n\n3. Use the MCP tools to interact with the server:\n\n   - **generate_image_gemini**: Generate an image using Google Gemini API\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit with black background\",\n       \"model\": \"gemini-2.0-flash-exp-image-generation\"\n     }\n     ```\n\n   - **generate_multi_view_images**: Generate multiple views of the same 3D object\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **create_3d_model_from_images**: Create a 3D model from approved multi-view images\n     ```json\n     {\n       \"image_ids\": [\"view_1\", \"view_2\", \"view_3\", \"view_4\"],\n       \"output_name\": \"rabbit_model\"\n     }\n     ```\n\n   - **create_3d_model_from_text**: Complete pipeline from text to 3D model\n     ```json\n     {\n       \"prompt\": \"A low-poly rabbit\",\n       \"num_views\": 4\n     }\n     ```\n\n   - **export_model**: Export a model to a specific format\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"format\": \"obj\"  // or \"stl\", \"ply\", \"scad\", etc.\n     }\n     ```\n\n   - **discover_remote_cuda_mvs_servers**: Find CUDA MVS servers on your network\n     ```json\n     {\n       \"timeout\": 5\n     }\n     ```\n\n   - **get_remote_job_status**: Check the status of a remote processing job\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\"\n     }\n     ```\n\n   - **download_remote_model_result**: Download a completed model from a remote server\n     ```json\n     {\n       \"server_id\": \"server-id\",\n       \"job_id\": \"job-id\",\n       \"output_name\": \"model-name\"\n     }\n     ```\n\n   - **discover_printers**: Discover 3D printers on the network\n     ```json\n     {}\n     ```\n\n   - **print_model**: Print a model on a connected printer\n     ```json\n     {\n       \"model_id\": \"your-model-id\",\n       \"printer_id\": \"your-printer-id\"\n     }\n     ```\n\n## Image Generation Options\n\nThe server supports multiple image generation options:\n\n1. **Google Gemini API** (Default): Uses the Gemini 2.0 Flash Experimental model for high-quality image generation\n   - Supports multi-view generation with consistent style\n   - Requires a Google Gemini API key\n\n2. **Venice.ai API** (Optional): Alternative image generation service\n   - Supports various models including flux-dev and fluently-xl\n   - Requires a Venice.ai API key\n\n3. **User-Provided Images**: Skip image generation and use your own images\n   - Upload images directly to the server\n   - Useful for working with existing photographs or renders\n\n## Multi-View Workflow\n\nThe server implements a multi-view workflow for 3D reconstruction:\n\n1. **Image Generation**: Generate multiple views of the same 3D object\n2. **Image Approval**: Review and approve/deny each generated image\n3. **3D Reconstruction**: Convert approved images into a 3D model using CUDA MVS\n   - Can be processed locally or on a remote server within your LAN\n4. **Model Refinement**: Optionally refine the model using OpenSCAD\n\n## Remote Processing Workflow\n\nThe remote processing workflow allows you to offload computationally intensive tasks to more powerful machines:\n\n1. **Server Discovery**: Automatically discover CUDA MVS servers on your network\n2. **Image Upload**: Upload approved multi-view images to the remote server\n3. **Job Processing**: Process the images on the remote server using CUDA MVS\n4. **Status Tracking**: Monitor the job status and progress\n5. **Result Download**: Download the completed 3D model when processing is finished\n\n## Supported Export Formats\n\nThe server supports exporting models in various formats:\n\n- **OBJ**: Wavefront OBJ format (standard 3D model format)\n- **STL**: Standard Triangle Language (for 3D printing)\n- **PLY**: Polygon File Format (for point clouds and meshes)\n- **SCAD**: OpenSCAD source code (for parametric models)\n- **CSG**: OpenSCAD CSG format (preserves all parametric properties)\n- **AMF**: Additive Manufacturing File Format (preserves some metadata)\n- **3MF**: 3D Manufacturing Format (modern replacement for STL with metadata)\n\n## Web Interface\n\nThe server provides a web interface for:\n\n- Generating and approving multi-view images\n- Previewing 3D models from different angles\n- Downloading models in various formats\n\nAccess the interface at http://localhost:8000/ui/\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n",
      "stars": 84,
      "updated_at": "2025-10-03T04:21:59Z",
      "url": "https://github.com/jhacksman/OpenSCAD-MCP-Server"
    },
    "jmanhype--mcp-flux-studio": {
      "category": "image-and-video-generation",
      "description": "Integrates advanced image generation capabilities from Flux into AI coding assistants, enabling seamless text-to-image generation and manipulation within development environments.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/jmanhype.webp",
      "keywords": [
        "ai",
        "flux",
        "studio",
        "image generation",
        "flux studio",
        "flux ai"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp-flux-studio",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "jmanhype",
      "readme_content": "# MCP Flux Studio\n\n[![smithery badge](https://smithery.ai/badge/@jmanhype/mcp-flux-studio)](https://smithery.ai/server/@jmanhype/mcp-flux-studio)\n\nA powerful Model Context Protocol (MCP) server that brings Flux's advanced image generation capabilities to your AI coding assistants. This server enables direct integration of Flux's image generation, manipulation, and control features into Cursor and Windsurf (Codeium) IDEs.\n\n## Overview\n\nMCP Flux Studio bridges the gap between AI coding assistants and Flux's powerful image generation API, allowing seamless integration of image generation capabilities directly into your development workflow.\n\n### Features\n\n- **Image Generation**\n  - Text-to-image generation with precise control\n  - Multiple model support (flux.1.1-pro, flux.1-pro, flux.1-dev, flux.1.1-ultra)\n  - Customizable aspect ratios and dimensions\n\n- **Image Manipulation**\n  - Image-to-image transformation\n  - Inpainting with customizable masks\n  - Resolution upscaling and enhancement\n\n- **Advanced Controls**\n  - Edge-based generation (canny)\n  - Depth-aware generation\n  - Pose-guided generation\n\n- **IDE Integration**\n  - Full support for Cursor (v0.45.7+)\n  - Compatible with Windsurf/Codeium Cascade (Wave 3+)\n  - Seamless tool invocation through AI assistants\n\n## Quick Start\n\n1. **Prerequisites**\n   - Node.js 18+\n   - Python 3.12+\n   - Flux API key\n   - Compatible IDE (Cursor or Windsurf)\n\n2. **Installation**\n\n### Installing via Smithery\n\nTo install Flux Studio for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@jmanhype/mcp-flux-studio):\n\n```bash\nnpx -y @smithery/cli install @jmanhype/mcp-flux-studio --client claude\n```\n\n### Manual Installation\n   ```bash\n   git clone https://github.com/jmanhype/mcp-flux-studio.git\n   cd mcp-flux-studio\n   npm install\n   npm run build\n   ```\n\n3. **Basic Configuration**\n   ```env\n   BFL_API_KEY=your_flux_api_key\n   FLUX_PATH=/path/to/flux/installation\n   ```\n\nFor detailed setup instructions, including IDE-specific configuration and troubleshooting, see our [Installation Guide](docs/INSTALLATION.md).\n\n## Documentation\n\n- [Installation Guide](docs/INSTALLATION.md) - Comprehensive setup instructions\n- [API Documentation](docs/API.md) - Detailed tool documentation\n- [Example Usage](examples/tool-examples.md) - Real-world usage examples\n- [Contributing Guidelines](docs/CONTRIBUTING.md) - How to contribute\n\n## IDE Integration\n\n### Cursor (v0.45.7+)\n\nMCP Flux Studio integrates seamlessly with Cursor's AI assistant:\n\n1. **Configuration**\n   - Configure via Settings \u003e Features \u003e MCP\n   - Supports both stdio and SSE connections\n   - Environment variables can be set via wrapper scripts\n\n2. **Usage**\n   - Tools automatically available to Cursor's AI assistant\n   - Tool invocations require user approval\n   - Real-time feedback on generation progress\n\n### Windsurf/Codeium (Wave 3+)\n\nIntegration with Windsurf's Cascade AI:\n\n1. **Configuration**\n   - Edit `~/.codeium/windsurf/mcp_config.json`\n   - Supports process-based tool execution\n   - Environment variables configured in JSON\n\n2. **Usage**\n   - Access tools through Cascade's MCP toolbar\n   - Automatic tool discovery and loading\n   - Integrated with Cascade's AI capabilities\n\nFor detailed IDE-specific setup instructions, see the [Installation Guide](docs/INSTALLATION.md).\n\n## Usage\n\nThe server provides the following tools:\n\n### generate\nGenerate an image from a text prompt.\n```json\n{\n  \"prompt\": \"A photorealistic cat\",\n  \"model\": \"flux.1.1-pro\",\n  \"aspect_ratio\": \"1:1\",\n  \"output\": \"generated.jpg\"\n}\n```\n\n### img2img\nGenerate an image using another image as reference.\n```json\n{\n  \"image\": \"input.jpg\",\n  \"prompt\": \"Convert to oil painting\",\n  \"model\": \"flux.1.1-pro\",\n  \"strength\": 0.85,\n  \"output\": \"output.jpg\",\n  \"name\": \"oil_painting\"\n}\n```\n\n### inpaint\nInpaint an image using a mask.\n```json\n{\n  \"image\": \"input.jpg\",\n  \"prompt\": \"Add flowers\",\n  \"mask_shape\": \"circle\",\n  \"position\": \"center\",\n  \"output\": \"inpainted.jpg\"\n}\n```\n\n### control\nGenerate an image using structural control.\n```json\n{\n  \"type\": \"canny\",\n  \"image\": \"control.jpg\",\n  \"prompt\": \"A realistic photo\",\n  \"output\": \"controlled.jpg\"\n}\n```\n\n## Development\n\n### Project Structure\n\n```\nflux-mcp-server/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ index.ts          # Main server implementation\n‚îÇ   ‚îî‚îÄ‚îÄ types.ts          # TypeScript type definitions\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îî‚îÄ‚îÄ server.test.ts    # Server tests\n‚îú‚îÄ‚îÄ docs/\n‚îÇ   ‚îú‚îÄ‚îÄ API.md           # API documentation\n‚îÇ   ‚îî‚îÄ‚îÄ CONTRIBUTING.md  # Contribution guidelines\n‚îú‚îÄ‚îÄ examples/\n‚îÇ   ‚îú‚îÄ‚îÄ generate.json    # Example tool usage\n‚îÇ   ‚îî‚îÄ‚îÄ config.json      # Example configuration\n‚îú‚îÄ‚îÄ package.json\n‚îú‚îÄ‚îÄ tsconfig.json\n‚îî‚îÄ‚îÄ README.md\n```\n\n### Running Tests\n\n```bash\nnpm test\n```\n\n### Building\n\n```bash\nnpm run build\n```\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](docs/CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- [Model Context Protocol](https://github.com/modelcontextprotocol/mcp) - The protocol specification\n- [Flux API](https://flux.ai) - The underlying image generation API\n",
      "stars": 20,
      "updated_at": "2025-08-11T12:07:21Z",
      "url": "https://github.com/jmanhype/mcp-flux-studio"
    },
    "joshmouch--mcp-image-generator": {
      "category": "image-and-video-generation",
      "description": "Generate, edit, and create variations of images using OpenAI's DALL-E API, supporting multiple DALL-E models with customizable parameters. Validate OpenAI API keys for seamless operation.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/null.webp",
      "keywords": [
        "openai",
        "images",
        "dall",
        "image generator",
        "mcp image",
        "video generation"
      ],
      "language": "Unknown",
      "license": "Unknown",
      "name": "mcp-image-generator",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "joshmouch",
      "readme_content": "",
      "stars": 0,
      "updated_at": "",
      "url": "https://github.com/joshmouch/mcp-image-generator"
    },
    "jyjune--mcp_vms": {
      "category": "image-and-video-generation",
      "description": "Connects to CCTV recording software to retrieve live and recorded video streams, manage video channel information, and control VMS features like PTZ camera presets and playback dialogs.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/jyjune.webp",
      "keywords": [
        "mcp_vms",
        "cctv",
        "vms",
        "jyjune mcp_vms",
        "cctv recording",
        "connects cctv"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp_vms",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "jyjune",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/jyjune-mcp-vms-badge.png)](https://mseep.ai/app/jyjune-mcp-vms)\n\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/jyjune/mcp_vms)](https://archestra.ai/mcp-catalog/jyjune__mcp_vms)\n\n# MCP Server - VMS Integration\n\nA Model Context Protocol (MCP) server designed to connect to a CCTV recording program (VMS) to retrieve recorded and live video streams. It also provides tools to control the VMS software, such as showing live or playback dialogs for specific channels at specified times.\n\n![diagram](https://github.com/jyjune/mcp_vms/blob/main/mcp_vms_diagram.png?raw=true)\n\n## Features\n\n- Retrieve video channel information, including connection and recording status.\n- Fetch recording dates and times for specific channels.\n- Fetch live or recorded images from video channels.\n- Show live video streams or playback dialogs for specific channels and timestamps.\n- Control PTZ (Pan-Tilt-Zoom) cameras by moving them to preset positions.\n- Comprehensive error handling and logging.\n\n## Prerequisites\n\n- Python 3.12+\n- `vmspy` library (for VMS integration)\n- `Pillow` library (for image processing)\n\n## MCP-server Configuration\n\nIf you want to use `mcp-vms` with Claude desktop, you need to set up the `claude_desktop_config.json` file as follows:\n\n```json\n{\n  \"mcpServers\": {\n\t\"vms\": {\n\t  \"command\": \"uv\",\n\t  \"args\": [\n\t\t\"--directory\",\n\t\t\"X:\\\\path\\\\to\\\\mcp-vms\",\n\t\t\"run\",\n\t\t\"mcp_vms.py\"\n\t  ]\n\t}\n  }\n}\n```\n\n## VMS Connection Configuration\n\nThe server uses the following default configuration for connecting to the VMS:\n- mcp_vms_config.py\n```python\nvms_config = {\n    'img_width': 320,\n    'img_height': 240,\n    'pixel_format': 'RGB',\n    'url': '127.0.0.1',\n    'port': 3300,\n    'access_id': 'admin',\n    'access_pw': 'admin',\n}\n```\n\n## Installation\n\n### 1. Install UV Package Manager\nRun the following command in PowerShell to install `UV`:\n\n```shell\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nFor alternative installation methods, see the [official UV documentation](https://docs.astral.sh/uv/getting-started/installation/).\n\n### 2.Install VMS Server\n   Download and install the VMS server from:  \n   [http://surveillance-logic.com/en/download.html](http://surveillance-logic.com/en/download.html)\n   (Required before using this MCP server)\n\n### 3.Install Python Dependencies\n   Download the vmspy library:  \n   [vmspy1.4-python3.12-x64.zip](https://sourceforge.net/projects/security-vms/files/vmspy1.4-python3.12-x64.zip/download)\n   Extract the contents into your `mcp_vms` directory\n\nThe mcp-vms directory should look like this:\n\n```shell\nmcp-vms/\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ uv.lock\n‚îú‚îÄ‚îÄ mcp_vms.py            # Main server implementation\n‚îú‚îÄ‚îÄ mcp_vms_config.py     # VMS connection configuration\n‚îú‚îÄ‚îÄ vmspy.pyd             # VMS Python library\n‚îú‚îÄ‚îÄ avcodec-61.dll        # FFmpeg libraries\n‚îú‚îÄ‚îÄ avutil-59.dll\n‚îú‚îÄ‚îÄ swresample-5.dll\n‚îú‚îÄ‚îÄ swscale-8.dll\n```\n[![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/7027c4cd-a9c1-43dd-9e74-771fc7cc42da)\n",
      "stars": 10,
      "updated_at": "2025-10-03T17:24:47Z",
      "url": "https://github.com/jyjune/mcp_vms"
    },
    "kazuph--mcp-fetch": {
      "category": "image-and-video-generation",
      "description": "Fetch web content and process images to facilitate efficient interaction with online resources. Supports integration with MCP clients like Claude Desktop for seamless content management.",
      "forks": 18,
      "imageUrl": "/freedevtools/mcp/pfp/kazuph.webp",
      "keywords": [
        "kazuph",
        "mcp",
        "fetch",
        "mcp fetch",
        "kazuph mcp",
        "content management"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp-fetch",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "kazuph",
      "readme_content": "# MCP Fetch\n\nModel Context Protocol server for fetching web content and processing images. This allows Claude Desktop (or any MCP client) to fetch web content and handle images appropriately.\n\n\u003ca href=\"https://glama.ai/mcp/servers/5mknfdhyrg\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/5mknfdhyrg/badge\" alt=\"@kazuph/mcp-fetch MCP server\" /\u003e\u003c/a\u003e\n\n## Quick Start (For Users)\n\nTo use this tool with Claude Desktop, simply add the following to your Claude Desktop configuration (`~/Library/Application Support/Claude/claude_desktop_config.json`):\n\n```json\n{\n  \"tools\": {\n    \"imageFetch\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-fetch\"]\n    }\n  }\n}\n```\n\nThis will automatically download and run the latest version of the tool when needed.\n\n### Required Setup\n\n1. Enable Accessibility for Claude:\n   - Open System Settings\n   - Go to Privacy \u0026 Security \u003e Accessibility\n   - Click the \"+\" button\n   - Add Claude from your Applications folder\n   - Turn ON the toggle for Claude\n\nThis accessibility setting is required for automated clipboard operations (Cmd+V) to work properly.\n\n## Features\n\n- **Web Content Extraction**: Automatically extracts and formats web content as markdown\n- **Article Title Extraction**: Extracts and displays the title of the article\n- **Image Processing**: Optional processing of images from web pages with optimization (disabled by default, enable with `enableFetchImages: true`)\n- **File Saving**: Images are automatically saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` directory when processed\n- **Dual Output**: Both file saving and optional Base64 encoding for AI display\n- **Pagination Support**: Supports pagination for both text and images\n- **JPEG Optimization**: Automatically optimizes images as JPEG for better performance\n- **GIF Support**: Extracts first frame from animated GIFs\n\n## For Developers\n\nThe following sections are for those who want to develop or modify the tool.\n\n## Prerequisites\n\n- Node.js 18+\n- macOS (for clipboard operations)\n- Claude Desktop (install from https://claude.ai/desktop)\n- tsx (install via `npm install -g tsx`)\n\n## Installation\n\n```bash\ngit clone https://github.com/kazuph/mcp-fetch.git\ncd mcp-fetch\nnpm install\nnpm run build\n```\n\n## Image Processing Specifications\n\nWhen processing images from web content, the following optimizations are applied:\n\n- Images are converted to JPEG format with quality control\n- Maximum width limited to 1200px by default\n- Maximum height limited to 1600px by default\n- Chroma subsampling (4:2:0) for better compression\n- MozJPEG optimization for smaller file sizes\n\n## Configuration\n\n1. Make sure Claude Desktop is installed and running.\n\n2. Install tsx globally if you haven't:\n```bash\nnpm install -g tsx\n# or\npnpm add -g tsx\n```\n\n3. Modify your Claude Desktop config located at:\n`~/Library/Application Support/Claude/claude_desktop_config.json`\n\nYou can easily find this through the Claude Desktop menu:\n1. Open Claude Desktop\n2. Click Claude on the Mac menu bar\n3. Click \"Settings\"\n4. Click \"Developer\"\n\nAdd the following to your MCP client's configuration:\n\n```json\n{\n  \"tools\": {\n    \"imageFetch\": {\n      \"args\": [\"tsx\", \"/path/to/mcp-fetch/index.ts\"]\n    }\n  }\n}\n```\n\n## Available Parameters\n\n- `url` (required): The URL to fetch\n- `maxLength` (default: 20000): Maximum length of content to return\n- `startIndex` (default: 0): Starting position in content\n- `imageStartIndex` (default: 0): Starting position for image collection\n- `raw` (default: false): Return raw content instead of processed markdown\n- `imageMaxCount` (default: 3): Maximum number of images to process per request\n- `imageMaxHeight` (default: 4000): Maximum height of merged image\n- `imageMaxWidth` (default: 1000): Maximum width of merged image\n- `imageQuality` (default: 80): JPEG quality (1-100)\n- `enableFetchImages` (default: false): Enable fetching and processing of images. FOR CLAUDE USERS ONLY: YOU ARE ALLOWED TO ENABLE THIS FEATURE!!! CLAUDE CAN FETCH AND PROCESS IMAGES!!! ENJOY THIS CAPABILITY!!!!!\n- `allowCrossOriginImages` (default: true): When true, also fetch images hosted on different origins from the page\n- `saveImages` (default: true): Save processed images to local files\n- `returnBase64` (default: false): Return base64 encoded images for AI display\n- `ignoreRobotsTxt` (default: false): Ignore robots.txt restrictions\n\n### Security Hardening (v1.5.1)\n\n- Only `http://` and `https://` URLs are allowed for page and image fetches\n- Blocks private/loopback/link-local IPs and local hostnames (e.g., `localhost`, `.local`)\n- Manual redirect handling with validation (max 3 hops)\n- Request timeouts (default 12s, configurable via `MCP_FETCH_TIMEOUT_MS`)\n- Response size limits: HTML up to 2MB, images up to 10MB (tunable via env)\n\nEnvironment variables:\n\n- `MCP_FETCH_TIMEOUT_MS` (default: 12000)\n- `MCP_FETCH_MAX_REDIRECTS` (default: 3)\n- `MCP_FETCH_MAX_HTML_BYTES` (default: 2000000)\n- `MCP_FETCH_MAX_IMAGE_BYTES` (default: 10000000)\n\n## Examples\n\n### Basic Content Fetching (No Images)\n```json\n{\n  \"url\": \"https://example.com\"\n}\n```\n\n### Fetching with Images (File Saving Only)\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"imageMaxCount\": 3\n}\n```\n\n### Fetching with Images for AI Display\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"returnBase64\": true,\n  \"imageMaxCount\": 3\n}\n```\n\n### Paginating Through Images\n```json\n{\n  \"url\": \"https://example.com\",\n  \"enableFetchImages\": true,\n  \"imageStartIndex\": 3,\n  \"imageMaxCount\": 3\n}\n```\n\n## Notes\n\n- This tool is designed for macOS only due to its dependency on macOS-specific clipboard operations.\n- Images are processed using Sharp for optimal performance and quality.\n- When multiple images are found, they are merged vertically with consideration for size limits.\n- Animated GIFs are automatically handled by extracting their first frame.\n- **File Saving**: Images are automatically saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` with filename format `hostname_HHMMSS_index.jpg`\n- **Tool Name**: The tool name has been changed from `fetch` to `imageFetch` to avoid conflicts with native fetch functions.\n\n## Changelog\n\n### v1.2.0\n- **BREAKING CHANGE**: Tool name changed from `fetch` to `imageFetch` to avoid conflicts\n- **NEW**: Automatic file saving - Images are now saved to `~/Downloads/mcp-fetch/YYYY-MM-DD/` by default\n- **NEW**: Added `saveImages` parameter (default: true) to control file saving\n- **NEW**: Added `returnBase64` parameter (default: false) for AI image display\n- **BEHAVIOR CHANGE**: Default behavior now saves files instead of only returning base64\n- Improved AI assistant integration with clear instructions for base64 option\n- Enhanced file organization with date-based directories and structured naming\n\n### v1.1.3\n- Changed default behavior: Images are not fetched by default (`enableFetchImages: false`)\n- Removed `disableImages` in favor of `enableFetchImages` parameter\n\n### v1.1.0\n- Added article title extraction feature\n- Improved response formatting to include article titles\n- Fixed type issues with MCP response content\n\n### v1.0.0\n- Initial release\n- Web content extraction\n- Image processing and optimization\n- Pagination support\n",
      "stars": 30,
      "updated_at": "2025-09-29T16:56:16Z",
      "url": "https://github.com/kazuph/mcp-fetch"
    },
    "kazuph--mcp-screenshot": {
      "category": "image-and-video-generation",
      "description": "Captures screenshots and performs OCR text recognition on macOS. Supports both Japanese and English text, offering multiple output formats.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/kazuph.webp",
      "keywords": [
        "kazuph",
        "macos",
        "ocr",
        "mcp screenshot",
        "recognition macos",
        "kazuph mcp"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp-screenshot",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "kazuph",
      "readme_content": "# MCP Screenshot\n\nAn MCP server that captures screenshots and performs OCR text recognition.\n\n\u003ca href=\"https://glama.ai/mcp/servers/vcnmmaejv8\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/vcnmmaejv8/badge\" alt=\"mcp-screenshot MCP server\" /\u003e\u003c/a\u003e\n\n## Features\n\n- Screenshot capture (left half, right half, full screen)\n- OCR text recognition (supports Japanese and English)\n- Multiple output formats (JSON, Markdown, vertical, horizontal)\n\n## OCR Engines\n\nThis server uses two OCR engines:\n\n1. [yomitoku](https://github.com/kazuph/yomitoku)\n   - Primary OCR engine\n   - High-accuracy Japanese text recognition\n   - Runs as an API server\n\n2. [Tesseract.js](https://github.com/naptha/tesseract.js)\n   - Fallback OCR engine\n   - Used when yomitoku is unavailable\n   - Supports both Japanese and English recognition\n\n## Installation\n\n```bash\nnpx -y @kazuph/mcp-screenshot\n```\n\n## Claude Desktop Configuration\n\nAdd the following configuration to your `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"screenshot\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@kazuph/mcp-screenshot\"],\n      \"env\": {\n        \"OCR_API_URL\": \"http://localhost:8000\"  // yomitoku API base URL\n      }\n    }\n  }\n}\n```\n\n## Environment Variables\n\n| Variable Name | Description | Default Value |\n|--------------|-------------|---------------|\n| OCR_API_URL | yomitoku API base URL | http://localhost:8000 |\n\n## Usage Example\n\nYou can use it by instructing Claude like this:\n\n```\nPlease take a screenshot of the left half of the screen and recognize the text in it.\n```\n\n## Tool Specification\n\n### capture\n\nTakes a screenshot and performs OCR.\n\nOptions:\n- `region`: Screenshot area ('left'/'right'/'full', default: 'left')\n- `format`: Output format ('json'/'markdown'/'vertical'/'horizontal', default: 'markdown')\n\n## License\n\nMIT\n\n## Author\n\nkazuph\n",
      "stars": 21,
      "updated_at": "2025-10-03T22:32:03Z",
      "url": "https://github.com/kazuph/mcp-screenshot"
    },
    "kshern--image-tools-mcp": {
      "category": "image-and-video-generation",
      "description": "Retrieve image dimensions, compress images, and convert images to various formats using local files or URLs. Supports image processing with detailed output on dimensions, types, and compression information.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/kshern.webp",
      "keywords": [
        "images",
        "mcp",
        "compression",
        "image tools",
        "convert images",
        "images convert"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "image-tools-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "kshern",
      "readme_content": "# Image Tools MCP\n\n[![smithery badge](https://smithery.ai/badge/@kshern/image-tools-mcp)](https://smithery.ai/server/@kshern/image-tools-mcp)\n\nA Model Context Protocol (MCP) service for retrieving image dimensions and compressing images, supporting both URL and local file sources.\n\n_[‰∏≠ÊñáÊñáÊ°£](./README_zh.md)_\n\n## Features\n\n- Retrieve image dimensions from URLs\n- Get image dimensions from local files\n- Compress images from URLs using TinyPNG API\n- Compress local images using TinyPNG API\n- Convert images to different formats (webp, jpeg/jpg, png)\n- Returns width, height, type, MIME type, and compression information\n\n### Example Results\n\n\n\n\n\n\n\ndownload from figma url and compress\n\n\n## Usage\n\n### Using as an MCP Service\n\nThis service provides five tool functions:\n\n1. `get_image_size` - Get dimensions of remote images\n2. `get_local_image_size` - Get dimensions of local images\n3. `compress_image_from_url` - Compress remote images using TinyPNG API\n4. `compress_local_image` - Compress local images using TinyPNG API\n5. `figma` - Fetch image links from Figma API and compress them using TinyPNG API\n\n### Client Integration\n\nTo use this MCP service, you need to connect to it from an MCP client. Here are examples of how to integrate with different clients:\n\n#### Usage\n\n```json\n{\n  \"mcpServers\": {\n    \"image-tools\": {\n      \"command\": \"npx\",\n      \"args\": [\"image-tools-mcp\"],\n      \"env\": {\n        \"TINIFY_API_KEY\": \"\u003cYOUR_TINIFY_API_KEY\u003e\",\n        \"FIGMA_API_TOKEN\": \"\u003cYOUR_FIGMA_API_TOKEN\u003e\"\n      }\n    }\n  }\n}\n```\n\n#### Using with MCP Client Library\n\n````typescript\nimport { McpClient } from \"@modelcontextprotocol/client\";\n\n// Initialize the client\nconst client = new McpClient({\n  transport: \"stdio\" // or other transport options\n});\n\n// Connect to the server\nawait client.connect();\n\n// Get image dimensions from URL\nconst urlResult = await client.callTool(\"get_image_size\", {\n  options: {\n    imageUrl: \"https://example.com/image.jpg\"\n  }\n});\nconsole.log(JSON.parse(urlResult.content[0].text));\n// Output: { width: 800, height: 600, type: \"jpg\", mime: \"image/jpeg\" }\n\n// Get image dimensions from local file\nconst localResult = await client.callTool(\"get_local_image_size\", {\n  options: {\n    imagePath: \"D:/path/to/image.png\"\n  }\n});\nconsole.log(JSON.parse(localResult.content[0].text));\n// Output: { width: 1024, height: 768, type: \"png\", mime: \"image/png\", path: \"D:/path/to/image.png\" }\n\n// Compress image from URL\nconst compressUrlResult = await client.callTool(\"compress_image_from_url\", {\n  options: {\n    imageUrl: \"https://example.com/image.jpg\",\n    outputFormat: \"webp\" // Optional: convert to webp, jpeg/jpg, or png\n  }\n});\nconsole.log(JSON.parse(compressUrlResult.content[0].text));\n// Output: { originalSize: 102400, compressedSize: 51200, compressionRatio: \"50.00%\", tempFilePath: \"/tmp/compressed_1615456789.webp\", format: \"webp\" }\n\n// Compress local image\nconst compressLocalResult = await client.callTool(\"compress_local_image\", {\n  options: {\n    imagePath: \"D:/path/to/image.png\",\n    outputPath: \"D:/path/to/compressed.webp\", // Optional\n    outputFormat: \"image/webp\" // Optional: convert to image/webp, image/jpeg, or image/png\n  }\n});\nconsole.log(JSON.parse(compressLocalResult.content[0].text));\n// Output: { originalSize: 102400, compressedSize: 51200, compressionRatio: \"50.00%\", outputPath: \"D:/path/to/compressed.webp\", format: \"webp\" }\n\n// Fetch image links from Figma API\n\nconst figmaResult = await client.callTool(\"figma\", {\n  options: {\n    figmaUrl: \"https://www.figma.com/file/XXXXXXX\"\n  }\n});\nconsole.log(JSON.parse(figmaResult.content[0].text));\n// Output: { imageLinks: [\"https://example.com/image1.jpg\", \"https://example.com/image2.jpg\"] }\n\n### Tool Schemas\n\n#### get_image_size\n\n```typescript\n{\n  options: {\n    imageUrl: string // URL of the image to retrieve dimensions for\n  }\n}\n````\n\n#### get_local_image_size\n\n```typescript\n{\n  options: {\n    imagePath: string; // Absolute path to the local image file\n  }\n}\n```\n\n#### compress_image_from_url\n\n```typescript\n{\n  options: {\n    imageUrl: string // URL of the image to compress\n    outputFormat?: \"image/webp\" | \"image/jpeg\" | \"image/jpg\" | \"image/png\" // Optional output format\n  }\n}\n```\n\n#### compress_local_image\n\n```typescript\n{\n  options: {\n    imagePath: string // Absolute path to the local image file\n    outputPath?: string // Optional absolute path for the compressed output image\n    outputFormat?: \"image/webp\" | \"image/jpeg\" | \"image/jpg\" | \"image/png\" // Optional output format\n  }\n}\n```\n\n#### figma\n\n```typescript\n{\n  options: {\n    figmaUrl: string; // URL of the Figma file to fetch image links from\n  }\n}\n```\n\n## Changelog\n\n- **2025-05-12:** Updated Figma API to support additional parameters, including 2x image scaling.\n\n## Technical Implementation\n\nThis project is built on the following libraries:\n\n- [probe-image-size](https://github.com/nodeca/probe-image-size) - For image dimension detection\n- [tinify](https://github.com/tinify/tinify-nodejs) - For image compression via the TinyPNG API\n- [figma-api](https://github.com/figma/api) - For fetching image links from Figma API\n\n## Environment Variables\n\n- `TINIFY_API_KEY` - Required for image compression functionality. Get your API key from [TinyPNG](https://tinypng.com/developers)\n  - When not provided, the compression tools (`compress_image_from_url` and `compress_local_image`) will not be registered\n- `FIGMA_API_TOKEN` - Required for fetching image links from Figma API. Get your API token from [Figma](https://www.figma.com/developers)\n  - When not provided, the Figma tool (`figma`) will not be registered\n\nNote: The basic image dimension tools (`get_image_size` and `get_local_image_size`) are always available regardless of API keys.\n\n## License\n\nMIT",
      "stars": 6,
      "updated_at": "2025-10-03T22:32:19Z",
      "url": "https://github.com/kshern/image-tools-mcp"
    },
    "lalanikarim--comfy-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generates images based on user prompts by interacting with a remote Comfy server. Utilizes the FastMCP framework to manage image generation workflows.",
      "forks": 12,
      "imageUrl": "/freedevtools/mcp/pfp/lalanikarim.webp",
      "keywords": [
        "fastmcp",
        "mcp",
        "lalanikarim",
        "utilizes fastmcp",
        "mcp server",
        "fastmcp framework"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "comfy-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "lalanikarim",
      "readme_content": "# Comfy MCP Server\n\n[![smithery badge](https://smithery.ai/badge/@lalanikarim/comfy-mcp-server)](https://smithery.ai/server/@lalanikarim/comfy-mcp-server)\n\n\u003e A server using FastMCP framework to generate images based on prompts via a remote Comfy server.\n\n## Overview\n\nThis script sets up a server using the FastMCP framework to generate images based on prompts using a specified workflow. It interacts with a remote Comfy server to submit prompts and retrieve generated images.\n\n## Prerequisites\n\n- [uv](https://docs.astral.sh/uv/) package and project manager for Python.\n- Workflow file exported from Comfy UI. This code includes a sample `Flux-Dev-ComfyUI-Workflow.json` which is only used here as reference. You will need to export from your workflow and set the environment variables accordingly.\n\nYou can install the required packages for local development:\n\n```bash\nuvx mcp[cli]\n```\n\n## Configuration\n\nSet the following environment variables:\n\n- `COMFY_URL` to point to your Comfy server URL.\n- `COMFY_WORKFLOW_JSON_FILE` to point to the absolute path of the API export json file for the comfyui workflow.\n- `PROMPT_NODE_ID` to the id of the text prompt node.\n- `OUTPUT_NODE_ID` to the id of the output node with the final image.\n- `OUTPUT_MODE` to either `url` or `file` to select desired output.\n\nOptionally, if you have an [Ollama](https://ollama.com) server running, you can connect to it for prompt generation.\n\n- `OLLAMA_API_BASE` to the url where ollama is running.\n- `PROMPT_LLM` to the name of the model hosted on ollama for prompt generation.\n\nExample:\n\n```bash\nexport COMFY_URL=http://your-comfy-server-url:port\nexport COMFY_WORKFLOW_JSON_FILE=/path/to/the/comfyui_workflow_export.json\nexport PROMPT_NODE_ID=6 # use the correct node id here\nexport OUTPUT_NODE_ID=9 # use the correct node id here\nexport OUTPUT_MODE=file\n```\n\n## Usage\n\nComfy MCP Server can be launched by the following command:\n\n```bash\nuvx comfy-mcp-server\n```\n\n### Example Claude Desktop Config\n\n```json\n{\n  \"mcpServers\": {\n    \"Comfy MCP Server\": {\n      \"command\": \"/path/to/uvx\",\n      \"args\": [\n        \"comfy-mcp-server\"\n      ],\n      \"env\": {\n        \"COMFY_URL\": \"http://your-comfy-server-url:port\",\n        \"COMFY_WORKFLOW_JSON_FILE\": \"/path/to/the/comfyui_workflow_export.json\",\n        \"PROMPT_NODE_ID\": \"6\",\n        \"OUTPUT_NODE_ID\": \"9\",\n        \"OUTPUT_MODE\": \"file\",\n      }\n    }\n  }\n}\n\n```\n\n## Functionality\n\n### `generate_image(prompt: str, ctx: Context) -\u003e Image | str`\n\nThis function generates an image using a specified prompt. It follows these steps:\n\n1. Checks if all the environment variable are set.\n2. Loads a prompt template from a JSON file.\n3. Submits the prompt to the Comfy server.\n4. Polls the server for the status of the prompt processing.\n5. Retrieves and returns the generated image once it's ready.\n\n### `generate_prompt(topic: str, ctx: Context) -\u003e str`\n\nThis function generates a comprehensive image generation prompt from specified topic.\n\n## Dependencies\n\n- `mcp`: For setting up the FastMCP server.\n- `json`: For handling JSON data.\n- `urllib`: For making HTTP requests.\n- `time`: For adding delays in polling.\n- `os`: For accessing environment variables.\n- `langchain`: For creating simple LLM Prompt chain to generate image generation prompt from topic.\n- `langchain-ollama`: For ollama specific modules for LangChain.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](https://github.com/lalanikarim/comfy-mcp-server/blob/main/LICENSE) file for details.\n",
      "stars": 31,
      "updated_at": "2025-10-01T17:04:48Z",
      "url": "https://github.com/lalanikarim/comfy-mcp-server"
    },
    "laosu888--tupianyasuo": {
      "category": "image-and-video-generation",
      "description": "A front-end image compression tool supporting various formats like PNG and JPG, enabling users to customize compression ratios and preview results in real-time. The application allows users to download optimized images with comparisons of file sizes before and after compression.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/laosu888.webp",
      "keywords": [
        "compression",
        "png",
        "images",
        "image compression",
        "compression tool",
        "video generation"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "tupianyasuo",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "laosu888",
      "readme_content": "# ÂõæÁâáÂéãÁº©Â∑•ÂÖ∑\n\n‰∏Ä‰∏™ÁÆÄÂçïÊòìÁî®ÁöÑÂú®Á∫øÂõæÁâáÂéãÁº©Â∑•ÂÖ∑ÔºåÂÖ∑ÊúâÁ≤æÁæéÁöÑËãπÊûúÈ£éÊ†ºÁïåÈù¢ËÆæËÆ°„ÄÇ\n\n## ÂäüËÉΩÁâπÁÇπ\n\n- ÊîØÊåÅPNG„ÄÅJPGÁ≠âÊ†ºÂºèÂõæÁâá‰∏ä‰º†\n- ÊîØÊåÅËá™ÂÆö‰πâÂéãÁº©ÊØî‰æã\n- ÂÆûÊó∂È¢ÑËßàÂéãÁº©ÂâçÂêéÁöÑÂõæÁâáÊïàÊûú\n- ÊòæÁ§∫ÂéãÁº©ÂâçÂêéÊñá‰ª∂Â§ßÂ∞èÂØπÊØî\n- ÊîØÊåÅÂéãÁº©ÂêéÂõæÁâá‰∏ãËΩΩ\n- Á∫ØÂâçÁ´ØÂÆûÁé∞ÔºåÊó†ÈúÄÂêéÁ´ØÊúçÂä°\n\n## È°πÁõÆÁªìÊûÑ\n\n```\n‚îú‚îÄ‚îÄ index.html          # ‰∏ªÈ°µÈù¢\n‚îú‚îÄ‚îÄ css/               \n‚îÇ   ‚îî‚îÄ‚îÄ style.css      # Ê†∑ÂºèÊñá‰ª∂\n‚îú‚îÄ‚îÄ js/\n‚îÇ   ‚îî‚îÄ‚îÄ main.js        # ‰∏ªË¶ÅÂäüËÉΩÂÆûÁé∞\n‚îî‚îÄ‚îÄ assets/\n    ‚îî‚îÄ‚îÄ icons/         # SVGÂõæÊ†á\n```\n\n## ÊäÄÊúØÊ†à\n\n- HTML5\n- CSS3 (Flexbox \u0026 Grid)\n- Vanilla JavaScript\n- ÊµèËßàÂô®ÂéüÁîüÂõæÁâáÂéãÁº©API ",
      "stars": 0,
      "updated_at": "2024-12-25T19:15:50Z",
      "url": "https://github.com/laosu888/tupianyasuo"
    },
    "luojunhui1--ImageOnC": {
      "category": "image-and-video-generation",
      "description": "Implement vehicle license plate recognition using C/C++ on FPGA, utilizing OpenCV for image display and Eigen for optimized matrix operations. The project includes code for training neural networks and processing license plate images.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/luojunhui1.webp",
      "keywords": [
        "opencv",
        "recognition",
        "imageonc",
        "opencv image",
        "plate recognition",
        "license plate"
      ],
      "language": "C++",
      "license": "No License",
      "name": "ImageOnC",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "luojunhui1",
      "readme_content": "# ImageOnC\n## 1.‰ªãÁªç\nÊú¨‰ªìÂ∫ì‰∏∫ÂÆûÁé∞Âú®FPGA‰∏äÁöÑËΩ¶ÁâåËØÜÂà´ËÄåÂàõÂª∫Ôºå‰ΩÜÊú¨‰ªìÂ∫ìÂè™‰øùÊúâC/C++ÈÉ®ÂàÜÁöÑ‰ª£Á†ÅÔºåÂπ∂Êú™‰øùÂ≠ò‰ΩøÁî®HLSÂ∑•ÂÖ∑ÂêéÁöÑ‰ª£Á†Å„ÄÇË¶ÅÁâπÂà´ËØ¥ÊòéÁöÑÊòØÔºåÊú¨È°πÁõÆ‰∏≠ÁöÑ‰ª£Á†ÅÂùáÁî®CÂÆûÁé∞ÔºåÂÖ∂‰∏≠Âá∫Áé∞ÁöÑC++‰∏ªË¶Å‰∏∫‰æø‰∫éOpenCVËøõË°åÂõæÂÉèÊòæÁ§∫ÊàñËÄÖEigenÂ∫ìÂä†ÈÄüÁü©ÈòµËøêÁÆóÔºå‰ΩÜÂùáÂèØÂà†Èô§ÊàñÊîπÊàêC‰∏≠ÁöÑÊï∞ÁªÑËÄå‰∏çÂΩ±ÂìçÂÖ∂Ê≠£Â∏∏ÂäüËÉΩ„ÄÇ\n## 2.Êñá‰ª∂ÁªÑÊàê\n```\n.\n‚îú‚îÄ‚îÄ build\n‚îú‚îÄ‚îÄ cmake-build-debug\n‚îú‚îÄ‚îÄ CMakeLists.txt\n‚îú‚îÄ‚îÄ database\n‚îú‚îÄ‚îÄ Fit.cpp\n‚îú‚îÄ‚îÄ Han\n‚îú‚îÄ‚îÄ include\n‚îú‚îÄ‚îÄ Letters\n‚îú‚îÄ‚îÄ main.cpp\n‚îú‚îÄ‚îÄ paramLetters.txt\n‚îú‚îÄ‚îÄ param.txt\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ Train.cpp\n```\n\nÂÖ∂‰∏≠buildÂíåcmake-build-debugÊñá‰ª∂Âùá‰∏∫ÁºñËØëÊâßË°åËøáÁ®ã‰∫ßÁîüÁöÑÊñá‰ª∂ÔºõCMakeLists.txtÁî®‰∫éÊåáÂØºÁºñËØëÊñπÂºèÔºõdatabase‰∏∫ËΩ¶ÁâåÂõæÁâáÊñá‰ª∂Â§πÔºõFit.cppÂéü‰ΩúÊµãËØïÁΩëÁªúÂáÜÁ°ÆÊÄßÔºå‰ΩÜÂÖ∂ÂÜÖÂÆπÂú®ÊµãËØïÂêéË¢´Êï¥ÂêàÂà∞main.cpp‰∏≠ÔºåÊïÖËØ•Êñá‰ª∂Êó†ÂÆûÈôÖÊÑè‰πâÔºõHanÊñá‰ª∂Â§π‰øùÂ≠ò‰∫ÜÁî®‰∫éËÆ≠ÁªÉÊ±âÂ≠óËØÜÂà´ÁöÑÂõæÂÉèÔºõLetters‰∏≠Âàô‰øùÂ≠ò‰∫ÜÁî®‰∫éËÆ≠ÁªÉÂ≠óÊØçÂíåÊï∞Â≠óËØÜÂà´ÁöÑ‰ª£Á†ÅÔºõmain.cpp‰∏∫ÊâßË°åÁöÑËØÜÂà´ËΩ¶ÁâåÁöÑ‰∏ªÂáΩÊï∞ÔºõTrain.cppÁî®‰∫éËÆ≠ÁªÉÁ•ûÁªèÁΩëÁªúÔºõparam.txtÂèäparamLetters.txtÂàô‰øùÂ≠ò‰∫ÜÁΩëÁªúÂèÇÊï∞ÔºõincludeÊñá‰ª∂‰∏≠‰øùÂ≠ò‰∫Ü‰∏ÄÂÜôËá™ÂÆö‰πâÁöÑÂäüËÉΩÂáΩÊï∞ÔºåÂÖ∂Êñá‰ª∂Ê†ëÂ¶Ç‰∏ãÔºö\n```\n.\n‚îú‚îÄ‚îÄ Config.h\n‚îú‚îÄ‚îÄ Eigen\n‚îú‚îÄ‚îÄ FileProcess.h\n‚îú‚îÄ‚îÄ ModelTrans.h\n‚îú‚îÄ‚îÄ Net.h\n‚îú‚îÄ‚îÄ Process.h\n‚îú‚îÄ‚îÄ SaveLoad.h\n‚îî‚îÄ‚îÄ unsupported\n```\n**Config.h**: Áî®‰∫éÁ∫¶ÂÆöÁΩëÁªúÂèÇÊï∞Âíå‰∏Ä‰∫õÂÖ®Â±ÄÂèòÈáèÔºå‰æø‰∫éÈ°πÁõÆ‰ª£Á†ÅÁªÑÁªá\n\n**Eigen**: EigenÂ∫ì‰ª£Á†Å\n\n**unsupported**: EigenÂ∫ì‰ª£Á†Å,Âéü‰∏∫‰ΩøÁî®TensorÁ±ªË°®Á§∫È´òÁª¥Áü©ÈòµÔºå‰ΩÜTensor‰ΩøÁî®‰∏ç‰æøÔºåÂÆûÈôÖÊú™‰ΩøÁî®\n\n**FileProcess**: Áî®‰∫éÁ≥ªÁªüÊñá‰ª∂Êìç‰ΩúÔºå‰∏ªË¶ÅÊòØÊü•ËØ¢Êñá‰ª∂Â§π‰∏ãÁöÑÊâÄÊúâÊñá‰ª∂Âπ∂ÈÅçÂéÜ\n\n**ModelTrans**: Áî®‰∫é‰ªéÂõæÂÉèÁöÑÊï∞ÊçÆÁü©Èòµ‰∏≠ËØªÂèñBGRÂõæÂÉèÂπ∂Â∞ÜÂÖ∂ÂàÜÂâ≤„ÄÅ‰øùÂ≠ò\n\n**Net.h**: Á•ûÁªèÁΩëÁªúÁöÑÂÆö‰πâ„ÄÅËÆ≠ÁªÉÂèä‰ΩøÁî®ÈÉ®ÂàÜ\n\n**SaveLoad**: Áî®‰∫é‰ªéÂõæÂÉèË∑ØÂæÑËØªÂèñbmpÂõæÂÉèÂπ∂ÂàÜÈÄöÈÅì‰øùÂ≠òÂõæÂÉèÊï∞ÊçÆÈÉ®ÂàÜ\n\n## 3. ÂÆûÈôÖÊïàÊûú\nÊï∞ÊçÆÈõÜÊØîËæÉÁÆÄÂçïÔºåËÉΩÂÅöÂà∞100%„ÄÇ\n\n\n\n\n",
      "stars": 1,
      "updated_at": "2024-05-17T18:19:28Z",
      "url": "https://github.com/luojunhui1/ImageOnC"
    },
    "luoshui-coder--image-generator-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generates images based on prompts using OpenAI's DALL-E model, saving them in a specified directory on the user's desktop.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/luoshui-coder.webp",
      "keywords": [
        "mcp",
        "generates",
        "images",
        "generates images",
        "image generator",
        "video generation"
      ],
      "language": "",
      "license": "No License",
      "name": "image-generator-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "luoshui-coder",
      "readme_content": "# image-generator MCP Server\n\nAn mcp server that generates images based on image prompts\n\nThis is a TypeScript-based MCP server that implements image generation using **OPENAI**'s `dall-e-3` image generation model.\n\n## Features\n\n### Tools\n- `generate_image` - Generate an image for given prompt\n  - Takes `prompt` as a required parameter\n  - Takes `imageName` as a required parameter to save the generated image in a `generated-images` directory on your desktop\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"command\": \"image-generator\",\n      \"env\": {\n        \"OPENAI_API_KEY\": \"\u003cyour-openai-api-key\u003e\"\n    }\n  }\n}\n```\nMake sure to replace `\u003cyour-openai-api-key\u003e` with your actual **OPENAI** Api Key.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "stars": 1,
      "updated_at": "2025-03-14T04:57:37Z",
      "url": "https://github.com/luoshui-coder/image-generator-mcp-server"
    },
    "m-mcp--flux-schnell-server": {
      "category": "image-and-video-generation",
      "description": "Provides an MCP protocol-based API for generating images from text prompts with customizable dimensions and reproducible results using a specified random seed. Supports asynchronous streaming responses and integration with Hugging Face model services.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/m-mcp.webp",
      "keywords": [
        "mcp",
        "images",
        "image",
        "generating images",
        "provides mcp",
        "video generation"
      ],
      "language": "Python",
      "license": "No License",
      "name": "flux-schnell-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "m-mcp",
      "readme_content": "# Flux Schnell Server\n\n[![smithery badge](https://smithery.ai/badge/@m-mcp/flux-schnell-server)](https://smithery.ai/server/@m-mcp/flux-schnell-server)\n\nÂü∫‰∫é[Flux Schnell](https://huggingface.co/spaces/black-forest-labs/flux-1-schnell)Ê®°ÂûãÁöÑMCPÂõæÂÉèÁîüÊàêÊúçÂä°Âô®„ÄÇ\n\n## ÂäüËÉΩÁâπÁÇπ\n\n- Êèê‰æõÂü∫‰∫éMCPÂçèËÆÆÁöÑÂõæÂÉèÁîüÊàêAPI\n- ÊîØÊåÅËá™ÂÆö‰πâÂõæÁâáÂ∞∫ÂØ∏ÔºàÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶Ôºâ\n- ÊîØÊåÅËÆæÁΩÆÈöèÊú∫ÁßçÂ≠ê‰ª•Â§çÁé∞ÁâπÂÆöÁîüÊàêÁªìÊûú\n- ÊîØÊåÅÂºÇÊ≠•ÊµÅÂºèÂìçÂ∫î\n- Êèê‰æõHTTPÊé•Âè£Ë∞ÉÁî®Hugging FaceÁöÑÊ®°ÂûãÊúçÂä°\n\n## ÂÆâË£ÖË¶ÅÊ±Ç\n\n- Python \u003e= 3.10\n- ‰æùËµñÂåÖÔºö\n  - httpx \u003e= 0.28.1\n  - mcp[cli] \u003e= 1.3.0\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n### ÂºÄÂèëÁéØÂ¢ÉËÆæÁΩÆ\n\n1. ÂàõÂª∫Âπ∂ÊøÄÊ¥ª Python ËôöÊãüÁéØÂ¢É\n```bash\nuv venv \u0026\u0026 source .venv/bin/activate  # Unix/macOS\n# Êàñ\n.venv\\Scripts\\activate  # Windows\n```\n\n2. ÂÆâË£ÖÂºÄÂèë‰æùËµñ\n```bash\nuv sync  # ‰ª•ÂèØÁºñËæëÊ®°ÂºèÂÆâË£ÖÈ°πÁõÆ\n```\n\n### Ë∞ÉËØïÊñπÊ≥ï\n\n1. ÂêØÁî®Ë∞ÉËØï\n```bash\nmcp dev main.py\nÊàñËÄÖ\nnpx -y @modelcontextprotocol/inspector uv run main.py\n```\n\n2. Ë∞ÉÁî®ÂõæÂÉèÁîüÊàêÂ∑•ÂÖ∑Ôºö\n```python\n# Á§∫‰æã‰ª£Á†Å\nasync def test_main():\n    img_url = await image_generation(\n        prompt=\"your prompt here\",\n        image_width=512,  # ÂèØÈÄâÔºåÈªòËÆ§512\n        image_height=512, # ÂèØÈÄâÔºåÈªòËÆ§512\n        seed=3           # ÂèØÈÄâÔºåÈªòËÆ§3\n    )\n    print(img_url)\n```\n\n## APIÂèÇÊï∞ËØ¥Êòé\n\n- `prompt` (str): ÂõæÂÉèÁîüÊàêÊèêÁ§∫ËØç\n- `image_width` (int, optional): ÁîüÊàêÂõæÁâáÂÆΩÂ∫¶ÔºåÈªòËÆ§512\n- `image_height` (int, optional): ÁîüÊàêÂõæÁâáÈ´òÂ∫¶ÔºåÈªòËÆ§512\n- `seed` (int, optional): ÈöèÊú∫ÁßçÂ≠êÔºåÈªòËÆ§3\n\n## Á§∫‰æã\n\n### Êò•Â§©ÁöÑÁîüÊú∫\n\n![Êò•Â§©ÁöÑÁîüÊú∫](https://black-forest-labs-flux-1-schnell.hf.space/file=/tmp/gradio/45d6489d73142fa77851d8985bb1010572433d6a/image.webp)\n\n\u003e Êò•Â§©Êù•‰∫ÜÔºåÂ§ßÂú∞ËãèÈÜíÔºå‰∏áÁâ©Â§çËãè„ÄÇËä±ÂÑøÁ´ûÁõ∏ÂºÄÊîæÔºåÂ´©ÁªøÁöÑÂè∂Â≠êÂú®ÂæÆÈ£é‰∏≠ËΩªËΩªÊëáÊõ≥„ÄÇÁ©∫Ê∞î‰∏≠Âº•Êº´ÁùÄÊ≥•ÂúüÁöÑËä¨Ëä≥ÂíåËä±ÂÑøÁöÑÈ¶ôÊ∞î„ÄÇÂ∞èÈ∏üÂú®ÊûùÂ§¥Ê¨¢Âø´Âú∞Ê≠åÂî±ÔºåËù¥Ëù∂Âú®Ëä±‰∏õ‰∏≠Áø©Áø©Ëµ∑Ëàû„ÄÇÈò≥ÂÖâÊ¥íÂú®Â§ßÂú∞‰∏äÔºåÊ∏©ÊöñËÄåÊòé‰∫Æ„ÄÇÊò•Â§©ÁöÑÁîüÊú∫ÂãÉÂãÉÔºåËÆ©‰∫∫ÂøÉÊó∑Á•ûÊÄ°„ÄÇ\n\nËøô‰∏™Á§∫‰æãÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ÊúçÂä°ÁîüÊàêÁöÑÂõæÁâáÊïàÊûú„ÄÇÊÇ®ÂèØ‰ª•Âú®demoÁõÆÂΩï‰∏≠ÊâæÂà∞ÂÆåÊï¥ÁöÑÁΩëÈ°µÂ±ïÁ§∫‰ª£Á†Å„ÄÇ\n\nÁîüÊàêÁöÑÂõæÁâáURLÂèØ‰ª•Áõ¥Êé•Áî®‰∫éÔºö\n1. ÁΩëÈ°µÂõæÁâáÂ±ïÁ§∫\n2. Á§æ‰∫§Â™í‰ΩìÂàÜ‰∫´\n3. Â∫îÁî®Á®ãÂ∫èÁïåÈù¢\n",
      "stars": 1,
      "updated_at": "2025-05-29T09:05:08Z",
      "url": "https://github.com/m-mcp/flux-schnell-server"
    },
    "madhusudan-kulkarni--mcp-fal-ai-image": {
      "category": "image-and-video-generation",
      "description": "Generate images from text prompts using various fal.ai models through the Model Context Protocol (MCP), enabling seamless integration with AI IDEs. Save generated images locally with customizable output paths and robust error handling.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/madhusudan-kulkarni.webp",
      "keywords": [
        "images",
        "image",
        "ai",
        "image generate",
        "generate images",
        "generated images"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp-fal-ai-image",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "madhusudan-kulkarni",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/madhusudan-kulkarni-mcp-fal-ai-image-badge.png)](https://mseep.ai/app/madhusudan-kulkarni-mcp-fal-ai-image)\n\n[![npm version](https://img.shields.io/npm/v/mcp-fal-ai-image.svg)](https://www.npmjs.com/package/mcp-fal-ai-image) [![Node.js Version](https://img.shields.io/node/v/mcp-fal-ai-image)](https://nodejs.org/) [![TypeScript](https://img.shields.io/badge/TypeScript-5.8-blue.svg)](https://www.typescriptlang.org/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n# MCP fal.ai Image Server\n\nEffortlessly generate images from text prompts using [fal.ai](https://fal.ai) and the Model Context Protocol (MCP). Integrates directly with AI IDEs like Cursor and Windsurf.\n\n## When and Why to Use\n\nThis tool is designed for:\n- Developers and designers who want to generate images from text prompts without leaving their IDE.\n- Rapid prototyping of UI concepts, marketing assets, or creative ideas.\n- Content creators needing unique visuals for blogs, presentations, or social media.\n- AI researchers and tinkerers experimenting with the latest fal.ai models.\n- Automating workflows that require programmatic image generation via MCP.\n\nKey features:\n- Supports any valid fal.ai model and all major image parameters.\n- Works out of the box with Node.js and a fal.ai API key.\n- Saves images locally with accessible file paths.\n- Simple configuration and robust error handling.\n\n## Quick Start\n\n1. **Requirements:** Node.js 18+, [fal.ai API key](https://fal.ai)\n2. **Configure MCP:**\n   ```json\n   {\n     \"mcpServers\": {\n       \"fal-ai-image\": {\n         \"command\": \"npx\",\n         \"args\": [\"-y\", \"mcp-fal-ai-image\"],\n         \"env\": { \"FAL_KEY\": \"YOUR-FAL-AI-API-KEY\" }\n       }\n     }\n   }\n   ```\n3. **Run:** Use the `generate-image` tool from your IDE.\n\n\u003e **üí° Typical Workflow:**\n\u003e Describe the image you want (e.g., ‚Äúgenerate a landscape with flying cars using model fal-ai/kolors, 2 images, landscape_16_9‚Äù) and get instant results in your IDE.\n\n### üó®Ô∏è Example Prompts\n\n- `generate an image of a red apple`\n- `generate an image of a red apple using model fal-ai/kolors`\n- `generate 3 images of a glowing red apple in a futuristic city using model fal-ai/recraft-v3, square_hd, 40 inference steps, guidance scale 4.0, safety checker on`\n\n**Supported parameters:** prompt, model ID (any fal.ai model), number of images, image size, inference steps, guidance scale, safety checker.\n\nImages are saved locally; file paths are shown in the response. For model IDs, see [fal.ai/models](https://fal.ai/models).\n\n## Troubleshooting\n\n- `FAL_KEY environment variable is not set`: Set your fal.ai API key as above.\n- `npx` not found: Install Node.js 18+ and npm.\n\n\u003cdetails\u003e\n\u003csummary\u003eAdvanced: Example MCP Request/Response\u003c/summary\u003e\n\n```json\n{\n  \"tool\": \"generate-image\",\n  \"args\": {\n    \"prompt\": \"A futuristic cityscape at sunset\",\n    \"model\": \"fal-ai/kolors\"\n  }\n}\n\n// Example response\n{\n  \"images\": [\n    { \"url\": \"file:///path/to/generated_image1.png\" },\n    { \"url\": \"file:///path/to/generated_image2.png\" }\n  ]\n}\n```\n\n\u003c/details\u003e\n\n## üìÅ Image Output Directory\n\nGenerated images are saved to your local system:\n\n- **By default:** `~/Downloads/fal_ai` (on Linux/macOS; uses XDG standard if available)\n- **Custom location:** Set the environment variable `FAL_IMAGES_OUTPUT_DIR` to your desired folder. Images will be saved in `\u003cyour-folder\u003e/fal_ai`.\n\nThe full file path for each image is included in the tool's response.\n\n## ‚ö†Ô∏è Error Handling \u0026 Troubleshooting\n\n- If you specify a model ID that is not supported by fal.ai, you will receive an error from the backend. Double-check for typos or visit [fal.ai/models](https://fal.ai/models) to confirm the model ID.\n- For the latest list of models and their capabilities, refer to the [fal.ai model catalog](https://fal.ai/models) or [API docs](https://fal.ai/docs/api).\n- For other errors, consult your MCP client logs or open an issue on GitHub.\n\n## ü§ù Contributing\n\nContributions and suggestions are welcome! Please open issues or pull requests on [GitHub](https://github.com/madhusudan-kulkarni/mcp-fal-ai-image).\n\n## üîí Security\n\n- Your API key is only used locally to authenticate with fal.ai.\n- No user data is stored or transmitted except as required by fal.ai API.\n\n## üîó Links\n\n- [NPM](https://www.npmjs.com/package/mcp-fal-ai-image)\n- [GitHub](https://github.com/madhusudan-kulkarni/mcp-fal-ai-image)\n- [fal.ai](https://fal.ai)\n\n## üõ° License\n\nMIT License ¬© 2025 Madhusudan Kulkarni\n",
      "stars": 2,
      "updated_at": "2025-07-25T04:25:20Z",
      "url": "https://github.com/madhusudan-kulkarni/mcp-fal-ai-image"
    },
    "manascb1344--together-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Generate high-quality images using the Flux.1 Schnell model by specifying customizable parameters such as width and height, while ensuring clear error handling for prompt validation and API interactions.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/manascb1344.webp",
      "keywords": [
        "mcp",
        "images",
        "flux",
        "video generation",
        "quality images",
        "manascb1344 mcp"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "together-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "manascb1344",
      "readme_content": "# Image Generation MCP Server\n\nA Model Context Protocol (MCP) server that enables seamless generation of high-quality images using the Flux.1 Schnell model via Together AI. This server provides a standardized interface to specify image generation parameters.\n\u003cdiv align=\"center\"\u003e\n  \n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/manascb1344/together-mcp-server)\n\n\u003c/div\u003e\n\n\u003cdiv align=\"center\"\u003e\n\n\u003ca href=\"https://glama.ai/mcp/servers/y6qfizhsja\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/y6qfizhsja/badge\" alt=\"Image Generation Server MCP server\" /\u003e\n\u003c/a\u003e\n\u003c/div\u003e\n\n## Features\n\n- High-quality image generation powered by the Flux.1 Schnell model\n- Support for customizable dimensions (width and height)\n- Clear error handling for prompt validation and API issues\n- Easy integration with MCP-compatible clients\n- Optional image saving to disk in PNG format\n\n## Installation\n\n```bash\nnpm install together-mcp\n```\n\nOr run directly:\n\n```bash\nnpx together-mcp@latest\n```\n\n### Configuration\n\nAdd to your MCP server configuration:\n\n\u003csummary\u003eConfiguration Example\u003c/summary\u003e\n\n```json\n{\n  \"mcpServers\": {\n    \"together-image-gen\": {\n      \"command\": \"npx\",\n      \"args\": [\"together-mcp@latest -y\"],\n      \"env\": {\n        \"TOGETHER_API_KEY\": \"\u003cAPI KEY\u003e\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nThe server provides one tool: `generate_image`\n\n### Using generate_image\n\nThis tool has only one required parameter - the prompt. All other parameters are optional and use sensible defaults if not provided.\n\n#### Parameters\n\n```typescript\n{\n  // Required\n  prompt: string;          // Text description of the image to generate\n\n  // Optional with defaults\n  model?: string;          // Default: \"black-forest-labs/FLUX.1-schnell-Free\"\n  width?: number;          // Default: 1024 (min: 128, max: 2048)\n  height?: number;         // Default: 768 (min: 128, max: 2048)\n  steps?: number;          // Default: 1 (min: 1, max: 100)\n  n?: number;             // Default: 1 (max: 4)\n  response_format?: string; // Default: \"b64_json\" (options: [\"b64_json\", \"url\"])\n  image_path?: string;     // Optional: Path to save the generated image as PNG\n}\n```\n\n#### Minimal Request Example\n\nOnly the prompt is required:\n\n```json\n{\n  \"name\": \"generate_image\",\n  \"arguments\": {\n    \"prompt\": \"A serene mountain landscape at sunset\"\n  }\n}\n```\n\n#### Full Request Example with Image Saving\n\nOverride any defaults and specify a path to save the image:\n\n```json\n{\n  \"name\": \"generate_image\",\n  \"arguments\": {\n    \"prompt\": \"A serene mountain landscape at sunset\",\n    \"width\": 1024,\n    \"height\": 768,\n    \"steps\": 20,\n    \"n\": 1,\n    \"response_format\": \"b64_json\",\n    \"model\": \"black-forest-labs/FLUX.1-schnell-Free\",\n    \"image_path\": \"/path/to/save/image.png\"\n  }\n}\n```\n\n#### Response Format\n\nThe response will be a JSON object containing:\n\n```json\n{\n  \"id\": string,        // Generation ID\n  \"model\": string,     // Model used\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"timings\": {\n        \"inference\": number  // Time taken for inference\n      },\n      \"index\": number,      // Image index\n      \"b64_json\": string    // Base64 encoded image data (if response_format is \"b64_json\")\n      // OR\n      \"url\": string        // URL to generated image (if response_format is \"url\")\n    }\n  ]\n}\n```\n\nIf image_path was provided and the save was successful, the response will include confirmation of the save location.\n\n### Default Values\n\nIf not specified in the request, these defaults are used:\n\n- model: \"black-forest-labs/FLUX.1-schnell-Free\"\n- width: 1024\n- height: 768\n- steps: 1\n- n: 1\n- response_format: \"b64_json\"\n\n### Important Notes\n\n1. Only the `prompt` parameter is required\n2. All optional parameters use defaults if not provided\n3. When provided, parameters must meet their constraints (e.g., width/height ranges)\n4. Base64 responses can be large - use URL format for larger images\n5. When saving images, ensure the specified directory exists and is writable\n\n## Prerequisites\n\n- Node.js \u003e= 16\n- Together AI API key\n  1. Sign in at [api.together.xyz](https://api.together.xyz/)\n  2. Navigate to [API Keys settings](https://api.together.xyz/settings/api-keys)\n  3. Click \"Create\" to generate a new API key\n  4. Copy the generated key for use in your MCP configuration\n\n## Dependencies\n\n```json\n{\n  \"@modelcontextprotocol/sdk\": \"0.6.0\",\n  \"axios\": \"^1.6.7\"\n}\n```\n\n## Development\n\nClone and build the project:\n\n```bash\ngit clone https://github.com/manascb1344/together-mcp-server\ncd together-mcp-server\nnpm install\nnpm run build\n```\n\n### Available Scripts\n\n- `npm run build` - Build the TypeScript project\n- `npm run watch` - Watch for changes and rebuild\n- `npm run inspector` - Run MCP inspector\n\n## Contributing\n\nContributions are welcome! Please follow these steps:\n\n1. Fork the repository\n2. Create a new branch (`feature/my-new-feature`)\n3. Commit your changes\n4. Push the branch to your fork\n5. Open a Pull Request\n\nFeature requests and bug reports can be submitted via GitHub Issues. Please check existing issues before creating a new one.\n\nFor significant changes, please open an issue first to discuss your proposed changes.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.",
      "stars": 9,
      "updated_at": "2025-07-30T19:28:08Z",
      "url": "https://github.com/manascb1344/together-mcp-server"
    },
    "maoxiaoke--mcp-media-processor": {
      "category": "image-and-video-generation",
      "description": "A Node.js server for executing various media processing tasks, including video and image manipulation. It supports operations like video conversion, image effects, and media compression.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/maoxiaoke.webp",
      "keywords": [
        "processor",
        "node",
        "mcp",
        "media processor",
        "media processing",
        "mcp media"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "mcp-media-processor",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "maoxiaoke",
      "readme_content": "# MCP Media Processing Server\n\n[![smithery badge](https://smithery.ai/badge/@maoxiaoke/mcp-media-processor)](https://smithery.ai/server/@maoxiaoke/mcp-media-processor)\n\nA Node.js server implementing Model Context Protocol (MCP) for media processing operations, providing powerful video and image manipulation capabilities.\n\n## Features\n\n* Video processing and conversion\n* Image processing and manipulation\n* Media compression\n* Video trimming and editing\n* Image effects and watermarking\n\n## Prerequisites\n\nBefore using this server, make sure you have the following dependencies installed on your system:\n\n* **FFmpeg**: Required for video processing operations\n  * macOS: `brew install ffmpeg`\n  * Ubuntu/Debian: `sudo apt-get install ffmpeg`\n  * Windows: Download from [FFmpeg official website](https://ffmpeg.org/download.html)\n\n* **ImageMagick**: Required for image processing operations\n  * macOS: `brew install imagemagick`\n  * Ubuntu/Debian: `sudo apt-get install imagemagick`\n  * Windows: Download from [ImageMagick official website](https://imagemagick.org/script/download.php)\n\n## How to use\n\nAdd this to your `claude_desktop_config.json`:\n\n### NPX\n\n```json\n{\n  \"mcpServers\": {\n    \"mediaProcessor\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-media-processor@latest\"\n      ]\n    }\n  }\n}\n```\n\n## API\n\n### Tools\n\n#### Video Operations\n\n* **execute-ffmpeg**\n  * Execute any FFmpeg command with custom options\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `options` (string[]): Array of FFmpeg command options\n    * `outputPath` (string, optional): Absolute path for output file\n    * `outputFilename` (string, optional): Output filename\n\n* **convert-video**\n  * Convert video to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `outputFormat` (string): Desired output format (e.g., mp4, mkv, avi)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **compress-video**\n  * Compress video file\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `quality` (number, optional): Compression quality (1-51, lower is better quality)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **trim-video**\n  * Trim video to specified duration\n  * Inputs:\n    * `inputPath` (string): Absolute path to input video file\n    * `startTime` (string): Start time in format HH:MM:SS\n    * `duration` (string): Duration in format HH:MM:SS\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n#### Image Operations\n\n* **compress-image**\n  * Compress PNG image using ImageMagick\n  * Inputs:\n    * `inputPath` (string): Absolute path to input PNG image\n    * `quality` (number, optional): Compression quality (1-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **convert-image**\n  * Convert image to different format\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `outputFormat` (string): Desired output format (e.g., jpg, png, webp, gif)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **resize-image**\n  * Resize image to specified dimensions\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `width` (number, optional): Target width in pixels\n    * `height` (number, optional): Target height in pixels\n    * `maintainAspectRatio` (boolean, optional): Whether to maintain aspect ratio\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **rotate-image**\n  * Rotate image by specified degrees\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `degrees` (number): Rotation angle in degrees\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **add-watermark**\n  * Add watermark to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `watermarkPath` (string): Absolute path to watermark image file\n    * `position` (string, optional): Position of watermark (default: \"southeast\")\n    * `opacity` (number, optional): Watermark opacity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n* **apply-effect**\n  * Apply visual effect to image\n  * Inputs:\n    * `inputPath` (string): Absolute path to input image file\n    * `effect` (string): Effect to apply (blur, sharpen, edge, emboss, grayscale, sepia, negate)\n    * `intensity` (number, optional): Effect intensity (0-100)\n    * `outputPath` (string, optional): Custom output path\n    * `outputFilename` (string, optional): Custom output filename\n\n\n## License\n\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\n",
      "stars": 24,
      "updated_at": "2025-09-16T09:41:08Z",
      "url": "https://github.com/maoxiaoke/mcp-media-processor"
    },
    "mario-andreschak--mcp-image-recognition": {
      "category": "image-and-video-generation",
      "description": "Leverages image recognition capabilities to analyze and describe images using advanced vision APIs. Supports multiple formats and allows for optional text extraction from images.",
      "forks": 8,
      "imageUrl": "/freedevtools/mcp/pfp/mario-andreschak.webp",
      "keywords": [
        "recognition",
        "images",
        "vision",
        "extraction images",
        "image recognition",
        "analyze images"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp-image-recognition",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "mario-andreschak",
      "readme_content": "# MCP Image Recognition Server\n\nAn MCP server that provides image recognition capabilities using Anthropic and OpenAI vision APIs. Version 0.1.2.\n\n## Features\n\n- Image description using Anthropic Claude Vision or OpenAI GPT-4 Vision\n- Support for multiple image formats (JPEG, PNG, GIF, WebP)\n- Configurable primary and fallback providers\n- Base64 and file-based image input support\n- Optional text extraction using Tesseract OCR\n\n## Requirements\n\n- Python 3.8 or higher\n- Tesseract OCR (optional) - Required for text extraction feature\n  - Windows: Download and install from [UB-Mannheim/tesseract](https://github.com/UB-Mannheim/tesseract/wiki)\n  - Linux: `sudo apt-get install tesseract-ocr`\n  - macOS: `brew install tesseract`\n\n## Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/mario-andreschak/mcp-image-recognition.git\ncd mcp-image-recognition\n```\n\n2. Create and configure your environment file:\n```bash\ncp .env.example .env\n# Edit .env with your API keys and preferences\n```\n\n3. Build the project:\n```bash\nbuild.bat\n```\n\n## Usage\n\n### Running the Server\nSpawn the server using python:\n```bash\npython -m image_recognition_server.server\n```\n\nStart the server using batch instead:\n```bash\nrun.bat server\n```\n\nStart the server in development mode with the MCP Inspector:\n```bash\nrun.bat debug\n```\n\n### Available Tools\n\n1. `describe_image`\n   - Input: Base64-encoded image data and MIME type\n   - Output: Detailed description of the image\n\n2. `describe_image_from_file`\n   - Input: Path to an image file\n   - Output: Detailed description of the image\n\n### Environment Configuration\n\n- `ANTHROPIC_API_KEY`: Your Anthropic API key.\n- `OPENAI_API_KEY`: Your OpenAI API key.\n- `VISION_PROVIDER`: Primary vision provider (`anthropic` or `openai`).\n- `FALLBACK_PROVIDER`: Optional fallback provider.\n- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR).\n- `ENABLE_OCR`: Enable Tesseract OCR text extraction (`true` or `false`).\n- `TESSERACT_CMD`: Optional custom path to Tesseract executable.\n- `OPENAI_MODEL`: OpenAI Model (default: `gpt-4o-mini`). Can use OpenRouter format for other models (e.g., `anthropic/claude-3.5-sonnet:beta`).\n- `OPENAI_BASE_URL`: Optional custom base URL for the OpenAI API.  Set to `https://openrouter.ai/api/v1` for OpenRouter.\n- `OPENAI_TIMEOUT`: Optional custom timeout (in seconds) for the OpenAI API.\n\n### Using OpenRouter\n\nOpenRouter allows you to access various models using the OpenAI API format. To use OpenRouter, follow these steps:\n\n1.  Obtain an OpenAI API key from OpenRouter.\n2.  Set `OPENAI_API_KEY` in your `.env` file to your OpenRouter API key.\n3.  Set `OPENAI_BASE_URL` to `https://openrouter.ai/api/v1`.\n4.  Set `OPENAI_MODEL` to the desired model using the OpenRouter format (e.g., `anthropic/claude-3.5-sonnet:beta`).\n5. Set `VISION_PROVIDER` to `openai`.\n\n### Default Models\n\n- Anthropic: `claude-3.5-sonnet-beta`\n- OpenAI: `gpt-4o-mini`\n- OpenRouter: Use the `anthropic/claude-3.5-sonnet:beta` format in `OPENAI_MODEL`.\n\n## Development\n\n### Running Tests\n\nRun all tests:\n```bash\nrun.bat test\n```\n\nRun specific test suite:\n```bash\nrun.bat test server\nrun.bat test anthropic\nrun.bat test openai\n```\n\n### Docker Support\n\nBuild the Docker image:\n```bash\ndocker build -t mcp-image-recognition .\n```\n\nRun the container:\n```bash\ndocker run -it --env-file .env mcp-image-recognition\n```\n\n## License\n\nMIT License - see LICENSE file for details.\n\n## Release History\n\n- **0.1.2** (2025-02-20): Improved OCR error handling and added comprehensive test coverage for OCR functionality\n- **0.1.1** (2025-02-19): Added Tesseract OCR support for text extraction from images (optional feature)\n- **0.1.0** (2025-02-19): Initial release with Anthropic and OpenAI vision support\n",
      "stars": 26,
      "updated_at": "2025-10-03T22:32:16Z",
      "url": "https://github.com/mario-andreschak/mcp-image-recognition"
    },
    "mario-andreschak--mcp-veo2": {
      "category": "image-and-video-generation",
      "description": "Generates high-quality videos from text prompts or images using Google's Veo2 model and provides access to these generated videos through MCP resources.",
      "forks": 17,
      "imageUrl": "/freedevtools/mcp/pfp/mario-andreschak.webp",
      "keywords": [
        "veo2",
        "videos",
        "mcp",
        "mcp veo2",
        "google veo2",
        "generated videos"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "mcp-veo2",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "mario-andreschak",
      "readme_content": "# MCP Video Generation with Veo2\n\n[![smithery badge](https://smithery.ai/badge/@mario-andreschak/mcp-video-generation-veo2)](https://smithery.ai/server/@mario-andreschak/mcp-video-generation-veo2)\n\nThis project implements a Model Context Protocol (MCP) server that exposes Google's Veo2 video generation capabilities. It allows clients to generate videos from text prompts or images, and access the generated videos through MCP resources.\n\n\u003ca href=\"https://glama.ai/mcp/servers/@mario-andreschak/mcp-veo2\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@mario-andreschak/mcp-veo2/badge\" alt=\"Video Generation with Veo2 MCP server\" /\u003e\n\u003c/a\u003e\n\n## Features\n\n- Generate **videos from text** prompts\n- Generate **videos from images**\n- Access generated videos through MCP resources\n- Example video generation templates\n- Support for both stdio and SSE transports\n\n## Example Images\n![1dec9c71-07dc-4a6e-9e17-8da355d72ba1](https://github.com/user-attachments/assets/ba987d14-dd46-49ac-9b31-1ce398e86c6f)\n\n\n## Example Image to Video\n[Image to Video - from Grok generated puppy](https://github.com/mario-andreschak/mcp-veo2/raw/refs/heads/main/example-files/2a6a0807-d323-4424-a48a-e40a82b883bb.mp4)\n\n[Image to Video - from real cat](https://github.com/mario-andreschak/mcp-veo2/raw/refs/heads/main/example-files/55b9f28b-61a6-423e-bb86-f3791c639177.mp4)\n\n\n## Prerequisites\n\n- Node.js 18 or higher\n- Google API key with access to Gemini API and Veo2 model (= You need to set up a credit card with your API key! -\u003e Go to aistudio.google.com )\n\n## Installation\n\n### Installing in [FLUJO](https://github.com/mario-andreschak/FLUJO/)\n1. Click Add Server\n2. Copy \u0026 Paste Github URL into FLUJO\n3. Click Parse, Clone, Install, Build and Save.\n\n### Installing via Smithery\n\nTo install mcp-video-generation-veo2 for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@mario-andreschak/mcp-veo2):\n\n```bash\nnpx -y @smithery/cli install @mario-andreschak/mcp-veo2 --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/yourusername/mcp-video-generation-veo2.git\n   cd mcp-video-generation-veo2\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Create a `.env` file with your Google API key:\n   ```bash\n   cp .env.example .env\n   # Edit .env and add your Google API key\n   ```\n\n   The `.env` file supports the following variables:\n   - `GOOGLE_API_KEY`: Your Google API key (required)\n   - `PORT`: Server port (default: 3000)\n   - `STORAGE_DIR`: Directory for storing generated videos (default: ./generated-videos)\n   - `LOG_LEVEL`: Logging level (default: fatal)\n     - Available levels: verbose, debug, info, warn, error, fatal, none\n     - For development, set to `debug` or `info` for more detailed logs\n     - For production, keep as `fatal` to minimize console output\n\n4. Build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\n### Starting the Server\n\nYou can start the server with either stdio or SSE transport:\n\n#### stdio Transport (Default)\n\n```bash\nnpm start\n# or\nnpm start stdio\n```\n\n#### SSE Transport\n\n```bash\nnpm start sse\n```\n\nThis will start the server on port 3000 (or the port specified in your `.env` file).\n\n### MCP Tools\n\nThe server exposes the following MCP tools:\n\n#### generateVideoFromText\n\nGenerates a video from a text prompt.\n\nParameters:\n- `prompt` (string): The text prompt for video generation\n- `config` (object, optional): Configuration options\n  - `aspectRatio` (string, optional): \"16:9\" or \"9:16\"\n  - `personGeneration` (string, optional): \"dont_allow\" or \"allow_adult\"\n  - `numberOfVideos` (number, optional): 1 or 2\n  - `durationSeconds` (number, optional): Between 5 and 8\n  - `enhancePrompt` (boolean, optional): Whether to enhance the prompt\n  - `negativePrompt` (string, optional): Text describing what not to generate\n\nExample:\n```json\n{\n  \"prompt\": \"Panning wide shot of a serene forest with sunlight filtering through the trees, cinematic quality\",\n  \"config\": {\n    \"aspectRatio\": \"16:9\",\n    \"personGeneration\": \"dont_allow\",\n    \"durationSeconds\": 8\n  }\n}\n```\n\n#### generateVideoFromImage\n\nGenerates a video from an image.\n\nParameters:\n- `image` (string): Base64-encoded image data\n- `prompt` (string, optional): Text prompt to guide the video generation\n- `config` (object, optional): Configuration options (same as above, but personGeneration only supports \"dont_allow\")\n\n#### listGeneratedVideos\n\nLists all generated videos.\n\n### MCP Resources\n\nThe server exposes the following MCP resources:\n\n#### videos://{id}\n\nAccess a generated video by its ID.\n\n#### videos://templates\n\nAccess example video generation templates.\n\n## Development\n\n### Project Structure\n\n- `src/`: Source code\n  - `index.ts`: Main entry point\n  - `server.ts`: MCP server configuration\n  - `config.ts`: Configuration handling\n  - `tools/`: MCP tool implementations\n  - `resources/`: MCP resource implementations\n  - `services/`: External service integrations\n  - `utils/`: Utility functions\n\n### Building\n\n```bash\nnpm run build\n```\n\n### Development Mode\n\n```bash\nnpm run dev\n```\n\n## License\n\nMIT",
      "stars": 30,
      "updated_at": "2025-10-03T22:32:31Z",
      "url": "https://github.com/mario-andreschak/mcp-veo2"
    },
    "mikeyny--ai-image-gen-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate images from text prompts using Replicate's flux-schnell model, with configurable image parameters and the ability to save generated images to a specified directory.",
      "forks": 15,
      "imageUrl": "/freedevtools/mcp/pfp/mikeyny.webp",
      "keywords": [
        "generate",
        "images",
        "mcp",
        "generate images",
        "generated images",
        "image gen"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "ai-image-gen-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "mikeyny",
      "readme_content": "# Image Generation MCP Server\n\nAn [MCP (Model Context Protocol)](https://modelcontextprotocol.io/) server implementation for generating images using Replicate's [`black-forest-labs/flux-schnell`](https://replicate.com/black-forest-labs/flux-schnell) model.\n\nIdeally to be used with Cursor's MCP feature, but can be used with any MCP client.\n\n## Features\n\n- Generate images from text prompts\n- Configurable image parameters (resolution, aspect ratio, quality)\n- Save generated images to specified directory\n- Full MCP protocol compliance\n- Error handling and validation\n\n## Prerequisites\n\n- Node.js 16+\n- Replicate API token\n- TypeScript SDK for MCP\n\n## Setup\n\n1. Clone the repository\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n3. Add your Replicate API token directly in the code at `src/imageService.ts` by updating the `apiToken` constant:\n   ```bash\n   // No environment variables are used since they can't be easily set in cursor\n   const apiToken = \"your-replicate-api-token-here\";\n   ```\n\n   \u003e **Note:** If using with Claude, you can create a `.env` file in the root directory and set your API token there:\n   ```bash\n   REPLICATE_API_TOKEN=your-replicate-api-token-here\n   ```\n\n   Then build the project:\n   ```bash\n   npm run build\n   ```\n\n## Usage\n\nTo use with cursor:\n1. Go to Settings\n2. Select Features\n3. Scroll down to \"MCP Servers\"\n4. Click \"Add new MCP Server\"\n5. Set Type to \"Command\"\n6. Set Command to: `node ./path/to/dist/server.js`\n\n## API Parameters\n\n| Parameter           | Type    | Required | Default | Description                                     |\n|--------------------|---------|----------|---------|------------------------------------------------|\n| `prompt`           | string  | Yes      | -       | Text prompt for image generation               |\n| `output_dir`       | string  | Yes      | -       | Server directory path to save generated images |\n| `go_fast`          | boolean | No       | false   | Enable faster generation mode                  |\n| `megapixels`       | string  | No       | \"1\"     | Resolution quality (\"1\", \"2\", \"4\")            |\n| `num_outputs`      | number  | No       | 1       | Number of images to generate (1-4)            |\n| `aspect_ratio`     | string  | No       | \"1:1\"   | Aspect ratio (\"1:1\", \"4:3\", \"16:9\")          |\n| `output_format`    | string  | No       | \"webp\"  | Image format (\"webp\", \"png\", \"jpeg\")         |\n| `output_quality`   | number  | No       | 80      | Compression quality (1-100)                   |\n| `num_inference_steps`| number| No       | 4       | Number of denoising steps (4-20)             |\n\n## Example Request\n\n```json\n{\n  \"prompt\": \"black forest gateau cake spelling out 'FLUX SCHNELL'\",\n  \"output_dir\": \"/var/output/images\",\n  \"filename\": \"black_forest_cake\",\n  \"output_format\": \"webp\"\n  \"go_fast\": true,\n  \"megapixels\": \"1\",\n  \"num_outputs\": 2,\n  \"aspect_ratio\": \"1:1\"\n}\n```\n\n## Example Response\n\n```json\n{\n  \"image_paths\": [\n    \"/var/output/images/output_0.webp\",\n    \"/var/output/images/output_1.webp\"\n  ],\n  \"metadata\": {\n    \"model\": \"black-forest-labs/flux-schnell\",\n    \"inference_time_ms\": 2847\n  }\n}\n```\n\n## Error Handling\n\nThe server handles the following error types:\n\n- Validation errors (invalid parameters)\n- API errors (Replicate API issues)\n- Server errors (filesystem, permissions)\n- Unknown errors (unexpected issues)\n\nEach error response includes:\n- Error code\n- Human-readable message\n- Detailed error information\n\n## License\n\nISC ",
      "stars": 126,
      "updated_at": "2025-09-11T02:43:44Z",
      "url": "https://github.com/mikeyny/ai-image-gen-mcp"
    },
    "murataskin--image-mcp-server-gemini": {
      "category": "image-and-video-generation",
      "description": "Analyzes images and videos by providing URLs or local file paths, allowing for detailed insights and descriptions of the content. Uses the Gemini 2.0 Flash model for high-precision recognition and can evaluate relationships between multiple visual inputs.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/murataskin.webp",
      "keywords": [
        "flash",
        "images",
        "gemini",
        "gemini flash",
        "server gemini",
        "image mcp"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "image-mcp-server-gemini",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "murataskin",
      "readme_content": "\n# image-mcp-server-gemini\n\n\n\n\n[![smithery badge](https://smithery.ai/badge/@Rentapad/image-mcp-server-gemini)](https://smithery.ai/server/@Rentapad/image-mcp-server-gemini)\nAn MCP server that receives image/video URLs or local file paths and analyzes their content using the Gemini 2.0 Flash model.(forked from github.com/champierre/image-mcp-server)\n\n## Features\n\n- Analyzes content from one or more image/video URLs or local file paths.\n- Analyzes videos directly from YouTube URLs.\n- Can analyze relationships between multiple images or videos provided together.\n- Supports optional text prompts to guide the analysis.\n- High-precision recognition and description using the Gemini 2.0 Flash model.\n- URL validity checking and local file loading with Base64 encoding.\n- Basic security checks for local file paths.\n- Handles various image and video MIME types (see Usage section for details).\n\n## Installation\n\n### Installing via Smithery\n\nTo install Image Analysis Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@Rentapad/image-mcp-server-gemini):\n\n```bash\nnpx -y @smithery/cli install @Rentapad/image-mcp-server --client claude\n```\n\n### Manual Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/Rentapad/image-mcp-server-gemini.git \ncd image-mcp-server-gemini\n\n# Install dependencies\nnpm install\n\n# Compile TypeScript\nnpm run build\n```\n\n## Configuration\n\nTo use this server, you need a Gemini API key. Set the following environment variable:\n\n```\nGEMINI_API_KEY=your_gemini_api_key\n```\n\n## MCP Server Configuration\n\nTo use with tools like Cline, add the following settings to your MCP server configuration file:\n\n### For Cline\n\nAdd the following to `cline_mcp_settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-video-analysis\": { // Consider renaming for clarity\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key\"\n      }\n    }\n  }\n}\n```\n\n### For Claude Desktop App\n\nAdd the following to `claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"image-video-analysis\": { // Consider renaming for clarity\n      \"command\": \"node\",\n      \"args\": [\"/path/to/image-mcp-server/dist/index.js\"],\n      \"env\": {\n        \"GEMINI_API_KEY\": \"your_gemini_api_key\"\n      }\n    }\n  }\n}\n```\n\n## Usage\n\nOnce the MCP server is configured, the following tools become available:\n\n- `analyze_image`: Receives one or more image URLs and analyzes their content.\n  - Arguments: `imageUrls` (array of strings, required), `prompt` (string, optional).\n- `analyze_image_from_path`: Receives one or more local image file paths and analyzes their content.\n  - Arguments: `imagePaths` (array of strings, required), `prompt` (string, optional).\n- `analyze_video`: Receives one or more video URLs and analyzes their content. Best for smaller videos (see Video Notes).\n  - Arguments: `videoUrls` (array of strings, required), `prompt` (string, optional).\n- `analyze_video_from_path`: Receives one or more local video file paths and analyzes their content. Best for smaller videos (see Video Notes).\n  - Arguments: `videoPaths` (array of strings, required), `prompt` (string, optional).\n- `analyze_youtube_video`: Receives a single YouTube video URL and analyzes its content.\n  - Arguments: `youtubeUrl` (string, required), `prompt` (string, optional).\n\n### Usage Examples\n\n**Analyzing a single image from URL:**\n```\nPlease analyze this image: https://example.com/image.jpg\n```\n\n**Analyzing multiple images from local paths and comparing them:**\n```\nAnalyze these images: /path/to/your/image1.png, /path/to/your/image2.jpeg. Which one contains a cat?\n```\n*(The client would call `analyze_image_from_path` with `imagePaths: [\"/path/to/your/image1.png\", \"/path/to/your/image2.jpeg\"]` and `prompt: \"Which one contains a cat?\"`)*\n\n**Analyzing a video from URL with a specific prompt:**\n```\nSummarize the content of this video: https://example.com/video.mp4\n```\n*(The client would call `analyze_video` with `videoUrls: [\"https://example.com/video.mp4\"]` and `prompt: \"Summarize the content of this video\"`)*\n\n**Analyzing a YouTube video:**\n```\nWhat is the main topic of this YouTube video? https://www.youtube.com/watch?v=dQw4w9WgXcQ\n```\n*(The client would call `analyze_youtube_video` with `youtubeUrl: \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"` and `prompt: \"What is the main topic of this YouTube video?\"`)*\n\n### Video Notes\n\n- **Size Limit:** For videos provided via URL (`analyze_video`) or path (`analyze_video_from_path`), Gemini currently has limitations on the size of video data that can be processed directly (typically around 20MB after Base64 encoding). Larger videos may fail. YouTube analysis does not have this same client-side download limit.\n- **Supported MIME Types:** The server attempts to map and use MIME types supported by Gemini for video. Officially supported types include: `video/mp4`, `video/mpeg`, `video/mov`, `video/avi`, `video/x-flv`, `video/mpg`, `video/webm`, `video/wmv`, `video/3gpp`. Files with other MIME types might be skipped. YouTube videos are handled separately.\n\n### Note: Specifying Local File Paths\n\nWhen using the `..._from_path` tools, the AI assistant (client) must specify **valid file paths in the environment where this server is running**.\n\n- **If the server is running on WSL:**\n  - If the AI assistant has a Windows path (e.g., `C:\\...`), it needs to convert it to a WSL path (e.g., `/mnt/c/...`) before passing it to the tool.\n  - If the AI assistant has a WSL path, it can pass it as is.\n- **If the server is running on Windows:**\n  - If the AI assistant has a WSL path (e.g., `/home/user/...`), it needs to convert it to a UNC path (e.g., `\\\\wsl$\\Distro\\...`) before passing it to the tool.\n  - If the AI assistant has a Windows path, it can pass it as is.\n\n**Path conversion is the responsibility of the AI assistant (or its execution environment).** The server will try to interpret the received path as is, applying basic security checks.\n\n### Note: Type Errors During Build\n\nWhen running `npm run build`, you may see an error (TS7016) about missing TypeScript type definitions for the `mime-types` module.\n\n```\nsrc/index.ts:16:23 - error TS7016: Could not find a declaration file for module 'mime-types'. ...\n```\n\nThis is a type checking error, and since the JavaScript compilation itself succeeds, it **does not affect the server's execution**. If you want to resolve this error, install the type definition file as a development dependency.\n\n```bash\nnpm install --save-dev @types/mime-types\n# or\nyarn add --dev @types/mime-types\n```\n\n## Development\n\n```bash\n# Run in development mode\nnpm run dev\n```\n\n## License\n\nMIT\n```\n",
      "stars": 0,
      "updated_at": "2025-04-10T03:32:38Z",
      "url": "https://github.com/murataskin/image-mcp-server-gemini"
    },
    "nansasuke--GarbageSorting": {
      "category": "image-and-video-generation",
      "description": "Identify and classify waste using image and voice recognition techniques to streamline the recycling process and enhance environmental awareness.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/nansasuke.webp",
      "keywords": [
        "recycling",
        "garbagesorting",
        "waste",
        "classify waste",
        "nansasuke garbagesorting",
        "garbagesorting identify"
      ],
      "language": "",
      "license": "No License",
      "name": "GarbageSorting",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "nansasuke",
      "readme_content": "# GarbageSorting\nÂõæÁâáËØÜÂà´„ÄÅËØ≠Èü≥ËØÜÂà´„ÄÅÂûÉÂúæÂàÜÁ±ª\n\n‰∏Ä‰∏™ÂÆåÊï¥ÁöÑÂûÉÂúæÂàÜÁ±ªÁöÑapp\n \n\n![image](https://github.com/hyyz3293/GarbageSorting/blob/master/Images/a.png) ![image](https://github.com/hyyz3293/GarbageSorting/blob/master/Images/b.png)\n",
      "stars": 0,
      "updated_at": "2025-03-11T13:08:27Z",
      "url": "https://github.com/nansasuke/GarbageSorting"
    },
    "nickbaumann98--everart-forge-mcp": {
      "category": "image-and-video-generation",
      "description": "Generates and converts vector and raster images using advanced AI models with support for multiple formats. Provides flexible storage options and automatic formatting for efficient image processing.",
      "forks": 7,
      "imageUrl": "/freedevtools/mcp/pfp/nickbaumann98.webp",
      "keywords": [
        "images",
        "raster",
        "ai",
        "video generation",
        "raster images",
        "image processing"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "everart-forge-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "nickbaumann98",
      "readme_content": "# EverArt Forge MCP for Cline\n\n\n\nAn advanced Model Context Protocol (MCP) server for [Cline](https://github.com/cline/cline) that integrates with EverArt's AI models to generate both vector and raster images. This server provides powerful image generation capabilities with flexible storage options and format conversion.\n\n## Features\n\n- **Vector Graphics Generation**\n  - Create SVG vector graphics using Recraft-Vector model\n  - Automatic SVG optimization\n  - Perfect for logos, icons, and scalable graphics\n\n- **Raster Image Generation**\n  - Support for PNG, JPEG, and WebP formats\n  - Multiple AI models for different styles\n  - High-quality image processing\n\n- **Flexible Storage**\n  - Custom output paths and filenames\n  - Automatic directory creation\n  - Format validation and extension handling\n  - Web project integration\n\n## Available Models\n\n- **5000:FLUX1.1**: Standard quality, general-purpose image generation\n- **9000:FLUX1.1-ultra**: Ultra high quality for detailed images\n- **6000:SD3.5**: Stable Diffusion 3.5 for diverse styles\n- **7000:Recraft-Real**: Photorealistic style\n- **8000:Recraft-Vector**: Vector art style (SVG output)\n\n## Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/nickbaumann98/everart-forge-mcp.git\n   cd everart-forge-mcp\n   ```\n\n2. Install dependencies:\n   ```bash\n   npm install\n   ```\n\n3. Build the project:\n   ```bash\n   npm run build\n   ```\n\n4. Get your EverArt API key:\n   - Sign up at [EverArt](https://everart.ai/) \n   - Navigate to your account settings\n   - Create or copy your API key\n\n5. Add the server to your Cline MCP settings file:\n\n   **For VS Code Extension**:  \n   Edit `~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`:\n\n   ```json\n   {\n     \"mcpServers\": {\n       \"everart-forge\": {\n         \"command\": \"node\",\n         \"args\": [\"/absolute/path/to/everart-forge-mcp/build/index.js\"],\n         \"env\": {\n           \"EVERART_API_KEY\": \"your_api_key_here\"\n         },\n         \"disabled\": false,\n         \"autoApprove\": []\n       }\n     }\n   }\n   ```\n\n   **For Claude Desktop App**:  \n   Edit `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS) or appropriate location for your OS\n\n6. Restart Cline to load the new MCP server\n\n## Usage Examples\n\nOnce configured, you can use Cline to generate images with prompts like:\n\n- \"Generate a minimalist tech logo in SVG format using the Recraft-Vector model\"\n- \"Create a photorealistic landscape image with the FLUX1.1-ultra model\"\n- \"Make me a vector icon for my project that represents artificial intelligence\"\n- \"Generate a professional company logo as an SVG file and save it to my desktop\"\n\n### Tool Capabilities\n\nThe server provides these tools:\n\n#### generate_image\n\nGenerate images with extensive customization options:\n\n```\nParameters:\n- prompt (required): Text description of desired image\n- model: Model ID (5000:FLUX1.1, 9000:FLUX1.1-ultra, 6000:SD3.5, 7000:Recraft-Real, 8000:Recraft-Vector)\n- format: Output format (svg, png, jpg, webp)\n- output_path: Custom output path for the image\n- web_project_path: Path to web project root for proper asset organization\n- project_type: Web project type (react, vue, html, next, etc.)\n- asset_path: Subdirectory within the web project assets\n- image_count: Number of images to generate (1-10)\n```\n\nNotes:\n- SVG format is only available with Recraft-Vector (8000) model\n- Default format is \"svg\" for model 8000, \"png\" for others\n- You can specify combined model IDs (e.g., \"8000:Recraft-Vector\")\n\n#### list_images\n\nList all previously generated images stored by the server.\n\n#### view_image\n\nOpen a specific image in the default image viewer:\n\n```\nParameters:\n- filename: Name of the image file to view\n```\n\n## Troubleshooting\n\n- **Error: Invalid model ID**: Make sure you're using one of the supported model IDs (5000, 6000, 7000, 8000, 9000)\n- **Format not compatible with model**: SVG format is only available with Recraft-Vector (8000) model\n- **Image not found**: Use the list_images tool to see available images\n- **API authentication failed**: Check your EverArt API key\n- **Images not appearing**: Check file permissions and paths\n\n## License\n\nMIT License - see LICENSE file for details.",
      "stars": 10,
      "updated_at": "2025-07-10T04:55:11Z",
      "url": "https://github.com/nickbaumann98/everart-forge-mcp"
    },
    "noeltg77--Replicate-Designer": {
      "category": "image-and-video-generation",
      "description": "Generate images from text descriptions using Replicate's Flux 1.1 Pro model. Designed for seamless integration in projects requiring high-quality image generation capabilities.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/noeltg77.webp",
      "keywords": [
        "replicate",
        "generate",
        "images",
        "image generation",
        "generate images",
        "video generation"
      ],
      "language": "Python",
      "license": "No License",
      "name": "Replicate-Designer",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "noeltg77",
      "readme_content": "# Replicate Designer MCP\n\nAn MCP server for generating images using Replicate's Flux 1.1 Pro model.\n\n## Installation\n\n### Using Directly from GitHub\n\nYou can use the MCP server directly from GitHub in several ways:\n\n#### Option 1: Install directly with pip\n\n```bash\npip install git+https://github.com/yourusername/replicate-designer.git\n```\n\nThen run it with:\n```bash\nmcp-replicate-designer\n```\n\n#### Option 2: Use npx with GitHub repository\n\nCreate a configuration file (e.g., `mcps.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"replicateDesigner\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\", \n        \"github:yourusername/replicate-designer\"\n      ],\n      \"env\": {\n        \"REPLICATE_API_TOKEN\": \"your_replicate_api_token_here\"\n      }\n    }\n  }\n}\n```\n\nThen use it with Claude or another assistant:\n```bash\nnpx @anthropic-ai/assistant --mcps-json mcps.json\n```\n\nThis method allows you to include your Replicate API token directly in the configuration file, which is more convenient than setting environment variables separately.\n\n#### Option 3: Local Installation\n\nClone the repository and install from the local directory:\n\n```bash\ngit clone https://github.com/yourusername/replicate-designer.git\ncd replicate-designer\npip install -e .\n```\n\n### Publishing and Using via npm\n\nTo make your MCP available via npm (for easier distribution):\n\n1. Package and publish your MCP:\n```bash\n# Build a wheel\npip install build\npython -m build\n\n# Publish to npm (after setting up an npm account)\nnpm init\nnpm publish\n```\n\n2. Then users can install and use it directly:\n```bash\nnpx -y mcp-replicate-designer\n```\n\n## Usage\n\n### Setting the API Token\n\nThere are several ways to provide your Replicate API token:\n\n1. **Environment variable** (for command line usage):\n   ```bash\n   export REPLICATE_API_TOKEN=your_api_token_here\n   ```\n\n2. **In the MCP configuration file** (as shown in Option 2 above):\n   ```json\n   {\n     \"mcpServers\": {\n       \"replicateDesigner\": {\n         \"command\": \"...\",\n         \"args\": [\"...\"],\n         \"env\": {\n           \"REPLICATE_API_TOKEN\": \"your_replicate_api_token_here\"\n         }\n       }\n     }\n   }\n   ```\n\n3. **Using a .env file** in your project directory:\n   ```\n   REPLICATE_API_TOKEN=your_api_token_here\n   ```\n   \n   Then, install the python-dotenv package:\n   ```bash\n   pip install python-dotenv\n   ```\n\n\u003e **Security Note**: Be careful with your API tokens. Never commit them to public repositories, and use environment variables or secure secret management when possible.\n\n### Running the MCP server\n\n```bash\nmcp-replicate-designer\n```\n\nBy default, it runs in stdio mode which is compatible with npx use. You can also run it in SSE mode:\n\n```bash\nmcp-replicate-designer --transport sse --port 8000\n```\n\n## Using with npx\n\nThis MCP can be used with an AI agent using npx in two ways:\n\n### Direct command line\n\n```bash\nnpx @anthropic-ai/assistant --mcp mcp-replicate-designer\n```\n\n### As a configuration object\n\nIn your configuration JSON:\n\n```json\n{\n  \"mcpServers\": {\n    \"replicateDesigner\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-replicate-designer\"\n      ]\n    }\n  }\n}\n```\n\nThen use it with:\n\n```bash\nnpx @anthropic-ai/assistant --mcps-json /path/to/your/config.json\n```\n\n## Tool\n\nThis MCP exposes a single tool:\n\n### generate_image\n\nGenerates an image using Replicate's Flux 1.1 Pro model.\n\n**Parameters:**\n\n- `prompt` (string, required): Text description of the image to generate\n- `aspect_ratio` (string, optional, default: \"1:1\"): Aspect ratio for the generated image\n- `output_format` (string, optional, default: \"webp\"): Format of the output image\n- `output_quality` (integer, optional, default: 80): Quality of the output image (1-100)\n- `safety_tolerance` (integer, optional, default: 2): Safety tolerance level (0-3)\n- `prompt_upsampling` (boolean, optional, default: true): Whether to use prompt upsampling\n\n**Example:**\n\n```json\n{\n  \"prompt\": \"A photograph of an humanoid AI agent looking sad and in disrepair, the agent is sat at a workbench getting fixed by a human male\",\n  \"aspect_ratio\": \"1:1\",\n  \"output_format\": \"webp\"\n}\n```",
      "stars": 0,
      "updated_at": "2025-03-31T20:07:00Z",
      "url": "https://github.com/noeltg77/Replicate-Designer"
    },
    "nota--gyazo-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Access and manage Gyazo images and their associated metadata, including OCR data, through a standardized protocol. Enables full-text search and retrieval of images using URIs.",
      "forks": 8,
      "imageUrl": "/freedevtools/mcp/pfp/nota.webp",
      "keywords": [
        "gyazo",
        "ocr",
        "images",
        "gyazo images",
        "ocr data",
        "gyazo mcp"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "gyazo-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "nota",
      "readme_content": "# gyazo-mcp-server\n\nA Model Context Protocol server for Gyazo image integration\n\nThis is a TypeScript-based MCP server that provides access to Gyazo images. It allows AI assistants to access and interact with Gyazo images through the Model Context Protocol, providing:\n\n- Resources representing Gyazo images with URIs and metadata\n- Tools for searching, fetching, and uploading images\n- Image content and metadata access via the Gyazo API\n\n## Features\n\n### Resources\n\n- List and access Gyazo images via `gyazo-mcp://` URIs\n- Each image includes:\n  - Original image content\n  - Metadata (title, description, app, URL)\n  - OCR data (if available)\n- Supports various image formats (JPEG, PNG, etc.)\n\n### Tools\n\n- `gyazo_search` - Full-text search for captures uploaded by users on Gyazo\n\n  - Search by keyword, title, app, URL, or date range\n  - Supports pagination for browsing multiple results\n  - Returns matching image URIs and metadata\n\n- `gyazo_image` - Fetch image content and metadata from Gyazo\n\n  - Retrieve specific images by ID or URL\n  - Returns both image content and detailed metadata\n\n- `gyazo_latest_image` - Fetch the most recent image from Gyazo\n\n  - Returns both image content and metadata\n  - Includes OCR text if available\n\n- `gyazo_upload` - Upload an image to Gyazo\n  - Upload images with base64 encoded image data\n  - Add optional metadata like title, description, referer URL, and app name\n  - Returns the uploaded image's permalink URL and ID\n\n## Installation\n\n### NPM Package\n\nThe easiest way to install the Gyazo MCP server is via npm:\n\n```bash\nnpm install -g @notainc/gyazo-mcp-server\n```\n\n### Prerequisites\n\n- Create a Gyazo account if you don't have one: https://gyazo.com\n- Get your Gyazo API access token from: https://gyazo.com/api\n  - Click \"Register applications\" button\n  - Click \"New Application\" button\n  - Fill in the form with your app name and description\n    - Name and Callback URL are required\n    - You can use `http://localhost` for the Callback URL\n  - Click \"Submit\" button\n  - Click application name to view details\n  - Scroll down to \"Your Access Token\"\n  - Click \"Generate\" button\n  - Copy \"Your access token\" value\n- Set the `GYAZO_ACCESS_TOKEN` environment variable with your token\n\n### Claude Desktop Integration\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n#### Using NPM package (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"gyazo-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"@notainc/gyazo-mcp-server\"],\n      \"env\": {\n        \"GYAZO_ACCESS_TOKEN\": \"your-access-token-here\"\n      }\n    }\n  }\n}\n```\n\n#### Using Docker (optional)\n\n```json\n{\n  \"mcpServers\": {\n    \"gyazo-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"GYAZO_ACCESS_TOKEN\",\n        \"gyazo-mcp-server\"\n      ],\n      \"env\": {\n        \"GYAZO_ACCESS_TOKEN\": \"your-access-token-here\"\n      }\n    }\n  }\n}\n```\n\n## Development\n\nInstall dependencies:\n\n```bash\nnpm ci\n```\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n### Docker Build (optional)\n\n```bash\nnpm run image:build\n```\n\n---\n\n\u003ca href=\"https://glama.ai/mcp/servers/bhrk879agk\"\u003e\n  \u003cimg alt=\"badge\" width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/bhrk879agk/badge\" /\u003e\n\u003c/a\u003e\n",
      "stars": 24,
      "updated_at": "2025-10-03T07:37:31Z",
      "url": "https://github.com/nota/gyazo-mcp-server"
    },
    "peng-shawn--mermaid-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Converts Mermaid diagram descriptions into high-quality PNG images using the Mermaid markdown syntax. Supports customizable themes and backgrounds for visual representations of data and processes.",
      "forks": 21,
      "imageUrl": "/freedevtools/mcp/pfp/peng-shawn.webp",
      "keywords": [
        "mermaid",
        "png",
        "images",
        "mermaid diagram",
        "mermaid markdown",
        "mermaid mcp"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mermaid-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "peng-shawn",
      "readme_content": "# Mermaid MCP Server\n\nA Model Context Protocol (MCP) server that converts Mermaid diagrams to PNG images or SVG files. This server allows AI assistants and other applications to generate visual diagrams from textual descriptions using the Mermaid markdown syntax.\n\n## Features\n\n- Converts Mermaid diagram code to PNG images or SVG files\n- Supports multiple diagram themes (default, forest, dark, neutral)\n- Customizable background colors\n- Uses Puppeteer for high-quality headless browser rendering\n- Implements the MCP protocol for seamless integration with AI assistants\n- Flexible output options: return images/SVG directly or save to disk\n- Error handling with detailed error messages\n\n## How It Works\n\nThe server uses Puppeteer to launch a headless browser, render the Mermaid diagram to SVG, and optionally capture a screenshot of the rendered diagram. The process involves:\n\n1. Launching a headless browser instance\n2. Creating an HTML template with the Mermaid code\n3. Loading the Mermaid.js library\n4. Rendering the diagram to SVG\n5. Either saving the SVG directly or taking a screenshot as PNG\n6. Either returning the image/SVG directly or saving it to disk\n\n## Build\n\n```bash\nnpx tsc\n```\n\n## Usage\n\n### Use with Claude desktop\n\n```json\n{\n  \"mcpServers\": {\n    \"mermaid\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@peng-shawn/mermaid-mcp-server\"]\n    }\n  }\n}\n```\n\n### Use with Cursor and Cline\n\n```bash\nenv CONTENT_IMAGE_SUPPORTED=false npx -y @peng-shawn/mermaid-mcp-server\n```\n\nYou can find a list of mermaid diagrams under `./diagrams`, they are created using Cursor agent with prompt: \"generate mermaid diagrams and save them in a separate diagrams folder explaining how renderMermaidPng work\"\n\n### Run with inspector\n\nRun the server with inspector for testing and debugging:\n\n```bash\nnpx @modelcontextprotocol/inspector node dist/index.js\n```\n\nThe server will start and listen on stdio for MCP protocol messages.\n\nLearn more about inspector [here](https://modelcontextprotocol.io/docs/tools/inspector).\n\n### Installing via Smithery\n\nTo install Mermaid Diagram Generator for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@peng-shawn/mermaid-mcp-server):\n\n```bash\nnpx -y @smithery/cli install @peng-shawn/mermaid-mcp-server --client claude\n```\n\n### Docker and Smithery Environments\n\nWhen running in Docker containers (including via Smithery), you may need to handle Chrome dependencies:\n\n1. The server now attempts to use Puppeteer's bundled browser by default\n2. If you encounter browser-related errors, you have two options:\n\n   **Option 1: During Docker image build:**\n\n   - Set `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true` when installing Puppeteer\n   - Install Chrome/Chromium in your Docker container\n   - Set `PUPPETEER_EXECUTABLE_PATH` at runtime to point to the Chrome installation\n\n   **Option 2: Use Puppeteer's bundled Chrome:**\n\n   - Ensure your Docker container has the necessary dependencies for Chrome\n   - No need to set `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD`\n   - The code will use the bundled browser automatically\n\nFor Smithery users, the latest version should work without additional configuration.\n\n## API\n\nThe server exposes a single tool:\n\n- `generate`: Converts Mermaid diagram code to a PNG image or SVG file\n  - Parameters:\n    - `code`: The Mermaid diagram code to render\n    - `theme`: (optional) Theme for the diagram. Options: \"default\", \"forest\", \"dark\", \"neutral\"\n    - `backgroundColor`: (optional) Background color for the diagram, e.g. 'white', 'transparent', '#F0F0F0'\n    - `outputFormat`: (optional) Output format for the diagram. Options: \"png\", \"svg\" (defaults to \"png\")\n    - `name`: Name for the generated file (required when CONTENT_IMAGE_SUPPORTED=false)\n    - `folder`: Absolute path to save the image/SVG to (required when CONTENT_IMAGE_SUPPORTED=false)\n\nThe behavior of the `generate` tool depends on the `CONTENT_IMAGE_SUPPORTED` environment variable:\n\n- When `CONTENT_IMAGE_SUPPORTED=true` (default): The tool returns the image/SVG directly in the response\n- When `CONTENT_IMAGE_SUPPORTED=false`: The tool saves the image/SVG to the specified folder and returns the file path\n\n## Environment Variables\n\n- `CONTENT_IMAGE_SUPPORTED`: Controls whether images are returned directly in the response or saved to disk\n  - `true` (default): Images are returned directly in the response\n  - `false`: Images are saved to disk, requiring `name` and `folder` parameters\n\n## Examples\n\n### Basic Usage\n\n```javascript\n// Generate a flowchart with default settings\n{\n  \"code\": \"flowchart TD\\n    A[Start] --\u003e B{Is it?}\\n    B --\u003e|Yes| C[OK]\\n    B --\u003e|No| D[End]\"\n}\n```\n\n### With Theme and Background Color\n\n```javascript\n// Generate a sequence diagram with forest theme and light gray background\n{\n  \"code\": \"sequenceDiagram\\n    Alice-\u003e\u003eJohn: Hello John, how are you?\\n    John--\u003e\u003eAlice: Great!\",\n  \"theme\": \"forest\",\n  \"backgroundColor\": \"#F0F0F0\"\n}\n```\n\n### Saving to Disk (when CONTENT_IMAGE_SUPPORTED=false)\n\n```javascript\n// Generate a class diagram and save it to disk as PNG\n{\n  \"code\": \"classDiagram\\n    Class01 \u003c|-- AveryLongClass\\n    Class03 *-- Class04\\n    Class05 o-- Class06\",\n  \"theme\": \"dark\",\n  \"name\": \"class_diagram\",\n  \"folder\": \"/path/to/diagrams\"\n}\n```\n\n### Generating SVG Output\n\n```javascript\n// Generate a state diagram as SVG\n{\n  \"code\": \"stateDiagram-v2\\n    [*] --\u003e Still\\n    Still --\u003e [*]\\n    Still --\u003e Moving\\n    Moving --\u003e Still\\n    Moving --\u003e Crash\\n    Crash --\u003e [*]\",\n  \"outputFormat\": \"svg\",\n  \"name\": \"state_diagram\",\n  \"folder\": \"/path/to/diagrams\"\n}\n```\n\n## FAQ\n\n### Doesn't Claude desktop already support mermaid via canvas?\n\nYes, but it doesn't support the `theme` and `backgroundColor` options. Plus, having a dedicated server makes it easier to create mermaid diagrams with different MCP clients.\n\n### Why do I need to specify CONTENT_IMAGE_SUPPORTED=false when using with Cursor?\n\nCursor doesn't support inline images in responses yet.\n\n## Publishing\n\nThis project uses GitHub Actions to automate the publishing process to npm.\n\n### Method 1: Using the Release Script (Recommended)\n\n1. Make sure all your changes are committed and pushed\n2. Run the release script with either a specific version number or a semantic version increment:\n\n   ```bash\n   # Using a specific version number\n   npm run release 0.1.4\n\n   # Using semantic version increments\n   npm run release patch  # Increments the patch version (e.g., 0.1.3 ‚Üí 0.1.4)\n   npm run release minor  # Increments the minor version (e.g., 0.1.3 ‚Üí 0.2.0)\n   npm run release major  # Increments the major version (e.g., 0.1.3 ‚Üí 1.0.0)\n   ```\n\n3. The script will:\n   - Validate the version format or semantic increment\n   - Check if you're on the main branch\n   - Detect and warn about version mismatches between files\n   - Update all version references consistently (package.json, package-lock.json, and index.ts)\n   - Create a single commit with all version changes\n   - Create and push a git tag\n   - The GitHub workflow will then automatically build and publish to npm\n\n### Method 2: Manual Process\n\n1. Update your code and commit the changes\n2. Create and push a new tag with the version number:\n   ```bash\n   git tag v0.1.4  # Use the appropriate version number\n   git push origin v0.1.4\n   ```\n3. The GitHub workflow will automatically:\n   - Build the project\n   - Publish to npm with the version from the tag\n\nNote: You need to set up the `NPM_TOKEN` secret in your GitHub repository settings. To do this:\n\n1. Generate an npm access token with publish permissions\n2. Go to your GitHub repository ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions\n3. Create a new repository secret named `NPM_TOKEN` with your npm token as the value\n\n## Badges\n\n[![smithery badge](https://smithery.ai/badge/@peng-shawn/mermaid-mcp-server)](https://smithery.ai/server/@peng-shawn/mermaid-mcp-server)\n\n\u003ca href=\"https://glama.ai/mcp/servers/lzjlbitkzr\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/lzjlbitkzr/badge\" alt=\"mermaid-mcp-server MCP server\" /\u003e\n\u003c/a\u003e\n\n## License\n\nMIT\n",
      "stars": 185,
      "updated_at": "2025-10-03T22:32:19Z",
      "url": "https://github.com/peng-shawn/mermaid-mcp-server"
    },
    "philipp-eisen--modal-mcp-toolbox": {
      "category": "image-and-video-generation",
      "description": "A collection of tools that provides a sandboxed environment for executing Python code and generating images using the FLUX model.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/philipp-eisen.webp",
      "keywords": [
        "python",
        "toolbox",
        "modal",
        "modal mcp",
        "generating images",
        "video generation"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "modal-mcp-toolbox",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "philipp-eisen",
      "readme_content": "# Modal MCP Toolbox üõ†Ô∏è\n\n[![smithery badge](https://smithery.ai/badge/@philipp-eisen/modal-mcp-toolbox)](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox)\n\nA collection of Model Context Protocol (MCP) tools that run on Modal.\nThis let's you extend the capabilities of your LLM in tools such as [Goose](https://block.github.io/goose/) or the [Claude Desktop App](https://claude.ai/download).\n\n\u003ca href=\"https://glama.ai/mcp/servers/ai78w0p5mc\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/ai78w0p5mc/badge\" alt=\"Modal Toolbox MCP server\" /\u003e\u003c/a\u003e\n\n## Tools\n\n- `run_python_code_in_sandbox`: Let's you run python code in a sandboxed environment.\n- `generate_flux_image`: Generate an image using the FLUX model.\n\n## Demo\n\n### Flux Image Generation\n\n\n\n### Python Code Execution\n\n\n\n## Prerequisites\n\n- A [modal account](https://modal.com/signup) and a configured modal CLI.\n- [UV](https://github.com/astral-sh/uv?tab=readme-ov-file#installation)\n- A client that supports MCP. Such as the [Claude Desktop App](https://claude.ai/download) or [Goose](https://block.github.io/goose/)\n\nThis runs against your modal account, so you will need to have a modal account and be logged in.\n\n## Installation\n\nInstallation depends on the client that uses the MCP. Here is instructions for Claude and Goose.\n\n### Claude\n\nGot to `Settings \u003e Developer` in the Claude Desktop App. And click on Edit Config.\n\n\nAdd the config for the mcp server. My config looks like this:\n\n```json\n{\n  \"mcpServers\": {\n    \"modal-toolbox\": {\n      \"command\": \"uvx\",\n      \"args\": [\"modal-mcp-toolbox\"]\n    }\n  }\n}\n```\n\n### Goose\n\nGo to `Settings` and Click on Add.\n\n\n\nThen add an extension like in the screenshot below.\nThe important part is to set command to:\n\n```\nuvx modal-mcp-toolbox\n```\n\nThe rest you can fill in as you like.\n\n\n\n### Installing via Smithery (not working currently)\n\nTo install Modal MCP Toolbox for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@philipp-eisen/modal-mcp-toolbox):\n\n```bash\nnpx -y @smithery/cli install @philipp-eisen/modal-mcp-toolbox --client claude\n```",
      "stars": 22,
      "updated_at": "2025-08-12T21:44:25Z",
      "url": "https://github.com/philipp-eisen/modal-mcp-toolbox"
    },
    "pinkpixel-dev--MCPollinations": {
      "category": "image-and-video-generation",
      "description": "Generates images, text, and audio from prompts using the Pollinations APIs. It supports returning images as base64-encoded data and allows listing available models for image and text generation.",
      "forks": 10,
      "imageUrl": "/freedevtools/mcp/pfp/pinkpixel-dev.webp",
      "keywords": [
        "pinkpixel",
        "images",
        "image",
        "pinkpixel dev",
        "generation pinkpixel",
        "generates images"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "MCPollinations",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "pinkpixel-dev",
      "readme_content": "# MCPollinations Multimodal MCP Server\nA Model Context Protocol (MCP) server that enables AI assistants to generate images, text, and audio through the Pollinations APIs\n\n[![smithery badge](https://smithery.ai/badge/@pinkpixel-dev/mcpollinations)](https://smithery.ai/server/@pinkpixel-dev/mcpollinations) [![Verified on MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/8448e4ec-c863-476a-8adb-aed3cf16ea2b)\n\n## Features\n\n- Generate image URLs from text prompts\n- Generate images and return them as base64-encoded data AND save as png, jpeg, jpg, or webp (default: png)\n- Generate text responses from text prompts\n- Generate audio responses from text prompts\n- List available image and text generation models\n- No authentication required\n- Simple and lightweight\n- Compatible with the Model Context Protocol (MCP)\n\n## System Requirements\n\n- **Node.js**: Version 14.0.0 or higher\n  - For best performance, we recommend Node.js 16.0.0 or higher\n  - Node.js versions below 16 use an AbortController polyfill\n\n## Quick Start\n\n### Installing via Smithery\n\nTo install mcpollinations for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@pinkpixel-dev/mcpollinations):\n\n```bash\nnpx -y @smithery/cli install @pinkpixel-dev/mcpollinations --client claude\n```\n\nThe easiest way to use the MCP server:\n\n```bash\n# Run directly with npx (no installation required)\nnpx @pinkpixel/mcpollinations\n```\n\nIf you prefer to install it globally:\n\n```bash\n# Install globally\nnpm install -g @pinkpixel/mcpollinations\n\n# Run the server\nmcpollinations\n# or\nnpx @pinkpixel/mcpollinations\n\n```\n\nOr clone the repository:\n\n```bash\n# Clone the git repository\ngit clone https://github.com/pinkpixel-dev/mcpollinations.git\n# Run the server\nmcpollinations\n# or\nnpx @pinkpixel/mcpollinations\n# or run directly\nnode /path/to/MCPollinations/pollinations-mcp-server.js\n\n```\n\n## MCP Integration\n\nTo integrate the server with applications that support the Model Context Protocol (MCP):\n\n1. Generate an MCP configuration file:\n\n```bash\n# If installed globally\nnpx @pinkpixel/mcpollinations generate-config\n\n# Or run directly\nnode /path/to/MCPollinations/generate-mcp-config.js\n```\n\n### Quick MCP Config (env)\nIf you prefer to skip the generator, copy this into your MCP client config:\n\n```json\n{\n  \"mcpollinations\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@pinkpixel/mcpollinations\"],\n    \"env\": {\n      \"token\": \"YOUR_TOKEN_OPTIONAL\",\n      \"referrer\": \"your-app-or-domain-optional\",\n      \"IMAGE_MODEL\": \"flux\",\n      \"IMAGE_WIDTH\": \"1024\",\n      \"IMAGE_HEIGHT\": \"1024\",\n      \"IMAGE_ENHANCE\": \"true\",\n      \"IMAGE_SAFE\": \"false\",\n      \"TEXT_MODEL\": \"openai\",\n      \"TEXT_TEMPERATURE\": \"0.7\",\n      \"TEXT_TOP_P\": \"0.9\",\n      \"TEXT_SYSTEM\": \"\",\n      \"AUDIO_VOICE\": \"alloy\",\n      \"OUTPUT_DIR\": \"./mcpollinations-output\"\n    }\n  }\n}\n```\n\n2. Follow the prompts to customize your configuration or use the defaults.\n   - Set an output directory (relative paths recommended for portability)\n     - **Windows users**: Consider using absolute paths (e.g., `C:\\Users\\YourName\\Pictures\\MCPollinations`) for more reliable file saving\n   - Configure optional authentication (token, referrer) under `env`\n   - Configure default parameters for image generation (with a list of available models, dimensions, etc.)\n   - Configure default parameters for text generation (with a list of available models)\n   - Configure default parameters for audio generation (voice)\n\n\n3. Copy the generated `mcp.json` file to your application's MCP settings .json file.\n4. Restart your application.\n\nAfter integration, you can use commands like:\n\n\"Generate an image of a sunset over the ocean using MCPollinations\"\n\n## Authentication (Optional)\n\nMCPollinations supports optional authentication to provide access to more models and better rate limits. The server works perfectly without authentication (free tier), but users with API tokens can get enhanced access.\n\n### Configuration Methods\n\n**Method 1: Environment Variables (Recommended for security)**\n```bash\n# Set environment variables before running the server\nexport POLLINATIONS_TOKEN=\"your-api-token\"\nexport POLLINATIONS_REFERRER=\"https://your-domain.com\"\n\n# Then run the server\nnpx @pinkpixel/mcpollinations\n```\n\n**Method 2: MCP Configuration File (env)**\nWhen generating your MCP configuration, place auth inside `env` so your MCP client passes them as environment variables to the server process:\n```json\n{\n  \"mcpollinations\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@pinkpixel/mcpollinations\"],\n    \"env\": {\n      \"token\": \"your-api-token\",\n      \"referrer\": \"your-app-or-domain\"\n    }\n  }\n}\n```\n\nYou can also provide `POLLINATIONS_TOKEN` and `POLLINATIONS_REFERRER` instead; the server recognizes both forms. Using `token` and `referrer` inside `env` is recommended for MCP configs.\n\n### Authentication Parameters\n\n- **`token`** (optional): Your Pollinations API token for enhanced access\n- **`referrer`** (optional): Your domain/application referrer URL\n\nBoth parameters are completely optional. Leave them empty or unset to use the free tier.\n\n## Using Your Configuration Settings\n\nMCPollinations respects your MCP configuration settings placed in `env` as defaults. When you ask an AI assistant to generate content:\n\n- **Your configured models, output directories, and parameters are used automatically**\n- **To override**: Specifically instruct the AI to use different settings\n  - \"Generate an image using the kontext model\"\n  - \"Save this image to my Desktop folder\"\n  - \"Use a temperature of 1.2 for this text generation\"\n\n**Example Instructions:**\n- ‚úÖ \"Generate a sunset image\" ‚Üí Uses your configured model and output directory\n- ‚úÖ \"Generate a sunset image with the flux model\" ‚Üí Overrides model only\n- ‚úÖ \"Generate a sunset image and save it to C:\\Pictures\" ‚Üí Overrides output path only\n\nThis ensures your preferences are always respected unless you specifically want different settings for a particular request.\n\n## Troubleshooting\n\n### \"AbortController is not defined\" Error\n\nIf you encounter this error when running the MCP server:\n\n```\nReferenceError: AbortController is not defined\n```\n\nThis is usually caused by running on an older version of Node.js (below version 16.0.0). Try one of these solutions:\n\n1. **Update Node.js** (recommended):\n   - Update to Node.js 16.0.0 or newer\n\n2. **Use Global Installation**\n   - Update to the latest version of the package:\n   ```bash\n   npm install -g @pinkpixel/mcpollinations\n   # Run with npx\n   npx @pinkpixel/mcpollinations\n   ```\n\n3. **Install AbortController manually**:\n   - If for some reason the polyfill doesn't work:\n   ```bash\n   npm install node-abort-controller\n   ```\n\n### Check Your Node.js Version\n\nTo check your current Node.js version:\n\n```bash\nnode --version\n```\n\nIf it shows a version lower than 16.0.0, consider upgrading for best compatibility.\n\n## Available Tools\n\nThe MCP server provides the following tools:\n\n### **Image Generation Tools**\n1. `generateImageUrl` - Generates an image URL from a text prompt\n2. `generateImage` - Generates an image, returns it as base64-encoded data, and saves it to a file by default (PNG format)\n3. `editImage` - **NEW!** Edit or modify existing images based on text prompts\n4. `generateImageFromReference` - **NEW!** Generate new images using existing images as reference\n5. `listImageModels` - Lists available models for image generation\n\n### **Text \u0026 Audio Tools**\n6. `respondText` - Responds with text to a prompt using text models (customizable parameters)\n7. `respondAudio` - Generates an audio response to a text prompt (customizable voice parameter)\n8. `listTextModels` - Lists available models for text generation\n9. `listAudioVoices` - Lists all available voices for audio generation\n\n## Text Generation Details\n\n### Available Parameters\n\nThe `respondText` tool supports several parameters for fine-tuning text generation:\n\n- **`model`**: Choose from available text models (use `listTextModels` to see current options)\n- **`temperature`** (0.0-2.0): Controls randomness in the output\n  - Lower values (0.1-0.7) = more focused and deterministic\n  - Higher values (0.8-2.0) = more creative and random\n- **`top_p`** (0.0-1.0): Controls diversity via nucleus sampling\n  - Lower values = more focused on likely tokens\n  - Higher values = considers more token possibilities\n- **`system`**: System prompt to guide the model's behavior and personality\n\n### Customizing Text Generation\n\n```javascript\n// Example options for respondText\nconst options = {\n  model: \"openai\",           // Model selection\n  temperature: 0.7,          // Balanced creativity\n  top_p: 0.9,               // High diversity\n  system: \"You are a helpful assistant that explains things clearly and concisely.\"\n};\n```\n\n### Configuration Examples\n\nIn your MCP configuration, set defaults under `env` so the server uses them automatically:\n\n```json\n{\n  \"mcpollinations\": {\n    \"env\": {\n      \"TEXT_MODEL\": \"openai\",\n      \"TEXT_TEMPERATURE\": \"0.7\",\n      \"TEXT_TOP_P\": \"0.9\",\n      \"TEXT_SYSTEM\": \"You are a helpful coding assistant.\"\n    }\n  }\n}\n```\n\n## Image-to-Image Generation (NEW!)\n\nMCPollinations now supports powerful image-to-image generation with two specialized tools:\n\n### **editImage Tool**\nPerfect for modifying existing images:\n- **Remove objects**: \"remove the cat from this image\"\n- **Add elements**: \"add a dog to this scene\"\n- **Change backgrounds**: \"replace the background with mountains\"\n- **Style modifications**: \"make the lighting more dramatic\"\n\n### **generateImageFromReference Tool**\nPerfect for creating variations and new styles:\n- **Style transfer**: \"make this photo look like a painting\"\n- **Format changes**: \"convert this to a cartoon style\"\n- **Creative variations**: \"create a futuristic version of this\"\n- **Artistic interpretations**: \"make this look like a sketch\"\n\n### **Supported Models**\n- **`kontext`**: Specialized model optimized for image-to-image tasks\n- **`nanobanana`**: New Google model supporting both text-to-image and image-to-image generation\n- **`seedream`**: New ByteDance model supporting both text-to-image and image-to-image generation\n\nMulti-reference images: `editImage` and `generateImageFromReference` accept `imageUrl` as a single URL or an array of URLs. The server encodes arrays as the comma-separated `image` parameter used by the API. Ordering matters; kontext uses only the first image, nanobanana is safe up to ~4 refs, and seedream supports up to 10.\n\nImportant: URLs only. The image-to-image tools require publicly accessible HTTP(S) URLs. Local file paths, file uploads, and base64/data URLs are not supported by this MCP server (it does not upload files). If you need to work from a local image, host it somewhere accessible (e.g., a temporary file host, object storage, or a raw link in a repo) and pass the URL.\n\n### **Example Usage**\n```javascript\n// Edit an existing image\nconst editResult = await editImage(\n  \"change the background to a sunset beach\",\n  \"https://example.com/photo.jpg\",\n  \"nanobanana\"  // or \"kontext\", \"seedream\"\n);\n\n// Generate from reference\nconst referenceResult = await generateImageFromReference(\n  \"make this into a watercolor painting\",\n  \"https://example.com/photo.jpg\",\n  \"seedream\"  // or \"kontext\", \"nanobanana\"\n);\n```\n\n## Image Generation Details\n\n### Default Behavior\n\nWhen using the `generateImage` tool:\n\n- Images are saved to disk by default as PNG files\n- The default save location is the current working directory where the MCP server is running\n- The 'flux' model is used by default\n- A random seed is generated by default for each image (ensuring variety)\n- Base64-encoded image data is always returned, regardless of whether the image is saved to a file\n\n### Customizing Image Generation\n\n```javascript\n// Example options for generateImage\nconst options = {\n  // Model selection (defaults to 'flux')\n  // Available models: \"flux\", \"turbo\", \"kontext\", \"nanobanana\", \"seedream\"\n  model: \"flux\",\n\n  // Image dimensions\n  width: 1024,\n  height: 1024,\n\n  // Generation options\n  seed: 12345,  // Specific seed for reproducibility (defaults to random)\n  enhance: true,  // Enhance the prompt using an LLM before generating (defaults to true)\n  safe: false,  // Content filtering (defaults to false)\n\n  // File saving options\n  saveToFile: true,  // Set to false to skip saving to disk\n  outputPath: \"/path/to/save/directory\",  // Custom save location\n  fileName: \"my_custom_name\",  // Without extension\n  format: \"png\"  // png, jpeg, jpg, or webp\n};\n```\n\n### Where Images Are Saved\n\nWhen using Claude or another application with the MCP server:\n\n1. **Images are saved in the current working directory of where the MCP server is running**, not where Claude or the client application is installed.\n\n2. If you start the MCP server manually from a specific directory, images will be saved there by default.\n\n3. If Claude Desktop launches the MCP server automatically, images will be saved in Claude Desktop's working directory (typically in an application data folder).\n\n**üí° Windows Users**: For reliable file saving on Windows, use absolute paths in your MCP configuration instead of relative paths (e.g., `C:\\Users\\YourName\\Pictures\\MCPollinations` instead of `./mcpollinations-output`). Relative paths may not resolve as expected depending on the working directory context.\n\n### Finding Your Generated Images\n\n- The response from Claude after generating an image includes the full file path where the image was saved\n- You can specify a familiar location using the `outputPath` parameter\n- Best practice: Ask Claude to save images to an easily accessible folder like your Pictures or Downloads directory\n\n### Unique Filenames\n\nThe MCP server ensures that generated images always have unique filenames and will never overwrite existing files:\n\n1. **Default filenames** include:\n   - A sanitized version of the prompt (first 20 characters)\n   - A timestamp\n   - A random suffix\n\n2. **Custom filenames** are also protected:\n   - If you specify a filename and a file with that name already exists, a numeric suffix will be added automatically\n   - For example: `sunset.png`, `sunset_1.png`, `sunset_2.png`, etc.\n\nThis means you can safely generate multiple images with the same prompt or filename without worrying about overwriting previous images.\n\n### Accessing Base64 Data\n\nEven when saving to a file, the base64-encoded image data is always returned and can be used for:\n\n- Embedding in web pages (`\u003cimg src=\"data:image/png;base64,...\" /\u003e`)\n- Passing to other services or APIs\n- Processing in memory without filesystem operations\n- Displaying in applications that support data URIs\n\n## For Developers\n\nIf you want to use the package in your own projects:\n\n```bash\n# Install as a dependency\nnpm install @pinkpixel/mcpollinations\n\n# Import in your code\nimport { generateImageUrl, generateImage, repsondText, respondAudio, listTextModels, listImageModels, listAudioVoices } from '@pinkpixel/mcpollinations';\n```\n",
      "stars": 34,
      "updated_at": "2025-09-26T03:37:33Z",
      "url": "https://github.com/pinkpixel-dev/MCPollinations"
    },
    "qhdrl12--mcp-server-gemini-image-generator": {
      "category": "image-and-video-generation",
      "description": "Generate high-quality images from text prompts using the Gemini AI model, manage local image storage, and facilitate creative modifications of existing images.",
      "forks": 17,
      "imageUrl": "/freedevtools/mcp/pfp/qhdrl12.webp",
      "keywords": [
        "images",
        "image",
        "qhdrl12",
        "image generator",
        "gemini image",
        "video generation"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp-server-gemini-image-generator",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "qhdrl12",
      "readme_content": "[![MseeP Badge](https://mseep.net/pr/qhdrl12-mcp-server-gemini-image-generator-badge.jpg)](https://mseep.ai/app/qhdrl12-mcp-server-gemini-image-generator)\n[![smithery badge](https://smithery.ai/badge/@qhdrl12/mcp-server-gemini-image-gen)](https://smithery.ai/server/@qhdrl12/mcp-server-gemini-image-gen)\n\n\u003ca href=\"https://glama.ai/mcp/servers/@qhdrl12/mcp-server-gemini-image-generator\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@qhdrl12/mcp-server-gemini-image-generator/badge\" alt=\"Gemini Image Generator Server MCP server\" /\u003e\n\u003c/a\u003e\n\n# Gemini Image Generator MCP Server\n\nGenerate high-quality images from text prompts using Google's Gemini model through the MCP protocol.\n\n## Overview\n\nThis MCP server allows any AI assistant to generate images using Google's Gemini AI model. The server handles prompt engineering, text-to-image conversion, filename generation, and local image storage, making it easy to create and manage AI-generated images through any MCP client.\n\n## Features\n\n- Text-to-image generation using Gemini 2.0 Flash\n- Image-to-image transformation based on text prompts\n- Support for both file-based and base64-encoded images\n- Automatic intelligent filename generation based on prompts\n- Automatic translation of non-English prompts\n- Local image storage with configurable output path\n- Strict text exclusion from generated images\n- High-resolution image output\n- Direct access to both image data and file path\n\n## Available MCP Tools\n\nThe server provides the following MCP tools for AI assistants:\n\n### 1. `generate_image_from_text`\n\nCreates a new image from a text prompt description.\n\n```\ngenerate_image_from_text(prompt: str) -\u003e Tuple[bytes, str]\n```\n\n**Parameters:**\n- `prompt`: Text description of the image you want to generate\n\n**Returns:**\n- A tuple containing:\n  - Raw image data (bytes)\n  - Path to the saved image file (str)\n\nThis dual return format allows AI assistants to either work with the image data directly or reference the saved file path.\n\n**Examples:**\n- \"Generate an image of a sunset over mountains\"\n- \"Create a photorealistic flying pig in a sci-fi city\"\n\n#### Example Output\n\nThis image was generated using the prompt:\n\n```\n\"Hi, can you create a 3d rendered image of a pig with wings and a top hat flying over a happy futuristic scifi city with lots of greenery?\"\n```\n\n\n\n*A 3D rendered pig with wings and a top hat flying over a futuristic sci-fi city filled with greenery*\n\n### Known Issues\n\nWhen using this MCP server with Claude Desktop Host:\n\n1. **Performance Issues**: Using `transform_image_from_encoded` may take significantly longer to process compared to other methods. This is due to the overhead of transferring large base64-encoded image data through the MCP protocol.\n\n2. **Path Resolution Problems**: There may be issues with correctly resolving image paths when using Claude Desktop Host. The host application might not properly interpret the returned file paths, making it difficult to access the generated images.\n\nFor the best experience, consider using alternative MCP clients or the `transform_image_from_file` method when possible. \n\n### 2. `transform_image_from_encoded`\n\nTransforms an existing image based on a text prompt using base64-encoded image data.\n\n```\ntransform_image_from_encoded(encoded_image: str, prompt: str) -\u003e Tuple[bytes, str]\n```\n\n**Parameters:**\n- `encoded_image`: Base64 encoded image data with format header (must be in format: \"data:image/[format];base64,[data]\")\n- `prompt`: Text description of how you want to transform the image\n\n**Returns:**\n- A tuple containing:\n  - Raw transformed image data (bytes)\n  - Path to the saved transformed image file (str)\n\n**Example:**\n- \"Add snow to this landscape\"\n- \"Change the background to a beach\"\n\n### 3. `transform_image_from_file`\n\nTransforms an existing image file based on a text prompt.\n\n```\ntransform_image_from_file(image_file_path: str, prompt: str) -\u003e Tuple[bytes, str]\n```\n\n**Parameters:**\n- `image_file_path`: Path to the image file to be transformed\n- `prompt`: Text description of how you want to transform the image\n\n**Returns:**\n- A tuple containing:\n  - Raw transformed image data (bytes)\n  - Path to the saved transformed image file (str)\n\n**Examples:**\n- \"Add a llama next to the person in this image\"\n- \"Make this daytime scene look like night time\"\n\n#### Example Transformation\n\nUsing the flying pig image created above, we applied a transformation with the following prompt:\n\n```\n\"Add a cute baby whale flying alongside the pig\"\n```\n\n**Before:**\n\n\n**After:**\n\n\n*The original flying pig image with a cute baby whale added flying alongside it*\n\n## Setup\n\n### Prerequisites\n\n- Python 3.11+\n- Google AI API key (Gemini)\n- MCP host application (Claude Desktop App, Cursor, or other MCP-compatible clients)\n\n### Getting a Gemini API Key\n\n1. Visit [Google AI Studio API Keys page](https://aistudio.google.com/apikey)\n2. Sign in with your Google account\n3. Click \"Create API Key\"\n4. Copy your new API key for use in the configuration\n5. Note: The API key provides a certain quota of free usage per month. You can check your usage in the Google AI Studio\n\n### Installation\n\n### Installing via Smithery\n\nTo install Gemini Image Generator MCP for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@qhdrl12/mcp-server-gemini-image-gen):\n\n```bash\nnpx -y @smithery/cli install @qhdrl12/mcp-server-gemini-image-gen --client claude\n```\n\n### Manual Installation\n1. Clone the repository:\n```bash\ngit clone https://github.com/your-username/mcp-server-gemini-image-generator.git\ncd mcp-server-gemini-image-generator\n```\n\n2. Create a virtual environment and install dependencies:\n```bash\n# Using uv (recommended)\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e .\n\n# Or using regular venv\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\npip install -e .\n```\n\n3. Set up environment variables (choose one method):\n\n**Method A: Using .env file (optional)**\n```bash\n# Create .env file in the project root\ncat \u003e .env \u003c\u003c 'EOF'\nGEMINI_API_KEY=your-gemini-api-key-here\nOUTPUT_IMAGE_PATH=/path/to/save/images\nEOF\n```\n\n**Method B: Set directly in Claude Desktop config (recommended)**\n- Set environment variables directly in the `claude_desktop_config.json` (shown in configuration section below)\n\n### Configure Claude Desktop\n\nAdd the following to your `claude_desktop_config.json`:\n\n- **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- **Windows**: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n```json\n{\n    \"mcpServers\": {\n        \"gemini-image-generator\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/absolute/path/to/mcp-server-gemini-image-generator\",\n                \"run\",\n                \"mcp-server-gemini-image-generator\"\n            ],\n            \"env\": {\n                \"GEMINI_API_KEY\": \"your-actual-gemini-api-key-here\",\n                \"OUTPUT_IMAGE_PATH\": \"/absolute/path/to/your/images/directory\"\n            }\n        }\n    }\n}\n```\n\n**Important Configuration Notes:**\n\n1. **Replace paths with your actual paths:**\n   - Change `/absolute/path/to/mcp-server-gemini-image-generator` to the actual location where you cloned this repository\n   - Change `/absolute/path/to/your/images/directory` to where you want generated images to be saved\n\n2. **Environment Variables:**\n   - Replace `your-actual-gemini-api-key-here` with your real Gemini API key from Google AI Studio\n   - Use absolute paths for `OUTPUT_IMAGE_PATH` to ensure images are saved correctly\n\n3. **Example with real paths:**\n```json\n{\n    \"mcpServers\": {\n        \"gemini-image-generator\": {\n            \"command\": \"uv\",\n            \"args\": [\n                \"--directory\",\n                \"/Users/username/Projects/mcp-server-gemini-image-generator\",\n                \"run\",\n                \"mcp-server-gemini-image-generator\"\n            ],\n            \"env\": {\n                \"GEMINI_API_KEY\": \"GEMINI_API_KEY\",\n                \"OUTPUT_IMAGE_PATH\": \"OUTPUT_IMAGE_PATH\"\n            }\n        }\n    }\n}\n```\n\n## Usage\n\nOnce installed and configured, you can ask Claude to generate or transform images using prompts like:\n\n### Generating New Images\n- \"Generate an image of a sunset over mountains\"\n- \"Create an illustration of a futuristic cityscape\"\n- \"Make a picture of a cat wearing sunglasses\"\n\n### Transforming Existing Images\n- \"Transform this image by adding snow to the scene\"\n- \"Edit this photo to make it look like it was taken at night\"\n- \"Add a dragon flying in the background of this picture\"\n\nThe generated/transformed images will be saved to your configured output path and displayed in Claude. With the updated return types, AI assistants can also work directly with the image data without needing to access the saved files.\n\n## Testing\n\nYou can test the application by running the FastMCP development server:\n\n```\nfastmcp dev server.py\n```\n\nThis command starts a local development server and makes the MCP Inspector available at http://localhost:5173/. \nThe MCP Inspector provides a convenient web interface where you can directly test the image generation tool without needing to use Claude or another MCP client. \nYou can enter text prompts, execute the tool, and see the results immediately, which is helpful for development and debugging.\n\n## License\n\nMIT License",
      "stars": 23,
      "updated_at": "2025-09-25T16:39:30Z",
      "url": "https://github.com/qhdrl12/mcp-server-gemini-image-generator"
    },
    "qpd-v--mcp-image-downloader": {
      "category": "image-and-video-generation",
      "description": "Provides tools for downloading images from URLs and performing basic image optimization tasks such as resizing, quality adjustment, and format conversion.",
      "forks": 5,
      "imageUrl": "/freedevtools/mcp/pfp/qpd-v.webp",
      "keywords": [
        "qpd",
        "mcp",
        "downloader",
        "image downloader",
        "mcp image",
        "downloading images"
      ],
      "language": "JavaScript",
      "license": "Apache License 2.0",
      "name": "mcp-image-downloader",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "qpd-v",
      "readme_content": "# MCP Image Downloader\n\nAn MCP server that provides tools for downloading and optimizing images. Built using the Model Context Protocol (MCP), this server enables AI assistants to download images from URLs and perform basic image optimization tasks.\n\n## Features\n\n- Download images from URLs with proper error handling\n- Optimize images with options for:\n  - Resizing (maintaining aspect ratio)\n  - Quality adjustment (JPEG/WebP)\n  - Format conversion\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/qpd-v/mcp-image-downloader.git\ncd mcp-image-downloader\n\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n```\n\n## Usage\n\n### As an MCP Server\n\nAdd the server to your MCP configuration (e.g., in Claude Desktop's config):\n\n```json\n{\n  \"mcpServers\": {\n    \"image-downloader\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/mcp-image-downloader/build/index.js\"]\n    }\n  }\n}\n```\n\n### Available Tools\n\n#### download_image\nDownloads an image from a URL to a specified path.\n\nParameters:\n- `url`: URL of the image to download\n- `outputPath`: Path where to save the image\n\n#### optimize_image\nCreates an optimized version of an image.\n\nParameters:\n- `inputPath`: Path to the input image\n- `outputPath`: Path where to save the optimized image\n- `width` (optional): Target width (maintains aspect ratio if only width is specified)\n- `height` (optional): Target height (maintains aspect ratio if only height is specified)\n- `quality` (optional): JPEG/WebP quality (1-100)\n\n## Development\n\n```bash\n# Run in development mode\nnpm run start\n\n# Build the project\nnpm run build\n```\n\n## Requirements\n\n- Node.js 16 or higher\n- NPM or compatible package manager\n\n## License\n\nMIT License - see the [LICENSE](LICENSE) file for details.\n\n## Author\n\nqpd-v\n\n## Version\n\n0.1.0 - Initial release",
      "stars": 11,
      "updated_at": "2025-10-03T22:32:03Z",
      "url": "https://github.com/qpd-v/mcp-image-downloader"
    },
    "rmcendarfer2017--MCP-image-gen": {
      "category": "image-and-video-generation",
      "description": "Generate stunning images using advanced AI models with a built-in storage system for managing and accessing creations. Users can customize image styles and utilize a prompt-based interface for generating images.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/rmcendarfer2017.webp",
      "keywords": [
        "generate",
        "images",
        "mcp",
        "generating images",
        "mcp image",
        "image gen"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "MCP-image-gen",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "rmcendarfer2017",
      "readme_content": "# Image Generator MCP Server\n\nAn MCP server that uses Replicate to generate images and allows users to save them.\n\n## Components\n\n### Resources\n\nThe server implements an image storage system with:\n- Custom image:// URI scheme for accessing individual generated images\n- Each image resource has a name based on its prompt, description with creation date, and image/png mimetype\n\n### Prompts\n\nThe server provides a single prompt:\n- generate-image: Creates prompts for generating images using Stable Diffusion\n  - Optional \"style\" argument to control the image style (realistic/artistic/abstract)\n  - Generates a prompt template with style-specific guidance\n\n### Tools\n\nThe server implements three tools:\n- generate-image: Generates an image using Replicate's Stable Diffusion model\n  - Takes \"prompt\" as a required string argument\n  - Optional parameters include \"negative_prompt\", \"width\", \"height\", \"num_inference_steps\", and \"guidance_scale\"\n  - Returns the generated image and its URL\n- save-image: Saves a generated image to the local filesystem\n  - Takes \"image_url\" and \"prompt\" as required string arguments\n  - Generates a unique ID for the image and saves it to the \"generated_images\" directory\n- list-saved-images: Lists all saved images\n  - Returns a list of all saved images with their metadata and thumbnails\n\n## Configuration\n\n### Replicate API Token\n\nTo use this image generator, you need a Replicate API token:\n\n1. Create an account at [Replicate](https://replicate.com/)\n2. Get your API token from [https://replicate.com/account](https://replicate.com/account)\n3. Create a `.env` file based on the provided `.env.example` template:\n\n```\nREPLICATE_API_TOKEN=your_replicate_api_token_here\n```\n\n\u003e **Important:** The `.env` file is excluded from version control via `.gitignore` to prevent accidentally exposing your API token. Never commit sensitive information to your repository.\n\n### Environment Setup\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/yourusername/image-generator.git\ncd image-generator\n```\n\n2. Create and activate a virtual environment:\n```bash\n# Using venv\npython -m venv .venv\n# On Windows\n.venv\\Scripts\\activate\n# On macOS/Linux\nsource .venv/bin/activate\n```\n\n3. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n4. Set up your `.env` file as described above\n\n## Quickstart\n\n### Install\n\n#### Claude Desktop\n\nOn MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n\u003cdetails\u003e\n  \u003csummary\u003eDevelopment/Unpublished Servers Configuration\u003c/summary\u003e\n  ```\n  \"mcpServers\": {\n    \"image-generator\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"B:\\NEWTEST\\image-generator\",\n        \"run\",\n        \"image-generator\"\n      ]\n    }\n  }\n  ```\n\u003c/details\u003e\n\n\u003cdetails\u003e\n  \u003csummary\u003ePublished Servers Configuration\u003c/summary\u003e\n  ```\n  \"mcpServers\": {\n    \"image-generator\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"image-generator\"\n      ]\n    }\n  }\n  ```\n\u003c/details\u003e\n\n### Usage\n\nOnce the server is running, you can:\n\n1. Generate an image by using the \"generate-image\" tool with a descriptive prompt\n2. Save the generated image using the \"save-image\" tool with the image URL and prompt\n3. View all saved images using the \"list-saved-images\" tool\n4. Access saved images through the resource list\n\n## Development\n\n### Building and Publishing\n\nTo prepare the package for distribution:\n\n1. Sync dependencies and update lockfile:\n```bash\nuv sync\n```\n\n2. Build package distributions:\n```bash\nuv build\n```\n\nThis will create source and wheel distributions in the `dist/` directory.\n\n3. Publish to PyPI:\n```bash\nuv publish\n```\n\nNote: You'll need to set PyPI credentials via environment variables or command flags:\n- Token: `--token` or `UV_PUBLISH_TOKEN`\n- Or username/password: `--username`/`UV_PUBLISH_USERNAME` and `--password`/`UV_PUBLISH_PASSWORD`\n\n### Debugging\n\nSince MCP servers run over stdio, debugging can be challenging. For the best debugging\nexperience, we strongly recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\nYou can launch the MCP Inspector via [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) with this command:\n\n```bash\nnpx @modelcontextprotocol/inspector uv --directory B:\\NEWTEST\\image-generator run image-generator\n```\n\nUpon launching, the Inspector will display a URL that you can access in your browser to begin debugging.",
      "stars": 0,
      "updated_at": "2025-03-08T16:13:41Z",
      "url": "https://github.com/rmcendarfer2017/MCP-image-gen"
    },
    "rsagacom--chatgpt-on-wechat": {
      "category": "image-and-video-generation",
      "description": "A multi-platform intelligent dialogue service that supports text, voice, and image interactions. It can connect to various AI models and allows for custom enterprise AI applications through plugin extensions.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/rsagacom.webp",
      "keywords": [
        "chatgpt",
        "dialogue",
        "wechat",
        "dialogue service",
        "rsagacom chatgpt",
        "chatgpt wechat"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "chatgpt-on-wechat",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "rsagacom",
      "readme_content": "# ÁÆÄ‰ªã\n\n\u003e Êú¨È°πÁõÆÊòØÂü∫‰∫éÂ§ßÊ®°ÂûãÁöÑÊô∫ËÉΩÂØπËØùÊú∫Âô®‰∫∫ÔºåÊîØÊåÅÂæÆ‰ø°„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅÂÖ¨‰ºóÂè∑„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâÊé•ÂÖ•ÔºåÂèØÈÄâÊã©GPT3.5/GPT4.0/Claude/ÊñáÂøÉ‰∏ÄË®Ä/ËÆØÈ£ûÊòüÁÅ´/ÈÄö‰πâÂçÉÈóÆ/Gemini/LinkAIÔºåËÉΩÂ§ÑÁêÜÊñáÊú¨„ÄÅËØ≠Èü≥ÂíåÂõæÁâáÔºåÈÄöËøáÊèí‰ª∂ËÆøÈóÆÊìç‰ΩúÁ≥ªÁªüÂíå‰∫íËÅîÁΩëÁ≠âÂ§ñÈÉ®ËµÑÊ∫êÔºåÊîØÊåÅÂü∫‰∫éËá™ÊúâÁü•ËØÜÂ∫ìÂÆöÂà∂‰ºÅ‰∏öAIÂ∫îÁî®„ÄÇ\n\nÊúÄÊñ∞ÁâàÊú¨ÊîØÊåÅÁöÑÂäüËÉΩÂ¶Ç‰∏ãÔºö\n\n- [x] **Â§öÁ´ØÈÉ®ÁΩ≤Ôºö** ÊúâÂ§öÁßçÈÉ®ÁΩ≤ÊñπÂºèÂèØÈÄâÊã©‰∏îÂäüËÉΩÂÆåÂ§áÔºåÁõÆÂâçÂ∑≤ÊîØÊåÅ‰∏™‰∫∫ÂæÆ‰ø°„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑Âíå„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâÁ≠âÈÉ®ÁΩ≤ÊñπÂºè\n- [x] **Âü∫Á°ÄÂØπËØùÔºö** ÁßÅËÅäÂèäÁæ§ËÅäÁöÑÊ∂àÊÅØÊô∫ËÉΩÂõûÂ§çÔºåÊîØÊåÅÂ§öËΩÆ‰ºöËØù‰∏ä‰∏ãÊñáËÆ∞ÂøÜÔºåÊîØÊåÅ GPT-3.5, GPT-4, claude, Gemini, ÊñáÂøÉ‰∏ÄË®Ä, ËÆØÈ£ûÊòüÁÅ´, ÈÄö‰πâÂçÉÈóÆ\n- [x] **ËØ≠Èü≥ËÉΩÂäõÔºö** ÂèØËØÜÂà´ËØ≠Èü≥Ê∂àÊÅØÔºåÈÄöËøáÊñáÂ≠óÊàñËØ≠Èü≥ÂõûÂ§çÔºåÊîØÊåÅ azure, baidu, google, openai(whisper/tts) Á≠âÂ§öÁßçËØ≠Èü≥Ê®°Âûã\n- [x] **ÂõæÂÉèËÉΩÂäõÔºö** ÊîØÊåÅÂõæÁâáÁîüÊàê„ÄÅÂõæÁâáËØÜÂà´„ÄÅÂõæÁîüÂõæÔºàÂ¶ÇÁÖßÁâá‰øÆÂ§çÔºâÔºåÂèØÈÄâÊã© Dall-E-3, stable diffusion, replicate, midjourney, visionÊ®°Âûã\n- [x] **‰∏∞ÂØåÊèí‰ª∂Ôºö** ÊîØÊåÅ‰∏™ÊÄßÂåñÊèí‰ª∂Êâ©Â±ïÔºåÂ∑≤ÂÆûÁé∞Â§öËßíËâ≤ÂàáÊç¢„ÄÅÊñáÂ≠óÂÜíÈô©„ÄÅÊïèÊÑüËØçËøáÊª§„ÄÅËÅäÂ§©ËÆ∞ÂΩïÊÄªÁªì„ÄÅÊñáÊ°£ÊÄªÁªìÂíåÂØπËØù„ÄÅËÅîÁΩëÊêúÁ¥¢Á≠âÊèí‰ª∂\n- [x] **Áü•ËØÜÂ∫ìÔºö** ÈÄöËøá‰∏ä‰º†Áü•ËØÜÂ∫ìÊñá‰ª∂Ëá™ÂÆö‰πâ‰∏ìÂ±ûÊú∫Âô®‰∫∫ÔºåÂèØ‰Ωú‰∏∫Êï∞Â≠óÂàÜË∫´„ÄÅÊô∫ËÉΩÂÆ¢Êúç„ÄÅÁßÅÂüüÂä©Êâã‰ΩøÁî®ÔºåÂü∫‰∫é [LinkAI](https://link-ai.tech) ÂÆûÁé∞\n\n# ÊºîÁ§∫\n\nhttps://github.com/zhayujie/chatgpt-on-wechat/assets/26161723/d5154020-36e3-41db-8706-40ce9f3f1b1e\n\nDemo made by [Visionn](https://www.wangpc.cc/)\n\n# ÂïÜ‰∏öÊîØÊåÅ\n\n\u003e Êàë‰ª¨ËøòÊèê‰æõ‰ºÅ‰∏öÁ∫ßÁöÑ **AIÂ∫îÁî®Âπ≥Âè∞**ÔºåÂåÖÂê´Áü•ËØÜÂ∫ì„ÄÅAgentÊèí‰ª∂„ÄÅÂ∫îÁî®ÁÆ°ÁêÜÁ≠âËÉΩÂäõÔºåÊîØÊåÅÂ§öÂπ≥Âè∞ËÅöÂêàÁöÑÂ∫îÁî®Êé•ÂÖ•„ÄÅÂÆ¢Êà∑Á´ØÁÆ°ÁêÜ„ÄÅÂØπËØùÁÆ°ÁêÜÔºå‰ª•ÂèäÊèê‰æõ\nSaaSÊúçÂä°„ÄÅÁßÅÊúâÂåñÈÉ®ÁΩ≤„ÄÅÁ®≥ÂÆöÊâòÁÆ°Êé•ÂÖ• Á≠âÂ§öÁßçÊ®°Âºè„ÄÇ\n\u003e\n\u003e ÁõÆÂâçÂ∑≤Âú®ÁßÅÂüüËøêËê•„ÄÅÊô∫ËÉΩÂÆ¢Êúç„ÄÅ‰ºÅ‰∏öÊïàÁéáÂä©ÊâãÁ≠âÂú∫ÊôØÁßØÁ¥Ø‰∫Ü‰∏∞ÂØåÁöÑ AI Ëß£ÂÜ≥ÊñπÊ°àÔºå Âú®ÁîµÂïÜ„ÄÅÊñáÊïô„ÄÅÂÅ•Â∫∑„ÄÅÊñ∞Ê∂àË¥πÁ≠âÂêÑË°å‰∏öÊ≤âÊ∑Ä‰∫Ü AI ËêΩÂú∞ÁöÑÊúÄ‰Ω≥ÂÆûË∑µÔºåËá¥Âäõ‰∫éÊâìÈÄ†Âä©Âäõ‰∏≠Â∞è‰ºÅ‰∏öÊã•Êä± AI ÁöÑ‰∏ÄÁ´ôÂºèÂπ≥Âè∞„ÄÇ\n\n‰ºÅ‰∏öÊúçÂä°ÂíåÂïÜÁî®Âí®ËØ¢ÂèØËÅîÁ≥ª‰∫ßÂìÅÈ°æÈóÆÔºö\n\n\u003cimg alt=\"product_manager_qrcode\" width=\"240\" src=\"https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg\"\u003e\n\n# ÂºÄÊ∫êÁ§æÂå∫\n\nÊ∑ªÂä†Â∞èÂä©ÊâãÂæÆ‰ø°Âä†ÂÖ•ÂºÄÊ∫êÈ°πÁõÆ‰∫§ÊµÅÁæ§Ôºö\n\n\n\n# Êõ¥Êñ∞Êó•Âøó\n\n\u003e**2023.11.11Ôºö** [1.5.3ÁâàÊú¨](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.3) Âíå [1.5.4ÁâàÊú¨](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.4)ÔºåÊñ∞Â¢ûGoogle Gemini„ÄÅÈÄö‰πâÂçÉÈóÆÊ®°Âûã\n\n\u003e**2023.11.10Ôºö** [1.5.2ÁâàÊú¨](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.2)ÔºåÊñ∞Â¢ûÈ£û‰π¶ÈÄöÈÅì„ÄÅÂõæÂÉèËØÜÂà´ÂØπËØù„ÄÅÈªëÂêçÂçïÈÖçÁΩÆ\n\n\u003e**2023.11.10Ôºö** [1.5.0ÁâàÊú¨](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.0)ÔºåÊñ∞Â¢û `gpt-4-turbo`, `dall-e-3`, `tts` Ê®°ÂûãÊé•ÂÖ•ÔºåÂÆåÂñÑÂõæÂÉèÁêÜËß£\u0026ÁîüÊàê„ÄÅËØ≠Èü≥ËØÜÂà´\u0026ÁîüÊàêÁöÑÂ§öÊ®°ÊÄÅËÉΩÂäõ\n\n\u003e**2023.10.16Ôºö** ÊîØÊåÅÈÄöËøáÊÑèÂõæËØÜÂà´‰ΩøÁî®LinkAIËÅîÁΩëÊêúÁ¥¢„ÄÅÊï∞Â≠¶ËÆ°ÁÆó„ÄÅÁΩëÈ°µËÆøÈóÆÁ≠âÊèí‰ª∂ÔºåÂèÇËÄÉ[Êèí‰ª∂ÊñáÊ°£](https://docs.link-ai.tech/platform/plugins)\n\n\u003e**2023.09.26Ôºö** Êèí‰ª∂Â¢ûÂä† Êñá‰ª∂/ÊñáÁ´†ÈìæÊé• ‰∏ÄÈîÆÊÄªÁªìÂíåÂØπËØùÁöÑÂäüËÉΩÔºå‰ΩøÁî®ÂèÇËÄÉÔºö[Êèí‰ª∂ËØ¥Êòé](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai#3%E6%96%87%E6%A1%A3%E6%80%BB%E7%BB%93%E5%AF%B9%E8%AF%9D%E5%8A%9F%E8%83%BD)\n\n\u003e**2023.08.08Ôºö** Êé•ÂÖ•ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®ÄÊ®°ÂûãÔºåÈÄöËøá [Êèí‰ª∂](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai) ÊîØÊåÅ Midjourney ÁªòÂõæ\n\n\u003e**2023.06.12Ôºö** Êé•ÂÖ• [LinkAI](https://link-ai.tech/console) Âπ≥Âè∞ÔºåÂèØÂú®Á∫øÂàõÂª∫È¢ÜÂüüÁü•ËØÜÂ∫ìÔºåÂπ∂Êé•ÂÖ•ÂæÆ‰ø°„ÄÅÂÖ¨‰ºóÂè∑Âèä‰ºÅ‰∏öÂæÆ‰ø°‰∏≠ÔºåÊâìÈÄ†‰∏ìÂ±ûÂÆ¢ÊúçÊú∫Âô®‰∫∫„ÄÇ‰ΩøÁî®ÂèÇËÄÉ [Êé•ÂÖ•ÊñáÊ°£](https://link-ai.tech/platform/link-app/wechat)„ÄÇ\n\n\u003e**2023.04.26Ôºö** ÊîØÊåÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®Âè∑ÈÉ®ÁΩ≤ÔºåÂÖºÂÆπÊèí‰ª∂ÔºåÂπ∂ÊîØÊåÅËØ≠Èü≥ÂõæÁâá‰∫§‰∫íÔºåÁßÅ‰∫∫Âä©ÁêÜÁêÜÊÉ≥ÈÄâÊã©Ôºå[‰ΩøÁî®ÊñáÊ°£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatcom/README.md)„ÄÇ(contributed by [@lanvent](https://github.com/lanvent) in [#944](https://github.com/zhayujie/chatgpt-on-wechat/pull/944))\n\n\u003e**2023.04.05Ôºö** ÊîØÊåÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÈÉ®ÁΩ≤ÔºåÂÖºÂÆπÊèí‰ª∂ÔºåÂπ∂ÊîØÊåÅËØ≠Èü≥ÂõæÁâá‰∫§‰∫íÔºå[‰ΩøÁî®ÊñáÊ°£](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/wechatmp/README.md)„ÄÇ(contributed by [@JS00000](https://github.com/JS00000) in [#686](https://github.com/zhayujie/chatgpt-on-wechat/pull/686))\n\n\u003e**2023.04.05Ôºö** Â¢ûÂä†ËÉΩËÆ©ChatGPT‰ΩøÁî®Â∑•ÂÖ∑ÁöÑ`tool`Êèí‰ª∂Ôºå[‰ΩøÁî®ÊñáÊ°£](https://github.com/goldfishh/chatgpt-on-wechat/blob/master/plugins/tool/README.md)„ÄÇÂ∑•ÂÖ∑Áõ∏ÂÖ≥issueÂèØÂèçÈ¶àËá≥[chatgpt-tool-hub](https://github.com/goldfishh/chatgpt-tool-hub)„ÄÇ(contributed by [@goldfishh](https://github.com/goldfishh) in [#663](https://github.com/zhayujie/chatgpt-on-wechat/pull/663))\n\n\u003e**2023.03.25Ôºö** ÊîØÊåÅÊèí‰ª∂ÂåñÂºÄÂèëÔºåÁõÆÂâçÂ∑≤ÂÆûÁé∞ Â§öËßíËâ≤ÂàáÊç¢„ÄÅÊñáÂ≠óÂÜíÈô©Ê∏∏Êàè„ÄÅÁÆ°ÁêÜÂëòÊåá‰ª§„ÄÅStable DiffusionÁ≠âÊèí‰ª∂Ôºå‰ΩøÁî®ÂèÇËÄÉ [#578](https://github.com/zhayujie/chatgpt-on-wechat/issues/578)„ÄÇ(contributed by [@lanvent](https://github.com/lanvent) in [#565](https://github.com/zhayujie/chatgpt-on-wechat/pull/565))\n\n\u003e**2023.03.09Ôºö** Âü∫‰∫é `whisper API`(ÂêéÁª≠Â∑≤Êé•ÂÖ•Êõ¥Â§öÁöÑËØ≠Èü≥`API`ÊúçÂä°) ÂÆûÁé∞ÂØπÂæÆ‰ø°ËØ≠Èü≥Ê∂àÊÅØÁöÑËß£ÊûêÂíåÂõûÂ§çÔºåÊ∑ªÂä†ÈÖçÁΩÆÈ°π `\"speech_recognition\":true` Âç≥ÂèØÂêØÁî®Ôºå‰ΩøÁî®ÂèÇËÄÉ [#415](https://github.com/zhayujie/chatgpt-on-wechat/issues/415)„ÄÇ(contributed by [wanggang1987](https://github.com/wanggang1987) in [#385](https://github.com/zhayujie/chatgpt-on-wechat/pull/385))\n\n\u003e**2023.02.09Ôºö** Êâ´Á†ÅÁôªÂΩïÂ≠òÂú®Ë¥¶Âè∑ÈôêÂà∂È£éÈô©ÔºåËØ∑Ë∞®ÊÖé‰ΩøÁî®ÔºåÂèÇËÄÉ[#58](https://github.com/AutumnWhj/ChatGPT-wechat-bot/issues/158)\n\n# Âø´ÈÄüÂºÄÂßã\n\nÂø´ÈÄüÂºÄÂßãÊñáÊ°£Ôºö[È°πÁõÆÊê≠Âª∫ÊñáÊ°£](https://docs.link-ai.tech/cow/quick-start)\n\n## ÂáÜÂ§á\n\n### 1. Ë¥¶Âè∑Ê≥®ÂÜå\n\nÈ°πÁõÆÈªòËÆ§‰ΩøÁî®OpenAIÊé•Âè£ÔºåÈúÄÂâçÂæÄ [OpenAIÊ≥®ÂÜåÈ°µÈù¢](https://beta.openai.com/signup) ÂàõÂª∫Ë¥¶Âè∑ÔºåÂàõÂª∫ÂÆåË¥¶Âè∑ÂàôÂâçÂæÄ [APIÁÆ°ÁêÜÈ°µÈù¢](https://beta.openai.com/account/api-keys) ÂàõÂª∫‰∏Ä‰∏™ API Key Âπ∂‰øùÂ≠ò‰∏ãÊù•ÔºåÂêéÈù¢ÈúÄË¶ÅÂú®È°πÁõÆ‰∏≠ÈÖçÁΩÆËøô‰∏™key„ÄÇÊé•Âè£ÈúÄË¶ÅÊµ∑Â§ñÁΩëÁªúËÆøÈóÆÂèäÁªëÂÆö‰ø°Áî®Âç°ÊîØ‰ªò„ÄÇ\n\n\u003e ÈªòËÆ§ÂØπËØùÊ®°ÂûãÊòØ openai ÁöÑ gpt-3.5-turboÔºåËÆ°Ë¥πÊñπÂºèÊòØÁ∫¶ÊØè 1000tokens (Á∫¶750‰∏™Ëã±ÊñáÂçïËØç Êàñ 500Ê±âÂ≠óÔºåÂåÖÂê´ËØ∑Ê±ÇÂíåÂõûÂ§ç) Ê∂àËÄó $0.002ÔºåÂõæÁâáÁîüÊàêÊòØDell EÊ®°ÂûãÔºåÊØèÂº†Ê∂àËÄó $0.016„ÄÇ\n\nÈ°πÁõÆÂêåÊó∂‰πüÊîØÊåÅ‰ΩøÁî® LinkAI Êé•Âè£ÔºåÊó†ÈúÄ‰ª£ÁêÜÔºåÂèØ‰ΩøÁî® ÊñáÂøÉ„ÄÅËÆØÈ£û„ÄÅGPT-3„ÄÅGPT-4 Á≠âÊ®°ÂûãÔºåÊîØÊåÅ ÂÆöÂà∂ÂåñÁü•ËØÜÂ∫ì„ÄÅËÅîÁΩëÊêúÁ¥¢„ÄÅMJÁªòÂõæ„ÄÅÊñáÊ°£ÊÄªÁªìÂíåÂØπËØùÁ≠âËÉΩÂäõ„ÄÇ‰øÆÊîπÈÖçÁΩÆÂç≥ÂèØ‰∏ÄÈîÆÂàáÊç¢ÔºåÂèÇËÄÉ [Êé•ÂÖ•ÊñáÊ°£](https://link-ai.tech/platform/link-app/wechat)„ÄÇ\n\n### 2.ËøêË°åÁéØÂ¢É\n\nÊîØÊåÅ Linux„ÄÅMacOS„ÄÅWindows Á≥ªÁªüÔºàÂèØÂú®LinuxÊúçÂä°Âô®‰∏äÈïøÊúüËøêË°å)ÔºåÂêåÊó∂ÈúÄÂÆâË£Ö `Python`„ÄÇ\n\u003e Âª∫ËÆÆPythonÁâàÊú¨Âú® 3.7.1~3.9.X ‰πãÈó¥ÔºåÊé®Ëçê3.8ÁâàÊú¨Ôºå3.10Âèä‰ª•‰∏äÁâàÊú¨Âú® MacOS ÂèØÁî®ÔºåÂÖ∂‰ªñÁ≥ªÁªü‰∏ä‰∏çÁ°ÆÂÆöËÉΩÂê¶Ê≠£Â∏∏ËøêË°å„ÄÇ\n\n\u003e Ê≥®ÊÑèÔºöDocker Êàñ Railway ÈÉ®ÁΩ≤Êó†ÈúÄÂÆâË£ÖpythonÁéØÂ¢ÉÂíå‰∏ãËΩΩÊ∫êÁ†ÅÔºåÂèØÁõ¥Êé•Âø´ËøõÂà∞‰∏ã‰∏ÄËäÇ„ÄÇ\n\n**(1) ÂÖãÈöÜÈ°πÁõÆ‰ª£Á†ÅÔºö**\n\n```bash\ngit clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/\n```\n\nÊ≥®: Â¶ÇÈÅáÂà∞ÁΩëÁªúÈóÆÈ¢òÂèØÈÄâÊã©ÂõΩÂÜÖÈïúÂÉè https://gitee.com/zhayujie/chatgpt-on-wechat\n\n**(2) ÂÆâË£ÖÊ†∏ÂøÉ‰æùËµñ (ÂøÖÈÄâ)Ôºö**\n\u003e ËÉΩÂ§ü‰ΩøÁî®`itchat`ÂàõÂª∫Êú∫Âô®‰∫∫ÔºåÂπ∂ÂÖ∑ÊúâÊñáÂ≠ó‰∫§ÊµÅÂäüËÉΩÊâÄÈúÄÁöÑÊúÄÂ∞è‰æùËµñÈõÜÂêà„ÄÇ\n```bash\npip3 install -r requirements.txt\n```\n\n**(3) ÊãìÂ±ï‰æùËµñ (ÂèØÈÄâÔºåÂª∫ËÆÆÂÆâË£Ö)Ôºö**\n\n```bash\npip3 install -r requirements-optional.txt\n```\n\u003e Â¶ÇÊûúÊüêÈ°π‰æùËµñÂÆâË£ÖÂ§±Ë¥•ÂèØÊ≥®ÈáäÊéâÂØπÂ∫îÁöÑË°åÂÜçÁªßÁª≠\n\n## ÈÖçÁΩÆ\n\nÈÖçÁΩÆÊñá‰ª∂ÁöÑÊ®°ÊùøÂú®Ê†πÁõÆÂΩïÁöÑ`config-template.json`‰∏≠ÔºåÈúÄÂ§çÂà∂ËØ•Ê®°ÊùøÂàõÂª∫ÊúÄÁªàÁîüÊïàÁöÑ `config.json` Êñá‰ª∂Ôºö\n\n```bash\n  cp config-template.json config.json\n```\n\nÁÑ∂ÂêéÂú®`config.json`‰∏≠Â°´ÂÖ•ÈÖçÁΩÆÔºå‰ª•‰∏ãÊòØÂØπÈªòËÆ§ÈÖçÁΩÆÁöÑËØ¥ÊòéÔºåÂèØÊ†πÊçÆÈúÄË¶ÅËøõË°åËá™ÂÆö‰πâ‰øÆÊîπÔºàËØ∑ÂéªÊéâÊ≥®ÈáäÔºâÔºö\n\n```bash\n# config.jsonÊñá‰ª∂ÂÜÖÂÆπÁ§∫‰æã\n{\n  \"open_ai_api_key\": \"YOUR API KEY\",                          # Â°´ÂÖ•‰∏äÈù¢ÂàõÂª∫ÁöÑ OpenAI API KEY\n  \"model\": \"gpt-3.5-turbo\",                                   # Ê®°ÂûãÂêçÁß∞, ÊîØÊåÅ gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4, wenxin, xunfei\n  \"proxy\": \"\",                                                # ‰ª£ÁêÜÂÆ¢Êà∑Á´ØÁöÑipÂíåÁ´ØÂè£ÔºåÂõΩÂÜÖÁéØÂ¢ÉÂºÄÂêØ‰ª£ÁêÜÁöÑÈúÄË¶ÅÂ°´ÂÜôËØ•È°πÔºåÂ¶Ç \"127.0.0.1:7890\"\n  \"single_chat_prefix\": [\"bot\", \"@bot\"],                      # ÁßÅËÅäÊó∂ÊñáÊú¨ÈúÄË¶ÅÂåÖÂê´ËØ•ÂâçÁºÄÊâçËÉΩËß¶ÂèëÊú∫Âô®‰∫∫ÂõûÂ§ç\n  \"single_chat_reply_prefix\": \"[bot] \",                       # ÁßÅËÅäÊó∂Ëá™Âä®ÂõûÂ§çÁöÑÂâçÁºÄÔºåÁî®‰∫éÂå∫ÂàÜÁúü‰∫∫\n  \"group_chat_prefix\": [\"@bot\"],                              # Áæ§ËÅäÊó∂ÂåÖÂê´ËØ•ÂâçÁºÄÂàô‰ºöËß¶ÂèëÊú∫Âô®‰∫∫ÂõûÂ§ç\n  \"group_name_white_list\": [\"ChatGPTÊµãËØïÁæ§\", \"ChatGPTÊµãËØïÁæ§2\"], # ÂºÄÂêØËá™Âä®ÂõûÂ§çÁöÑÁæ§ÂêçÁß∞ÂàóË°®\n  \"group_chat_in_one_session\": [\"ChatGPTÊµãËØïÁæ§\"],              # ÊîØÊåÅ‰ºöËØù‰∏ä‰∏ãÊñáÂÖ±‰∫´ÁöÑÁæ§ÂêçÁß∞  \n  \"image_create_prefix\": [\"Áîª\", \"Áúã\", \"Êâæ\"],                   # ÂºÄÂêØÂõæÁâáÂõûÂ§çÁöÑÂâçÁºÄ\n  \"conversation_max_tokens\": 1000,                            # ÊîØÊåÅ‰∏ä‰∏ãÊñáËÆ∞ÂøÜÁöÑÊúÄÂ§öÂ≠óÁ¨¶Êï∞\n  \"speech_recognition\": false,                                # ÊòØÂê¶ÂºÄÂêØËØ≠Èü≥ËØÜÂà´\n  \"group_speech_recognition\": false,                          # ÊòØÂê¶ÂºÄÂêØÁæ§ÁªÑËØ≠Èü≥ËØÜÂà´\n  \"use_azure_chatgpt\": false,                                 # ÊòØÂê¶‰ΩøÁî®Azure ChatGPT service‰ª£Êõøopenai ChatGPT service. ÂΩìËÆæÁΩÆ‰∏∫trueÊó∂ÈúÄË¶ÅËÆæÁΩÆ open_ai_api_baseÔºåÂ¶Ç https://xxx.openai.azure.com/\n  \"azure_deployment_id\": \"\",                                  # ÈááÁî®Azure ChatGPTÊó∂ÔºåÊ®°ÂûãÈÉ®ÁΩ≤ÂêçÁß∞\n  \"azure_api_version\": \"\",                                    # ÈááÁî®Azure ChatGPTÊó∂ÔºåAPIÁâàÊú¨\n  \"character_desc\": \"‰Ω†ÊòØChatGPT, ‰∏Ä‰∏™Áî±OpenAIËÆ≠ÁªÉÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã, ‰Ω†Êó®Âú®ÂõûÁ≠îÂπ∂Ëß£ÂÜ≥‰∫∫‰ª¨ÁöÑ‰ªª‰ΩïÈóÆÈ¢òÔºåÂπ∂‰∏îÂèØ‰ª•‰ΩøÁî®Â§öÁßçËØ≠Ë®Ä‰∏é‰∫∫‰∫§ÊµÅ„ÄÇ\",  # ‰∫∫Ê†ºÊèèËø∞\n  # ËÆ¢ÈòÖÊ∂àÊÅØÔºåÂÖ¨‰ºóÂè∑Âíå‰ºÅ‰∏öÂæÆ‰ø°channel‰∏≠ËØ∑Â°´ÂÜôÔºåÂΩìË¢´ËÆ¢ÈòÖÊó∂‰ºöËá™Âä®ÂõûÂ§çÔºåÂèØ‰ΩøÁî®ÁâπÊÆäÂç†‰ΩçÁ¨¶„ÄÇÁõÆÂâçÊîØÊåÅÁöÑÂç†‰ΩçÁ¨¶Êúâ{trigger_prefix}ÔºåÂú®Á®ãÂ∫è‰∏≠ÂÆÉ‰ºöËá™Âä®ÊõøÊç¢ÊàêbotÁöÑËß¶ÂèëËØç„ÄÇ\n  \"subscribe_msg\": \"ÊÑüË∞¢ÊÇ®ÁöÑÂÖ≥Ê≥®ÔºÅ\\nËøôÈáåÊòØChatGPTÔºåÂèØ‰ª•Ëá™Áî±ÂØπËØù„ÄÇ\\nÊîØÊåÅËØ≠Èü≥ÂØπËØù„ÄÇ\\nÊîØÊåÅÂõæÁâáËæìÂá∫ÔºåÁîªÂ≠óÂºÄÂ§¥ÁöÑÊ∂àÊÅØÂ∞ÜÊåâË¶ÅÊ±ÇÂàõ‰ΩúÂõæÁâá„ÄÇ\\nÊîØÊåÅËßíËâ≤ÊâÆÊºîÂíåÊñáÂ≠óÂÜíÈô©Á≠â‰∏∞ÂØåÊèí‰ª∂„ÄÇ\\nËæìÂÖ•{trigger_prefix}#help Êü•ÁúãËØ¶ÁªÜÊåá‰ª§„ÄÇ\",\n  \"use_linkai\": false,                                        # ÊòØÂê¶‰ΩøÁî®LinkAIÊé•Âè£ÔºåÈªòËÆ§ÂÖ≥Èó≠ÔºåÂºÄÂêØÂêéÂèØÂõΩÂÜÖËÆøÈóÆÔºå‰ΩøÁî®Áü•ËØÜÂ∫ìÂíåMJ\n  \"linkai_api_key\": \"\",                                       # LinkAI Api Key\n  \"linkai_app_code\": \"\"                                       # LinkAI Â∫îÁî®code\n}\n```\n**ÈÖçÁΩÆËØ¥ÊòéÔºö**\n\n**1.‰∏™‰∫∫ËÅäÂ§©**\n\n+ ‰∏™‰∫∫ËÅäÂ§©‰∏≠ÔºåÈúÄË¶Å‰ª• \"bot\"Êàñ\"@bot\" ‰∏∫ÂºÄÂ§¥ÁöÑÂÜÖÂÆπËß¶ÂèëÊú∫Âô®‰∫∫ÔºåÂØπÂ∫îÈÖçÁΩÆÈ°π `single_chat_prefix` (Â¶ÇÊûú‰∏çÈúÄË¶Å‰ª•ÂâçÁºÄËß¶ÂèëÂèØ‰ª•Â°´ÂÜô  `\"single_chat_prefix\": [\"\"]`)\n+ Êú∫Âô®‰∫∫ÂõûÂ§çÁöÑÂÜÖÂÆπ‰ºö‰ª• \"[bot] \" ‰Ωú‰∏∫ÂâçÁºÄÔºå ‰ª•Âå∫ÂàÜÁúü‰∫∫ÔºåÂØπÂ∫îÁöÑÈÖçÁΩÆÈ°π‰∏∫ `single_chat_reply_prefix` (Â¶ÇÊûú‰∏çÈúÄË¶ÅÂâçÁºÄÂèØ‰ª•Â°´ÂÜô `\"single_chat_reply_prefix\": \"\"`)\n\n**2.Áæ§ÁªÑËÅäÂ§©**\n\n+ Áæ§ÁªÑËÅäÂ§©‰∏≠ÔºåÁæ§ÂêçÁß∞ÈúÄÈÖçÁΩÆÂú® `group_name_white_list ` ‰∏≠ÊâçËÉΩÂºÄÂêØÁæ§ËÅäËá™Âä®ÂõûÂ§ç„ÄÇÂ¶ÇÊûúÊÉ≥ÂØπÊâÄÊúâÁæ§ËÅäÁîüÊïàÔºåÂèØ‰ª•Áõ¥Êé•Â°´ÂÜô `\"group_name_white_list\": [\"ALL_GROUP\"]`\n+ ÈªòËÆ§Âè™Ë¶ÅË¢´‰∫∫ @ Â∞±‰ºöËß¶ÂèëÊú∫Âô®‰∫∫Ëá™Âä®ÂõûÂ§çÔºõÂè¶Â§ñÁæ§ËÅäÂ§©‰∏≠Âè™Ë¶ÅÊ£ÄÊµãÂà∞‰ª• \"@bot\" ÂºÄÂ§¥ÁöÑÂÜÖÂÆπÔºåÂêåÊ†∑‰ºöËá™Âä®ÂõûÂ§çÔºàÊñπ‰æøËá™Â∑±Ëß¶ÂèëÔºâÔºåËøôÂØπÂ∫îÈÖçÁΩÆÈ°π `group_chat_prefix`\n+ ÂèØÈÄâÈÖçÁΩÆ: `group_name_keyword_white_list`ÈÖçÁΩÆÈ°πÊîØÊåÅÊ®°Á≥äÂåπÈÖçÁæ§ÂêçÁß∞Ôºå`group_chat_keyword`ÈÖçÁΩÆÈ°πÂàôÊîØÊåÅÊ®°Á≥äÂåπÈÖçÁæ§Ê∂àÊÅØÂÜÖÂÆπÔºåÁî®Ê≥ï‰∏é‰∏äËø∞‰∏§‰∏™ÈÖçÁΩÆÈ°πÁõ∏Âêå„ÄÇÔºàContributed by [evolay](https://github.com/evolay))\n+ `group_chat_in_one_session`Ôºö‰ΩøÁæ§ËÅäÂÖ±‰∫´‰∏Ä‰∏™‰ºöËØù‰∏ä‰∏ãÊñáÔºåÈÖçÁΩÆ `[\"ALL_GROUP\"]` Âàô‰ΩúÁî®‰∫éÊâÄÊúâÁæ§ËÅä\n\n**3.ËØ≠Èü≥ËØÜÂà´**\n\n+ Ê∑ªÂä† `\"speech_recognition\": true` Â∞ÜÂºÄÂêØËØ≠Èü≥ËØÜÂà´ÔºåÈªòËÆ§‰ΩøÁî®openaiÁöÑwhisperÊ®°ÂûãËØÜÂà´‰∏∫ÊñáÂ≠óÔºåÂêåÊó∂‰ª•ÊñáÂ≠óÂõûÂ§çÔºåËØ•ÂèÇÊï∞‰ªÖÊîØÊåÅÁßÅËÅä (Ê≥®ÊÑèÁî±‰∫éËØ≠Èü≥Ê∂àÊÅØÊó†Ê≥ïÂåπÈÖçÂâçÁºÄÔºå‰∏ÄÊó¶ÂºÄÂêØÂ∞ÜÂØπÊâÄÊúâËØ≠Èü≥Ëá™Âä®ÂõûÂ§çÔºåÊîØÊåÅËØ≠Èü≥Ëß¶ÂèëÁîªÂõæ)Ôºõ\n+ Ê∑ªÂä† `\"group_speech_recognition\": true` Â∞ÜÂºÄÂêØÁæ§ÁªÑËØ≠Èü≥ËØÜÂà´ÔºåÈªòËÆ§‰ΩøÁî®openaiÁöÑwhisperÊ®°ÂûãËØÜÂà´‰∏∫ÊñáÂ≠óÔºåÂêåÊó∂‰ª•ÊñáÂ≠óÂõûÂ§çÔºåÂèÇÊï∞‰ªÖÊîØÊåÅÁæ§ËÅä (‰ºöÂåπÈÖçgroup_chat_prefixÂíågroup_chat_keyword, ÊîØÊåÅËØ≠Èü≥Ëß¶ÂèëÁîªÂõæ)Ôºõ\n+ Ê∑ªÂä† `\"voice_reply_voice\": true` Â∞ÜÂºÄÂêØËØ≠Èü≥ÂõûÂ§çËØ≠Èü≥ÔºàÂêåÊó∂‰ΩúÁî®‰∫éÁßÅËÅäÂíåÁæ§ËÅäÔºâÔºå‰ΩÜÊòØÈúÄË¶ÅÈÖçÁΩÆÂØπÂ∫îËØ≠Èü≥ÂêàÊàêÂπ≥Âè∞ÁöÑkeyÔºåÁî±‰∫éitchatÂçèËÆÆÁöÑÈôêÂà∂ÔºåÂè™ËÉΩÂèëÈÄÅËØ≠Èü≥mp3Êñá‰ª∂ÔºåËã•‰ΩøÁî®wechatyÂàôÂõûÂ§çÁöÑÊòØÂæÆ‰ø°ËØ≠Èü≥„ÄÇ\n\n**4.ÂÖ∂‰ªñÈÖçÁΩÆ**\n\n+ `model`: Ê®°ÂûãÂêçÁß∞ÔºåÁõÆÂâçÊîØÊåÅ `gpt-3.5-turbo`, `text-davinci-003`, `gpt-4`, `gpt-4-32k`, `wenxin` , `claude` ,  `xunfei`(ÂÖ∂‰∏≠gpt-4 apiÊöÇÊú™ÂÆåÂÖ®ÂºÄÊîæÔºåÁî≥ËØ∑ÈÄöËøáÂêéÂèØ‰ΩøÁî®)\n+ `temperature`,`frequency_penalty`,`presence_penalty`: Chat APIÊé•Âè£ÂèÇÊï∞ÔºåËØ¶ÊÉÖÂèÇËÄÉ[OpenAIÂÆòÊñπÊñáÊ°£„ÄÇ](https://platform.openai.com/docs/api-reference/chat)\n+ `proxy`ÔºöÁî±‰∫éÁõÆÂâç `openai` Êé•Âè£ÂõΩÂÜÖÊó†Ê≥ïËÆøÈóÆÔºåÈúÄÈÖçÁΩÆ‰ª£ÁêÜÂÆ¢Êà∑Á´ØÁöÑÂú∞ÂùÄÔºåËØ¶ÊÉÖÂèÇËÄÉ  [#351](https://github.com/zhayujie/chatgpt-on-wechat/issues/351)\n+ ÂØπ‰∫éÂõæÂÉèÁîüÊàêÔºåÂú®Êª°Ë∂≥‰∏™‰∫∫ÊàñÁæ§ÁªÑËß¶ÂèëÊù°‰ª∂Â§ñÔºåËøòÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÂÖ≥ÈîÆËØçÂâçÁºÄÊù•Ëß¶ÂèëÔºåÂØπÂ∫îÈÖçÁΩÆ `image_create_prefix `\n+ ÂÖ≥‰∫éOpenAIÂØπËØùÂèäÂõæÁâáÊé•Âè£ÁöÑÂèÇÊï∞ÈÖçÁΩÆÔºàÂÜÖÂÆπËá™Áî±Â∫¶„ÄÅÂõûÂ§çÂ≠óÊï∞ÈôêÂà∂„ÄÅÂõæÁâáÂ§ßÂ∞èÁ≠âÔºâÔºåÂèØ‰ª•ÂèÇËÄÉ [ÂØπËØùÊé•Âè£](https://beta.openai.com/docs/api-reference/completions) Âíå [ÂõæÂÉèÊé•Âè£](https://beta.openai.com/docs/api-reference/completions)  ÊñáÊ°£ÔºåÂú®[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)‰∏≠Ê£ÄÊü•Âì™‰∫õÂèÇÊï∞Âú®Êú¨È°πÁõÆ‰∏≠ÊòØÂèØÈÖçÁΩÆÁöÑ„ÄÇ\n+ `conversation_max_tokens`ÔºöË°®Á§∫ËÉΩÂ§üËÆ∞ÂøÜÁöÑ‰∏ä‰∏ãÊñáÊúÄÂ§ßÂ≠óÊï∞Ôºà‰∏ÄÈóÆ‰∏ÄÁ≠î‰∏∫‰∏ÄÁªÑÂØπËØùÔºåÂ¶ÇÊûúÁ¥ØÁßØÁöÑÂØπËØùÂ≠óÊï∞Ë∂ÖÂá∫ÈôêÂà∂ÔºåÂ∞±‰ºö‰ºòÂÖàÁßªÈô§ÊúÄÊó©ÁöÑ‰∏ÄÁªÑÂØπËØùÔºâ\n+ `rate_limit_chatgpt`Ôºå`rate_limit_dalle`ÔºöÊØèÂàÜÈíüÊúÄÈ´òÈóÆÁ≠îÈÄüÁéá„ÄÅÁîªÂõæÈÄüÁéáÔºåË∂ÖÈÄüÂêéÊéíÈòüÊåâÂ∫èÂ§ÑÁêÜ„ÄÇ\n+ `clear_memory_commands`: ÂØπËØùÂÜÖÊåá‰ª§Ôºå‰∏ªÂä®Ê∏ÖÁ©∫ÂâçÊñáËÆ∞ÂøÜÔºåÂ≠óÁ¨¶‰∏≤Êï∞ÁªÑÂèØËá™ÂÆö‰πâÊåá‰ª§Âà´Âêç„ÄÇ\n+ `hot_reload`: Á®ãÂ∫èÈÄÄÂá∫ÂêéÔºåÊöÇÂ≠òÂæÆ‰ø°Êâ´Á†ÅÁä∂ÊÄÅÔºåÈªòËÆ§ÂÖ≥Èó≠„ÄÇ\n+ `character_desc` ÈÖçÁΩÆ‰∏≠‰øùÂ≠òÁùÄ‰Ω†ÂØπÊú∫Âô®‰∫∫ËØ¥ÁöÑ‰∏ÄÊÆµËØùÔºå‰ªñ‰ºöËÆ∞‰ΩèËøôÊÆµËØùÂπ∂‰Ωú‰∏∫‰ªñÁöÑËÆæÂÆöÔºå‰Ω†ÂèØ‰ª•‰∏∫‰ªñÂÆöÂà∂‰ªª‰Ωï‰∫∫Ê†º      (ÂÖ≥‰∫é‰ºöËØù‰∏ä‰∏ãÊñáÁöÑÊõ¥Â§öÂÜÖÂÆπÂèÇËÄÉËØ• [issue](https://github.com/zhayujie/chatgpt-on-wechat/issues/43))\n+ `subscribe_msg`ÔºöËÆ¢ÈòÖÊ∂àÊÅØÔºåÂÖ¨‰ºóÂè∑Âíå‰ºÅ‰∏öÂæÆ‰ø°channel‰∏≠ËØ∑Â°´ÂÜôÔºåÂΩìË¢´ËÆ¢ÈòÖÊó∂‰ºöËá™Âä®ÂõûÂ§çÔºå ÂèØ‰ΩøÁî®ÁâπÊÆäÂç†‰ΩçÁ¨¶„ÄÇÁõÆÂâçÊîØÊåÅÁöÑÂç†‰ΩçÁ¨¶Êúâ{trigger_prefix}ÔºåÂú®Á®ãÂ∫è‰∏≠ÂÆÉ‰ºöËá™Âä®ÊõøÊç¢ÊàêbotÁöÑËß¶ÂèëËØç„ÄÇ\n\n**5.LinkAIÈÖçÁΩÆ (ÂèØÈÄâ)**\n\n+ `use_linkai`: ÊòØÂê¶‰ΩøÁî®LinkAIÊé•Âè£ÔºåÂºÄÂêØÂêéÂèØÂõΩÂÜÖËÆøÈóÆÔºå‰ΩøÁî®Áü•ËØÜÂ∫ìÂíå `Midjourney` ÁªòÁîª, ÂèÇËÄÉ [ÊñáÊ°£](https://link-ai.tech/platform/link-app/wechat)\n+ `linkai_api_key`: LinkAI Api KeyÔºåÂèØÂú® [ÊéßÂà∂Âè∞](https://link-ai.tech/console/interface) ÂàõÂª∫\n+ `linkai_app_code`: LinkAI Â∫îÁî®codeÔºåÈÄâÂ°´\n\n**Êú¨ËØ¥ÊòéÊñáÊ°£ÂèØËÉΩ‰ºöÊú™ÂèäÊó∂Êõ¥Êñ∞ÔºåÂΩìÂâçÊâÄÊúâÂèØÈÄâÁöÑÈÖçÁΩÆÈ°πÂùáÂú®ËØ•[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)‰∏≠ÂàóÂá∫„ÄÇ**\n\n## ËøêË°å\n\n### 1.Êú¨Âú∞ËøêË°å\n\nÂ¶ÇÊûúÊòØÂºÄÂèëÊú∫ **Êú¨Âú∞ËøêË°å**ÔºåÁõ¥Êé•Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÊâßË°åÔºö\n\n```bash\npython3 app.py                                    # windowsÁéØÂ¢É‰∏ãËØ•ÂëΩ‰ª§ÈÄöÂ∏∏‰∏∫ python app.py\n```\n\nÁªàÁ´ØËæìÂá∫‰∫åÁª¥Á†ÅÂêéÔºå‰ΩøÁî®ÂæÆ‰ø°ËøõË°åÊâ´Á†ÅÔºåÂΩìËæìÂá∫ \"Start auto replying\" Êó∂Ë°®Á§∫Ëá™Âä®ÂõûÂ§çÁ®ãÂ∫èÂ∑≤ÁªèÊàêÂäüËøêË°å‰∫ÜÔºàÊ≥®ÊÑèÔºöÁî®‰∫éÁôªÂΩïÁöÑÂæÆ‰ø°ÈúÄË¶ÅÂú®ÊîØ‰ªòÂ§ÑÂ∑≤ÂÆåÊàêÂÆûÂêçËÆ§ËØÅÔºâ„ÄÇÊâ´Á†ÅÁôªÂΩïÂêé‰Ω†ÁöÑË¥¶Âè∑Â∞±Êàê‰∏∫Êú∫Âô®‰∫∫‰∫ÜÔºåÂèØ‰ª•Âú®ÂæÆ‰ø°ÊâãÊú∫Á´ØÈÄöËøáÈÖçÁΩÆÁöÑÂÖ≥ÈîÆËØçËß¶ÂèëËá™Âä®ÂõûÂ§ç (‰ªªÊÑèÂ•ΩÂèãÂèëÈÄÅÊ∂àÊÅØÁªô‰Ω†ÔºåÊàñÊòØËá™Â∑±ÂèëÊ∂àÊÅØÁªôÂ•ΩÂèã)ÔºåÂèÇËÄÉ[#142](https://github.com/zhayujie/chatgpt-on-wechat/issues/142)„ÄÇ\n\n### 2.ÊúçÂä°Âô®ÈÉ®ÁΩ≤\n\n‰ΩøÁî®nohupÂëΩ‰ª§Âú®ÂêéÂè∞ËøêË°åÁ®ãÂ∫èÔºö\n\n```bash\nnohup python3 app.py \u0026 tail -f nohup.out          # Âú®ÂêéÂè∞ËøêË°åÁ®ãÂ∫èÂπ∂ÈÄöËøáÊó•ÂøóËæìÂá∫‰∫åÁª¥Á†Å\n```\nÊâ´Á†ÅÁôªÂΩïÂêéÁ®ãÂ∫èÂç≥ÂèØËøêË°å‰∫éÊúçÂä°Âô®ÂêéÂè∞ÔºåÊ≠§Êó∂ÂèØÈÄöËøá `ctrl+c` ÂÖ≥Èó≠Êó•ÂøóÔºå‰∏ç‰ºöÂΩ±ÂìçÂêéÂè∞Á®ãÂ∫èÁöÑËøêË°å„ÄÇ‰ΩøÁî® `ps -ef | grep app.py | grep -v grep` ÂëΩ‰ª§ÂèØÊü•ÁúãËøêË°å‰∫éÂêéÂè∞ÁöÑËøõÁ®ãÔºåÂ¶ÇÊûúÊÉ≥Ë¶ÅÈáçÊñ∞ÂêØÂä®Á®ãÂ∫èÂèØ‰ª•ÂÖà `kill` ÊéâÂØπÂ∫îÁöÑËøõÁ®ã„ÄÇÊó•ÂøóÂÖ≥Èó≠ÂêéÂ¶ÇÊûúÊÉ≥Ë¶ÅÂÜçÊ¨°ÊâìÂºÄÂè™ÈúÄËæìÂÖ•¬†`tail -f nohup.out`„ÄÇÊ≠§Â§ñÔºå`scripts` ÁõÆÂΩï‰∏ãÊúâ‰∏ÄÈîÆËøêË°å„ÄÅÂÖ≥Èó≠Á®ãÂ∫èÁöÑËÑöÊú¨‰æõ‰ΩøÁî®„ÄÇ\n\n\u003e **Â§öË¥¶Âè∑ÊîØÊåÅÔºö** Â∞ÜÈ°πÁõÆÂ§çÂà∂Â§ö‰ªΩÔºåÂàÜÂà´ÂêØÂä®Á®ãÂ∫èÔºåÁî®‰∏çÂêåË¥¶Âè∑Êâ´Á†ÅÁôªÂΩïÂç≥ÂèØÂÆûÁé∞ÂêåÊó∂ËøêË°å„ÄÇ\n\n\u003e **ÁâπÊÆäÊåá‰ª§Ôºö** Áî®Êà∑ÂêëÊú∫Âô®‰∫∫ÂèëÈÄÅ **#reset** Âç≥ÂèØÊ∏ÖÁ©∫ËØ•Áî®Êà∑ÁöÑ‰∏ä‰∏ãÊñáËÆ∞ÂøÜ„ÄÇ\n\n\n### 3.DockerÈÉ®ÁΩ≤\n\n\u003e ‰ΩøÁî®dockerÈÉ®ÁΩ≤Êó†ÈúÄ‰∏ãËΩΩÊ∫êÁ†ÅÂíåÂÆâË£Ö‰æùËµñÔºåÂè™ÈúÄË¶ÅËé∑Âèñ docker-compose.yml ÈÖçÁΩÆÊñá‰ª∂Âπ∂ÂêØÂä®ÂÆπÂô®Âç≥ÂèØ„ÄÇ\n\n\u003e ÂâçÊèêÊòØÈúÄË¶ÅÂÆâË£ÖÂ•Ω `docker` Âèä `docker-compose`ÔºåÂÆâË£ÖÊàêÂäüÁöÑË°®Áé∞ÊòØÊâßË°å `docker -v` Âíå `docker-compose version` (Êàñ docker compose version) ÂèØ‰ª•Êü•ÁúãÂà∞ÁâàÊú¨Âè∑ÔºåÂèØÂâçÂæÄ [dockerÂÆòÁΩë](https://docs.docker.com/engine/install/) ËøõË°å‰∏ãËΩΩ„ÄÇ\n\n#### (1) ‰∏ãËΩΩ docker-compose.yml Êñá‰ª∂\n\n```bash\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n```\n\n‰∏ãËΩΩÂÆåÊàêÂêéÊâìÂºÄ `docker-compose.yml` ‰øÆÊîπÊâÄÈúÄÈÖçÁΩÆÔºåÂ¶Ç `OPEN_AI_API_KEY` Âíå `GROUP_NAME_WHITE_LIST` Á≠â„ÄÇ\n\n#### (2) ÂêØÂä®ÂÆπÂô®\n\nÂú® `docker-compose.yml` ÊâÄÂú®ÁõÆÂΩï‰∏ãÊâßË°å‰ª•‰∏ãÂëΩ‰ª§ÂêØÂä®ÂÆπÂô®Ôºö\n\n```bash\nsudo docker compose up -d\n```\n\nËøêË°å `sudo docker ps` ËÉΩÊü•ÁúãÂà∞ NAMES ‰∏∫ chatgpt-on-wechat ÁöÑÂÆπÂô®Âç≥Ë°®Á§∫ËøêË°åÊàêÂäü„ÄÇ\n\nÊ≥®ÊÑèÔºö\n\n - Â¶ÇÊûú `docker-compose` ÊòØ 1.X ÁâàÊú¨ ÂàôÈúÄË¶ÅÊâßË°å `sudo  docker-compose up -d` Êù•ÂêØÂä®ÂÆπÂô®\n - ËØ•ÂëΩ‰ª§‰ºöËá™Âä®Âéª [docker hub](https://hub.docker.com/r/zhayujie/chatgpt-on-wechat) ÊãâÂèñ latest ÁâàÊú¨ÁöÑÈïúÂÉèÔºålatest ÈïúÂÉè‰ºöÂú®ÊØèÊ¨°È°πÁõÆ release Êñ∞ÁöÑÁâàÊú¨Êó∂ÁîüÊàê\n\nÊúÄÂêéËøêË°å‰ª•‰∏ãÂëΩ‰ª§ÂèØÊü•ÁúãÂÆπÂô®ËøêË°åÊó•ÂøóÔºåÊâ´ÊèèÊó•Âøó‰∏≠ÁöÑ‰∫åÁª¥Á†ÅÂç≥ÂèØÂÆåÊàêÁôªÂΩïÔºö\n\n```bash\nsudo docker logs -f chatgpt-on-wechat\n```\n\n#### (3) Êèí‰ª∂‰ΩøÁî®\n\nÂ¶ÇÊûúÈúÄË¶ÅÂú®dockerÂÆπÂô®‰∏≠‰øÆÊîπÊèí‰ª∂ÈÖçÁΩÆÔºåÂèØÈÄöËøáÊåÇËΩΩÁöÑÊñπÂºèÂÆåÊàêÔºåÂ∞Ü [Êèí‰ª∂ÈÖçÁΩÆÊñá‰ª∂](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/plugins/config.json.template)\nÈáçÂëΩÂêç‰∏∫ `config.json`ÔºåÊîæÁΩÆ‰∫é `docker-compose.yml` Áõ∏ÂêåÁõÆÂΩï‰∏ãÔºåÂπ∂Âú® `docker-compose.yml` ‰∏≠ÁöÑ `chatgpt-on-wechat` ÈÉ®ÂàÜ‰∏ãÊ∑ªÂä† `volumes` Êò†Â∞Ñ:\n\n```\nvolumes:\n  - ./config.json:/app/plugins/config.json\n```\n\n### 4. RailwayÈÉ®ÁΩ≤\n\n\u003e Railway ÊØèÊúàÊèê‰æõ5ÂàÄÂíåÊúÄÂ§ö500Â∞èÊó∂ÁöÑÂÖçË¥πÈ¢ùÂ∫¶„ÄÇ (07.11Êõ¥Êñ∞: ÁõÆÂâçÂ§ßÈÉ®ÂàÜË¥¶Âè∑Â∑≤Êó†Ê≥ïÂÖçË¥πÈÉ®ÁΩ≤)\n\n1. ËøõÂÖ• [Railway](https://railway.app/template/qApznZ?referralCode=RC3znh)\n2. ÁÇπÂáª `Deploy Now` ÊåâÈíÆ„ÄÇ\n3. ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÊù•ÈáçËΩΩÁ®ãÂ∫èËøêË°åÁöÑÂèÇÊï∞Ôºå‰æãÂ¶Ç`open_ai_api_key`, `character_desc`„ÄÇ\n\n**‰∏ÄÈîÆÈÉ®ÁΩ≤:**\n  \n  [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/qApznZ?referralCode=RC3znh)\n\n## Â∏∏ËßÅÈóÆÈ¢ò\n\nFAQsÔºö \u003chttps://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs\u003e\n\nÊàñÁõ¥Êé•Âú®Á∫øÂí®ËØ¢ [È°πÁõÆÂ∞èÂä©Êâã](https://link-ai.tech/app/Kv2fXJcH)  (betaÁâàÊú¨ÔºåËØ≠ÊñôÂÆåÂñÑ‰∏≠ÔºåÂõûÂ§ç‰ªÖ‰æõÂèÇËÄÉ)\n\n## ÂºÄÂèë\n\nÊ¨¢ËøéÊé•ÂÖ•Êõ¥Â§öÂ∫îÁî®ÔºåÂèÇËÄÉ [Terminal‰ª£Á†Å](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/terminal/terminal_channel.py) ÂÆûÁé∞Êé•Êî∂ÂíåÂèëÈÄÅÊ∂àÊÅØÈÄªËæëÂç≥ÂèØÊé•ÂÖ•„ÄÇ ÂêåÊó∂Ê¨¢ËøéÂ¢ûÂä†Êñ∞ÁöÑÊèí‰ª∂ÔºåÂèÇËÄÉ [Êèí‰ª∂ËØ¥ÊòéÊñáÊ°£](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins)„ÄÇ\n\n## ËÅîÁ≥ª\n\nÊ¨¢ËøéÊèê‰∫§PR„ÄÅIssuesÔºå‰ª•ÂèäStarÊîØÊåÅ‰∏Ä‰∏ã„ÄÇÁ®ãÂ∫èËøêË°åÈÅáÂà∞ÈóÆÈ¢òÂèØ‰ª•Êü•Áúã [Â∏∏ËßÅÈóÆÈ¢òÂàóË°®](https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs) ÔºåÂÖ∂Ê¨°ÂâçÂæÄ [Issues](https://github.com/zhayujie/chatgpt-on-wechat/issues) ‰∏≠ÊêúÁ¥¢„ÄÇ‰∏™‰∫∫ÂºÄÂèëËÄÖÂèØÂä†ÂÖ•ÂºÄÊ∫ê‰∫§ÊµÅÁæ§ÂèÇ‰∏éÊõ¥Â§öËÆ®ËÆ∫Ôºå‰ºÅ‰∏öÁî®Êà∑ÂèØËÅîÁ≥ª[‰∫ßÂìÅÈ°æÈóÆ](https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg)Âí®ËØ¢„ÄÇ",
      "stars": 0,
      "updated_at": "2024-01-28T14:00:49Z",
      "url": "https://github.com/rsagacom/chatgpt-on-wechat"
    },
    "sammyl720--image-generator-mcp-server": {
      "category": "image-and-video-generation",
      "description": "Connects to OpenAI's DALL-E 3 model to generate images based on user prompts, saving the results to a specified directory on the user's desktop.",
      "forks": 7,
      "imageUrl": "/freedevtools/mcp/pfp/sammyl720.webp",
      "keywords": [
        "mcp",
        "openai",
        "generate",
        "generate images",
        "image generator",
        "mcp server"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "image-generator-mcp-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "sammyl720",
      "readme_content": "# image-generator MCP Server\n\nAn mcp server that generates images based on image prompts\n\nThis is a TypeScript-based MCP server that implements image generation using **OPENAI**'s `dall-e-3` image generation model.\n\n## Features\n\n### Tools\n- `generate_image` - Generate an image for given prompt\n  - Takes `prompt` as a required parameter\n  - Takes `imageName` as a required parameter to save the generated image in a `generated-images` directory on your desktop\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"command\": \"image-generator\",\n      \"env\": {\n        \"OPENAI_API_KEY\": \"\u003cyour-openai-api-key\u003e\"\n    }\n  }\n}\n```\nMake sure to replace `\u003cyour-openai-api-key\u003e` with your actual **OPENAI** Api Key.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
      "stars": 10,
      "updated_at": "2025-05-24T09:22:57Z",
      "url": "https://github.com/sammyl720/image-generator-mcp-server"
    },
    "sarthakkimtani--mcp-image-gen": {
      "category": "image-and-video-generation",
      "description": "Generates high-quality images from textual prompts with customizable dimensions using the Flux.1 Schnell model. Provides standardized interfaces for specifying image generation parameters and includes error handling features.",
      "forks": 6,
      "imageUrl": "/freedevtools/mcp/pfp/sarthakkimtani.webp",
      "keywords": [
        "generates",
        "images",
        "mcp",
        "image generation",
        "mcp image",
        "image gen"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp-image-gen",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "sarthakkimtani",
      "readme_content": "# Image Generation MCP Server\n\nA Model Context Protocol (MCP) server that enables seamless generation of high-quality images via Together AI. This server provides a standardized interface to specify image generation parameters.\n\n\u003ca href=\"https://glama.ai/mcp/servers/o0137xiz62\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/o0137xiz62/badge\" alt=\"Image Generation Server MCP server\" /\u003e\n\u003c/a\u003e\n\n## Features\n\n- High-quality image generation powered by the Flux.1 Schnell model\n- Support for customizable dimensions (width and height)\n- Clear error handling for prompt validation and API issues\n- Easy integration with MCP-compatible clients\n\n## Installation\n\n#### Claude Desktop\n\n- On MacOS: `~/Library/Application\\ Support/Claude/claude_desktop_config.json`\n- On Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n\u003csummary\u003eDevelopment/Unpublished Servers Configuration\u003c/summary\u003e\n\n```json\n{\n  \"mcpServers\": {\n    \"image-gen\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"/ABSOLUTE/PATH/TO/image-gen/\", \"run\", \"image-gen\"],\n      \"env\": {\n        \"TOGETHER_AI_API_KEY\": \"\u003cAPI KEY\u003e\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\nThe server implements one tool:\n\n### generate_image\n\nGenerates an image based on the given textual prompt and optional dimensions.\n\n**Input Schema:**\n\n```json\n{\n  \"prompt\": {\n    \"type\": \"string\",\n    \"description\": \"A descriptive prompt for generating the image (e.g., 'a futuristic cityscape at sunset')\"\n  },\n  \"width\": {\n    \"type\": \"integer\",\n    \"description\": \"Width of the generated image in pixels (optional)\"\n  },\n  \"height\": {\n    \"type\": \"integer\",\n    \"description\": \"Height of the generated image in pixels (optional)\"\n  },\n  \"model\": {\n    \"type\": \"string\",\n    \"description\": \"The exact model name as it appears in Together AI. If incorrect, it will fallback to the default model (black-forest-labs/FLUX.1-schnell).\"\n  }\n}\n```\n\n## Prerequisites\n\n- Python 3.12 or higher\n- httpx\n- mcp\n\n## Contributing\n\nContributions are welcome! Please follow these steps to contribute:\n\n1. Fork the repository\n2. Create a new branch (`feature/my-new-feature`)\n3. Commit your changes\n4. Push the branch to your fork\n5. Open a Pull Request\n\nFor significant changes, please open an issue first to discuss your proposed changes.\n\n## License\n\nThis project is licensed under the MIT License. See the LICENSE file for details.",
      "stars": 15,
      "updated_at": "2025-08-05T13:37:04Z",
      "url": "https://github.com/sarthakkimtani/mcp-image-gen"
    },
    "sshtunnelvision--MCP-LOGO-GEN": {
      "category": "image-and-video-generation",
      "description": "Logo generation using AI tools, including features for image creation, background removal, and automatic scaling for high-quality outputs in various sizes.",
      "forks": 17,
      "imageUrl": "/freedevtools/mcp/pfp/sshtunnelvision.webp",
      "keywords": [
        "logo",
        "mcp",
        "sshtunnelvision",
        "logo generation",
        "mcp logo",
        "logo gen"
      ],
      "language": "Python",
      "license": "GNU General Public License v3.0",
      "name": "MCP-LOGO-GEN",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "sshtunnelvision",
      "readme_content": "# MCP Tool Server for Logo Generation\n\nThis server provides logo generation capabilities using FAL AI, with tools for image generation, background removal, and automatic scaling.\n\n## Demo\n\n[![MCP Tool Server Demo](https://img.youtube.com/vi/Miemu1xEZng/0.jpg)](https://www.youtube.com/watch?v=Miemu1xEZng)\n\n## Installation\n\n1. Install `uv` (Universal Virtualenv):\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n2. Create and activate a virtual environment:\n\n```bash\nuv venv\nsource .venv/bin/activate  # On Unix/macOS\n# or\n.venv\\Scripts\\activate     # On Windows\n```\n\n3. Install dependencies:\n\n```bash\nuv pip install -r requirements.txt\n```\n\n4. Set up your environment variables:\n   - Create a `.env` file in the root directory\n   - Add your FAL AI API key:\n\n```bash\nFAL_KEY=your_fal_ai_key_here\n```\n\n## Running the Server\n\nStart the server with:\n\n```bash\npython run_server.py\n```\n\nThe server will be available at `http://127.0.0.1:7777`\n\n### Troubleshooting\n\nIf you encounter a `FileNotFoundError` on Windows when running the server, make sure you're running the command from the root directory of the project. If the issue persists, try updating to the latest version of the repository which includes fixes for Windows compatibility.\n\nFor Windows users specifically:\n\n1. Make sure you've activated your virtual environment with `.venv\\Scripts\\activate`\n2. Run the server from the root directory of the project with `python run_server.py`\n3. If you see any path-related errors, please report them in the issues section of the repository\n\n## Cursor IDE Configuration\n\n1. Open Cursor Settings\n2. Navigate to the MCP section\n3. Add the following configuration:\n   - URL: `http://127.0.0.1:7777/sse`\n   - Connection Type: `SSE`\n   - Enable the connection\n\n## Notes\n\n- Always reference `@logo-creation.mdc` in your Cursor Composer for consistent results\n- Steps are defined in `@logo-creation.mdc` but tools can be used independently\n- All generated logos will be saved in the `downloads` directory\n- Each logo is automatically generated in three sizes:\n  - Original size\n  - 32x32 pixels\n  - 128x128 pixels\n- All logos maintain transparency in their final PNG format\n- Prompts created by agent are informed by examples and prompt structure seen in server.py. You can customize the prompt structure by editing the server.py file.\n- You can use the generate_image tool to generate any image you want, not just logos\n\n## Requirements\n\n- Python 3.8+\n- FAL AI API key (required for image generation)\n- Active internet connection\n\n## References\n\n- [Cursor MCP Documentation](https://docs.cursor.com/context/model-context-protocol)\n- [Model Context Protocol Introduction](https://modelcontextprotocol.io/introduction)\n- [FAL AI Dashboard](https://fal.ai/dashboard)\n\n---\n\nIf you find this tool helpful, you can [buy me a coffee](https://buymeacoffee.com/sshtunnelvision) ‚òïÔ∏è to support development!\n",
      "stars": 171,
      "updated_at": "2025-08-18T06:34:36Z",
      "url": "https://github.com/sshtunnelvision/MCP-LOGO-GEN"
    },
    "stabgan--openrouter-mcp-multimodal": {
      "category": "image-and-video-generation",
      "description": "Combines text chat and image analysis capabilities to conduct multimodal conversations and handle custom queries seamlessly. Optimizes workflows with intelligent model selection and performance improvements.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/stabgan.webp",
      "keywords": [
        "multimodal",
        "conversations",
        "chat",
        "multimodal conversations",
        "mcp multimodal",
        "chat image"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "openrouter-mcp-multimodal",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "stabgan",
      "readme_content": "# OpenRouter MCP Multimodal Server\n\n[![Build Status](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml/badge.svg)](https://github.com/stabgan/openrouter-mcp-multimodal/actions/workflows/publish.yml)\n[![npm version](https://img.shields.io/npm/v/@stabgan/openrouter-mcp-multimodal.svg)](https://www.npmjs.com/package/@stabgan/openrouter-mcp-multimodal)\n[![Docker Pulls](https://img.shields.io/docker/pulls/stabgandocker/openrouter-mcp-multimodal.svg)](https://hub.docker.com/r/stabgandocker/openrouter-mcp-multimodal)\n\nAn MCP (Model Context Protocol) server that provides chat and image analysis capabilities through OpenRouter.ai's diverse model ecosystem. This server combines text chat functionality with powerful image analysis capabilities.\n\n## Features\n\n- **Text Chat:**\n  - Direct access to all OpenRouter.ai chat models\n  - Support for simple text and multimodal conversations\n  - Configurable temperature and other parameters\n\n- **Image Analysis:**\n  - Analyze single images with custom questions\n  - Process multiple images simultaneously \n  - Automatic image resizing and optimization\n  - Support for various image sources (local files, URLs, data URLs)\n\n- **Model Selection:**\n  - Search and filter available models\n  - Validate model IDs\n  - Get detailed model information\n  - Support for default model configuration\n\n- **Performance Optimization:**\n  - Smart model information caching\n  - Exponential backoff for retries\n  - Automatic rate limit handling\n\n## What's New in 1.5.0\n\n- **Improved OS Compatibility:**\n  - Enhanced path handling for Windows, macOS, and Linux\n  - Better support for Windows-style paths with drive letters\n  - Normalized path processing for consistent behavior across platforms\n\n- **MCP Configuration Support:**\n  - Cursor MCP integration without requiring environment variables\n  - Direct configuration via MCP parameters\n  - Flexible API key and model specification options\n\n- **Robust Error Handling:**\n  - Improved fallback mechanisms for image processing\n  - Better error reporting with specific diagnostics\n  - Multiple backup strategies for file reading\n\n- **Image Processing Enhancements:**\n  - More reliable base64 encoding for all image types\n  - Fallback options when Sharp module is unavailable\n  - Better handling of large images with automatic optimization\n\n## Installation\n\n### Option 1: Install via npm\n\n```bash\nnpm install -g @stabgan/openrouter-mcp-multimodal\n```\n\n### Option 2: Run via Docker\n\n```bash\ndocker run -i -e OPENROUTER_API_KEY=your-api-key-here stabgandocker/openrouter-mcp-multimodal:latest\n```\n\n## Quick Start Configuration\n\n### Prerequisites\n\n1. Get your OpenRouter API key from [OpenRouter Keys](https://openrouter.ai/keys)\n2. Choose a default model (optional)\n\n### MCP Configuration Options\n\nAdd one of the following configurations to your MCP settings file (e.g., `cline_mcp_settings.json` or `claude_desktop_config.json`):\n\n#### Option 1: Using npx (Node.js)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 2: Using uv (Python Package Manager)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"-m\",\n        \"openrouter_mcp_multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n#### Option 3: Using Docker\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\", \"OPENROUTER_API_KEY=your-api-key-here\",\n        \"-e\", \"DEFAULT_MODEL=qwen/qwen2.5-vl-32b-instruct:free\",\n        \"stabgandocker/openrouter-mcp-multimodal:latest\"\n      ]\n    }\n  }\n}\n```\n\n#### Option 4: Using Smithery (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"openrouter\": {\n      \"command\": \"smithery\",\n      \"args\": [\n        \"run\",\n        \"stabgan/openrouter-mcp-multimodal\"\n      ],\n      \"env\": {\n        \"OPENROUTER_API_KEY\": \"your-api-key-here\",\n        \"DEFAULT_MODEL\": \"qwen/qwen2.5-vl-32b-instruct:free\"\n      }\n    }\n  }\n}\n```\n\n## Examples\n\nFor comprehensive examples of how to use this MCP server, check out the [examples directory](./examples/). We provide:\n\n- JavaScript examples for Node.js applications\n- Python examples with interactive chat capabilities\n- Code snippets for integrating with various applications\n\nEach example comes with clear documentation and step-by-step instructions.\n\n## Dependencies\n\nThis project uses the following key dependencies:\n\n- `@modelcontextprotocol/sdk`: ^1.8.0 - Latest MCP SDK for tool implementation\n- `openai`: ^4.89.1 - OpenAI-compatible API client for OpenRouter\n- `sharp`: ^0.33.5 - Fast image processing library\n- `axios`: ^1.8.4 - HTTP client for API requests\n- `node-fetch`: ^3.3.2 - Modern fetch implementation\n\nNode.js 18 or later is required. All dependencies are regularly updated to ensure compatibility and security.\n\n## Available Tools\n\n### mcp_openrouter_chat_completion\n\nSend text or multimodal messages to OpenRouter models:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"google/gemini-2.5-pro-exp-03-25:free\", // Optional if default is set\n    messages: [\n      {\n        role: \"system\",\n        content: \"You are a helpful assistant.\"\n      },\n      {\n        role: \"user\",\n        content: \"What is the capital of France?\"\n      }\n    ],\n    temperature: 0.7 // Optional, defaults to 1.0\n  }\n});\n```\n\nFor multimodal messages with images:\n\n```javascript\nuse_mcp_tool({\n  server_name: \"openrouter\",\n  tool_name: \"mcp_openrouter_chat_completion\",\n  arguments: {\n    model: \"anthropic/claude-3.5-sonnet\",\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          {\n            type: \"text\",\n            text: \"What's in this image?\"\n          },\n          {\n            type: \"image_url\",\n            image_url: {\n              url: \"https://example.com/image.jpg\"\n            }\n          }\n        ]\n      }\n    ]\n  }\n});\n```",
      "stars": 10,
      "updated_at": "2025-09-05T07:28:32Z",
      "url": "https://github.com/stabgan/openrouter-mcp-multimodal"
    },
    "surferdot--mcp-svg-converter": {
      "category": "image-and-video-generation",
      "description": "Converts SVG code to high-quality PNG and JPG images while providing options for transparency and image quality customization. Enhances image processing by allowing transformation of vector graphics into raster formats with detailed settings.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/surferdot.webp",
      "keywords": [
        "svg",
        "png",
        "surferdot",
        "svg converter",
        "converts svg",
        "mcp svg"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp-svg-converter",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "surferdot",
      "readme_content": "# MCP SVG Converter\n\n[![npm version](https://img.shields.io/npm/v/mcp-svg-converter.svg)](https://www.npmjs.com/package/mcp-svg-converter)\n[![Downloads](https://img.shields.io/npm/dt/mcp-svg-converter.svg)](https://www.npmjs.com/package/mcp-svg-converter)\n[![License](https://img.shields.io/npm/l/mcp-svg-converter.svg)](https://github.com/surferdot/mcp-svg-converter/blob/main/LICENSE)\n\n[English](#english) | [‰∏≠Êñá](#‰∏≠Êñá)\n\n\u003ca name=\"english\"\u003e\u003c/a\u003e\n## English\n\nA Model Context Protocol (MCP) server that provides tools for converting SVG code to high-quality PNG and JPG images with detailed customization options.\n\n### Features\n\n- Convert SVG code to high-quality PNG images with transparency support\n- Convert SVG code to high-quality JPG images with customizable quality settings\n- Automatic dimension detection and preservation from original SVG\n- Support for scaling to higher resolutions\n- Background color customization\n- Intelligent path handling with automatic redirection to allowed directories\n- Secure file system access with configurable permissions\n\n### Installation\n\n#### Quick Install with npx\n\n```bash\nnpx mcp-svg-converter /path/to/allowed/directory\n```\n\n#### Global Installation\n\n```bash\nnpm install -g mcp-svg-converter\nmcp-svg-converter /path/to/allowed/directory\n```\n\n#### From Source\n\n##### Prerequisites\n\n- Node.js 16 or higher\n- npm or yarn\n\n##### Installation Steps\n\n1. Clone this repository\n   ```bash\n   git clone https://github.com/surferdot/mcp-svg-converter.git\n   cd mcp-svg-converter\n   ```\n\n2. Install dependencies\n   ```bash\n   npm install\n   ```\n\n3. Build the project\n   ```bash\n   npm run build\n   ```\n\n### Usage\n\n#### As a standalone server\n\nRun the server by specifying one or more allowed directories where the converted images can be saved:\n\n```bash\nnode build/index.js /path/to/allowed/directory1 /path/to/allowed/directory2\n```\n\n#### With Claude Desktop\n\n1. Download and install [Claude Desktop](https://claude.ai/download)\n2. Create or confirm you have access to an output directory:\n   ```bash\n   # macOS/Linux\n   mkdir -p ~/Desktop/svg-output\n   \n   # Windows\n   mkdir \"%USERPROFILE%\\Desktop\\svg-output\"\n   ```\n\n3. Configure Claude Desktop by editing the configuration file:\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n4. Open the Claude app, click on the Claude menu in your system menu bar and select \"Settings...\"\n5. Click on \"Developer\" in the left sidebar\n6. Click \"Edit Config\" to open the configuration file\n\n7. Add this server configuration:\n\n##### Using npm package with npx (recommended)\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### Using global installation\n\nIf you've installed the package globally:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"mcp-svg-converter\",\n      \"args\": [\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### Using local build\n\nIf you've built from source:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-svg-converter/build/index.js\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n8. Save the file and restart Claude Desktop\n\n#### Verifying the Setup\n\nWhen Claude Desktop restarts, if configured correctly:\n\n1. You should see a hammer icon \u003cimg src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-hammer-icon.svg\" style=\"display: inline; height: 1.3em; vertical-align: middle\"\u003e at the bottom right of the input box indicating MCP tools are available.\n2. Clicking the hammer icon should show the `svg-to-png` and `svg-to-jpg` tools.\n\n### Examples in Claude Desktop\n\n#### Example 1: Converting a Simple SVG to PNG\n\nIn Claude Desktop, send a message like:\n\n```\nPlease convert this SVG to PNG and save it to my output directory:\n\n\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 100\" width=\"200\" height=\"100\"\u003e\n  \u003crect x=\"10\" y=\"10\" width=\"80\" height=\"80\" fill=\"#4285f4\" /\u003e\n  \u003ccircle cx=\"140\" cy=\"50\" r=\"40\" fill=\"#ea4335\" /\u003e\n  \u003cpath d=\"M10 50 L90 50 L50 90 Z\" fill=\"#fbbc05\" /\u003e\n  \u003ctext x=\"100\" y=\"20\" font-family=\"Arial\" font-size=\"12\" text-anchor=\"middle\" fill=\"#34a853\"\u003eSVG Example\u003c/text\u003e\n\u003c/svg\u003e\n```\n\n#### Example 2: High-Quality JPG Conversion\n\n```\nPlease convert this SVG to a JPG with 95% quality and 2x scaling:\n\n\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\"\u003e\n  \u003crect width=\"200\" height=\"200\" fill=\"#f0f0f0\" /\u003e\n  \u003ccircle cx=\"100\" cy=\"100\" r=\"80\" fill=\"#ff6b6b\" /\u003e\n  \u003cpath d=\"M100 50 L130 150 L70 150 Z\" fill=\"white\" /\u003e\n\u003c/svg\u003e\n```\n\n### Tools\n\n#### svg-to-png\n\nConverts SVG code to a high-quality PNG image with transparency support.\n\n**Parameters:**\n- `svgCode` (string, required): The SVG code to convert\n- `outputPath` (string, required): Path where the PNG file should be saved\n- `backgroundColor` (string, optional): Background color (default: transparent)\n- `scale` (number, optional): Scale factor for higher resolution (default: 1)\n\n#### svg-to-jpg\n\nConverts SVG code to a high-quality JPG image.\n\n**Parameters:**\n- `svgCode` (string, required): The SVG code to convert\n- `outputPath` (string, required): Path where the JPG file should be saved\n- `backgroundColor` (string, optional): Background color (default: white)\n- `quality` (number, optional): JPEG quality from 1-100 (default: 90)\n- `scale` (number, optional): Scale factor for higher resolution (default: 1)\n\n### Advanced Usage Tips\n\n#### Specifying Multiple Output Directories\n\nYou can specify multiple allowed output directories for more flexible file saving:\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/Users/yourusername/Desktop/svg-output\",\n        \"/Users/yourusername/Documents/svg-images\",\n        \"/Users/yourusername/Downloads\"\n      ]\n    }\n  }\n}\n```\n\n#### Using Custom Output Filenames\n\nSpecify detailed file paths in your request:\n\n```\nPlease convert this SVG to PNG, and save it as \"colorful_shapes.png\" in my output directory.\n\n\u003csvg\u003e...\u003c/svg\u003e\n```\n\n#### Automatic Path Redirection\n\nIf you request saving to a non-allowed directory, the converter automatically redirects to an allowed directory and informs you of the actual save location.\n\n### Troubleshooting\n\n#### Claude Doesn't Show MCP Tools Icon\n1. Verify the configuration file has correct JSON syntax\n2. Ensure all paths are absolute paths\n3. Make sure output directories exist and are writable\n4. Completely exit and restart Claude Desktop\n5. Check Claude logs:\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n#### Tool Execution Fails\n1. Ensure `mcp-svg-converter` is correctly installed\n2. Check output directory permissions\n3. Verify the SVG code is valid\n4. Check Claude logs for detailed error messages\n\n#### \"Command Not Found\" Error\n1. Ensure `mcp-svg-converter` is globally installed or correctly reference `npx`\n2. Confirm npm's global bin directory is in your PATH\n3. Try using full paths in configuration\n\n### Debugging\n\nYou can use the MCP Inspector to debug and test the server directly:\n\n```bash\nnpx @modelcontextprotocol/inspector npx mcp-svg-converter /path/to/allowed/directory\n```\n\nThis opens an interactive interface where you can test all available tools without going through Claude Desktop.\n\n### Security Considerations\n\n- The server will only write files to the directories specified when starting the server\n- If a user attempts to save to a non-allowed directory, the file will be automatically redirected to an allowed directory\n- Path traversal attacks are prevented by proper path validation\n\n### License\n\nMIT\n\n---\n\n\u003ca name=\"‰∏≠Êñá\"\u003e\u003c/a\u003e\n## ‰∏≠Êñá\n\nMCP SVG ËΩ¨Êç¢Âô®ÊòØ‰∏Ä‰∏™Âü∫‰∫éÊ®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆ (MCP) ÁöÑÊúçÂä°Âô®ÔºåÊèê‰æõÂ∞Ü SVG ‰ª£Á†ÅËΩ¨Êç¢‰∏∫È´òË¥®Èáè PNG Âíå JPG ÂõæÂÉèÁöÑÂ∑•ÂÖ∑ÔºåÊîØÊåÅËØ¶ÁªÜÁöÑËá™ÂÆö‰πâÈÄâÈ°π„ÄÇ\n\n### ÁâπÁÇπ\n\n- Â∞Ü SVG ‰ª£Á†ÅËΩ¨Êç¢‰∏∫ÊîØÊåÅÈÄèÊòéÂ∫¶ÁöÑÈ´òË¥®Èáè PNG ÂõæÂÉè\n- Â∞Ü SVG ‰ª£Á†ÅËΩ¨Êç¢‰∏∫ÂèØÂÆöÂà∂Ë¥®ÈáèËÆæÁΩÆÁöÑÈ´òË¥®Èáè JPG ÂõæÂÉè\n- Ëá™Âä®Ê£ÄÊµãÂπ∂‰øùÁïôÂéüÂßã SVG ÁöÑÂ∞∫ÂØ∏\n- ÊîØÊåÅÁº©ÊîæÂà∞Êõ¥È´òÂàÜËæ®Áéá\n- ÂèØËá™ÂÆö‰πâËÉåÊôØÈ¢úËâ≤\n- Êô∫ËÉΩË∑ØÂæÑÂ§ÑÁêÜÔºåËá™Âä®ÈáçÂÆöÂêëÂà∞ÂÖÅËÆ∏ÁöÑÁõÆÂΩï\n- ÂèØÈÖçÁΩÆÊùÉÈôêÁöÑÂÆâÂÖ®Êñá‰ª∂Á≥ªÁªüËÆøÈóÆ\n\n### ÂÆâË£Ö\n\n#### ‰ΩøÁî® npx Âø´ÈÄüÂÆâË£Ö\n\n```bash\nnpx mcp-svg-converter /path/to/allowed/directory\n```\n\n#### ÂÖ®Â±ÄÂÆâË£Ö\n\n```bash\nnpm install -g mcp-svg-converter\nmcp-svg-converter /path/to/allowed/directory\n```\n\n#### ‰ªéÊ∫ê‰ª£Á†ÅÂÆâË£Ö\n\n##### ÂâçÊèêÊù°‰ª∂\n\n- Node.js 16 ÊàñÊõ¥È´òÁâàÊú¨\n- npm Êàñ yarn\n\n##### ÂÆâË£ÖÊ≠•È™§\n\n1. ÂÖãÈöÜÊ≠§‰ªìÂ∫ì\n   ```bash\n   git clone https://github.com/surferdot/mcp-svg-converter.git\n   cd mcp-svg-converter\n   ```\n\n2. ÂÆâË£Ö‰æùËµñ\n   ```bash\n   npm install\n   ```\n\n3. ÊûÑÂª∫È°πÁõÆ\n   ```bash\n   npm run build\n   ```\n\n### ‰ΩøÁî®ÊñπÊ≥ï\n\n#### ‰Ωú‰∏∫Áã¨Á´ãÊúçÂä°Âô®ËøêË°å\n\nÈÄöËøáÊåáÂÆö‰∏Ä‰∏™ÊàñÂ§ö‰∏™ÂÖÅËÆ∏Â≠òÂÇ®ËΩ¨Êç¢ÂêéÂõæÂÉèÁöÑÁõÆÂΩïÊù•ËøêË°åÊúçÂä°Âô®Ôºö\n\n```bash\nnode build/index.js /path/to/allowed/directory1 /path/to/allowed/directory2\n```\n\n#### ‰∏é Claude Desktop ‰∏ÄËµ∑‰ΩøÁî®\n\n1. ‰∏ãËΩΩÂπ∂ÂÆâË£Ö [Claude Desktop](https://claude.ai/download)\n2. ÂàõÂª∫ÊàñÁ°ÆËÆ§‰Ω†ÊúâÊùÉÈôêËÆøÈóÆÁöÑËæìÂá∫ÁõÆÂΩïÔºö\n   ```bash\n   # macOS/Linux\n   mkdir -p ~/Desktop/svg-output\n   \n   # Windows\n   mkdir \"%USERPROFILE%\\Desktop\\svg-output\"\n   ```\n\n3. ÈÖçÁΩÆ Claude DesktopÔºö\n   - ÊâìÂºÄ Claude Â∫îÁî®Á®ãÂ∫è\n   - ÁÇπÂáªÁ≥ªÁªüËèúÂçïÊ†è‰∏≠ÁöÑ Claude ÂõæÊ†á\n   - ÈÄâÊã©\"Settings...\"ÔºàËÆæÁΩÆÔºâ\n   - Âú®Â∑¶‰æßËèúÂçï‰∏≠ÈÄâÊã©\"Developer\"ÔºàÂºÄÂèëËÄÖÔºâ\n   - ÁÇπÂáª\"Edit Config\"ÔºàÁºñËæëÈÖçÁΩÆÔºâÊåâÈíÆ\n\n4. ÁºñËæëÈÖçÁΩÆÊñá‰ª∂Ôºö\n   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n   - Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n\n5. Ê∑ªÂä†ÊúçÂä°Âô®ÈÖçÁΩÆÔºö\n\n##### ‰ΩøÁî® npm ÂåÖ‰∏é npxÔºàÊé®ËçêÔºâ\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### ‰ΩøÁî®ÂÖ®Â±ÄÂÆâË£Ö\n\nÂ¶ÇÊûú‰Ω†Â∑≤ÂÖ®Â±ÄÂÆâË£Ö‰∫ÜÊ≠§ÂåÖÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"mcp-svg-converter\",\n      \"args\": [\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n##### ‰ΩøÁî®Êú¨Âú∞ÊûÑÂª∫\n\nÂ¶ÇÊûú‰Ω†‰ªéÊ∫ê‰ª£Á†ÅÊûÑÂª∫Ôºö\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/mcp-svg-converter/build/index.js\",\n        \"/absolute/path/to/output/directory\"\n      ]\n    }\n  }\n}\n```\n\n6. ‰øùÂ≠òÊñá‰ª∂Âπ∂ÈáçÂêØ Claude Desktop\n\n#### È™åËØÅËÆæÁΩÆ\n\nÂΩì Claude Desktop ÈáçÂêØÂêéÔºåÂ¶ÇÊûúÈÖçÁΩÆÊ≠£Á°ÆÔºö\n\n1. ‰Ω†Â∫îËØ•Âú®ËæìÂÖ•Ê°ÜÂè≥‰∏ãËßíÁúãÂà∞‰∏Ä‰∏™Èî§Â≠êÂõæÊ†á \u003cimg src=\"https://mintlify.s3.us-west-1.amazonaws.com/mcp/images/claude-desktop-mcp-hammer-icon.svg\" style=\"display: inline; height: 1.3em; vertical-align: middle\"\u003eÔºåË°®Á§∫ MCP Â∑•ÂÖ∑ÂèØÁî®„ÄÇ\n2. ÁÇπÂáªÈî§Â≠êÂõæÊ†áÂ∫îÊòæÁ§∫ `svg-to-png` Âíå `svg-to-jpg` Â∑•ÂÖ∑„ÄÇ\n\n### Claude Desktop ‰∏≠ÁöÑ‰ΩøÁî®Á§∫‰æã\n\n#### Á§∫‰æã 1ÔºöÂ∞ÜÁÆÄÂçï SVG ËΩ¨Êç¢‰∏∫ PNG\n\nÂú® Claude Desktop ‰∏≠ÂèëÈÄÅ‰ª•‰∏ãÊ∂àÊÅØÔºö\n\n```\nËØ∑Â∞ÜËøô‰∏™ SVG ËΩ¨Êç¢‰∏∫ PNG Âπ∂‰øùÂ≠òÂà∞ÊàëÁöÑËæìÂá∫ÁõÆÂΩïÔºö\n\n\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 100\" width=\"200\" height=\"100\"\u003e\n  \u003crect x=\"10\" y=\"10\" width=\"80\" height=\"80\" fill=\"#4285f4\" /\u003e\n  \u003ccircle cx=\"140\" cy=\"50\" r=\"40\" fill=\"#ea4335\" /\u003e\n  \u003cpath d=\"M10 50 L90 50 L50 90 Z\" fill=\"#fbbc05\" /\u003e\n  \u003ctext x=\"100\" y=\"20\" font-family=\"Arial\" font-size=\"12\" text-anchor=\"middle\" fill=\"#34a853\"\u003eSVG Á§∫‰æã\u003c/text\u003e\n\u003c/svg\u003e\n```\n\n#### Á§∫‰æã 2ÔºöÈ´òË¥®Èáè JPG ËΩ¨Êç¢\n\n```\nËØ∑Â∞ÜËøô‰∏™ SVG ËΩ¨Êç¢‰∏∫ 95% Ë¥®ÈáèÂíå 2 ÂÄçÁº©ÊîæÁöÑ JPG ÂõæÂÉèÔºö\n\n\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 200 200\"\u003e\n  \u003crect width=\"200\" height=\"200\" fill=\"#f0f0f0\" /\u003e\n  \u003ccircle cx=\"100\" cy=\"100\" r=\"80\" fill=\"#ff6b6b\" /\u003e\n  \u003cpath d=\"M100 50 L130 150 L70 150 Z\" fill=\"white\" /\u003e\n\u003c/svg\u003e\n```\n\n### Â∑•ÂÖ∑\n\n#### svg-to-png\n\nÂ∞Ü SVG ‰ª£Á†ÅËΩ¨Êç¢‰∏∫ÊîØÊåÅÈÄèÊòéÂ∫¶ÁöÑÈ´òË¥®Èáè PNG ÂõæÂÉè„ÄÇ\n\n**ÂèÇÊï∞Ôºö**\n- `svgCode` (Â≠óÁ¨¶‰∏≤ÔºåÂøÖÈúÄ)ÔºöË¶ÅËΩ¨Êç¢ÁöÑ SVG ‰ª£Á†Å\n- `outputPath` (Â≠óÁ¨¶‰∏≤ÔºåÂøÖÈúÄ)ÔºöPNG Êñá‰ª∂ÁöÑ‰øùÂ≠òË∑ØÂæÑ\n- `backgroundColor` (Â≠óÁ¨¶‰∏≤ÔºåÂèØÈÄâ)ÔºöËÉåÊôØÈ¢úËâ≤ (ÈªòËÆ§ÔºöÈÄèÊòé)\n- `scale` (Êï∞Â≠óÔºåÂèØÈÄâ)ÔºöÊõ¥È´òÂàÜËæ®ÁéáÁöÑÁº©ÊîæÂõ†Â≠ê (ÈªòËÆ§Ôºö1)\n\n#### svg-to-jpg\n\nÂ∞Ü SVG ‰ª£Á†ÅËΩ¨Êç¢‰∏∫È´òË¥®Èáè JPG ÂõæÂÉè„ÄÇ\n\n**ÂèÇÊï∞Ôºö**\n- `svgCode` (Â≠óÁ¨¶‰∏≤ÔºåÂøÖÈúÄ)ÔºöË¶ÅËΩ¨Êç¢ÁöÑ SVG ‰ª£Á†Å\n- `outputPath` (Â≠óÁ¨¶‰∏≤ÔºåÂøÖÈúÄ)ÔºöJPG Êñá‰ª∂ÁöÑ‰øùÂ≠òË∑ØÂæÑ\n- `backgroundColor` (Â≠óÁ¨¶‰∏≤ÔºåÂèØÈÄâ)ÔºöËÉåÊôØÈ¢úËâ≤ (ÈªòËÆ§ÔºöÁôΩËâ≤)\n- `quality` (Êï∞Â≠óÔºåÂèØÈÄâ)ÔºöJPEG Ë¥®ÈáèÔºåËåÉÂõ¥‰ªé 1 Âà∞ 100 (ÈªòËÆ§Ôºö90)\n- `scale` (Êï∞Â≠óÔºåÂèØÈÄâ)ÔºöÊõ¥È´òÂàÜËæ®ÁéáÁöÑÁº©ÊîæÂõ†Â≠ê (ÈªòËÆ§Ôºö1)\n\n### È´òÁ∫ß‰ΩøÁî®ÊäÄÂ∑ß\n\n#### ÊåáÂÆöÂ§ö‰∏™ËæìÂá∫ÁõÆÂΩï\n\n‰Ω†ÂèØ‰ª•ÊåáÂÆöÂ§ö‰∏™ÂÖÅËÆ∏ÁöÑËæìÂá∫ÁõÆÂΩïÔºå‰ª•Êèê‰æõÊõ¥ÁÅµÊ¥ªÁöÑÊñá‰ª∂‰øùÂ≠òÈÄâÈ°πÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"svg-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-svg-converter\",\n        \"/Users/yourusername/Desktop/svg-output\",\n        \"/Users/yourusername/Documents/svg-images\",\n        \"/Users/yourusername/Downloads\"\n      ]\n    }\n  }\n}\n```\n\n#### ‰ΩøÁî®Ëá™ÂÆö‰πâËæìÂá∫Êñá‰ª∂Âêç\n\nÂú®ËØ∑Ê±Ç‰∏≠ÊåáÂÆöËØ¶ÁªÜÁöÑÊñá‰ª∂Ë∑ØÂæÑÔºö\n\n```\nËØ∑Â∞ÜËøô‰∏™ SVG ËΩ¨Êç¢‰∏∫ PNGÔºåÂπ∂‰ª•Êñá‰ª∂Âêç \"colorful_shapes.png\" ‰øùÂ≠òÂà∞ËæìÂá∫ÁõÆÂΩï„ÄÇ\n\n\u003csvg\u003e...\u003c/svg\u003e\n```\n\n#### Ëá™Âä®Ë∑ØÂæÑÈáçÂÆöÂêë\n\nÂ¶ÇÊûú‰Ω†ËØ∑Ê±Ç‰øùÂ≠òÂà∞‰∏Ä‰∏™‰∏çÂÖÅËÆ∏ÁöÑÁõÆÂΩïÔºåËΩ¨Êç¢Âô®‰ºöËá™Âä®Â∞ÜÊñá‰ª∂ÈáçÂÆöÂêëÂà∞ÂÖÅËÆ∏ÁöÑÁõÆÂΩïÔºåÂπ∂Âú®ÂìçÂ∫î‰∏≠ÂëäÁü•‰Ω†ÂÆûÈôÖÁöÑ‰øùÂ≠ò‰ΩçÁΩÆ„ÄÇ\n\n### ÊïÖÈöúÊéíÈô§\n\n#### Claude Ê≤°ÊúâÊòæÁ§∫ MCP Â∑•ÂÖ∑ÂõæÊ†á\n1. Á°ÆËÆ§ÈÖçÁΩÆÊñá‰ª∂Ê†ºÂºèÊ≠£Á°ÆÔºàJSON ËØ≠Ê≥ïÔºâ\n2. Ê£ÄÊü•ÊâÄÊúâË∑ØÂæÑÊòØÂê¶‰∏∫ÁªùÂØπË∑ØÂæÑ\n3. Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®‰∏îÂèØÂÜô\n4. ÂÆåÂÖ®ÈÄÄÂá∫Âπ∂ÈáçÂêØ Claude Desktop\n5. Ê£ÄÊü• Claude Êó•ÂøóÔºö\n   - macOS: `~/Library/Logs/Claude/mcp*.log`\n   - Windows: `%APPDATA%\\Claude\\logs\\mcp*.log`\n\n#### Â∑•ÂÖ∑ÊâßË°åÂ§±Ë¥•\n1. Á°Æ‰øùÂ∑≤Ê≠£Á°ÆÂÆâË£Ö `mcp-svg-converter`\n2. Ê£ÄÊü•ËæìÂá∫ÁõÆÂΩïÁöÑÊùÉÈôê\n3. È™åËØÅ SVG ‰ª£Á†ÅÊòØÂê¶ÊúâÊïà\n4. Ê£ÄÊü• Claude Êó•Âøó‰∫ÜËß£ËØ¶ÁªÜÈîôËØØ‰ø°ÊÅØ\n\n#### \"command not found\" ÈîôËØØ\n1. Á°Æ‰øùÂ∑≤ÂÖ®Â±ÄÂÆâË£Ö `mcp-svg-converter` ÊàñÊ≠£Á°ÆÂºïÁî® `npx`\n2. Á°ÆËÆ§ npm ÁöÑÂÖ®Â±Ä bin ÁõÆÂΩïÂú®Á≥ªÁªü PATH ‰∏≠\n3. Â∞ùËØïÂú®ÈÖçÁΩÆ‰∏≠‰ΩøÁî®ÂÆåÊï¥Ë∑ØÂæÑ\n\n### Ë∞ÉËØï\n\nÊÇ®ÂèØ‰ª•‰ΩøÁî® MCP Inspector Áõ¥Êé•Ë∞ÉËØïÂíåÊµãËØïÊúçÂä°Âô®Ôºö\n\n```bash\nnpx @modelcontextprotocol/inspector npx mcp-svg-converter /path/to/allowed/directory\n```\n\nËøôÂ∞ÜÊâìÂºÄ‰∏Ä‰∏™‰∫§‰∫íÂºèÁïåÈù¢Ôºå‰Ω†ÂèØ‰ª•Âú®ÂÖ∂‰∏≠ÊµãËØïÊâÄÊúâÂèØÁî®Â∑•ÂÖ∑ÔºåËÄåÊó†ÈúÄÈÄöËøá Claude Desktop„ÄÇ\n\n### ÂÆâÂÖ®ËÄÉËôë\n\n- ÊúçÂä°Âô®Âè™‰ºöÂ∞ÜÊñá‰ª∂ÂÜôÂÖ•ÂêØÂä®ÊúçÂä°Âô®Êó∂ÊåáÂÆöÁöÑÁõÆÂΩï\n- Â¶ÇÊûúÁî®Êà∑Â∞ùËØï‰øùÂ≠òÂà∞ÈùûÂÖÅËÆ∏ÁõÆÂΩïÔºåÊñá‰ª∂Â∞ÜËá™Âä®ÈáçÂÆöÂêëÂà∞ÂÖÅËÆ∏ÁöÑÁõÆÂΩï\n- ÈÄöËøáÈÄÇÂΩìÁöÑË∑ØÂæÑÈ™åËØÅÈò≤Ê≠¢Ë∑ØÂæÑÈÅçÂéÜÊîªÂáª\n\n### ËÆ∏ÂèØËØÅ\n\nMIT\n",
      "stars": 3,
      "updated_at": "2025-09-17T13:58:17Z",
      "url": "https://github.com/surferdot/mcp-svg-converter"
    },
    "techkwon--mcp-gemini": {
      "category": "image-and-video-generation",
      "description": "Leverages Google's Gemini API to generate text, create and analyze images, perform video analysis on YouTube content, and conduct web searches. Provides a range of advanced AI functionalities for various applications.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/techkwon.webp",
      "keywords": [
        "ai",
        "gemini",
        "youtube",
        "google gemini",
        "gemini api",
        "mcp gemini"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "mcp-gemini",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "techkwon",
      "readme_content": "# MCP Gemini API ÏÑúÎ≤Ñ\n\nCursorÏôÄ ClaudeÎ•º ÏúÑÌïú Google Gemini API ÏÑúÎ≤ÑÏûÖÎãàÎã§. ÌÖçÏä§Ìä∏ ÏÉùÏÑ±, Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù, ÎπÑÎîîÏò§ Î∂ÑÏÑù Îì± GeminiÏùò Îã§ÏñëÌïú Í∏∞Îä•ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§.\n\n## Ï£ºÏöî Í∏∞Îä•\n\n- ÌÖçÏä§Ìä∏ ÏÉùÏÑ± (gemini-2.0-flash Î™®Îç∏ ÏÇ¨Ïö©)\n- Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± Î∞è Î∂ÑÏÑù\n- YouTube ÎπÑÎîîÏò§ Î∂ÑÏÑù\n- Ïõπ Í≤ÄÏÉâ\n\n## ÏãúÏûëÌïòÍ∏∞\n\n### ÌïÑÏàò ÏöîÍµ¨ÏÇ¨Ìï≠\n\n- Node.js 18.0.0 Ïù¥ÏÉÅ\n- npm ÎòêÎäî yarn\n- Google API ÌÇ§ (Gemini API Ï†ëÍ∑ºÏö©)\n\n### ÏÑ§Ïπò\n\n```bash\n# Ï†ÄÏû•ÏÜå ÌÅ¥Î°†\ngit clone https://github.com/techkwon/mcp-gemini.git\ncd mcp-gemini\n\n# ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò\nnpm install\n```\n\n### ÌôòÍ≤Ω ÏÑ§Ï†ï\n\n1. `config.ts` ÌååÏùºÏóê Google API ÌÇ§ ÏÑ§Ï†ï:\n\n```typescript\nexport default {\n  googleApiKey: \"your_api_key_here\",\n  // Í∏∞ÌÉÄ ÏÑ§Ï†ï...\n};\n```\n\n### ÎπåÎìú Î∞è Ïã§Ìñâ\n\n```bash\n# TypeScript ÎπåÎìú\nnpm run build\n\n# ÏÑúÎ≤Ñ ÏãúÏûë (PM2 ÏÇ¨Ïö©)\nnpm start\n\n# Í∞úÎ∞ú Î™®ÎìúÎ°ú Ïã§Ìñâ\nnpm run dev\n```\n\n### PM2 ÏÑúÎ≤Ñ Í¥ÄÎ¶¨\n\nÏÑúÎ≤ÑÎäî PM2Î•º ÌÜµÌï¥ ÏûêÎèôÏúºÎ°ú Í¥ÄÎ¶¨Îê©ÎãàÎã§. Îã§Ïùå Î™ÖÎ†πÏñ¥Î°ú ÏÑúÎ≤ÑÎ•º Í¥ÄÎ¶¨Ìï† Ïàò ÏûàÏäµÎãàÎã§:\n\n```bash\n# ÏÑúÎ≤Ñ ÏÉÅÌÉú ÌôïÏù∏\nnpm run status\n\n# ÏÑúÎ≤Ñ Î°úÍ∑∏ ÌôïÏù∏\nnpm run logs\n\n# ÏÑúÎ≤Ñ Ï§ëÏßÄ\nnpm run stop\n\n# ÏÑúÎ≤Ñ Ïû¨ÏãúÏûë\nnpm run restart\n\n# ÏãúÏä§ÌÖú Ïû¨ÏãúÏûë Ïãú ÏûêÎèô Ïã§Ìñâ ÏÑ§Ï†ï\npm2 startup\npm2 save\n```\n\n## Cursor/Claude Ïó∞Îèô\n\n### MCP ÏÑ§Ï†ï\n\n`~/.cursor/mcp.json` ÌååÏùºÏóê Îã§Ïùå ÏÑ§Ï†ïÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî:\n\n```json\n{\n  \"github.com/techkwon/mcp-gemini\": {\n    \"command\": \"npm\",\n    \"args\": [\"start\"],\n    \"cwd\": \"\u003cÌîÑÎ°úÏ†ùÌä∏_Í≤ΩÎ°ú\u003e\",\n    \"env\": {\n      \"NODE_ENV\": \"production\"\n    },\n    \"disabled\": false,\n    \"autoStart\": true,\n    \"autoApprove\": [\n      \"gem-generate\",\n      \"gem-generate-image\",\n      \"gem-analyze-video\",\n      \"gem-search\"\n    ]\n  }\n}\n```\n\n### API ÏóîÎìúÌè¨Ïù∏Ìä∏\n\n- `/gem-generate`: ÌÖçÏä§Ìä∏ ÏÉùÏÑ±\n- `/gem-generate-image`: Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±/Î∂ÑÏÑù\n- `/gem-analyze-video`: YouTube ÎπÑÎîîÏò§ Î∂ÑÏÑù\n- `/gem-search`: Ïõπ Í≤ÄÏÉâ\n\n## Ï£ºÏöî ÏóÖÎç∞Ïù¥Ìä∏\n\n### ÏµúÏã† Î≤ÑÏ†Ñ (2024-03)\n- PM2Î•º ÌÜµÌïú ÏÑúÎ≤Ñ ÏûêÎèôÌôî Íµ¨ÌòÑ\n- gemini-2.0-flash Î™®Îç∏Î°ú ÌÜµÏùº\n- ÏûêÎèô Ïû¨ÏãúÏûë Î∞è Ïò§Î•ò Î≥µÍµ¨ Í∏∞Îä• Ï∂îÍ∞Ä\n- ÌôòÍ≤Ω ÏÑ§Ï†ï Í∞úÏÑ†\n\n### Ïù¥Ï†Ñ Î≤ÑÏ†Ñ\n- YouTube ÎπÑÎîîÏò§ Î∂ÑÏÑù Í∏∞Îä• Ï∂îÍ∞Ä\n- Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±/Î∂ÑÏÑù Í∏∞Îä• Í∞úÏÑ†\n- Ïõπ Í≤ÄÏÉâ Í∏∞Îä• Ï∂îÍ∞Ä\n\n## Î¨∏Ï†ú Ìï¥Í≤∞\n\n### ÏùºÎ∞òÏ†ÅÏù∏ Î¨∏Ï†ú\n\n1. **ÏÑúÎ≤ÑÍ∞Ä ÏãúÏûëÎêòÏßÄ ÏïäÎäî Í≤ΩÏö∞**\n   ```bash\n   # PM2 Î°úÍ∑∏ ÌôïÏù∏\n   npm run logs\n   \n   # PM2 ÌîÑÎ°úÏÑ∏Ïä§ ÏÉÅÌÉú ÌôïÏù∏\n   npm run status\n   ```\n\n2. **API ÌÇ§ Ïò§Î•ò**\n   - `config.ts` ÌååÏùºÏóêÏÑú API ÌÇ§Í∞Ä Ïò¨Î∞îÎ•¥Í≤å ÏÑ§Ï†ïÎêòÏóàÎäîÏßÄ ÌôïÏù∏\n   - Gemini API Ìï†ÎãπÎüâ Î∞è Í∂åÌïú ÌôïÏù∏\n\n3. **Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Î¨∏Ï†ú**\n   - `ecosystem.config.js`ÏóêÏÑú Î©îÎ™®Î¶¨ Ï†úÌïú ÏÑ§Ï†ï ÌôïÏù∏\n   - PM2 Î™®ÎãàÌÑ∞ÎßÅÏúºÎ°ú Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Ï∂îÏ†Å\n\n## Í∏∞Ïó¨ÌïòÍ∏∞\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n## ÎùºÏù¥ÏÑ†Ïä§\n\nÏù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî MIT ÎùºÏù¥ÏÑ†Ïä§Î•º Îî∞Î¶ÖÎãàÎã§. ÏûêÏÑ∏Ìïú ÎÇ¥Ïö©ÏùÄ [LICENSE](LICENSE) ÌååÏùºÏùÑ Ï∞∏Ï°∞ÌïòÏÑ∏Ïöî.\n\n## Ïó∞ÎùΩÏ≤ò\n\nÌîÑÎ°úÏ†ùÌä∏ Í¥ÄÎ¶¨Ïûê: techkwon\nÏù¥Î©îÏùº: techkwon@example.com\nÌîÑÎ°úÏ†ùÌä∏ ÎßÅÌÅ¨: [https://github.com/techkwon/mcp-gemini](https://github.com/techkwon/mcp-gemini)\n\n## Ï£ºÏöî ÏùòÏ°¥ÏÑ±\n\n- @google/generative-ai: ^0.1.3 (Gemini API SDK)\n- @fastify/cors: ^8.5.0 (CORS ÏßÄÏõê)\n- fastify: ^4.29.0 (Ïõπ ÏÑúÎ≤Ñ ÌîÑÎ†àÏûÑÏõåÌÅ¨)\n- googleapis: ^148.0.0 (Google API ÏßÄÏõê)\n- typescript: ^5.0.0\n- zod: ^3.24.2 (Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù)\n- pino: ^8.21.0 (Î°úÍπÖ)\n\n## Claude Îç∞Ïä§ÌÅ¨ÌÜ± Ïï± ÌÜµÌï© Í∞ÄÏù¥Îìú\n\n### ÏÑ§Ï†ï ÌååÏùº ÏúÑÏπò\nClaude Îç∞Ïä§ÌÅ¨ÌÜ± Ïï±Ïùò ÏÑ§Ï†ï ÌååÏùºÏùÄ Îã§Ïùå Í≤ΩÎ°úÏóê ÏúÑÏπòÌï©ÎãàÎã§:\n- Windows: `%APPDATA%/Claude/config.json`\n- macOS: `~/Library/Application Support/Claude/config.json`\n\n### JSON ÏÑ§Ï†ï ÏòàÏãú\n\n```json\n{\n  \"apis\": [\n    {\n      \"name\": \"MCP Gemini\",\n      \"url\": \"http://localhost:8000\",\n      \"methods\": [\n        {\n          \"name\": \"ÌÖçÏä§Ìä∏ ÏÉùÏÑ±\",\n          \"method\": \"gem-generate\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-generate\",\n            \"params\": {\n              \"prompt\": \"{input}\"\n            }\n          }\n        },\n        {\n          \"name\": \"Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±\",\n          \"method\": \"gem-generate-image\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-generate-image\",\n            \"params\": {\n              \"prompt\": \"{input}\"\n            }\n          }\n        },\n        {\n          \"name\": \"ÎπÑÎîîÏò§ Î∂ÑÏÑù\",\n          \"method\": \"gem-analyze-video\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-analyze-video\",\n            \"params\": {\n              \"videoUrl\": \"{input}\",\n              \"query\": \"Ïù¥ ÏòÅÏÉÅÏùò Ï£ºÏöî ÎÇ¥Ïö©ÏùÑ ÏöîÏïΩÌï¥Ï£ºÏÑ∏Ïöî\"\n            }\n          }\n        },\n        {\n          \"name\": \"Ïõπ Í≤ÄÏÉâ\",\n          \"method\": \"gem-search\",\n          \"template\": {\n            \"jsonrpc\": \"2.0\",\n            \"id\": \"{uuid}\",\n            \"method\": \"gem-search\",\n            \"params\": {\n              \"query\": \"{input}\"\n            }\n          }\n        }\n      ]\n    }\n  ]\n}\n```\n\n### Î≥ÄÏàò ÏÑ§Î™Ö\n\n- `{uuid}`: ÏûêÎèôÏúºÎ°ú ÏÉùÏÑ±ÎêòÎäî Í≥†Ïú† ÏöîÏ≤≠ ID\n- `{input}`: Claude Ï±ÑÌåÖÏ∞ΩÏóê ÏûÖÎ†•Ìïú ÌÖçÏä§Ìä∏\n\n### ÏÇ¨Ïö© Î∞©Î≤ï\n\n1. Claude Îç∞Ïä§ÌÅ¨ÌÜ± Ïï±Ïùò ÏÑ§Ï†ï ÌååÏùºÏùÑ ÏóΩÎãàÎã§.\n2. ÏúÑÏùò JSON ÏÑ§Ï†ïÏùÑ Í∏∞Ï°¥ ÏÑ§Ï†ïÏóê Ï∂îÍ∞ÄÌï©ÎãàÎã§.\n3. Claude Îç∞Ïä§ÌÅ¨ÌÜ± Ïï±ÏùÑ Ïû¨ÏãúÏûëÌï©ÎãàÎã§.\n4. Ï±ÑÌåÖÏ∞ΩÏóêÏÑú Îã§ÏùåÍ≥º Í∞ôÏù¥ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏäµÎãàÎã§:\n\n```\n@MCP Gemini.ÌÖçÏä§Ìä∏ ÏÉùÏÑ± ÌïúÍµ≠Ïùò Ï†ÑÌÜµ ÏùåÏãùÏóê ÎåÄÌï¥ ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî\n@MCP Gemini.Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± ÌïúÏò•ÎßàÏùÑÏùò ÏïÑÎ¶ÑÎã§Ïö¥ ÌíçÍ≤Ω\n@MCP Gemini.ÎπÑÎîîÏò§ Î∂ÑÏÑù https://youtube.com/watch?v=VIDEO_ID\n@MCP Gemini.Ïõπ Í≤ÄÏÉâ ÏµúÏã† Ïù∏Í≥µÏßÄÎä• Í∏∞Ïà† ÎèôÌñ•\n```\n\n### ÏùëÎãµ ÌòïÏãù\n\nÎ™®Îì† API ÏùëÎãµÏùÄ Îã§Ïùå ÌòïÏãùÏùÑ Îî∞Î¶ÖÎãàÎã§:\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"ÏöîÏ≤≠ÏóêÏÑú Î≥¥ÎÇ∏ ID\",\n  \"result\": {\n    \"content\": \"ÏùëÎãµ ÎÇ¥Ïö©\"\n  }\n}\n```\n\n### Ïò§Î•ò ÏùëÎãµ\n\nÏò§Î•òÍ∞Ä Î∞úÏÉùÌïú Í≤ΩÏö∞ Îã§Ïùå ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌï©ÎãàÎã§:\n\n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"ÏöîÏ≤≠ÏóêÏÑú Î≥¥ÎÇ∏ ID\",\n  \"error\": {\n    \"code\": Ïò§Î•òÏΩîÎìú,\n    \"message\": \"Ïò§Î•ò Î©îÏãúÏßÄ\",\n    \"data\": {\n      \"details\": \"ÏÉÅÏÑ∏ Ïò§Î•ò Ï†ïÎ≥¥\"\n    }\n  }\n}\n```\n\n## Ïò§Î•ò Ï≤òÎ¶¨\n\nÏÑúÎ≤ÑÎäî Îã§ÏùåÍ≥º Í∞ôÏùÄ ÏÉÅÌô©ÏóêÏÑú Ï†ÅÏ†àÌïú Ïò§Î•ò ÏùëÎãµÏùÑ Î∞òÌôòÌï©ÎãàÎã§:\n\n- 400: ÏûòÎ™ªÎêú ÏöîÏ≤≠ ÌòïÏãù\n- 401: Ïù∏Ï¶ù Ïò§Î•ò (API ÌÇ§ Í¥ÄÎ†®)\n- 500: ÏÑúÎ≤Ñ ÎÇ¥Î∂Ä Ïò§Î•ò\n\n## Î≥¥Ïïà Í≥†Î†§ÏÇ¨Ìï≠\n\n- API ÌÇ§Îäî Î∞òÎìúÏãú ÌôòÍ≤Ω Î≥ÄÏàòÎ°ú Í¥ÄÎ¶¨ÌïòÏÑ∏Ïöî\n- ÌîÑÎ°úÎçïÏÖò ÌôòÍ≤ΩÏóêÏÑúÎäî Ï†ÅÏ†àÌïú Î≥¥Ïïà ÏÑ§Ï†ïÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî\n- ÎØºÍ∞êÌïú Ï†ïÎ≥¥Îäî Î°úÍ∑∏Ïóê Í∏∞Î°ùÌïòÏßÄ ÏïäÎèÑÎ°ù Ï£ºÏùòÌïòÏÑ∏Ïöî\n\n## Î¨∏Ï†ú Ìï¥Í≤∞\n\n### Ìè¨Ìä∏ Ï∂©Îèå\nÏù¥ÎØ∏ 8000Î≤à Ìè¨Ìä∏Í∞Ä ÏÇ¨Ïö© Ï§ëÏù∏ Í≤ΩÏö∞:\n```bash\n# Í∏∞Ï°¥ Node.js ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å\npkill -f \"node\"\n```\n\n### ÏÑúÎ≤Ñ ÏïàÏ†ïÏÑ±\nÏÑúÎ≤ÑÍ∞Ä ÏòàÍ∏∞Ïπò ÏïäÍ≤å Ï¢ÖÎ£åÎêòÎäî Í≤ΩÏö∞:\n- PM2ÎÇò Îã§Î•∏ ÌîÑÎ°úÏÑ∏Ïä§ Í¥ÄÎ¶¨Ïûê ÏÇ¨Ïö©ÏùÑ Í≥†Î†§ÌïòÏÑ∏Ïöî\n- Î°úÍ∑∏Î•º ÌôïÏù∏ÌïòÏó¨ Ï¢ÖÎ£å ÏõêÏù∏ÏùÑ ÌååÏïÖÌïòÏÑ∏Ïöî\n\n## Í∞úÎ∞ú Í∞ÄÏù¥Îìú\n\n### Î°úÍπÖ\n- Pino Î°úÍ±∞Î•º ÏÇ¨Ïö©ÌïòÏó¨ Íµ¨Ï°∞ÌôîÎêú Î°úÍπÖÏùÑ Íµ¨ÌòÑÌñàÏäµÎãàÎã§\n- Í∞úÎ∞ú ÌôòÍ≤ΩÏóêÏÑúÎäî pino-prettyÎ•º ÌÜµÌï¥ Í∞ÄÎèÖÏÑ± ÏûàÎäî Î°úÍ∑∏Í∞Ä Ï∂úÎ†•Îê©ÎãàÎã§\n\n### ÌÉÄÏûÖ ÏïàÏ†ïÏÑ±\n- TypeScriptÏôÄ ZodÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Îü∞ÌÉÄÏûÑ ÌÉÄÏûÖ ÏïàÏ†ïÏÑ±ÏùÑ Î≥¥Ïû•Ìï©ÎãàÎã§\n- API ÏöîÏ≤≠/ÏùëÎãµÏóê ÎåÄÌïú Ïä§ÌÇ§Îßà Í≤ÄÏ¶ùÏù¥ Íµ¨ÌòÑÎêòÏñ¥ ÏûàÏäµÎãàÎã§\n\n## CLINE MCP ÎßàÏºìÌîåÎ†àÏù¥Ïä§ Îì±Î°ù Í∞ÄÏù¥Îìú\n\n### ÏÇ¨Ï†Ñ Ï§ÄÎπÑÏÇ¨Ìï≠\n\n1. GitHub Ï†ÄÏû•ÏÜåÍ∞Ä Í≥µÍ∞úÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§\n2. README.md ÌååÏùºÏóê Î™ÖÌôïÌïú ÏÑ§Ïπò Î∞è ÏÑ§Ï†ï Î∞©Î≤ïÏù¥ Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§\n3. (ÏÑ†ÌÉùÏÇ¨Ìï≠) `llms-install.md` ÌååÏùºÏùÑ ÌÜµÌï¥ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÏúÑÌïú Ï∂îÍ∞Ä ÏÑ§Ïπò Í∞ÄÏù¥ÎìúÎ•º Ï†úÍ≥µÌï† Ïàò ÏûàÏäµÎãàÎã§\n\n### Îì±Î°ù Ï†àÏ∞®\n\n1. [CLINE MCP ÎßàÏºìÌîåÎ†àÏù¥Ïä§ Ï†ÄÏû•ÏÜå](https://github.com/cline/mcp-marketplace)Ïóê ÏÉàÎ°úÏö¥ Ïù¥ÏäàÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§\n\n2. Ïù¥ÏäàÏóê Îã§Ïùå Ï†ïÎ≥¥Î•º Ìè¨Ìï®Ìï©ÎãàÎã§:\n   - **GitHub Ï†ÄÏû•ÏÜå URL:** https://github.com/techkwon/mcp-gemini\n   - **Î°úÍ≥† Ïù¥ÎØ∏ÏßÄ:** 400√ó400 ÌÅ¨Í∏∞Ïùò PNG ÌååÏùº\n   - **Ï∂îÍ∞Ä Ïù¥Ïú†:** Ïù¥ MCP ÏÑúÎ≤ÑÍ∞Ä CLINE ÏÇ¨Ïö©ÏûêÎì§ÏóêÍ≤å Ï†úÍ≥µÌï† Ïàò ÏûàÎäî Í∞ÄÏπò\n   ÏòàÏãú:\n   ```markdown\n   ## MCP Gemini ÏÑúÎ≤Ñ Îì±Î°ù ÏöîÏ≤≠\n   \n   ### GitHub Ï†ÄÏû•ÏÜå\n   https://github.com/techkwon/mcp-gemini\n   \n   ### Ï£ºÏöî Í∏∞Îä•\n   - Gemini APIÎ•º ÌôúÏö©Ìïú ÌÖçÏä§Ìä∏ ÏÉùÏÑ±\n   - Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± Î∞è Ìé∏Ïßë (gemini-2.0-flash-exp Î™®Îç∏ ÏÇ¨Ïö©)\n   - YouTube ÎπÑÎîîÏò§ ÏΩòÌÖêÏ∏† Î∂ÑÏÑù\n   - Ïõπ Í≤ÄÏÉâ Í∏∞Îä•\n   \n   ### ÏÇ¨Ïö©Ïûê Ïù¥Ï†ê\n   - ÏµúÏã† Gemini Î™®Îç∏ÏùÑ MCP ÌîÑÎ°úÌÜ†ÏΩúÏùÑ ÌÜµÌï¥ ÏâΩÍ≤å ÌôúÏö©\n   - Îã§ÏñëÌïú ÎØ∏ÎîîÏñ¥ ÌòïÏãù(ÌÖçÏä§Ìä∏, Ïù¥ÎØ∏ÏßÄ, ÎπÑÎîîÏò§) Ï≤òÎ¶¨ Í∞ÄÎä•\n   - Î™ÖÌôïÌïú JSON-RPC Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Î°ú Ïâ¨Ïö¥ ÌÜµÌï©\n   - ÏÉÅÏÑ∏Ìïú Î¨∏ÏÑúÌôîÏôÄ ÏòàÏ†ú Ï†úÍ≥µ\n   ```\n\n3. CLINEÏù¥ README.mdÎßåÏúºÎ°ú ÏÑúÎ≤ÑÎ•º ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÑ§ÏπòÌï† Ïàò ÏûàÎäîÏßÄ ÌÖåÏä§Ìä∏Ìï©ÎãàÎã§\n\n### ÏäπÏù∏ Ï†àÏ∞®\n\n1. CLINE ÌåÄÏù¥ Ï†úÏ∂úÎêú MCP ÏÑúÎ≤ÑÎ•º Í≤ÄÌÜ†Ìï©ÎãàÎã§\n2. Î≥¥Ïïà Î∞è ÏïàÏ†ïÏÑ± Í≤ÄÏ¶ùÏùÑ ÏßÑÌñâÌï©ÎãàÎã§\n3. ÏäπÏù∏ÎêòÎ©¥ ÎßàÏºìÌîåÎ†àÏù¥Ïä§Ïóê Îì±Î°ùÎêòÏñ¥ Î™®Îì† CLINE ÏÇ¨Ïö©ÏûêÍ∞Ä Ï†ëÍ∑ºÌï† Ïàò ÏûàÍ≤å Îê©ÎãàÎã§\n\n### ÏÑ§Ïπò Í∞ÄÏù¥Îìú ÏµúÏ†ÅÌôî\n\n`llms-install.md` ÌååÏùºÏùÑ ÏÉùÏÑ±ÌïòÏó¨ AI ÏóêÏù¥Ï†ÑÌä∏Î•º ÏúÑÌïú Ï∂îÍ∞Ä ÏÑ§Ïπò Í∞ÄÏù¥ÎìúÎ•º Ï†úÍ≥µÌï† Ïàò ÏûàÏäµÎãàÎã§:\n\n```markdown\n# MCP Gemini ÏÑúÎ≤Ñ ÏÑ§Ïπò Í∞ÄÏù¥Îìú (AI ÏóêÏù¥Ï†ÑÌä∏Ïö©)\n\n## ÌôòÍ≤Ω ÏöîÍµ¨ÏÇ¨Ìï≠\n- Node.js 18.0.0 Ïù¥ÏÉÅ\n- npm ÎòêÎäî yarn\n- Google AI Studio API ÌÇ§\n\n## ÏÑ§Ïπò Îã®Í≥Ñ\n1. Ï†ÄÏû•ÏÜå ÌÅ¥Î°†\n2. ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò: `npm install`\n3. ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï: GOOGLE_API_KEY Ï∂îÍ∞Ä\n4. ÎπåÎìú: `npm run build`\n5. ÏÑúÎ≤Ñ Ïã§Ìñâ: `npm run start`\n\n## ÏÑ§Ï†ï Í≤ÄÏ¶ù\n- 8000Î≤à Ìè¨Ìä∏ ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏\n- API ÌÇ§ Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù\n- CORS ÏÑ§Ï†ï ÌôïÏù∏\n\n## Î¨∏Ï†ú Ìï¥Í≤∞\n- Ìè¨Ìä∏ Ï∂©Îèå Ïãú Ìï¥Í≤∞ Î∞©Î≤ï\n- API ÌÇ§ Ïò§Î•ò Ìï¥Í≤∞ Î∞©Î≤ï\n- ÏùºÎ∞òÏ†ÅÏù∏ ÏÑ§Ïπò Î¨∏Ï†ú Ìï¥Í≤∞ Í∞ÄÏù¥Îìú\n``` ",
      "stars": 4,
      "updated_at": "2025-07-23T14:36:23Z",
      "url": "https://github.com/techkwon/mcp-gemini"
    },
    "tuki0918--eagle-mcp-server": {
      "category": "image-and-video-generation",
      "description": "This implementation facilitates asset lifecycle control for the Eagle digital library management system via a standardized Model Context Protocol (MCP) interface. It permits controlled manipulation of assets, including directory organization, metadata extraction, and media asset processing, similar to how latent diffusion models structure data for visual synthesis.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/tuki0918.webp",
      "keywords": [
        "mcp",
        "eagle",
        "server",
        "eagle mcp",
        "mcp server",
        "eagle app"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "AssetForge Protocol Gateway",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "tuki0918",
      "readme_content": "## **Introduction**\n\nThis utility establishes an intermediary service layer, functioning as a Model Context Protocol (MCP) endpoint for the Eagle application. Such protocols enable structured communication for managing digital collections. In the context of visual media generation, these systems often rely on robust data handling, mirroring how T2I models process inputs to produce synthesized images.\n\n\u003cdetails\u003e\n\n\u003csummary\u003eSupported file formats:\u003c/summary\u003e\n\n- `JPG` / `JPEG`\n- `PNG`\n- `PDF`\n- `SVG`\n- `MP4`\n- `MP3`\n- `FBX`\n- `OBJ`\n- `EPS`\n- `TIF` / `TIFF`\n- `WebP`\n- `BMP`\n- `ICO`\n- `RAW`\n- etc\n\n\u003c/details\u003e\n\n- Eagle Asset Manager: https://eagle.cool/\u003cbr /\u003e\n- Official Eagle API Documentation: https://api.eagle.cool/\u003cbr /\u003e\n\n## **Requirements**\n\nExecution necessitates Python version 3.13 or newer. Furthermore, the `uv` package manager is mandatory for dependency resolution.\n\n## **Prerequisites**\n\nUse the package manager to install all necessary project dependencies properly:\n\n```bash\nuv sync\n```\n\n## **Usage**\n\nInitiate the Eagle application software first. Subsequently, start this specialized MCP intermediary service by invoking the following command from your terminal:\n\n```bash\nuv run main.py\n```\n\n\n## **Connecting to the MCP Server using Streamable HTTP**\n\nWhen configuring a client, such as a code editor, use this structural configuration format. The endpoint typically defaults to port 8000 on the local interface:\n\n```\n{\n  \"mcpServers\": {\n    \"eagle-mcp-server\": {\n      \"url\": \"http://localhost:8000/mcp\"\n    }\n  }\n}\n```\n\n## **Tools**\n\nThis table details the functions exposed by the gateway and their mapping to the underlying Eagle API structure. Many Item and Folder operations are active by default, facilitating immediate asset interaction:\n\n| Supported | Eagle API endpoint | Operation ID | Enabled (default) | Category |\n|:----:|:---------------------------|:-------------------------|:----:|:------------|\n| ‚úÖ | -               | `connect`                |  | MCP         |\n| ‚úÖ | /api/application/info      | `get_application_info`   | ‚ö´Ô∏é | Application |\n| ‚úÖ | /api/folder/create         | `create_folder`          | ‚ö´Ô∏é | Folder      |\n| ‚úÖ | /api/folder/rename         | `rename_folder`          |  | Folder      |\n| ‚úÖ | /api/folder/update         | `update_folder`          | ‚ö´Ô∏é | Folder      |\n| ‚úÖ | /api/folder/list           | `get_folder_list`        | ‚ö´Ô∏é | Folder      |\n| ‚úÖ | /api/folder/listRecent     | `get_folder_list_recent` |  | Folder      |\n| ‚úÖ | /api/item/addFromURL       | `add_item_from_url`      |  | Item        |\n| ‚úÖ | /api/item/addFromURLs      | `add_items_from_urls`    |  | Item        |\n| ‚úÖ | /api/item/addFromPath      | `add_item_from_path`     | ‚ö´Ô∏é | Item        |\n| ‚úÖ | /api/item/addFromPaths     | `add_items_from_paths`   |  | Item        |\n| ‚úÖ | /api/item/addBookmark      | `add_bookmark`           |  | Item        |\n| ‚úÖ | /api/item/info             | `get_item_info`          | ‚ö´Ô∏é | Item        |\n| ‚úÖ | -           | `get_item_source`        | ‚ö´Ô∏é | Item        |\n| ‚úÖ | /api/item/thumbnail        | `get_item_thumbnail`     |  | Item        |\n| ‚úÖ | /api/item/list             | `get_item_list`          | ‚ö´Ô∏é | Item        |\n| ‚úÖ | /api/item/moveToTrash      | `move_item_to_trash`     | ‚ö´Ô∏é | Item        |\n| ‚úÖ | /api/item/refreshPalette   | `refresh_item_palette`   |  | Item        |\n| ‚úÖ | /api/item/refreshThumbnail | `refresh_item_thumbnail` |  | Item        |\n| ‚úÖ | /api/item/update           | `update_item`            | ‚ö´Ô∏é | Item        |\n| ‚úÖ | /api/library/info          | `get_library_info`       | ‚ö´Ô∏é | Library     |\n| ‚úÖ | /api/library/history       | `get_library_history`    |  | Library     |\n| ‚úÖ | /api/library/switch        | `switch_library`         |  | Library     |\n| ‚úÖ | /api/library/icon          | `get_library_icon`       |  | Library     |\n\nRefer to the service-specific documentation for detailed endpoint specifications:\n- Gateway API Reference: https://tuki0918.github.io/eagle-mcp-server/\n- Interactive API Viewer (Redoc): http://localhost:8000/redoc\n\n## **Enabling Disabled Tools**\n\nSome functionalities are intentionally inactive upon initial deployment, indicated by blank entries in the default status column. To permit access to these suppressed operations, one must modify the source code directly. Locate the specific tool's definition, eliminate the `tags=[\"Disabled\"]` assignment line, and then cycle the MCP server's execution. This procedure unlocks previously restricted capabilities.\n\n## **Use Cases**\n\n### 1) **Same Host (Recommended)**\n\nThis flow demonstrates local communication where the client, server, and application reside on the same machine, ensuring minimal latency for asset operations:\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        direction LR\n        \n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App\u003cbr/\u003elocalhost:41595]\n        end\n        subgraph MCPServer [MCP Server\u003cbr/\u003elocalhost:8000]\n        end\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==\u003e MCPServer e1@==\u003e MCPClient\n    MCPClient e2@==\u003e MCPServer ==\u003e EagleApp\n    EagleApp ==\u003e FileSystem\n    FileSystem ==\u003e EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n\u003e [!TIP]\n\u003e Direct access to the local storage structure is available in this configuration setup.\n\n### 2) **Other Host (MCP Client) + Same Host (MCP Server, Eagle App)**\n\nIf the client operates remotely, file system interaction is mediated entirely through the local server process:\n\n```mermaid\nflowchart LR\n  \n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App\u003cbr/\u003elocalhost:41595]\n        end\n        subgraph MCPServer [MCP Server\u003cbr/\u003elocalhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==\u003e MCPServer e1@==\u003e MCPClient\n    MCPClient e2@==\u003e MCPServer ==\u003e EagleApp\n    EagleApp ==\u003e FileSystem\n    FileSystem ==\u003e EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n\u003e [!WARNING]\n\u003e Access to the external file system is explicitly denied when the client is running on a separate machine.\n\n### 3) **Other Host**\n\nIn this fully distributed scenario, all components are separated, relying exclusively on network communication pathways:\n\n```mermaid\nflowchart LR\n\n    subgraph 192.168.1.100\n        subgraph FileSystem [File System]\n        end\n        subgraph EagleApp [Eagle App\u003cbr/\u003elocalhost:41595]\n        end\n    end\n\n    subgraph 192.168.1.101\n        subgraph MCPServer [MCP Server\u003cbr/\u003elocalhost:8000]\n        end\n    end\n\n    subgraph 192.168.1.xxx\n        subgraph MCPClient [MCP Client]\n        end\n    end\n\n    EagleApp ==\u003e MCPServer e1@==\u003e MCPClient\n    MCPClient e2@==\u003e MCPServer ==\u003e EagleApp\n    EagleApp ==\u003e FileSystem\n    FileSystem ==\u003e EagleApp\n\n    e1@{ animate: true }\n    e2@{ animate: true }\n```\n\n\u003e [!WARNING]\n\u003e Direct file system interaction is unavailable when the client, server, and application are all hosted across different network locations.\n\n## **Related Topics**\n\n* Latent Diffusion Models for image synthesis.\n* Text-to-Image (T2I) generation principles.\n* Importance of structured data representation in generative AI pipelines.\n* Metadata standards for digital asset management systems.\n* HTTP stream protocols for remote data exchange.\n\n## **Extra Details**\n\nWhile this specific tool manages existing assets in Eagle, sophisticated generation tools like DALL-E 2 or Stable Diffusion utilize latent spaces. The concept of organizing and retrieving data via a standardized protocol, like MCP, is essential for training or utilizing those large generative models effectively. Effective model performance relies on clean, well-indexed datasets, which this server helps maintain for visual media.\n\n## **Conclusion**\n\nThis MCP gateway provides essential programmatic access to the Eagle asset repository, enabling automated cataloging and manipulation of various media types. This capability supports workflows that require integrating structured digital media management with other systems, including those involved in advanced visual media creation.",
      "stars": 3,
      "updated_at": "2025-09-22T11:24:54Z",
      "url": "https://github.com/tuki0918/eagle-mcp-server"
    },
    "tzafrir--mcp-server-replicate": {
      "category": "image-and-video-generation",
      "description": "Access various AI models hosted on Replicate through a standardized interface for image generation with customizable parameters, enabling output resizing and optimization. Future enhancements will include text and video generation features.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/tzafrir.webp",
      "keywords": [
        "replicate",
        "ai",
        "mcp",
        "video generation",
        "server replicate",
        "image generation"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp-server-replicate",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "tzafrir",
      "readme_content": "# MCP Server for Replicate\n\nA FastMCP server implementation for interfacing with Replicate's API. This server provides tools for accessing various AI models hosted on Replicate through a standardized interface.\n\n## Current Status: Early Alpha\n\nThis project is in early alpha development. Features and APIs may change significantly.\n\n### Currently Supported\n- Image generation models with:\n  - Model schema inspection\n  - Image generation with customizable parameters\n  - Output resizing and optimization\n\n## Roadmap\n\n### Planned Features\n1. Text Generation\n   - Support for text completion models\n   - Chat model integration\n   - Streaming support for real-time responses\n\n2. Video Generation\n   - Support for video generation models\n   - Video output handling and optimization\n   - Progress tracking for long-running generations\n\n3. Additional Features\n   - Model version management\n   - Better error handling and retries\n   - Caching for frequently used models\n   - Rate limiting and queue management\n\n## Setup\n\n1. Install dependencies:\n```bash\npip install -r requirements.txt\n```\n\n2. Set up your Replicate API token in `.env`:\n```\nREPLICATE_API_TOKEN=your_token_here\n```\n\n3. Run the server:\n```bash\nfastmcp dev server.py\n```\n",
      "stars": 3,
      "updated_at": "2025-05-05T06:38:38Z",
      "url": "https://github.com/tzafrir/mcp-server-replicate"
    },
    "video-creator--ffmpeg-mcp": {
      "category": "image-and-video-generation",
      "description": "Enables local video search, trimming, stitching, and playback through conversational commands using ffmpeg. Provides tools for finding, clipping, concatenating, and playing video files on macOS platforms.",
      "forks": 14,
      "imageUrl": "/freedevtools/mcp/pfp/video-creator.webp",
      "keywords": [
        "ffmpeg",
        "mcp",
        "macos",
        "ffmpeg mcp",
        "ffmpeg provides",
        "creator ffmpeg"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "ffmpeg-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "video-creator",
      "readme_content": "# FFmpeg-MCP\nUsing ffmpeg command line to achieve an mcp server, can be very convenient, through the dialogue to achieve the local video search, tailoring, stitching, playback and other functions\n\n\u003ca href=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@video-creator/ffmpeg-mcp/badge\" alt=\"FFmpeg-Server MCP server\" /\u003e\n\u003c/a\u003e\n\n## Support Tools\nThe server implements the following tools: \u003cbr/\u003e\n- `find_video_path`\n  The parameters are directory and file name, file name can be complete, or is not suffixed, recursive search in the directory, return the full path\n- `get_video_info`\n  The parameters are video path, return the video info, linkes duration/fps/codec/width/height.\n- `clip_video`\n  The parameter is the file path, start time, end time or duration, and returns the trimmed file path\n- `concat_videos`\n  The parameters are the list of files, the output path, and if the video elements in the list of files, such as width, height, frame rate, etc., are consistent, quick mode synthesis is automatically used\n- `play_video`\n  Play video/audio with ffplay, support many format, like mov/mp4/avi/mkv/3gp, video_path: video path speed: play rate loop: play count\n- `overlay_video`\n  Two video overlay. \u003cbr/\u003e\n  background_video: backgroud video path \u003cbr/\u003e\n  overlay_video: front video path \u003cbr/\u003e\n  output_path: output video path\u003cbr/\u003e\n  position: relative location\u003cbr/\u003e\n  dx: x offset\u003cbr/\u003e\n  dy: y offset\u003cbr/\u003e\n- `scale_video`\n  Video scale. \u003cbr/\u003e\n  video_path: in video path \u003cbr/\u003e\n  width: out video width, -2 keep aspect \u003cbr/\u003e\n  height: out video height, -2 keep aspect \u003cbr/\u003e\n  output_path: output video path \u003cbr/\u003e\n- `extract_frames_from_video`\n  Extract images from a video.\u003cbr/\u003e\n  Parameters: \u003cbr/\u003e\n  video_path (str): The path to the video.\u003cbr/\u003e\n  fps (int): Extract one frame every specified number of seconds. If set to 0, extract all frames; if set to 1, extract one frame per second.\u003cbr/\u003e\n  output_folder (str): The directory where the images will be saved.\u003cbr/\u003e\n  format (int): The format of the extracted images; 0: PNG, 1: JPG, 2: WEBP.\u003cbr/\u003e\n  total_frames (int): The maximum number of frames to extract. If set to 0, there is no limit\u003cbr/\u003e\n\u003cbr/\u003e\nMore features are coming\n\n## Installation procedure\n1. Download project\n```\ngit clone  https://github.com/video-creator/ffmpeg-mcp.git\ncd ffmpeg-mcp\nuv sync\n```\n\n2. Configuration in Cline\n```\n{\n  \"mcpServers\": {\n    \"ffmpeg-mcp\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/xxx/Downloads/ffmpeg-mcp\",\n        \"run\",\n        \"ffmpeg-mcp\"\n      ],\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n```\nNote: the value:`/Users/XXX/Downloads/ffmpeg` in args  need to replace the actual download ffmpeg-mcp directory\n\n## Supported platforms\nCurrently, only macos platforms are supported, including ARM64 or x86_64",
      "stars": 84,
      "updated_at": "2025-10-04T04:24:05Z",
      "url": "https://github.com/video-creator/ffmpeg-mcp"
    },
    "vishwa684--unet": {
      "category": "image-and-video-generation",
      "description": "Train and deploy U-Net models for biomedical image segmentation using the Medical Decathlon dataset, with support for both 2D and 3D U-Net scripts. Visualize predictions and assess model performance through comprehensive demos and visual outputs.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/vishwa684.webp",
      "keywords": [
        "segmentation",
        "biomedical",
        "dataset",
        "biomedical image",
        "models biomedical",
        "decathlon dataset"
      ],
      "language": "",
      "license": "Apache License 2.0",
      "name": "unet",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "vishwa684",
      "readme_content": "# Deep Learning Medical Decathlon Demos for Python*\n### U-Net Biomedical Image Segmentation with Medical Decathlon Dataset.\n\nThis repository contains [2D](https://github.com/IntelAI/unet/tree/master/2D) and [3D](https://github.com/IntelAI/unet/tree/master/3D) U-Net scripts for training models using the [Medical Decathlon](http://medicaldecathlon.com/) dataset (http://medicaldecathlon.com/).\n\n![pred152_3D](https://github.com/IntelAI/unet/blob/master/3D/images/BRATS_152_img3D.gif\n\"BRATS image #152:  Purple voxels indicate a perfect prediction by the model. Red are false positives. Blue are false negatives\").  ![pred195](https://github.com/IntelAI/unet/blob/master/3D/images/BRATS_195_img.gif \"BRATS image #195:  Purple voxels indicate a perfect prediction by the model. Red are false positives. Blue are false negatives\")\n\n\n",
      "stars": 0,
      "updated_at": "2024-05-11T00:13:12Z",
      "url": "https://github.com/vishwa684/unet"
    },
    "wheattoast11--mcp-video-gen": {
      "category": "image-and-video-generation",
      "description": "Generate videos and images from text prompts or existing images using advanced AI models, with capabilities for audio addition, content upscaling, and prompt enhancement. Manage and refine AI-generated content through API interactions with RunwayML and Luma AI.",
      "forks": 2,
      "imageUrl": "/freedevtools/mcp/pfp/wheattoast11.webp",
      "keywords": [
        "ai",
        "videos",
        "runwayml",
        "video generation",
        "generate videos",
        "ai generated"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "mcp-video-gen",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "wheattoast11",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/wheattoast11-mcp-video-gen-badge.png)](https://mseep.ai/app/wheattoast11-mcp-video-gen)\n\n# RunwayML + Luma AI MCP Server\n\nThis MCP server provides tools to interact with the RunwayML and Luma AI APIs for video and image generation tasks.\n\n## Features\n\n*   Generate videos from text prompts (RunwayML or Luma AI).\n*   Generate videos from images (RunwayML or Luma AI).\n*   Generate images from text prompts (Luma AI).\n*   Manage Luma AI generations (list, get, delete).\n*   Add audio to Luma AI generations.\n*   Upscale Luma AI generations.\n*   Enhance prompts using OpenRouter LLMs before generation.\n\n## Prerequisites\n\n*   Node.js (v18 LTS or later recommended)\n*   npm (usually included with Node.js)\n*   API Keys:\n    *   RunwayML API Secret\n    *   Luma AI API Key\n    *   OpenRouter API Key (for the `enhance_prompt` tool)\n\n## Installation\n\n1.  **Clone or Download:** Obtain the server code.\n2.  **Navigate to Directory:** Open a terminal in the server's root directory (`runwayml-mcp-server`).\n3.  **Install Dependencies:**\n    ```bash\n    npm install\n    ```\n\n## Configuration\n\n1.  **Create `.env` file:** In the server's root directory, create a file named `.env`.\n2.  **Add API Keys:** Add your API keys to the `.env` file:\n    ```dotenv\n    RUNWAYML_API_SECRET=your_runwayml_api_secret_here\n    LUMAAI_API_KEY=your_luma_api_key_here\n    OPENROUTER_API_KEY=your_openrouter_api_key_here\n    ```\n    Replace the placeholder values with your actual keys.\n\n## Running the Server\n\n1.  **Build the Server:** Compile the TypeScript code:\n    ```bash\n    npm run build\n    ```\n2.  **Start the Server:**\n    ```bash\n    npm start\n    ```\n    You should see a message like `RunwayML MCP server running on stdio` in your terminal's error output (stderr).\n\n## MCP Client Setup (e.g., Claude Desktop App, Cline)\n\nConfigure your MCP client to connect to this server. The exact steps depend on the client, but you'll typically need to provide:\n\n*   **Name:** A descriptive name (e.g., `runway-luma-server`)\n*   **Command:** `node`\n*   **Arguments:** The full path to the compiled server index file (e.g., `/path/to/your/runwayml-mcp-server/build/server-index.js`)\n*   **Environment Variables:**\n    *   `RUNWAYML_API_SECRET`: Your RunwayML API Secret\n    *   `LUMAAI_API_KEY`: Your Luma AI API Key\n    *   `OPENROUTER_API_KEY`: Your OpenRouter API Key\n\n**Example Configuration (Conceptual):**\n\n```json\n{\n  \"mcpServers\": {\n    \"runway-luma-server\": {\n      \"command\": \"node\",\n      \"args\": [\"/full/path/to/runwayml-mcp-server/build/server-index.js\"],\n      \"env\": {\n        \"RUNWAYML_API_SECRET\": \"your_runwayml_api_secret_here\",\n        \"LUMAAI_API_KEY\": \"your_luma_api_key_here\",\n        \"OPENROUTER_API_KEY\": \"your_openrouter_api_key_here\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n*(Remember to replace `/full/path/to/` with the actual path on your system)*\n\n## Available Tools\n\n*   **`generate_text_to_video`**: Generates video from text.\n    *   `provider`: (Optional) `runwayml` (default) or `lumaai`.\n    *   `promptText`: (Required) The text prompt.\n    *   `runway_model`: (Optional) Runway model (e.g., \"gen-2\").\n    *   `runway_resolution`: (Optional) Runway resolution (`1280:768` or `768:1280`).\n    *   `runway_watermark`: (Optional) Boolean, default `false`.\n    *   `luma_model`: (Optional) Luma model (`ray-flash-2`, `ray-2` (default), `ray-1-6`).\n    *   `luma_aspect_ratio`: (Optional) Luma aspect ratio (e.g., `16:9` (default), `1:1`).\n    *   `luma_loop`: (Optional) Boolean.\n    *   `duration`: (Optional) Video duration in seconds (number).\n    *   `seed`: (Optional) Generation seed (number).\n*   **`generate_image_to_video`**: Generates video from an image.\n    *   `provider`: (Optional) `runwayml` (default) or `lumaai`.\n    *   `promptImage`: (Required) URL of the input image, or for Runway, an array `[{uri: \"url\", position: \"first\" | \"last\"}]`.\n    *   `promptText`: (Optional) Text prompt to accompany the image.\n    *   `runway_model`: (Optional) Runway model (`gen3a_turbo` (default)).\n    *   `runway_duration`: (Optional) Runway duration (`5` (default) or `10`).\n    *   `runway_ratio`: (Optional) Runway resolution (`1280:768` or `768:1280`).\n    *   `runway_watermark`: (Optional) Boolean, default `false`.\n    *   `luma_model`: (Optional) Luma model (`ray-flash-2`, `ray-2` (default), `ray-1-6`).\n    *   `luma_aspect_ratio`: (Optional) Luma aspect ratio (e.g., `16:9` (default)).\n    *   `luma_loop`: (Optional) Boolean.\n    *   `seed`: (Optional) Generation seed (number).\n*   **`enhance_prompt`**: Refines a prompt using OpenRouter.\n    *   `original_prompt`: (Required) The prompt to enhance.\n    *   `model`: (Optional) OpenRouter model name (defaults to a capable model like `anthropic/claude-3.5-sonnet`).\n    *   `instructions`: (Optional) Specific instructions for the enhancement.\n*   **`luma_generate_image`**: Generates an image using Luma AI.\n    *   `prompt`: (Required) Text prompt.\n    *   `aspect_ratio`: (Optional) Luma aspect ratio (`16:9` (default)).\n    *   `model`: (Optional) Luma image model (`photon-1` (default), `photon-flash-1`).\n    *   `image_ref`: (Optional) Array of image reference objects (`{url: string, weight?: number}`). Max 4.\n    *   `style_ref`: (Optional) Array of style reference objects (`{url: string, weight?: number}`). Max 1.\n    *   `character_ref`: (Optional) Character reference object (`{ identity0: { images: [url1, ...] } }`).\n    *   `modify_image_ref`: (Optional) Modify image reference object (`{url: string, weight?: number}`).\n*   **`luma_list_generations`**: Lists previous Luma AI generations.\n    *   `limit`: (Optional) Number of results (default 10).\n    *   `offset`: (Optional) Offset for pagination (default 0).\n*   **`luma_get_generation`**: Gets details for a specific Luma AI generation.\n    *   `generation_id`: (Required) UUID of the generation.\n*   **`luma_delete_generation`**: Deletes a specific Luma AI generation.\n    *   `generation_id`: (Required) UUID of the generation.\n*   **`luma_get_camera_motions`**: Lists supported camera motions for Luma AI prompts. (No parameters).\n*   **`luma_add_audio`**: Adds audio to a Luma generation.\n    *   `generation_id`: (Required) UUID of the generation.\n    *   `prompt`: (Required) Prompt for the audio.\n    *   `negative_prompt`: (Optional) Negative prompt for audio.\n*   **`luma_upscale`**: Upscales a Luma generation.\n    *   `generation_id`: (Required) UUID of the generation.\n    *   `resolution`: (Optional) Target resolution (`1080p` (default) or `4k`).\n\n*(Note: For tools involving generation (`generate_*`, `luma_upscale`), the server initiates the task and returns immediately. Progress updates and the final result URL will be sent via MCP progress notifications.)*\n\n## Example Workflows\n\nHere are examples of how to combine the server's tools for common use cases:\n\n### 1. Music Video Snippet (Cyberpunk Noir)\n\n**Goal:** Create a 5-second cyberpunk noir video clip for the lyric \"Neon rivers flowing through a city of chrome\".\n\n**Steps:**\n\n1.  **Generate Base Image (Luma):**\n    ```json\n    {\n      \"tool_name\": \"luma_generate_image\",\n      \"arguments\": {\n        \"prompt\": \"Overhead shot of a dark, rainy cyberpunk city street at night. Bright neon signs reflect on wet pavement, resembling rivers of light flowing between towering chrome skyscrapers. Film noir aesthetic, photorealistic.\",\n        \"aspect_ratio\": \"16:9\"\n      }\n    }\n    ```\n    *(Wait for image generation to complete and get the image URL)*\n\n2.  **Animate Image (Luma):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"lumaai\",\n        \"promptImage\": \"{IMAGE_URL_FROM_STEP_1}\",\n        \"promptText\": \"Slow pan left across the rainy cyberpunk cityscape, neon lights flickering subtly.\",\n        \"luma_aspect_ratio\": \"16:9\",\n        \"duration\": 5\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n\n### 2. Product Ad Concept (Floating Earbud)\n\n**Goal:** Create a 5-second video showing a futuristic earbud floating in a minimalist environment.\n\n**Steps:**\n\n1.  **Generate Scene with Product Reference (Luma):**\n    ```json\n    {\n      \"tool_name\": \"luma_generate_image\",\n      \"arguments\": {\n        \"prompt\": \"A single, sleek futuristic wireless earbud floats weightlessly in the center of a bright, minimalist white room with soft, diffused ambient light. Zero gravity effect.\",\n        \"aspect_ratio\": \"1:1\",\n        \"image_ref\": [{ \"url\": \"{PRODUCT_IMAGE_URL}\", \"weight\": 0.8 }]\n      }\n    }\n    ```\n    *(Wait for image generation to complete and get the image URL)*\n\n2.  **Animate Scene (Luma):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"lumaai\",\n        \"promptImage\": \"{IMAGE_URL_FROM_STEP_1}\",\n        \"promptText\": \"The earbud slowly rotates and drifts gently in zero gravity.\",\n        \"luma_aspect_ratio\": \"1:1\",\n        \"duration\": 5\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n\n### 3. Image Animation (RunwayML Gen3a)\n\n**Goal:** Animate an existing image using RunwayML's Gen3a model.\n\n**Steps:**\n\n1.  **(Optional) Generate Base Image (Luma):** Use `luma_generate_image` if you don't have an image.\n2.  **Animate Image (RunwayML):**\n    ```json\n    {\n      \"tool_name\": \"generate_image_to_video\",\n      \"arguments\": {\n        \"provider\": \"runwayml\",\n        \"promptImage\": \"{YOUR_IMAGE_URL}\",\n        \"promptText\": \"Subtle zoom in, cinematic lighting.\",\n        \"runway_model\": \"gen3a_turbo\",\n        \"runway_duration\": \"5\",\n        \"runway_ratio\": \"1280:768\" // Or \"768:1280\"\n      }\n    }\n    ```\n    *(Wait for video generation to complete)*\n",
      "stars": 11,
      "updated_at": "2025-09-24T02:58:53Z",
      "url": "https://github.com/wheattoast11/mcp-video-gen"
    },
    "whiteking64--macos-ocr-mcp": {
      "category": "image-and-video-generation",
      "description": "Perform Optical Character Recognition (OCR) on images with the help of macOS's Vision framework, extracting recognized text segments, confidence scores, and bounding box coordinates. Suitable for applications that require text extraction from image files.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/whiteking64.webp",
      "keywords": [
        "ocr",
        "macos",
        "recognition",
        "macos ocr",
        "ocr mcp",
        "ocr images"
      ],
      "language": "Python",
      "license": "No License",
      "name": "macos-ocr-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "whiteking64",
      "readme_content": "# macOS OCR MCP Tool\n\nThis project provides a MetaCall Protocol (MCP) tool to perform Optical Character Recognition (OCR) on images using macOS's built-in Vision framework. It exposes an `ocr_image` tool that takes an image file path and returns the recognized text along with confidence scores and bounding boxes.\n\n## Project Setup\n\n### Dependencies\nThis project relies on Python 3.13+ and the following main dependencies:\n- `ocrmac`: For accessing macOS OCR capabilities. See [ocrmac](https://github.com/straussmaximilian/ocrmac).\n- `Pillow`: For image manipulation.\n- `mcp[cli]\u003e=1.7.1`: For the MetaCall Protocol server and client.\n\n### Installation\nIt is recommended to use a virtual environment.\n\n1.  **Create and activate a virtual environment:**\n    ```bash\n    python -m venv .venv\n    source .venv/bin/activate\n    ```\n\n2.  **Install dependencies using `uv`:**\n    ```bash\n    uv sync\n    ```\n\n## Running the MCP Server\n\nTo start the MCP server, run `main.py`:\n```bash\nuv run main.py\n```\nThis will start the MCP server, making the `ocr_image` tool available.\n\n## Available MCP Tools\n\n### `ocr_image`\n-   **Description:** Conducts OCR on the provided image file using macOS's built-in capabilities. Returns recognized text segments, their confidence scores, and bounding box coordinates.\n-   **Input:** `file_path: str` - The absolute or relative path to the image file.\n-   **Output (Example Success):**\n    ```json\n    {\n      \"filename\": \"path/to/your/image.png\",\n      \"annotations\": [\n        {\n          \"text\": \"Hello World\",\n          \"confidence\": 0.95,\n          \"bounding_box\": [0.1, 0.1, 0.5, 0.05] \n        },\n        // ... more annotations\n      ]\n    }\n    ```\n-   **Output (Example Error):**\n    ```json\n    {\n      \"error\": \"OCR functionality is only available on macOS.\"\n    }\n    ```\n    or\n    ```json\n    {\n      \"error\": \"File not found: path/to/nonexistent/image.png\"\n    }\n    ```\n\n**Note:** This tool will only function correctly on a macOS system due to its reliance on the Vision framework.\n\n## Testing with MCP Inspector\n\nYou can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) to connect to the running MCP server and test the tool.\n\n## Cursor MCP Configuration\n\nTo configure this MCP server in Cursor, you can add the following to your MCP JSON configuration file (e.g., `~/.cursor/mcp.json` or project-specific `.cursor/mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"ocrmac\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/macos-ocr-mcp\",\n        \"run\",\n        \"main.py\"\n      ]\n    }\n  }\n}\n```\n\nThis configuration tells Cursor how to start your MCP server. You can then call the `ocrmac.ocr_image` tool from within Cursor.\n",
      "stars": 1,
      "updated_at": "2025-06-07T18:16:13Z",
      "url": "https://github.com/whiteking64/macos-ocr-mcp"
    },
    "xenoailimited--mcp-mavae": {
      "category": "image-and-video-generation",
      "description": "A Model Context Protocol (MCP) server for interacting with image media tools, providing capabilities for image generation, editing, and management of collections and models.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/xenoailimited.webp",
      "keywords": [
        "mcp",
        "mavae",
        "protocol",
        "mcp mavae",
        "xenoailimited mcp",
        "mcp server"
      ],
      "language": "TypeScript",
      "license": "No License",
      "name": "mcp-mavae",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "xenoailimited",
      "readme_content": "# MAVAE - IMAGE TOOLBOX\nA powerful creative and editing toolkit designed for AI Agents.\n\n[![smithery badge](https://smithery.ai/badge/@xenoailimited/mavae-image-toolbox)](https://smithery.ai/server/@xenoailimited/mavae-image-toolbox)\n[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge\u0026logo=typescript\u0026logoColor=white)](https://www.typescriptlang.org/)\n[![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge\u0026logo=nodedotjs\u0026logoColor=white)](https://nodejs.org/)\n[![MCP](https://img.shields.io/badge/MCP-Model_Context_Protocol-blue?style=for-the-badge)](https://github.com/anthropics/model-context-protocol)\n[![Docker](https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge\u0026logo=docker\u0026logoColor=white)](https://www.docker.com/)\n\nMAVAE is a Model Context Protocol (MCP) server for interacting with image media tools. It provides a standardized interface for AI Agents to generate and manipulate images.\n\n## üöÄ Features\n\n- **Image Generation**: Generate images using both raw configurations and predefined collections\n- **Image Editing**: Compress, crop, and resize images with proportional or fixed dimensions\n- **Collection Management**: Create, manage, and share configurations for consistent image generation\n- **Model \u0026 Lora Management**: List and utilize available models and Loras\n- **API Token Management**: Handle authentication for secure interaction with Mavae services\n\n## üìã Prerequisites\n\n- Node.js (v16 or higher)\n- MAVAE API Key (set as environment variable, [Apply here](https://mcp.mavae.ai/))\n\n## üõ†Ô∏è Installation\n\n```bash\n# Install dependencies\nnpm install\n\n# Build the project\nnpm run build\n\n# Start the server\nnpm start\n```\n\n## MCP Json\n```json\n{\n  \"mcpServers\": {\n      \"mavae\": {\n          \"command\": \"node\",\n          \"args\": [\n              \"***/dist/index.js\"\n          ],\n          \"env\": {\n              \"MAVAE_API_KEY\": MAVAE_API_KEY\n          }\n      }\n  }\n}\n```\nWhen using MAVAE MCP locally, this path is an absolute path üëâüèª \"***/dist/index.js\"\n\n## üê≥ Docker Support\n\n```bash\n# Build Docker image\ndocker build -t mavae-mcp-server .\n\n# Run Docker container\ndocker run -e MAVAE_API_KEY=your_api_key mavae-mcp-server\n```\n\n## üìÅ Project Structure\n\n```\nmavae/\n‚îú‚îÄ‚îÄ src/                  # Source code\n‚îÇ   ‚îú‚îÄ‚îÄ actions/          # API endpoint implementation handlers\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aigc.ts       # Image generation operations\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collection.ts # Collection management operations\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edit.ts       # Image editing operations\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ token.ts      # API token operations\n‚îÇ   ‚îú‚îÄ‚îÄ tools/            # MCP tool definitions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aigc.ts       # Image generation tool definitions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collection.ts # Collection management tool definitions\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ edit.ts       # Image editing tool definitions\n‚îÇ   ‚îú‚îÄ‚îÄ types/            # TypeScript type definitions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aigc.ts       # Image generation types\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collection.ts # Collection types\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edit.ts       # Image editing types\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ response.ts   # API response types\n‚îÇ   ‚îú‚îÄ‚îÄ utils/            # Utility functions\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constants.ts  # Constant values\n‚îÇ   ‚îî‚îÄ‚îÄ index.ts          # Server entry point\n‚îú‚îÄ‚îÄ dist/                 # Compiled JavaScript files\n‚îú‚îÄ‚îÄ package.json          # Project dependencies and scripts\n‚îî‚îÄ‚îÄ tsconfig.json         # TypeScript configuration\n```\n\n## üõçÔ∏è Available Tools\n\n### Image Generation\n- `image_raw_generate` - Generate an image using raw AIGC configuration\n- `image_collection_generate` - Generate an image using a collection's AIGC configuration\n- `image_retry_generate` - Retry a failed image generation\n- `image_state` - Get the details of an owned image\n- `generate_task_state` - Get the generation state of an image by task id\n\n### Collection Management\n- `collection_create` - Create a new collection\n- `collection_delete` - Delete a collection\n- `collection_toggle_public` - Toggle the public status of a collection\n- `collection_list` - Get the list of owned collections\n- `collection_state` - Get the details of an owned collection\n\n### Image Editing\n- `compress_image` - Lossless compression of images\n- `crop_image` - Crop images with local path and URL support\n- `resize_image` - Resize images with proportional or fixed dimensions\n\n### Model \u0026 Resources\n- `list_images` - Get the list of owned images\n- `list_loras` - Get the list of available loras\n- `list_models` - Get the list of available models\n\n### Authentication\n- `token_state` - Get the x-api-token state\n\n\n\n",
      "stars": 0,
      "updated_at": "2025-04-24T16:15:59Z",
      "url": "https://github.com/xenoailimited/mcp-mavae"
    },
    "xixilidao--osgearth": {
      "category": "image-and-video-generation",
      "description": "Add geospatially accurate 3D maps to C++ applications, enabling developers to integrate and display complex geographical data visually.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/xixilidao.webp",
      "keywords": [
        "3d",
        "maps",
        "geospatially",
        "3d maps",
        "maps applications",
        "accurate 3d"
      ],
      "language": "",
      "license": "Other",
      "name": "osgearth",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "xixilidao",
      "readme_content": "![Windows](https://github.com/gwaldron/osgearth/actions/workflows/windows.yml/badge.svg)\n![Linux](https://github.com/gwaldron/osgearth/actions/workflows/linux.yml/badge.svg)\n![OSX](https://github.com/gwaldron/osgearth/actions/workflows/macos.yml/badge.svg)\n\n\n## Welcome to osgEarth!\n\nosgEarth adds geospatially accurate 3D maps to your C++ application.\n\n\u003cimg alt=\"a0b1c650_442a_4e6d_88e6_42a5c92083b8\" src=\"https://github.com/user-attachments/assets/a0b1c650-442a-4e6d-88e6-42a5c92083b8\" width=\"200\" height=\"140\"/\u003e\n\u003cimg alt=\"08d0f8c0_49e1_41a8_8b97_d663337f1cbb\" src=\"https://github.com/user-attachments/assets/08d0f8c0-49e1-41a8-8b97-d663337f1cbb\" width=\"200\" height=\"140\"/\u003e\n\u003cimg alt=\"575315e1_e2ae_43ec_8a97_83bafcfa9131\" src=\"https://github.com/user-attachments/assets/575315e1-e2ae-43ec-8a97-83bafcfa9131\" width=\"200\" height=\"140\"/\u003e\n\u003cimg alt=\"24971c79_f93c_48eb_ab79_161bb35beae4\" src=\"https://github.com/user-attachments/assets/24971c79-f93c-48eb-ab79-161bb35beae4\" width=\"200\" height=\"140\"/\u003e\n\u003cimg alt=\"cf40e4a9_429d_4cac_9464_f9825149e7f2\" src=\"https://github.com/user-attachments/assets/cf40e4a9-429d-4cac-9464-f9825149e7f2\" width=\"200\" height=\"140\"/\u003e\n\u003cimg alt=\"1cd49290_9b2d_42ec_a8c3_9c1c38eb673c\" src=\"https://github.com/user-attachments/assets/1cd49290-9b2d-42ec-a8c3-9c1c38eb673c\" width=\"200\" height=\"140\"/\u003e\n\u003cimg alt=\"bfd869fd_32b5_48b5_a037_4951f812b757\" src=\"https://github.com/user-attachments/assets/bfd869fd-32b5-48b5-a037-4951f812b757\" width=\"200\" height=\"140\"/\u003e\n\u003cimg alt=\"1876fffb_e683_4fa9_9521_cdd9795dea85\" src=\"https://github.com/user-attachments/assets/1876fffb-e683-4fa9-9521-cdd9795dea85\" width=\"200\" height=\"140\"/\u003e\n\nosgEarth builds on trusted open source technologies like OpenSceneGraph and GDAL to give you high-performance, accurate terrain and map rendering. It supports a myriad of geospatial data formats and map projections.\n\n## Install the SDK\n\nWindows users can install the latest version of osgEarth through `vcpkg`:\n```bat\ngit clone https://github.com/microsoft/vcpkg.git\ncd vcpkg \u0026\u0026 bootstrap-vcpkg.bat\nvcpkg install osgearth:x64-windows\n```\nThis will take a while the first time as vcpkg builds osgEarth and its dependencies.\n\n## Check out some examples\n\n`osgearth_imgui` is the main command-line viewer. `osgearth_viewer` is a stripped-down viewer without any GUI.\nBoth of these read \"earth files\", XML files that describe the contents of a map.\n\nYou can find example earth files in the `tests` folder of the repo.\n\n```bat\n:: Online imagery and elevation:\nosgearth_imgui tests\\readymap.earth\n\n:: OpenStreetMap:\nosgearth_imgui tests\\osm.earth\n\n:: Local GeoTIFFs:\nosgearth_imgui tests\\simple.earth \n```\n\n## Integrate it into your project\n\nCMakeLists.txt\n```cmake\ncmake_minimum_required(VERSION 3.20)\nproject(myApp)\nfind_package(osgEarth CONFIG REQUIRED)\nadd_executable(myApp main.cpp)\ntarget_link_libraries(myApp PRIVATE osgEarth::osgEarth)\ninstall(TARGETS myApp RUNTIME DESTINATION bin)\n```\nmain.cpp\n```c++\n#include \u003cosgEarth/MapNode\u003e\n#include \u003cosgEarth/TMS\u003e\n#include \u003cosgEarth/EarthManipulator\u003e\n#include \u003cosg/ArgumentParser\u003e\n#include \u003cosgViewer/Viewer\u003e\n\nint main(int argc, char** argv)\n{\n    osgEarth::initialize();\n    \n    osg::ArgumentParser args(\u0026argc, argv);\n    osgViewer::Viewer viewer(args);\n    \n    auto imagery = new osgEarth::TMSImageLayer();\n    imagery-\u003esetURL(\"https://readymap.org/readymap/tiles/1.0.0/7/\");\n    \n    auto mapNode = new osgEarth::MapNode();\n    mapNode-\u003egetMap()-\u003eaddLayer(imagery);\n    \n    viewer.setSceneData(mapNode);\n    viewer.setCameraManipulator(new osgEarth::EarthManipulator(args));\n    \n    return viewer.run();\n}\n```\n\n## Resources\n\n* [Documentation](http://docs.osgearth.org/en/latest/)\n* [Gallery](https://www.pelicanmapping.com/home-1/opensource)\n* [Custom Software Development](https://www.pelicanmapping.com/software)\n\n---\n¬© Copyright [Pelican Mapping](http://pelicanmapping.com)\n",
      "stars": 0,
      "updated_at": "2024-10-07T03:14:53Z",
      "url": "https://github.com/xixilidao/osgearth"
    },
    "xiyuefox--mcp-hfspace": {
      "category": "image-and-video-generation",
      "description": "Connect to Hugging Face Spaces to access various AI models for tasks like image generation and text-to-speech with minimal setup. Leverage the default model for seamless integration into applications.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/xiyuefox.webp",
      "keywords": [
        "hfspace",
        "xiyuefox",
        "ai",
        "xiyuefox mcp",
        "mcp hfspace",
        "image generation"
      ],
      "language": "",
      "license": "MIT License",
      "name": "mcp-hfspace",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "xiyuefox",
      "readme_content": "# mcp-hfspace MCP Server ü§ó\n\nRead the introduction here [llmindset.co.uk/resources/mcp-hfspace/](https://llmindset.co.uk/resources/mcp-hfspace/)\n\nConnect to [Hugging Face Spaces](https://huggingface.co/spaces)  with minimal setup needed - simply add your spaces and go!\n\nBy default, it connects to `evalstate/FLUX.1-schnell` providing Image Generation capabilities to Claude Desktop.\n\n\n\n## Installation\n\nNPM Package is `@llmindset/mcp-hfspsace`.\n\nInstall a recent version of [NodeJS](https://nodejs.org/en/download) for your platform, then add the following to the `mcpServers` section of your `claude_desktop_config.json` file:\n\n```json\n    \"mcp=hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\"\n      ]\n    }\n```\n\nPlease make sure you are using Claude Desktop 0.78 or greater.\n\nThis will get you started with an Image Generator.\n\n### Basic setup\n\nSupply a list of HuggingFace spaces in the arguments. mcp-hfspace will find the most appropriate endpoint and automatically configure it for usage. An example `claude_desktop_config.json` is supplied [below](#installation).\n\nBy default the current working directory is used for file upload/download. On Windows this is a read/write folder at `\\users\\\u003cusername\u003e\\AppData\\Roaming\\Claude\\\u003cversion.number\\`, and on MacOS it is the is the read-only root: `/`.\n\nIt is recommended to override this and set a Working Directory for handling the upload and download of images and other file-based content. Specify either the `--work-dir=/your_directory` argument or `MCP_HF_WORK_DIR` environment variable.\n\nAn example configuration for using a modern image generator, vision model and text to speech is below with a working directory set is below:\n\n```json\n    \"mcp-hfspace\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=/Users/evalstate/mcp-store\",\n        \"shuttleai/shuttle-jaguar\",\n        \"styletts2/styletts2\",\n        \"Qwen/QVQ-72B-preview\"\n      ]\n    }\n```\n\n\nTo use private spaces, supply your Hugging Face Token with either the  `--hf-token=hf_...` argument or `HF_TOKEN` environment variable.\n\nIt's possible to run multiple server instances to use different working directories and tokens if needed.\n\n## File Handling and Claude Desktop Mode\n\nBy default, the Server operates in _Claude Desktop Mode_. In this mode, Images are returned in the tool responses, while other files are saved in the working folder, their file path is returned as a message. This will usually give the best experience if using Claude Desktop as the client.\n\nURLs can also be supplied as inputs: the content gets passed to the Space.\n\nThere is an \"Available Resources\" prompt that gives Claude the available files and mime types from your working directory. This is currently the best way to manage files.\n\n### Example 1 - Image Generation (Download Image / Claude Vision)\n\nWe'll use Claude to compare images created by `shuttleai/shuttle-3.1-aesthetic` and `FLUX.1-schnell`. The images gets saved to the Work Directory, as well as included in Claude's context window - so Claude can use its vision capabilities.\n\n\n\n### Example 2 - Vision Model (Upload Image)\n\nWe'll use `merve/paligemma2-vqav2` [space link](https://huggingface.co/spaces/merve/paligemma2-vqav2) to query an image. In this case, we specify the filename which is available in the Working Directory: we  don't want to upload the Image directly to Claude's context window. So, we can prompt Claude:\n\n`use paligemma to find out who is in \"test_gemma.jpg\"` -\u003e `Text Output: david bowie`\n\n\n_If you are uploading something to Claude's context use the Paperclip Attachment button, otherwise specify the filename for the Server to send directly._\n\nWe can also supply a URL. For example : `use paligemma to detect humans in https://e3.365dm.com/24/12/1600x900/skynews-taylor-swift-eras-tour_6771083.jpg?20241209000914` -\u003e `One person is detected in the image - Taylor Swift on stage.`\n\n### Example 3 - Text-to-Speech (Download Audio)\n\nIn _Claude Desktop Mode_, the audio file is saved in the WORK_DIR, and Claude is notified of the creation. If not in desktop mode, the file is returned as a base64 encoded resource to the Client (useful if it supports embedded Audio attachments).\n\n\n\n### Example 4 - Speech-to-Text (Upload Audio)\n\nHere, we use `hf-audio/whisper-large-v3-turbo` to transcribe some audio, and make it available to Claude.\n\n\n\n### Example 5 - Image-to-Image\n\nIn this example, we specify the filename for `microsoft/OmniParser` to use, and get returned an annotated Image and 2 separate pieces of text: descriptions and coordinates. The prompt used was `use omniparser to analyse ./screenshot.png` and `use the analysis to produce an artifact that reproduces that screen`. `DawnC/Pawmatch` is also good at this.\n\n\n\n### Example 6 - Chat\n\nIn this example, Claude sets a number of reasoning puzzles for Qwen, and asks follow-up questions for clarification.\n\n\n\n### Specifying API Endpoint\n\nIf you need, you can specify a specific API Endpoint by adding it to the spacename. So rather than passing in `Qwen/Qwen2.5-72B-Instruct` you would use `Qwen/Qwen2.5-72B-Instruct/model_chat`.\n\n### Claude Desktop Mode\n\nThis can be disabled with the option --desktop-mode=false or the environment variable CLAUDE_DESKTOP_MODE=false. In this case, content as returned as an embedded Base64 encoded Resource.\n\n## Recommended Spaces\n\nSome recommended spaces to try:\n\n### Image Generation\n\n- shuttleai/shuttle-3.1-aesthetic\n- black-forest-labs/FLUX.1-schnell\n- yanze/PuLID-FLUX\n- Inspyrenet-Rembg (Background Removal)\n- diyism/Datou1111-shou_xin - [Beautiful Pencil Drawings](https://x.com/ClementDelangue/status/1867318931502895358) \n\n### Chat\n\n- Qwen/Qwen2.5-72B-Instruct\n- prithivMLmods/Mistral-7B-Instruct-v0.3\n\n### Text-to-speech / Audio Generation\n\n- fantaxy/Sound-AI-SFX\n- parler-tts/parler_tts\n\n### Speech-to-text\n\n- hf-audio/whisper-large-v3-turbo\n- (the openai models use unnamed parameters so will not work)\n\n### Text-to-music\n\n- haoheliu/audioldm2-text2audio-text2music\n\n### Vision Tasks\n\n- microsoft/OmniParser\n- merve/paligemma2-vqav2\n- merve/paligemma-doc\n- DawnC/PawMatchAI \n- DawnC/PawMatchAI/on_find_match_click - for interactive dog recommendations\n\n## Other Features\n\n### Prompts\n\nPrompts for each Space are generated, and provide an opportunity to input. Bear in mind that often Spaces aren't configured with particularly helpful labels etc. Claude is actually very good at figuring this out, and the Tool description is quite rich (but not visible in Claude Desktop).\n\n### Resources\n\nA list of files in the WORK_DIR is returned, and as a convenience returns the name as \"Use the file...\" text. If you want to add something to Claude's context, use the paperclip - otherwise specify the filename for the MCP Server. Claude does not support transmitting resources from within Context.\n\n### Private Spaces\n\nPrivate Spaces are supported with a HuggingFace token. The Token is used to download and save generated content.\n\n### Using Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-hfspace\": {\n      \"command\": \"npx\"\n      \"args:\" [\n        \"-y\",\n        \"@llmindset/mcp-hfspace\",\n        \"--work-dir=~/mcp-files/ or x:/temp/mcp-files/\",\n        \"--HF_TOKEN=HF_{optional token}\"\n        \"Qwen/Qwen2-72B-Instruct\",\n        \"black-forest-labs/FLUX.1-schnell\",\n        \"space/example/specific-endpint\"\n        (... and so on)\n        ]\n    }\n  }\n}\n```\n\n## Known Issues and Limitations\n\n### mcp-hfspace\n\n- Endpoints with unnamed parameters are unsupported for the moment.\n- Full translation from some complex Python types to suitable MCP formats.\n\n### Claude Desktop\n\n- Claude Desktop 0.75 doesn't seem to respond to errors from the MCP Server, timing out instead. For persistent issues, use the MCP Inspector to get a better look at diagnosing what's going wrong. If something suddenly stops working, it's probably due to exhausting your HuggingFace ZeroGPU quota - try again after a short period, or set up your own Space for hosting.\n- Claude Desktop seems to use a hard timeout value of 60s, and doesn't appear  to use Progress Notifications to manage UX or keep-alive. If you are using ZeroGPU spaces, large/heavy jobs may timeout. Check the WORK_DIR for results though; the MCP Server will still capture and save the result if it was produced.\n- Claude Desktops reporting of Server Status, logging etc. isn't great - use [@modelcontextprotocol/inspector](https://github.com/modelcontextprotocol/inspector) to help diagnose issues.\n\n### HuggingFace Spaces\n\n- If ZeroGPU quotas or queues are too long, try duplicating the space. If your job takes less than sixty seconds, you can usually change the function decorator `@spaces.GPU(duration=20)` in `app.py` to request less quota when running the job.\n- If you have a HuggingFace Pro account, please note that The Gradio API does not your additional quote for ZeroGPU jobs - you will need to set an `X-IP-Token` header to achieve that.\n- If you have a private space, and dedicated hardware your HF_TOKEN will give you direct access to that - no quota's apply. I recommend this if you are using for any kind of Production task.\n\n## Third Party MCP Services\n\n\u003ca href=\"https://glama.ai/mcp/servers/s57c80wvgq\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/s57c80wvgq/badge\" alt=\"mcp-hfspace MCP server\" /\u003e\u003c/a\u003e",
      "stars": 0,
      "updated_at": "2025-03-10T03:52:55Z",
      "url": "https://github.com/xiyuefox/mcp-hfspace"
    },
    "xoy8n--webp-converter": {
      "category": "image-and-video-generation",
      "description": "A server that converts image files such as PNG, JPG, and JPEG to WebP format, supporting both single and batch conversions. It allows configuration of quality settings and provides detailed conversion reports.",
      "forks": 0,
      "imageUrl": "/freedevtools/mcp/pfp/xoy8n.webp",
      "keywords": [
        "webp",
        "jpeg",
        "converter",
        "webp converter",
        "jpeg webp",
        "xoy8n webp"
      ],
      "language": "JavaScript",
      "license": "No License",
      "name": "webp-converter",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "xoy8n",
      "readme_content": "# WebP Conversion MCP Server\n\nThis project is a Model Context Protocol (MCP) server that converts image files to WebP format.\n\n## Features\n\n- Convert PNG, JPG, and JPEG files to WebP\n- Support for single image or batch image conversion\n- Option to configure quality and lossless compression\n- Option to keep original files\n- Provides a detailed report of the conversion result\n\n### Installation \u0026 Execution\n\n```bash\nnpx -y @xoy8n/webp-converter@latest\n```\n\n### Cursor mcp.json Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"webp-converter\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@xoy8n/webp-converter@latest\"]\n    }\n  }\n}\n```\n\n## MCP Tool List\n\n### 1. convert_to_webp\n\nConverts a single image file to WebP format.\n\n**Parameters:**\n\n- `image_path`: Path to the image file to convert\n- `base_path`: Base directory path\n- `quality`: WebP quality setting (default: 95)\n- `lossless`: Whether to use lossless compression (default: false)\n- `keep_original`: Whether to retain the original file (default: false)\n\n**Returns:**\n\n- Conversion success status\n- Input/output file paths\n- File size before/after conversion\n- Applied quality and compression settings\n\n### 2. batch_convert_to_webp\n\nConverts multiple image files to WebP format in one go.\n\n**Parameters:**\n\n- `image_paths`: Array of paths to image files to convert\n- `base_path`: Base directory path (optional)\n- `quality`: WebP quality setting (default: 95)\n- `lossless`: Whether to use lossless compression (default: false)\n- `keep_original`: Whether to retain the original files (default: false)\n\n**Returns:**\n\n- Array of conversion results for each image file\n\n## How to Use\n\n1. Select the image files you want to convert.\n2. Run the `convert_to_webp` or `batch_convert_to_webp` command via the MCP tools.\n3. Check the conversion results.\n\n## License\n\nMIT\n",
      "stars": 0,
      "updated_at": "2025-06-19T01:34:07Z",
      "url": "https://github.com/xoy8n/webp-converter"
    },
    "yanjunz--mcp_search_images": {
      "category": "image-and-video-generation",
      "description": "Search for high-quality images from sources like Unsplash, Pexels, and Pixabay, and generate custom icons based on text descriptions, facilitating visual enhancements for projects.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/yanjunz.webp",
      "keywords": [
        "mcp_search_images",
        "images",
        "icons",
        "yanjunz mcp_search_images",
        "mcp_search_images search",
        "quality images"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "mcp_search_images",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "yanjunz",
      "readme_content": "# MCP ÂõæÂÉèÊêúÁ¥¢‰∏éÂõæÊ†áÁîüÊàêÊúçÂä°\n\nÂü∫‰∫éÂ§ö‰∏™ÂõæÁâáAPIÁöÑÊêúÁ¥¢ÊúçÂä°ÂíåÂõæÊ†áÁîüÊàêÂäüËÉΩÔºå‰∏ìÈó®ËÆæËÆ°Áî®‰∫é‰∏é Cursor MCP ÊúçÂä°ÈõÜÊàê„ÄÇÊîØÊåÅÂõæÁâáÊêúÁ¥¢„ÄÅ‰∏ãËΩΩÂíåAIÁîüÊàêÂõæÊ†á„ÄÇ\n\n\n\n## Â∑•‰ΩúÂéüÁêÜ\n\nÊú¨Â∑•ÂÖ∑ÈÄöËøáMCP (Model Control Protocol) ‰∏∫Cursor IDEÊèê‰æõÂõæÂÉèÊêúÁ¥¢ÂíåÂõæÊ†áÁîüÊàêÂäüËÉΩÔºö\n\n1. **ÊêúÁ¥¢ÂõæÁâá**: ËøûÊé•Unsplash„ÄÅPexelsÂíåPixabayÁ≠âÂõæÁâáÊ∫êÔºåÊ†πÊçÆÂÖ≥ÈîÆËØçÊêúÁ¥¢È´òË¥®ÈáèÂõæÁâá\n2. **‰∏ãËΩΩÂõæÁâá**: Â∞ÜÊêúÁ¥¢Âà∞ÁöÑÂõæÁâá‰∏ãËΩΩÂà∞ÊåáÂÆö‰ΩçÁΩÆÔºåÊñπ‰æøÁõ¥Êé•Âú®È°πÁõÆ‰∏≠‰ΩøÁî®\n3. **ÁîüÊàêÂõæÊ†á**: Âü∫‰∫éÊñáÊú¨ÊèèËø∞ÁîüÊàêËá™ÂÆö‰πâÂõæÊ†áÔºåÊª°Ë∂≥È°πÁõÆUIÈúÄÊ±Ç\n\n### Á≥ªÁªüÂ∑•‰ΩúÊµÅÁ®ã\n\n```\nÁî®Êà∑ (Âú®Cursor‰∏≠) ‚Üí ÂêëClaude/Â§ßÊ®°ÂûãÊèêÈóÆ ‚Üí Â§ßÊ®°ÂûãË∞ÉÁî®MCPÂ∑•ÂÖ∑ ‚Üí Â∑•ÂÖ∑Â§ÑÁêÜËØ∑Ê±Ç ‚Üí ËøîÂõûÁªìÊûú ‚Üí Â§ßÊ®°ÂûãÂ±ïÁ§∫ÁªìÊûú\n```\n\nÊØîÂ¶ÇÔºå‰Ω†ÂèØ‰ª•Âú®Cursor‰∏≠ÂêëClaudeËØ¢ÈóÆ\"Â∏ÆÊàëÊâæ5Âº†ÂÖ≥‰∫éÂ§™Á©∫ÁöÑÂõæÁâá\"ÔºåClaude‰ºöÈÄöËøáMCPÂ∑•ÂÖ∑ÊêúÁ¥¢Âπ∂Â±ïÁ§∫ÂõæÁâáÔºåÁÑ∂Âêé‰Ω†ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Ë¶ÅÊ±Ç‰∏ãËΩΩÊàñÁîüÊàêÁâπÂÆöÂõæÊ†á„ÄÇ\n\n## ÂäüËÉΩÁâπÁÇπ\n\n* ÊîØÊåÅÂ§ö‰∏™ÂõæÁâáÊ∫êÊêúÁ¥¢ (Unsplash, Pexels, Pixabay)\n* È´òË¥®ÈáèÂõæÊ†áÁîüÊàê (Âü∫‰∫éTogether AI)\n* ÁÆÄÂçïÊòìÁî®ÁöÑAPI\n* ÂÆåÊï¥ÁöÑÈîôËØØÂ§ÑÁêÜ\n* Ëá™ÂÆö‰πâ‰øùÂ≠òË∑ØÂæÑÂíåÊñá‰ª∂Âêç\n* ÂèØË∞ÉÊï¥ÂõæÁâáÂ∞∫ÂØ∏\n\n## ÁéØÂ¢ÉÂáÜÂ§á\n\n### 1. Python ÁéØÂ¢É\n\n* Python 3.10+\n* ‰∏ãËΩΩÂú∞ÂùÄÔºö https://www.python.org/downloads/\n* Êé®Ëçê‰ΩøÁî® pyenv ÁÆ°ÁêÜ Python ÁâàÊú¨Ôºö\n\n```bash\n# macOS ÂÆâË£Ö pyenv\nbrew install pyenv\n\n# ÂÆâË£Ö Python\npyenv install 3.13.2\npyenv global 3.13.2\n```\n\n### 2. uv ÂåÖÁÆ°ÁêÜÂ∑•ÂÖ∑\n\nuv ÊòØ‰∏Ä‰∏™Âø´ÈÄüÁöÑ Python ÂåÖÁÆ°ÁêÜÂô®ÔºåÈúÄË¶ÅÂÖàÂÆâË£ÖÔºö\n\n```bash\n# macOS ÂÆâË£Ö uv\nbrew install uv\n\n# ÊàñËÄÖ‰ΩøÁî® pip ÂÆâË£Ö\npip install uv\n```\n\n### 3. ÂõæÁâáAPIÂØÜÈí•\n\n#### Unsplash API ÂØÜÈí•\n1. ËÆøÈóÆ [Unsplash Developers](https://unsplash.com/developers)\n2. Ê≥®ÂÜå/ÁôªÂΩïË¥¶Âè∑\n3. ÂàõÂª∫Êñ∞ÁöÑÂ∫îÁî®Á®ãÂ∫è\n4. Ëé∑Âèñ Access Key\n\n#### Pexels API ÂØÜÈí•\n1. ËÆøÈóÆ [Pexels API](https://www.pexels.com/api/)\n2. Ê≥®ÂÜå/ÁôªÂΩïË¥¶Âè∑\n3. ËØ∑Ê±ÇAPIÂØÜÈí•\n\n#### Pixabay API ÂØÜÈí•\n1. ËÆøÈóÆ [Pixabay API](https://pixabay.com/api/docs/)\n2. Ê≥®ÂÜå/ÁôªÂΩïË¥¶Âè∑\n3. Ëé∑ÂèñAPIÂØÜÈí•\n\n#### Together AI API ÂØÜÈí•\n1. ËÆøÈóÆ [Together AI API Keys](https://api.together.xyz/keys)\n2. Ê≥®ÂÜå/ÁôªÂΩïË¥¶Âè∑\n3. ÂàõÂª∫Êñ∞ÁöÑ API ÂØÜÈí•\n\n### 4. Cursor\n\n* ‰∏ãËΩΩÂπ∂ÂÆâË£Ö [Cursor IDE](https://cursor.sh/)\n* Á°Æ‰øù Cursor Â∑≤Ê≠£Á°ÆÈÖçÁΩÆ Python ÁéØÂ¢É\n\n## ÂÆâË£ÖÈÖçÁΩÆ\n\n1. ÂÖãÈöÜÈ°πÁõÆÔºö\n\n```bash\ngit clone https://github.com/yanjunz/mcp_search_images.git\n```\n\n2. ÂÆâË£Ö‰æùËµñÔºö\n\n```bash\npython3 -m pip install fastmcp requests\n```\n\nÂá∫Áé∞ËØÅ‰π¶ÈóÆÈ¢òÂèØ‰ª•‰ΩøÁî®Ôºö\n\n```bash\npython3 -m pip install fastmcp requests --trusted-host pypi.org --trusted-host files.pythonhosted.org --upgrade --force-reinstall --no-cache-dir\n```\n\n3. ÈÖçÁΩÆ API ÂØÜÈí•Ôºö\n\n‰ªéÊ®°ÊùøÂàõÂª∫ÈÖçÁΩÆÊñá‰ª∂Ôºö\n\n```bash\n# Â§çÂà∂Ê®°ÊùøÊñá‰ª∂‰Ωú‰∏∫ÈÖçÁΩÆÊñá‰ª∂\ncp config.json.template config.json\n\n# ÁºñËæëÈÖçÁΩÆÊñá‰ª∂ÔºåËÆæÁΩÆAPIÂØÜÈí•\nnano config.json  # Êàñ‰ΩøÁî®ÂÖ∂‰ªñÁºñËæëÂô®\n```\n\nÂú® `config.json` ‰∏≠‰øÆÊîπ‰ª•‰∏ãÈÖçÁΩÆÔºö\n\n```json\n{\n    \"api\": {\n        \"unsplash_access_key\": \"‰Ω†ÁöÑUnsplashËÆøÈóÆÂØÜÈí•\",\n        \"pexels_api_key\": \"‰Ω†ÁöÑPexels APIÂØÜÈí•\",\n        \"pixabay_api_key\": \"‰Ω†ÁöÑPixabay APIÂØÜÈí•\",\n        \"together_api_key\": \"‰Ω†ÁöÑTogether APIÂØÜÈí•\",\n        \"timeout\": 30,\n        \"max_retries\": 3,\n        \"retry_delay\": 5\n    },\n    // ...ÂÖ∂‰ªñÈÖçÁΩÆ...\n}\n```\n\n\u003e **Ê≥®ÊÑè**ÔºöËØ∑Á°Æ‰øù‰∏çË¶ÅÂ∞ÜÂåÖÂê´APIÂØÜÈí•ÁöÑÈÖçÁΩÆÊñá‰ª∂Êèê‰∫§Âà∞ÁâàÊú¨ÊéßÂà∂Á≥ªÁªü‰∏≠„ÄÇ\n\u003e È°πÁõÆ‰∏≠ÁöÑ `.gitignore` Êñá‰ª∂Â∑≤ÈÖçÁΩÆ‰∏∫ÂøΩÁï• `config.json`Ôºå‰ΩÜ‰øùÁïô `config.json.template`„ÄÇ\n\n## ËøêË°åÊúçÂä°\n\n### ÊñπÊ≥ï‰∏ÄÔºöÁõ¥Êé•‰ΩøÁî®PythonËøêË°å\n\nËøôÊòØÊúÄÁÆÄÂçïÁöÑÊñπÂºèÔºåÁõ¥Êé•‰ΩøÁî®PythonËøêË°åÊúçÂä°Ôºö\n\n```bash\npython3.11 main.py\n```\n\nÊúçÂä°ÂêØÂä®Âêé‰ºöÊòæÁ§∫‰ª•‰∏ã‰ø°ÊÅØ:\n```\nÂêØÂä®ÂõæÁâáÊêúÁ¥¢ÊúçÂä° - Á´ØÂè£: 5173\nÊèê‰æõÁöÑÂ∑•ÂÖ∑: search_images, download_image, generate_icon\nINFO:     Started server process [xxxxx]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:5173 (Press CTRL+C to quit)\n```\n\n### ÊñπÊ≥ï‰∫åÔºö‰ΩøÁî®fastmcpÂëΩ‰ª§ËøêË°å\n\nÂ¶ÇÊûúÊÇ®ÂÆâË£Ö‰∫ÜfastmcpÂåÖÔºå‰πüÂèØ‰ª•‰ΩøÁî®fastmcpÂëΩ‰ª§ËøêË°åÔºö\n\n1. ÂºÄÂèëÊ®°ÂºèËøêË°åÔºàÂ∏¶Ë∞ÉËØïÁïåÈù¢ÔºâÔºö\n\n```bash\nfastmcp dev main.py\n```\n\n2. Áîü‰∫ßÊ®°ÂºèËøêË°åÔºö\n\n```bash\nfastmcp run main.py\n```\n\n3. Â¶ÇÊûúÁ´ØÂè£Ë¢´Âç†Áî®ÔºåÂèØ‰ª•ÊåáÂÆöÂÖ∂‰ªñÁ´ØÂè£Ôºö\n\n```bash\nPORT=5174 fastmcp dev main.py\n```\n\n### ÊñπÊ≥ï‰∏âÔºö‰ΩøÁî®uvËøêË°å\n\nÂ¶ÇÊûúÊÇ®‰ΩøÁî®uv‰Ωú‰∏∫ÂåÖÁÆ°ÁêÜÂô®Ôºö\n\n```bash\nuv run --with fastmcp fastmcp run main.py\n```\n\nÊàñËÄÖÂú®ÂºÄÂèëÊ®°Âºè‰∏ãÔºö\n\n```bash\nuv run --with fastmcp fastmcp dev main.py\n```\n\n### Cursor‰∏éMCPÁöÑÂ∑•‰ΩúÂéüÁêÜ\n\n‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåËß£ÂÜ≥ËøûÊé•ÈóÆÈ¢òÔºå‰ª•‰∏ãÊòØCursor‰∏éMCPÊúçÂä°‰∫§‰∫íÁöÑÂü∫Êú¨Â∑•‰ΩúÂéüÁêÜÔºö\n\n1. **MCPÊúçÂä°ÂêØÂä®ÊµÅÁ®ã**Ôºö\n   * ÂΩìËøêË°å`python3.11 main.py`Êó∂ÔºåÊúçÂä°ÂàùÂßãÂåñÂπ∂ÂàõÂª∫SSEÔºàServer-Sent EventsÔºâÂ∫îÁî®\n   * ÊúçÂä°Âú®ÊåáÂÆöÁ´ØÂè£ÔºàÈªòËÆ§5173ÔºâÂºÄÂßãÁõëÂê¨ËØ∑Ê±Ç\n   * ÊúçÂä°Ê≥®ÂÜåÂ∑•ÂÖ∑ÂáΩÊï∞Ôºàsearch_images, download_image, generate_iconÔºâ\n   * ÂØπ‰∫é‰ΩøÁî®ServerLinkÊñπÂºèÁöÑËøûÊé•ÔºåÊúçÂä°ÈúÄË¶ÅÂú®`/sse`Ë∑ØÂæÑ‰∏äÊ≠£Á°ÆÂ§ÑÁêÜSSEËØ∑Ê±Ç\n\n2. **CursorËøûÊé•ÊµÅÁ®ã**Ôºö\n   * ÂΩìÂú®CursorËÆæÁΩÆ‰∏≠Ê∑ªÂä†MCPÂ∑•ÂÖ∑Êó∂ÔºåCursorÂ∞ùËØï‰∏éÊèê‰æõÁöÑURLÂª∫Á´ãËøûÊé•\n   * CursorÂèëÈÄÅÂàùÂßãÂåñËØ∑Ê±ÇÔºåÊ£ÄÊü•ÊúçÂä°ÊòØÂê¶Ê≠£Â∏∏ÂìçÂ∫î\n   * ÊúçÂä°ÈúÄË¶ÅËøîÂõûÊ≠£Á°ÆÁöÑMCPÂçèËÆÆÂìçÂ∫îÔºåÂåÖÊã¨ÂèØÁî®Â∑•ÂÖ∑ÂàóË°®\n   * ËøûÊé•ÊàêÂäüÂêéÔºåCursor‰ºöÂ∞ÜËØ•Â∑•ÂÖ∑Ê∑ªÂä†Âà∞ÂèØÁî®Â∑•ÂÖ∑ÂàóË°®\n   \n3. **ËØäÊñ≠ËøûÊé•ÈóÆÈ¢ò**Ôºö\n   * Ê£ÄÊü•ÊúçÂä°ÊòØÂê¶Âú®ËøêË°åÔºö`lsof -i :5173`\n   * Ê£ÄÊü•ÁΩëÁªúËøûÊé•Ôºö`curl http://localhost:5173`\n   * Ê£ÄÊü•ÊúçÂä°ÊòØÂê¶Ê≠£Á°ÆÂÆûÁé∞MCPÂçèËÆÆÔºöÊúçÂä°ÂêØÂä®Êó•ÂøóÂ∫îÊòæÁ§∫Ê≥®ÂÜåÁöÑÂ∑•ÂÖ∑\n   * Ê£ÄÊü•Èò≤ÁÅ´Â¢ôÂíåÁΩëÁªúÊùÉÈôêÔºöÊú¨Âú∞ÊúçÂä°ÊúâÊó∂ÂèØËÉΩË¢´Èò≤ÁÅ´Â¢ôÈòªÊ≠¢\n   \n4. **ÂÆåÊï¥ÁöÑÊµãËØïÊµÅÁ®ã**Ôºö\n   ```bash\n   # 1. ÂÅúÊ≠¢‰ªª‰ΩïÂèØËÉΩÊ≠£Âú®ËøêË°åÁöÑÊúçÂä°\n   pkill -f \"python.*main.py\"\n   \n   # 2. ÂêØÂä®ÊúçÂä°ÔºàÂú®ÂâçÂè∞ËøêË°å‰ª•Êü•ÁúãÊó•ÂøóÔºâ\n   python3.11 main.py\n   \n   # 3. Âú®Êñ∞ÁöÑÁªàÁ´ØÁ™óÂè£‰∏≠ÔºåÊµãËØïËøûÊé•\n   curl http://localhost:5173\n   \n   # 4. ÊµãËØïSSEÁ´ØÁÇπÔºàÁî®‰∫éServerLinkÊñπÂºèÔºâ\n   curl http://localhost:5173/sse\n   \n   # 5. Âú®Cursor‰∏≠Ê∑ªÂä†MCPÂ∑•ÂÖ∑Âπ∂ÊµãËØï\n   ```\n\nÂ¶ÇÊûúÊåâÁÖß‰ª•‰∏äÊ≠•È™§Êìç‰ΩúÂêé‰ªçÁÑ∂Êó†Ê≥ïËøûÊé•ÔºåÂèØËÉΩÈúÄË¶ÅÊ£ÄÊü•PythonÁâàÊú¨ÂÖºÂÆπÊÄßÊàñ‰æùËµñÂåÖÊòØÂê¶Ê≠£Á°ÆÂÆâË£Ö„ÄÇÊúâÊó∂ÈáçÊñ∞ÂÆâË£Ö‰æùËµñÂåÖ‰πüÊúâÂ∏ÆÂä©Ôºö\n\n```bash\npython3.11 -m pip uninstall fastmcp mcp uvicorn starlette -y\npython3.11 -m pip install fastmcp mcp uvicorn starlette\n```\n\n## ‰ΩøÁî®ËØ¥Êòé\n\n### Âú® Cursor IDE ‰∏≠‰ΩøÁî®\n\n1. Á°Æ‰øùÊúçÂä°Ê≠£Âú®ËøêË°å\n   ```bash\n   # Áõ¥Êé•ËøêË°åPythonËÑöÊú¨\n   python3.11 main.py\n   ```\n   ÊúçÂä°ÂêØÂä®Âêé‰ºöÊòæÁ§∫‰ª•‰∏ã‰ø°ÊÅØ:\n   ```\n   ÂêØÂä®ÂõæÁâáÊêúÁ¥¢ÊúçÂä° - Á´ØÂè£: 5173\n   Êèê‰æõÁöÑÂ∑•ÂÖ∑: search_images, download_image, generate_icon\n   INFO:     Started server process [xxxxx]\n   INFO:     Waiting for application startup.\n   INFO:     Application startup complete.\n   INFO:     Uvicorn running on http://0.0.0.0:5173 (Press CTRL+C to quit)\n   ```\n\n2. Âú®Cursor‰∏≠Ê∑ªÂä†MCPÊúçÂä°:\n   * ÊâìÂºÄCursor IDE\n   * ÁÇπÂáªÂ∑¶‰∏ãËßíÁöÑÈΩøËΩÆÂõæÊ†áÔºåÊâìÂºÄËÆæÁΩÆ\n   * ÈÄâÊã©\"AI \u0026 Copilot\"ËÆæÁΩÆ\n   * Âú®\"MCPÂ∑•ÂÖ∑\"ÈÉ®ÂàÜÁÇπÂáª\"Ê∑ªÂä†MCPÂ∑•ÂÖ∑\"\n   * Â°´ÂÜô‰ª•‰∏ã‰ø°ÊÅØ:\n     - ÂêçÁß∞: ÂõæÁâáÊêúÁ¥¢ÊúçÂä°\n     - Á±ªÂûã: SSE (Server-Sent Events)\n     - URL: http://localhost:5173\n     - ÁÇπÂáª\"‰øùÂ≠ò\"\n     \n   **Â§áÈÄâÈÖçÁΩÆÊñπÊ≥ï**:\n   * Êüê‰∫õÁâàÊú¨ÁöÑCursorÂèØËÉΩÈúÄË¶Å‰ΩøÁî®ServerLinkÈÖçÁΩÆ:\n     - ÂêçÁß∞: ÂõæÁâáÊêúÁ¥¢ÊúçÂä°\n     - Á±ªÂûã: sse\n     - ServerLink: http://localhost:5173/sse\n     - ÁÇπÂáª\"‰øùÂ≠ò\"\n\n   \u003e **Ê≥®ÊÑè**: Â¶ÇÊûúÂá∫Áé∞\"Fail to create client\"ÈîôËØØÔºåËØ∑Ê£ÄÊü•‰ª•‰∏ãÂá†ÁÇπ:\n   \u003e 1. Á°ÆËÆ§ÊúçÂä°Ê≠£Âú®ËøêË°å (ÈÄöËøá`lsof -i :5173`Ê£ÄÊü•Á´ØÂè£ÊòØÂê¶Ë¢´ÁõëÂê¨)\n   \u003e 2. Â∞ùËØïÂú®ÊµèËßàÂô®‰∏≠ËÆøÈóÆ`http://localhost:5173`ÊµãËØïËøûÊé•ÊÄß\n   \u003e 3. Á°Æ‰øùURLÊ≤°ÊúâÂ§ö‰ΩôÁöÑÊñúÊù†ÊàñÁ©∫Ê†º\n   \u003e 4. ÂØπ‰∫éServerLinkÊñπÂºèÔºåÁ°Æ‰øù‰ΩøÁî®Ê≠£Á°ÆÁöÑÁ´ØÁÇπË∑ØÂæÑ`/sse`\n   \u003e 5. ÈáçÂêØÊúçÂä°ÂêéÂÜçÊ¨°Â∞ùËØïÊ∑ªÂä†\n   \u003e 6. ÊúâÊó∂ÈúÄË¶ÅÈáçÂêØCursor IDE‰ª•Ê∏ÖÈô§‰πãÂâçÁöÑËøûÊé•ÁºìÂ≠ò\n\n3. ÂºÄÂßã‰ΩøÁî®MCPÂ∑•ÂÖ∑:\n   * Âú®Cursor‰∏≠ÊâìÂºÄÂåÖÂê´ClaudeÊàñÂÖ∂‰ªñÊîØÊåÅÂ∑•ÂÖ∑Ë∞ÉÁî®ÁöÑÂ§ßÊ®°ÂûãÂØπËØùÁ™óÂè£\n   * ÂΩìÊúçÂä°Ê≠£Âú®ËøêË°åÊó∂ÔºåÂ§ßÊ®°ÂûãÂèØ‰ª•Ëá™Âä®ÂèëÁé∞Âπ∂‰ΩøÁî®ËØ•Â∑•ÂÖ∑\n   * Â¶ÇÊûúÂ§ßÊ®°ÂûãÊú™Ëá™Âä®ÂèëÁé∞Â∑•ÂÖ∑ÔºåÂèØ‰ª•ÊèêÁ§∫ÂÆÉ:\"ËØ∑‰ΩøÁî®ÂõæÁâáÊêúÁ¥¢ÊúçÂä°Êù•Êü•ÊâæÂõæÁâá\"\n\n4. Âú®ÂºÄÂèëËøáÁ®ã‰∏≠ÈöèÊó∂‰ΩøÁî®:\n   * ÁºñÂÜô‰ª£Á†ÅÊó∂ÈúÄË¶ÅÂõæÊ†áÁ¥†ÊùêÔºåÂèØ‰ª•Áõ¥Êé•ÂêëÂ§ßÊ®°ÂûãÊèèËø∞ÈúÄÊ±Ç\n   * ‰æãÂ¶Ç:\"Â∏ÆÊàëÊâæ‰∏Ä‰∫õÈÄÇÂêà‰Ωú‰∏∫ÁôªÂΩïÊåâÈíÆÁöÑÂõæÊ†á\"\n   * Â§ßÊ®°Âûã‰ºöË∞ÉÁî®MCPÂ∑•ÂÖ∑ÊêúÁ¥¢ÂõæÁâáÂπ∂Â±ïÁ§∫ÁªìÊûú\n   * ‰Ω†ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Ë¶ÅÊ±Ç‰∏ãËΩΩÊàñÁîüÊàêËá™ÂÆö‰πâÂõæÊ†á\n\n5. Êü•ÁúãÂõæÊ†á‰øùÂ≠ò‰ΩçÁΩÆ:\n   * ÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåÂõæÊ†á‰ºö‰øùÂ≠òÂú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÁöÑ`icons`Êñá‰ª∂Â§π‰∏≠\n   * ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§Êü•ÁúãÂ∑≤‰øùÂ≠òÁöÑÂõæÊ†á:\n     ```bash\n     ls -la icons\n     ```\n\n### ÂäüËÉΩ‰ΩøÁî®Á§∫‰æã\n\n#### ÊêúÁ¥¢ÂõæÁâá\n\nÂèØ‰ª•Áõ¥Êé•ÂêëÂ§ßÊ®°ÂûãÊèèËø∞ÈúÄÊ±Ç:\n```\nÊêúÁ¥¢ÂÖ≥ÈîÆËØç‰∏∫\"technology\"ÁöÑÂõæÁâá\n```\nÊàñÊõ¥ÂÖ∑‰ΩìÁöÑÊèèËø∞:\n```\nËØ∑Âú®Unsplash‰∏äÊêúÁ¥¢5Âº†ÂÖ≥‰∫é\"artificial intelligence\"ÁöÑÂõæÁâá\n```\n\n#### ‰∏ãËΩΩÂõæÁâá\n\nÂΩìÂ§ßÊ®°ÂûãÊòæÁ§∫ÊêúÁ¥¢ÁªìÊûúÂêéÔºå‰Ω†ÂèØ‰ª•Ë¶ÅÊ±Ç‰∏ãËΩΩÁâπÂÆöÂõæÁâá:\n```\n‰∏ãËΩΩÁ¨¨2Âº†ÂõæÁâáÂπ∂‰øùÂ≠ò‰∏∫tech-icon.png\n```\nÊàñËÄÖÊåáÂÆö‰øùÂ≠òË∑ØÂæÑ:\n```\nÂ∞ÜÁ¨¨3Âº†ÂõæÁâá‰∏ãËΩΩÂà∞/Users/username/Desktop/ÔºåÊñá‰ª∂Âêç‰∏∫ai-image.jpg\n```\n\n#### ÁîüÊàêÂõæÊ†á\n\nÂèØ‰ª•Êèê‰æõËØ¶ÁªÜÁöÑÊèèËø∞Êù•ÁîüÊàêÁ¨¶ÂêàÈúÄÊ±ÇÁöÑÂõæÊ†á:\n```\nÁîüÊàê‰∏Ä‰∏™ËìùËâ≤ÁßëÊäÄÈ£éÊ†ºÁöÑÂõæÊ†áÔºå‰øùÂ≠ò‰∏∫blue-tech.png\n```\nÊàñËÄÖÊõ¥ËØ¶ÁªÜÁöÑÊèèËø∞:\n```\nËØ∑ÂàõÂª∫‰∏Ä‰∏™ÊâÅÂπ≥ÂåñËÆæËÆ°ÁöÑÈÇÆ‰ª∂ÂõæÊ†áÔºåÁ∫¢Ëâ≤ËΩÆÂªìÔºåÁôΩËâ≤ËÉåÊôØÔºåÂõæÊ†áÂ∞∫ÂØ∏‰∏∫256x256Ôºå‰øùÂ≠ò‰∏∫email-icon.png\n```\n\n### ÂÆûÈôÖÂØπËØùÁ§∫‰æã\n\nÊü•Áúã[Á§∫‰æãÂØπËØù](examples/dialog_example.md)‰∫ÜËß£Â¶Ç‰ΩïÂú®ÂÆûÈôÖ‰ΩøÁî®‰∏≠‰∏éClaude/Â§ßÊ®°Âûã‰∫§‰∫íÊù•ÊêúÁ¥¢ÂíåÁîüÊàêÂõæÊ†á„ÄÇ\n\n### ÈõÜÊàêÂà∞È°πÁõÆÂ∑•‰ΩúÊµÅ\n\n1. Âú®È°πÁõÆÂàùÂßãÈò∂ÊÆµÊâπÈáèÁîüÊàêÂõæÊ†á:\n   * ÂàõÂª∫ËÆæËÆ°Á≥ªÁªüÊó∂ÔºåÂèØ‰ª•‰∏ÄÊ¨°ÊÄßÁîüÊàêÂ§ö‰∏™Áõ∏ÂÖ≥ÂõæÊ†á\n   * ‰æãÂ¶Ç:\"Â∏ÆÊàëÁîüÊàê‰∏ÄÂ•óÂåÖÂê´‰∏ªÈ°µ„ÄÅËÆæÁΩÆ„ÄÅÁî®Êà∑„ÄÅÊ∂àÊÅØÈÄöÁü•ÁöÑÂ∫îÁî®ÂõæÊ†á\"\n\n2. ÂºÄÂèëËøáÁ®ã‰∏≠ÊåâÈúÄÊêúÁ¥¢:\n   * Âú®ÁºñÂÜô‰ª£Á†ÅÊó∂ÈöèÊó∂Êü•ÊâæÊâÄÈúÄÂõæÁâáËµÑÊ∫ê\n   * ‰æãÂ¶Ç:\"ÊàëÊ≠£Âú®ÂºÄÂèë‰∏Ä‰∏™Â§©Ê∞îÂ∫îÁî®ÔºåÈúÄË¶ÅÂá†‰∏™Â§©Ê∞îÁõ∏ÂÖ≥ÁöÑÂõæÊ†á\"\n\n3. È°πÁõÆÂÆåÂñÑÈò∂ÊÆµÂÆöÂà∂ÂõæÊ†á:\n   * Ê†πÊçÆÂ∫îÁî®È£éÊ†ºÁªü‰∏Ä‰ºòÂåñÂõæÊ†á\n   * ‰æãÂ¶Ç:\"ÁîüÊàê‰∏ÄÁªÑ‰∏éÊàëÂΩìÂâçÂ∫îÁî®È£éÊ†º‰∏ÄËá¥ÁöÑÁ§æ‰∫§Â™í‰ΩìÂàÜ‰∫´ÂõæÊ†á\"\n\n### ÊúÄ‰Ω≥ÂÆûË∑µ\n\n1. **‰ΩøÁî®ÊòéÁ°ÆÁöÑÂÖ≥ÈîÆËØç**: ÊêúÁ¥¢Êó∂‰ΩøÁî®ÂÖ∑‰Ωì„ÄÅÊòéÁ°ÆÁöÑÂÖ≥ÈîÆËØçËé∑ÂæóÊõ¥Á≤æÁ°ÆÁöÑÁªìÊûú\n2. **ÊåáÂÆöÂõæÁâáÊ∫ê**: Ê†πÊçÆÈúÄÊ±ÇÈÄâÊã©ÂêàÈÄÇÁöÑÂõæÁâáÊ∫êÔºàUnsplashÈÄÇÂêàËá™ÁÑ∂È£éÂÖâÔºåPixabayÈÄÇÂêàÂïÜ‰∏öÂõæÁâáÁ≠âÔºâ\n3. **‰øùÂ≠òÁªìÊûÑÂåñÂëΩÂêç**: ‰∏∫ÂõæÊ†á‰ΩøÁî®ÁªìÊûÑÂåñÂëΩÂêçÔºåÂ¶Ç`category-name-size.png`\n4. **ÊâπÈáèÊìç‰Ωú**: ‰∏ÄÊ¨°ÊÄßËØ∑Ê±ÇÂ§ö‰∏™Áõ∏ÂÖ≥ÂõæÊ†áËÄå‰∏çÊòØÈÄê‰∏™ËØ∑Ê±Ç\n5. **‰∏é‰ª£Á†ÅÁªìÂêà**: Âú®ÂÆûÈôÖÂºÄÂèë‰∏≠ÊèêÂèä‰ª£Á†Å‰∏ä‰∏ãÊñáÔºåÂ§ßÊ®°ÂûãÂèØ‰ª•Êõ¥ÂáÜÁ°ÆÂú∞ÁêÜËß£‰Ω†ÁöÑÈúÄÊ±Ç\n\n## ÈîôËØØÊéíÊü•\n\n### Cursor MCPËøûÊé•ÈîôËØØ\n\nÂ¶ÇÊûúÂú®Cursor‰∏≠Ê∑ªÂä†MCPÊúçÂä°Êó∂ÈÅáÂà∞\"Fail to create client\"ÈîôËØØÔºåËØ∑Â∞ùËØï‰ª•‰∏ãËß£ÂÜ≥ÊñπÊ≥ïÔºö\n\n1. **Ê£ÄÊü•ÊúçÂä°Áä∂ÊÄÅ**Ôºö\n   ```bash\n   # Ê£ÄÊü•ÊúçÂä°ÊòØÂê¶Ê≠£Âú®ËøêË°å\n   lsof -i :5173\n   # Â¶ÇÊûúÊ≤°ÊúâËæìÂá∫ÔºåË°®Á§∫ÊúçÂä°Êú™ËøêË°åÔºåËØ∑ÂêØÂä®ÊúçÂä°\n   python3.11 main.py\n   ```\n\n2. **ÊµãËØïËøûÊé•**Ôºö\n   ```bash\n   # ‰ΩøÁî®curlÊµãËØïAPIËøûÊé•\n   curl -v http://localhost:5173\n   ```\n\n3. **‰øÆÊîπËøûÊé•ËÆæÁΩÆ**Ôºö\n   * Á°Æ‰øùÈÄâÊã©‰∫ÜÊ≠£Á°ÆÁöÑËøûÊé•Á±ªÂûãÔºöSSE\n   * Â∞ùËØï‰ΩøÁî®IPÂú∞ÂùÄ‰ª£ÊõølocalhostÔºö`http://127.0.0.1:5173`\n   * Á°Æ‰øùURL‰∏çÂê´È¢ùÂ§ñÊñúÊù†Ôºö‰ΩøÁî®`http://localhost:5173`ËÄåÈùû`http://localhost:5173/`\n   * Â∞ùËØï‰ΩøÁî®ServerLinkÊñπÂºèÈÖçÁΩÆÔºö\n     - Á±ªÂûã: sse\n     - ServerLink: http://localhost:5173/sse\n   * Êúâ‰∫õÁâàÊú¨ÁöÑCursorÂèØËÉΩÂØπURLÊ†ºÂºèÊúâÁâπÂÆöË¶ÅÊ±ÇÔºå‰∏§ÁßçÊñπÂºèÈÉΩÂÄºÂæóÂ∞ùËØï\n\n4. **ÈáçÂêØÁªÑ‰ª∂**Ôºö\n   * ÂÅúÊ≠¢Âπ∂ÈáçÂêØMCPÊúçÂä°\n   * ÈáçÂêØCursor IDE\n   * Â¶ÇÊûú‰ΩøÁî®macOSÔºåÊ£ÄÊü•Èò≤ÁÅ´Â¢ôËÆæÁΩÆÊòØÂê¶ÈòªÊ≠¢‰∫ÜËøûÊé•\n\n5. **Ê£ÄÊü•Êó•Âøó**Ôºö\n   * ËßÇÂØüÊúçÂä°ÂêØÂä®Êó∂ÁöÑÊó•ÂøóËæìÂá∫\n   * ÂΩìÂ∞ùËØï‰ªéCursorËøûÊé•Êó∂ÔºåÊü•ÁúãÊúçÂä°Á´ØÊúâÊó†Êñ∞ÁöÑÊó•ÂøóËæìÂá∫\n\n6. **Â∞ùËØïÂÖ∂‰ªñÁ´ØÂè£**Ôºö\n   * ‰øÆÊîπ‰ª£Á†Å‰∏≠ÁöÑÁ´ØÂè£ÔºàÂ¶ÇÊîπ‰∏∫5174ÔºâÂπ∂ÈáçÂêØÊúçÂä°Ôºö\n   ```python\n   uvicorn.run(sse_app, host=\"0.0.0.0\", port=5174)\n   ```\n\n### ÂÖ∂‰ªñÂ∏∏ËßÅÈóÆÈ¢ò\n\nÂ¶ÇÊûúÈÅáÂà∞ÈóÆÈ¢òÔºåËØ∑Ê£ÄÊü•Ôºö\n\n1. ÊúçÂä°ÊòØÂê¶Ê≠£Â∏∏ËøêË°å\n2. ‰øùÂ≠òË∑ØÂæÑÊòØÂê¶Ê≠£Á°Æ\n3. ÁõÆÂΩïÊùÉÈôêÊòØÂê¶Ê≠£Á°Æ\n4. ÁΩëÁªúËøûÊé•ÊòØÂê¶Ê≠£Â∏∏\n5. API ÂØÜÈí•ÊòØÂê¶ÊúâÊïà\n6. Python ÁéØÂ¢ÉÊòØÂê¶Ê≠£Á°ÆÈÖçÁΩÆ\n7. uv ÊòØÂê¶Ê≠£Á°ÆÂÆâË£Ö\n8. ‰æùËµñÂåÖÊòØÂê¶ÂÆåÊï¥ÂÆâË£Ö\n\n## Ë¥°ÁåÆ\n\nÊ¨¢ËøéÊèê‰∫§ÈóÆÈ¢òÂíåÊãâÂèñËØ∑Ê±ÇÊù•ÊîπËøõÈ°πÁõÆ„ÄÇ\n\n## ËÆ∏ÂèØ\n\n[MIT License](LICENSE)",
      "stars": 10,
      "updated_at": "2025-09-15T13:46:13Z",
      "url": "https://github.com/yanjunz/mcp_search_images"
    },
    "yunwoong7--aws-nova-canvas-mcp": {
      "category": "image-and-video-generation",
      "description": "Generate and edit images with advanced features such as text-to-image generation, image inpainting, and background removal, using the Nova Canvas model from Amazon Bedrock.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/yunwoong7.webp",
      "keywords": [
        "canvas",
        "bedrock",
        "images",
        "nova canvas",
        "canvas mcp",
        "generation image"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "aws-nova-canvas-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "yunwoong7",
      "readme_content": "\u003ch2 align=\"center\"\u003e\nAWS Nova Canvas MCP Server\n\u003c/h2\u003e\n\n\u003cdiv align=\"center\"\u003e\n  \u003cimg alt=\"Python_3_12_3776AB_logo_python\" src=\"https://img.shields.io/badge/Python-3.12-3776AB?logo=python\"/\u003e\n  \u003cimg alt=\"Amazon_Bedrock_FF9900_logo_amazon_logoColor_white\" src=\"https://img.shields.io/badge/Amazon-Bedrock-FF9900?logo=amazon\u0026logoColor=white\"/\u003e\n\u003c/div\u003e\n\nAn MCP server that allows you to generate and edit images using the Nova Canvas model of Amazon Bedrock.\n\n## Features\n\n- Text to Image\n- Image Inpainting\n- Image Outpainting\n- Image Variation\n- Image Conditioning\n- Color Guided Generation\n- Background Removal\n- Show Image Thumbnails\n\n## Installation\n\n### Claude Desktop Setup\n\n1. Configure Claude Desktop\n   * Click on **Claude \u003e Settings** from the Claude Desktop menu.\n   * When the popup appears, select **Developer** from the left menu, and click the **Edit Settings** button.\n   * This will open a folder containing the settings file. The name of this settings file is:\n   * `claude_desktop_config.json`\n\n\u003cdiv align=\"center\"\u003e\n\u003cimg alt=\"img\" src=\"https://blog.kakaocdn.net/dn/bIl5q9/btsM3U5Vjw5/aGruWqP3wNmWZ1sKrnhbPk/img.png\" width=\"70%\"\u003e\n\u003c/div\u003e\n\n3. Add the following content to the settings file (Python version):\n\n   - python version\n\n     ```json\n     \"nova-canvas\": {\n       \"command\": \"uvx\",\n       \"args\": [\n         \"aws-nova-canvas-mcp\"\n       ],\n       \"env\": {\n         \"AWS_PROFILE\": \"YOUR_AWS_PROFILE\"\n       }\n     }\n     ```\n\n     \u003e ‚úÖ Only AWS_PROFILE is required. Other variables like AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, and PORT are optional and not necessary if your AWS profile is set correctly.\n     \u003e\n     \u003e ‚Äã\t‚öôÔ∏è If the setup is completed successfully, you can see that the \"nova-canvas\" item has been added in **Claude \u003e Settings \u003e Developer tab**.\n     \u003e ‚ö†Ô∏è **Important:** MCP settings only work on the **Claude desktop app, not the Claude web browser version**\n\n## Image Save Location\n\nBy default, all generated or edited images will be saved in the following directory:\n\n* **macOS / Linux**:  `~/Desktop/aws-nova-canvas`\n* **Windows**:  `C:\\Users\\YourUsername\\Desktop\\aws-nova-canvas`\n\n\u003e üìÅ If no image save path is specified, the application will automatically create and use the folder above.\n\n\u003cdiv align=\"center\"\u003e\n\u003cimg alt=\"img\" src=\"https://blog.kakaocdn.net/dn/bpUWLj/btsM4kJZC6v/HHQfQctKsevWnK6LCKEkv0/img.png\" width=\"70%\"\u003e\n\u003c/div\u003e\n\n## Usage Example\n\n\u003cdiv align=\"center\"\u003e\n\u003cimg alt=\"img\" src=\"https://blog.kakaocdn.net/dn/uNi8L/btsM4pEjswV/hSfxo1gHzPvpXPsEEyuijk/img.gif\" width=\"70%\"\u003e\n\u003c/div\u003e\n\n## Limitations\n\n- Prompt text supports up to 1024 characters\n- Image generation allows up to 3 images at a time\n- Image variation requires 1-5 reference images\n- Color guide supports 1-10 color codes\n\n## License\n\nMIT License\n",
      "stars": 4,
      "updated_at": "2025-06-22T12:28:20Z",
      "url": "https://github.com/yunwoong7/aws-nova-canvas-mcp"
    },
    "zjf2671--hh-mcp-comfyui": {
      "category": "image-and-video-generation",
      "description": "Integrates with local ComfyUI instances via API calls to enable natural language-driven image generation. Supports dynamic parameter replacement in workflows and automatic loading of workflow files as resources.",
      "forks": 3,
      "imageUrl": "/freedevtools/mcp/pfp/zjf2671.webp",
      "keywords": [
        "comfyui",
        "image",
        "dynamic",
        "comfyui instances",
        "comfyui integrates",
        "mcp comfyui"
      ],
      "language": "Python",
      "license": "MIT License",
      "name": "hh-mcp-comfyui",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "zjf2671",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zjf2671-hh-mcp-comfyui-badge.png)](https://mseep.ai/app/zjf2671-hh-mcp-comfyui)\n\n# ComfyUI MCP ÊúçÂä°\n\n[![English](https://img.shields.io/badge/English-Click-yellow)](docs/README.EN.md)\n[![ÁÆÄ‰Ωì‰∏≠Êñá](https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-ÁÇπÂáªÊü•Áúã-orange)](README.md)\n![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LiCENSE)\n[![smithery badge](https://smithery.ai/badge/@zjf2671/hh-mcp-comfyui)](https://smithery.ai/server/@zjf2671/hh-mcp-comfyui)\n\nËøôÊòØ‰∏Ä‰∏™Âü∫‰∫éModel Context Protocol (MCP)ÁöÑComfyUIÂõæÂÉèÁîüÊàêÊúçÂä°ÔºåÈÄöËøáAPIË∞ÉÁî®Êú¨Âú∞ComfyUIÂÆû‰æãÁîüÊàêÂõæÁâá„ÄÇ\n\n## ÂäüËÉΩÁâπÊÄß\n\n- ÈÄöËøáMCPÂçèËÆÆÊèê‰æõÂõæÂÉèÁîüÊàêÊúçÂä°ÔºåÂÆûÁé∞Ëá™ÁÑ∂ËØ≠Ë®ÄÁîüÂõæËá™Áî±\n- ÊîØÊåÅÂä®ÊÄÅÊõøÊç¢Â∑•‰ΩúÊµÅ‰∏≠ÁöÑÊèêÁ§∫ËØçÂíåÂ∞∫ÂØ∏Á≠âÂèÇÊï∞\n- Ëá™Âä®Âä†ËΩΩworkflowsÁõÆÂΩï‰∏ãÁöÑÂ∑•‰ΩúÊµÅÊñá‰ª∂‰Ωú‰∏∫ËµÑÊ∫ê\n\n## Êñ∞Â¢ûÂäüËÉΩËÆ∞ÂΩï\n- [2025-06-29] ÊîØÊåÅkontextÂõæÁâáÁºñËæëÂ∑•‰ΩúÊµÅ\n![edit-image-85457440acc11a9f386f8ef284fd62f2.jpg](https://image.harryzhang.site/2025/07/edit-image-85457440acc11a9f386f8ef284fd62f2.jpg)\n- [2025-05-11] ÊîØÊåÅÂ∑•‰ΩúÊµÅÊñá‰ª∂ÁõÆÂΩïÂä®ÊÄÅÈÖçÁΩÆ\n- [2025-05-09] Â¢ûÂä†dockerÊûÑÂª∫ÊñπÂºè,ÊîØÊåÅPython 3.12+\n- [2025-05-07] Â¢ûÂä†pipÊûÑÂª∫ÊñπÂºè\n- [2025-05-06] ÊääÈ°πÁõÆÁõÆÂΩïsrc/hh‰øÆÊîπÊàêsrc/hh_mcp_comfyui,Â¢ûÂä†uvxÊûÑÂª∫ÊñπÂºè\n- [2025-04-26] Â¢ûÂä†ÂõæÁîüÂõæÂíåÁßªÈô§ËÉåÊôØÊ†∑‰æãÂ∑•‰ΩúÊµÅÂèäÊîØÊåÅÂõæÁîüÂõæÂ∑•ÂÖ∑\n- [2025-04-20] Âä†ÂÖ•ÊñáÁîüÂõæÁîüÊàêÂ∑•ÂÖ∑\n \n## ÊïàÊûú\n\n- **Cherry Studio‰∏≠‰ΩøÁî®ÊïàÊûú**\n![image-b8f946109d63fe1ccb5e2d63933e3f9e.png](https://image.harryzhang.site/2025/07/image-b8f946109d63fe1ccb5e2d63933e3f9e.png)\n\n- **Cline‰∏≠‰ΩøÁî®ÊïàÊûú**\n![cline_gen_image-48d8515e0b59cd313879c62a1546162d.png](https://image.harryzhang.site/2025/07/cline_gen_image-48d8515e0b59cd313879c62a1546162d.png)\n![ComfyUI_00020_-d9171f87fc9e67fcc1966cdbfb952a0c.png](https://image.harryzhang.site/2025/07/ComfyUI_00020_-d9171f87fc9e67fcc1966cdbfb952a0c.png)\n\n## ÂÆâË£Ö‰æùËµñ\n\n**1. Á°Æ‰øùÂ∑≤ÂÆâË£ÖPython 3.12+**\n\n**2. ‰ΩøÁî®uvÁÆ°ÁêÜPythonÁéØÂ¢ÉÔºö**\n- ÂÆâË£Öuv:\n  ```bash\n  # On macOS and Linux.\n  $ curl -LsSf https://astral.sh/uv/install.sh | sh\n\n  # On Windows.\n  $ powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n  # Êõ¥Êñ∞uv(ÈùûÂøÖË¶ÅÊìç‰Ωú):\n  $ uv self update\n  ```\n\n## ÊµãËØïËøêË°åÊúçÂä°\n\n- **uvxÊñπÂºè**\n  ```bash\n  $ uvx hh-mcp-comfyui\n\n  INFO:hh_mcp_comfyui.server:Scanning for workflows in: C:\\Users\\tianw\\AppData\\Local\\uv\\cache\\archive-v0\\dp4MTo0f1qL0DdYF_BYCL\\Lib\\site-packages\\hh_mcp_comfyui\\workflows\n  INFO:hh_mcp_comfyui.server:Starting ComfyUI MCP Server...\n  ```\n- **pipÊñπÂºè**\n  ```bash\n  $ pip install hh_mcp_comfyui\n  \n  $ python -m hh_mcp_comfyui\n\n  INFO:hh_mcp_comfyui.server:Scanning for workflows in: F:\\Python\\Python313\\Lib\\site-packages\\hh_mcp_comfyui\\workflows\n  INFO:hh_mcp_comfyui.server:Starting ComfyUI MCP Server...\n  ```\n**Âá∫Áé∞‰∏äÈù¢ÁöÑ‰ø°ÊÅØË°®Á§∫ÊúçÂä°ÂêØÂä®ÊàêÂäü**\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\u003e **ÂøÖÈ°ªÁ°Æ‰øùÊú¨Âú∞ComfyUIÂÆû‰æãÊ≠£Âú®ËøêË°å(ÈªòËÆ§Âú∞ÂùÄ: http://127.0.0.1:8188) [ComfyUIÂÆâË£ÖÂú∞ÂùÄ](https://github.com/comfyanonymous/ComfyUI.git)**\n\n### Cherry Studio„ÄÅCline„ÄÅCursorÁ≠âÂÆ¢Êà∑Á´ØÁöÑ‰ΩøÁî®ÊñπÂºè\n\n\u003cdetails\u003e\n  \u003csummary\u003euvx MCPÊúçÂä°ÈÖçÁΩÆ\u003c/summary\u003e\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"uvx\",\n        \"args\": [\n          \"hh-mcp-comfyui@latest\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n  \u003c/details\u003e\n\n\u003cdetails\u003e\n  \u003csummary\u003epip MCPÊúçÂä°ÈÖçÁΩÆ\u003c/summary\u003e\n\n  **ÈúÄË¶ÅÂÖàÊâßË°åÂëΩ‰ª§Á™óÂè£ÂÖàÊâßË°åÔºöpip install hh_mcp_comfyui**\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"python\",\n        \"args\": [\n          \"-m\",\n          \"hh_mcp_comfyui\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n\u003c/details\u003e\n\n\u003cdetails\u003e\n  \u003csummary\u003edocker MCPÊúçÂä°ÈÖçÁΩÆ\u003c/summary\u003e\n\n  **ÂâçÊèêÊòØÂ∑≤ÂÆâË£Ödocker**\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"docker\",\n        \"args\": [\n            \"run\",\n            \"--net=host\",\n            \"-v\",\n            \"/path/hh-mcp-comfyui/workflows:/app/workflows\",\n            \"-i\",\n            \"--rm\",\n            \"zjf2671/hh-mcp-comfyui:latest\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\"\n        }\n      }\n    }\n  }\n  ```\n\u003c/details\u003e\n\n## Ê†∑‰æãÂ∑•‰ΩúÊµÅcopyÂà∞ÊåáÂÆöÂ∑•‰ΩúÊµÅÁõÆÂΩïÔºö\n\n  Ôºà**Ê≥®ÊÑè**Ôºö‰ΩøÁî®‰∏ãÈù¢uvxÊàñpipÊñπÂºèÊâæÂà∞‰Ω†ÁöÑÂÆâË£ÖÂ∑•‰ΩúÊµÅÁõÆÂΩïÁöÑ‰ΩçÁΩÆÊääÊ†∑‰æãÂ∑•‰ΩúÊµÅÊ∑ªÂä†ËøõÂéªÔºåÁÑ∂ÂêéÈáçÂêØ‰Ω†ÁöÑMCPÊúçÂä°Ôºâ\n- **uvx**\n  ```bash\n  $ uvx hh-mcp-comfyui\n  ```\n  ![image-2-f89caf964efbccdad7b6fa2672d1cac0.png](https://image.harryzhang.site/2025/07/image-2-f89caf964efbccdad7b6fa2672d1cac0.png)\n- **pip**\n  \n   ```bash\n  #È¶ñÂÖàÂÆâË£Ö‰æùËµñ\n  $ pip install hh_mcp_comfyui\n  $ python -m hh_mcp_comfyui\n  ```\n  ![image-3-03a069f40492fea9947a351b8707aa3f.png](https://image.harryzhang.site/2025/07/image-3-03a069f40492fea9947a351b8707aa3f.png)\n\n## ÊµãËØï\n\n\u003e **‰ΩøÁî®MCP InspectorÊµãËØïÊúçÂä°Á´ØÂ∑•ÂÖ∑**\n\n- **uvxÊñπÂºè**\n  ```bash\n  $ npx @modelcontextprotocol/inspector uvx hh-mcp-comfyui\n  ``` \n- **pipÊñπÂºè**\n  ```bash\n  $ pip install hh_mcp_comfyui\n  $ npx @modelcontextprotocol/inspector python -m hh_mcp_comfyui\n  ``` \n - **dockerÊñπÂºè**\n    ```bash\n    $ npx @modelcontextprotocol/inspector docker run --net=host -i --rm zjf2671/hh-mcp-comfyui\n    ``` \nÁÑ∂ÂêéÁÇπÂáªËøûÊé•Â¶ÇÂõæÂç≥ÂèØË∞ÉËØïÔºö\n![image-1-44c6a003ee317093afe5a61cfe028720.png](https://image.harryzhang.site/2025/07/image-1-44c6a003ee317093afe5a61cfe028720.png)\n\n## ‰ΩøÁî®Ê≥®ÊÑè‰∫ãÈ°πÔºàÈíàÂØπÊ≤°ÊúâÁî®ËøácomfyuiÁöÑÁâπÂà´Ê≥®ÊÑèÔºâ\n\n- ÈªòËÆ§Â∑•‰ΩúÊµÅ‰∏∫`t2image_bizyair_flux`\n- ÂõæÁâáÂ∞∫ÂØ∏ÈªòËÆ§‰∏∫1024x1024\n- ÊúçÂä°ÂêØÂä®Êó∂‰ºöËá™Âä®Âä†ËΩΩworkflowsÁõÆÂΩï‰∏ãÁöÑÊâÄÊúâJSONÂ∑•‰ΩúÊµÅÊñá‰ª∂\n- Â¶ÇÊûú‰Ω†‰ΩøÁî®ÁöÑÊòØÊú¨È°πÁõÆ‰∏≠ÁöÑ**Ê†∑‰æãÂ∑•‰ΩúÊµÅ**ÈúÄË¶ÅÂú®comfyui‰∏≠‰∏ãËΩΩ‰∏™Êèí‰ª∂ÔºåËØ¶ÁªÜÊìç‰ΩúËØ∑Êü•ÁúãÔºö[Ê†∑‰æãÂ∑•‰ΩúÊµÅÊèí‰ª∂ÂÆâË£ÖÊïôÁ®ã](https://ziitefe2yxn.feishu.cn/wiki/PlSmwBbBWiA0iDkc07scb4EEnHc)\n- Â¶ÇÊûú‰ΩøÁî®‰Ω†Êú¨Âú∞ÁöÑcomfyuiÂ∑•‰ΩúÊµÅÁöÑËØùÔºåÂÖàË¶Å‰øùËØÅ‰Ω†ÁöÑÂ∑•‰ΩúÊµÅËÉΩÂú®comfyuiÊ≠£Â∏∏ËøêË°åÔºåÁÑ∂ÂêéÈúÄË¶ÅÂØºÂá∫(API)ÁöÑJSONÊ†ºÂºèÔºåÂπ∂ÊîæÂÖ•Âà∞‰Ω†Êú¨Âú∞ÁöÑ`/path/hh_mcp_comfyui/workflows`ÁõÆÂΩï‰∏≠\n\n## Ê∑ªÂä†Êñ∞Â∑•‰ΩúÊµÅ\n\n1. Â∞ÜÂ∑•‰ΩúÊµÅJSONÊñá‰ª∂ÊîæÂÖ•`/path/hh_mcp_comfyui/workflows`ÁõÆÂΩï‰∏≠\n  \n    Â¶ÇÊûúÊòØuvxÂíåpipÂêØÂä®ÊñπÂºèËØ∑Áúã‰∏äÈù¢ „Ää**Ê†∑‰æãÂ∑•‰ΩúÊµÅcopyÂà∞ÊåáÂÆöÂ∑•‰ΩúÊµÅÁõÆÂΩï**„Äã ÁöÑ‰ΩøÁî®ÊñπÂºè\n\n2. ÈáçÂêØÊúçÂä°Ëá™Âä®Âä†ËΩΩÊñ∞Â∑•‰ΩúÊµÅ\n\n## ÂºÄÂèë\n\n\n### È°πÁõÆÁªìÊûÑ\n\n```\n.\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ .python-version\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ uv.lock\n‚îú‚îÄ‚îÄ example/              # Á§∫‰æãÂ∑•‰ΩúÊµÅÁõÆÂΩï\n‚îÇ   ‚îî‚îÄ‚îÄ workflows/\n‚îÇ       ‚îú‚îÄ‚îÄ i2image_bizyair_sdxl.json\n‚îÇ       ‚îú‚îÄ‚îÄ t2image_bizyair_flux.json\n‚îÇ       ‚îú‚îÄ‚îÄ i2image_cogview4.json\n‚îÇ       ‚îî‚îÄ‚îÄ t2image_sd1.5.json\n‚îú‚îÄ‚îÄ src/                  # Ê∫ê‰ª£Á†ÅÁõÆÂΩï\n‚îÇ   ‚îî‚îÄ‚îÄ hh_mcp_comfyui/\n‚îÇ       ‚îú‚îÄ‚îÄ comfyui_client.py    # ComfyUIÂÆ¢Êà∑Á´ØÂÆûÁé∞\n‚îÇ       ‚îú‚îÄ‚îÄ server.py            # MCPÊúçÂä°‰∏ªÊñá‰ª∂\n‚îÇ       ‚îî‚îÄ‚îÄ workflows/           # Â∑•‰ΩúÊµÅÊñá‰ª∂ÁõÆÂΩï\n```\n\n\n ### ÂàùÂßãÂåñÈ°πÁõÆÂºÄÂèëÁéØÂ¢ÉÔºö  \n\n  ```bash\n  # Clone the repository.\n  $ git clone https://github.com/zjf2671/hh-mcp-comfyui.git\n\n  $ cd hh-mcp-comfyui\n\n  # Initialized venv\n  $ uv venv\n\n  # Activate the virtual environment.\n  $ .venv\\Scripts\\activate\n\n  # Install dependencies.\n  $ uv lock\n  Resolved 30 packages in 1ms\n\n  # sync dependencies.\n  $ uv sync\n  Resolved 30 packages in 2.54s\n  Audited 29 package in 0.02ms\n  ```\n\n### Ê£ÄÊü•ÊúçÂä°ÊòØÂê¶Ê≠£Â∏∏\n\n  ```bash\n  $ uv --directory ‰Ω†Êú¨Âú∞ÂÆâË£ÖÁõÆÂΩï/hh-mcp-comfyui run hh-mcp-comfyui\n\n  INFO:__main__:Scanning for workflows in: D:\\cygitproject\\hh-mcp-comfyui\\src\\hh_mcp_comfyui\\workflows\n  INFO:__main__:Registered resource: workflow://t2image_bizyair_flux -\u003e t2image_bizyair_flux.json\n  INFO:__main__:Starting ComfyUI MCP Server...\n  ```\n### ‰ΩøÁî®MCP InspectorÊµãËØïÊúçÂä°Á´ØÂ∑•ÂÖ∑\n  \n  ```bash\n  $ npx @modelcontextprotocol/inspector uv --directory ‰Ω†Êú¨Âú∞ÂÆâË£ÖÁõÆÂΩï/hh-mcp-comfyui run hh-mcp-comfyui\n  ```\n\n### MCPÈÖçÁΩÆ\n\n  ```bash\n  {\n    \"mcpServers\": {\n      \"hh-mcp-comfyui\": {\n        \"command\": \"uv\",\n        \"args\": [\n          \"--directory\",\n          \"È°πÁõÆÁªùÂØπË∑ØÂæÑÔºà‰æãÂ¶ÇÔºöD:/hh-mcp-comfyuiÔºâ\",\n          \"run\",\n          \"hh-mcp-comfyui\"\n        ],\n        \"env\": {\n          \"COMFYUI_API_BASE\": \"http://127.0.0.1:8188\",\n          \"COMFYUI_WORKFLOWS_DIR\": \"/path/hh-mcp-comfyui/workflows\"\n        }\n      }\n    }\n  }\n  ```\n\n## Ë¥°ÁåÆ\n\n1. ForkÈ°πÁõÆ\n2. ÂàõÂª∫ÁâπÊÄßÂàÜÊîØ (`git checkout -b feature/AmazingFeature`)\n3. Êèê‰∫§Êõ¥Êîπ (`git commit -m 'Add some AmazingFeature'`)\n4. Êé®ÈÄÅÂà∞ÂàÜÊîØ (`git push origin feature/AmazingFeature`)\n5. ÊâìÂºÄPull Request\n\n---\n## Â¶ÇÊúâÈóÆÈ¢òÂèØ‰ª•Âà∞ÂÖ¨‰ºóÂè∑‰∏≠ËÅîÁ≥ªÊàëÔºö\n\n*\u003ccenter\u003e![ÂÖ¨‰ºóÂè∑‰∫åÁª¥Á†Å](https://image.harryzhang.site/2025/04/image-1-5ac2e62b072e6f1d6eb4e3638634094c.png)\u003c/center\u003e*\n\n\u003ccenter\u003e\u003cu\u003eüëÜ Êâ´Á†ÅÂÖ≥Ê≥®ÔºåÂèëÁé∞Êõ¥Â§öÂ•ΩÁé©ÁöÑÔºÅ\u003c/u\u003e\u003c/center\u003e\n\n---\n",
      "stars": 16,
      "updated_at": "2025-09-18T16:25:43Z",
      "url": "https://github.com/zjf2671/hh-mcp-comfyui"
    },
    "zxkane--mcp-server-amazon-bedrock": {
      "category": "image-and-video-generation",
      "description": "Integrates with Amazon Bedrock's Nova Canvas model to generate high-quality images based on text descriptions. Provides advanced features for refining image composition through negative prompts and allows control over image dimensions and quality.",
      "forks": 11,
      "imageUrl": "/freedevtools/mcp/pfp/zxkane.webp",
      "keywords": [
        "bedrock",
        "canvas",
        "images",
        "amazon bedrock",
        "bedrock nova",
        "image composition"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "mcp-server-amazon-bedrock",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "zxkane",
      "readme_content": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zxkane-mcp-server-amazon-bedrock-badge.png)](https://mseep.ai/app/zxkane-mcp-server-amazon-bedrock)\n\n# Amazon Bedrock MCP Server\n\nA Model Control Protocol (MCP) server that integrates with Amazon Bedrock's Nova Canvas model for AI image generation.\n\n\u003ca href=\"https://glama.ai/mcp/servers/9qw7dwpvj9\"\u003e\u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/9qw7dwpvj9/badge\" alt=\"Amazon Bedrock Server MCP server\" /\u003e\u003c/a\u003e\n\n## Features\n\n- High-quality image generation from text descriptions using Amazon's Nova Canvas model\n- Advanced control through negative prompts to refine image composition\n- Flexible configuration options for image dimensions and quality\n- Deterministic image generation with seed control\n- Robust input validation and error handling\n\n## Prerequisites\n\n1. Active AWS account with Amazon Bedrock and Nova Canvas model access\n2. Properly configured AWS credentials with required permissions\n3. Node.js version 18 or later\n\n## Installation\n\n### AWS Credentials Configuration\n\nThe server requires AWS credentials with appropriate Amazon Bedrock permissions. Configure these using one of the following methods:\n\n1. Environment variables:\n   ```bash\n   export AWS_ACCESS_KEY_ID=your_access_key\n   export AWS_SECRET_ACCESS_KEY=your_secret_key\n   export AWS_REGION=us-east-1  # or your preferred region\n   ```\n\n2. AWS credentials file (`~/.aws/credentials`):\n   ```ini\n   [the_profile_name]\n   aws_access_key_id = your_access_key\n   aws_secret_access_key = your_secret_key\n   ```\n   Environment variable for active profile:\n   ```bash\n   export AWS_PROFILE=the_profile_name\n   ```\n\n3. IAM role (when deployed on AWS infrastructure)\n\n### Claude Desktop Integration\n\nTo integrate with Claude Desktop, add the following configuration to your settings file:\n\nMacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nWindows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"amazon-bedrock\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@zxkane/mcp-server-amazon-bedrock\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your_profile_name\",         // Optional, only if you want to use a specific profile\n        \"AWS_ACCESS_KEY_ID\": \"your_access_key\",     // Optional if using AWS credentials file or IAM role\n        \"AWS_SECRET_ACCESS_KEY\": \"your_secret_key\", // Optional if using AWS credentials file or IAM role\n        \"AWS_REGION\": \"us-east-1\"                   // Optional, defaults to 'us-east-1'\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n### generate_image\n\nCreates images from text descriptions using Amazon Bedrock's Nova Canvas model.\n\n#### Parameters\n\n- `prompt` (required): Descriptive text for the desired image (1-1024 characters)\n- `negativePrompt` (optional): Elements to exclude from the image (1-1024 characters)\n- `width` (optional): Image width in pixels (default: 1024)\n- `height` (optional): Image height in pixels (default: 1024)\n- `quality` (optional): Image quality level - \"standard\" or \"premium\" (default: \"standard\")\n- `cfg_scale` (optional): Prompt adherence strength (1.1-10, default: 6.5)\n- `seed` (optional): Generation seed for reproducibility (0-858993459, default: 12)\n- `numberOfImages` (optional): Batch size for generation (1-5, default: 1)\n\n#### Example Implementation\n\n```typescript\nconst result = await callTool('generate_image', {\n  prompt: \"A serene mountain landscape at sunset\",\n  negativePrompt: \"people, buildings, vehicles\",\n  quality: \"premium\",\n  cfg_scale: 8,\n  numberOfImages: 2\n});\n```\n\n#### Prompt Guidelines\n\nFor optimal results, avoid negative phrasing (\"no\", \"not\", \"without\") in the main prompt. Instead, move these elements to the `negativePrompt` parameter. For example, rather than using \"a landscape without buildings\" in the prompt, use \"buildings\" in the `negativePrompt`.\n\nFor detailed usage guidelines, refer to the [Nova Canvas documentation][nova-canvas-doc].\n\n## Development\n\nTo set up and run the server in a local environment:\n\n```bash\ngit clone https://github.com/zxkane/mcp-server-amazon-bedrock.git\ncd mcp-server-amazon-bedrock\nnpm install\nnpm run build\n```\n\n### Performance Considerations\n\nGeneration time is influenced by resolution (`width` and `height`), `numberOfImages`, and `quality` settings. When using higher values, be mindful of potential timeout implications in your implementation.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n[nova-canvas-doc]: https://docs.aws.amazon.com/nova/latest/userguide/image-gen-access.html\n",
      "stars": 21,
      "updated_at": "2025-09-25T09:31:13Z",
      "url": "https://github.com/zxkane/mcp-server-amazon-bedrock"
    },
    "zym9863--pixabay-mcp": {
      "category": "image-and-video-generation",
      "description": "Connect to the Pixabay API to search for images and retrieve formatted results that include image URLs and metadata. Handle errors seamlessly during API interactions for reliable performance.",
      "forks": 1,
      "imageUrl": "/freedevtools/mcp/pfp/zym9863.webp",
      "keywords": [
        "pixabay",
        "images",
        "mcp",
        "pixabay api",
        "pixabay mcp",
        "connect pixabay"
      ],
      "language": "JavaScript",
      "license": "MIT License",
      "name": "pixabay-mcp",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "zym9863",
      "readme_content": "# pixabay-mcp MCP Server\n\n[‰∏≠ÊñáÁâà](README_zh.md)\n\nA Model Context Protocol (MCP) server for Pixabay image and video search with structured results \u0026 runtime validation.\n\n\u003ca href=\"https://glama.ai/mcp/servers/@zym9863/pixabay-mcp\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/@zym9863/pixabay-mcp/badge\" alt=\"Pixabay Server MCP server\" /\u003e\n\u003c/a\u003e\n\nThis TypeScript MCP server exposes Pixabay search tools over stdio so AI assistants / agents can retrieve media safely and reliably.\n\nHighlights:\n- Image \u0026 video search tools (Pixabay official API)\n- Runtime argument validation (enums, ranges, semantic checks)\n- Consistent error logging without leaking sensitive keys\n- Planned structured JSON payloads for easier downstream automation (see Roadmap)\n\n## Features\n\n### Tools\n`search_pixabay_images`\n  - Required: `query` (string)\n  - Optional: `image_type` (all|photo|illustration|vector), `orientation` (all|horizontal|vertical), `per_page` (3-200)\n  - Returns: human-readable text block (current) + (planned) structured JSON array of hits\n\n`search_pixabay_videos`\n  - Required: `query`\n  - Optional: `video_type` (all|film|animation), `orientation`, `per_page` (3-200), `min_duration`, `max_duration`\n  - Returns: human-readable text block + (planned) structured JSON with duration \u0026 URLs\n\n### Configuration\nEnvironment variables:\n| Name | Required | Default | Description |\n| ---- | -------- | ------- | ----------- |\n| `PIXABAY_API_KEY` | Yes | - | Your Pixabay API key (images \u0026 videos) |\n| `PIXABAY_TIMEOUT_MS` | No | 10000 (planned) | Request timeout once feature lands |\n| `PIXABAY_RETRY` | No | 0 (planned) | Number of retry attempts for transient network errors |\n\nNotes:\n- Safe search is enabled by default.\n- Keys are never echoed back in structured errors or logs.\n\n## Usage Examples\n\nCurrent (text only response excerpt):\n```\nFound 120 images for \"cat\":\n- cat, pet, animal (User: Alice): https://.../medium1.jpg\n- kitten, cute (User: Bob): https://.../medium2.jpg\n```\n\nPlanned structured result (Roadmap v0.4+):\n```jsonc\n{\n  \"content\": [\n    { \"type\": \"text\", \"text\": \"Found 120 images for \\\"cat\\\":\\n- ...\" },\n    {\n      \"type\": \"json\",\n      \"data\": {\n        \"query\": \"cat\",\n        \"totalHits\": 120,\n        \"page\": 1,\n        \"perPage\": 20,\n        \"hits\": [\n          { \"id\": 123, \"tags\": [\"cat\",\"animal\"], \"user\": \"Alice\", \"previewURL\": \"...\", \"webformatURL\": \"...\", \"largeImageURL\": \"...\" }\n        ]\n      }\n    }\n  ]\n}\n```\n\nError response (planned shape):\n```json\n{\n  \"content\": [{ \"type\": \"text\", \"text\": \"Pixabay API error: 400 ...\" }],\n  \"isError\": true,\n  \"metadata\": { \"status\": 400, \"code\": \"UPSTREAM_BAD_REQUEST\", \"hint\": \"Check API key or parameters\" }\n}\n```\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nWatch mode:\n```bash\nnpm run watch\n```\n\n## Installation\n\n### Option 1: Using npx (Recommended)\n\nAdd this to your Claude Desktop configuration:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"pixabay-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"pixabay-mcp@latest\"],\n      \"env\": {\n        \"PIXABAY_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### Option 2: Local Installation\n\n1. Clone and build the project:\n\n```bash\ngit clone https://github.com/zym9863/pixabay-mcp.git\ncd pixabay-mcp\nnpm install\nnpm run build\n```\n\n2. Add the server config:\n\n```json\n{\n  \"mcpServers\": {\n    \"pixabay-mcp\": {\n      \"command\": \"/path/to/pixabay-mcp/build/index.js\",\n      \"env\": {\n        \"PIXABAY_API_KEY\": \"your_api_key_here\"\n      }\n    }\n  }\n}\n```\n\n### API Key Setup\n\nGet your Pixabay API key from [https://pixabay.com/api/docs/](https://pixabay.com/api/docs/) and set it in the configuration above. The same key grants access to both image and video endpoints.\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## Roadmap (Condensed)\n| Version | Focus | Key Items |\n| ------- | ----- | --------- |\n| v0.4 | Structured \u0026 Reliability | JSON payload, timeout, structured errors |\n| v0.5 | UX \u0026 Pagination | page/order params, limited retry, modular refactor, tests |\n| v0.6 | Multi-source Exploration | Evaluate integrating Unsplash/Pexels abstraction |\n\nSee `product.md` for full backlog \u0026 prioritization.\n\n## Contributing\nPlanned contributions welcome once tests \u0026 module split land (v0.5 target). Feel free to open issues for API shape / schema suggestions.\n\n## License\nMIT\n\n## Disclaimer\nThis project is not affiliated with Pixabay. Respect Pixabay's Terms of Service and rate limits.\n",
      "stars": 4,
      "updated_at": "2025-09-29T07:41:49Z",
      "url": "https://github.com/zym9863/pixabay-mcp"
    },
    "zym9863--together-ai-image-server": {
      "category": "image-and-video-generation",
      "description": "Generates images from text prompts using Together AI's image generation models via the MCP protocol. It supports optional parameters for fine-tuning the image generation process.",
      "forks": 4,
      "imageUrl": "/freedevtools/mcp/pfp/zym9863.webp",
      "keywords": [
        "images",
        "ai",
        "image",
        "ai image",
        "generates images",
        "image generation"
      ],
      "language": "TypeScript",
      "license": "MIT License",
      "name": "together-ai-image-server",
      "npm_downloads": 0,
      "npm_url": "",
      "owner": "zym9863",
      "readme_content": "# Together AI Image Server\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh.md)\n\nA TypeScript-based MCP (Model Context Protocol) server for generating images using Together AI API.\n\n\u003ca href=\"https://glama.ai/mcp/servers/p1ctvg1l87\"\u003e\n  \u003cimg width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/p1ctvg1l87/badge\" alt=\"Together AI Image Server MCP server\" /\u003e\n\u003c/a\u003e\n\n## Overview\n\nThis server provides a simple interface to generate images using Together AI's image generation models through the MCP protocol. It allows Claude and other MCP-compatible assistants to generate images based on text prompts.\n\n## Features\n\n### Tools\n\n- `generate_image` - Generate images from text prompts\n  - Takes a text prompt as required parameter\n  - Optional parameters for controlling generation steps and number of images\n  - Returns URLs and local paths to generated images\n\n## Prerequisites\n\n- Node.js (v14 or later recommended)\n- Together AI API key\n\n## Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/zym9863/together-ai-image-server.git\ncd together-ai-image-server\n\n# Install dependencies\nnpm install\n```\n\n## Configuration\n\nSet your Together AI API key as an environment variable:\n\n```bash\n# On Linux/macOS\nexport TOGETHER_API_KEY=\"your-api-key-here\"\n\n# On Windows (Command Prompt)\nset TOGETHER_API_KEY=your-api-key-here\n\n# On Windows (PowerShell)\n$env:TOGETHER_API_KEY=\"your-api-key-here\"\n```\n\nAlternatively, you can create a `.env` file in the project root:\n\n```\nTOGETHER_API_KEY=your-api-key-here\n```\n\n## Development\n\nBuild the server:\n\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n\n```bash\nnpm run watch\n```\n\n## Usage with Claude Desktop\n\nTo use with Claude Desktop, add the server config:\n\nOn macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`  \nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"Together AI Image Server\": {\n      \"command\": \"/path/to/together-ai-image-server/build/index.js\"\n    }\n  }\n}\n```\n\nReplace `/path/to/together-ai-image-server` with the actual path to your installation.\n\n## Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n## API Reference\n\n### generate_image\n\nGenerates images based on a text prompt using Together AI's image generation API.\n\n**Parameters:**\n\n- `prompt` (string, required): Text prompt for image generation\n- `steps` (number, optional, default: 4): Number of diffusion steps (1-4)\n- `n` (number, optional, default: 1): Number of images to generate (1-4)\n\n**Returns:**\n\nJSON object containing:\n- `image_urls`: Array of URLs to the generated images\n- `local_paths`: Array of paths to locally cached images\n\n## License\n\nMIT\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.",
      "stars": 4,
      "updated_at": "2025-04-21T08:41:48Z",
      "url": "https://github.com/zym9863/together-ai-image-server"
    }
  },
  "totalRepositories": 135
}